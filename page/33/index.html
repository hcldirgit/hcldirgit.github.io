<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>失落的乐章</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="失落的乐章的Blog">
<meta property="og:type" content="website">
<meta property="og:title" content="失落的乐章">
<meta property="og:url" content="https://hcldirgit.github.io/page/33/index.html">
<meta property="og:site_name" content="失落的乐章">
<meta property="og:description" content="失落的乐章的Blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="失落的乐章">
<meta name="twitter:description" content="失落的乐章的Blog">
  
    <link rel="alternative" href="/atom.xml" title="失落的乐章" type="application/atom+xml">
  
  
    <link rel="icon" href="https://github.com/hcldirgit/image/blob/master/0.png?raw=true">
  
  <link rel="stylesheet" href="/css/style.css">
  
  
<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-85415703-1', 'auto');
  ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  <script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
  <script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
</head>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://github.com/hcldirgit/image/blob/master/0.png?raw=true" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">失落的乐章</a></h1>
		</hgroup>

		
		<p class="header-subtitle">技术面前，永远都是学生。</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/tags">静心阅读</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Ansible/" style="font-size: 10.42px;">Ansible</a> <a href="/tags/Apache/" style="font-size: 18.33px;">Apache</a> <a href="/tags/Cacti/" style="font-size: 11.67px;">Cacti</a> <a href="/tags/DNS/" style="font-size: 13.33px;">DNS</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/FTP/" style="font-size: 11.25px;">FTP</a> <a href="/tags/Git/" style="font-size: 10.83px;">Git</a> <a href="/tags/HA集群/" style="font-size: 11.67px;">HA集群</a> <a href="/tags/Hadoop/" style="font-size: 12.5px;">Hadoop</a> <a href="/tags/Jenkins/" style="font-size: 10.42px;">Jenkins</a> <a href="/tags/LAMP/" style="font-size: 19.58px;">LAMP</a> <a href="/tags/LNMP/" style="font-size: 17.08px;">LNMP</a> <a href="/tags/LVS/" style="font-size: 16.67px;">LVS</a> <a href="/tags/Linux/" style="font-size: 19.17px;">Linux</a> <a href="/tags/Linux命令/" style="font-size: 20px;">Linux命令</a> <a href="/tags/Linux安全/" style="font-size: 14.17px;">Linux安全</a> <a href="/tags/Memcached/" style="font-size: 11.25px;">Memcached</a> <a href="/tags/MongoDB/" style="font-size: 15.42px;">MongoDB</a> <a href="/tags/MySQL/" style="font-size: 17.5px;">MySQL</a> <a href="/tags/NFS/" style="font-size: 10px;">NFS</a> <a href="/tags/Nagios/" style="font-size: 11.67px;">Nagios</a> <a href="/tags/Nginx/" style="font-size: 17.92px;">Nginx</a> <a href="/tags/OpenStack/" style="font-size: 11.25px;">OpenStack</a> <a href="/tags/Php/" style="font-size: 14.58px;">Php</a> <a href="/tags/Puppet/" style="font-size: 11.25px;">Puppet</a> <a href="/tags/Python/" style="font-size: 14.58px;">Python</a> <a href="/tags/Redis/" style="font-size: 16.25px;">Redis</a> <a href="/tags/Resin/" style="font-size: 10px;">Resin</a> <a href="/tags/Saltstack/" style="font-size: 10px;">Saltstack</a> <a href="/tags/Samba/" style="font-size: 12.08px;">Samba</a> <a href="/tags/Squid/" style="font-size: 14.58px;">Squid</a> <a href="/tags/Tomcat/" style="font-size: 13.75px;">Tomcat</a> <a href="/tags/Zabbix/" style="font-size: 15.83px;">Zabbix</a> <a href="/tags/haproxy/" style="font-size: 12.5px;">haproxy</a> <a href="/tags/keepalived/" style="font-size: 12.92px;">keepalived</a> <a href="/tags/shell/" style="font-size: 15px;">shell</a> <a href="/tags/shell练习/" style="font-size: 18.75px;">shell练习</a> <a href="/tags/正则表达式/" style="font-size: 12.92px;">正则表达式</a>
					</div>
				</section>
				
				
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">失落的乐章</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="https://github.com/hcldirgit/image/blob/master/0.png?raw=true" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">失落的乐章</h1>
			</hgroup>
			
			<p class="header-subtitle">技术面前，永远都是学生。</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/tags">静心阅读</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap">
  
    <article id="post-Hadoop/6. HDFS原理分析—— 基本概念" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/09/03/Hadoop/6. HDFS原理分析—— 基本概念/" class="article-date">
  	<time datetime="2017-09-02T18:02:06.166Z" itemprop="datePublished">2017-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/03/Hadoop/6. HDFS原理分析—— 基本概念/">
        HDFS原理分析—— 基本概念
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS是Hadoop Distribute File System 的简称，也就是Hadoop的一个分布式文件系统。</p>
<h2 id="一、HDFS的主要设计理念"><a href="#一、HDFS的主要设计理念" class="headerlink" title="一、HDFS的主要设计理念"></a>一、HDFS的主要设计理念</h2><h3 id="1、存储超大文件"><a href="#1、存储超大文件" class="headerlink" title="1、存储超大文件"></a>1、存储超大文件</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里的“超大文件”是指几百MB、GB甚至TB级别的文件。</p>
<h3 id="2、最高效的访问模式是-一次写入、多次读取-流式数据访问"><a href="#2、最高效的访问模式是-一次写入、多次读取-流式数据访问" class="headerlink" title="2、最高效的访问模式是 一次写入、多次读取(流式数据访问)"></a>2、最高效的访问模式是 一次写入、多次读取(流式数据访问)</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS存储的数据集作为hadoop的分析对象。在数据集生成后，长时间在此数据集上进行各种分析。每次分析都将设计该数据集的大部分数据甚至全部数据，因此读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要。</p>
<h3 id="3、运行在普通廉价的服务器上"><a href="#3、运行在普通廉价的服务器上" class="headerlink" title="3、运行在普通廉价的服务器上"></a>3、运行在普通廉价的服务器上</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS设计理念之一就是让它能运行在普通的硬件之上，即便硬件出现故障，也可以通过容错策略来保证数据的高可用。</p>
<h2 id="二、HDFS的忌讳"><a href="#二、HDFS的忌讳" class="headerlink" title="二、HDFS的忌讳"></a>二、HDFS的忌讳</h2><h3 id="1、将HDFS用于对数据访问要求低延迟的场景"><a href="#1、将HDFS用于对数据访问要求低延迟的场景" class="headerlink" title="1、将HDFS用于对数据访问要求低延迟的场景"></a>1、将HDFS用于对数据访问要求低延迟的场景</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;由于HDFS是为高数据吞吐量应用而设计的，必然以高延迟为代价。</p>
<h3 id="2、存储大量小文件"><a href="#2、存储大量小文件" class="headerlink" title="2、存储大量小文件"></a>2、存储大量小文件</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS中元数据（文件的基本信息）存储在namenode的内存中，而namenode为单点，小文件数量大到一定程度，namenode内存就吃不消了。</p>
<h2 id="三、HDFS基本概念"><a href="#三、HDFS基本概念" class="headerlink" title="三、HDFS基本概念"></a>三、HDFS基本概念</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据块（block）：大文件会被分割成多个block进行存储，block大小默认为64MB。每一个block会在多个datanode上存储多份副本，默认是3份。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;namenode：namenode负责管理文件目录、文件和block的对应关系以及block和datanode的对应关系。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;datanode：datanode就负责存储了，当然大部分容错机制都是在datanode上实现的。</p>
<h2 id="四、HDFS基本架构图"><a href="#四、HDFS基本架构图" class="headerlink" title="四、HDFS基本架构图"></a>四、HDFS基本架构图</h2><p><img src="https://github.com/hcldirgit/image/blob/master/HDFS%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%20%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/01.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图中有几个概念需要介绍一下</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Rack 是指机柜的意思，一个block的三个副本通常会保存到两个或者两个以上的机柜中（当然是机柜中的服务器），这样做的目的是做防灾容错，因为发生一个机柜掉电或者一个机柜的交换机挂了的概率还是蛮高的。</p>
<h2 id="五、HDFS写文件流程"><a href="#五、HDFS写文件流程" class="headerlink" title="五、HDFS写文件流程"></a>五、HDFS写文件流程</h2><p><img src="https://github.com/hcldirgit/image/blob/master/HDFS%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%20%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/02.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;思考：</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在datanode执行create file后，namenode采用什么策略给client分配datanode？</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;顺序写入三个datanode，写入过程中有一个datanode挂掉了，如何容错？</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;client往datanode写入数据时挂掉了，怎么容错？</p>
<h2 id="六、HDFS读文件流程"><a href="#六、HDFS读文件流程" class="headerlink" title="六、HDFS读文件流程"></a>六、HDFS读文件流程</h2><p><img src="https://github.com/hcldirgit/image/blob/master/HDFS%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%20%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/03.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;思考：namenode挂掉了怎么办，这个时候HDFS是否有相应的容错方案。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Hadoop/5. HDFS 原理、架构与特性介绍" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/09/03/Hadoop/5. HDFS 原理、架构与特性介绍/" class="article-date">
  	<time datetime="2017-09-02T18:02:06.165Z" itemprop="datePublished">2017-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/03/Hadoop/5. HDFS 原理、架构与特性介绍/">
        HDFS 原理、架构与特性介绍
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;本文主要讲述 HDFS原理-架构、副本机制、HDFS负载均衡、机架感知、健壮性、文件删除恢复机制</p>
<h2 id="1-当前HDFS架构详尽分析"><a href="#1-当前HDFS架构详尽分析" class="headerlink" title="1.当前HDFS架构详尽分析"></a>1.当前HDFS架构详尽分析</h2><p><img src="https://github.com/hcldirgit/image/blob/master/HDFS%20%E5%8E%9F%E7%90%86%E3%80%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/01.jpeg?raw=true" alt=""></p>
<h3 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h3><ul>
<li>NameNode </li>
<li>DataNode </li>
<li>Sencondary NameNode </li>
</ul>
<h3 id="数据存储细节"><a href="#数据存储细节" class="headerlink" title="数据存储细节"></a>数据存储细节</h3><p><img src="https://github.com/hcldirgit/image/blob/master/HDFS%20%E5%8E%9F%E7%90%86%E3%80%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/02.jpeg?raw=true" alt=""></p>
<h3 id="NameNode-目录结构"><a href="#NameNode-目录结构" class="headerlink" title="NameNode 目录结构"></a>NameNode 目录结构</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 的目录结构： </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$&#123; dfs.name.dir&#125;</span>/current /VERSION</div><div class="line">                         /edits</div><div class="line">                         /fsimage</div><div class="line">                         /fstime</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;dfs.name.dir 是 hdfs-site.xml 里配置的若干个目录组成的列表。 </p>
<h4 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h4><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 上保存着 HDFS 的名字空间。对于任何对文件系统元数据产生修改的操作， Namenode 都会使用一种称为 EditLog 的事务日志记录下来。例如，在 HDFS 中创建一个文件， Namenode 就会在 Editlog 中插入一条记录来表示；同样地，修改文件的副本系数也将往 Editlog 插入一条记录。 Namenode 在本地操作系统的文件系统中存储这个 Editlog 。整个文件系统的名 字空间，包括数据块到文件的映射、文件的属性等，都存储在一个称为 FsImage 的文件中，这 个文件也是放在 Namenode 所在的本地文件系统上。 </p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 在内存中保存着整个文件系统的名字空间和文件数据块映射 (Blockmap) 的映像 。这个关键的元数据结构设计得很紧凑，因而一个有 4G 内存的 Namenode 足够支撑大量的文件 和目录。当 Namenode 启动时，它从硬盘中读取 Editlog 和 FsImage ，将所有 Editlog 中的事务作 用在内存中的 FsImage 上，并将这个新版本的 FsImage 从内存中保存到本地磁盘上，然后删除 旧的 Editlog ，因为这个旧的 Editlog 的事务都已经作用在 FsImage 上了。这个过程称为一个检查 点 (checkpoint) 。在当前实现中，检查点只发生在 Namenode 启动时，在不久的将来将实现支持 周期性的检查点。 </p>
<h4 id="HDFS-NameSpace"><a href="#HDFS-NameSpace" class="headerlink" title="HDFS NameSpace"></a>HDFS NameSpace</h4><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS 支持传统的层次型文件组织结构。用户或者应用程序可以创建目 录，然后将文件保存在这些目录里。文件系统名字空间的层次结构和大多数 现有的文件系统类似：用户可以创建、删除、移动或重命名文件。当前， HDFS 不支持用户磁盘配额和访问权限控制，也不支持硬链接和软链接。但 是 HDFS 架构并不妨碍实现这些特性。 </p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 负责维护文件系统命名空间，任何对文件系统名字空间或属 性的修改都将被 Namenode 记录下来。应用程序可以设置 HDFS 保存的文件 的副本数目。文件副本的数目称为文件的副本系数，这个信息也是由 Namenode 保存的。 </p>
<h4 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h4><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Datanode 将 HDFS 数据以文件的形式存储在本地的文件系统中，它并不知道有 关 HDFS 文件的信息。它把每个 HDFS 数据块存储在本地文件系统的一个单独的文件 中。 Datanode 并不在同一个目录创建所有的文件，实际上，它用试探的方法来确定 每个目录的最佳文件数目，并且在适当的时候创建子目录。在同一个目录中创建所 有的本地文件并不是最优的选择，这是因为本地文件系统可能无法高效地在单个目 录中支持大量的文件。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当一个 Datanode 启动时，它会扫描本地文件系统，产生一个这些本地文件对应 的所有 HDFS 数据块的列表，然后作为报告发送到 Namenode ，这个报告就是块状态 报告。</p>
<h4 id="配置Secondary-NameNode"><a href="#配置Secondary-NameNode" class="headerlink" title="配置Secondary NameNode"></a>配置Secondary NameNode</h4><ul>
<li>conf/masters文件指定的为Secondary NameNode节点</li>
<li>修改在masters文件中配置了的机器上的conf/hdfs-site.xml文件，加上如下选项：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.http.address&lt;/name&gt;</div><div class="line">    &lt;value&gt;namenode.hadoop-host.com:50070&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure>
<ul>
<li>core-site.xml：这里有2个参数可配置，但一般来说我们不做修改。fs.checkpoint.period表示多长时间记录一次hdfs的镜像。默认是1小时。fs.checkpoint.size表示一次记录多大的size，默认64M。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;fs.checkpoint.period&lt;/name&gt;</div><div class="line">    &lt;value&gt;3600&lt;/value&gt;</div><div class="line">    &lt;description&gt;The number of seconds between two periodic checkpoints. &lt;/description</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">    &lt;name&gt;fs.checkpoint.size&lt;/name&gt;</div><div class="line">    &lt;value&gt;67108864&lt;/value&gt;</div><div class="line">    &lt;description&gt;The size of the current edit <span class="built_in">log</span> (<span class="keyword">in</span> bytes) that triggers a periodic checkpoint even <span class="keyword">if</span> the fs.checkpoint.period hasn<span class="string">'t expired. &lt;/description&gt;</span></div><div class="line"><span class="string">&lt;/property&gt;</span></div></pre></td></tr></table></figure>
<h3 id="Secondary-NameNode"><a href="#Secondary-NameNode" class="headerlink" title="Secondary NameNode"></a>Secondary NameNode</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Secondary NameNode 定期合并 fsimage 和 edits 日志，将 edits 日志文件大小控制在一个限度下。</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/HDFS%20%E5%8E%9F%E7%90%86%E3%80%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/03.jpeg?raw=true" alt=""></p>
<h4 id="Secondary-NameNode处理流程"><a href="#Secondary-NameNode处理流程" class="headerlink" title="Secondary NameNode处理流程"></a>Secondary NameNode处理流程</h4><ol>
<li>namenode 响应 Secondary namenode 请求，将 edit log 推送给 Secondary namenode ， 开始重新写一个新的 edit log 。</li>
<li>Secondary namenode 收到来自 namenode 的 fsimage 文件和 edit log 。</li>
<li>Secondary namenode 将 fsimage 加载到内存，应用 edit log ， 并生成一 个新的 fsimage 文件。</li>
<li>Secondary namenode 将新的 fsimage 推送给 Namenode 。</li>
<li>Namenode 用新的 fsimage 取代旧的 fsimage ， 在 fstime 文件中记下检查 点发生的时</li>
</ol>
<h4 id="HDFS通信协议"><a href="#HDFS通信协议" class="headerlink" title="HDFS通信协议"></a>HDFS通信协议</h4><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所有的 HDFS 通讯协议都是构建在 TCP/IP 协议上。客户端通过一个可 配置的端口连接到 Namenode ， 通过 ClientProtocol 与 Namenode 交互。而 Datanode 是使用 DatanodeProtocol 与 Namenode 交互。再设计上， DataNode 通过周期性的向 NameNode 发送心跳和数据块来保持和 NameNode 的通信，数据块报告的信息包括数据块的属性，即数据块属于哪 个文件，数据块 ID ，修改时间等， NameNode 的 DataNode 和数据块的映射 关系就是通过系统启动时 DataNode 的数据块报告建立的。从 ClientProtocol 和 Datanodeprotocol 抽象出一个远程调用 ( RPC ）， 在设计上， Namenode 不会主动发起 RPC ， 而是是响应来自客户端和 Datanode 的 RPC 请求。 </p>
<h4 id="HDFS的安全模式"><a href="#HDFS的安全模式" class="headerlink" title="HDFS的安全模式"></a>HDFS的安全模式</h4><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 启动后会进入一个称为安全模式的特殊状态。处于安全模式 的 Namenode 是不会进行数据块的复制的。 Namenode 从所有的 Datanode 接收心跳信号和块状态报告。块状态报告包括了某个 Datanode 所有的数据 块列表。每个数据块都有一个指定的最小副本数。当 Namenode 检测确认某 个数据块的副本数目达到这个最小值，那么该数据块就会被认为是副本安全 (safely replicated) 的；在一定百分比（这个参数可配置）的数据块被 Namenode 检测确认是安全之后（加上一个额外的 30 秒等待时间）， Namenode 将退出安全模式状态。接下来它会确定还有哪些数据块的副本没 有达到指定数目，并将这些数据块复制到其他 Datanode 上。</p>
<h2 id="2-HDFS文件读取的解析"><a href="#2-HDFS文件读取的解析" class="headerlink" title="2.HDFS文件读取的解析"></a>2.HDFS文件读取的解析</h2><p>###文件读取流程</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/HDFS%20%E5%8E%9F%E7%90%86%E3%80%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/04.jpeg?raw=true" alt=""></p>
<h3 id="流程分析"><a href="#流程分析" class="headerlink" title="流程分析"></a>流程分析</h3><ul>
<li>使用HDFS提供的客户端开发库Client，向远程的Namenode发起RPC请求；</li>
<li>Namenode会视情况返回文件的部分或者全部block列表，对于每个block，Namenode都会返回有该block拷贝的DataNode地址；</li>
<li>客户端开发库Client会选取离客户端最接近的DataNode来读取block；如果客户端本身就是DataNode,那么将从本地直接获取数据.</li>
<li>读取完当前block的数据后，关闭与当前的DataNode连接，并为读取下一个block寻找最佳的DataNode；</li>
<li>当读完列表的block后，且文件读取还没有结束，客户端开发库会继续向Namenode获取下一批的block列表。</li>
<li>读取完一个block都会进行checksum验证，如果读取datanode时出现错误，客户端会通知Namenode，然后再从下一个拥有该block拷贝的datanode继续读。</li>
</ul>
<h2 id="3-HDFS文件写入的解析"><a href="#3-HDFS文件写入的解析" class="headerlink" title="3.HDFS文件写入的解析"></a>3.HDFS文件写入的解析</h2><h3 id="文件写入流程"><a href="#文件写入流程" class="headerlink" title="文件写入流程"></a>文件写入流程</h3><p><img src="https://github.com/hcldirgit/image/blob/master/HDFS%20%E5%8E%9F%E7%90%86%E3%80%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/05.jpeg?raw=true" alt=""></p>
<h3 id="流程分析-1"><a href="#流程分析-1" class="headerlink" title="流程分析"></a>流程分析</h3><ul>
<li>使用HDFS提供的客户端开发库Client，向远程的Namenode发起RPC请求； </li>
<li>Namenode会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件 创建一个记录，否则会让客户端抛出异常；</li>
<li>当客户端开始写入文件的时候，会将文件切分成多个packets，并在内部以数据队列”data queue”的形式管理这些packets，并向Namenode申请新的blocks，获取用来存储replicas的合适的datanodes列表，列表的大小根据在Namenode中对replication的设置而定。</li>
<li>开始以pipeline（管道）的形式将packet写入所有的replicas中。把packet以流的方式写入第一个datanode，该datanode把该packet存储之后，再将其传递给在此pipeline中的下一个datanode，直到最后一个datanode，这种写数据的方式呈流水线的形式。</li>
<li>最后一个datanode成功存储之后会返回一个ack packet，在pipeline里传递至客户端，在客户端的开发库内部维护着”ack queue”，成功收到datanode返回的ack packet后会从”ack queue”移除相应的packet。</li>
<li>如果传输过程中，有某个datanode出现了故障，那么当前的pipeline会被关闭，出现故障的datanode会从当前的pipeline中移除，剩余的block会继续剩下的datanode中继续以pipeline的形式传输，同时Namenode会分配一个新的datanode，保持replicas设定的数量。</li>
</ul>
<h3 id="流水线复制"><a href="#流水线复制" class="headerlink" title="流水线复制"></a>流水线复制</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当客户端向 HDFS 文件写入数据的时候，一开始是写到本地临时文件中。假设该文件的副 本系数设置为 3 ，当本地临时文件累积到一个数据块的大小时，客户端会从 Namenode 获取一个 Datanode 列表用于存放副本。然后客户端开始向第一个 Datanode 传输数据，第一个 Datanode 一小部分一小部分 (4 KB) 地接收数据，将每一部分写入本地仓库，并同时传输该部分到列表中 第二个 Datanode 节点。第二个 Datanode 也是这样，一小部分一小部分地接收数据，写入本地 仓库，并同时传给第三个 Datanode 。最后，第三个 Datanode 接收数据并存储在本地。因此， Datanode 能流水线式地从前一个节点接收数据，并在同时转发给下一个节点，数据以流水线的 方式从前一个 Datanode 复制到下一个</p>
<h3 id="更细节的原理"><a href="#更细节的原理" class="headerlink" title="更细节的原理"></a>更细节的原理</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;客户端创建文件的请求其实并没有立即发送给 Namenode ，事实上，在刚开始阶 段 HDFS 客户端会先将文件数据缓存到本地的一个临时文件。应用程序的写操作被透 明地重定向到这个临时文件。当这个临时文件累积的数据量超过一个数据块的大小 ，客户端才会联系 Namenode 。 Namenode 将文件名插入文件系统的层次结构中，并 且分配一个数据块给它。然后返回 Datanode 的标识符和目标数据块给客户端。接着 客户端将这块数据从本地临时文件上传到指定的 Datanode 上。当文件关闭时，在临 时文件中剩余的没有上传的数据也会传输到指定的 Datanode 上。然后客户端告诉 Namenode 文件已经关闭。此时 Namenode 才将文件创建操作提交到日志里进行存储 。如果 Namenode 在文件关闭前宕机了，则该文件将丢失。</p>
<h2 id="4-副本机制"><a href="#4-副本机制" class="headerlink" title="4.副本机制"></a>4.副本机制</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;特点</p>
<ol>
<li>数据类型单一</li>
<li>副本数比较多</li>
<li>写文件时副本的放置方法</li>
<li>动态的副本创建策略</li>
<li>弱化的副本一致性要求</li>
</ol>
<h3 id="副本摆放策略"><a href="#副本摆放策略" class="headerlink" title="副本摆放策略"></a>副本摆放策略</h3><p><img src="https://github.com/hcldirgit/image/blob/master/HDFS%20%E5%8E%9F%E7%90%86%E3%80%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/06.jpeg?raw=true" alt=""></p>
<h3 id="修改副本数"><a href="#修改副本数" class="headerlink" title="修改副本数"></a>修改副本数</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;集群只有三个Datanode，hadoop系统replication=4时，会出现什么情况？</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于上传文件到hdfs上时，当时hadoop的副本系数是几，这个文件的块数副本数就会有几份，无论以后你怎么更改系统副本系统，这个文件的副本数都不会改变，也就说上传到分布式系统上的文件副本数由当时的系统副本数决定，不会受replication的更改而变化，除非用命令来更改文件的副本数。因为dfs.replication实质上是client参数，在create文件时可以指定具体replication，属性dfs.replication是不指定具体replication时的采用默认备份数。文件上传后，备份数已定，修改dfs.replication是不会影响以前的文件的，也不会影响后面指定备份数的文件。只影响后面采用默认备份数的文件。但可以利用hadoop提供的命令后期改某文件的备份数：hadoop fs -setrep -R 1。如果你是在hdfs-site.xml设置了dfs.replication，这并一定就得了，因为你可能没把conf文件夹加入到你的 project的classpath里，你的程序运行时取的dfs.replication可能是hdfs-default.xml里的 dfs.replication，默认是3。可能这个就是造成你为什么dfs.replication老是3的原因。你可以试试在创建文件时，显式设定replication。replication一般到3就可以了，大了意义也不大。</p>
<h2 id="5-HDFS负载均衡"><a href="#5-HDFS负载均衡" class="headerlink" title="5.HDFS负载均衡"></a>5.HDFS负载均衡</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS的数据也许并不是非常均匀的分布在各个DataNode中。一个常见的原因是在现有的集群上经常会增添新的DataNode节点。当新增一个数据块（一个文件的数据被保存在一系列的块中）时，NameNode在选择DataNode接收这个数据块之前，会考虑到很多因素。其中的一些考虑的是：</p>
<ul>
<li>将数据块的一个副本放在正在写这个数据块的节点上。</li>
<li>尽量将数据块的不同副本分布在不同的机架上，这样集群可在完全失去某一机架的情况下还能存活。</li>
<li>一个副本通常被放置在和写文件的节点同一机架的某个节点上，这样可以减少跨越机架的网络I/O。</li>
<li>尽量均匀地将HDFS数据分布在集群的DataNode中。</li>
</ul>
<h2 id="6-HDFS机架感知"><a href="#6-HDFS机架感知" class="headerlink" title="6.HDFS机架感知"></a>6.HDFS机架感知</h2><h3 id="HDFS机架感知"><a href="#HDFS机架感知" class="headerlink" title="HDFS机架感知"></a>HDFS机架感知</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通常，大型 Hadoop 集群是以机架的形式来组织的，同一个机架上不同 节点间的网络状况比不同机架之间的更为理想。 另外， NameNode 设法将 数据块副本保存在不同的机架上以提高容错性。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;而 HDFS 不能够自动判断集群中各个 datanode 的网络拓扑情况 Hadoop 允 许集群的管理员通过配置 dfs.network.script 参数来确定节点所处的机架。 文 件提供了 IP-&gt;rackid 的翻译。 NameNode 通过这个得到集群中各个 datanode 机器的 rackid 。 如果 topology.script.file.name 没有设定，则每个 IP 都会翻译 成 / default-rack。</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/HDFS%20%E5%8E%9F%E7%90%86%E3%80%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/07.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;有了机架感知， NameNode 就可以画出上图所示的 datanode 网络拓扑图。 D1,R1 都是交换机，最底层是 datanode 。 则 H1 的 rackid=/D1/R1/H1 ， H1 的 parent 是 R1 ， R1 的是 D1 。 这些 rackid 信息可以通过 topology.script.file.name 配置。有了这些 rackid 信息就可以计算出任意两台 datanode 之间的距离。</p>
<p>distance(/D1/R1/H1,/D1/R1/H1)=0  相同的 datanode<br>distance(/D1/R1/H1,/D1/R1/H2)=2  同一 rack 下的不同 datanode<br>distance(/D1/R1/H1,/D1/R1/H4)=4  同一 IDC 下的不同 datanode<br>distance(/D1/R1/H1,/D2/R3/H7)=6   不同 IDC 下的 datanode    </p>
<h2 id="7-HDFS访问"><a href="#7-HDFS访问" class="headerlink" title="7.HDFS访问"></a>7.HDFS访问</h2><h3 id="访问方式"><a href="#访问方式" class="headerlink" title="访问方式"></a>访问方式</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; HDFS 给应用提供了多种访问方式。用户可以通过 Java API 接口访问，也 可以通过 C 语言的封装 API 访问，还可以通过浏览器的方式访问 HDFS 中的文件。    </p>
<h2 id="8-HDFS-健壮性"><a href="#8-HDFS-健壮性" class="headerlink" title="8.HDFS 健壮性"></a>8.HDFS 健壮性</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS 的主要目标就是即使在出错的情况下也要保证数据存储的可靠性。 常见的三种出错情况是： Namenode 出错 , Datanode 出错和网络割裂 ( network partitions) 。   </p>
<h3 id="磁盘数据错误，心跳检测和重新复制"><a href="#磁盘数据错误，心跳检测和重新复制" class="headerlink" title="磁盘数据错误，心跳检测和重新复制"></a>磁盘数据错误，心跳检测和重新复制</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个 Datanode 节点周期性地向 Namenode 发送心跳信号。网络割裂可能 导致一部分 Datanode 跟 Namenode 失去联系。 Namenode 通过心跳信号的缺 失来检测这一情况，并将这些近期不再发送心跳信号 Datanode 标记为宕机 ，不会再将新的 IO 请求发给它们。任何存储在宕机 Datanode 上的数据将不 再有效。 Datanode 的宕机可能会引起一些数据块的副本系数低于指定值， Namenode 不断地检测这些需要复制的数据块，一旦发现就启动复制操作。 在下列情况下，可能需要重新复制：某个 Datanode 节点失效，某个副本遭 到损坏， Datanode 上的硬盘错误，或者文件的副本系数增大。    </p>
<h3 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;从某个 Datanode 获取的数据块有可能是损坏的，损坏可能是由 Datanode 的存储设备错误、网络错误或者软件 bug 造成的。 HDFS 客户端软 件实现了对 HDFS 文件内容的校验和 (checksum) 检查。当客户端创建一个新 的 HDFS 文件，会计算这个文件每个数据块的校验和，并将校验和作为一个 单独的隐藏文件保存在同一个 HDFS 名字空间下。当客户端获取文件内容后 ，它会检验从 Datanode 获取的数据跟相应的校验和文件中的校验和是否匹 配，如果不匹配，客户端可以选择从其他 Datanode 获取该数据块的副本。    </p>
<h3 id="元数据磁盘错误"><a href="#元数据磁盘错误" class="headerlink" title="元数据磁盘错误"></a>元数据磁盘错误</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;FsImage 和 Editlog 是 HDFS 的核心数据结构。如果这些文件损坏了，整个 HDFS 实例都将失效。因而， Namenode 可以配置成支持维护多个 FsImage 和 Editlog 的副本。任何对 FsImage 或者 Editlog 的修改，都将同步到它们的副 本上。这种多副本的同步操作可能会降低 Namenode 每秒处理的名字空间事 务数量。然而这个代价是可以接受的，因为即使 HDFS 的应用是数据密集的 ，它们也非元数据密集的。当 Namenode 重启的时候，它会选取最近的完整 的 FsImage 和 Editlog 来使用。    </p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode 是 HDFS 集群中的单点故障 (single point of failure) 所在。如果 Namenode 机器故障，是需要手工干预的。目前，自动重启或在另一台机器 上做 Namenode 故障转移的功能还没实现。    </p>
<h3 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;快照支持某一特定时刻的数据的复制备份。利用快照，可以让 HDFS 在 数据损坏时恢复到过去一个已知正确的时间点。 HDFS 目前还不支持快照功 能，但计划在将来的版本进行支持。     </p>
<h2 id="9-HDFS-文件删除恢复机制"><a href="#9-HDFS-文件删除恢复机制" class="headerlink" title="9.HDFS 文件删除恢复机制"></a>9.HDFS 文件删除恢复机制</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当用户或应用程序删除某个文件时，这个文件并没有立刻从 HDFS 中删 除。实际上， HDFS 会将这个文件重命名转移到 /trash 目录。只要文件还在 /trash 目录中，该文件就可以被迅速地恢复。文件在 /trash 中保存的时间是可 配置的，当超过这个时间时， Namenode 就会将该文件从名字空间中删除。 删除文件会使得该文件相关的数据块被释放。注意，从用户删除文件到 HDFS 空闲空间的增加之间会有一定时间的延迟。    </p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只要被删除的文件还在 /trash 目录中，用户就可以恢复这个文件。如果 用户想恢复被删除的文件，他 / 她可以浏览 /trash 目录找回该文件。 /trash 目 录仅仅保存被删除文件的最后副本。 /trash 目录与其他的目录没有什么区别 ，除了一点：在该目录上 HDFS 会应用一个特殊策略来自动删除文件。目前 的默认策略是删除 /trash 中保留时间超过 6 小时的文件。将来，这个策略可以 通过一个被良好定义的接口配置。    </p>
<h3 id="开启回收站"><a href="#开启回收站" class="headerlink" title="开启回收站"></a>开启回收站</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">hdfs-site.xml    </div><div class="line">&lt;configuration&gt;    </div><div class="line">       &lt;property&gt;    </div><div class="line">               &lt;name&gt;fs.trash.interval&lt;/name&gt;    </div><div class="line">                &lt;value&gt;    1440   &lt;/value&gt;    </div><div class="line">                &lt;description&gt;Number ofminutes between trash checkpoints.    </div><div class="line">                        If zero, the trashfeature is disabled.    </div><div class="line">                &lt;/description&gt;    </div><div class="line">       &lt;/property&gt;    </div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<ol>
<li>fs.trash.interval参数设置保留时间为 1440 分钟(1天)    </li>
<li>回收站的位置：在HDFS上的 /user/$USER/.Trash/Current/      </li>
</ol>
<h2 id="10-HDFS-分布式缓存（DistributedCache-）"><a href="#10-HDFS-分布式缓存（DistributedCache-）" class="headerlink" title="10.HDFS 分布式缓存（DistributedCache ）"></a>10.HDFS 分布式缓存（DistributedCache ）</h2><ol>
<li>在HDFS上准备好要共享的数据(text、archive、jar)，你拼路径的时候必须加前缀”file://“说明是本地路径，否则hadoop默认访问的路径是hdfs。</li>
<li>DistributedCache 在 Mapper 或者 Reducer 启动时会被 copy to local，然后被 DistributedCache.getLocalCacheFiles() 调用，运行完 job 后 local cache file 会被删掉，如果另一个 job 也需要这样一份文件，需要重新添加、重新缓存，因为在分布式场景下 task 并不知道该 node 是否存在 cache file。如果在同台机器已经有了dist cache file,不会再次download，DistributedCache 根据缓存文档修改的时间戳进行追踪。 在作业执行期间，当前应用程序或者外部程序不能修改缓存文件，所以分布式缓存一般用来缓存只读文件。</li>
<li>DistributedCache 在添加的时候注意要添加具体的文件，如果你添加目录，DistributedCache 将不会自动遍历、识别目录下的文件。</li>
</ol>
<h2 id="11-HDFS缺点"><a href="#11-HDFS缺点" class="headerlink" title="11.HDFS缺点"></a>11.HDFS缺点</h2><h3 id="大量小文件"><a href="#大量小文件" class="headerlink" title="大量小文件"></a>大量小文件</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;因为 Namenode 把文件系统的元数据放置在内存中，所以文件系统所能 容纳的文件数目是由 Namenode 的内存大小来决定。一般来说，每一个文件 、文件夹和 Block 需要占据 150 字节左右的空间，所以，如果你有 100 万个文 件，每一个占据一个 Block ，你就至少需要 300MB 内存。当前来说，数百万 的文件还是可行的，当扩展到数十亿时，对于当前的硬件水平来说就没法实 现了。还有一个问题就是，因为 Map task 的数量是由 splits 来决定的，所以 用 MR 处理大量的小文件时，就会产生过多的 Maptask ，线程管理开销将会 增加作业时间。举个例子，处理 10000M 的文件，若每个 split 为 1M ，那就会 有 10000 个 Maptasks ，会有很大的线程开销；若每个 split 为 100M ，则只有 100 个 Maptasks ，每个 Maptask 将会有更多的事情做，而线程的管理开销也 将减小很多。 </p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Hadoop/4. Avro简介" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/09/03/Hadoop/4. Avro简介/" class="article-date">
  	<time datetime="2017-09-02T18:02:06.164Z" itemprop="datePublished">2017-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/03/Hadoop/4. Avro简介/">
        Avro简介
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h2><h3 id="1、-简介"><a href="#1、-简介" class="headerlink" title="1、 简介"></a>1、 简介</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro是Hadoop中的一个子项目，也是Apache中一个独立的项目，Avro是一个基于二进制数据传输高性能的中间件。在Hadoop的其他项目中例如HBase(Ref)和Hive(Ref)的Client端与服务端的数据传输也采用了这个工具。Avro是一个数据序列化的系统。Avro 可以将数据结构或对象转化成便于存储或传输的格式。Avro设计之初就用来支持数据密集型应用，适合于远程或本地大规模数据的存储和交换。</p>
<h3 id="2、-特点"><a href="#2、-特点" class="headerlink" title="2、 特点"></a>2、 特点</h3><ul>
<li>丰富的数据结构类型；</li>
<li>快速可压缩的二进制数据形式，对数据二进制序列化后可以节约数据存储空间和网络传输带宽；</li>
<li>存储持久数据的文件容器；</li>
<li>可以实现远程过程调用RPC；</li>
<li>简单的动态语言结合功能。</li>
</ul>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;avro支持跨编程语言实现（C, C++, C#，Java, Python, Ruby, PHP），类似于Thrift，但是avro的显著特征是：avro依赖于模式，动态加载相关数据的模式，Avro数据的读写操作很频繁，而这些操作使用的都是模式，这样就减少写入每个数据文件的开销，使得序列化快速而又轻巧。这种数据及其模式的自我描述方便了动态脚本语言的使用。当Avro数据存储到文件中时，它的模式也随之存储，这样任何程序都可以对文件进行处理。如果读取数据时使用的模式与写入数据时使用的模式不同，也很容易解决，因为读取和写入的模式都是已知的。</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Avro%E7%AE%80%E4%BB%8B/01.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro和动态语言结合后，读/写数据文件和使用RPC协议都不需要生成代码，而代码生成作为一种可选的优化只需要在静态类型语言中实现。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro依赖于模式(Schema)。通过模式定义各种数据结构，只有确定了模式才能对数据进行解释，所以在数据的序列化和反序列化之前，必须先确定模式的结构。正是模式的引入，使得数据具有了自描述的功能，同时能够实现动态加载，另外与其他的数据序列化系统如Thrift相比，数据之间不存在其他的任何标识，有利于提高数据处理的效率。    </p>
<h2 id="二、技术要领"><a href="#二、技术要领" class="headerlink" title="二、技术要领"></a>二、技术要领</h2><h3 id="1、类型"><a href="#1、类型" class="headerlink" title="1、类型"></a>1、类型</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据类型标准化的意义：一方面使不同系统对相同的数据能够正确解析，另一方面，数据类型的标准定义有利于数据序列化/反序列化。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单的数据类型：Avro定义了几种简单数据类型，下表是其简单说明：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>null</td>
<td>no value</td>
</tr>
<tr>
<td>boolean</td>
<td>a binary value</td>
</tr>
<tr>
<td>int</td>
<td>32-bit signed integer</td>
</tr>
<tr>
<td>long</td>
<td>64-bit signed integer</td>
</tr>
<tr>
<td>float</td>
<td>single precision (32-bit) IEEE 754 floating-point number</td>
</tr>
<tr>
<td>double</td>
<td>double precision (64-bit) IEEE 754 floating-point number</td>
</tr>
<tr>
<td>bytes</td>
<td>sequence of 8-bit unsigned bytes</td>
</tr>
<tr>
<td>string</td>
<td>unicode character sequence</td>
</tr>
</tbody>
</table>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单数据类型由类型名称定义，不包含属性信息，例如字符串定义如下：</p>
<p>{“type”: “string”}</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复杂数据类型：Avro定义了六种复杂数据类型，每一种复杂数据类型都具有独特的属性，下表就每一种复杂数据类型进行说明。</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Avro%E7%AE%80%E4%BB%8B/02.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每一种复杂数据类型都含有各自的一些属性，其中部分属性是必需的，部分是可选的。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这里需要说明Record类型中field属性的默认值，当Record Schema实例数据中某个field属性没有提供实例数据时，则由默认值提供，具体值见下表。Union的field默认值由Union定义中的第一个Schema决定。</p>
<table>
<thead>
<tr>
<th>avro type</th>
<th>json type</th>
<th>example</th>
</tr>
</thead>
<tbody>
<tr>
<td>null</td>
<td>null</td>
<td>null</td>
</tr>
<tr>
<td>boolean</td>
<td>boolean</td>
<td>true</td>
</tr>
<tr>
<td>int,long</td>
<td>integer</td>
<td>1</td>
</tr>
<tr>
<td>float,double</td>
<td>number</td>
<td>1.1</td>
</tr>
<tr>
<td>bytes</td>
<td>string</td>
<td>“\u00FF”</td>
</tr>
<tr>
<td>string</td>
<td>string</td>
<td>“foo”</td>
</tr>
<tr>
<td>record</td>
<td>object</td>
<td>{“a”: 1}</td>
</tr>
<tr>
<td>enum</td>
<td>string</td>
<td>“FOO”</td>
</tr>
<tr>
<td>array</td>
<td>array</td>
<td>[1]</td>
</tr>
<tr>
<td>map</td>
<td>object</td>
<td>{“a”: 1}</td>
</tr>
<tr>
<td>fixed</td>
<td>string</td>
<td>“\u00ff”</td>
</tr>
</tbody>
</table>
<h3 id="2、序列化-反序列化"><a href="#2、序列化-反序列化" class="headerlink" title="2、序列化/反序列化"></a>2、序列化/反序列化</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro指定两种数据序列化编码方式：binary encoding 和Json encoding。使用二进制编码会高效序列化，并且序列化后得到的结果会比较小；而JSON一般用于调试系统或是基于WEB的应用。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;binary encoding规则如下：</p>
<ol>
<li>简单数据类型</li>
</ol>
<table>
<thead>
<tr>
<th>Type</th>
<th>Encoding</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>null</td>
<td>Zero bytes</td>
<td>Null</td>
</tr>
<tr>
<td>boolean</td>
<td>A single byte</td>
<td>{true:1, false:0}</td>
</tr>
<tr>
<td>int/long</td>
<td>variable-length zig-zag coding</td>
<td>&#160;</td>
</tr>
<tr>
<td>float</td>
<td>4 bytes</td>
<td>Java’s floatToIntBits</td>
</tr>
<tr>
<td>double</td>
<td>8 bytes</td>
<td>Java’s doubleToLongBits</td>
</tr>
<tr>
<td>bytes</td>
<td>a long followed by that many bytes of data</td>
<td>&#160;</td>
</tr>
<tr>
<td>string</td>
<td>a long followed by that many bytes of UTF-8 encoded character data</td>
<td>“foo”:{3,f,o,o} 06 66 6f 6f</td>
</tr>
</tbody>
</table>
<ol>
<li>复杂数据类型</li>
</ol>
<table>
<thead>
<tr>
<th>Type</th>
<th>encoding</th>
</tr>
</thead>
<tbody>
<tr>
<td>Records</td>
<td>encoded just the concatenation of the encodings of its fields</td>
</tr>
<tr>
<td>Enums</td>
<td>a int representing the zero-based position of the symbol in the schema</td>
</tr>
<tr>
<td>Arrays</td>
<td>encoded as series of blocks. A block with count 0 indicates the end of the array. block:{long,items}</td>
</tr>
<tr>
<td>Maps</td>
<td>encoded as series of blocks. A block with count 0 indicates the end of the map. block:{long,key/value pairs}.</td>
</tr>
<tr>
<td>Unions</td>
<td>encoded by first writing a long value indicating the zero-based position within the union of the schema of its value. The value is then encoded per the indicated schema within the union.</td>
</tr>
<tr>
<td>fixed</td>
<td>encoded using number of bytes declared in the schema</td>
</tr>
</tbody>
</table>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;实例：</p>
<ul>
<li>records</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line"><span class="string">"type"</span>:<span class="string">"record"</span>,</div><div class="line"><span class="string">"name"</span>:<span class="string">"test"</span>,</div><div class="line"><span class="string">"fields"</span> : [</div><div class="line">&#123;<span class="string">"name"</span>: <span class="string">"a"</span>,<span class="string">"type"</span>: <span class="string">"long"</span>&#125;,</div><div class="line">&#123;<span class="string">"name"</span>: <span class="string">"b"</span>,<span class="string">"type"</span>: <span class="string">"string"</span>&#125;</div><div class="line">]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;假设：a=27b=”foo” (encoding：36(27), 06(3), 66(“f”), 6f(“o”))</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;binary encoding：3606 66 6f 6f</p>
<ul>
<li>enums</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&#123;<span class="string">"type"</span>: <span class="string">"enum"</span>,<span class="string">"name"</span>: <span class="string">"Foo"</span>, <span class="string">"symbols"</span>: [<span class="string">"A"</span>,<span class="string">"B"</span>, <span class="string">"C"</span>, <span class="string">"D"</span>] &#125;</div><div class="line">“D”(encoding: 06(3))</div><div class="line">binary encoding: 06</div></pre></td></tr></table></figure>
<ul>
<li>arrays</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;<span class="string">"type"</span>: <span class="string">"array"</span>,<span class="string">"items"</span>: <span class="string">"long"</span>&#125;</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设：{3, 27 } (encoding：04(2), 06(3), 36(27) )</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;binary encoding：0406 36 00</p>
<ul>
<li>maps</li>
</ul>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设：{(“a”:1), (“b”:2) } （encoding：61(“a”), 62(“b”), 02(1), 04(2)）</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;binary encoding：0261 02 02 62 04</p>
<ul>
<li>unions</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[<span class="string">"string"</span>,<span class="string">"null"</span>]</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设：(1)null; (2) “a”<br>binary encoding：</p>
<p>(1) 02；说明：02代表null在union定义中的位置1；</p>
<p>(2) 00 02 61；说明：00为string在union定义的位置，02 61为”a”的编码。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图1表示的是Avro本地序列化和反序列化的实例，它将用户定义的模式和具体的数据编码成二进制序列存储在对象容器文件中，例如用户定义了包含学号、姓名、院系和电话的学生模式，而Avro对其进行编码后存储在student.db文件中，其中存储数据的模式放在文件头的元数据中，这样读取的模式即使与写入的模式不同，也可以迅速地读出数据。假如另一个程序需要获取学生的姓名和电话，只需要定义包含姓名和电话的学生模式，然后用此模式去读取容器文件中的数据即可。</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Avro%E7%AE%80%E4%BB%8B/06.jpeg?raw=true" alt=""></p>
<h3 id="3、模式Schema"><a href="#3、模式Schema" class="headerlink" title="3、模式Schema"></a>3、模式Schema</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Schema通过JSON对象表示。Schema定义了简单数据类型和复杂数据类型，其中复杂数据类型包含不同属性。通过各种数据类型用户可以自定义丰富的数据结构。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Schema由下列JSON对象之一定义：</p>
<ul>
<li>JSON字符串：命名</li>
<li>JSON对象：{“type”: “typeName” …attributes…}</li>
<li>JSON数组：Avro中Union的定义</li>
</ul>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;举例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">&#123;<span class="string">"namespace"</span>: <span class="string">"example.avro"</span>,</div><div class="line"> <span class="string">"type"</span>:<span class="string">"record"</span>,</div><div class="line"> <span class="string">"name"</span>:<span class="string">"User"</span>,</div><div class="line"> <span class="string">"fields"</span>: [</div><div class="line">     &#123;<span class="string">"name"</span>:<span class="string">"name"</span>, <span class="string">"type"</span>: <span class="string">"string"</span>&#125;,</div><div class="line">     &#123;<span class="string">"name"</span>:<span class="string">"favorite_number"</span>, <span class="string">"type"</span>: [<span class="string">"int"</span>, <span class="string">"null"</span>]&#125;,</div><div class="line">     &#123;<span class="string">"name"</span>:<span class="string">"favorite_color"</span>, <span class="string">"type"</span>: [<span class="string">"string"</span>,<span class="string">"null"</span>]&#125;</div><div class="line"> ]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="4、排序"><a href="#4、排序" class="headerlink" title="4、排序"></a>4、排序</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro为数据定义了一个标准的排列顺序。比较在很多时候是经常被使用到的对象之间的操作，标准定义可以进行方便有效的比较和排序。同时标准的定义可以方便对Avro的二进制编码数据直接进行排序而不需要反序列化。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只有当数据项包含相同的Schema的时候，数据之间的比较才有意义。数据的比较按照Schema深度优先，从左至右的顺序递归的进行。找到第一个不匹配即可终止比较。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两个拥有相同的模式的项的比较按照以下规则进行：</p>
<ul>
<li>null：总是相等。</li>
<li>int,long,float：按照数值大小比较。</li>
<li>boolean：false在true之前。</li>
<li>string：按照字典序进行比较。</li>
<li>bytes，fixed：按照byte的字典序进行比较。</li>
<li>array：按照元素的字典序进行比较。</li>
<li>enum：按照符号在枚举中的位置比较。</li>
<li>record：按照域的字典序排序，如果指定了以下属性：</li>
<li>“ascending”，域值的顺序不变。</li>
<li>“descending”，域值的顺序颠倒。</li>
<li>“ignore”，排序的时候忽略域值。</li>
<li>map：不可进行比较。</li>
</ul>
<h3 id="5、对象容器文件"><a href="#5、对象容器文件" class="headerlink" title="5、对象容器文件"></a>5、对象容器文件</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro定义了一个简单的对象容器文件格式。一个文件对应一个模式，所有存储在文件中的对象都是根据模式写入的。对象按照块进行存储，块可以采用压缩的方式存储。为了在进行mapreduce处理的时候有效的切分文件，在块之间采用了同步记号。一个文件可以包含任意用户定义的元数据。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个文件由两部分组成：文件头和一个或者多个文件数据块。</p>
<ul>
<li>文件头：<ul>
<li>四个字节，ASCII‘O’，‘b’，‘j’,1。</li>
<li>文件元数据，用于描述Schema。</li>
<li>16字节的文件同步记号。</li>
<li>其中，文件元数据的格式为：<ul>
<li>i.             值为-1的长整型，表明这是一个元数据块。</li>
<li>ii.             标识块长度的长整型。</li>
<li>iii.             标识块中key/value对数目的长整型。</li>
<li>iv.             每一个key/value对的string key和bytesvalue。</li>
<li>v.             标识块中字节总数的4字节长的整数。</li>
</ul>
</li>
</ul>
</li>
<li>文件数据块：<br>数据是以块结构进行组织的，一个文件可以包含一个或者多个文件数据块。<ul>
<li>表示文件中块中对象数目的长整型。</li>
<li>表示块中数据序列化后的字节数长度的长整型。</li>
<li>序列化的对象。</li>
<li>16字节的文件同步记号。</li>
</ul>
</li>
</ul>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当数据块的长度为0时即为文件数据块的最后一个数据，此后的所有数据被自动忽略。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下图示对象容器文件的结构分解及说明：</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Avro%E7%AE%80%E4%BB%8B/03.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个存储文件由两部分组成:头信息(Header)和数据块(Data Block)。而头信息又由三部分构成：四个字节的前缀，文件Meta-data信息和随机生成的16字节同步标记符。Avro目前支持的Meta-data有两种：schema和codec。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;codec表示对后面的文件数据块(File Data Block)采用何种压缩方式。Avro的实现都需要支持下面两种压缩方式：null(不压缩)和deflate(使用Deflate算法压缩数据块)。除了文档中认定的两种Meta-data，用户还可以自定义适用于自己的Meta-data。这里用long型来表示有多少个Meta-data数据对，也是让用户在实际应用中可以定义足够的Meta-data信息。对于每对Meta-data信息，都有一个string型的key(需要以“avro.” 为前缀)和二进制编码后的value。对于文件中头信息之后的每个数据块，有这样的结构：一个long值记录当前块有多少个对象，一个long值用于记录当前块经过压缩后的字节数，真正的序列化对象和16字节长度的同步标记符。由于对象可以组织成不同的块，使用时就可以不经过反序列化而对某个数据块进行操作。还可以由数据块数，对象数和同步标记符来定位损坏的块以确保数据完整性。</p>
<h2 id="三、RPC实现"><a href="#三、RPC实现" class="headerlink" title="三、RPC实现"></a>三、RPC实现</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当在RPC中使用Avro时，服务器和客户端可以在握手连接时交换模式。服务器和客户端有彼此全部的模式，因此相同命名字段、缺失字段和多余字段等信息之间通信中需要处理的一致性问题就可以容易解决。如图2所示，协议中定义了用于传输的消息，消息使用框架后放入缓冲区中进行传输，由于传输的初始就交换了各自的协议定义，因此即使传输双方使用的协议不同所传输的数据也能够正确解析。</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Avro%E7%AE%80%E4%BB%8B/04.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Avro作为RPC框架来使用。客户端希望同服务器端交互时，就需要交换双方通信的协议，它类似于模式，需要双方来定义，在Avro中被称为消息(Message)。通信双方都必须保持这种协议，以便于解析从对方发送过来的数据，这也就是传说中的握手阶段。 </p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;消息从客户端发送到服务器端需要经过传输层(Transport Layer)，它发送消息并接收服务器端的响应。到达传输层的数据就是二进制数据。通常以HTTP作为传输模型，数据以POST方式发送到对方去。在 Avro中，它的消息被封装成为一组缓冲区(Buffer)，类似于下图的模型：</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Avro%E7%AE%80%E4%BB%8B/05.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如上图，每个缓冲区以四个字节开头，中间是多个字节的缓冲数据，最后以一个空缓冲区结尾。这种机制的好处在于，发送端在发送数据时可以很方便地组装不同数据源的数据，接收方也可以将数据存入不同的存储区。还有，当往缓冲区中写数据时，大对象可以独占一个缓冲区，而不是与其它小对象混合存放，便于接收方方便地读取大对象。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对象容器文件是Avro的数据存储的具体实现，数据交换则由RPC服务提供，与对象容器文件类似，数据交换也完全依赖Schema，所以与Hadoop目前的RPC不同，Avro在数据交换之前需要通过握手过程先交换Schema。</p>
<h3 id="1、握手过程"><a href="#1、握手过程" class="headerlink" title="1、握手过程"></a>1、握手过程</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;握手的过程是确保Server和Client获得对方的Schema定义，从而使Server能够正确反序列化请求信息，Client能够正确反序列化响应信息。一般的，Server/Client会缓存最近使用到的一些协议格式，所以，大多数情况下，握手过程不需要交换整个Schema文本。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;所有的RPC请求和响应处理都建立在已经完成握手的基础上。对于无状态的连接，所有的请求响应之前都附有一次握手过程；对于有状态的连接，一次握手完成，整个连接的生命期内都有效。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;具体过程：</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Client发起HandshakeRequest，其中含有Client本身SchemaHash值和对应Server端的Schema Hash值(clientHash!=null,clientProtocol=null, serverHash!=null)。如果本地缓存有serverHash值则直接填充，如果没有则通过猜测填充。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Server用如下之一HandshakeResponse响应Client请求：</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(match=BOTH, serverProtocol=null,serverHash=null)：当Client发送正确的serverHash值且Server缓存相应的clientHash。握手过程完成，之后的数据交换都遵守本次握手结果。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(match=CLIENT, serverProtocol!=null,serverHash!=null)：当Server缓存有Client的Schema，但是Client请求中ServerHash值不正确。此时Server发送Server端的Schema数据和相应的Hash值，此次握手完成，之后的数据交换都遵守本次握手结果。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;(match=NONE)：当Client发送的ServerHash不正确且Server端没有Client Schema的缓存。这种情况下Client需要重新提交请求信息 (clientHash!=null,clientProtocol!=null, serverHash!=null)，Server响应 (match=BOTH, serverProtocol=null,serverHash=null)，此次握手过程完成，之后的数据交换都遵守本次握手结果。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;握手过程使用的Schema结构如下示。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line"><span class="string">"type"</span>:<span class="string">"record"</span>,</div><div class="line"><span class="string">"name"</span>:<span class="string">"HandshakeRequest"</span>,<span class="string">"namespace"</span>:<span class="string">"org.apache.avro.ipc"</span>,</div><div class="line"><span class="string">"fields"</span>:[</div><div class="line">&#123;<span class="string">"name"</span>:<span class="string">"clientHash"</span>, <span class="string">"type"</span>: &#123;<span class="string">"type"</span>: <span class="string">"fixed"</span>,<span class="string">"name"</span>: <span class="string">"MD5"</span>, <span class="string">"size"</span>: 16&#125;&#125;,</div><div class="line">&#123;<span class="string">"name"</span>:<span class="string">"clientProtocol"</span>, <span class="string">"type"</span>: [<span class="string">"null"</span>,<span class="string">"string"</span>]&#125;,</div><div class="line">&#123;<span class="string">"name"</span>:<span class="string">"serverHash"</span>, <span class="string">"type"</span>: <span class="string">"MD5"</span>&#125;,</div><div class="line">&#123;<span class="string">"name"</span>:<span class="string">"meta"</span>, <span class="string">"type"</span>: [<span class="string">"null"</span>, &#123;<span class="string">"type"</span>:<span class="string">"map"</span>, <span class="string">"values"</span>: <span class="string">"bytes"</span>&#125;]&#125;</div><div class="line">]</div><div class="line">&#125;</div><div class="line">&#123;</div><div class="line"><span class="string">"type"</span>:<span class="string">"record"</span>,</div><div class="line"><span class="string">"name"</span>:<span class="string">"HandshakeResponse"</span>, <span class="string">"namespace"</span>:<span class="string">"org.apache.avro.ipc"</span>,</div><div class="line"><span class="string">"fields"</span>:[</div><div class="line">&#123;<span class="string">"name"</span>:<span class="string">"match"</span>,<span class="string">"type"</span>: &#123;<span class="string">"type"</span>: <span class="string">"enum"</span>,<span class="string">"name"</span>: <span class="string">"HandshakeMatch"</span>,</div><div class="line"><span class="string">"symbols"</span>:[<span class="string">"BOTH"</span>, <span class="string">"CLIENT"</span>, <span class="string">"NONE"</span>]&#125;&#125;,</div><div class="line">&#123;<span class="string">"name"</span>:<span class="string">"serverProtocol"</span>, <span class="string">"type"</span>: [<span class="string">"null"</span>,<span class="string">"string"</span>]&#125;,</div><div class="line">&#123;<span class="string">"name"</span>:<span class="string">"serverHash"</span>,<span class="string">"type"</span>: [<span class="string">"null"</span>, &#123;<span class="string">"type"</span>:<span class="string">"fixed"</span>, <span class="string">"name"</span>: <span class="string">"MD5"</span>, <span class="string">"size"</span>: 16&#125;]&#125;,</div><div class="line">&#123;<span class="string">"name"</span>:<span class="string">"meta"</span>,<span class="string">"type"</span>: [<span class="string">"null"</span>, &#123;<span class="string">"type"</span>:<span class="string">"map"</span>, <span class="string">"values"</span>: <span class="string">"bytes"</span>&#125;]&#125;</div><div class="line">]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="2、消息帧格式"><a href="#2、消息帧格式" class="headerlink" title="2、消息帧格式"></a>2、消息帧格式</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;消息从客户端发送到服务器端需要经过传输层，它发送请求并接收服务器端的响应。到达传输层的数据就是二进制数据。通常以HTTP作为传输模型，数据以POST方式发送到对方去。在 Avro中消息首先分帧后被封装成为一组缓冲区(Buffer)。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;数据帧的格式如下：</p>
<ul>
<li>一系列Buffer：<ul>
<li>4字节的Buffer长度</li>
<li>Buffer字节数据</li>
</ul>
</li>
<li>长度为0的Buffer结束数据帧 </li>
</ul>
<h3 id="3、Call格式"><a href="#3、Call格式" class="headerlink" title="3、Call格式"></a>3、Call格式</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一个调用由请求消息、结果响应消息或者错误消息组成。请求和响应包含可扩展的元数据，两种消息都按照之前提出的方法分帧。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;调用的请求格式为：</p>
<ul>
<li>请求元数据，一个类型值的映射。</li>
<li>消息名，一个Avro字符串。</li>
<li>消息参数。参数根据消息的请求定义序列化。</li>
</ul>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;调用的响应格式为：</p>
<ul>
<li>响应的元数据，一个类型值的映射。</li>
<li>一字节的错误标志位。</li>
<li>如果错误标志为false，响应消息，根据响应的模式序列化。</li>
</ul>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果错误标志位true，错误消息，根据消息的错误联合模式序列化。 </p>
<h2 id="四、实例"><a href="#四、实例" class="headerlink" title="四、实例"></a>四、实例</h2><h3 id="1、本地序列化-反序列化"><a href="#1、本地序列化-反序列化" class="headerlink" title="1、本地序列化/反序列化"></a>1、本地序列化/反序列化</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">user.avsc</div><div class="line">&#123;<span class="string">"namespace"</span>:<span class="string">"example.avro"</span>,</div><div class="line"> <span class="string">"type"</span>: <span class="string">"record"</span>,</div><div class="line"> <span class="string">"name"</span>: <span class="string">"User"</span>,</div><div class="line"> <span class="string">"fields"</span>: [</div><div class="line">    &#123;<span class="string">"name"</span>: <span class="string">"name"</span>, <span class="string">"type"</span>:<span class="string">"string"</span>&#125;,</div><div class="line">    &#123;<span class="string">"name"</span>: <span class="string">"favorite_number"</span>,  <span class="string">"type"</span>: [<span class="string">"int"</span>, <span class="string">"null"</span>]&#125;,</div><div class="line">    &#123;<span class="string">"name"</span>: <span class="string">"favorite_color"</span>, <span class="string">"type"</span>:[<span class="string">"string"</span>, <span class="string">"null"</span>]&#125;</div><div class="line"> ]</div><div class="line">&#125;</div><div class="line">Main.java</div><div class="line">public class Main &#123;</div><div class="line">    public static void main(String[] args)throws Exception &#123;</div><div class="line">       User user1 = new User();</div><div class="line">       user1.setName(<span class="string">"Alyssa"</span>);</div><div class="line">       user1.setFavoriteNumber(256);</div><div class="line">       // Leave favorite color null </div><div class="line">       // Alternate constructor</div><div class="line">       User user2 = new User(<span class="string">"Ben"</span>, 7,<span class="string">"red"</span>); </div><div class="line">       // Construct via builder</div><div class="line">       User user3 = User.newBuilder()</div><div class="line">                    .setName(<span class="string">"Charlie"</span>)</div><div class="line">                   .setFavoriteColor(<span class="string">"blue"</span>)</div><div class="line">                   .setFavoriteNumber(null)</div><div class="line">                    .build();      </div><div class="line">       // Serialize user1 and user2to disk</div><div class="line">       File file = new File(<span class="string">"users.avro"</span>);</div><div class="line">       DatumWriter&lt;User&gt; userDatumWriter = new SpecificDatumWriter&lt;User&gt;(User.class);</div><div class="line">       DataFileWriter&lt;User&gt; dataFileWriter = newDataFileWriter&lt;User&gt;(userDatumWriter);</div><div class="line">       dataFileWriter.create(user1.getSchema(),new File(<span class="string">"users.avro"</span>));</div><div class="line">       dataFileWriter.append(user1);</div><div class="line">       dataFileWriter.append(user2);</div><div class="line">       dataFileWriter.append(user3);</div><div class="line">       dataFileWriter.close();      </div><div class="line">       // Deserialize Usersfrom disk</div><div class="line">       DatumReader&lt;User&gt; userDatumReader = newSpecificDatumReader&lt;User&gt;(User.class);</div><div class="line">       DataFileReader&lt;User&gt; dataFileReader = newDataFileReader&lt;User&gt;(file, userDatumReader);</div><div class="line">       User user = null;</div><div class="line">       <span class="keyword">while</span> (dataFileReader.hasNext()) &#123;</div><div class="line">       // Reuse user object bypassing it to next(). This saves us from</div><div class="line">       // allocating and garbagecollecting many objects <span class="keyword">for</span> files with</div><div class="line">       // many items.</div><div class="line">       user = dataFileReader.next(user);</div><div class="line">       System.out.println(user);</div><div class="line">       &#125;                  </div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="2、RPC"><a href="#2、RPC" class="headerlink" title="2、RPC"></a>2、RPC</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line">mail.avsc</div><div class="line">&#123;<span class="string">"namespace"</span>:<span class="string">"example.proto"</span>,</div><div class="line"> <span class="string">"protocol"</span>: <span class="string">"Mail"</span>,</div><div class="line"> <span class="string">"types"</span>: [</div><div class="line">    &#123;<span class="string">"name"</span>: <span class="string">"Message"</span>, <span class="string">"type"</span>:<span class="string">"record"</span>,</div><div class="line">     <span class="string">"fields"</span>: [</div><div class="line">         &#123;<span class="string">"name"</span>: <span class="string">"to"</span>,  <span class="string">"type"</span>: <span class="string">"string"</span>&#125;,</div><div class="line">         &#123;<span class="string">"name"</span>: <span class="string">"from"</span>, <span class="string">"type"</span>: <span class="string">"string"</span>&#125;,</div><div class="line">         &#123;<span class="string">"name"</span>: <span class="string">"body"</span>, <span class="string">"type"</span>:<span class="string">"string"</span>&#125;</div><div class="line">     ]</div><div class="line">    &#125;</div><div class="line"> ],</div><div class="line"> <span class="string">"messages"</span>: &#123;</div><div class="line">    <span class="string">"send"</span>: &#123;</div><div class="line">        <span class="string">"request"</span>: [&#123;<span class="string">"name"</span>: <span class="string">"message"</span>,<span class="string">"type"</span>: <span class="string">"Message"</span>&#125;],</div><div class="line">        <span class="string">"response"</span>: <span class="string">"string"</span></div><div class="line">    &#125;</div><div class="line"> &#125;</div><div class="line">&#125;</div><div class="line">Main.java</div><div class="line">public class Main &#123;</div><div class="line">    public static class MailImpl implements Mail &#123;</div><div class="line">        // <span class="keyword">in</span> this simple example just <span class="built_in">return</span> details of the message</div><div class="line">        public Utf8 send(Message message) &#123;</div><div class="line">            System.out.println(<span class="string">"Sending message"</span>);</div><div class="line">            <span class="built_in">return</span> new Utf8(<span class="string">"Sending message to "</span> + message.getTo().toString()</div><div class="line">                    + <span class="string">" from "</span> +message.getFrom().toString()</div><div class="line">                    + <span class="string">" with body "</span> +message.getBody().toString());</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    private static Server server;</div><div class="line">    private static void startServer() throws IOException &#123;</div><div class="line">        server = new NettyServer(new SpecificResponder(Mail.class,new MailImpl()),newInetSocketAddress(65111));</div><div class="line">        // the server implements the Mail protocol (MailImpl)</div><div class="line">    &#125;</div><div class="line">    public static void main(String[] args)throws IOException &#123;</div><div class="line">        System.out.println(<span class="string">"Starting server"</span>);</div><div class="line">        // usually this would be anotherapp, but <span class="keyword">for</span> simplicity</div><div class="line">        startServer();</div><div class="line">        System.out.println(<span class="string">"Server started"</span>);</div><div class="line">        NettyTransceiver client = new NettyTransceiver(new InetSocketAddress(65111));</div><div class="line">        // client code - attach to the server and send a message</div><div class="line">        Mail proxy = (Mail) SpecificRequestor.getClient(Mail.class, client);</div><div class="line">        System.out.println(<span class="string">"Client built, got proxy"</span>);</div><div class="line">        // fill <span class="keyword">in</span> the Message record and send it</div><div class="line">        Message message = new Message();</div><div class="line">        message.setTo(new Utf8(<span class="string">"127.0.0.1"</span>));</div><div class="line">        message.setFrom(new Utf8(<span class="string">"127.0.0.1"</span>));</div><div class="line">        message.setBody(new Utf8(<span class="string">"this is my message"</span>));</div><div class="line">        System.out.println(<span class="string">"Calling proxy.send with message: "</span> + message.toString());</div><div class="line">        System.out.println(<span class="string">"Result: "</span> +proxy.send(message));</div><div class="line">        // cleanup</div><div class="line">        client.close();</div><div class="line">        server.close();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Hadoop/3. Ambari——大数据平台的搭建利器" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/09/03/Hadoop/3. Ambari——大数据平台的搭建利器/" class="article-date">
  	<time datetime="2017-09-02T18:02:06.163Z" itemprop="datePublished">2017-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/03/Hadoop/3. Ambari——大数据平台的搭建利器/">
        Ambari——大数据平台的搭建利器
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;虽然大数据越来越流行，但其学习的门槛却一直阻碍着很多的分布式应用初学者或者大数据的业务应用开发者。多个产品之间的不兼容问题，快速集成和维护也显得比较困难。不管是 Hadoop V1 或者 V2 的安装，又或者 Spark/YARN 等的集成，都不是几行简单的命令可以完成的，而是需要手工修改很多的集群配置，这进一步增加了业务开发者的学习和使用难度。有了 Ambari，这些都不再是难题。</p>
<h2 id="Ambari-是什么"><a href="#Ambari-是什么" class="headerlink" title="Ambari 是什么"></a>Ambari 是什么</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari 跟 Hadoop 等开源软件一样，也是 Apache Software Foundation 中的一个项目，并且是顶级项目。目前最新的发布版本是 2.0.1，未来不久将发布 2.1 版本。就 Ambari 的作用来说，就是创建、管理、监视 Hadoop 的集群，但是这里的 Hadoop 是广义，指的是 Hadoop 整个生态圈（例如 Hive，Hbase，Sqoop，Zookeeper 等），而并不仅是特指 Hadoop。用一句话来说，Ambari 就是为了让 Hadoop 以及相关的大数据软件更容易使用的一个工具。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;说到这里，大家就应该明白什么人最需要 Ambari 了。那些苦苦花费好几天去安装、调试 Hadoop 的初学者是最能体会到 Ambari 的方便之处的。而且，Ambari 现在所支持的平台组件也越来越多，例如流行的 Spark，Storm 等计算框架，以及资源调度平台 YARN 等，我们都能轻松地通过 Ambari 来进行部署。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari 自身也是一个分布式架构的软件，主要由两部分组成：Ambari Server 和 Ambari Agent。简单来说，用户通过 Ambari Server 通知 Ambari Agent 安装对应的软件；Agent 会定时地发送各个机器每个软件模块的状态给 Ambari Server，最终这些状态信息会呈现在 Ambari 的 GUI，方便用户了解到集群的各种状态，并进行相应的维护。详细的操作和介绍会在后续章节介绍。</p>
<h2 id="Ambari-的安装"><a href="#Ambari-的安装" class="headerlink" title="Ambari 的安装"></a>Ambari 的安装</h2><h3 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于 Ambari 的安装，目前网上能找到两个发行版，一个是 Apache 的 Ambari，另一个是 Hortonworks 的，两者区别不大。这里就以 Apache 的 Ambari 2.0.1 作为示例。本文使用三台 Redhat 6.6 作为安装环境（目前测试验证结果为 Ambari 在 Redhat 6.6 的版本上运行比较稳定），三台机器分别为 zwshen37.example.com、zwshen38.example.com、zwshen39.example.com。zwshen37 计划安装为 Ambari 的 Server，另外两台为 Ambari Agent。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装 Ambari 最方便的方式就是使用公共的库源（public repository）。有兴趣的朋友可以自己研究一下搭建一个本地库（local repository）进行安装。这个不是重点，所以不在此赘述。在进行具体的安装之前，需要做几个准备工作。</p>
<h4 id="1-SSH-的无密码登录；"><a href="#1-SSH-的无密码登录；" class="headerlink" title="1. SSH 的无密码登录；"></a>1. SSH 的无密码登录；</h4><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari 的 Server 会 SSH 到 Agent 的机器，拷贝并执行一些命令。因此我们需要配置 Ambari Server 到 Agent 的 SSH 无密码登录。在这个例子里，zwshen37 可以 SSH 无密码登录 zwshen38 和 zwshen39。</p>
<h4 id="2-确保-Yum-可以正常工作；"><a href="#2-确保-Yum-可以正常工作；" class="headerlink" title="2. 确保 Yum 可以正常工作；"></a>2. 确保 Yum 可以正常工作；</h4><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;通过公共库（public repository），安装 Hadoop 这些软件，背后其实就是应用 Yum 在安装公共库里面的 rpm 包。所以这里需要您的机器都能访问 Internet。</p>
<h4 id="3-确保-home-目录的写权限。"><a href="#3-确保-home-目录的写权限。" class="headerlink" title="3. 确保 home 目录的写权限。"></a>3. 确保 home 目录的写权限。</h4><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari 会创建一些 OS 用户。</p>
<h4 id="4-确保机器的-Python-版本大于或等于-2-6-（Redhat6-6，默认就是-2-6-的）。"><a href="#4-确保机器的-Python-版本大于或等于-2-6-（Redhat6-6，默认就是-2-6-的）。" class="headerlink" title="4. 确保机器的 Python 版本大于或等于 2.6.（Redhat6.6，默认就是 2.6 的）。"></a>4. 确保机器的 Python 版本大于或等于 2.6.（Redhat6.6，默认就是 2.6 的）。</h4><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上的准备工作完成后，便可以真正的开始安装 Ambari 了。</p>
<h3 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先需要获取 Ambari 的公共库文件（public repository）。登录到 Linux 主机并执行下面的命令（也可以自己手工下载）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.0.1/ambari.repo</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将下载的 ambari.repo 文件拷贝到 Linux 的系统目录/etc/yum.repos.d/。拷贝完后，我们需要获取该公共库的所有的源文件列表。依次执行以下命令。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">yum clean all</div><div class="line">yum list|grep ambari</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如图 1 所示：</p>
<p><strong>图 1. 获取公共库源文件列表</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/01.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果可以看到 Ambari 的对应版本的安装包列表，说明公共库已配置成功。然后就可以安装 Ambari 的 package 了。执行下面的命令安装 Ambari Server 到该机器。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install ambari-server</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;待安装完成后，便需要对 Ambari Server 做一个简单的配置。执行下面的命令。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">amari-server setup</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在这个交互式的设置中，采用默认配置即可。Ambari 会使用 Postgres 数据库，默认会安装并使用 Oracle 的 JDK。默认设置了 Ambari GUI 的登录用户为 admin/admin。并且指定 Ambari Server 的运行用户为 root。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;简单的 setup 配置完成后。就可以启动 Ambari 了。运行下面的命令。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ambari-server start</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当成功启动 Ambari Server 之后，便可以从浏览器登录，默认的端口为 8080。以本文环境为例，在浏览器的地址栏输入 <a href="http://zwshen37.example.com:8080，登录密码为" target="_blank" rel="external">http://zwshen37.example.com:8080，登录密码为</a> admin/admin。登入 Ambari 之后的页面如下图。</p>
<p><strong>图 2. Ambari 的 welcome 页面</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/02.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至此，Ambari Server 就安装完成了。</p>
<h2 id="部署一个-Hadoop2-x-集群"><a href="#部署一个-Hadoop2-x-集群" class="headerlink" title="部署一个 Hadoop2.x 集群"></a>部署一个 Hadoop2.x 集群</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到这一节，我们将可以真正地体验到 Ambari 的用武之地，以及它所能带来的方便之处。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录 Ambari 之后，点击按钮“Launch Install Wizard”，就可以开始创建属于自己的大数据平台。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>第一步</strong>，命名集群的名字。本环境为 bigdata。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>第二步</strong>，选择一个 Stack，这个 Stack 相当于一个 Hadoop 生态圈软件的集合。Stack 的版本越高，里面的软件版本也就越高。这里我们选择 HDP2.2，里面的对应的 Hadoop 版本为 2.6.x。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>第三步</strong>，指定 Agent 机器（如果配置了域，必须包含完整域名，例如本文环境的域为 example.com），这些机器会被安装 Hadoop 等软件包。还记得在安装章节中提到的 SSH 无密码登陆吗，这里需要指定当时在 Ambari Server 机器生成的私钥（ssh-keygen 生成的，公钥已经拷贝到 Ambari Agent 的机器，具体的 SSH 无密码登录配置，可以在网上很容易找到配置方法，不在此赘述）。另外不要选择“Perform manual registration on hosts and do not use SSH“。因为我们需要 Ambari Server 自动去安装 Ambari Agent。具体参见下图示例。</p>
<p><strong>图 3. 安装配置页面</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/03.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>第四步</strong>，Ambari Server 会自动安装 Ambari Agent 到刚才指定的机器列表。安装完成后，Agent 会向 Ambari Server 注册。成功注册后，就可以继续 Next 到下一步。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>第五步</strong>，这里我们终于看到跟 Hadoop 有关的名词了。在这一步，我们需要选择要安装的软件名称。本文环境选择了 HDFS，YARN + MapReduce2，Zoopkeeper，Storm 以及 Spark。选的越多，就会需要越多的机器内存。选择之后就可以继续下一步了。这里需要注意某些 Service 是有依赖关系的。如果您选了一个需要依赖其他 Service 的一个 Service，Ambari 会提醒安装对应依赖的 Service。参见下图。</p>
<p><strong>图 4. Service 选择页面</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/04.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>第六步和第七步</strong>，分别是选择安装软件所指定的 Master 机器和 Slave 机器，以及 Client 机器。这里使用默认选择即可（真正在生产环境中，需要根据具体的机器配置选择）。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>第八步</strong>，就是 Service 的配置。绝大部分配置已经有默认值，不需要修改。初学者，如果不需要进行调优是可以直接使用默认配置的。有些 Service 会有一些必须的手工配置项，则必须手动输入，才可以下一步。本文环境直接使用默认配置。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>第九步</strong>，Ambari 会总结一个安装列表，供用户审阅。这里没问题，就直接下一步。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>第十步</strong>，Ambari 会开始安装选择的 Service 到 Ambari Agent 的机器（如下图）。这里可能需要等好一会，因为都是在线安装。安装完成之后，Ambari 就会启动这些 Service。</p>
<p><strong>图 5. Service 的安装进度</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/05.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;安装完成之后，就可以查看 Ambari 的 Dashboard 了。例如下图。</p>
<p><strong>图 6. Ambari 的 Dashboard 页面</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/06.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;至此，您专属的 bigdata 集群已经安装完成。</p>
<h2 id="利用-Ambari-管理-Hadoop-集群"><a href="#利用-Ambari-管理-Hadoop-集群" class="headerlink" title="利用 Ambari 管理 Hadoop 集群"></a>利用 Ambari 管理 Hadoop 集群</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在上一章节中，我们已经体验到 Ambari 为 Hadoop 生态圈的安装提供的便利。这已经省去了很多的人力成本。尤其是对大数据圈子的测试人员来说，自动化就容易了很多。下面我们看看如何通过 Ambari 管理 Hadoop 的集群。</p>
<h3 id="Service-Level-Action（服务级别的操作）"><a href="#Service-Level-Action（服务级别的操作）" class="headerlink" title="Service Level Action（服务级别的操作）"></a>Service Level Action（服务级别的操作）</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先我们进到 Ambari 的 GUI 页面，并查看 Dashboard。在左侧的 Service 列表中，我们可以点击任何一个您想要操作的 Service。以 MapReduce2 为例（Hadoop 这里的版本为 2.6.x，也就是 YARN+HDFS+MapReduce），当点击 MapReduce2 后，就会看到该 Service 的相关信息，如下图。</p>
<p><strong>图 7. MapRduce2 的 Service 页面</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/07.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;中间部分是 Service 的模块（Component）信息，也就是该 Service 有哪些模块及其数目。右上角有个 Service Action 的按钮，当点击该按钮后就可以看到很多 Service 的控制命令。也就是通过这些 Service Action 命令，对 Service 进行管理的。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可能有的人会说，装完 Hadoop 的集群后，并不知道这个集群是不是可用。这时候我们就可以运行一个“Run Service Check”。点击这个命令后，就会出现下图的进度显示。</p>
<p><strong>图 8. MapReduce Service Check</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/08.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其实这里就是通过运行一个经典的 MapReduce Wordcount 实例，来检查 MapReduce 是不是正常。对于 Service Action 里面的 Start、Stop 的含义就是，启停整个集群所有该 Service 的模块（也就是 Service level）。当执行进度页面弹出来的时候，我们可以点击 Operations 的名字，进而查看每个机器的进度和运行 log。如下图 Stop 的操作。</p>
<p><strong>图 9. 命令执行进度 1</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/09.jpeg?raw=true" alt=""></p>
<p><strong>图 10. 命令执行进度 2</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/10.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;维护模式（Maintenance Mode）以及如何添加一个自定义的命令到 Service Action，我会在后续的连载中进行介绍。</p>
<h3 id="Host-Level-Action（机器级别的操作）"><a href="#Host-Level-Action（机器级别的操作）" class="headerlink" title="Host Level Action（机器级别的操作）"></a>Host Level Action（机器级别的操作）</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，我们回到 Ambari 的 Dashboard 页面。页面最上面中间的地方有个 Hosts，点击这个标签，我们就可以看到 Ambari 所管理的机器列表。如下图。</p>
<p><strong>图 11. Ambari 的机器列表</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/11.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;图片中红色的数字是警告信息（Ambari Alert），这里我们先略过它，后续文章再做介绍。先看左上角的 Actions，点击这个按钮，就可以看到 Host level Action 的选项了，其实和 Service Level 是类似的，只是执行的范围不一样。如下图。当用户选择 All Hosts -&gt; Hosts -&gt; Start All Components，Ambari 就会将所有 Service 的所有模块启动。</p>
<p><strong>图 12. 启动所有 Service 的所有模块</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/12.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果用户选择 All Hosts-&gt; DataNodes -&gt; Stop，Ambari 就会把所有机器的 DataNode 这个模块关闭。如下图。</p>
<p><strong>图 13. 关闭所有的 DataNode 模块</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/13.jpeg?raw=true" alt=""></p>
<h3 id="Component-Level-Action（模块级别的操作）"><a href="#Component-Level-Action（模块级别的操作）" class="headerlink" title="Component Level Action（模块级别的操作）"></a>Component Level Action（模块级别的操作）</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;上面的图中，我们可以看到 Decommisson、Recommission。这些命令其实是自定义的模块级别的操作（Component Level Action）。不过上图中命令一旦执行，就是对多个机器的同个模块执行。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们现在尝试只对单个机器的一个模块（Component）执行。首先我们回到 Hosts 的页面。这时候点击机器名，我们就会进入到该机器的 Component 页面。如下图。</p>
<p><strong>图 14. Component 页面</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/14.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时候只要点击每个 Component（模块）后面的按钮，就可以看到该模块的操作命令了。例如，我们可以停掉这台机器的 DataNode 模块。</p>
<p><strong>图 15. 停止 DataNode 模块 1</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/15.jpeg?raw=true" alt=""></p>
<p><strong>图 16. 停止 DataNode 模块 2</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/16.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关于如何给一个模块添加自定义的命令，也会在后续的连载中做介绍。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这一章节中，主要介绍了如何通过三种级别的 Action（操作）管理 Hadoop 的集群。在 Ambari 中已经加入了很多自定义的 Action 去做一些特殊的操作。如果对 Hadoop 生态圈的软件足够熟悉，就可以尝试更多的 Action。可能有的人会问，Ambari 可不可以扩容集群。答案当然是可以的。Ambari 可以给自身的集群添加机器（也就是添加 Ambari Agent），然后将 Service 的模块安装在新的机器，也可以把某些模块安装到已有的其他的机器。篇幅有限，将在后续的连载中介绍更多的内容。</p>
<h2 id="Ambari-的架构和工作原理"><a href="#Ambari-的架构和工作原理" class="headerlink" title="Ambari 的架构和工作原理"></a>Ambari 的架构和工作原理</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari 基本的架构和工作原理如下图 17 所示。</p>
<p><strong>图 17. Ambari 的基本架构</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/17.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari Server 会读取 Stack 和 Service 的配置文件。当用 Ambari 创建集群的时候，Ambari Server 传送 Stack 和 Service 的配置文件以及 Service 生命周期的控制脚本到 Ambari Agent。Agent 拿到配置文件后，会下载安装公共源里软件包（Redhat，就是使用 yum 服务）。安装完成后，Ambari Server 会通知 Agent 去启动 Service。之后 Ambari Server 会定期发送命令到 Agent 检查 Service 的状态，Agent 上报给 Server，并呈现在 Ambari 的 GUI 上。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Ambari Server 支持 Rest API，这样可以很容易的扩展和定制化 Ambari。甚至于不用登陆 Ambari 的 GUI，只需要在命令行通过 curl 就可以控制 Ambari，以及控制 Hadoop 的 cluster。具体的 API 可以参见 Apache Ambari 的官方网页 API reference。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;对于安全方面要求比较苛刻的环境来说，Ambari 可以支持 Kerberos 认证的 Hadoop 集群。</p>
<h2 id="扩展-Ambari-管理一个自定义的-Service"><a href="#扩展-Ambari-管理一个自定义的-Service" class="headerlink" title="扩展 Ambari 管理一个自定义的 Service"></a>扩展 Ambari 管理一个自定义的 Service</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，我们需要规划自定义的 Service 属于哪个 Stack（当然 Stack 也是可以自定义的）。这里为了快速创建一个新的 Service，而且我们已经安装了 HDP 2.2 的 Stack，所以就将自定义的 Service 放在 HDP 2.2 之下。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一步，首先在 Ambari Service 机器上找到 HDP 2.2 Stack 的目录，如下图所示。</p>
<p><strong>图 18. HDP 2.2 的目录</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/18.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二步，需要创建一个 Service 目录，我们这里用“SAMPLE”作为目录名。并在 SAMPLE 底下创建 metainfo.xml。示例代码如下。主要解释下 xml 代码中的两个字段 category 和 cardinality。category 指定了该模块（Component）的类别，可以是 MASTER、SLAVE、CLIENT。Cardinality 指的是所要安装的机器数，可以是固定数字 1，可以是一个范围比如 1-2，也可以是 1+，或者 ALL。如果是一个范围的时候，安装的时候会让用户选择机器。另外这里有关 Service 和 Component 的 name 配置要用大写，小写有时候会有问题。Displayname 可以随意设置。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version=<span class="string">"1.0"</span>?&gt;</div><div class="line">&lt;metainfo&gt;</div><div class="line"> &lt;schemaVersion&gt;2.0&lt;/schemaVersion&gt;</div><div class="line"> &lt;services&gt;</div><div class="line"> &lt;service&gt;</div><div class="line"> &lt;name&gt;SAMPLE&lt;/name&gt;</div><div class="line"> &lt;displayName&gt;My Sample&lt;/displayName&gt;</div><div class="line"> &lt;comment&gt;My v1 Sample&lt;/comment&gt;</div><div class="line"> &lt;version&gt;1.0&lt;/version&gt;</div><div class="line"> &lt;components&gt;</div><div class="line"> &lt;component&gt;</div><div class="line"> &lt;name&gt;MYMASTER&lt;/name&gt;</div><div class="line"> &lt;displayName&gt;My Master&lt;/displayName&gt;</div><div class="line"> &lt;category&gt;MASTER&lt;/category&gt;</div><div class="line"> &lt;cardinality&gt;1&lt;/cardinality&gt;</div><div class="line"> &lt;commandScript&gt;</div><div class="line"> &lt;script&gt;scripts/master.py&lt;/script&gt;</div><div class="line"> &lt;scriptType&gt;PYTHON&lt;/scriptType&gt;</div><div class="line"> &lt;timeout&gt;5000&lt;/timeout&gt;</div><div class="line"> &lt;/commandScript&gt;</div><div class="line"> &lt;/component&gt;</div><div class="line"> &lt;component&gt;</div><div class="line"> &lt;name&gt;MYSALVE&lt;/name&gt;</div><div class="line"> &lt;displayName&gt;My Slave&lt;/displayName&gt;</div><div class="line"> &lt;category&gt;SLAVE&lt;/category&gt;</div><div class="line"> &lt;cardinality&gt;1+&lt;/cardinality&gt;</div><div class="line"> &lt;commandScript&gt;</div><div class="line"> &lt;script&gt;scripts/slave.py&lt;/script&gt;</div><div class="line"> &lt;scriptType&gt;PYTHON&lt;/scriptType&gt;</div><div class="line"> &lt;timeout&gt;5000&lt;/timeout&gt;</div><div class="line"> &lt;/commandScript&gt;</div><div class="line"> &lt;/component&gt;</div><div class="line"> &lt;/components&gt;</div><div class="line"> &lt;osSpecifics&gt;</div><div class="line"> &lt;osSpecific&gt;</div><div class="line"> &lt;osFamily&gt;any&lt;/osFamily&gt;</div><div class="line"> &lt;/osSpecific&gt;</div><div class="line"> &lt;/osSpecifics&gt;</div><div class="line"> &lt;/service&gt;</div><div class="line"> &lt;/services&gt;</div><div class="line">&lt;/metainfo&gt;</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三步，需要创建 Service 的控制脚本。这里我们需要在 SAMPLE 底下创建一个 package 目录，然后在 package 底下创建目录 scripts ，进而创建 master.py 和 slave.py。这里需要保证脚本路径和上一步中 metainfo.xml 中的配置路径是一致的。这两个 Python 脚本是用来控制 Master 和 Slave 模块的生命周期。脚本中函数的含义也如其名字一样：install 就是安装调用的接口；start、stop 分别就是启停的调用；Status 是定期检查 component 状态的调用；Configure 是安装完成配置该模块的调用。示例目录结构如下图。</p>
<p><strong>图 19. Sample Service 的目录结构</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/19.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Python 脚本的示例代码：</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Master.py：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys, os</div><div class="line"><span class="keyword">from</span> resource_management <span class="keyword">import</span> *</div><div class="line"><span class="keyword">from</span> resource_management.core.exceptions <span class="keyword">import</span> ComponentIsNotRunning</div><div class="line"><span class="keyword">from</span> resource_management.core.environment <span class="keyword">import</span> Environment</div><div class="line"><span class="keyword">from</span> resource_management.core.logger <span class="keyword">import</span> Logger</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Master</span><span class="params">(Script)</span>:</span></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">install</span><span class="params">(self, env)</span>:</span></div><div class="line"> <span class="keyword">print</span> <span class="string">"Install My Master"</span></div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">configure</span><span class="params">(self, env)</span>:</span></div><div class="line"> <span class="keyword">print</span> <span class="string">"Configure My Master"</span></div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self, env)</span>:</span></div><div class="line"> <span class="keyword">print</span> <span class="string">"Start My Master"</span></div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">stop</span><span class="params">(self, env)</span>:</span></div><div class="line"> <span class="keyword">print</span> <span class="string">"Stop My Master"</span></div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">status</span><span class="params">(self, env)</span>:</span> </div><div class="line"> <span class="keyword">print</span> <span class="string">"Status..."</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line"> Master().execute()</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Slave.py:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys, os</div><div class="line"><span class="keyword">from</span> resource_management <span class="keyword">import</span> *</div><div class="line"><span class="keyword">from</span> resource_management.core.exceptions <span class="keyword">import</span> ComponentIsNotRunning</div><div class="line"><span class="keyword">from</span> resource_management.core.environment <span class="keyword">import</span> Environment</div><div class="line"><span class="keyword">from</span> resource_management.core.logger <span class="keyword">import</span> Logger</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Slave</span><span class="params">(Script)</span>:</span></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">install</span><span class="params">(self, env)</span>:</span></div><div class="line"> <span class="keyword">print</span> <span class="string">"Install My Slave"</span></div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">configure</span><span class="params">(self, env)</span>:</span></div><div class="line"> <span class="keyword">print</span> <span class="string">"Configure My Slave"</span></div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self, env)</span>:</span></div><div class="line"> <span class="keyword">print</span> <span class="string">"Start My Slave"</span></div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">stop</span><span class="params">(self, env)</span>:</span></div><div class="line"> <span class="keyword">print</span> <span class="string">"Stop My Slave"</span></div><div class="line"> <span class="function"><span class="keyword">def</span> <span class="title">status</span><span class="params">(self, env)</span>:</span> </div><div class="line"> <span class="keyword">print</span> <span class="string">"Status..."</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line"> Slave().execute()</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第四步，需要重启 Ambari Server。因为 Ambari Server 只有在重启的时候才会读取 Service 和 Stack 的配置。命令行执行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ambari-server restart</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第五步，登录 Ambari 的 GUI，点击左下角的 Action，选择 Add Service。如下图：</p>
<p><strong>图 20. Add Service 按钮</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/20.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这时候就可以看到我们自定义的 Service：SAMPLE。如下图：</p>
<p><strong>图 21. Sample Service 列表</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/21.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;选择左侧 My Sample 后，就可以一路 Next 了，这个过程其实和我们在搭建 Hadoop2.x 集群的时候是类似的。由于这个 Service 没有真的安装包，所以安装过程会非常的快，启动命令也没有真正的逻辑，所以启动过程也是很快的。等最后点击完 Complete，整个安装过程也就结束了。再回到 Ambari 的 Dashboard 的时候，我们就可以看到这个 My Sample 了，如下图：</p>
<p><strong>图 22. My Sample 的 Service 页面</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/22.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;到此就可以和第四节中管理 Hadoop 集群一样管理我们的 My Sample。例如下图，Stop 我们的 My Sample。</p>
<p><strong>图 23. Stop Sample 页面 1</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/23.jpeg?raw=true" alt=""></p>
<p><strong>图 24. Stop Sample 页面 2</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/24.jpeg?raw=true" alt=""></p>
<p><strong>图 25. Stop Sample 页面 3</strong></p>
<p><img src="https://github.com/hcldirgit/image/blob/master/Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/25.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;进阶的篇幅中，将会探讨如何给我们的 My Sample 自定义一些 Actions，以及 Action 之间的依赖关系如何定义。篇幅有限，这里就先到此为止。希望以上的介绍能够燃起大家对 Ambari 的热情。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大数据与云计算可谓是如今数据中心中最火的两项技术领域，几乎所有的 IT 服务商都想在这两项技术中有所建树。相信 Ambari 可以帮助一些 Hadoop 的初学者。长远看来，大数据的发展离不开云计算，云计算中 IaaS 可谓已经很成熟，并且价格低廉。这时候许多公司将目光聚集在了 PaaS。大数据的流行更是加速了相关 PaaS 产品的发展，而 Ambari 的出现必然可以拉近 IaaS 和 PaaS 的距离。也就是说有了 Ambari，或许再加上 Docker，那么快速从 IaaS 演进到 PaaS 就显得不是那么困难了。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当然这里 Ambari 要跟 IaaS 更好的切合，还有个对手那就是 Sahara。它是另一个土生土长的 OpenStack 的子项目，其目的也是为了在 Openstack 上面快速搭建 Hadoop 等集群。期望着这些项目能够快速成长，将来对大家都有所帮助。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Hadoop/1. Hadoop 大数据" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/09/03/Hadoop/1. Hadoop 大数据/" class="article-date">
  	<time datetime="2017-09-02T18:02:06.162Z" itemprop="datePublished">2017-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/03/Hadoop/1. Hadoop 大数据/">
        Hadoop 大数据
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-大数据介绍"><a href="#1-大数据介绍" class="headerlink" title="1.大数据介绍"></a>1.大数据介绍</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大数据指的是所涉及的数据量规模巨大到无法通过人工，在合理时间内达到截取、管理、处理、并整理成为人类所能解读的形式的信息。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大数据，可帮助我们察觉商业趋势、判定研究质量、避免疾病扩散、打击犯罪或测定即时交通路况等。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;麦肯锡全球研究院（MGI）预测，到 2020年，全球数据使用量预计将达到 35ZB（1ZB=1000EB，1EB=1000PB，1PB=1000TB，1TB=1000GB）。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Google每天要处理的数据高达几百PB。百度每天处理数据几十PB。腾讯微信活跃用户数达7亿，每天产生的数据量上百TB，2016年除夕当日，微信红包的参与人数达到4.2亿人，收发总量达80.8亿个。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;多源异构：描述同一主题的数据由不同的用户、不同的网站产生。网络数据有多种不同的呈现形式，如音视频、图片、文本等，导致网络数据格式上的异构性。</p>
<ul>
<li><p>交互性：不同于测量和传感获取的大规模科学数据，微博等社交网络兴起导至大量网络数据具有很强的交互性。</p>
</li>
<li><p>时效性：在网络平台上，每时每刻都有大量新的网络数据发布，网络信息内容不断变化，导致了信息传播的时序相关性。</p>
</li>
<li><p>社会性：网络上用户根据自己的需要和喜好发布、回复或转发信息，因而网络数据成了对社会状态的直接反映。</p>
</li>
<li><p>突发性：有些信息在传播过程中会在短时间内引起大量新的网络数据与信息的产生，并使相关的网络用户形成网络群体，体现出网络大数据以及网络群体的突发特性。</p>
</li>
<li><p>高噪声：网络数据来自于众多不同的网络用户，具有很高的噪声。</p>
</li>
</ul>
<h2 id="2-Hadoop-介绍"><a href="#2-Hadoop-介绍" class="headerlink" title="2.Hadoop 介绍"></a>2.Hadoop 介绍</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hadoop是一个开源分布式计算平台框架，基于apache协议发布，由java语言开发。<a href="http://hadoop.apache.org/" target="_blank" rel="external">http://hadoop.apache.org/</a></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hadoop两大核心组件：<strong>HDFS</strong>（分布式文件系统，为分布式计算提供了数据存储）和<strong>mapreduce</strong>（应用程序被分区成许多小部分，而每个部分都能在集群中的任意节点上运行，一句话就是任务的分解和结果的汇总）</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;另外两个模块：<strong>Common、YARN</strong></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;其他和hadoop相关的项目：<strong>Ambari、Avro、Cassandra、Chukwa、Hbase、Hive、Mahout、Pig、Spark、Tez、Zookeeper</strong></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hadoop支持由廉价的计算机搭建集群，有强大的冗余机制。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hadoop在各大互联网企业中应用广泛，百度使用hadoop进行搜索日志的分析和网页数据的挖掘工作；淘宝使用hadoop存储并处理电子商务交易相关数据；facebook使用hadoop进行数据分析和机器学习。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;还有哪些企业在使用hadoop <a href="http://wiki.apache.org/hadoop/PoweredBy" target="_blank" rel="external">http://wiki.apache.org/hadoop/PoweredBy</a></p>
<h2 id="3-Hadoop组件以及相关项目介绍"><a href="#3-Hadoop组件以及相关项目介绍" class="headerlink" title="3.Hadoop组件以及相关项目介绍"></a>3.Hadoop组件以及相关项目介绍</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>Common</strong>：为其他组件提供常用工具支持。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>YARN</strong>：作业调度和集群管理的框架。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>Ambari</strong>: 是 Apache Software Foundation 中的一个项目。就 Ambari 的作用来说，就是创建、管理、监视 Hadoop 的集群，但是这里的 Hadoop 是广义，指的是 Hadoop 整个生态圈（例如 Hive，Hbase，Sqoop，Zookeeper 等）。用一句话来说，Ambari 就是为了让 Hadoop 以及相关的大数据软件更容易使用的一个工具。<a href="https://hcldirgit.github.io/2017/08/18/Hadoop/3.%20Ambari%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%90%AD%E5%BB%BA%E5%88%A9%E5%99%A8/">Ambari——大数据平台的搭建利器</a></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>Avro</strong>：Avro是Hadoop中的一个子项目，也是Apache中一个独立的项目，Avro是一个基于二进制数据传输高性能的中间件。在Hadoop的其他项目中例如HBase(Ref)和Hive(Ref)的Client端与服务端的数据传输也采用了这个工具。Avro是一个数据序列化的系统。Avro 可以将数据结构或对象转化成便于存储或传输的格式。Avro设计之初就用来支持数据密集型应用，适合于远程或本地大规模数据的存储和交换。<a href="https://hcldirgit.github.io/2017/08/18/Hadoop/4.%20Avro%E7%AE%80%E4%BB%8B/">Avro简介</a></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>Cassandra</strong>：可扩展的多主数据库，不存在单点故障。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>Chukwa</strong>：是数据收集系统，用于监控和分析大型分布式系统的数据。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>HBase</strong>：是一个分布式面向列的数据库。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>Hive</strong>：最早由facebook设计，是建立在hadoop基础之上的数据仓库，它提供了一些用于数据整理、特殊查询和分析在hadoop文件中数据集工具。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>Mahout</strong>：可扩展的机器学习和数据挖掘库。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>Pig</strong>：是一种高级语言和并行计算可执行框架，它是一个对大型数据集分析和评估的平台。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>Spark</strong>：一个快速和通用计算的Hadoop数据引擎。和mapreduce类似，但是要比mapreduce快。它提供了一个简单而丰富的编程模型，支持多种应用，包括ETL、机器学习、数据流处理、图形计算。 参考文档 <a href="https://hcldirgit.github.io/2017/08/18/Hadoop/2.%202%E5%88%86%E9%92%9F%E8%AF%BB%E6%87%82Hadoop%E5%92%8CSpark%E7%9A%84%E5%BC%82%E5%90%8C/">2分钟读懂Hadoop和Spark的异同</a></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>Tez</strong>：是Apache最新的支持DAG作业的开源计算框架，它可以将多个有依赖的作业转换为一个作业从而大幅提升DAG作业的性能。Tez并不直接面向最终用户，事实上它允许开发者为最终用户构建性能更快、扩展性更好的应用程序。Hadoop传统上是一个大量数据批处理平台。但是，有很多用例需要近乎实时的查询处理性能。还有一些工作则不太适合MapReduce，例如机器学习。Tez的目的就是帮助Hadoop处理这些用例场景。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>ZooKeeper</strong>：ZooKeeper是一组工具，用来配置和支持分布式调度。一个重要功能就是对所有节点进行配置的同步。它能处理分布式应用的“部分失败”问题。部分失败是分布式处理系统的固有特征，即发送者无法知道接收者是否收到消息，它的出现可能和网络传输问题、接收进程意外死掉等有关系。ZooKeeper是Hadoop生态系统的一部分，但又远不止如此，它能支持更多类似的分布式平台和系统，如Jubatus，Cassender等等。而且HBase明确指出至少需要一个ZooKeeper实例的支持。</p>
<h2 id="4-HDFS-介绍"><a href="#4-HDFS-介绍" class="headerlink" title="4.HDFS 介绍"></a>4.HDFS 介绍</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS设计思想来源于Google的GFS，是GFS的开源实现。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS要解决的问题</p>
<ol>
<li>存储超大文件，比如TB级别</li>
<li>防止文件丢失</li>
</ol>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS的特点</p>
<ol>
<li>可以存储超大文件</li>
<li>只允许对一个已经打开的文件顺序写入，还可以在现有文件的末尾追加。要想修改一个文件（追加内容除外），只能删除后再重写</li>
<li>可以使用廉价的硬件平台搭建，通过容错策略来保证数据的高可用，默认存储3份数据，任何一份丢失可以自动恢复</li>
</ol>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS的缺点</p>
<ol>
<li>数据访问延迟比较高，因为它的设计场景是用于大吞吐量数据，HDFS是单master，所有文件都要经过它，当请求数据量很大时，延迟就增加了</li>
<li>文件数受限，和NameNode有关系</li>
<li>不支持多用户写入，也不支持文件任意修改</li>
</ol>
<h3 id="HDFS-架构"><a href="#HDFS-架构" class="headerlink" title="HDFS 架构"></a>HDFS 架构</h3><p><img src="https://github.com/hcldirgit/image/blob/master/Hadoop%20%E5%A4%A7%E6%95%B0%E6%8D%AE/01.png?raw=true" alt=""></p>
<h4 id="HDFS的几个核心概念"><a href="#HDFS的几个核心概念" class="headerlink" title="HDFS的几个核心概念"></a>HDFS的几个核心概念</h4><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>数据块（block）</strong>：大文件会被分割成多个block进行存储，block大小默认为64MB。每一个block会在多个datanode上存储多份副本，默认是3份。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>namenode</strong>：namenode负责管理文件目录、文件和block的对应关系以及block和datanode的对应关系。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>SecondaryNameNode</strong>：分担namenode的工作量，是NameNode的冷备份，它的主要工作是合并fsimage（元数据镜像文件）和fsedits（元数据操作日志）然后再发给namenode。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>datanode</strong>：datanode就负责存储了，当然大部分容错机制都是在datanode上实现的。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<strong>rack</strong> 是指机柜的意思，一个block的三个副本通常会保存到两个或者两个以上的机柜中（当然是机柜中的服务器），这样做的目的是做防灾容错，因为发生一个机柜掉电或者一个机柜的交换机挂了的概率还是蛮高的。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;几篇不错的文章</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<a href="https://hcldirgit.github.io/2017/08/18/Hadoop/7.%20%E3%80%90Hadoop%E3%80%91HDFS%E7%9A%84%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86/">【Hadoop】HDFS的运行原理</a></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<a href="https://hcldirgit.github.io/2017/08/18/Hadoop/6.%20HDFS%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%20%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/">HDFS原理分析—— 基本概念</a></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<a href="https://hcldirgit.github.io/2017/08/18/Hadoop/5.%20HDFS%20%E5%8E%9F%E7%90%86%E3%80%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%89%B9%E6%80%A7%E4%BB%8B%E7%BB%8D/">HDFS 原理、架构与特性介绍</a></p>
<h2 id="5-HSDS写数据流程"><a href="#5-HSDS写数据流程" class="headerlink" title="5.HSDS写数据流程"></a>5.HSDS写数据流程</h2><p><img src="https://github.com/hcldirgit/image/blob/master/Hadoop%20%E5%A4%A7%E6%95%B0%E6%8D%AE/02.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS写文件流程</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Client向远程的Namenode发起RPC请求；</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件 创建一个记录，否则会让客户端抛出异常</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当客户端开始写入文件的时候，会将文件切分成多个packets，并向Namenode申请blocks，获取用来存储replicas的合适的datanodes列表，列表的大小根据在Namenode中对replication的设置而定。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;此时会形成一个pipline用来传输packet。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;packet以流的方式写入第一个datanode，该datanode把packet存储之后，再将其传递给下一个datanode，直到最后一个datanode。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;最后一个datanode成功存储之后会返回一个ack 传递至客户端，在客户端，客户端确认ack后继续写入下一个packet。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果传输过程中，有某个datanode出现了故障，那么当前的pipeline会被关闭，出现故障的datanode会从当前的pipeline中移除，剩余的block会继续剩下的datanode中继续以pipeline的形式传输，同时Namenode会分配一个新的datanode，保持replicas设定的数量</p>
<h2 id="6-HDFS-读数据流程"><a href="#6-HDFS-读数据流程" class="headerlink" title="6.HDFS 读数据流程"></a>6.HDFS 读数据流程</h2><p><img src="https://github.com/hcldirgit/image/blob/master/Hadoop%20%E5%A4%A7%E6%95%B0%E6%8D%AE/03.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;HDFS读文件流程</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Client向远程的Namenode发起RPC请求</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Namenode会视情况返回文件的部分或者全部block列表，对于每个block，Namenode都会返回有该block拷贝的DataNode地址</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Client会选取离自己最接近的DataNode来读取block</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;读取完当前block的数据后，关闭与当前的DataNode连接，并为读取下一个block寻找最佳的DataNode</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当读完列表的block后，且文件读取还没有结束，client会继续向Namenode获取下一批的block列表</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;读取完block会进行checksum验证，如果读取datanode时出现错误，客户端会通知Namenode，然后再从下一个拥有该block拷贝的datanode继续读</p>
<h2 id="7-mapreduce-详解"><a href="#7-mapreduce-详解" class="headerlink" title="7.mapreduce 详解"></a>7.mapreduce 详解</h2><h3 id="MapReduce模型"><a href="#MapReduce模型" class="headerlink" title="MapReduce模型"></a>MapReduce模型</h3><p><img src="https://github.com/hcldirgit/image/blob/master/Hadoop%20%E5%A4%A7%E6%95%B0%E6%8D%AE/04.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;MapReduce 是大规模数据（TB 级）计算的利器，Map 和Reduce 是它的主要思想，来源于函数式编程语言。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Map负责将数据打散，Reduce负责对数据进行聚集，用户只需要实现map 和reduce 两个接口，即可完成TB级数据的计算。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;常见的应用包括：日志分析和数据挖掘等数据分析应用。另外，还可用于科学数据计算，如圆周率PI 的计算等。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;当我们提交一个计算作业时，MapReduce会首先把计算作业拆分成若干个Map 任务，然后分配到不同的节点上去执行，每一个Map 任务处理输入数据中的一部分，当Map 任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce 任务的输入数据。Reduce 任务的主要目标就是把前面若干个Map 的输出汇总到一起并输出</p>
<h3 id="MapReduce-执行过程"><a href="#MapReduce-执行过程" class="headerlink" title="MapReduce 执行过程"></a>MapReduce 执行过程</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个 Mapper 任务是一个 java 进程，它会读取 HDFS 中的文件，解析成很多的键值对，经过我们 map 方法处理后， 转换为很多的键值对再输出</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把 Mapper 任务的运行过程分为六个阶段。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一阶段是把输入文件按照一定的标准分片(InputSplit)，每个输入片的大小是固定的。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二阶段是对输入片中的记录按照一定的规则解析成键值对。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三阶段是调用 Mapper 类中的 map 方法。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第四阶段是按照一定的规则对第三阶段输出的键值对进行分区。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第五阶段是对每个分区中的键值对进行排序。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第六阶段是对数据进行归纳处理，也就是 reduce 处理。键相等的键值对会调用一次reduce 方法。</p>
<h3 id="Reducer任务的执行过程"><a href="#Reducer任务的执行过程" class="headerlink" title="Reducer任务的执行过程"></a>Reducer任务的执行过程</h3><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;每个 Reducer 任务是一个 java 进程。Reducer 任务接收 Mapper 任务的输出，归约处理后写入到 HDFS 中。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以分为3个阶段</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第一阶段是 Reducer 任务会主动从 Mapper 任务复制其输出的键值对。 Mapper 任务可能会有很多，因此 Reducer 会复制多个 Mapper 的输出。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第二阶段是把复制到 Reducer 本地数据，全部进行合并，即把分散的数据合并成一个大的数据。再对合并后的数据排序。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;第三阶段是对排序后的键值对调用 reduce 方法。 键相等的键值对调用一次 reduce 方法，每次调用会产生零个或者多个键值对。最后把这些输出的键值对写入到 HDFS 文件中。</p>
<h2 id="8-安装-hadoop–准备工作"><a href="#8-安装-hadoop–准备工作" class="headerlink" title="8.安装 hadoop–准备工作"></a>8.安装 hadoop–准备工作</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;三台机器（内存大于2G） 分别写hosts、设定hostname。三台机器分别设置hostname 为master 、slave1、slave2。更改 hosts</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">vim /etc/hosts</div><div class="line">``` </div><div class="line"></div><div class="line">```bash</div><div class="line">192.168.0.87 master</div><div class="line">192.168.0.86 slave1</div><div class="line">192.168.0.85 slave2</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;关闭selinux，关闭firewalld</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[root@master ~]<span class="comment"># systemctl disable firewalld</span></div><div class="line">Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.</div><div class="line">Removed symlink /etc/systemd/system/basic.target.wants/firewalld.service.</div><div class="line">[root@master ~]<span class="comment"># systemctl stop firewalld</span></div><div class="line">[root@master ~]<span class="comment"># yum install -y iptables-services</span></div><div class="line"> </div><div class="line">[root@master ~]<span class="comment"># systemctl enable iptables</span></div><div class="line">Created symlink from /etc/systemd/system/basic.target.wants/iptables.service to /usr/lib/systemd/system/iptables.service.</div><div class="line">[root@master ~]<span class="comment"># systemctl start iptables</span></div><div class="line">[root@master ~]<span class="comment"># iptables -F</span></div><div class="line">[root@master ~]<span class="comment"># service iptables save</span></div><div class="line">iptables: Saving firewall rules to /etc/sysconfig/iptables:[ 确定 ]</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以上操作三台机器都需执行。</p>
<h2 id="9-安装-hadoop–密钥认证"><a href="#9-安装-hadoop–密钥认证" class="headerlink" title="9.安装 hadoop–密钥认证"></a>9.安装 hadoop–密钥认证</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master可以通过密钥登陆本机和两台slave</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master上生成密钥对：</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;ssh-keygen 一直回车</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">[root@master ~]<span class="comment"># ssh-keygen</span></div><div class="line">Generating public/private rsa key pair.</div><div class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/root/.ssh/id_rsa): </div><div class="line">Created directory <span class="string">'/root/.ssh'</span>.</div><div class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase): </div><div class="line">Enter same passphrase again: </div><div class="line">Your identification has been saved <span class="keyword">in</span> /root/.ssh/id_rsa.</div><div class="line">Your public key has been saved <span class="keyword">in</span> /root/.ssh/id_rsa.pub.</div><div class="line">The key fingerprint is:</div><div class="line">29:86:0f:70:28:2b:0a:9e:9c:98:39:dc:d2:c2:5b:d4 root@master</div><div class="line">The key<span class="string">'s randomart image is:</span></div><div class="line"><span class="string">+--[ RSA 2048]----+</span></div><div class="line"><span class="string">|                 |</span></div><div class="line"><span class="string">|   .             |</span></div><div class="line"><span class="string">|. o .            |</span></div><div class="line"><span class="string">| o o..    .      |</span></div><div class="line"><span class="string">|+  .oEo  S       |</span></div><div class="line"><span class="string">|Xo*  +  .        |</span></div><div class="line"><span class="string">|*X +  .          |</span></div><div class="line"><span class="string">| .=              |</span></div><div class="line"><span class="string">| .               |</span></div><div class="line"><span class="string">+-----------------+</span></div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;复制~/.ssh/id_rsa.pub 内容到本机和两台slave的 ~/.ssh/authorized_keys</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@master ~]<span class="comment"># cat .ssh/id_rsa.pub</span></div><div class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDZfOQKxMrCOf95iZvdNkTg32nQeUp3rywF+d0SS+t5ccZ0YjbZUZVFOkh5Sg5gdsjLgJoduZDePtYYhbex1kKPs8E6cx073ZqpW37TBGObCv7Inz1Ks+TSplnw/AKH6uRTEswC5P2SD+mJ+iz+OTgsNJyrj+OGGH1gOhmzQuAznSChqkJaihNhcBOOuJf8rVqhmplN9YPuGBlGc3It6uFHZvw8C42bC7xyqobL3FRZwKw85WQ9ZjdPTKQzg5rcn76gCld9fRuWkL1ABbP6MRIawN5eonYMYVS05PUGVadHM+a9L5nwTAbA4YqGyQ0m37mHV+5BwaBHxQyY5RSIiiyH root@master</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master ~]<span class="comment"># vim .ssh/authorized_keys</span></div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置本机和两台slave机器上的~/.ssh/authorized_keys文件权限为600</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master ~]<span class="comment"># chmod 600 ~/.ssh/authorized_keys</span></div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在master上</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[root@master ~]<span class="comment"># ssh master</span></div><div class="line">Last failed login: Tue Jan 10 16:58:22 CST 2017 from master on ssh:notty</div><div class="line">There were 8 failed login attempts since the last successful login.</div><div class="line">Last login: Tue Jan 10 16:53:03 2017 from 192.168.0.100</div><div class="line">[root@master ~]<span class="comment"># 登出</span></div><div class="line">Connection to master closed.</div><div class="line">[root@master ~]<span class="comment"># ssh slave1</span></div><div class="line">Last login: Tue Jan 10 16:52:18 2017 from master</div><div class="line">[root@slave1 ~]<span class="comment"># 登出</span></div><div class="line">Connection to slave1 closed.</div><div class="line">[root@master ~]<span class="comment"># ssh slave2</span></div><div class="line">Last login: Tue Jan 10 16:55:40 2017 from master</div><div class="line">[root@slave2 ~]<span class="comment"># 登出</span></div><div class="line">Connection to slave2 closed.</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;可以直接登陆</p>
<h2 id="10-安装-hadoop-–安装-JDK"><a href="#10-安装-hadoop-–安装-JDK" class="headerlink" title="10.安装 hadoop –安装 JDK"></a>10.安装 hadoop –安装 JDK</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;hadoop2.7 需要安装jdk1.7版本</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载地址<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html" target="_blank" rel="external">http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html</a></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压压缩包 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@master ~]<span class="comment"># tar zxvf jdk-8u111-linux-x64.tar.gz</span></div><div class="line">[root@master ~]<span class="comment"># mv jdk1.8.0_111 /usr/local/</span></div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;编写环境变量配置 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master ~]<span class="comment"># vim /etc/profile.d/java.sh</span></div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;写入</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.7.0_79</div><div class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/jre/lib/rt.jar:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/li</div><div class="line">b/tools.jar</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master ~]<span class="comment"># source /etc/profile.d/java.sh</span></div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;java -version 查看是否生效</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@master ~]<span class="comment"># java -version</span></div><div class="line">java version <span class="string">"1.8.0_111"</span></div><div class="line">Java(TM) SE Runtime Environment (build 1.8.0_111-b14)</div><div class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode)</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;slave1 和 slave2 重复上面的操作</p>
<h2 id="11-安装hadooop-安装-hadoop-包"><a href="#11-安装hadooop-安装-hadoop-包" class="headerlink" title="11.安装hadooop-安装 hadoop 包"></a>11.安装hadooop-安装 hadoop 包</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下操作在master上执行</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载地址 <a href="http://hadoop.apache.org/releases.html" target="_blank" rel="external">http://hadoop.apache.org/releases.html</a></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;镜像站 <a href="http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.1/" target="_blank" rel="external">http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.1/</a></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;下载2.7.1 binary版本  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解压 tar zxf hadoop-2.7.1.tar.gz</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@master ~]<span class="comment"># tar zxf hadoop-2.7.1.tar.gz</span></div><div class="line">[root@master ~]<span class="comment"># mv hadoop-2.7.1 /usr/local/hadoop</span></div><div class="line">[root@master ~]<span class="comment"># cd /usr/local/hadoop</span></div><div class="line">[root@master hadoop]<span class="comment"># mkdir tmp dfs dfs/data dfs/name</span></div><div class="line">[root@master hadoop]<span class="comment"># ls</span></div><div class="line">bin etc lib LICENSE.txt README.txt share</div><div class="line">dfs include libexec NOTICE.txt sbin tmp</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;把/usr/local/hadoop 目录分别拷贝至两个slave上</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># rsync -av /usr/local/hadoop slave1:/usr/local/</span></div><div class="line">[root@master hadoop]<span class="comment"># rsync -av /usr/local/hadoop slave2:/usr/local/</span></div></pre></td></tr></table></figure>
<h2 id="12-安装-hadoop-配置-hadoop"><a href="#12-安装-hadoop-配置-hadoop" class="headerlink" title="12.安装 hadoop -配置 hadoop"></a>12.安装 hadoop -配置 hadoop</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master上 vim /usr/local/hadoop/etc/hadoop/core-site.xml</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># vim /usr/local/hadoop/etc/hadoop/core-site.xml</span></div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">        &lt;value&gt;hdfs://192.168.0.87:9000&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">        &lt;value&gt;file:/usr/<span class="built_in">local</span>/hadoop/tmp&lt;/value&gt;</div><div class="line">        &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;io.file.buffer.size&lt;/name&gt;</div><div class="line">        &lt;value&gt;131702&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master上 vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml</span></div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</div><div class="line">        &lt;value&gt;file:/usr/<span class="built_in">local</span>/hadoop/dfs/name&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</div><div class="line">        &lt;value&gt;file:/usr/<span class="built_in">local</span>/hadoop/dfs/data&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">        &lt;value&gt;2&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">        &lt;value&gt;192.168.0.87:9001&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;</div><div class="line">        &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master上 vim /usr/local/hadoop/etc/hadoop/mapred-site.xml</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># mv /usr/local/hadoop/etc/hadoop/mapred-site.xml.template /usr/local/hadoop/etc/hadoop/mapred-site.xml</span></div><div class="line">[root@master hadoop]<span class="comment"># vim /usr/local/hadoop/etc/hadoop/mapred-site.xml</span></div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">        &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;172.7.15.113:10020&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;192.168.0.87:19888&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;master上 vim /usr/local/hadoop/etc/hadoop/yarn-site.xml</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># vim /usr/local/hadoop/etc/hadoop/yarn-site.xml</span></div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt;</div><div class="line">        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;192.168.0.87:8032&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;192.168.0.87:8030&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;192.168.0.87:8031&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;192.168.0.87:8033&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</div><div class="line">        &lt;value&gt;192.168.0.87:8088&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;</div><div class="line">        &lt;value&gt;2048&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下在master上操作</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改JAVA_HOME</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># cd /usr/local/hadoop/etc/hadoop</span></div><div class="line">[root@master hadoop]<span class="comment"># vim hadoop-env.sh</span></div></pre></td></tr></table></figure>
<p><img src="https://github.com/hcldirgit/image/blob/master/Hadoop%20%E5%A4%A7%E6%95%B0%E6%8D%AE/05.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改为</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.8.0_111</div></pre></td></tr></table></figure>
<p><img src="https://github.com/hcldirgit/image/blob/master/Hadoop%20%E5%A4%A7%E6%95%B0%E6%8D%AE/06.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;更改JAVA_HOME</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># vim yarn-env.sh</span></div></pre></td></tr></table></figure>
<p><img src="https://github.com/hcldirgit/image/blob/master/Hadoop%20%E5%A4%A7%E6%95%B0%E6%8D%AE/07.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;改为</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.8.0_111</div></pre></td></tr></table></figure>
<p><img src="https://github.com/hcldirgit/image/blob/master/Hadoop%20%E5%A4%A7%E6%95%B0%E6%8D%AE/08.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;slaves 文件修改</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># vim slaves</span></div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">192.168.0.86</div><div class="line">192.168.0.85</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将master上的etc目录同步至两个slave</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># rsync -av /usr/local/hadoop/etc/ slave1:/usr/local/hadoop/etc/</span></div><div class="line">sending incremental file list</div><div class="line">hadoop/</div><div class="line">hadoop/core-site.xml</div><div class="line">hadoop/hadoop-env.sh</div><div class="line">hadoop/hdfs-site.xml</div><div class="line">hadoop/mapred-site.xml</div><div class="line">hadoop/slaves</div><div class="line">hadoop/yarn-env.sh</div><div class="line">hadoop/yarn-site.xml</div><div class="line"> </div><div class="line">sent 6527 bytes received 269 bytes 13592.00 bytes/sec</div><div class="line">total size is 79165 speedup is 11.65</div><div class="line">[root@master hadoop]<span class="comment"># rsync -av /usr/local/hadoop/etc/ slave2:/usr/local/hadoop/etc/</span></div><div class="line">sending incremental file list</div><div class="line">hadoop/</div><div class="line">hadoop/core-site.xml</div><div class="line">hadoop/hadoop-env.sh</div><div class="line">hadoop/hdfs-site.xml</div><div class="line">hadoop/mapred-site.xml</div><div class="line">hadoop/slaves</div><div class="line">hadoop/yarn-env.sh</div><div class="line">hadoop/yarn-site.xml</div><div class="line"> </div><div class="line">sent 6527 bytes received 269 bytes 13592.00 bytes/sec</div><div class="line">total size is 79165 speedup is 11.65</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在master上操作即可，两个slave会自动启动</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;初始化</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># /usr/local/hadoop/bin/hdfs namenode -format</span></div><div class="line">[root@master hadoop]<span class="comment"># echo $?</span></div><div class="line">0</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;启动服务 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># /usr/local/hadoop/sbin/start-all.sh</span></div><div class="line">This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh</div><div class="line">Starting namenodes on [master]</div><div class="line">master: starting namenode, logging to /usr/<span class="built_in">local</span>/hadoop/logs/hadoop-root-namenode-master.out</div><div class="line">192.168.0.85: starting datanode, logging to /usr/<span class="built_in">local</span>/hadoop/logs/hadoop-root-datanode-slave2.out</div><div class="line">192.168.0.86: starting datanode, logging to /usr/<span class="built_in">local</span>/hadoop/logs/hadoop-root-datanode-slave1.out</div><div class="line">Starting secondary namenodes [master]</div><div class="line">master: starting secondarynamenode, logging to /usr/<span class="built_in">local</span>/hadoop/logs/hadoop-root-secondarynamenode-master.out</div><div class="line">starting yarn daemons</div><div class="line">starting resourcemanager, logging to /usr/<span class="built_in">local</span>/hadoop/logs/yarn-root-resourcemanager-master.out</div><div class="line">192.168.0.85: starting nodemanager, logging to /usr/<span class="built_in">local</span>/hadoop/logs/yarn-root-nodemanager-slave2.out</div><div class="line">192.168.0.86: starting nodemanager, logging to /usr/<span class="built_in">local</span>/hadoop/logs/yarn-root-nodemanager-slave1.out</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;停止服务 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># /usr/local/hadoop/sbin/stop-all.sh</span></div><div class="line">This script is Deprecated. Instead use stop-dfs.sh and stop-yarn.sh</div><div class="line">Stopping namenodes on [master]</div><div class="line">master: stopping namenode</div><div class="line">192.168.0.85: stopping datanode</div><div class="line">192.168.0.86: stopping datanode</div><div class="line">Stopping secondary namenodes [master]</div><div class="line">master: stopping secondarynamenode</div><div class="line">stopping yarn daemons</div><div class="line">stopping resourcemanager</div><div class="line">192.168.0.85: no nodemanager to stop</div><div class="line">192.168.0.86: no nodemanager to stop</div><div class="line">no proxyserver to stop</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;访问</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器打开<a href="http://192.168.0.87:8088" target="_blank" rel="external">http://192.168.0.87:8088</a></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;浏览器打开<a href="http://192.168.0.87:50070" target="_blank" rel="external">http://192.168.0.87:50070</a></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;也可以在 master、slave1、slave2 上执行命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># ps aux |grep java</span></div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># netstat -lnp |grep java</span></div><div class="line">tcp  0  0  0.0.0.0:50070      0.0.0.0:*  LISTEN  3626/java </div><div class="line">tcp  0  0  192.168.0.87:9000  0.0.0.0:*  LISTEN  3626/java </div><div class="line">tcp  0  0  192.168.0.87:9001  0.0.0.0:*  LISTEN  3820/java </div><div class="line">tcp6 0  0  192.168.0.87:8088  :::*       LISTEN  3985/java </div><div class="line">tcp6 0  0  192.168.0.87:8030  :::*       LISTEN  3985/java </div><div class="line">tcp6 0  0  192.168.0.87:8031  :::*       LISTEN  3985/java </div><div class="line">tcp6 0  0  192.168.0.87:8032  :::*       LISTEN  3985/java </div><div class="line">tcp6 0  0  192.168.0.87:8033  :::*       LISTEN  3985/java</div></pre></td></tr></table></figure>
<h2 id="13-测试-hadoop"><a href="#13-测试-hadoop" class="headerlink" title="13.测试 hadoop"></a>13.测试 hadoop</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下操作在master上实现</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;建立测试目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># cd /usr/local/hadoop</span></div><div class="line">[root@master hadoop]<span class="comment"># bin/hdfs dfs -mkdir /123</span></div><div class="line">[root@master hadoop]<span class="comment"># bin/hdfs dfs -ls /</span></div><div class="line">Found 1 items</div><div class="line">drwxr-xr-x     - root supergroup       0 2017-01-11 17:22 /123</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果提示 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">copyFromLocal: Cannot create directory /123/. Name node is <span class="keyword">in</span> safe mode.</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;这是因为开启了安全模式，解决办法</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># bin/hdfs dfsadmin -safemode leave</span></div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;将当前目录下的LICENSE.txt复制到hadopp中，查看/123/下有哪些文件  bin/hdfs dfs -ls /123</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># bin/hdfs dfs -copyFromLocal ./LICENSE.txt /123 </span></div><div class="line">[root@master hadoop]<span class="comment"># bin/hdfs dfs -ls /123</span></div><div class="line">Found 1 items</div><div class="line">-rw-r--r-- 2 root supergroup 15429 2017-01-11 17:29 /123/LICENSE.txt</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;用wordcount分析LICENSE.txt</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /123/LICENSE.txt /output/123</span></div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;bin/hdfs dfs -ls /output/123  查看分析后的文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># bin/hdfs dfs -ls /output/123</span></div><div class="line">Found 2 items</div><div class="line">-rw-r--r-- 2 root supergroup 0 2017-01-11 17:47 /output/123/_SUCCESS</div><div class="line">-rw-r--r-- 2 root supergroup 8006 2017-01-11 17:47 /output/123/part-r-00000</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;bin/hdfs dfs -cat /output/123/part-r-00000  查看分析结果</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@master hadoop]<span class="comment"># bin/hdfs dfs -cat /output/123/part-r-00000</span></div></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Hadoop/2. 2分钟读懂Hadoop和Spark的异同" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/09/03/Hadoop/2. 2分钟读懂Hadoop和Spark的异同/" class="article-date">
  	<time datetime="2017-09-02T18:02:06.162Z" itemprop="datePublished">2017-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/03/Hadoop/2. 2分钟读懂Hadoop和Spark的异同/">
        2分钟读懂Hadoop和Spark的异同
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;谈到大数据，相信大家对Hadoop和Apache Spark这两个名字并不陌生。但我们往往对它们的理解只是提留在字面上，并没有对它们进行深入的思考，下面不妨跟我一块看下它们究竟有什么异同。</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/2%E5%88%86%E9%92%9F%E8%AF%BB%E6%87%82Hadoop%E5%92%8CSpark%E7%9A%84%E5%BC%82%E5%90%8C/01.jpeg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决问题的层面不一样</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;首先，Hadoop和Apache Spark两者都是大数据框架，但是各自存在的目的不尽相同。Hadoop实质上更多是一个分布式数据基础设施: 它将巨大的数据集分派到一个由普通计算机组成的集群中的多个节点进行存储，意味着您不需要购买和维护昂贵的服务器硬件。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;同时，Hadoop还会索引和跟踪这些数据，让大数据处理和分析效率达到前所未有的高度。Spark，则是那么一个专门用来对那些分布式存储的大数据进行处理的工具，它并不会进行分布式数据的存储。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两者可合可分<br>Hadoop除了提供为大家所共识的HDFS分布式数据存储功能之外，还提供了叫做MapReduce的数据处理功能。所以这里我们完全可以抛开Spark，使用Hadoop自身的MapReduce来完成数据的处理。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;相反，Spark也不是非要依附在Hadoop身上才能生存。但如上所述，毕竟它没有提供文件管理系统，所以，它必须和其他的分布式文件系统进行集成才能运作。这里我们可以选择Hadoop的HDFS,也可以选择其他的基于云的数据系统平台。但Spark默认来说还是被用在Hadoop上面的，毕竟，大家都认为它们的结合是最好的。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;以下是从网上摘录的对MapReduce的最简洁明了的解析:</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;我们要数图书馆中的所有书。你数1号书架，我数2号书架。这就是“Map”。我们人越多，数书就更快。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;现在我们到一起，把所有人的统计数加在一起。这就是“Reduce”。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Spark数据处理速度秒杀MapReduce</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Spark因为其处理数据的方式不一样，会比MapReduce快上很多。MapReduce是分步对数据进行处理的: ”从集群中读取数据，进行一次处理，将结果写到集群，从集群中读取更新后的数据，进行下一次的处理，将结果写到集群，等等…“ Booz Allen Hamilton的数据科学家Kirk Borne如此解析。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;反观Spark，它会在内存中以接近“实时”的时间完成所有的数据分析：“从集群中读取数据，完成所有必须的分析处理，将结果写回集群，完成，” Born说道。Spark的批处理速度比MapReduce快近10倍，内存中的数据分析速度则快近100倍。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;如果需要处理的数据和结果需求大部分情况下是静态的，且你也有耐心等待批处理的完成的话，MapReduce的处理方式也是完全可以接受的。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;但如果你需要对流数据进行分析，比如那些来自于工厂的传感器收集回来的数据，又或者说你的应用是需要多重数据处理的，那么你也许更应该使用Spark进行处理。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;大部分机器学习算法都是需要多重数据处理的。此外，通常会用到Spark的应用场景有以下方面：实时的市场活动，在线产品推荐，网络安全分析，机器日记监控等。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;灾难恢复</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;两者的灾难恢复方式迥异，但是都很不错。因为Hadoop将每次处理后的数据都写入到磁盘上，所以其天生就能很有弹性的对系统错误进行处理。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Spark的数据对象存储在分布于数据集群中的叫做弹性分布式数据集(RDD: Resilient Distributed Dataset)中。“这些数据对象既可以放在内存，也可以放在磁盘，所以RDD同样也可以提供完成的灾难恢复功能，”Borne指出。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Cacti/5. cacti监控找到网卡的方法" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/09/03/Cacti/5. cacti监控找到网卡的方法/" class="article-date">
  	<time datetime="2017-09-02T18:00:30.950Z" itemprop="datePublished">2017-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/03/Cacti/5. cacti监控找到网卡的方法/">
        cacti 监控找到网卡的方法
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;只需要在客户机（要监控的机器）修改配置文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]<span class="comment"># vim /etc/snmp/snmpd.conf </span></div><div class="line"></div><div class="line"></div><div class="line">view    systemview    included   .1.3.6.1.2.1.1</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改为:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">view    systemview    included   .1.3.6.1.2.1</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后重启snmpd服务；</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]<span class="comment"># /etc/init.d/snmpd restart</span></div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在web监控里面添加</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/cacti%E7%9B%91%E6%8E%A7%E6%89%BE%E5%88%B0%E7%BD%91%E5%8D%A1%E7%9A%84%E6%96%B9%E6%B3%95/01.jpg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;类型选择Graph Types: SNMP - Interface Statistics 就看到客户机的网卡了。点击create。保存。</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/cacti%E7%9B%91%E6%8E%A7%E6%89%BE%E5%88%B0%E7%BD%91%E5%8D%A1%E7%9A%84%E6%96%B9%E6%B3%95/02.jpg?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在Graphs中就可以看到添加的网卡流量信息了；</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/cacti%E7%9B%91%E6%8E%A7%E6%89%BE%E5%88%B0%E7%BD%91%E5%8D%A1%E7%9A%84%E6%96%B9%E6%B3%95/03.jpg?raw=true" alt=""></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cacti/">Cacti</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Cacti/4. cacti 有图无数据参数设定" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/09/03/Cacti/4. cacti 有图无数据参数设定/" class="article-date">
  	<time datetime="2017-09-02T18:00:30.949Z" itemprop="datePublished">2017-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/03/Cacti/4. cacti 有图无数据参数设定/">
        cacti 有图无数据参数设定
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;一切参数设定在客户端。（/etc/snmp/snmpd.conf）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#       sec.name  source          community</span></div><div class="line">com2sec notConfigUser  192.168.1.107(cacti主机的IP)       public</div><div class="line"></div><div class="line"><span class="comment">#       name           incl/excl     subtree         mask(optional)</span></div><div class="line"><span class="comment">#view    systemview    included   .1.3.6.1.2.1.1</span></div><div class="line">view    systemview    included   .1.3.6.1.2.1</div><div class="line">view    systemview    included   .1.3.6.1.2.1.25.1.1</div><div class="line">view all        include         .1</div><div class="line"></div><div class="line"><span class="comment">#       group          context sec.model sec.level prefix read   write  notif</span></div><div class="line">access  notConfigGroup <span class="string">""</span>      any       noauth    exact  all none none</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;然后重启客户端</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">service snmpd restart</div></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cacti/">Cacti</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Cacti/3. cacti 的错误" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/09/03/Cacti/3. cacti 的错误/" class="article-date">
  	<time datetime="2017-09-02T18:00:30.948Z" itemprop="datePublished">2017-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/03/Cacti/3. cacti 的错误/">
        cacti的错误
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">FATAL: Cannot connect to MySQL server on <span class="string">'localhost'</span>. Please make sure you have specified a valid MySQL database name <span class="keyword">in</span> <span class="string">'include/config.php'</span></div></pre></td></tr></table></figure>
<h2 id="1-查看config-php下，是否配置正确"><a href="#1-查看config-php下，是否配置正确" class="headerlink" title="1.查看config.php下，是否配置正确"></a>1.查看config.php下，是否配置正确</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看cactiusr的host是否有localhost 权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql -ucactiuser -h localhost -p</div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;查看登录是否成功 ，如果登录正常则排除</p>
<h2 id="2-MYSQL权限问题"><a href="#2-MYSQL权限问题" class="headerlink" title="2.MYSQL权限问题"></a>2.MYSQL权限问题</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">SQL&gt;GRANT ALL ON cacti.* TO cactiuser@localhost IDENTIFIED BY <span class="string">'somepassword'</span>;</div></pre></td></tr></table></figure>
<h2 id="3-当mysql中的所有配置和cacti的config-php都正确，却还是出现该错误时，那就是mysql套接字的原因了"><a href="#3-当mysql中的所有配置和cacti的config-php都正确，却还是出现该错误时，那就是mysql套接字的原因了" class="headerlink" title="3.当mysql中的所有配置和cacti的config.php都正确，却还是出现该错误时，那就是mysql套接字的原因了~"></a>3.当mysql中的所有配置和cacti的config.php都正确，却还是出现该错误时，那就是mysql套接字的原因了~</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;cacti会自动的去查找/var/lib/mysql/mysql.sock 该套接字，但是如果是源码安装的mysql，未指定套接字位置时，套接字的位置为/tmp/mysql.sock，由于cacti未找到/var/lib/mysql/mysql.sock，所以显示的是“Cannot connect to MySQL server on ‘localhost’”</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;解决：做一个/tmp/mysql.sock到/var/lib/mysql/mysql.sock的软连接</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ln -s  /tmp/mysql.sock  /var/lib/mysql/mysql.sock</div></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cacti/">Cacti</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
    <article id="post-Cacti/2. cacti增加客户端监控" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/09/03/Cacti/2. cacti增加客户端监控/" class="article-date">
  	<time datetime="2017-09-02T18:00:30.947Z" itemprop="datePublished">2017-09-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/03/Cacti/2. cacti增加客户端监控/">
        cacti增加客户端监控
        
      </a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-安装-snmp"><a href="#1-安装-snmp" class="headerlink" title="1.安装 snmp"></a>1.安装 snmp</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@lnmp ~]<span class="comment"># yum install -y net-snmp</span></div></pre></td></tr></table></figure>
<h2 id="2-修改-snmp-conf"><a href="#2-修改-snmp-conf" class="headerlink" title="2.修改 snmp.conf"></a>2.修改 snmp.conf</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@lnmp ~]<span class="comment"># vim /etc/snmp/snmpd.conf</span></div></pre></td></tr></table></figure>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;修改 syslocation 以及 syscontact ，其中 syslocation 可以写本机 ip，syscontact 写管理员邮箱。</p>
<p><img src="https://github.com/hcldirgit/image/blob/master/cacti%E5%A2%9E%E5%8A%A0%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9B%91%E6%8E%A7/01.png?raw=true" alt=""></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3.启动 snmp</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@lnmp ~]<span class="comment"># service snmpd start</span></div></pre></td></tr></table></figure>
<h2 id="4-cacti-增加监控"><a href="#4-cacti-增加监控" class="headerlink" title="4.cacti 增加监控"></a>4.cacti 增加监控</h2><p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;登录 cacti 管理后台，点控制台，再点设备，在右上角点 “add” </p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;描述： 写本机 ip 或自定义一个名字</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;主机名：hostname 写本机 ip</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设备模版：选择 Net-SNMP Device </p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;采集线程数：可以选择 2-5</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;SNMP版本：改为 version 2</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;设置完成点右下角的创建，然后点右上角的 “Create Graphs for this Device”</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Graph Types:  选择SNMP - Interface Statistics </p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在下面框中选择要监控的网卡，比如我选择eth0, 在最右侧小方块里打对勾，然后点右下角的create（如果在这一步找不到网卡，可以参考<a href="https://hcldirgit.github.io/2017/08/12/Cacti/5.%20cacti%E7%9B%91%E6%8E%A7%E6%89%BE%E5%88%B0%E7%BD%91%E5%8D%A1%E7%9A%84%E6%96%B9%E6%B3%95/">cacti监控找到网卡的方法</a>）</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;Graph Types:  再选择 Graph Template Based</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在下面的框中，选择你要监控的项目，比如ucd/net - Load Average </p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;在右侧小方块中打对勾，然后点右下角的创建</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;点击设备，选择新增加主机，选择  defaur tree 点 go</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;defaut tree 下面已经增加了添加的主机，图形一开始不会那么快出来，要等一会才可以</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cacti/">Cacti</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
      
    
  </div>
  
</article>







  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/32/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/31/">31</a><a class="page-number" href="/page/32/">32</a><span class="page-number current">33</span><a class="page-number" href="/page/34/">34</a><a class="page-number" href="/page/35/">35</a><span class="space">&hellip;</span><a class="page-number" href="/page/63/">63</a><a class="extend next" rel="next" href="/page/34/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2017 失落的乐章
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/smackgg/hexo-theme-smackdown" target="_blank">Smackdown</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    

<script>
	var yiliaConfig = {
		fancybox: ,
		mathjax: ,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="/js/main.js"></script>



  </div>
</body>
</html>